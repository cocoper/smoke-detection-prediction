{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import xgboost as xgb\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()+'\\\\data\\\\alarm data.csv'\n",
    "\n",
    "data = pd.read_csv(path,na_values=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 516 entries, 0 to 515\n",
      "Data columns (total 2 columns):\n",
      "Dis      516 non-null float64\n",
      "Alarm    516 non-null object\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 8.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 =  pd.DataFrame(data = data,index = range(1,len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reindex(index = range(1,len(data)),fill_value = np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.Alarm == '20.1a','Alarm'] = 20.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data.Alarm[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:,'Alarm'] = data.Alarm.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 515 entries, 1 to 515\n",
      "Data columns (total 2 columns):\n",
      "Dis      515 non-null float64\n",
      "Alarm    515 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 8.1 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(data['Dis'],data['Alarm'],\n",
    "                                                 test_size = 0.3,\n",
    "                                                 random_state = 42,\n",
    "                                                 shuffle = True\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(-1,1)\n",
    "# y_train = y_train.reshape(-1,1)\n",
    "x_test = x_test.reshape(-1,1)\n",
    "# y_test = y_test.reshape(-1,1)\n",
    "# x_train = x_train.ravel()\n",
    "y_train = y_train.ravel()\n",
    "# x_test = x_test.ravel()\n",
    "y_test = y_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(n_estimators=500,\n",
    "                             n_jobs=4,\n",
    "                             criterion='mse',\n",
    "                             max_depth = 20,\n",
    "                             min_samples_split = 2,\n",
    "                             random_state = 42,\n",
    "                             verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score=0.999630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "regr.fit(x_train,y_train)\n",
    "y_pred=regr.predict(x_test)\n",
    "r2score = r2_score(y_test,y_pred)\n",
    "print('R2 score={:f}'.format(r2score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({ 'X':x_test.reshape(1,-1)[0],\n",
    "                        'y_true':y_test,\n",
    "                        'y_pred':y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\pandas\\plotting\\_core.py:1716: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  series.name = label\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21ffcfee2e8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEKCAYAAAAcgp5RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEuD+H6cVoD9tr1pRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = result.sort_values(by='X',ascending=True)\n",
    "result.plot(x=result['X'],y=['y_true','y_pred'],kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.getcwd()+'\\\\rf_model.model','wb') as f: # Save RF model\n",
    "    pickle.dump(regr,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = {'n_estimators':[10,20,50,60,80,100,200,500,1000],\n",
    "            'max_depth':[2,5,7,10,12,15,20,30],\n",
    "            'min_samples_split':[2,3,4,5,6],\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state = 42,verbose =1, n_jobs=4)\n",
    "grid_regr = GridSearchCV(rf,grid_param,scoring = 'r2',cv =3 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n",
      "C:\\Users\\XuanYang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:725: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "grid_regr.fit(x_train.reshape(-1,1),y_train.reshape(-1,1))\n",
    "print(grid_regr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_data = np.array([587,123,257])\n",
    "pred_data_xgb = xgb.DMatrix(pred_data.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 179.38229524,   20.86493833,   41.35538111])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.predict(pred_data.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(x_train,y_train)\n",
    "dvalid = xgb.DMatrix(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evallist = [(dvalid,'eval'),(dtrain,'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\"objective\":\"reg:linear\",\n",
    "              \"booster\":\"gbtree\",\n",
    "              \"eta\":0.005,\n",
    "              \"max_depth\":10,\n",
    "              \"subsample\":0.5,\n",
    "              \"colsample_bytree\":0.4,\n",
    "              \"min_child_weight\":4,\n",
    "             \"silent\":1,\n",
    "             \"thread\":32,\n",
    "             \"seed\":42,\n",
    "            \n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:127.547\ttrain-rmse:116.203\n",
      "Multiple eval metrics have been passed: 'train-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until train-rmse hasn't improved in 500 rounds.\n",
      "[1]\teval-rmse:126.971\ttrain-rmse:115.691\n",
      "[2]\teval-rmse:126.381\ttrain-rmse:115.168\n",
      "[3]\teval-rmse:125.791\ttrain-rmse:114.628\n",
      "[4]\teval-rmse:125.221\ttrain-rmse:114.12\n",
      "[5]\teval-rmse:124.63\ttrain-rmse:113.587\n",
      "[6]\teval-rmse:124.062\ttrain-rmse:113.079\n",
      "[7]\teval-rmse:123.499\ttrain-rmse:112.572\n",
      "[8]\teval-rmse:122.916\ttrain-rmse:112.052\n",
      "[9]\teval-rmse:122.341\ttrain-rmse:111.532\n",
      "[10]\teval-rmse:121.788\ttrain-rmse:111.016\n",
      "[11]\teval-rmse:121.231\ttrain-rmse:110.517\n",
      "[12]\teval-rmse:120.653\ttrain-rmse:110.004\n",
      "[13]\teval-rmse:120.14\ttrain-rmse:109.535\n",
      "[14]\teval-rmse:119.589\ttrain-rmse:109.033\n",
      "[15]\teval-rmse:119.037\ttrain-rmse:108.539\n",
      "[16]\teval-rmse:118.505\ttrain-rmse:108.045\n",
      "[17]\teval-rmse:117.947\ttrain-rmse:107.54\n",
      "[18]\teval-rmse:117.446\ttrain-rmse:107.081\n",
      "[19]\teval-rmse:116.91\ttrain-rmse:106.599\n",
      "[20]\teval-rmse:116.384\ttrain-rmse:106.129\n",
      "[21]\teval-rmse:115.851\ttrain-rmse:105.654\n",
      "[22]\teval-rmse:115.307\ttrain-rmse:105.171\n",
      "[23]\teval-rmse:114.765\ttrain-rmse:104.688\n",
      "[24]\teval-rmse:114.248\ttrain-rmse:104.202\n",
      "[25]\teval-rmse:113.737\ttrain-rmse:103.744\n",
      "[26]\teval-rmse:113.223\ttrain-rmse:103.283\n",
      "[27]\teval-rmse:112.695\ttrain-rmse:102.813\n",
      "[28]\teval-rmse:112.185\ttrain-rmse:102.347\n",
      "[29]\teval-rmse:111.663\ttrain-rmse:101.881\n",
      "[30]\teval-rmse:111.185\ttrain-rmse:101.439\n",
      "[31]\teval-rmse:110.665\ttrain-rmse:100.976\n",
      "[32]\teval-rmse:110.155\ttrain-rmse:100.519\n",
      "[33]\teval-rmse:109.718\ttrain-rmse:100.102\n",
      "[34]\teval-rmse:109.206\ttrain-rmse:99.639\n",
      "[35]\teval-rmse:108.696\ttrain-rmse:99.1787\n",
      "[36]\teval-rmse:108.218\ttrain-rmse:98.7419\n",
      "[37]\teval-rmse:107.734\ttrain-rmse:98.2893\n",
      "[38]\teval-rmse:107.273\ttrain-rmse:97.8669\n",
      "[39]\teval-rmse:106.784\ttrain-rmse:97.4047\n",
      "[40]\teval-rmse:106.295\ttrain-rmse:96.9636\n",
      "[41]\teval-rmse:105.808\ttrain-rmse:96.5095\n",
      "[42]\teval-rmse:105.355\ttrain-rmse:96.0683\n",
      "[43]\teval-rmse:104.867\ttrain-rmse:95.6262\n",
      "[44]\teval-rmse:104.397\ttrain-rmse:95.1848\n",
      "[45]\teval-rmse:103.93\ttrain-rmse:94.763\n",
      "[46]\teval-rmse:103.48\ttrain-rmse:94.3436\n",
      "[47]\teval-rmse:103.012\ttrain-rmse:93.9214\n",
      "[48]\teval-rmse:102.532\ttrain-rmse:93.4936\n",
      "[49]\teval-rmse:102.08\ttrain-rmse:93.0653\n",
      "[50]\teval-rmse:101.633\ttrain-rmse:92.6341\n",
      "[51]\teval-rmse:101.175\ttrain-rmse:92.2161\n",
      "[52]\teval-rmse:100.737\ttrain-rmse:91.7966\n",
      "[53]\teval-rmse:100.274\ttrain-rmse:91.3783\n",
      "[54]\teval-rmse:99.8181\ttrain-rmse:90.9692\n",
      "[55]\teval-rmse:99.3696\ttrain-rmse:90.5696\n",
      "[56]\teval-rmse:98.913\ttrain-rmse:90.1576\n",
      "[57]\teval-rmse:98.4727\ttrain-rmse:89.7599\n",
      "[58]\teval-rmse:98.0124\ttrain-rmse:89.3526\n",
      "[59]\teval-rmse:97.5744\ttrain-rmse:88.9548\n",
      "[60]\teval-rmse:97.1387\ttrain-rmse:88.5629\n",
      "[61]\teval-rmse:96.6905\ttrain-rmse:88.1631\n",
      "[62]\teval-rmse:96.2524\ttrain-rmse:87.7646\n",
      "[63]\teval-rmse:95.8353\ttrain-rmse:87.3598\n",
      "[64]\teval-rmse:95.4354\ttrain-rmse:86.9881\n",
      "[65]\teval-rmse:95.0165\ttrain-rmse:86.5814\n",
      "[66]\teval-rmse:94.5837\ttrain-rmse:86.1896\n",
      "[67]\teval-rmse:94.1513\ttrain-rmse:85.8022\n",
      "[68]\teval-rmse:93.7881\ttrain-rmse:85.4572\n",
      "[69]\teval-rmse:93.3735\ttrain-rmse:85.0581\n",
      "[70]\teval-rmse:92.9667\ttrain-rmse:84.6689\n",
      "[71]\teval-rmse:92.5597\ttrain-rmse:84.2733\n",
      "[72]\teval-rmse:92.1878\ttrain-rmse:83.9233\n",
      "[73]\teval-rmse:91.7938\ttrain-rmse:83.542\n",
      "[74]\teval-rmse:91.3936\ttrain-rmse:83.1623\n",
      "[75]\teval-rmse:91.0067\ttrain-rmse:82.7874\n",
      "[76]\teval-rmse:90.5976\ttrain-rmse:82.4209\n",
      "[77]\teval-rmse:90.1974\ttrain-rmse:82.0447\n",
      "[78]\teval-rmse:89.7996\ttrain-rmse:81.6714\n",
      "[79]\teval-rmse:89.4291\ttrain-rmse:81.3266\n",
      "[80]\teval-rmse:89.0179\ttrain-rmse:80.9596\n",
      "[81]\teval-rmse:88.6347\ttrain-rmse:80.6012\n",
      "[82]\teval-rmse:88.2465\ttrain-rmse:80.2296\n",
      "[83]\teval-rmse:87.8631\ttrain-rmse:79.8825\n",
      "[84]\teval-rmse:87.4721\ttrain-rmse:79.5118\n",
      "[85]\teval-rmse:87.09\ttrain-rmse:79.168\n",
      "[86]\teval-rmse:86.71\ttrain-rmse:78.8226\n",
      "[87]\teval-rmse:86.3445\ttrain-rmse:78.4631\n",
      "[88]\teval-rmse:85.9558\ttrain-rmse:78.1148\n",
      "[89]\teval-rmse:85.5764\ttrain-rmse:77.7734\n",
      "[90]\teval-rmse:85.1941\ttrain-rmse:77.4311\n",
      "[91]\teval-rmse:84.8285\ttrain-rmse:77.0814\n",
      "[92]\teval-rmse:84.4599\ttrain-rmse:76.7279\n",
      "[93]\teval-rmse:84.1019\ttrain-rmse:76.3884\n",
      "[94]\teval-rmse:83.7183\ttrain-rmse:76.0445\n",
      "[95]\teval-rmse:83.356\ttrain-rmse:75.6982\n",
      "[96]\teval-rmse:82.9907\ttrain-rmse:75.3527\n",
      "[97]\teval-rmse:82.6397\ttrain-rmse:75.0111\n",
      "[98]\teval-rmse:82.275\ttrain-rmse:74.6818\n",
      "[99]\teval-rmse:81.9189\ttrain-rmse:74.3451\n",
      "[100]\teval-rmse:81.5763\ttrain-rmse:74.0187\n",
      "[101]\teval-rmse:81.2275\ttrain-rmse:73.6847\n",
      "[102]\teval-rmse:80.8718\ttrain-rmse:73.3479\n",
      "[103]\teval-rmse:80.5305\ttrain-rmse:73.0145\n",
      "[104]\teval-rmse:80.1788\ttrain-rmse:72.697\n",
      "[105]\teval-rmse:79.8249\ttrain-rmse:72.3747\n",
      "[106]\teval-rmse:79.4717\ttrain-rmse:72.0503\n",
      "[107]\teval-rmse:79.1421\ttrain-rmse:71.7303\n",
      "[108]\teval-rmse:78.7956\ttrain-rmse:71.4009\n",
      "[109]\teval-rmse:78.4645\ttrain-rmse:71.0982\n",
      "[110]\teval-rmse:78.1252\ttrain-rmse:70.776\n",
      "[111]\teval-rmse:77.8329\ttrain-rmse:70.4957\n",
      "[112]\teval-rmse:77.5022\ttrain-rmse:70.1751\n",
      "[113]\teval-rmse:77.1748\ttrain-rmse:69.865\n",
      "[114]\teval-rmse:76.8346\ttrain-rmse:69.5599\n",
      "[115]\teval-rmse:76.5033\ttrain-rmse:69.2454\n",
      "[116]\teval-rmse:76.1731\ttrain-rmse:68.9371\n",
      "[117]\teval-rmse:75.8532\ttrain-rmse:68.6231\n",
      "[118]\teval-rmse:75.5369\ttrain-rmse:68.3117\n",
      "[119]\teval-rmse:75.2121\ttrain-rmse:68.0014\n",
      "[120]\teval-rmse:74.8993\ttrain-rmse:67.7008\n",
      "[121]\teval-rmse:74.5767\ttrain-rmse:67.3937\n",
      "[122]\teval-rmse:74.2663\ttrain-rmse:67.0952\n",
      "[123]\teval-rmse:73.9556\ttrain-rmse:66.8077\n",
      "[124]\teval-rmse:73.6453\ttrain-rmse:66.5251\n",
      "[125]\teval-rmse:73.3422\ttrain-rmse:66.2415\n",
      "[126]\teval-rmse:73.0275\ttrain-rmse:65.9566\n",
      "[127]\teval-rmse:72.7021\ttrain-rmse:65.6641\n",
      "[128]\teval-rmse:72.3834\ttrain-rmse:65.3749\n",
      "[129]\teval-rmse:72.0744\ttrain-rmse:65.0778\n",
      "[130]\teval-rmse:71.7635\ttrain-rmse:64.7959\n",
      "[131]\teval-rmse:71.4497\ttrain-rmse:64.5123\n",
      "[132]\teval-rmse:71.1506\ttrain-rmse:64.2241\n",
      "[133]\teval-rmse:70.8587\ttrain-rmse:63.9486\n",
      "[134]\teval-rmse:70.5689\ttrain-rmse:63.662\n",
      "[135]\teval-rmse:70.2698\ttrain-rmse:63.376\n",
      "[136]\teval-rmse:69.9607\ttrain-rmse:63.0987\n",
      "[137]\teval-rmse:69.6659\ttrain-rmse:62.8186\n",
      "[138]\teval-rmse:69.3735\ttrain-rmse:62.5406\n",
      "[139]\teval-rmse:69.0977\ttrain-rmse:62.278\n",
      "[140]\teval-rmse:68.8002\ttrain-rmse:61.9929\n",
      "[141]\teval-rmse:68.5038\ttrain-rmse:61.7255\n",
      "[142]\teval-rmse:68.2484\ttrain-rmse:61.4806\n",
      "[143]\teval-rmse:67.9468\ttrain-rmse:61.2107\n",
      "[144]\teval-rmse:67.659\ttrain-rmse:60.9378\n",
      "[145]\teval-rmse:67.3787\ttrain-rmse:60.6715\n",
      "[146]\teval-rmse:67.0993\ttrain-rmse:60.3971\n",
      "[147]\teval-rmse:66.8233\ttrain-rmse:60.1412\n",
      "[148]\teval-rmse:66.5667\ttrain-rmse:59.898\n",
      "[149]\teval-rmse:66.2886\ttrain-rmse:59.6315\n",
      "[150]\teval-rmse:66.0062\ttrain-rmse:59.3766\n",
      "[151]\teval-rmse:65.7326\ttrain-rmse:59.1073\n",
      "[152]\teval-rmse:65.4493\ttrain-rmse:58.8525\n",
      "[153]\teval-rmse:65.1918\ttrain-rmse:58.6112\n",
      "[154]\teval-rmse:64.9157\ttrain-rmse:58.3495\n",
      "[155]\teval-rmse:64.6408\ttrain-rmse:58.089\n",
      "[156]\teval-rmse:64.3693\ttrain-rmse:57.8217\n",
      "[157]\teval-rmse:64.1292\ttrain-rmse:57.5943\n",
      "[158]\teval-rmse:63.8645\ttrain-rmse:57.3414\n",
      "[159]\teval-rmse:63.5946\ttrain-rmse:57.0845\n",
      "[160]\teval-rmse:63.3264\ttrain-rmse:56.8273\n",
      "[161]\teval-rmse:63.0661\ttrain-rmse:56.578\n",
      "[162]\teval-rmse:62.815\ttrain-rmse:56.3454\n",
      "[163]\teval-rmse:62.5641\ttrain-rmse:56.1112\n",
      "[164]\teval-rmse:62.313\ttrain-rmse:55.8609\n",
      "[165]\teval-rmse:62.0503\ttrain-rmse:55.6116\n",
      "[166]\teval-rmse:61.7885\ttrain-rmse:55.3677\n",
      "[167]\teval-rmse:61.5272\ttrain-rmse:55.1193\n",
      "[168]\teval-rmse:61.2745\ttrain-rmse:54.8708\n",
      "[169]\teval-rmse:61.0209\ttrain-rmse:54.6402\n",
      "[170]\teval-rmse:60.7682\ttrain-rmse:54.3905\n",
      "[171]\teval-rmse:60.5244\ttrain-rmse:54.1494\n",
      "[172]\teval-rmse:60.2664\ttrain-rmse:53.9059\n",
      "[173]\teval-rmse:60.0316\ttrain-rmse:53.6751\n",
      "[174]\teval-rmse:59.7804\ttrain-rmse:53.4362\n",
      "[175]\teval-rmse:59.5359\ttrain-rmse:53.1977\n",
      "[176]\teval-rmse:59.279\ttrain-rmse:52.9661\n",
      "[177]\teval-rmse:59.031\ttrain-rmse:52.7295\n",
      "[178]\teval-rmse:58.7759\ttrain-rmse:52.5003\n",
      "[179]\teval-rmse:58.5308\ttrain-rmse:52.2788\n",
      "[180]\teval-rmse:58.2862\ttrain-rmse:52.0459\n",
      "[181]\teval-rmse:58.0501\ttrain-rmse:51.8097\n",
      "[182]\teval-rmse:57.8069\ttrain-rmse:51.5878\n",
      "[183]\teval-rmse:57.5656\ttrain-rmse:51.3573\n",
      "[184]\teval-rmse:57.3248\ttrain-rmse:51.1277\n",
      "[185]\teval-rmse:57.0895\ttrain-rmse:50.8967\n",
      "[186]\teval-rmse:56.8526\ttrain-rmse:50.6817\n",
      "[187]\teval-rmse:56.6194\ttrain-rmse:50.4539\n",
      "[188]\teval-rmse:56.3898\ttrain-rmse:50.2293\n",
      "[189]\teval-rmse:56.1832\ttrain-rmse:50.0326\n",
      "[190]\teval-rmse:55.9366\ttrain-rmse:49.7994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[191]\teval-rmse:55.7083\ttrain-rmse:49.5814\n",
      "[192]\teval-rmse:55.4823\ttrain-rmse:49.3656\n",
      "[193]\teval-rmse:55.2585\ttrain-rmse:49.1432\n",
      "[194]\teval-rmse:55.0303\ttrain-rmse:48.9376\n",
      "[195]\teval-rmse:54.8152\ttrain-rmse:48.7271\n",
      "[196]\teval-rmse:54.5893\ttrain-rmse:48.521\n",
      "[197]\teval-rmse:54.3681\ttrain-rmse:48.3032\n",
      "[198]\teval-rmse:54.141\ttrain-rmse:48.0907\n",
      "[199]\teval-rmse:53.9219\ttrain-rmse:47.875\n",
      "[200]\teval-rmse:53.7007\ttrain-rmse:47.6635\n",
      "[201]\teval-rmse:53.4803\ttrain-rmse:47.4464\n",
      "[202]\teval-rmse:53.2595\ttrain-rmse:47.2287\n",
      "[203]\teval-rmse:53.0572\ttrain-rmse:47.0399\n",
      "[204]\teval-rmse:52.8502\ttrain-rmse:46.8353\n",
      "[205]\teval-rmse:52.638\ttrain-rmse:46.6412\n",
      "[206]\teval-rmse:52.4329\ttrain-rmse:46.4528\n",
      "[207]\teval-rmse:52.2158\ttrain-rmse:46.2461\n",
      "[208]\teval-rmse:52.0061\ttrain-rmse:46.0396\n",
      "[209]\teval-rmse:51.7925\ttrain-rmse:45.8371\n",
      "[210]\teval-rmse:51.5829\ttrain-rmse:45.6457\n",
      "[211]\teval-rmse:51.3735\ttrain-rmse:45.4386\n",
      "[212]\teval-rmse:51.1603\ttrain-rmse:45.2299\n",
      "[213]\teval-rmse:50.9492\ttrain-rmse:45.024\n",
      "[214]\teval-rmse:50.7498\ttrain-rmse:44.8245\n",
      "[215]\teval-rmse:50.546\ttrain-rmse:44.63\n",
      "[216]\teval-rmse:50.343\ttrain-rmse:44.4321\n",
      "[217]\teval-rmse:50.141\ttrain-rmse:44.2403\n",
      "[218]\teval-rmse:49.9358\ttrain-rmse:44.0478\n",
      "[219]\teval-rmse:49.7406\ttrain-rmse:43.8609\n",
      "[220]\teval-rmse:49.5432\ttrain-rmse:43.6726\n",
      "[221]\teval-rmse:49.3466\ttrain-rmse:43.481\n",
      "[222]\teval-rmse:49.1429\ttrain-rmse:43.2953\n",
      "[223]\teval-rmse:48.958\ttrain-rmse:43.1233\n",
      "[224]\teval-rmse:48.7618\ttrain-rmse:42.9351\n",
      "[225]\teval-rmse:48.5612\ttrain-rmse:42.7375\n",
      "[226]\teval-rmse:48.3647\ttrain-rmse:42.5518\n",
      "[227]\teval-rmse:48.1691\ttrain-rmse:42.3666\n",
      "[228]\teval-rmse:47.9757\ttrain-rmse:42.1825\n",
      "[229]\teval-rmse:47.7876\ttrain-rmse:42.0035\n",
      "[230]\teval-rmse:47.5953\ttrain-rmse:41.8291\n",
      "[231]\teval-rmse:47.4188\ttrain-rmse:41.6658\n",
      "[232]\teval-rmse:47.2284\ttrain-rmse:41.4922\n",
      "[233]\teval-rmse:47.0568\ttrain-rmse:41.3317\n",
      "[234]\teval-rmse:46.8808\ttrain-rmse:41.1573\n",
      "[235]\teval-rmse:46.6943\ttrain-rmse:40.9882\n",
      "[236]\teval-rmse:46.5031\ttrain-rmse:40.8004\n",
      "[237]\teval-rmse:46.3253\ttrain-rmse:40.6263\n",
      "[238]\teval-rmse:46.1458\ttrain-rmse:40.4486\n",
      "[239]\teval-rmse:45.9649\ttrain-rmse:40.2823\n",
      "[240]\teval-rmse:45.775\ttrain-rmse:40.0964\n",
      "[241]\teval-rmse:45.5958\ttrain-rmse:39.9215\n",
      "[242]\teval-rmse:45.4116\ttrain-rmse:39.7476\n",
      "[243]\teval-rmse:45.2331\ttrain-rmse:39.5685\n",
      "[244]\teval-rmse:45.0499\ttrain-rmse:39.3871\n",
      "[245]\teval-rmse:44.872\ttrain-rmse:39.2109\n",
      "[246]\teval-rmse:44.6938\ttrain-rmse:39.0477\n",
      "[247]\teval-rmse:44.5211\ttrain-rmse:38.8774\n",
      "[248]\teval-rmse:44.3575\ttrain-rmse:38.7239\n",
      "[249]\teval-rmse:44.1775\ttrain-rmse:38.5522\n",
      "[250]\teval-rmse:44.0038\ttrain-rmse:38.3918\n",
      "[251]\teval-rmse:43.832\ttrain-rmse:38.2243\n",
      "[252]\teval-rmse:43.6674\ttrain-rmse:38.0605\n",
      "[253]\teval-rmse:43.4846\ttrain-rmse:37.8871\n",
      "[254]\teval-rmse:43.3195\ttrain-rmse:37.7274\n",
      "[255]\teval-rmse:43.147\ttrain-rmse:37.5577\n",
      "[256]\teval-rmse:42.9881\ttrain-rmse:37.4035\n",
      "[257]\teval-rmse:42.8185\ttrain-rmse:37.2381\n",
      "[258]\teval-rmse:42.6545\ttrain-rmse:37.0824\n",
      "[259]\teval-rmse:42.4884\ttrain-rmse:36.9308\n",
      "[260]\teval-rmse:42.322\ttrain-rmse:36.7681\n",
      "[261]\teval-rmse:42.1558\ttrain-rmse:36.6031\n",
      "[262]\teval-rmse:41.9943\ttrain-rmse:36.4545\n",
      "[263]\teval-rmse:41.8314\ttrain-rmse:36.3054\n",
      "[264]\teval-rmse:41.6676\ttrain-rmse:36.1524\n",
      "[265]\teval-rmse:41.4988\ttrain-rmse:35.9914\n",
      "[266]\teval-rmse:41.333\ttrain-rmse:35.8278\n",
      "[267]\teval-rmse:41.1721\ttrain-rmse:35.6682\n",
      "[268]\teval-rmse:41.0108\ttrain-rmse:35.5089\n",
      "[269]\teval-rmse:40.8481\ttrain-rmse:35.3492\n",
      "[270]\teval-rmse:40.6799\ttrain-rmse:35.1839\n",
      "[271]\teval-rmse:40.5262\ttrain-rmse:35.0304\n",
      "[272]\teval-rmse:40.3689\ttrain-rmse:34.8806\n",
      "[273]\teval-rmse:40.2144\ttrain-rmse:34.739\n",
      "[274]\teval-rmse:40.0622\ttrain-rmse:34.5927\n",
      "[275]\teval-rmse:39.9069\ttrain-rmse:34.4392\n",
      "[276]\teval-rmse:39.7569\ttrain-rmse:34.2988\n",
      "[277]\teval-rmse:39.5994\ttrain-rmse:34.149\n",
      "[278]\teval-rmse:39.4468\ttrain-rmse:33.9994\n",
      "[279]\teval-rmse:39.2939\ttrain-rmse:33.8513\n",
      "[280]\teval-rmse:39.1374\ttrain-rmse:33.7045\n",
      "[281]\teval-rmse:38.9851\ttrain-rmse:33.559\n",
      "[282]\teval-rmse:38.8394\ttrain-rmse:33.4162\n",
      "[283]\teval-rmse:38.7012\ttrain-rmse:33.2861\n",
      "[284]\teval-rmse:38.5593\ttrain-rmse:33.1465\n",
      "[285]\teval-rmse:38.4134\ttrain-rmse:33.0015\n",
      "[286]\teval-rmse:38.2746\ttrain-rmse:32.8726\n",
      "[287]\teval-rmse:38.1263\ttrain-rmse:32.7312\n",
      "[288]\teval-rmse:37.9716\ttrain-rmse:32.5796\n",
      "[289]\teval-rmse:37.8317\ttrain-rmse:32.4404\n",
      "[290]\teval-rmse:37.6884\ttrain-rmse:32.3089\n",
      "[291]\teval-rmse:37.5428\ttrain-rmse:32.1644\n",
      "[292]\teval-rmse:37.4117\ttrain-rmse:32.0403\n",
      "[293]\teval-rmse:37.2686\ttrain-rmse:31.9057\n",
      "[294]\teval-rmse:37.1312\ttrain-rmse:31.7791\n",
      "[295]\teval-rmse:37.0003\ttrain-rmse:31.6528\n",
      "[296]\teval-rmse:36.8613\ttrain-rmse:31.5155\n",
      "[297]\teval-rmse:36.7199\ttrain-rmse:31.3803\n",
      "[298]\teval-rmse:36.5794\ttrain-rmse:31.2423\n",
      "[299]\teval-rmse:36.4346\ttrain-rmse:31.0989\n",
      "[300]\teval-rmse:36.3004\ttrain-rmse:30.9647\n",
      "[301]\teval-rmse:36.1571\ttrain-rmse:30.8237\n",
      "[302]\teval-rmse:36.0285\ttrain-rmse:30.704\n",
      "[303]\teval-rmse:35.894\ttrain-rmse:30.575\n",
      "[304]\teval-rmse:35.7635\ttrain-rmse:30.4444\n",
      "[305]\teval-rmse:35.634\ttrain-rmse:30.318\n",
      "[306]\teval-rmse:35.499\ttrain-rmse:30.1848\n",
      "[307]\teval-rmse:35.3617\ttrain-rmse:30.0502\n",
      "[308]\teval-rmse:35.2272\ttrain-rmse:29.9162\n",
      "[309]\teval-rmse:35.0897\ttrain-rmse:29.7807\n",
      "[310]\teval-rmse:34.9516\ttrain-rmse:29.6451\n",
      "[311]\teval-rmse:34.8216\ttrain-rmse:29.5208\n",
      "[312]\teval-rmse:34.692\ttrain-rmse:29.3969\n",
      "[313]\teval-rmse:34.5698\ttrain-rmse:29.2759\n",
      "[314]\teval-rmse:34.4401\ttrain-rmse:29.1472\n",
      "[315]\teval-rmse:34.314\ttrain-rmse:29.0218\n",
      "[316]\teval-rmse:34.19\ttrain-rmse:28.9024\n",
      "[317]\teval-rmse:34.0686\ttrain-rmse:28.7854\n",
      "[318]\teval-rmse:33.9352\ttrain-rmse:28.6556\n",
      "[319]\teval-rmse:33.812\ttrain-rmse:28.5336\n",
      "[320]\teval-rmse:33.6834\ttrain-rmse:28.4115\n",
      "[321]\teval-rmse:33.5524\ttrain-rmse:28.2816\n",
      "[322]\teval-rmse:33.4183\ttrain-rmse:28.158\n",
      "[323]\teval-rmse:33.2816\ttrain-rmse:28.039\n",
      "[324]\teval-rmse:33.1586\ttrain-rmse:27.9215\n",
      "[325]\teval-rmse:33.0349\ttrain-rmse:27.7999\n",
      "[326]\teval-rmse:32.9087\ttrain-rmse:27.6747\n",
      "[327]\teval-rmse:32.795\ttrain-rmse:27.5632\n",
      "[328]\teval-rmse:32.6747\ttrain-rmse:27.445\n",
      "[329]\teval-rmse:32.5414\ttrain-rmse:27.3282\n",
      "[330]\teval-rmse:32.4078\ttrain-rmse:27.2048\n",
      "[331]\teval-rmse:32.2992\ttrain-rmse:27.1037\n",
      "[332]\teval-rmse:32.1633\ttrain-rmse:26.9875\n",
      "[333]\teval-rmse:32.0436\ttrain-rmse:26.8735\n",
      "[334]\teval-rmse:31.924\ttrain-rmse:26.756\n",
      "[335]\teval-rmse:31.8064\ttrain-rmse:26.6393\n",
      "[336]\teval-rmse:31.69\ttrain-rmse:26.5244\n",
      "[337]\teval-rmse:31.59\ttrain-rmse:26.4297\n",
      "[338]\teval-rmse:31.4737\ttrain-rmse:26.3161\n",
      "[339]\teval-rmse:31.3649\ttrain-rmse:26.2122\n",
      "[340]\teval-rmse:31.2556\ttrain-rmse:26.1043\n",
      "[341]\teval-rmse:31.1374\ttrain-rmse:25.9931\n",
      "[342]\teval-rmse:31.027\ttrain-rmse:25.8875\n",
      "[343]\teval-rmse:30.9036\ttrain-rmse:25.7736\n",
      "[344]\teval-rmse:30.7958\ttrain-rmse:25.6739\n",
      "[345]\teval-rmse:30.6871\ttrain-rmse:25.5654\n",
      "[346]\teval-rmse:30.5775\ttrain-rmse:25.4608\n",
      "[347]\teval-rmse:30.4691\ttrain-rmse:25.3523\n",
      "[348]\teval-rmse:30.3587\ttrain-rmse:25.2443\n",
      "[349]\teval-rmse:30.2534\ttrain-rmse:25.1394\n",
      "[350]\teval-rmse:30.1432\ttrain-rmse:25.0322\n",
      "[351]\teval-rmse:30.0434\ttrain-rmse:24.9383\n",
      "[352]\teval-rmse:29.9412\ttrain-rmse:24.838\n",
      "[353]\teval-rmse:29.8236\ttrain-rmse:24.7293\n",
      "[354]\teval-rmse:29.7233\ttrain-rmse:24.6326\n",
      "[355]\teval-rmse:29.6066\ttrain-rmse:24.5249\n",
      "[356]\teval-rmse:29.5048\ttrain-rmse:24.4292\n",
      "[357]\teval-rmse:29.4034\ttrain-rmse:24.3322\n",
      "[358]\teval-rmse:29.2822\ttrain-rmse:24.2225\n",
      "[359]\teval-rmse:29.1653\ttrain-rmse:24.1165\n",
      "[360]\teval-rmse:29.0579\ttrain-rmse:24.0146\n",
      "[361]\teval-rmse:28.9522\ttrain-rmse:23.915\n",
      "[362]\teval-rmse:28.8433\ttrain-rmse:23.8119\n",
      "[363]\teval-rmse:28.7501\ttrain-rmse:23.7213\n",
      "[364]\teval-rmse:28.6324\ttrain-rmse:23.6149\n",
      "[365]\teval-rmse:28.5373\ttrain-rmse:23.5215\n",
      "[366]\teval-rmse:28.4352\ttrain-rmse:23.4248\n",
      "[367]\teval-rmse:28.3356\ttrain-rmse:23.3301\n",
      "[368]\teval-rmse:28.2346\ttrain-rmse:23.2314\n",
      "[369]\teval-rmse:28.1243\ttrain-rmse:23.1307\n",
      "[370]\teval-rmse:28.0362\ttrain-rmse:23.0478\n",
      "[371]\teval-rmse:27.9412\ttrain-rmse:22.9552\n",
      "[372]\teval-rmse:27.8328\ttrain-rmse:22.8549\n",
      "[373]\teval-rmse:27.7391\ttrain-rmse:22.761\n",
      "[374]\teval-rmse:27.6299\ttrain-rmse:22.6608\n",
      "[375]\teval-rmse:27.5369\ttrain-rmse:22.574\n",
      "[376]\teval-rmse:27.4462\ttrain-rmse:22.4838\n",
      "[377]\teval-rmse:27.3405\ttrain-rmse:22.3864\n",
      "[378]\teval-rmse:27.2354\ttrain-rmse:22.2856\n",
      "[379]\teval-rmse:27.1343\ttrain-rmse:22.1913\n",
      "[380]\teval-rmse:27.0314\ttrain-rmse:22.0953\n",
      "[381]\teval-rmse:26.9287\ttrain-rmse:22.0013\n",
      "[382]\teval-rmse:26.8428\ttrain-rmse:21.918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[383]\teval-rmse:26.7556\ttrain-rmse:21.8312\n",
      "[384]\teval-rmse:26.6678\ttrain-rmse:21.7469\n",
      "[385]\teval-rmse:26.5764\ttrain-rmse:21.6593\n",
      "[386]\teval-rmse:26.4753\ttrain-rmse:21.5618\n",
      "[387]\teval-rmse:26.3867\ttrain-rmse:21.4798\n",
      "[388]\teval-rmse:26.2967\ttrain-rmse:21.3912\n",
      "[389]\teval-rmse:26.2115\ttrain-rmse:21.3079\n",
      "[390]\teval-rmse:26.1259\ttrain-rmse:21.2234\n",
      "[391]\teval-rmse:26.0383\ttrain-rmse:21.139\n",
      "[392]\teval-rmse:25.9304\ttrain-rmse:21.0469\n",
      "[393]\teval-rmse:25.8435\ttrain-rmse:20.9613\n",
      "[394]\teval-rmse:25.7605\ttrain-rmse:20.8831\n",
      "[395]\teval-rmse:25.6756\ttrain-rmse:20.7995\n",
      "[396]\teval-rmse:25.5716\ttrain-rmse:20.7098\n",
      "[397]\teval-rmse:25.4632\ttrain-rmse:20.6184\n",
      "[398]\teval-rmse:25.3717\ttrain-rmse:20.5328\n",
      "[399]\teval-rmse:25.28\ttrain-rmse:20.4447\n",
      "[400]\teval-rmse:25.1961\ttrain-rmse:20.3611\n",
      "[401]\teval-rmse:25.0906\ttrain-rmse:20.2717\n",
      "[402]\teval-rmse:24.9972\ttrain-rmse:20.1851\n",
      "[403]\teval-rmse:24.9153\ttrain-rmse:20.1068\n",
      "[404]\teval-rmse:24.8374\ttrain-rmse:20.0311\n",
      "[405]\teval-rmse:24.7563\ttrain-rmse:19.9538\n",
      "[406]\teval-rmse:24.6761\ttrain-rmse:19.8789\n",
      "[407]\teval-rmse:24.5808\ttrain-rmse:19.7924\n",
      "[408]\teval-rmse:24.4972\ttrain-rmse:19.711\n",
      "[409]\teval-rmse:24.4143\ttrain-rmse:19.6305\n",
      "[410]\teval-rmse:24.3262\ttrain-rmse:19.5467\n",
      "[411]\teval-rmse:24.2453\ttrain-rmse:19.4664\n",
      "[412]\teval-rmse:24.1798\ttrain-rmse:19.403\n",
      "[413]\teval-rmse:24.101\ttrain-rmse:19.3273\n",
      "[414]\teval-rmse:24.0052\ttrain-rmse:19.2436\n",
      "[415]\teval-rmse:23.9386\ttrain-rmse:19.179\n",
      "[416]\teval-rmse:23.8537\ttrain-rmse:19.1001\n",
      "[417]\teval-rmse:23.7568\ttrain-rmse:19.0186\n",
      "[418]\teval-rmse:23.6664\ttrain-rmse:18.9355\n",
      "[419]\teval-rmse:23.5928\ttrain-rmse:18.8624\n",
      "[420]\teval-rmse:23.511\ttrain-rmse:18.7824\n",
      "[421]\teval-rmse:23.433\ttrain-rmse:18.706\n",
      "[422]\teval-rmse:23.3374\ttrain-rmse:18.6255\n",
      "[423]\teval-rmse:23.2544\ttrain-rmse:18.5474\n",
      "[424]\teval-rmse:23.1805\ttrain-rmse:18.4781\n",
      "[425]\teval-rmse:23.0857\ttrain-rmse:18.3979\n",
      "[426]\teval-rmse:23.0119\ttrain-rmse:18.3242\n",
      "[427]\teval-rmse:22.9349\ttrain-rmse:18.2488\n",
      "[428]\teval-rmse:22.8487\ttrain-rmse:18.1708\n",
      "[429]\teval-rmse:22.767\ttrain-rmse:18.0912\n",
      "[430]\teval-rmse:22.6757\ttrain-rmse:18.0148\n",
      "[431]\teval-rmse:22.5957\ttrain-rmse:17.9402\n",
      "[432]\teval-rmse:22.509\ttrain-rmse:17.8579\n",
      "[433]\teval-rmse:22.4304\ttrain-rmse:17.7848\n",
      "[434]\teval-rmse:22.3507\ttrain-rmse:17.7072\n",
      "[435]\teval-rmse:22.2758\ttrain-rmse:17.6334\n",
      "[436]\teval-rmse:22.1941\ttrain-rmse:17.5617\n",
      "[437]\teval-rmse:22.1273\ttrain-rmse:17.4965\n",
      "[438]\teval-rmse:22.0545\ttrain-rmse:17.4274\n",
      "[439]\teval-rmse:21.9888\ttrain-rmse:17.3656\n",
      "[440]\teval-rmse:21.9119\ttrain-rmse:17.2934\n",
      "[441]\teval-rmse:21.8325\ttrain-rmse:17.2169\n",
      "[442]\teval-rmse:21.7637\ttrain-rmse:17.15\n",
      "[443]\teval-rmse:21.7004\ttrain-rmse:17.09\n",
      "[444]\teval-rmse:21.6209\ttrain-rmse:17.0175\n",
      "[445]\teval-rmse:21.5481\ttrain-rmse:16.9476\n",
      "[446]\teval-rmse:21.4821\ttrain-rmse:16.8834\n",
      "[447]\teval-rmse:21.4177\ttrain-rmse:16.8211\n",
      "[448]\teval-rmse:21.3539\ttrain-rmse:16.7581\n",
      "[449]\teval-rmse:21.2757\ttrain-rmse:16.6862\n",
      "[450]\teval-rmse:21.1969\ttrain-rmse:16.6145\n",
      "[451]\teval-rmse:21.1204\ttrain-rmse:16.5477\n",
      "[452]\teval-rmse:21.0414\ttrain-rmse:16.4713\n",
      "[453]\teval-rmse:20.9788\ttrain-rmse:16.4092\n",
      "[454]\teval-rmse:20.902\ttrain-rmse:16.3399\n",
      "[455]\teval-rmse:20.8367\ttrain-rmse:16.2774\n",
      "[456]\teval-rmse:20.7595\ttrain-rmse:16.208\n",
      "[457]\teval-rmse:20.6781\ttrain-rmse:16.1383\n",
      "[458]\teval-rmse:20.6014\ttrain-rmse:16.0703\n",
      "[459]\teval-rmse:20.536\ttrain-rmse:16.0075\n",
      "[460]\teval-rmse:20.4733\ttrain-rmse:15.9462\n",
      "[461]\teval-rmse:20.4089\ttrain-rmse:15.8836\n",
      "[462]\teval-rmse:20.3544\ttrain-rmse:15.8311\n",
      "[463]\teval-rmse:20.2963\ttrain-rmse:15.7759\n",
      "[464]\teval-rmse:20.2256\ttrain-rmse:15.7119\n",
      "[465]\teval-rmse:20.1644\ttrain-rmse:15.6529\n",
      "[466]\teval-rmse:20.0922\ttrain-rmse:15.5891\n",
      "[467]\teval-rmse:20.0154\ttrain-rmse:15.5224\n",
      "[468]\teval-rmse:19.9554\ttrain-rmse:15.4621\n",
      "[469]\teval-rmse:19.8804\ttrain-rmse:15.3894\n",
      "[470]\teval-rmse:19.8177\ttrain-rmse:15.3301\n",
      "[471]\teval-rmse:19.7534\ttrain-rmse:15.2701\n",
      "[472]\teval-rmse:19.6865\ttrain-rmse:15.2028\n",
      "[473]\teval-rmse:19.6085\ttrain-rmse:15.1375\n",
      "[474]\teval-rmse:19.5324\ttrain-rmse:15.0739\n",
      "[475]\teval-rmse:19.4657\ttrain-rmse:15.0132\n",
      "[476]\teval-rmse:19.4075\ttrain-rmse:14.9567\n",
      "[477]\teval-rmse:19.3485\ttrain-rmse:14.9007\n",
      "[478]\teval-rmse:19.2858\ttrain-rmse:14.8387\n",
      "[479]\teval-rmse:19.2298\ttrain-rmse:14.7828\n",
      "[480]\teval-rmse:19.1757\ttrain-rmse:14.7314\n",
      "[481]\teval-rmse:19.107\ttrain-rmse:14.6689\n",
      "[482]\teval-rmse:19.0451\ttrain-rmse:14.6119\n",
      "[483]\teval-rmse:18.9799\ttrain-rmse:14.5522\n",
      "[484]\teval-rmse:18.9163\ttrain-rmse:14.4948\n",
      "[485]\teval-rmse:18.8575\ttrain-rmse:14.4396\n",
      "[486]\teval-rmse:18.7971\ttrain-rmse:14.3825\n",
      "[487]\teval-rmse:18.7377\ttrain-rmse:14.3243\n",
      "[488]\teval-rmse:18.6846\ttrain-rmse:14.2728\n",
      "[489]\teval-rmse:18.6274\ttrain-rmse:14.219\n",
      "[490]\teval-rmse:18.5603\ttrain-rmse:14.1602\n",
      "[491]\teval-rmse:18.4979\ttrain-rmse:14.103\n",
      "[492]\teval-rmse:18.4274\ttrain-rmse:14.0435\n",
      "[493]\teval-rmse:18.3658\ttrain-rmse:13.9885\n",
      "[494]\teval-rmse:18.3117\ttrain-rmse:13.9368\n",
      "[495]\teval-rmse:18.2518\ttrain-rmse:13.8808\n",
      "[496]\teval-rmse:18.2025\ttrain-rmse:13.8337\n",
      "[497]\teval-rmse:18.1348\ttrain-rmse:13.7758\n",
      "[498]\teval-rmse:18.0922\ttrain-rmse:13.7343\n",
      "[499]\teval-rmse:18.0244\ttrain-rmse:13.6774\n",
      "[500]\teval-rmse:17.9872\ttrain-rmse:13.6396\n",
      "[501]\teval-rmse:17.9363\ttrain-rmse:13.5893\n",
      "[502]\teval-rmse:17.883\ttrain-rmse:13.539\n",
      "[503]\teval-rmse:17.8308\ttrain-rmse:13.4885\n",
      "[504]\teval-rmse:17.7721\ttrain-rmse:13.4361\n",
      "[505]\teval-rmse:17.7062\ttrain-rmse:13.3805\n",
      "[506]\teval-rmse:17.6427\ttrain-rmse:13.3239\n",
      "[507]\teval-rmse:17.5928\ttrain-rmse:13.2756\n",
      "[508]\teval-rmse:17.5276\ttrain-rmse:13.2198\n",
      "[509]\teval-rmse:17.4922\ttrain-rmse:13.1837\n",
      "[510]\teval-rmse:17.4277\ttrain-rmse:13.128\n",
      "[511]\teval-rmse:17.3783\ttrain-rmse:13.079\n",
      "[512]\teval-rmse:17.3252\ttrain-rmse:13.0297\n",
      "[513]\teval-rmse:17.2667\ttrain-rmse:12.9743\n",
      "[514]\teval-rmse:17.2056\ttrain-rmse:12.9195\n",
      "[515]\teval-rmse:17.1606\ttrain-rmse:12.8767\n",
      "[516]\teval-rmse:17.1153\ttrain-rmse:12.8321\n",
      "[517]\teval-rmse:17.0627\ttrain-rmse:12.7826\n",
      "[518]\teval-rmse:17.0039\ttrain-rmse:12.7324\n",
      "[519]\teval-rmse:16.9608\ttrain-rmse:12.6907\n",
      "[520]\teval-rmse:16.9178\ttrain-rmse:12.6489\n",
      "[521]\teval-rmse:16.8558\ttrain-rmse:12.5964\n",
      "[522]\teval-rmse:16.7925\ttrain-rmse:12.543\n",
      "[523]\teval-rmse:16.734\ttrain-rmse:12.492\n",
      "[524]\teval-rmse:16.6965\ttrain-rmse:12.4552\n",
      "[525]\teval-rmse:16.6546\ttrain-rmse:12.4141\n",
      "[526]\teval-rmse:16.5918\ttrain-rmse:12.3619\n",
      "[527]\teval-rmse:16.5473\ttrain-rmse:12.3187\n",
      "[528]\teval-rmse:16.4848\ttrain-rmse:12.2669\n",
      "[529]\teval-rmse:16.4446\ttrain-rmse:12.2278\n",
      "[530]\teval-rmse:16.3998\ttrain-rmse:12.1828\n",
      "[531]\teval-rmse:16.3524\ttrain-rmse:12.1368\n",
      "[532]\teval-rmse:16.3139\ttrain-rmse:12.0994\n",
      "[533]\teval-rmse:16.262\ttrain-rmse:12.0535\n",
      "[534]\teval-rmse:16.2068\ttrain-rmse:12.0066\n",
      "[535]\teval-rmse:16.1523\ttrain-rmse:11.9589\n",
      "[536]\teval-rmse:16.0967\ttrain-rmse:11.9098\n",
      "[537]\teval-rmse:16.045\ttrain-rmse:11.8628\n",
      "[538]\teval-rmse:15.9969\ttrain-rmse:11.8163\n",
      "[539]\teval-rmse:15.9453\ttrain-rmse:11.7715\n",
      "[540]\teval-rmse:15.9076\ttrain-rmse:11.7346\n",
      "[541]\teval-rmse:15.8604\ttrain-rmse:11.6887\n",
      "[542]\teval-rmse:15.8174\ttrain-rmse:11.647\n",
      "[543]\teval-rmse:15.7591\ttrain-rmse:11.598\n",
      "[544]\teval-rmse:15.7078\ttrain-rmse:11.5485\n",
      "[545]\teval-rmse:15.6496\ttrain-rmse:11.5003\n",
      "[546]\teval-rmse:15.6058\ttrain-rmse:11.4578\n",
      "[547]\teval-rmse:15.5586\ttrain-rmse:11.4128\n",
      "[548]\teval-rmse:15.5024\ttrain-rmse:11.3665\n",
      "[549]\teval-rmse:15.4615\ttrain-rmse:11.3263\n",
      "[550]\teval-rmse:15.4174\ttrain-rmse:11.2849\n",
      "[551]\teval-rmse:15.3655\ttrain-rmse:11.238\n",
      "[552]\teval-rmse:15.3215\ttrain-rmse:11.1972\n",
      "[553]\teval-rmse:15.2818\ttrain-rmse:11.1577\n",
      "[554]\teval-rmse:15.2415\ttrain-rmse:11.1175\n",
      "[555]\teval-rmse:15.1964\ttrain-rmse:11.073\n",
      "[556]\teval-rmse:15.1453\ttrain-rmse:11.0288\n",
      "[557]\teval-rmse:15.1081\ttrain-rmse:10.9925\n",
      "[558]\teval-rmse:15.0675\ttrain-rmse:10.953\n",
      "[559]\teval-rmse:15.0296\ttrain-rmse:10.9153\n",
      "[560]\teval-rmse:14.996\ttrain-rmse:10.8818\n",
      "[561]\teval-rmse:14.9588\ttrain-rmse:10.8447\n",
      "[562]\teval-rmse:14.9096\ttrain-rmse:10.8006\n",
      "[563]\teval-rmse:14.8675\ttrain-rmse:10.7609\n",
      "[564]\teval-rmse:14.8347\ttrain-rmse:10.729\n",
      "[565]\teval-rmse:14.7934\ttrain-rmse:10.6907\n",
      "[566]\teval-rmse:14.7513\ttrain-rmse:10.6498\n",
      "[567]\teval-rmse:14.7134\ttrain-rmse:10.6135\n",
      "[568]\teval-rmse:14.666\ttrain-rmse:10.5713\n",
      "[569]\teval-rmse:14.6287\ttrain-rmse:10.5361\n",
      "[570]\teval-rmse:14.5953\ttrain-rmse:10.503\n",
      "[571]\teval-rmse:14.5475\ttrain-rmse:10.4572\n",
      "[572]\teval-rmse:14.5092\ttrain-rmse:10.4201\n",
      "[573]\teval-rmse:14.4729\ttrain-rmse:10.3838\n",
      "[574]\teval-rmse:14.4373\ttrain-rmse:10.3498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[575]\teval-rmse:14.3909\ttrain-rmse:10.3078\n",
      "[576]\teval-rmse:14.3479\ttrain-rmse:10.2678\n",
      "[577]\teval-rmse:14.2994\ttrain-rmse:10.2241\n",
      "[578]\teval-rmse:14.249\ttrain-rmse:10.1824\n",
      "[579]\teval-rmse:14.218\ttrain-rmse:10.1515\n",
      "[580]\teval-rmse:14.1795\ttrain-rmse:10.1149\n",
      "[581]\teval-rmse:14.1503\ttrain-rmse:10.086\n",
      "[582]\teval-rmse:14.112\ttrain-rmse:10.05\n",
      "[583]\teval-rmse:14.082\ttrain-rmse:10.0208\n",
      "[584]\teval-rmse:14.0519\ttrain-rmse:9.99089\n",
      "[585]\teval-rmse:14.0225\ttrain-rmse:9.96228\n",
      "[586]\teval-rmse:13.9878\ttrain-rmse:9.92937\n",
      "[587]\teval-rmse:13.9577\ttrain-rmse:9.90009\n",
      "[588]\teval-rmse:13.9295\ttrain-rmse:9.87223\n",
      "[589]\teval-rmse:13.9021\ttrain-rmse:9.84513\n",
      "[590]\teval-rmse:13.8704\ttrain-rmse:9.81367\n",
      "[591]\teval-rmse:13.8385\ttrain-rmse:9.78192\n",
      "[592]\teval-rmse:13.7895\ttrain-rmse:9.74116\n",
      "[593]\teval-rmse:13.754\ttrain-rmse:9.70903\n",
      "[594]\teval-rmse:13.7154\ttrain-rmse:9.67117\n",
      "[595]\teval-rmse:13.6688\ttrain-rmse:9.63241\n",
      "[596]\teval-rmse:13.6298\ttrain-rmse:9.59744\n",
      "[597]\teval-rmse:13.6006\ttrain-rmse:9.56824\n",
      "[598]\teval-rmse:13.5642\ttrain-rmse:9.53583\n",
      "[599]\teval-rmse:13.5235\ttrain-rmse:9.5012\n",
      "[600]\teval-rmse:13.4877\ttrain-rmse:9.46836\n",
      "[601]\teval-rmse:13.4474\ttrain-rmse:9.43426\n",
      "[602]\teval-rmse:13.4061\ttrain-rmse:9.39849\n",
      "[603]\teval-rmse:13.3687\ttrain-rmse:9.36318\n",
      "[604]\teval-rmse:13.3313\ttrain-rmse:9.33036\n",
      "[605]\teval-rmse:13.3001\ttrain-rmse:9.30064\n",
      "[606]\teval-rmse:13.2624\ttrain-rmse:9.26464\n",
      "[607]\teval-rmse:13.2151\ttrain-rmse:9.22612\n",
      "[608]\teval-rmse:13.1805\ttrain-rmse:9.19241\n",
      "[609]\teval-rmse:13.1434\ttrain-rmse:9.15647\n",
      "[610]\teval-rmse:13.1064\ttrain-rmse:9.12353\n",
      "[611]\teval-rmse:13.0696\ttrain-rmse:9.09003\n",
      "[612]\teval-rmse:13.0241\ttrain-rmse:9.05291\n",
      "[613]\teval-rmse:12.9908\ttrain-rmse:9.02041\n",
      "[614]\teval-rmse:12.9718\ttrain-rmse:9.00039\n",
      "[615]\teval-rmse:12.9333\ttrain-rmse:8.96419\n",
      "[616]\teval-rmse:12.8941\ttrain-rmse:8.92894\n",
      "[617]\teval-rmse:12.8702\ttrain-rmse:8.90528\n",
      "[618]\teval-rmse:12.8412\ttrain-rmse:8.87796\n",
      "[619]\teval-rmse:12.8083\ttrain-rmse:8.84782\n",
      "[620]\teval-rmse:12.7881\ttrain-rmse:8.82732\n",
      "[621]\teval-rmse:12.7643\ttrain-rmse:8.80385\n",
      "[622]\teval-rmse:12.7438\ttrain-rmse:8.78303\n",
      "[623]\teval-rmse:12.7194\ttrain-rmse:8.75894\n",
      "[624]\teval-rmse:12.6778\ttrain-rmse:8.72463\n",
      "[625]\teval-rmse:12.6493\ttrain-rmse:8.69799\n",
      "[626]\teval-rmse:12.6107\ttrain-rmse:8.66502\n",
      "[627]\teval-rmse:12.5677\ttrain-rmse:8.62974\n",
      "[628]\teval-rmse:12.526\ttrain-rmse:8.59558\n",
      "[629]\teval-rmse:12.4896\ttrain-rmse:8.56205\n",
      "[630]\teval-rmse:12.4625\ttrain-rmse:8.53622\n",
      "[631]\teval-rmse:12.44\ttrain-rmse:8.51415\n",
      "[632]\teval-rmse:12.4113\ttrain-rmse:8.48604\n",
      "[633]\teval-rmse:12.3712\ttrain-rmse:8.4506\n",
      "[634]\teval-rmse:12.3423\ttrain-rmse:8.42326\n",
      "[635]\teval-rmse:12.3059\ttrain-rmse:8.39046\n",
      "[636]\teval-rmse:12.2712\ttrain-rmse:8.35981\n",
      "[637]\teval-rmse:12.2444\ttrain-rmse:8.33418\n",
      "[638]\teval-rmse:12.2159\ttrain-rmse:8.30683\n",
      "[639]\teval-rmse:12.1787\ttrain-rmse:8.27463\n",
      "[640]\teval-rmse:12.1379\ttrain-rmse:8.24145\n",
      "[641]\teval-rmse:12.108\ttrain-rmse:8.2138\n",
      "[642]\teval-rmse:12.0792\ttrain-rmse:8.18817\n",
      "[643]\teval-rmse:12.0472\ttrain-rmse:8.15741\n",
      "[644]\teval-rmse:12.0062\ttrain-rmse:8.12428\n",
      "[645]\teval-rmse:11.9703\ttrain-rmse:8.09244\n",
      "[646]\teval-rmse:11.9316\ttrain-rmse:8.06079\n",
      "[647]\teval-rmse:11.8956\ttrain-rmse:8.03024\n",
      "[648]\teval-rmse:11.8689\ttrain-rmse:8.00526\n",
      "[649]\teval-rmse:11.8361\ttrain-rmse:7.97425\n",
      "[650]\teval-rmse:11.7952\ttrain-rmse:7.94115\n",
      "[651]\teval-rmse:11.7747\ttrain-rmse:7.92037\n",
      "[652]\teval-rmse:11.7496\ttrain-rmse:7.89652\n",
      "[653]\teval-rmse:11.7123\ttrain-rmse:7.86603\n",
      "[654]\teval-rmse:11.6779\ttrain-rmse:7.83378\n",
      "[655]\teval-rmse:11.6414\ttrain-rmse:7.80412\n",
      "[656]\teval-rmse:11.6098\ttrain-rmse:7.77707\n",
      "[657]\teval-rmse:11.5831\ttrain-rmse:7.75282\n",
      "[658]\teval-rmse:11.5508\ttrain-rmse:7.72223\n",
      "[659]\teval-rmse:11.5138\ttrain-rmse:7.69195\n",
      "[660]\teval-rmse:11.4926\ttrain-rmse:7.67102\n",
      "[661]\teval-rmse:11.4617\ttrain-rmse:7.64355\n",
      "[662]\teval-rmse:11.4257\ttrain-rmse:7.61399\n",
      "[663]\teval-rmse:11.3978\ttrain-rmse:7.58716\n",
      "[664]\teval-rmse:11.3746\ttrain-rmse:7.5648\n",
      "[665]\teval-rmse:11.3557\ttrain-rmse:7.54586\n",
      "[666]\teval-rmse:11.3344\ttrain-rmse:7.52473\n",
      "[667]\teval-rmse:11.311\ttrain-rmse:7.50247\n",
      "[668]\teval-rmse:11.2806\ttrain-rmse:7.47646\n",
      "[669]\teval-rmse:11.2486\ttrain-rmse:7.44881\n",
      "[670]\teval-rmse:11.2165\ttrain-rmse:7.42129\n",
      "[671]\teval-rmse:11.1795\ttrain-rmse:7.39147\n",
      "[672]\teval-rmse:11.1472\ttrain-rmse:7.36421\n",
      "[673]\teval-rmse:11.1222\ttrain-rmse:7.34015\n",
      "[674]\teval-rmse:11.1034\ttrain-rmse:7.32164\n",
      "[675]\teval-rmse:11.0845\ttrain-rmse:7.30281\n",
      "[676]\teval-rmse:11.0598\ttrain-rmse:7.2806\n",
      "[677]\teval-rmse:11.0431\ttrain-rmse:7.26387\n",
      "[678]\teval-rmse:11.0196\ttrain-rmse:7.24153\n",
      "[679]\teval-rmse:10.9906\ttrain-rmse:7.21716\n",
      "[680]\teval-rmse:10.9565\ttrain-rmse:7.18949\n",
      "[681]\teval-rmse:10.9282\ttrain-rmse:7.16431\n",
      "[682]\teval-rmse:10.9135\ttrain-rmse:7.1494\n",
      "[683]\teval-rmse:10.8873\ttrain-rmse:7.126\n",
      "[684]\teval-rmse:10.8689\ttrain-rmse:7.10766\n",
      "[685]\teval-rmse:10.8473\ttrain-rmse:7.08735\n",
      "[686]\teval-rmse:10.8238\ttrain-rmse:7.0652\n",
      "[687]\teval-rmse:10.8062\ttrain-rmse:7.04784\n",
      "[688]\teval-rmse:10.7788\ttrain-rmse:7.02362\n",
      "[689]\teval-rmse:10.7447\ttrain-rmse:6.9962\n",
      "[690]\teval-rmse:10.7113\ttrain-rmse:6.96921\n",
      "[691]\teval-rmse:10.6915\ttrain-rmse:6.95021\n",
      "[692]\teval-rmse:10.6748\ttrain-rmse:6.93346\n",
      "[693]\teval-rmse:10.656\ttrain-rmse:6.91503\n",
      "[694]\teval-rmse:10.6263\ttrain-rmse:6.88793\n",
      "[695]\teval-rmse:10.5945\ttrain-rmse:6.86208\n",
      "[696]\teval-rmse:10.5635\ttrain-rmse:6.83605\n",
      "[697]\teval-rmse:10.5395\ttrain-rmse:6.8148\n",
      "[698]\teval-rmse:10.522\ttrain-rmse:6.79799\n",
      "[699]\teval-rmse:10.4897\ttrain-rmse:6.77204\n",
      "[700]\teval-rmse:10.4754\ttrain-rmse:6.75772\n",
      "[701]\teval-rmse:10.4538\ttrain-rmse:6.73846\n",
      "[702]\teval-rmse:10.4273\ttrain-rmse:6.71637\n",
      "[703]\teval-rmse:10.409\ttrain-rmse:6.69908\n",
      "[704]\teval-rmse:10.3852\ttrain-rmse:6.67749\n",
      "[705]\teval-rmse:10.3736\ttrain-rmse:6.66526\n",
      "[706]\teval-rmse:10.3556\ttrain-rmse:6.64815\n",
      "[707]\teval-rmse:10.3254\ttrain-rmse:6.62244\n",
      "[708]\teval-rmse:10.2948\ttrain-rmse:6.59782\n",
      "[709]\teval-rmse:10.2826\ttrain-rmse:6.58537\n",
      "[710]\teval-rmse:10.2524\ttrain-rmse:6.5609\n",
      "[711]\teval-rmse:10.2293\ttrain-rmse:6.53936\n",
      "[712]\teval-rmse:10.2122\ttrain-rmse:6.5226\n",
      "[713]\teval-rmse:10.1895\ttrain-rmse:6.5015\n",
      "[714]\teval-rmse:10.1592\ttrain-rmse:6.47719\n",
      "[715]\teval-rmse:10.15\ttrain-rmse:6.46723\n",
      "[716]\teval-rmse:10.126\ttrain-rmse:6.44515\n",
      "[717]\teval-rmse:10.0961\ttrain-rmse:6.42131\n",
      "[718]\teval-rmse:10.0643\ttrain-rmse:6.39613\n",
      "[719]\teval-rmse:10.0428\ttrain-rmse:6.37707\n",
      "[720]\teval-rmse:10.0269\ttrain-rmse:6.36166\n",
      "[721]\teval-rmse:10.0074\ttrain-rmse:6.34437\n",
      "[722]\teval-rmse:9.9881\ttrain-rmse:6.32731\n",
      "[723]\teval-rmse:9.97583\ttrain-rmse:6.31495\n",
      "[724]\teval-rmse:9.94445\ttrain-rmse:6.29003\n",
      "[725]\teval-rmse:9.92642\ttrain-rmse:6.27341\n",
      "[726]\teval-rmse:9.90818\ttrain-rmse:6.25674\n",
      "[727]\teval-rmse:9.88431\ttrain-rmse:6.23676\n",
      "[728]\teval-rmse:9.86583\ttrain-rmse:6.21968\n",
      "[729]\teval-rmse:9.84698\ttrain-rmse:6.20316\n",
      "[730]\teval-rmse:9.81854\ttrain-rmse:6.18032\n",
      "[731]\teval-rmse:9.80571\ttrain-rmse:6.16763\n",
      "[732]\teval-rmse:9.79738\ttrain-rmse:6.15862\n",
      "[733]\teval-rmse:9.77191\ttrain-rmse:6.13553\n",
      "[734]\teval-rmse:9.75834\ttrain-rmse:6.1222\n",
      "[735]\teval-rmse:9.74744\ttrain-rmse:6.11125\n",
      "[736]\teval-rmse:9.72757\ttrain-rmse:6.09392\n",
      "[737]\teval-rmse:9.70735\ttrain-rmse:6.07608\n",
      "[738]\teval-rmse:9.68003\ttrain-rmse:6.05433\n",
      "[739]\teval-rmse:9.65766\ttrain-rmse:6.03498\n",
      "[740]\teval-rmse:9.63271\ttrain-rmse:6.01385\n",
      "[741]\teval-rmse:9.60844\ttrain-rmse:5.99347\n",
      "[742]\teval-rmse:9.58654\ttrain-rmse:5.9753\n",
      "[743]\teval-rmse:9.57404\ttrain-rmse:5.96301\n",
      "[744]\teval-rmse:9.56096\ttrain-rmse:5.95016\n",
      "[745]\teval-rmse:9.53358\ttrain-rmse:5.92854\n",
      "[746]\teval-rmse:9.50685\ttrain-rmse:5.9073\n",
      "[747]\teval-rmse:9.48051\ttrain-rmse:5.88573\n",
      "[748]\teval-rmse:9.46423\ttrain-rmse:5.87119\n",
      "[749]\teval-rmse:9.43758\ttrain-rmse:5.85001\n",
      "[750]\teval-rmse:9.41611\ttrain-rmse:5.83097\n",
      "[751]\teval-rmse:9.39745\ttrain-rmse:5.8147\n",
      "[752]\teval-rmse:9.37066\ttrain-rmse:5.7935\n",
      "[753]\teval-rmse:9.34745\ttrain-rmse:5.77432\n",
      "[754]\teval-rmse:9.32392\ttrain-rmse:5.75497\n",
      "[755]\teval-rmse:9.30476\ttrain-rmse:5.73827\n",
      "[756]\teval-rmse:9.28704\ttrain-rmse:5.72309\n",
      "[757]\teval-rmse:9.27726\ttrain-rmse:5.71324\n",
      "[758]\teval-rmse:9.26493\ttrain-rmse:5.70131\n",
      "[759]\teval-rmse:9.24129\ttrain-rmse:5.68058\n",
      "[760]\teval-rmse:9.21828\ttrain-rmse:5.66173\n",
      "[761]\teval-rmse:9.19757\ttrain-rmse:5.64427\n",
      "[762]\teval-rmse:9.17748\ttrain-rmse:5.62725\n",
      "[763]\teval-rmse:9.15032\ttrain-rmse:5.60613\n",
      "[764]\teval-rmse:9.12335\ttrain-rmse:5.58514\n",
      "[765]\teval-rmse:9.10305\ttrain-rmse:5.5682\n",
      "[766]\teval-rmse:9.08127\ttrain-rmse:5.55062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[767]\teval-rmse:9.07393\ttrain-rmse:5.54276\n",
      "[768]\teval-rmse:9.06392\ttrain-rmse:5.53293\n",
      "[769]\teval-rmse:9.05121\ttrain-rmse:5.52113\n",
      "[770]\teval-rmse:9.04437\ttrain-rmse:5.5138\n",
      "[771]\teval-rmse:9.03594\ttrain-rmse:5.50528\n",
      "[772]\teval-rmse:9.01195\ttrain-rmse:5.48624\n",
      "[773]\teval-rmse:8.99209\ttrain-rmse:5.46889\n",
      "[774]\teval-rmse:8.98186\ttrain-rmse:5.4589\n",
      "[775]\teval-rmse:8.95931\ttrain-rmse:5.44043\n",
      "[776]\teval-rmse:8.94249\ttrain-rmse:5.42591\n",
      "[777]\teval-rmse:8.92588\ttrain-rmse:5.41172\n",
      "[778]\teval-rmse:8.91149\ttrain-rmse:5.39925\n",
      "[779]\teval-rmse:8.8929\ttrain-rmse:5.3841\n",
      "[780]\teval-rmse:8.88005\ttrain-rmse:5.37255\n",
      "[781]\teval-rmse:8.87054\ttrain-rmse:5.3632\n",
      "[782]\teval-rmse:8.85657\ttrain-rmse:5.35116\n",
      "[783]\teval-rmse:8.83496\ttrain-rmse:5.33261\n",
      "[784]\teval-rmse:8.81473\ttrain-rmse:5.31481\n",
      "[785]\teval-rmse:8.79916\ttrain-rmse:5.30168\n",
      "[786]\teval-rmse:8.78096\ttrain-rmse:5.28579\n",
      "[787]\teval-rmse:8.76862\ttrain-rmse:5.2747\n",
      "[788]\teval-rmse:8.75715\ttrain-rmse:5.2645\n",
      "[789]\teval-rmse:8.74552\ttrain-rmse:5.25348\n",
      "[790]\teval-rmse:8.73507\ttrain-rmse:5.24346\n",
      "[791]\teval-rmse:8.72481\ttrain-rmse:5.23366\n",
      "[792]\teval-rmse:8.71584\ttrain-rmse:5.22497\n",
      "[793]\teval-rmse:8.70303\ttrain-rmse:5.21391\n",
      "[794]\teval-rmse:8.6946\ttrain-rmse:5.20569\n",
      "[795]\teval-rmse:8.67135\ttrain-rmse:5.18761\n",
      "[796]\teval-rmse:8.65648\ttrain-rmse:5.17528\n",
      "[797]\teval-rmse:8.64045\ttrain-rmse:5.16137\n",
      "[798]\teval-rmse:8.61843\ttrain-rmse:5.14414\n",
      "[799]\teval-rmse:8.59838\ttrain-rmse:5.12824\n",
      "[800]\teval-rmse:8.57914\ttrain-rmse:5.11308\n",
      "[801]\teval-rmse:8.56487\ttrain-rmse:5.1012\n",
      "[802]\teval-rmse:8.54253\ttrain-rmse:5.08386\n",
      "[803]\teval-rmse:8.52078\ttrain-rmse:5.06703\n",
      "[804]\teval-rmse:8.5051\ttrain-rmse:5.05404\n",
      "[805]\teval-rmse:8.48998\ttrain-rmse:5.04095\n",
      "[806]\teval-rmse:8.47336\ttrain-rmse:5.02759\n",
      "[807]\teval-rmse:8.45291\ttrain-rmse:5.01088\n",
      "[808]\teval-rmse:8.43855\ttrain-rmse:4.99884\n",
      "[809]\teval-rmse:8.42249\ttrain-rmse:4.98493\n",
      "[810]\teval-rmse:8.41611\ttrain-rmse:4.97834\n",
      "[811]\teval-rmse:8.4023\ttrain-rmse:4.96687\n",
      "[812]\teval-rmse:8.38984\ttrain-rmse:4.95631\n",
      "[813]\teval-rmse:8.36653\ttrain-rmse:4.93866\n",
      "[814]\teval-rmse:8.35699\ttrain-rmse:4.93009\n",
      "[815]\teval-rmse:8.34833\ttrain-rmse:4.92202\n",
      "[816]\teval-rmse:8.34089\ttrain-rmse:4.91476\n",
      "[817]\teval-rmse:8.32001\ttrain-rmse:4.89893\n",
      "[818]\teval-rmse:8.30428\ttrain-rmse:4.8864\n",
      "[819]\teval-rmse:8.29553\ttrain-rmse:4.8782\n",
      "[820]\teval-rmse:8.2842\ttrain-rmse:4.8687\n",
      "[821]\teval-rmse:8.26752\ttrain-rmse:4.85445\n",
      "[822]\teval-rmse:8.25057\ttrain-rmse:4.84058\n",
      "[823]\teval-rmse:8.23617\ttrain-rmse:4.82888\n",
      "[824]\teval-rmse:8.22292\ttrain-rmse:4.81808\n",
      "[825]\teval-rmse:8.20499\ttrain-rmse:4.80427\n",
      "[826]\teval-rmse:8.19912\ttrain-rmse:4.79846\n",
      "[827]\teval-rmse:8.17644\ttrain-rmse:4.78234\n",
      "[828]\teval-rmse:8.15447\ttrain-rmse:4.76576\n",
      "[829]\teval-rmse:8.13726\ttrain-rmse:4.75247\n",
      "[830]\teval-rmse:8.12937\ttrain-rmse:4.74508\n",
      "[831]\teval-rmse:8.11356\ttrain-rmse:4.73207\n",
      "[832]\teval-rmse:8.09981\ttrain-rmse:4.72101\n",
      "[833]\teval-rmse:8.0924\ttrain-rmse:4.71417\n",
      "[834]\teval-rmse:8.08878\ttrain-rmse:4.71013\n",
      "[835]\teval-rmse:8.08236\ttrain-rmse:4.70391\n",
      "[836]\teval-rmse:8.06517\ttrain-rmse:4.69004\n",
      "[837]\teval-rmse:8.04359\ttrain-rmse:4.6738\n",
      "[838]\teval-rmse:8.02369\ttrain-rmse:4.65869\n",
      "[839]\teval-rmse:8.01576\ttrain-rmse:4.65168\n",
      "[840]\teval-rmse:8.00206\ttrain-rmse:4.64085\n",
      "[841]\teval-rmse:7.99655\ttrain-rmse:4.63541\n",
      "[842]\teval-rmse:7.97994\ttrain-rmse:4.6228\n",
      "[843]\teval-rmse:7.96676\ttrain-rmse:4.61194\n",
      "[844]\teval-rmse:7.95392\ttrain-rmse:4.60173\n",
      "[845]\teval-rmse:7.93251\ttrain-rmse:4.58668\n",
      "[846]\teval-rmse:7.91596\ttrain-rmse:4.57405\n",
      "[847]\teval-rmse:7.90846\ttrain-rmse:4.56745\n",
      "[848]\teval-rmse:7.90304\ttrain-rmse:4.56224\n",
      "[849]\teval-rmse:7.88689\ttrain-rmse:4.54995\n",
      "[850]\teval-rmse:7.87718\ttrain-rmse:4.5418\n",
      "[851]\teval-rmse:7.8583\ttrain-rmse:4.52752\n",
      "[852]\teval-rmse:7.83973\ttrain-rmse:4.51376\n",
      "[853]\teval-rmse:7.82285\ttrain-rmse:4.50058\n",
      "[854]\teval-rmse:7.81112\ttrain-rmse:4.49129\n",
      "[855]\teval-rmse:7.79032\ttrain-rmse:4.47671\n",
      "[856]\teval-rmse:7.7721\ttrain-rmse:4.46337\n",
      "[857]\teval-rmse:7.75805\ttrain-rmse:4.45265\n",
      "[858]\teval-rmse:7.74244\ttrain-rmse:4.44102\n",
      "[859]\teval-rmse:7.72591\ttrain-rmse:4.42872\n",
      "[860]\teval-rmse:7.71216\ttrain-rmse:4.41824\n",
      "[861]\teval-rmse:7.70691\ttrain-rmse:4.41322\n",
      "[862]\teval-rmse:7.69381\ttrain-rmse:4.40304\n",
      "[863]\teval-rmse:7.68888\ttrain-rmse:4.39828\n",
      "[864]\teval-rmse:7.68014\ttrain-rmse:4.39114\n",
      "[865]\teval-rmse:7.67145\ttrain-rmse:4.38404\n",
      "[866]\teval-rmse:7.66259\ttrain-rmse:4.37671\n",
      "[867]\teval-rmse:7.65397\ttrain-rmse:4.36959\n",
      "[868]\teval-rmse:7.64711\ttrain-rmse:4.36338\n",
      "[869]\teval-rmse:7.63664\ttrain-rmse:4.35516\n",
      "[870]\teval-rmse:7.62233\ttrain-rmse:4.34446\n",
      "[871]\teval-rmse:7.61607\ttrain-rmse:4.33886\n",
      "[872]\teval-rmse:7.61204\ttrain-rmse:4.33478\n",
      "[873]\teval-rmse:7.59719\ttrain-rmse:4.32389\n",
      "[874]\teval-rmse:7.58924\ttrain-rmse:4.31736\n",
      "[875]\teval-rmse:7.57845\ttrain-rmse:4.30916\n",
      "[876]\teval-rmse:7.57402\ttrain-rmse:4.30496\n",
      "[877]\teval-rmse:7.56484\ttrain-rmse:4.29753\n",
      "[878]\teval-rmse:7.5593\ttrain-rmse:4.29281\n",
      "[879]\teval-rmse:7.55106\ttrain-rmse:4.28591\n",
      "[880]\teval-rmse:7.53444\ttrain-rmse:4.27364\n",
      "[881]\teval-rmse:7.52428\ttrain-rmse:4.26594\n",
      "[882]\teval-rmse:7.52227\ttrain-rmse:4.26343\n",
      "[883]\teval-rmse:7.5191\ttrain-rmse:4.2602\n",
      "[884]\teval-rmse:7.50254\ttrain-rmse:4.24828\n",
      "[885]\teval-rmse:7.49252\ttrain-rmse:4.24032\n",
      "[886]\teval-rmse:7.4769\ttrain-rmse:4.22883\n",
      "[887]\teval-rmse:7.45998\ttrain-rmse:4.21627\n",
      "[888]\teval-rmse:7.44126\ttrain-rmse:4.2025\n",
      "[889]\teval-rmse:7.42433\ttrain-rmse:4.19006\n",
      "[890]\teval-rmse:7.41056\ttrain-rmse:4.17994\n",
      "[891]\teval-rmse:7.40401\ttrain-rmse:4.17445\n",
      "[892]\teval-rmse:7.39909\ttrain-rmse:4.16995\n",
      "[893]\teval-rmse:7.38032\ttrain-rmse:4.15701\n",
      "[894]\teval-rmse:7.37818\ttrain-rmse:4.15441\n",
      "[895]\teval-rmse:7.37218\ttrain-rmse:4.14924\n",
      "[896]\teval-rmse:7.36688\ttrain-rmse:4.14458\n",
      "[897]\teval-rmse:7.34862\ttrain-rmse:4.13138\n",
      "[898]\teval-rmse:7.33223\ttrain-rmse:4.11935\n",
      "[899]\teval-rmse:7.31758\ttrain-rmse:4.10865\n",
      "[900]\teval-rmse:7.30402\ttrain-rmse:4.09869\n",
      "[901]\teval-rmse:7.29017\ttrain-rmse:4.08882\n",
      "[902]\teval-rmse:7.27471\ttrain-rmse:4.07785\n",
      "[903]\teval-rmse:7.26357\ttrain-rmse:4.06932\n",
      "[904]\teval-rmse:7.24683\ttrain-rmse:4.05717\n",
      "[905]\teval-rmse:7.23148\ttrain-rmse:4.04602\n",
      "[906]\teval-rmse:7.21749\ttrain-rmse:4.03596\n",
      "[907]\teval-rmse:7.21288\ttrain-rmse:4.03189\n",
      "[908]\teval-rmse:7.19504\ttrain-rmse:4.01899\n",
      "[909]\teval-rmse:7.18376\ttrain-rmse:4.0108\n",
      "[910]\teval-rmse:7.17905\ttrain-rmse:4.00668\n",
      "[911]\teval-rmse:7.17053\ttrain-rmse:4.00023\n",
      "[912]\teval-rmse:7.16999\ttrain-rmse:3.99879\n",
      "[913]\teval-rmse:7.16696\ttrain-rmse:3.99584\n",
      "[914]\teval-rmse:7.16418\ttrain-rmse:3.99309\n",
      "[915]\teval-rmse:7.14898\ttrain-rmse:3.98197\n",
      "[916]\teval-rmse:7.14246\ttrain-rmse:3.97691\n",
      "[917]\teval-rmse:7.13556\ttrain-rmse:3.97139\n",
      "[918]\teval-rmse:7.1266\ttrain-rmse:3.96492\n",
      "[919]\teval-rmse:7.11843\ttrain-rmse:3.95888\n",
      "[920]\teval-rmse:7.10343\ttrain-rmse:3.94878\n",
      "[921]\teval-rmse:7.09689\ttrain-rmse:3.94379\n",
      "[922]\teval-rmse:7.08673\ttrain-rmse:3.93605\n",
      "[923]\teval-rmse:7.0765\ttrain-rmse:3.92873\n",
      "[924]\teval-rmse:7.07061\ttrain-rmse:3.92401\n",
      "[925]\teval-rmse:7.06468\ttrain-rmse:3.91932\n",
      "[926]\teval-rmse:7.0592\ttrain-rmse:3.91505\n",
      "[927]\teval-rmse:7.05328\ttrain-rmse:3.91053\n",
      "[928]\teval-rmse:7.04074\ttrain-rmse:3.90168\n",
      "[929]\teval-rmse:7.02393\ttrain-rmse:3.88973\n",
      "[930]\teval-rmse:7.01145\ttrain-rmse:3.88129\n",
      "[931]\teval-rmse:7.01081\ttrain-rmse:3.88026\n",
      "[932]\teval-rmse:6.99862\ttrain-rmse:3.87165\n",
      "[933]\teval-rmse:6.99431\ttrain-rmse:3.868\n",
      "[934]\teval-rmse:6.98377\ttrain-rmse:3.86088\n",
      "[935]\teval-rmse:6.96936\ttrain-rmse:3.85047\n",
      "[936]\teval-rmse:6.95324\ttrain-rmse:3.83894\n",
      "[937]\teval-rmse:6.95024\ttrain-rmse:3.83618\n",
      "[938]\teval-rmse:6.94586\ttrain-rmse:3.83246\n",
      "[939]\teval-rmse:6.94176\ttrain-rmse:3.82903\n",
      "[940]\teval-rmse:6.92735\ttrain-rmse:3.81886\n",
      "[941]\teval-rmse:6.91148\ttrain-rmse:3.80759\n",
      "[942]\teval-rmse:6.91028\ttrain-rmse:3.8059\n",
      "[943]\teval-rmse:6.90528\ttrain-rmse:3.80207\n",
      "[944]\teval-rmse:6.90568\ttrain-rmse:3.80142\n",
      "[945]\teval-rmse:6.89846\ttrain-rmse:3.79635\n",
      "[946]\teval-rmse:6.89383\ttrain-rmse:3.7926\n",
      "[947]\teval-rmse:6.88121\ttrain-rmse:3.78443\n",
      "[948]\teval-rmse:6.87734\ttrain-rmse:3.7812\n",
      "[949]\teval-rmse:6.86778\ttrain-rmse:3.77447\n",
      "[950]\teval-rmse:6.854\ttrain-rmse:3.76452\n",
      "[951]\teval-rmse:6.8452\ttrain-rmse:3.75782\n",
      "[952]\teval-rmse:6.8385\ttrain-rmse:3.75314\n",
      "[953]\teval-rmse:6.83093\ttrain-rmse:3.74783\n",
      "[954]\teval-rmse:6.82337\ttrain-rmse:3.74261\n",
      "[955]\teval-rmse:6.81647\ttrain-rmse:3.73777\n",
      "[956]\teval-rmse:6.8097\ttrain-rmse:3.73293\n",
      "[957]\teval-rmse:6.79641\ttrain-rmse:3.72339\n",
      "[958]\teval-rmse:6.78938\ttrain-rmse:3.71853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[959]\teval-rmse:6.77614\ttrain-rmse:3.70925\n",
      "[960]\teval-rmse:6.77403\ttrain-rmse:3.70723\n",
      "[961]\teval-rmse:6.77287\ttrain-rmse:3.70567\n",
      "[962]\teval-rmse:6.76139\ttrain-rmse:3.69819\n",
      "[963]\teval-rmse:6.74603\ttrain-rmse:3.6876\n",
      "[964]\teval-rmse:6.74128\ttrain-rmse:3.68396\n",
      "[965]\teval-rmse:6.73921\ttrain-rmse:3.68203\n",
      "[966]\teval-rmse:6.72737\ttrain-rmse:3.67461\n",
      "[967]\teval-rmse:6.72305\ttrain-rmse:3.67122\n",
      "[968]\teval-rmse:6.70996\ttrain-rmse:3.66189\n",
      "[969]\teval-rmse:6.70334\ttrain-rmse:3.65742\n",
      "[970]\teval-rmse:6.69928\ttrain-rmse:3.65443\n",
      "[971]\teval-rmse:6.68399\ttrain-rmse:3.64425\n",
      "[972]\teval-rmse:6.68075\ttrain-rmse:3.64154\n",
      "[973]\teval-rmse:6.66999\ttrain-rmse:3.63424\n",
      "[974]\teval-rmse:6.66179\ttrain-rmse:3.62896\n",
      "[975]\teval-rmse:6.64713\ttrain-rmse:3.61891\n",
      "[976]\teval-rmse:6.64577\ttrain-rmse:3.61735\n",
      "[977]\teval-rmse:6.63964\ttrain-rmse:3.6132\n",
      "[978]\teval-rmse:6.63051\ttrain-rmse:3.60731\n",
      "[979]\teval-rmse:6.62973\ttrain-rmse:3.60617\n",
      "[980]\teval-rmse:6.6257\ttrain-rmse:3.6031\n",
      "[981]\teval-rmse:6.61978\ttrain-rmse:3.59875\n",
      "[982]\teval-rmse:6.60525\ttrain-rmse:3.58879\n",
      "[983]\teval-rmse:6.60184\ttrain-rmse:3.5861\n",
      "[984]\teval-rmse:6.5972\ttrain-rmse:3.58277\n",
      "[985]\teval-rmse:6.59518\ttrain-rmse:3.58105\n",
      "[986]\teval-rmse:6.59623\ttrain-rmse:3.58089\n",
      "[987]\teval-rmse:6.59424\ttrain-rmse:3.5791\n",
      "[988]\teval-rmse:6.58786\ttrain-rmse:3.57492\n",
      "[989]\teval-rmse:6.57352\ttrain-rmse:3.56524\n",
      "[990]\teval-rmse:6.55905\ttrain-rmse:3.55571\n",
      "[991]\teval-rmse:6.54816\ttrain-rmse:3.54915\n",
      "[992]\teval-rmse:6.53794\ttrain-rmse:3.54284\n",
      "[993]\teval-rmse:6.52916\ttrain-rmse:3.53738\n",
      "[994]\teval-rmse:6.52609\ttrain-rmse:3.53489\n",
      "[995]\teval-rmse:6.51724\ttrain-rmse:3.52943\n",
      "[996]\teval-rmse:6.50896\ttrain-rmse:3.52424\n",
      "[997]\teval-rmse:6.49924\ttrain-rmse:3.51832\n",
      "[998]\teval-rmse:6.4929\ttrain-rmse:3.51436\n",
      "[999]\teval-rmse:6.48582\ttrain-rmse:3.50933\n",
      "[1000]\teval-rmse:6.47758\ttrain-rmse:3.50423\n",
      "[1001]\teval-rmse:6.47281\ttrain-rmse:3.50097\n",
      "[1002]\teval-rmse:6.46087\ttrain-rmse:3.49259\n",
      "[1003]\teval-rmse:6.45584\ttrain-rmse:3.48936\n",
      "[1004]\teval-rmse:6.45247\ttrain-rmse:3.48691\n",
      "[1005]\teval-rmse:6.45055\ttrain-rmse:3.48522\n",
      "[1006]\teval-rmse:6.4493\ttrain-rmse:3.48394\n",
      "[1007]\teval-rmse:6.43907\ttrain-rmse:3.47804\n",
      "[1008]\teval-rmse:6.43088\ttrain-rmse:3.47325\n",
      "[1009]\teval-rmse:6.42516\ttrain-rmse:3.46973\n",
      "[1010]\teval-rmse:6.41495\ttrain-rmse:3.46362\n",
      "[1011]\teval-rmse:6.40502\ttrain-rmse:3.45767\n",
      "[1012]\teval-rmse:6.39808\ttrain-rmse:3.45245\n",
      "[1013]\teval-rmse:6.39734\ttrain-rmse:3.4514\n",
      "[1014]\teval-rmse:6.38364\ttrain-rmse:3.44238\n",
      "[1015]\teval-rmse:6.37973\ttrain-rmse:3.43983\n",
      "[1016]\teval-rmse:6.37622\ttrain-rmse:3.43732\n",
      "[1017]\teval-rmse:6.3703\ttrain-rmse:3.43369\n",
      "[1018]\teval-rmse:6.37044\ttrain-rmse:3.43316\n",
      "[1019]\teval-rmse:6.35581\ttrain-rmse:3.42499\n",
      "[1020]\teval-rmse:6.34674\ttrain-rmse:3.41985\n",
      "[1021]\teval-rmse:6.34024\ttrain-rmse:3.41518\n",
      "[1022]\teval-rmse:6.33786\ttrain-rmse:3.41335\n",
      "[1023]\teval-rmse:6.33734\ttrain-rmse:3.41254\n",
      "[1024]\teval-rmse:6.33609\ttrain-rmse:3.41138\n",
      "[1025]\teval-rmse:6.32604\ttrain-rmse:3.40578\n",
      "[1026]\teval-rmse:6.32299\ttrain-rmse:3.40367\n",
      "[1027]\teval-rmse:6.31342\ttrain-rmse:3.39831\n",
      "[1028]\teval-rmse:6.30197\ttrain-rmse:3.39174\n",
      "[1029]\teval-rmse:6.29526\ttrain-rmse:3.38787\n",
      "[1030]\teval-rmse:6.29619\ttrain-rmse:3.38779\n",
      "[1031]\teval-rmse:6.28652\ttrain-rmse:3.38225\n",
      "[1032]\teval-rmse:6.27702\ttrain-rmse:3.37708\n",
      "[1033]\teval-rmse:6.27241\ttrain-rmse:3.37431\n",
      "[1034]\teval-rmse:6.25974\ttrain-rmse:3.36559\n",
      "[1035]\teval-rmse:6.25778\ttrain-rmse:3.36407\n",
      "[1036]\teval-rmse:6.25162\ttrain-rmse:3.36058\n",
      "[1037]\teval-rmse:6.25119\ttrain-rmse:3.35985\n",
      "[1038]\teval-rmse:6.24652\ttrain-rmse:3.35691\n",
      "[1039]\teval-rmse:6.23584\ttrain-rmse:3.35118\n",
      "[1040]\teval-rmse:6.22651\ttrain-rmse:3.34622\n",
      "[1041]\teval-rmse:6.22847\ttrain-rmse:3.34667\n",
      "[1042]\teval-rmse:6.22169\ttrain-rmse:3.3423\n",
      "[1043]\teval-rmse:6.21443\ttrain-rmse:3.3383\n",
      "[1044]\teval-rmse:6.20556\ttrain-rmse:3.33291\n",
      "[1045]\teval-rmse:6.19312\ttrain-rmse:3.32462\n",
      "[1046]\teval-rmse:6.18406\ttrain-rmse:3.3199\n",
      "[1047]\teval-rmse:6.18635\ttrain-rmse:3.32047\n",
      "[1048]\teval-rmse:6.17585\ttrain-rmse:3.31341\n",
      "[1049]\teval-rmse:6.16572\ttrain-rmse:3.30671\n",
      "[1050]\teval-rmse:6.16466\ttrain-rmse:3.30565\n",
      "[1051]\teval-rmse:6.1559\ttrain-rmse:3.3009\n",
      "[1052]\teval-rmse:6.15349\ttrain-rmse:3.29926\n",
      "[1053]\teval-rmse:6.15259\ttrain-rmse:3.29831\n",
      "[1054]\teval-rmse:6.15067\ttrain-rmse:3.2969\n",
      "[1055]\teval-rmse:6.13957\ttrain-rmse:3.29114\n",
      "[1056]\teval-rmse:6.12998\ttrain-rmse:3.28626\n",
      "[1057]\teval-rmse:6.11964\ttrain-rmse:3.28098\n",
      "[1058]\teval-rmse:6.11859\ttrain-rmse:3.28\n",
      "[1059]\teval-rmse:6.10943\ttrain-rmse:3.27538\n",
      "[1060]\teval-rmse:6.10305\ttrain-rmse:3.27205\n",
      "[1061]\teval-rmse:6.09502\ttrain-rmse:3.26719\n",
      "[1062]\teval-rmse:6.08669\ttrain-rmse:3.26215\n",
      "[1063]\teval-rmse:6.07682\ttrain-rmse:3.25519\n",
      "[1064]\teval-rmse:6.07405\ttrain-rmse:3.25333\n",
      "[1065]\teval-rmse:6.06629\ttrain-rmse:3.24929\n",
      "[1066]\teval-rmse:6.05834\ttrain-rmse:3.24529\n",
      "[1067]\teval-rmse:6.04635\ttrain-rmse:3.23737\n",
      "[1068]\teval-rmse:6.049\ttrain-rmse:3.23818\n",
      "[1069]\teval-rmse:6.04416\ttrain-rmse:3.23546\n",
      "[1070]\teval-rmse:6.04591\ttrain-rmse:3.2358\n",
      "[1071]\teval-rmse:6.04538\ttrain-rmse:3.23513\n",
      "[1072]\teval-rmse:6.03346\ttrain-rmse:3.22736\n",
      "[1073]\teval-rmse:6.02762\ttrain-rmse:3.22369\n",
      "[1074]\teval-rmse:6.02556\ttrain-rmse:3.22238\n",
      "[1075]\teval-rmse:6.02069\ttrain-rmse:3.21986\n",
      "[1076]\teval-rmse:6.01208\ttrain-rmse:3.21524\n",
      "[1077]\teval-rmse:6.01201\ttrain-rmse:3.21491\n",
      "[1078]\teval-rmse:6.00185\ttrain-rmse:3.20965\n",
      "[1079]\teval-rmse:5.99408\ttrain-rmse:3.20593\n",
      "[1080]\teval-rmse:5.98474\ttrain-rmse:3.19989\n",
      "[1081]\teval-rmse:5.9772\ttrain-rmse:3.19543\n",
      "[1082]\teval-rmse:5.97449\ttrain-rmse:3.19383\n",
      "[1083]\teval-rmse:5.96832\ttrain-rmse:3.19057\n",
      "[1084]\teval-rmse:5.96862\ttrain-rmse:3.19047\n",
      "[1085]\teval-rmse:5.96189\ttrain-rmse:3.18723\n",
      "[1086]\teval-rmse:5.9602\ttrain-rmse:3.18614\n",
      "[1087]\teval-rmse:5.95838\ttrain-rmse:3.18494\n",
      "[1088]\teval-rmse:5.94925\ttrain-rmse:3.17912\n",
      "[1089]\teval-rmse:5.94969\ttrain-rmse:3.17895\n",
      "[1090]\teval-rmse:5.94099\ttrain-rmse:3.1748\n",
      "[1091]\teval-rmse:5.93818\ttrain-rmse:3.17327\n",
      "[1092]\teval-rmse:5.92687\ttrain-rmse:3.16601\n",
      "[1093]\teval-rmse:5.92091\ttrain-rmse:3.16298\n",
      "[1094]\teval-rmse:5.90973\ttrain-rmse:3.15537\n",
      "[1095]\teval-rmse:5.90764\ttrain-rmse:3.1541\n",
      "[1096]\teval-rmse:5.89882\ttrain-rmse:3.14838\n",
      "[1097]\teval-rmse:5.88775\ttrain-rmse:3.14112\n",
      "[1098]\teval-rmse:5.87709\ttrain-rmse:3.13645\n",
      "[1099]\teval-rmse:5.87723\ttrain-rmse:3.13608\n",
      "[1100]\teval-rmse:5.87851\ttrain-rmse:3.13631\n",
      "[1101]\teval-rmse:5.877\ttrain-rmse:3.13528\n",
      "[1102]\teval-rmse:5.86973\ttrain-rmse:3.13132\n",
      "[1103]\teval-rmse:5.86948\ttrain-rmse:3.13084\n",
      "[1104]\teval-rmse:5.86002\ttrain-rmse:3.12625\n",
      "[1105]\teval-rmse:5.86063\ttrain-rmse:3.12613\n",
      "[1106]\teval-rmse:5.86065\ttrain-rmse:3.12587\n",
      "[1107]\teval-rmse:5.86205\ttrain-rmse:3.12605\n",
      "[1108]\teval-rmse:5.85543\ttrain-rmse:3.12309\n",
      "[1109]\teval-rmse:5.85026\ttrain-rmse:3.12003\n",
      "[1110]\teval-rmse:5.83957\ttrain-rmse:3.11332\n",
      "[1111]\teval-rmse:5.83723\ttrain-rmse:3.1117\n",
      "[1112]\teval-rmse:5.82975\ttrain-rmse:3.10844\n",
      "[1113]\teval-rmse:5.82618\ttrain-rmse:3.10674\n",
      "[1114]\teval-rmse:5.82413\ttrain-rmse:3.10557\n",
      "[1115]\teval-rmse:5.81827\ttrain-rmse:3.10301\n",
      "[1116]\teval-rmse:5.81659\ttrain-rmse:3.10206\n",
      "[1117]\teval-rmse:5.81747\ttrain-rmse:3.10213\n",
      "[1118]\teval-rmse:5.81625\ttrain-rmse:3.10134\n",
      "[1119]\teval-rmse:5.80932\ttrain-rmse:3.09834\n",
      "[1120]\teval-rmse:5.80205\ttrain-rmse:3.09485\n",
      "[1121]\teval-rmse:5.80373\ttrain-rmse:3.09526\n",
      "[1122]\teval-rmse:5.8029\ttrain-rmse:3.09464\n",
      "[1123]\teval-rmse:5.79821\ttrain-rmse:3.09252\n",
      "[1124]\teval-rmse:5.78812\ttrain-rmse:3.08606\n",
      "[1125]\teval-rmse:5.78817\ttrain-rmse:3.08576\n",
      "[1126]\teval-rmse:5.78109\ttrain-rmse:3.08272\n",
      "[1127]\teval-rmse:5.77378\ttrain-rmse:3.07978\n",
      "[1128]\teval-rmse:5.76528\ttrain-rmse:3.07464\n",
      "[1129]\teval-rmse:5.76174\ttrain-rmse:3.0728\n",
      "[1130]\teval-rmse:5.75406\ttrain-rmse:3.06958\n",
      "[1131]\teval-rmse:5.75237\ttrain-rmse:3.06861\n",
      "[1132]\teval-rmse:5.74561\ttrain-rmse:3.06501\n",
      "[1133]\teval-rmse:5.74089\ttrain-rmse:3.06224\n",
      "[1134]\teval-rmse:5.7389\ttrain-rmse:3.06118\n",
      "[1135]\teval-rmse:5.73625\ttrain-rmse:3.05972\n",
      "[1136]\teval-rmse:5.72619\ttrain-rmse:3.05348\n",
      "[1137]\teval-rmse:5.71661\ttrain-rmse:3.04714\n",
      "[1138]\teval-rmse:5.71301\ttrain-rmse:3.04548\n",
      "[1139]\teval-rmse:5.71412\ttrain-rmse:3.04558\n",
      "[1140]\teval-rmse:5.71203\ttrain-rmse:3.04415\n",
      "[1141]\teval-rmse:5.70385\ttrain-rmse:3.03983\n",
      "[1142]\teval-rmse:5.70443\ttrain-rmse:3.03972\n",
      "[1143]\teval-rmse:5.70648\ttrain-rmse:3.04018\n",
      "[1144]\teval-rmse:5.69834\ttrain-rmse:3.03574\n",
      "[1145]\teval-rmse:5.68866\ttrain-rmse:3.02922\n",
      "[1146]\teval-rmse:5.68683\ttrain-rmse:3.02834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1147]\teval-rmse:5.6798\ttrain-rmse:3.02526\n",
      "[1148]\teval-rmse:5.67318\ttrain-rmse:3.0226\n",
      "[1149]\teval-rmse:5.67542\ttrain-rmse:3.02321\n",
      "[1150]\teval-rmse:5.66919\ttrain-rmse:3.02071\n",
      "[1151]\teval-rmse:5.66979\ttrain-rmse:3.02066\n",
      "[1152]\teval-rmse:5.67202\ttrain-rmse:3.02123\n",
      "[1153]\teval-rmse:5.6658\ttrain-rmse:3.01873\n",
      "[1154]\teval-rmse:5.66734\ttrain-rmse:3.01909\n",
      "[1155]\teval-rmse:5.66028\ttrain-rmse:3.01631\n",
      "[1156]\teval-rmse:5.65948\ttrain-rmse:3.01574\n",
      "[1157]\teval-rmse:5.64979\ttrain-rmse:3.01218\n",
      "[1158]\teval-rmse:5.64821\ttrain-rmse:3.01139\n",
      "[1159]\teval-rmse:5.63849\ttrain-rmse:3.00472\n",
      "[1160]\teval-rmse:5.6381\ttrain-rmse:3.00436\n",
      "[1161]\teval-rmse:5.63911\ttrain-rmse:3.00445\n",
      "[1162]\teval-rmse:5.63992\ttrain-rmse:3.00448\n",
      "[1163]\teval-rmse:5.63644\ttrain-rmse:3.00169\n",
      "[1164]\teval-rmse:5.63785\ttrain-rmse:3.00192\n",
      "[1165]\teval-rmse:5.63115\ttrain-rmse:2.99935\n",
      "[1166]\teval-rmse:5.62142\ttrain-rmse:2.99296\n",
      "[1167]\teval-rmse:5.61812\ttrain-rmse:2.99099\n",
      "[1168]\teval-rmse:5.61753\ttrain-rmse:2.99053\n",
      "[1169]\teval-rmse:5.61021\ttrain-rmse:2.98564\n",
      "[1170]\teval-rmse:5.60922\ttrain-rmse:2.98507\n",
      "[1171]\teval-rmse:5.60662\ttrain-rmse:2.98394\n",
      "[1172]\teval-rmse:5.60898\ttrain-rmse:2.98461\n",
      "[1173]\teval-rmse:5.6109\ttrain-rmse:2.9851\n",
      "[1174]\teval-rmse:5.60331\ttrain-rmse:2.98079\n",
      "[1175]\teval-rmse:5.59701\ttrain-rmse:2.9784\n",
      "[1176]\teval-rmse:5.59692\ttrain-rmse:2.97816\n",
      "[1177]\teval-rmse:5.59097\ttrain-rmse:2.9752\n",
      "[1178]\teval-rmse:5.59018\ttrain-rmse:2.97476\n",
      "[1179]\teval-rmse:5.58218\ttrain-rmse:2.97168\n",
      "[1180]\teval-rmse:5.57471\ttrain-rmse:2.96713\n",
      "[1181]\teval-rmse:5.57543\ttrain-rmse:2.96715\n",
      "[1182]\teval-rmse:5.56622\ttrain-rmse:2.96174\n",
      "[1183]\teval-rmse:5.56656\ttrain-rmse:2.96161\n",
      "[1184]\teval-rmse:5.56053\ttrain-rmse:2.95904\n",
      "[1185]\teval-rmse:5.55733\ttrain-rmse:2.95785\n",
      "[1186]\teval-rmse:5.55443\ttrain-rmse:2.95665\n",
      "[1187]\teval-rmse:5.55504\ttrain-rmse:2.95665\n",
      "[1188]\teval-rmse:5.55576\ttrain-rmse:2.95676\n",
      "[1189]\teval-rmse:5.55577\ttrain-rmse:2.95655\n",
      "[1190]\teval-rmse:5.54669\ttrain-rmse:2.95146\n",
      "[1191]\teval-rmse:5.54727\ttrain-rmse:2.95144\n",
      "[1192]\teval-rmse:5.53926\ttrain-rmse:2.94857\n",
      "[1193]\teval-rmse:5.53528\ttrain-rmse:2.94705\n",
      "[1194]\teval-rmse:5.534\ttrain-rmse:2.94606\n",
      "[1195]\teval-rmse:5.52914\ttrain-rmse:2.94438\n",
      "[1196]\teval-rmse:5.52177\ttrain-rmse:2.9393\n",
      "[1197]\teval-rmse:5.52055\ttrain-rmse:2.93876\n",
      "[1198]\teval-rmse:5.51725\ttrain-rmse:2.93751\n",
      "[1199]\teval-rmse:5.51281\ttrain-rmse:2.9359\n",
      "[1200]\teval-rmse:5.51296\ttrain-rmse:2.93572\n",
      "[1201]\teval-rmse:5.50714\ttrain-rmse:2.93332\n",
      "[1202]\teval-rmse:5.50241\ttrain-rmse:2.93173\n",
      "[1203]\teval-rmse:5.50118\ttrain-rmse:2.93105\n",
      "[1204]\teval-rmse:5.5017\ttrain-rmse:2.9311\n",
      "[1205]\teval-rmse:5.49518\ttrain-rmse:2.92897\n",
      "[1206]\teval-rmse:5.48658\ttrain-rmse:2.92354\n",
      "[1207]\teval-rmse:5.47771\ttrain-rmse:2.91771\n",
      "[1208]\teval-rmse:5.4763\ttrain-rmse:2.91709\n",
      "[1209]\teval-rmse:5.46921\ttrain-rmse:2.91478\n",
      "[1210]\teval-rmse:5.47022\ttrain-rmse:2.91486\n",
      "[1211]\teval-rmse:5.46986\ttrain-rmse:2.91456\n",
      "[1212]\teval-rmse:5.47319\ttrain-rmse:2.91548\n",
      "[1213]\teval-rmse:5.47365\ttrain-rmse:2.91541\n",
      "[1214]\teval-rmse:5.46482\ttrain-rmse:2.90935\n",
      "[1215]\teval-rmse:5.46218\ttrain-rmse:2.90685\n",
      "[1216]\teval-rmse:5.46139\ttrain-rmse:2.90646\n",
      "[1217]\teval-rmse:5.46498\ttrain-rmse:2.9074\n",
      "[1218]\teval-rmse:5.462\ttrain-rmse:2.90611\n",
      "[1219]\teval-rmse:5.46303\ttrain-rmse:2.90624\n",
      "[1220]\teval-rmse:5.45599\ttrain-rmse:2.90175\n",
      "[1221]\teval-rmse:5.45239\ttrain-rmse:2.90054\n",
      "[1222]\teval-rmse:5.45125\ttrain-rmse:2.89959\n",
      "[1223]\teval-rmse:5.45205\ttrain-rmse:2.89973\n",
      "[1224]\teval-rmse:5.4511\ttrain-rmse:2.89927\n",
      "[1225]\teval-rmse:5.45009\ttrain-rmse:2.89873\n",
      "[1226]\teval-rmse:5.44654\ttrain-rmse:2.89687\n",
      "[1227]\teval-rmse:5.43995\ttrain-rmse:2.89468\n",
      "[1228]\teval-rmse:5.43716\ttrain-rmse:2.8937\n",
      "[1229]\teval-rmse:5.4374\ttrain-rmse:2.8936\n",
      "[1230]\teval-rmse:5.43704\ttrain-rmse:2.89334\n",
      "[1231]\teval-rmse:5.43542\ttrain-rmse:2.89268\n",
      "[1232]\teval-rmse:5.43058\ttrain-rmse:2.8911\n",
      "[1233]\teval-rmse:5.42588\ttrain-rmse:2.8895\n",
      "[1234]\teval-rmse:5.41828\ttrain-rmse:2.88693\n",
      "[1235]\teval-rmse:5.42028\ttrain-rmse:2.88742\n",
      "[1236]\teval-rmse:5.4217\ttrain-rmse:2.88775\n",
      "[1237]\teval-rmse:5.4237\ttrain-rmse:2.88822\n",
      "[1238]\teval-rmse:5.4151\ttrain-rmse:2.88285\n",
      "[1239]\teval-rmse:5.41594\ttrain-rmse:2.88294\n",
      "[1240]\teval-rmse:5.41453\ttrain-rmse:2.88244\n",
      "[1241]\teval-rmse:5.40824\ttrain-rmse:2.88042\n",
      "[1242]\teval-rmse:5.39979\ttrain-rmse:2.87576\n",
      "[1243]\teval-rmse:5.3966\ttrain-rmse:2.87478\n",
      "[1244]\teval-rmse:5.39386\ttrain-rmse:2.8739\n",
      "[1245]\teval-rmse:5.39498\ttrain-rmse:2.87407\n",
      "[1246]\teval-rmse:5.39155\ttrain-rmse:2.8728\n",
      "[1247]\teval-rmse:5.38345\ttrain-rmse:2.86773\n",
      "[1248]\teval-rmse:5.38456\ttrain-rmse:2.86789\n",
      "[1249]\teval-rmse:5.3781\ttrain-rmse:2.86377\n",
      "[1250]\teval-rmse:5.37479\ttrain-rmse:2.86276\n",
      "[1251]\teval-rmse:5.37838\ttrain-rmse:2.86358\n",
      "[1252]\teval-rmse:5.37995\ttrain-rmse:2.86387\n",
      "[1253]\teval-rmse:5.37169\ttrain-rmse:2.86127\n",
      "[1254]\teval-rmse:5.36679\ttrain-rmse:2.8595\n",
      "[1255]\teval-rmse:5.35848\ttrain-rmse:2.85397\n",
      "[1256]\teval-rmse:5.35231\ttrain-rmse:2.84971\n",
      "[1257]\teval-rmse:5.35221\ttrain-rmse:2.84954\n",
      "[1258]\teval-rmse:5.35112\ttrain-rmse:2.84904\n",
      "[1259]\teval-rmse:5.34771\ttrain-rmse:2.84797\n",
      "[1260]\teval-rmse:5.33973\ttrain-rmse:2.84322\n",
      "[1261]\teval-rmse:5.34033\ttrain-rmse:2.84324\n",
      "[1262]\teval-rmse:5.3391\ttrain-rmse:2.84276\n",
      "[1263]\teval-rmse:5.34135\ttrain-rmse:2.84326\n",
      "[1264]\teval-rmse:5.34203\ttrain-rmse:2.84331\n",
      "[1265]\teval-rmse:5.33553\ttrain-rmse:2.83918\n",
      "[1266]\teval-rmse:5.32879\ttrain-rmse:2.83732\n",
      "[1267]\teval-rmse:5.33121\ttrain-rmse:2.83782\n",
      "[1268]\teval-rmse:5.3236\ttrain-rmse:2.83302\n",
      "[1269]\teval-rmse:5.32567\ttrain-rmse:2.83351\n",
      "[1270]\teval-rmse:5.32075\ttrain-rmse:2.83213\n",
      "[1271]\teval-rmse:5.31896\ttrain-rmse:2.83066\n",
      "[1272]\teval-rmse:5.31692\ttrain-rmse:2.83001\n",
      "[1273]\teval-rmse:5.31178\ttrain-rmse:2.82862\n",
      "[1274]\teval-rmse:5.30637\ttrain-rmse:2.82677\n",
      "[1275]\teval-rmse:5.306\ttrain-rmse:2.82657\n",
      "[1276]\teval-rmse:5.30126\ttrain-rmse:2.82486\n",
      "[1277]\teval-rmse:5.29622\ttrain-rmse:2.82342\n",
      "[1278]\teval-rmse:5.29859\ttrain-rmse:2.82396\n",
      "[1279]\teval-rmse:5.29572\ttrain-rmse:2.82311\n",
      "[1280]\teval-rmse:5.29588\ttrain-rmse:2.82303\n",
      "[1281]\teval-rmse:5.29176\ttrain-rmse:2.82194\n",
      "[1282]\teval-rmse:5.29016\ttrain-rmse:2.8204\n",
      "[1283]\teval-rmse:5.28248\ttrain-rmse:2.81643\n",
      "[1284]\teval-rmse:5.2837\ttrain-rmse:2.81661\n",
      "[1285]\teval-rmse:5.2817\ttrain-rmse:2.81597\n",
      "[1286]\teval-rmse:5.2826\ttrain-rmse:2.81613\n",
      "[1287]\teval-rmse:5.28427\ttrain-rmse:2.81652\n",
      "[1288]\teval-rmse:5.27898\ttrain-rmse:2.81477\n",
      "[1289]\teval-rmse:5.27313\ttrain-rmse:2.81314\n",
      "[1290]\teval-rmse:5.2763\ttrain-rmse:2.81388\n",
      "[1291]\teval-rmse:5.27834\ttrain-rmse:2.81431\n",
      "[1292]\teval-rmse:5.27684\ttrain-rmse:2.81269\n",
      "[1293]\teval-rmse:5.27254\ttrain-rmse:2.81157\n",
      "[1294]\teval-rmse:5.27127\ttrain-rmse:2.81117\n",
      "[1295]\teval-rmse:5.27035\ttrain-rmse:2.81075\n",
      "[1296]\teval-rmse:5.26268\ttrain-rmse:2.80659\n",
      "[1297]\teval-rmse:5.26293\ttrain-rmse:2.80656\n",
      "[1298]\teval-rmse:5.2569\ttrain-rmse:2.80349\n",
      "[1299]\teval-rmse:5.25595\ttrain-rmse:2.80316\n",
      "[1300]\teval-rmse:5.24948\ttrain-rmse:2.80154\n",
      "[1301]\teval-rmse:5.2464\ttrain-rmse:2.8007\n",
      "[1302]\teval-rmse:5.24144\ttrain-rmse:2.79914\n",
      "[1303]\teval-rmse:5.23671\ttrain-rmse:2.79801\n",
      "[1304]\teval-rmse:5.23733\ttrain-rmse:2.79808\n",
      "[1305]\teval-rmse:5.23218\ttrain-rmse:2.79677\n",
      "[1306]\teval-rmse:5.22744\ttrain-rmse:2.79448\n",
      "[1307]\teval-rmse:5.22673\ttrain-rmse:2.7942\n",
      "[1308]\teval-rmse:5.22712\ttrain-rmse:2.79429\n",
      "[1309]\teval-rmse:5.2241\ttrain-rmse:2.79349\n",
      "[1310]\teval-rmse:5.21667\ttrain-rmse:2.78886\n",
      "[1311]\teval-rmse:5.21871\ttrain-rmse:2.78927\n",
      "[1312]\teval-rmse:5.21342\ttrain-rmse:2.78807\n",
      "[1313]\teval-rmse:5.20896\ttrain-rmse:2.78595\n",
      "[1314]\teval-rmse:5.20309\ttrain-rmse:2.78195\n",
      "[1315]\teval-rmse:5.20276\ttrain-rmse:2.78179\n",
      "[1316]\teval-rmse:5.20265\ttrain-rmse:2.78171\n",
      "[1317]\teval-rmse:5.19536\ttrain-rmse:2.77792\n",
      "[1318]\teval-rmse:5.19076\ttrain-rmse:2.77677\n",
      "[1319]\teval-rmse:5.18821\ttrain-rmse:2.77557\n",
      "[1320]\teval-rmse:5.1905\ttrain-rmse:2.77604\n",
      "[1321]\teval-rmse:5.18626\ttrain-rmse:2.775\n",
      "[1322]\teval-rmse:5.1802\ttrain-rmse:2.77364\n",
      "[1323]\teval-rmse:5.17334\ttrain-rmse:2.7693\n",
      "[1324]\teval-rmse:5.17138\ttrain-rmse:2.76883\n",
      "[1325]\teval-rmse:5.17246\ttrain-rmse:2.76898\n",
      "[1326]\teval-rmse:5.17663\ttrain-rmse:2.76987\n",
      "[1327]\teval-rmse:5.17239\ttrain-rmse:2.76863\n",
      "[1328]\teval-rmse:5.1753\ttrain-rmse:2.76913\n",
      "[1329]\teval-rmse:5.17707\ttrain-rmse:2.76944\n",
      "[1330]\teval-rmse:5.17173\ttrain-rmse:2.76597\n",
      "[1331]\teval-rmse:5.17035\ttrain-rmse:2.76558\n",
      "[1332]\teval-rmse:5.16467\ttrain-rmse:2.76217\n",
      "[1333]\teval-rmse:5.15953\ttrain-rmse:2.75896\n",
      "[1334]\teval-rmse:5.1634\ttrain-rmse:2.75977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1335]\teval-rmse:5.1595\ttrain-rmse:2.7589\n",
      "[1336]\teval-rmse:5.16099\ttrain-rmse:2.75909\n",
      "[1337]\teval-rmse:5.16219\ttrain-rmse:2.75923\n",
      "[1338]\teval-rmse:5.16452\ttrain-rmse:2.75972\n",
      "[1339]\teval-rmse:5.15842\ttrain-rmse:2.75843\n",
      "[1340]\teval-rmse:5.15816\ttrain-rmse:2.75831\n",
      "[1341]\teval-rmse:5.1539\ttrain-rmse:2.75629\n",
      "[1342]\teval-rmse:5.15408\ttrain-rmse:2.75622\n",
      "[1343]\teval-rmse:5.15393\ttrain-rmse:2.75612\n",
      "[1344]\teval-rmse:5.14697\ttrain-rmse:2.75189\n",
      "[1345]\teval-rmse:5.14255\ttrain-rmse:2.75088\n",
      "[1346]\teval-rmse:5.13571\ttrain-rmse:2.74633\n",
      "[1347]\teval-rmse:5.12999\ttrain-rmse:2.74516\n",
      "[1348]\teval-rmse:5.13258\ttrain-rmse:2.74561\n",
      "[1349]\teval-rmse:5.13216\ttrain-rmse:2.74548\n",
      "[1350]\teval-rmse:5.1311\ttrain-rmse:2.7452\n",
      "[1351]\teval-rmse:5.13265\ttrain-rmse:2.74539\n",
      "[1352]\teval-rmse:5.13153\ttrain-rmse:2.74465\n",
      "[1353]\teval-rmse:5.13039\ttrain-rmse:2.74436\n",
      "[1354]\teval-rmse:5.12894\ttrain-rmse:2.74399\n",
      "[1355]\teval-rmse:5.12312\ttrain-rmse:2.74287\n",
      "[1356]\teval-rmse:5.11933\ttrain-rmse:2.74205\n",
      "[1357]\teval-rmse:5.11401\ttrain-rmse:2.73832\n",
      "[1358]\teval-rmse:5.11823\ttrain-rmse:2.73917\n",
      "[1359]\teval-rmse:5.11423\ttrain-rmse:2.73743\n",
      "[1360]\teval-rmse:5.11415\ttrain-rmse:2.737\n",
      "[1361]\teval-rmse:5.10991\ttrain-rmse:2.7362\n",
      "[1362]\teval-rmse:5.11144\ttrain-rmse:2.73645\n",
      "[1363]\teval-rmse:5.11357\ttrain-rmse:2.73676\n",
      "[1364]\teval-rmse:5.10877\ttrain-rmse:2.7336\n",
      "[1365]\teval-rmse:5.11219\ttrain-rmse:2.7342\n",
      "[1366]\teval-rmse:5.10719\ttrain-rmse:2.73158\n",
      "[1367]\teval-rmse:5.10271\ttrain-rmse:2.73061\n",
      "[1368]\teval-rmse:5.10191\ttrain-rmse:2.7304\n",
      "[1369]\teval-rmse:5.1037\ttrain-rmse:2.73078\n",
      "[1370]\teval-rmse:5.10402\ttrain-rmse:2.73074\n",
      "[1371]\teval-rmse:5.10539\ttrain-rmse:2.73093\n",
      "[1372]\teval-rmse:5.1001\ttrain-rmse:2.72795\n",
      "[1373]\teval-rmse:5.10077\ttrain-rmse:2.72803\n",
      "[1374]\teval-rmse:5.09701\ttrain-rmse:2.7264\n",
      "[1375]\teval-rmse:5.09488\ttrain-rmse:2.72587\n",
      "[1376]\teval-rmse:5.09605\ttrain-rmse:2.72599\n",
      "[1377]\teval-rmse:5.09835\ttrain-rmse:2.72643\n",
      "[1378]\teval-rmse:5.09619\ttrain-rmse:2.72596\n",
      "[1379]\teval-rmse:5.09711\ttrain-rmse:2.72603\n",
      "[1380]\teval-rmse:5.093\ttrain-rmse:2.72516\n",
      "[1381]\teval-rmse:5.09434\ttrain-rmse:2.7254\n",
      "[1382]\teval-rmse:5.08949\ttrain-rmse:2.72257\n",
      "[1383]\teval-rmse:5.08871\ttrain-rmse:2.72236\n",
      "[1384]\teval-rmse:5.08968\ttrain-rmse:2.72244\n",
      "[1385]\teval-rmse:5.08295\ttrain-rmse:2.71844\n",
      "[1386]\teval-rmse:5.08512\ttrain-rmse:2.71877\n",
      "[1387]\teval-rmse:5.08605\ttrain-rmse:2.71891\n",
      "[1388]\teval-rmse:5.08506\ttrain-rmse:2.71867\n",
      "[1389]\teval-rmse:5.08519\ttrain-rmse:2.71861\n",
      "[1390]\teval-rmse:5.08144\ttrain-rmse:2.71782\n",
      "[1391]\teval-rmse:5.07659\ttrain-rmse:2.71452\n",
      "[1392]\teval-rmse:5.07802\ttrain-rmse:2.71475\n",
      "[1393]\teval-rmse:5.07946\ttrain-rmse:2.71501\n",
      "[1394]\teval-rmse:5.08083\ttrain-rmse:2.7152\n",
      "[1395]\teval-rmse:5.07449\ttrain-rmse:2.71125\n",
      "[1396]\teval-rmse:5.07013\ttrain-rmse:2.71036\n",
      "[1397]\teval-rmse:5.06369\ttrain-rmse:2.7068\n",
      "[1398]\teval-rmse:5.05883\ttrain-rmse:2.70581\n",
      "[1399]\teval-rmse:5.0525\ttrain-rmse:2.70218\n",
      "[1400]\teval-rmse:5.04821\ttrain-rmse:2.70141\n",
      "[1401]\teval-rmse:5.04378\ttrain-rmse:2.69829\n",
      "[1402]\teval-rmse:5.04304\ttrain-rmse:2.69769\n",
      "[1403]\teval-rmse:5.04161\ttrain-rmse:2.69732\n",
      "[1404]\teval-rmse:5.04218\ttrain-rmse:2.69735\n",
      "[1405]\teval-rmse:5.04379\ttrain-rmse:2.69762\n",
      "[1406]\teval-rmse:5.03922\ttrain-rmse:2.6968\n",
      "[1407]\teval-rmse:5.03582\ttrain-rmse:2.69543\n",
      "[1408]\teval-rmse:5.03656\ttrain-rmse:2.69552\n",
      "[1409]\teval-rmse:5.03733\ttrain-rmse:2.69558\n",
      "[1410]\teval-rmse:5.03316\ttrain-rmse:2.69476\n",
      "[1411]\teval-rmse:5.02836\ttrain-rmse:2.69231\n",
      "[1412]\teval-rmse:5.02742\ttrain-rmse:2.69211\n",
      "[1413]\teval-rmse:5.02341\ttrain-rmse:2.69137\n",
      "[1414]\teval-rmse:5.01877\ttrain-rmse:2.69048\n",
      "[1415]\teval-rmse:5.01483\ttrain-rmse:2.68976\n",
      "[1416]\teval-rmse:5.01652\ttrain-rmse:2.69002\n",
      "[1417]\teval-rmse:5.01794\ttrain-rmse:2.69023\n",
      "[1418]\teval-rmse:5.01177\ttrain-rmse:2.68655\n",
      "[1419]\teval-rmse:5.01323\ttrain-rmse:2.68671\n",
      "[1420]\teval-rmse:5.0122\ttrain-rmse:2.68647\n",
      "[1421]\teval-rmse:5.01224\ttrain-rmse:2.6864\n",
      "[1422]\teval-rmse:5.01627\ttrain-rmse:2.68707\n",
      "[1423]\teval-rmse:5.01125\ttrain-rmse:2.68617\n",
      "[1424]\teval-rmse:5.00515\ttrain-rmse:2.683\n",
      "[1425]\teval-rmse:5.00743\ttrain-rmse:2.68326\n",
      "[1426]\teval-rmse:5.00333\ttrain-rmse:2.68261\n",
      "[1427]\teval-rmse:4.99718\ttrain-rmse:2.67908\n",
      "[1428]\teval-rmse:4.99922\ttrain-rmse:2.6794\n",
      "[1429]\teval-rmse:4.99383\ttrain-rmse:2.67855\n",
      "[1430]\teval-rmse:4.99523\ttrain-rmse:2.67877\n",
      "[1431]\teval-rmse:4.99199\ttrain-rmse:2.67829\n",
      "[1432]\teval-rmse:4.98513\ttrain-rmse:2.67722\n",
      "[1433]\teval-rmse:4.98786\ttrain-rmse:2.67765\n",
      "[1434]\teval-rmse:4.98377\ttrain-rmse:2.67661\n",
      "[1435]\teval-rmse:4.98545\ttrain-rmse:2.67685\n",
      "[1436]\teval-rmse:4.98081\ttrain-rmse:2.67413\n",
      "[1437]\teval-rmse:4.97779\ttrain-rmse:2.67363\n",
      "[1438]\teval-rmse:4.9733\ttrain-rmse:2.67136\n",
      "[1439]\teval-rmse:4.97543\ttrain-rmse:2.67169\n",
      "[1440]\teval-rmse:4.96941\ttrain-rmse:2.67071\n",
      "[1441]\teval-rmse:4.97061\ttrain-rmse:2.67085\n",
      "[1442]\teval-rmse:4.96508\ttrain-rmse:2.66997\n",
      "[1443]\teval-rmse:4.96918\ttrain-rmse:2.67058\n",
      "[1444]\teval-rmse:4.97152\ttrain-rmse:2.67093\n",
      "[1445]\teval-rmse:4.96724\ttrain-rmse:2.67022\n",
      "[1446]\teval-rmse:4.96835\ttrain-rmse:2.67031\n",
      "[1447]\teval-rmse:4.97053\ttrain-rmse:2.67062\n",
      "[1448]\teval-rmse:4.9724\ttrain-rmse:2.67094\n",
      "[1449]\teval-rmse:4.9751\ttrain-rmse:2.67134\n",
      "[1450]\teval-rmse:4.97659\ttrain-rmse:2.67149\n",
      "[1451]\teval-rmse:4.97544\ttrain-rmse:2.67125\n",
      "[1452]\teval-rmse:4.9709\ttrain-rmse:2.66907\n",
      "[1453]\teval-rmse:4.96903\ttrain-rmse:2.66872\n",
      "[1454]\teval-rmse:4.97203\ttrain-rmse:2.66914\n",
      "[1455]\teval-rmse:4.96625\ttrain-rmse:2.66829\n",
      "[1456]\teval-rmse:4.96748\ttrain-rmse:2.66851\n",
      "[1457]\teval-rmse:4.96805\ttrain-rmse:2.66853\n",
      "[1458]\teval-rmse:4.96475\ttrain-rmse:2.66779\n",
      "[1459]\teval-rmse:4.96184\ttrain-rmse:2.66731\n",
      "[1460]\teval-rmse:4.9632\ttrain-rmse:2.66749\n",
      "[1461]\teval-rmse:4.9641\ttrain-rmse:2.66756\n",
      "[1462]\teval-rmse:4.96628\ttrain-rmse:2.66786\n",
      "[1463]\teval-rmse:4.96291\ttrain-rmse:2.66735\n",
      "[1464]\teval-rmse:4.96059\ttrain-rmse:2.66702\n",
      "[1465]\teval-rmse:4.95738\ttrain-rmse:2.66625\n",
      "[1466]\teval-rmse:4.96022\ttrain-rmse:2.66663\n",
      "[1467]\teval-rmse:4.95898\ttrain-rmse:2.66626\n",
      "[1468]\teval-rmse:4.95995\ttrain-rmse:2.66632\n",
      "[1469]\teval-rmse:4.96257\ttrain-rmse:2.66669\n",
      "[1470]\teval-rmse:4.95876\ttrain-rmse:2.66585\n",
      "[1471]\teval-rmse:4.95924\ttrain-rmse:2.66586\n",
      "[1472]\teval-rmse:4.96129\ttrain-rmse:2.66615\n",
      "[1473]\teval-rmse:4.96294\ttrain-rmse:2.66631\n",
      "[1474]\teval-rmse:4.96307\ttrain-rmse:2.66628\n",
      "[1475]\teval-rmse:4.96372\ttrain-rmse:2.66634\n",
      "[1476]\teval-rmse:4.95937\ttrain-rmse:2.66565\n",
      "[1477]\teval-rmse:4.95577\ttrain-rmse:2.6651\n",
      "[1478]\teval-rmse:4.95746\ttrain-rmse:2.66535\n",
      "[1479]\teval-rmse:4.95596\ttrain-rmse:2.66509\n",
      "[1480]\teval-rmse:4.95795\ttrain-rmse:2.66531\n",
      "[1481]\teval-rmse:4.95958\ttrain-rmse:2.66552\n",
      "[1482]\teval-rmse:4.95381\ttrain-rmse:2.66227\n",
      "[1483]\teval-rmse:4.94813\ttrain-rmse:2.65881\n",
      "[1484]\teval-rmse:4.94418\ttrain-rmse:2.65795\n",
      "[1485]\teval-rmse:4.94059\ttrain-rmse:2.65718\n",
      "[1486]\teval-rmse:4.93505\ttrain-rmse:2.65389\n",
      "[1487]\teval-rmse:4.93063\ttrain-rmse:2.65193\n",
      "[1488]\teval-rmse:4.93308\ttrain-rmse:2.65223\n",
      "[1489]\teval-rmse:4.93505\ttrain-rmse:2.65251\n",
      "[1490]\teval-rmse:4.93067\ttrain-rmse:2.64947\n",
      "[1491]\teval-rmse:4.93344\ttrain-rmse:2.64985\n",
      "[1492]\teval-rmse:4.93656\ttrain-rmse:2.6502\n",
      "[1493]\teval-rmse:4.93901\ttrain-rmse:2.6505\n",
      "[1494]\teval-rmse:4.93881\ttrain-rmse:2.65045\n",
      "[1495]\teval-rmse:4.93917\ttrain-rmse:2.65044\n",
      "[1496]\teval-rmse:4.9401\ttrain-rmse:2.65049\n",
      "[1497]\teval-rmse:4.93442\ttrain-rmse:2.6497\n",
      "[1498]\teval-rmse:4.93509\ttrain-rmse:2.64973\n",
      "[1499]\teval-rmse:4.93145\ttrain-rmse:2.64919\n",
      "[1500]\teval-rmse:4.93217\ttrain-rmse:2.6493\n",
      "[1501]\teval-rmse:4.931\ttrain-rmse:2.64895\n",
      "[1502]\teval-rmse:4.93359\ttrain-rmse:2.6493\n",
      "[1503]\teval-rmse:4.92921\ttrain-rmse:2.64865\n",
      "[1504]\teval-rmse:4.93345\ttrain-rmse:2.64926\n",
      "[1505]\teval-rmse:4.93389\ttrain-rmse:2.64925\n",
      "[1506]\teval-rmse:4.93754\ttrain-rmse:2.64965\n",
      "[1507]\teval-rmse:4.93175\ttrain-rmse:2.64661\n",
      "[1508]\teval-rmse:4.93314\ttrain-rmse:2.64671\n",
      "[1509]\teval-rmse:4.9345\ttrain-rmse:2.64682\n",
      "[1510]\teval-rmse:4.93652\ttrain-rmse:2.64705\n",
      "[1511]\teval-rmse:4.93185\ttrain-rmse:2.64528\n",
      "[1512]\teval-rmse:4.93377\ttrain-rmse:2.64554\n",
      "[1513]\teval-rmse:4.93049\ttrain-rmse:2.64511\n",
      "[1514]\teval-rmse:4.92814\ttrain-rmse:2.64478\n",
      "[1515]\teval-rmse:4.92466\ttrain-rmse:2.64333\n",
      "[1516]\teval-rmse:4.92523\ttrain-rmse:2.64336\n",
      "[1517]\teval-rmse:4.92086\ttrain-rmse:2.64043\n",
      "[1518]\teval-rmse:4.91499\ttrain-rmse:2.63634\n",
      "[1519]\teval-rmse:4.91279\ttrain-rmse:2.6359\n",
      "[1520]\teval-rmse:4.91305\ttrain-rmse:2.63592\n",
      "[1521]\teval-rmse:4.90884\ttrain-rmse:2.63531\n",
      "[1522]\teval-rmse:4.91165\ttrain-rmse:2.63567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1523]\teval-rmse:4.91031\ttrain-rmse:2.63544\n",
      "[1524]\teval-rmse:4.90622\ttrain-rmse:2.63276\n",
      "[1525]\teval-rmse:4.90804\ttrain-rmse:2.63299\n",
      "[1526]\teval-rmse:4.90378\ttrain-rmse:2.63251\n",
      "[1527]\teval-rmse:4.90233\ttrain-rmse:2.63179\n",
      "[1528]\teval-rmse:4.89862\ttrain-rmse:2.63135\n",
      "[1529]\teval-rmse:4.89968\ttrain-rmse:2.63143\n",
      "[1530]\teval-rmse:4.89558\ttrain-rmse:2.62896\n",
      "[1531]\teval-rmse:4.89174\ttrain-rmse:2.62677\n",
      "[1532]\teval-rmse:4.89309\ttrain-rmse:2.62692\n",
      "[1533]\teval-rmse:4.89482\ttrain-rmse:2.6271\n",
      "[1534]\teval-rmse:4.89522\ttrain-rmse:2.62709\n",
      "[1535]\teval-rmse:4.89304\ttrain-rmse:2.62682\n",
      "[1536]\teval-rmse:4.88886\ttrain-rmse:2.62634\n",
      "[1537]\teval-rmse:4.8848\ttrain-rmse:2.62392\n",
      "[1538]\teval-rmse:4.88667\ttrain-rmse:2.62417\n",
      "[1539]\teval-rmse:4.88397\ttrain-rmse:2.62385\n",
      "[1540]\teval-rmse:4.88168\ttrain-rmse:2.62357\n",
      "[1541]\teval-rmse:4.88251\ttrain-rmse:2.62366\n",
      "[1542]\teval-rmse:4.87785\ttrain-rmse:2.62307\n",
      "[1543]\teval-rmse:4.87985\ttrain-rmse:2.62331\n",
      "[1544]\teval-rmse:4.87734\ttrain-rmse:2.62282\n",
      "[1545]\teval-rmse:4.87431\ttrain-rmse:2.6217\n",
      "[1546]\teval-rmse:4.87472\ttrain-rmse:2.62169\n",
      "[1547]\teval-rmse:4.87159\ttrain-rmse:2.62129\n",
      "[1548]\teval-rmse:4.86755\ttrain-rmse:2.61943\n",
      "[1549]\teval-rmse:4.86822\ttrain-rmse:2.61951\n",
      "[1550]\teval-rmse:4.86263\ttrain-rmse:2.61622\n",
      "[1551]\teval-rmse:4.86367\ttrain-rmse:2.61627\n",
      "[1552]\teval-rmse:4.86154\ttrain-rmse:2.61605\n",
      "[1553]\teval-rmse:4.8625\ttrain-rmse:2.61609\n",
      "[1554]\teval-rmse:4.86217\ttrain-rmse:2.61603\n",
      "[1555]\teval-rmse:4.86287\ttrain-rmse:2.61606\n",
      "[1556]\teval-rmse:4.85775\ttrain-rmse:2.61286\n",
      "[1557]\teval-rmse:4.85161\ttrain-rmse:2.61228\n",
      "[1558]\teval-rmse:4.84776\ttrain-rmse:2.61022\n",
      "[1559]\teval-rmse:4.85037\ttrain-rmse:2.61046\n",
      "[1560]\teval-rmse:4.85262\ttrain-rmse:2.61071\n",
      "[1561]\teval-rmse:4.85585\ttrain-rmse:2.61107\n",
      "[1562]\teval-rmse:4.85631\ttrain-rmse:2.61112\n",
      "[1563]\teval-rmse:4.85943\ttrain-rmse:2.61139\n",
      "[1564]\teval-rmse:4.86062\ttrain-rmse:2.61152\n",
      "[1565]\teval-rmse:4.86275\ttrain-rmse:2.61176\n",
      "[1566]\teval-rmse:4.85911\ttrain-rmse:2.60962\n",
      "[1567]\teval-rmse:4.85405\ttrain-rmse:2.60631\n",
      "[1568]\teval-rmse:4.84949\ttrain-rmse:2.60551\n",
      "[1569]\teval-rmse:4.85086\ttrain-rmse:2.60566\n",
      "[1570]\teval-rmse:4.85494\ttrain-rmse:2.60602\n",
      "[1571]\teval-rmse:4.85756\ttrain-rmse:2.60626\n",
      "[1572]\teval-rmse:4.85199\ttrain-rmse:2.60262\n",
      "[1573]\teval-rmse:4.84928\ttrain-rmse:2.60213\n",
      "[1574]\teval-rmse:4.84476\ttrain-rmse:2.60158\n",
      "[1575]\teval-rmse:4.8459\ttrain-rmse:2.60165\n",
      "[1576]\teval-rmse:4.84876\ttrain-rmse:2.60192\n",
      "[1577]\teval-rmse:4.84471\ttrain-rmse:2.59926\n",
      "[1578]\teval-rmse:4.84354\ttrain-rmse:2.59895\n",
      "[1579]\teval-rmse:4.83952\ttrain-rmse:2.59846\n",
      "[1580]\teval-rmse:4.84175\ttrain-rmse:2.59871\n",
      "[1581]\teval-rmse:4.8443\ttrain-rmse:2.59899\n",
      "[1582]\teval-rmse:4.84439\ttrain-rmse:2.59898\n",
      "[1583]\teval-rmse:4.83888\ttrain-rmse:2.59565\n",
      "[1584]\teval-rmse:4.83617\ttrain-rmse:2.5953\n",
      "[1585]\teval-rmse:4.83703\ttrain-rmse:2.59539\n",
      "[1586]\teval-rmse:4.84068\ttrain-rmse:2.59582\n",
      "[1587]\teval-rmse:4.8387\ttrain-rmse:2.59547\n",
      "[1588]\teval-rmse:4.83519\ttrain-rmse:2.59503\n",
      "[1589]\teval-rmse:4.83008\ttrain-rmse:2.5944\n",
      "[1590]\teval-rmse:4.82924\ttrain-rmse:2.59428\n",
      "[1591]\teval-rmse:4.82639\ttrain-rmse:2.59316\n",
      "[1592]\teval-rmse:4.82108\ttrain-rmse:2.58888\n",
      "[1593]\teval-rmse:4.8178\ttrain-rmse:2.58831\n",
      "[1594]\teval-rmse:4.81289\ttrain-rmse:2.58532\n",
      "[1595]\teval-rmse:4.81497\ttrain-rmse:2.58553\n",
      "[1596]\teval-rmse:4.81168\ttrain-rmse:2.58516\n",
      "[1597]\teval-rmse:4.8065\ttrain-rmse:2.58236\n",
      "[1598]\teval-rmse:4.80392\ttrain-rmse:2.58189\n",
      "[1599]\teval-rmse:4.80621\ttrain-rmse:2.58211\n",
      "[1600]\teval-rmse:4.80869\ttrain-rmse:2.5823\n",
      "[1601]\teval-rmse:4.80805\ttrain-rmse:2.5822\n",
      "[1602]\teval-rmse:4.80892\ttrain-rmse:2.58223\n",
      "[1603]\teval-rmse:4.80391\ttrain-rmse:2.57977\n",
      "[1604]\teval-rmse:4.8006\ttrain-rmse:2.57919\n",
      "[1605]\teval-rmse:4.79711\ttrain-rmse:2.57707\n",
      "[1606]\teval-rmse:4.79283\ttrain-rmse:2.57637\n",
      "[1607]\teval-rmse:4.79132\ttrain-rmse:2.57619\n",
      "[1608]\teval-rmse:4.7886\ttrain-rmse:2.57591\n",
      "[1609]\teval-rmse:4.78989\ttrain-rmse:2.57605\n",
      "[1610]\teval-rmse:4.79279\ttrain-rmse:2.57631\n",
      "[1611]\teval-rmse:4.79377\ttrain-rmse:2.57639\n",
      "[1612]\teval-rmse:4.79626\ttrain-rmse:2.57674\n",
      "[1613]\teval-rmse:4.79848\ttrain-rmse:2.57689\n",
      "[1614]\teval-rmse:4.80108\ttrain-rmse:2.57715\n",
      "[1615]\teval-rmse:4.80346\ttrain-rmse:2.57737\n",
      "[1616]\teval-rmse:4.80307\ttrain-rmse:2.5773\n",
      "[1617]\teval-rmse:4.80586\ttrain-rmse:2.57753\n",
      "[1618]\teval-rmse:4.80237\ttrain-rmse:2.57577\n",
      "[1619]\teval-rmse:4.8003\ttrain-rmse:2.57554\n",
      "[1620]\teval-rmse:4.79521\ttrain-rmse:2.57331\n",
      "[1621]\teval-rmse:4.79026\ttrain-rmse:2.57058\n",
      "[1622]\teval-rmse:4.79199\ttrain-rmse:2.57073\n",
      "[1623]\teval-rmse:4.79291\ttrain-rmse:2.57081\n",
      "[1624]\teval-rmse:4.79508\ttrain-rmse:2.57104\n",
      "[1625]\teval-rmse:4.79741\ttrain-rmse:2.57129\n",
      "[1626]\teval-rmse:4.79365\ttrain-rmse:2.56976\n",
      "[1627]\teval-rmse:4.79085\ttrain-rmse:2.56947\n",
      "[1628]\teval-rmse:4.79409\ttrain-rmse:2.56975\n",
      "[1629]\teval-rmse:4.78899\ttrain-rmse:2.56708\n",
      "[1630]\teval-rmse:4.79105\ttrain-rmse:2.5673\n",
      "[1631]\teval-rmse:4.79073\ttrain-rmse:2.56724\n",
      "[1632]\teval-rmse:4.78676\ttrain-rmse:2.56683\n",
      "[1633]\teval-rmse:4.78432\ttrain-rmse:2.56656\n",
      "[1634]\teval-rmse:4.78362\ttrain-rmse:2.56646\n",
      "[1635]\teval-rmse:4.78228\ttrain-rmse:2.5663\n",
      "[1636]\teval-rmse:4.78228\ttrain-rmse:2.56626\n",
      "[1637]\teval-rmse:4.78473\ttrain-rmse:2.56646\n",
      "[1638]\teval-rmse:4.78634\ttrain-rmse:2.5666\n",
      "[1639]\teval-rmse:4.78893\ttrain-rmse:2.56685\n",
      "[1640]\teval-rmse:4.78938\ttrain-rmse:2.5669\n",
      "[1641]\teval-rmse:4.79169\ttrain-rmse:2.56713\n",
      "[1642]\teval-rmse:4.79447\ttrain-rmse:2.56737\n",
      "[1643]\teval-rmse:4.7945\ttrain-rmse:2.56732\n",
      "[1644]\teval-rmse:4.79125\ttrain-rmse:2.56677\n",
      "[1645]\teval-rmse:4.78614\ttrain-rmse:2.5634\n",
      "[1646]\teval-rmse:4.78341\ttrain-rmse:2.56247\n",
      "[1647]\teval-rmse:4.78524\ttrain-rmse:2.56264\n",
      "[1648]\teval-rmse:4.78541\ttrain-rmse:2.56264\n",
      "[1649]\teval-rmse:4.78499\ttrain-rmse:2.56257\n",
      "[1650]\teval-rmse:4.78707\ttrain-rmse:2.56277\n",
      "[1651]\teval-rmse:4.78767\ttrain-rmse:2.56279\n",
      "[1652]\teval-rmse:4.78434\ttrain-rmse:2.56242\n",
      "[1653]\teval-rmse:4.78521\ttrain-rmse:2.56249\n",
      "[1654]\teval-rmse:4.78581\ttrain-rmse:2.5625\n",
      "[1655]\teval-rmse:4.78581\ttrain-rmse:2.5625\n",
      "[1656]\teval-rmse:4.78667\ttrain-rmse:2.56256\n",
      "[1657]\teval-rmse:4.78751\ttrain-rmse:2.56261\n",
      "[1658]\teval-rmse:4.78613\ttrain-rmse:2.56244\n",
      "[1659]\teval-rmse:4.78099\ttrain-rmse:2.5598\n",
      "[1660]\teval-rmse:4.7782\ttrain-rmse:2.55952\n",
      "[1661]\teval-rmse:4.77559\ttrain-rmse:2.55924\n",
      "[1662]\teval-rmse:4.77485\ttrain-rmse:2.55914\n",
      "[1663]\teval-rmse:4.77561\ttrain-rmse:2.5592\n",
      "[1664]\teval-rmse:4.7771\ttrain-rmse:2.55933\n",
      "[1665]\teval-rmse:4.78001\ttrain-rmse:2.5596\n",
      "[1666]\teval-rmse:4.78209\ttrain-rmse:2.55981\n",
      "[1667]\teval-rmse:4.77877\ttrain-rmse:2.55945\n",
      "[1668]\teval-rmse:4.77496\ttrain-rmse:2.55904\n",
      "[1669]\teval-rmse:4.77183\ttrain-rmse:2.55692\n",
      "[1670]\teval-rmse:4.76916\ttrain-rmse:2.55648\n",
      "[1671]\teval-rmse:4.76555\ttrain-rmse:2.55612\n",
      "[1672]\teval-rmse:4.76182\ttrain-rmse:2.55377\n",
      "[1673]\teval-rmse:4.75867\ttrain-rmse:2.5533\n",
      "[1674]\teval-rmse:4.76066\ttrain-rmse:2.55346\n",
      "[1675]\teval-rmse:4.75594\ttrain-rmse:2.55115\n",
      "[1676]\teval-rmse:4.75341\ttrain-rmse:2.55037\n",
      "[1677]\teval-rmse:4.75562\ttrain-rmse:2.55055\n",
      "[1678]\teval-rmse:4.75325\ttrain-rmse:2.54977\n",
      "[1679]\teval-rmse:4.75524\ttrain-rmse:2.54992\n",
      "[1680]\teval-rmse:4.75462\ttrain-rmse:2.54983\n",
      "[1681]\teval-rmse:4.74971\ttrain-rmse:2.54695\n",
      "[1682]\teval-rmse:4.74565\ttrain-rmse:2.5458\n",
      "[1683]\teval-rmse:4.74852\ttrain-rmse:2.54603\n",
      "[1684]\teval-rmse:4.74981\ttrain-rmse:2.54612\n",
      "[1685]\teval-rmse:4.74383\ttrain-rmse:2.54552\n",
      "[1686]\teval-rmse:4.73985\ttrain-rmse:2.54515\n",
      "[1687]\teval-rmse:4.73729\ttrain-rmse:2.54492\n",
      "[1688]\teval-rmse:4.73916\ttrain-rmse:2.54505\n",
      "[1689]\teval-rmse:4.73954\ttrain-rmse:2.54505\n",
      "[1690]\teval-rmse:4.73715\ttrain-rmse:2.54422\n",
      "[1691]\teval-rmse:4.73588\ttrain-rmse:2.54409\n",
      "[1692]\teval-rmse:4.73321\ttrain-rmse:2.54382\n",
      "[1693]\teval-rmse:4.73354\ttrain-rmse:2.54387\n",
      "[1694]\teval-rmse:4.72924\ttrain-rmse:2.54354\n",
      "[1695]\teval-rmse:4.72555\ttrain-rmse:2.54325\n",
      "[1696]\teval-rmse:4.72795\ttrain-rmse:2.54343\n",
      "[1697]\teval-rmse:4.7252\ttrain-rmse:2.54256\n",
      "[1698]\teval-rmse:4.72529\ttrain-rmse:2.54255\n",
      "[1699]\teval-rmse:4.72735\ttrain-rmse:2.54268\n",
      "[1700]\teval-rmse:4.7287\ttrain-rmse:2.54278\n",
      "[1701]\teval-rmse:4.72629\ttrain-rmse:2.54257\n",
      "[1702]\teval-rmse:4.72332\ttrain-rmse:2.54217\n",
      "[1703]\teval-rmse:4.72001\ttrain-rmse:2.5407\n",
      "[1704]\teval-rmse:4.72049\ttrain-rmse:2.54074\n",
      "[1705]\teval-rmse:4.71569\ttrain-rmse:2.53678\n",
      "[1706]\teval-rmse:4.71866\ttrain-rmse:2.53699\n",
      "[1707]\teval-rmse:4.71387\ttrain-rmse:2.53454\n",
      "[1708]\teval-rmse:4.71534\ttrain-rmse:2.53462\n",
      "[1709]\teval-rmse:4.7122\ttrain-rmse:2.53438\n",
      "[1710]\teval-rmse:4.71403\ttrain-rmse:2.53446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1711]\teval-rmse:4.71125\ttrain-rmse:2.53424\n",
      "[1712]\teval-rmse:4.71299\ttrain-rmse:2.53446\n",
      "[1713]\teval-rmse:4.71368\ttrain-rmse:2.53446\n",
      "[1714]\teval-rmse:4.71183\ttrain-rmse:2.53431\n",
      "[1715]\teval-rmse:4.71372\ttrain-rmse:2.53444\n",
      "[1716]\teval-rmse:4.71514\ttrain-rmse:2.53452\n",
      "[1717]\teval-rmse:4.71587\ttrain-rmse:2.53456\n",
      "[1718]\teval-rmse:4.71622\ttrain-rmse:2.53455\n",
      "[1719]\teval-rmse:4.71788\ttrain-rmse:2.53465\n",
      "[1720]\teval-rmse:4.7134\ttrain-rmse:2.53225\n",
      "[1721]\teval-rmse:4.7132\ttrain-rmse:2.53223\n",
      "[1722]\teval-rmse:4.70852\ttrain-rmse:2.52849\n",
      "[1723]\teval-rmse:4.70382\ttrain-rmse:2.52655\n",
      "[1724]\teval-rmse:4.6999\ttrain-rmse:2.52541\n",
      "[1725]\teval-rmse:4.69424\ttrain-rmse:2.52484\n",
      "[1726]\teval-rmse:4.69106\ttrain-rmse:2.52464\n",
      "[1727]\teval-rmse:4.68873\ttrain-rmse:2.52436\n",
      "[1728]\teval-rmse:4.68996\ttrain-rmse:2.52442\n",
      "[1729]\teval-rmse:4.69137\ttrain-rmse:2.5245\n",
      "[1730]\teval-rmse:4.68704\ttrain-rmse:2.524\n",
      "[1731]\teval-rmse:4.68289\ttrain-rmse:2.5215\n",
      "[1732]\teval-rmse:4.68532\ttrain-rmse:2.52164\n",
      "[1733]\teval-rmse:4.68266\ttrain-rmse:2.52144\n",
      "[1734]\teval-rmse:4.68553\ttrain-rmse:2.52162\n",
      "[1735]\teval-rmse:4.68111\ttrain-rmse:2.52132\n",
      "[1736]\teval-rmse:4.68169\ttrain-rmse:2.52135\n",
      "[1737]\teval-rmse:4.68361\ttrain-rmse:2.52145\n",
      "[1738]\teval-rmse:4.68061\ttrain-rmse:2.52126\n",
      "[1739]\teval-rmse:4.67746\ttrain-rmse:2.52014\n",
      "[1740]\teval-rmse:4.6749\ttrain-rmse:2.51994\n",
      "[1741]\teval-rmse:4.6724\ttrain-rmse:2.51918\n",
      "[1742]\teval-rmse:4.66899\ttrain-rmse:2.519\n",
      "[1743]\teval-rmse:4.67041\ttrain-rmse:2.51906\n",
      "[1744]\teval-rmse:4.666\ttrain-rmse:2.51633\n",
      "[1745]\teval-rmse:4.66798\ttrain-rmse:2.51643\n",
      "[1746]\teval-rmse:4.66354\ttrain-rmse:2.5132\n",
      "[1747]\teval-rmse:4.66689\ttrain-rmse:2.5135\n",
      "[1748]\teval-rmse:4.66592\ttrain-rmse:2.5134\n",
      "[1749]\teval-rmse:4.66226\ttrain-rmse:2.51249\n",
      "[1750]\teval-rmse:4.65933\ttrain-rmse:2.51099\n",
      "[1751]\teval-rmse:4.65653\ttrain-rmse:2.51086\n",
      "[1752]\teval-rmse:4.6523\ttrain-rmse:2.50869\n",
      "[1753]\teval-rmse:4.64773\ttrain-rmse:2.50818\n",
      "[1754]\teval-rmse:4.64329\ttrain-rmse:2.50507\n",
      "[1755]\teval-rmse:4.64666\ttrain-rmse:2.50515\n",
      "[1756]\teval-rmse:4.64748\ttrain-rmse:2.5052\n",
      "[1757]\teval-rmse:4.64829\ttrain-rmse:2.50521\n",
      "[1758]\teval-rmse:4.64556\ttrain-rmse:2.50508\n",
      "[1759]\teval-rmse:4.64147\ttrain-rmse:2.50293\n",
      "[1760]\teval-rmse:4.6433\ttrain-rmse:2.50299\n",
      "[1761]\teval-rmse:4.64105\ttrain-rmse:2.50287\n",
      "[1762]\teval-rmse:4.64349\ttrain-rmse:2.50295\n",
      "[1763]\teval-rmse:4.64522\ttrain-rmse:2.50302\n",
      "[1764]\teval-rmse:4.64308\ttrain-rmse:2.50248\n",
      "[1765]\teval-rmse:4.64104\ttrain-rmse:2.5019\n",
      "[1766]\teval-rmse:4.63837\ttrain-rmse:2.50045\n",
      "[1767]\teval-rmse:4.63598\ttrain-rmse:2.50034\n",
      "[1768]\teval-rmse:4.63784\ttrain-rmse:2.5004\n",
      "[1769]\teval-rmse:4.63495\ttrain-rmse:2.50028\n",
      "[1770]\teval-rmse:4.63227\ttrain-rmse:2.49848\n",
      "[1771]\teval-rmse:4.63164\ttrain-rmse:2.49839\n",
      "[1772]\teval-rmse:4.63387\ttrain-rmse:2.49847\n",
      "[1773]\teval-rmse:4.63653\ttrain-rmse:2.49856\n",
      "[1774]\teval-rmse:4.63652\ttrain-rmse:2.49853\n",
      "[1775]\teval-rmse:4.6334\ttrain-rmse:2.49834\n",
      "[1776]\teval-rmse:4.63073\ttrain-rmse:2.49822\n",
      "[1777]\teval-rmse:4.63184\ttrain-rmse:2.49825\n",
      "[1778]\teval-rmse:4.62824\ttrain-rmse:2.49725\n",
      "[1779]\teval-rmse:4.62856\ttrain-rmse:2.49725\n",
      "[1780]\teval-rmse:4.6304\ttrain-rmse:2.49731\n",
      "[1781]\teval-rmse:4.6261\ttrain-rmse:2.49583\n",
      "[1782]\teval-rmse:4.62817\ttrain-rmse:2.49597\n",
      "[1783]\teval-rmse:4.63138\ttrain-rmse:2.49607\n",
      "[1784]\teval-rmse:4.63309\ttrain-rmse:2.49616\n",
      "[1785]\teval-rmse:4.63507\ttrain-rmse:2.49622\n",
      "[1786]\teval-rmse:4.63329\ttrain-rmse:2.49613\n",
      "[1787]\teval-rmse:4.63518\ttrain-rmse:2.49627\n",
      "[1788]\teval-rmse:4.63087\ttrain-rmse:2.49402\n",
      "[1789]\teval-rmse:4.63128\ttrain-rmse:2.49402\n",
      "[1790]\teval-rmse:4.63194\ttrain-rmse:2.49401\n",
      "[1791]\teval-rmse:4.62981\ttrain-rmse:2.49337\n",
      "[1792]\teval-rmse:4.62548\ttrain-rmse:2.48971\n",
      "[1793]\teval-rmse:4.62735\ttrain-rmse:2.48976\n",
      "[1794]\teval-rmse:4.62324\ttrain-rmse:2.48957\n",
      "[1795]\teval-rmse:4.62052\ttrain-rmse:2.48932\n",
      "[1796]\teval-rmse:4.61806\ttrain-rmse:2.48767\n",
      "[1797]\teval-rmse:4.62079\ttrain-rmse:2.48775\n",
      "[1798]\teval-rmse:4.61787\ttrain-rmse:2.48654\n",
      "[1799]\teval-rmse:4.61581\ttrain-rmse:2.48634\n",
      "[1800]\teval-rmse:4.61378\ttrain-rmse:2.4862\n",
      "[1801]\teval-rmse:4.6115\ttrain-rmse:2.48611\n",
      "[1802]\teval-rmse:4.60829\ttrain-rmse:2.48599\n",
      "[1803]\teval-rmse:4.60561\ttrain-rmse:2.48491\n",
      "[1804]\teval-rmse:4.60613\ttrain-rmse:2.48494\n",
      "[1805]\teval-rmse:4.60352\ttrain-rmse:2.48486\n",
      "[1806]\teval-rmse:4.60132\ttrain-rmse:2.48479\n",
      "[1807]\teval-rmse:4.60391\ttrain-rmse:2.48501\n",
      "[1808]\teval-rmse:4.60571\ttrain-rmse:2.48504\n",
      "[1809]\teval-rmse:4.60811\ttrain-rmse:2.48509\n",
      "[1810]\teval-rmse:4.6053\ttrain-rmse:2.48497\n",
      "[1811]\teval-rmse:4.60223\ttrain-rmse:2.48487\n",
      "[1812]\teval-rmse:4.6041\ttrain-rmse:2.48488\n",
      "[1813]\teval-rmse:4.60007\ttrain-rmse:2.48323\n",
      "[1814]\teval-rmse:4.59802\ttrain-rmse:2.48308\n",
      "[1815]\teval-rmse:4.59914\ttrain-rmse:2.48308\n",
      "[1816]\teval-rmse:4.60134\ttrain-rmse:2.48311\n",
      "[1817]\teval-rmse:4.59829\ttrain-rmse:2.48303\n",
      "[1818]\teval-rmse:4.59553\ttrain-rmse:2.48295\n",
      "[1819]\teval-rmse:4.59223\ttrain-rmse:2.48287\n",
      "[1820]\teval-rmse:4.58963\ttrain-rmse:2.48162\n",
      "[1821]\teval-rmse:4.58753\ttrain-rmse:2.48147\n",
      "[1822]\teval-rmse:4.58396\ttrain-rmse:2.48141\n",
      "[1823]\teval-rmse:4.58611\ttrain-rmse:2.48147\n",
      "[1824]\teval-rmse:4.58596\ttrain-rmse:2.48145\n",
      "[1825]\teval-rmse:4.58484\ttrain-rmse:2.48137\n",
      "[1826]\teval-rmse:4.58222\ttrain-rmse:2.48119\n",
      "[1827]\teval-rmse:4.58018\ttrain-rmse:2.48113\n",
      "[1828]\teval-rmse:4.58124\ttrain-rmse:2.48114\n",
      "[1829]\teval-rmse:4.58404\ttrain-rmse:2.48115\n",
      "[1830]\teval-rmse:4.58293\ttrain-rmse:2.48113\n",
      "[1831]\teval-rmse:4.58231\ttrain-rmse:2.48109\n",
      "[1832]\teval-rmse:4.58421\ttrain-rmse:2.4811\n",
      "[1833]\teval-rmse:4.58216\ttrain-rmse:2.48063\n",
      "[1834]\teval-rmse:4.58275\ttrain-rmse:2.48061\n",
      "[1835]\teval-rmse:4.58425\ttrain-rmse:2.48061\n",
      "[1836]\teval-rmse:4.58482\ttrain-rmse:2.48062\n",
      "[1837]\teval-rmse:4.58772\ttrain-rmse:2.48065\n",
      "[1838]\teval-rmse:4.58952\ttrain-rmse:2.48065\n",
      "[1839]\teval-rmse:4.59105\ttrain-rmse:2.48066\n",
      "[1840]\teval-rmse:4.59357\ttrain-rmse:2.4807\n",
      "[1841]\teval-rmse:4.59666\ttrain-rmse:2.48076\n",
      "[1842]\teval-rmse:4.59261\ttrain-rmse:2.47928\n",
      "[1843]\teval-rmse:4.58905\ttrain-rmse:2.47919\n",
      "[1844]\teval-rmse:4.59079\ttrain-rmse:2.4792\n",
      "[1845]\teval-rmse:4.59236\ttrain-rmse:2.47923\n",
      "[1846]\teval-rmse:4.59174\ttrain-rmse:2.47899\n",
      "[1847]\teval-rmse:4.58814\ttrain-rmse:2.47891\n",
      "[1848]\teval-rmse:4.58603\ttrain-rmse:2.47826\n",
      "[1849]\teval-rmse:4.58838\ttrain-rmse:2.4783\n",
      "[1850]\teval-rmse:4.58438\ttrain-rmse:2.47592\n",
      "[1851]\teval-rmse:4.58671\ttrain-rmse:2.47593\n",
      "[1852]\teval-rmse:4.58426\ttrain-rmse:2.47587\n",
      "[1853]\teval-rmse:4.58168\ttrain-rmse:2.47458\n",
      "[1854]\teval-rmse:4.57848\ttrain-rmse:2.47445\n",
      "[1855]\teval-rmse:4.57585\ttrain-rmse:2.4744\n",
      "[1856]\teval-rmse:4.57371\ttrain-rmse:2.47376\n",
      "[1857]\teval-rmse:4.57178\ttrain-rmse:2.47323\n",
      "[1858]\teval-rmse:4.56793\ttrain-rmse:2.47121\n",
      "[1859]\teval-rmse:4.56935\ttrain-rmse:2.47121\n",
      "[1860]\teval-rmse:4.56822\ttrain-rmse:2.47118\n",
      "[1861]\teval-rmse:4.56568\ttrain-rmse:2.4698\n",
      "[1862]\teval-rmse:4.56535\ttrain-rmse:2.46977\n",
      "[1863]\teval-rmse:4.56231\ttrain-rmse:2.46963\n",
      "[1864]\teval-rmse:4.56396\ttrain-rmse:2.46969\n",
      "[1865]\teval-rmse:4.56149\ttrain-rmse:2.46851\n",
      "[1866]\teval-rmse:4.55893\ttrain-rmse:2.46849\n",
      "[1867]\teval-rmse:4.56156\ttrain-rmse:2.46859\n",
      "[1868]\teval-rmse:4.56107\ttrain-rmse:2.46856\n",
      "[1869]\teval-rmse:4.55862\ttrain-rmse:2.46851\n",
      "[1870]\teval-rmse:4.55956\ttrain-rmse:2.46897\n",
      "[1871]\teval-rmse:4.5597\ttrain-rmse:2.46898\n",
      "[1872]\teval-rmse:4.56158\ttrain-rmse:2.46895\n",
      "[1873]\teval-rmse:4.56256\ttrain-rmse:2.46899\n",
      "[1874]\teval-rmse:4.55945\ttrain-rmse:2.46894\n",
      "[1875]\teval-rmse:4.5633\ttrain-rmse:2.46896\n",
      "[1876]\teval-rmse:4.56143\ttrain-rmse:2.46847\n",
      "[1877]\teval-rmse:4.56426\ttrain-rmse:2.46847\n",
      "[1878]\teval-rmse:4.56575\ttrain-rmse:2.46847\n",
      "[1879]\teval-rmse:4.56321\ttrain-rmse:2.46745\n",
      "[1880]\teval-rmse:4.56078\ttrain-rmse:2.46562\n",
      "[1881]\teval-rmse:4.56365\ttrain-rmse:2.46564\n",
      "[1882]\teval-rmse:4.56008\ttrain-rmse:2.46305\n",
      "[1883]\teval-rmse:4.56215\ttrain-rmse:2.46308\n",
      "[1884]\teval-rmse:4.56005\ttrain-rmse:2.46295\n",
      "[1885]\teval-rmse:4.557\ttrain-rmse:2.4629\n",
      "[1886]\teval-rmse:4.55339\ttrain-rmse:2.46283\n",
      "[1887]\teval-rmse:4.55283\ttrain-rmse:2.46279\n",
      "[1888]\teval-rmse:4.55396\ttrain-rmse:2.46283\n",
      "[1889]\teval-rmse:4.55041\ttrain-rmse:2.46091\n",
      "[1890]\teval-rmse:4.55266\ttrain-rmse:2.4609\n",
      "[1891]\teval-rmse:4.55362\ttrain-rmse:2.46089\n",
      "[1892]\teval-rmse:4.55638\ttrain-rmse:2.4609\n",
      "[1893]\teval-rmse:4.55243\ttrain-rmse:2.45814\n",
      "[1894]\teval-rmse:4.55338\ttrain-rmse:2.45815\n",
      "[1895]\teval-rmse:4.55435\ttrain-rmse:2.45815\n",
      "[1896]\teval-rmse:4.55104\ttrain-rmse:2.4581\n",
      "[1897]\teval-rmse:4.5494\ttrain-rmse:2.45805\n",
      "[1898]\teval-rmse:4.55228\ttrain-rmse:2.45806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1899]\teval-rmse:4.55397\ttrain-rmse:2.45805\n",
      "[1900]\teval-rmse:4.55011\ttrain-rmse:2.45581\n",
      "[1901]\teval-rmse:4.54754\ttrain-rmse:2.45487\n",
      "[1902]\teval-rmse:4.54943\ttrain-rmse:2.45488\n",
      "[1903]\teval-rmse:4.54705\ttrain-rmse:2.45475\n",
      "[1904]\teval-rmse:4.54329\ttrain-rmse:2.45254\n",
      "[1905]\teval-rmse:4.54137\ttrain-rmse:2.45212\n",
      "[1906]\teval-rmse:4.53605\ttrain-rmse:2.45194\n",
      "[1907]\teval-rmse:4.53456\ttrain-rmse:2.45192\n",
      "[1908]\teval-rmse:4.53081\ttrain-rmse:2.44978\n",
      "[1909]\teval-rmse:4.53202\ttrain-rmse:2.44974\n",
      "[1910]\teval-rmse:4.53487\ttrain-rmse:2.44972\n",
      "[1911]\teval-rmse:4.53194\ttrain-rmse:2.44969\n",
      "[1912]\teval-rmse:4.53366\ttrain-rmse:2.44965\n",
      "[1913]\teval-rmse:4.53074\ttrain-rmse:2.44963\n",
      "[1914]\teval-rmse:4.52699\ttrain-rmse:2.44947\n",
      "[1915]\teval-rmse:4.52322\ttrain-rmse:2.44696\n",
      "[1916]\teval-rmse:4.5248\ttrain-rmse:2.44693\n",
      "[1917]\teval-rmse:4.52491\ttrain-rmse:2.44691\n",
      "[1918]\teval-rmse:4.52656\ttrain-rmse:2.44689\n",
      "[1919]\teval-rmse:4.52278\ttrain-rmse:2.44354\n",
      "[1920]\teval-rmse:4.52466\ttrain-rmse:2.4435\n",
      "[1921]\teval-rmse:4.52094\ttrain-rmse:2.44218\n",
      "[1922]\teval-rmse:4.51682\ttrain-rmse:2.44195\n",
      "[1923]\teval-rmse:4.52005\ttrain-rmse:2.44194\n",
      "[1924]\teval-rmse:4.51764\ttrain-rmse:2.44072\n",
      "[1925]\teval-rmse:4.51539\ttrain-rmse:2.44062\n",
      "[1926]\teval-rmse:4.51657\ttrain-rmse:2.44059\n",
      "[1927]\teval-rmse:4.51296\ttrain-rmse:2.43933\n",
      "[1928]\teval-rmse:4.51559\ttrain-rmse:2.43928\n",
      "[1929]\teval-rmse:4.51392\ttrain-rmse:2.43887\n",
      "[1930]\teval-rmse:4.51231\ttrain-rmse:2.43883\n",
      "[1931]\teval-rmse:4.5071\ttrain-rmse:2.43863\n",
      "[1932]\teval-rmse:4.50884\ttrain-rmse:2.43866\n",
      "[1933]\teval-rmse:4.50705\ttrain-rmse:2.4383\n",
      "[1934]\teval-rmse:4.50953\ttrain-rmse:2.43825\n",
      "[1935]\teval-rmse:4.50735\ttrain-rmse:2.43826\n",
      "[1936]\teval-rmse:4.50966\ttrain-rmse:2.4382\n",
      "[1937]\teval-rmse:4.51017\ttrain-rmse:2.43817\n",
      "[1938]\teval-rmse:4.50802\ttrain-rmse:2.43724\n",
      "[1939]\teval-rmse:4.50576\ttrain-rmse:2.43716\n",
      "[1940]\teval-rmse:4.50343\ttrain-rmse:2.43716\n",
      "[1941]\teval-rmse:4.49931\ttrain-rmse:2.43719\n",
      "[1942]\teval-rmse:4.49998\ttrain-rmse:2.43718\n",
      "[1943]\teval-rmse:4.50075\ttrain-rmse:2.43718\n",
      "[1944]\teval-rmse:4.50041\ttrain-rmse:2.43702\n",
      "[1945]\teval-rmse:4.49704\ttrain-rmse:2.43704\n",
      "[1946]\teval-rmse:4.49471\ttrain-rmse:2.43707\n",
      "[1947]\teval-rmse:4.49309\ttrain-rmse:2.43709\n",
      "[1948]\teval-rmse:4.49404\ttrain-rmse:2.43707\n",
      "[1949]\teval-rmse:4.49693\ttrain-rmse:2.437\n",
      "[1950]\teval-rmse:4.49866\ttrain-rmse:2.43696\n",
      "[1951]\teval-rmse:4.49506\ttrain-rmse:2.43501\n",
      "[1952]\teval-rmse:4.49752\ttrain-rmse:2.43496\n",
      "[1953]\teval-rmse:4.4992\ttrain-rmse:2.43493\n",
      "[1954]\teval-rmse:4.50347\ttrain-rmse:2.43487\n",
      "[1955]\teval-rmse:4.50516\ttrain-rmse:2.43483\n",
      "[1956]\teval-rmse:4.50641\ttrain-rmse:2.43483\n",
      "[1957]\teval-rmse:4.50399\ttrain-rmse:2.43474\n",
      "[1958]\teval-rmse:4.5013\ttrain-rmse:2.43475\n",
      "[1959]\teval-rmse:4.50296\ttrain-rmse:2.43472\n",
      "[1960]\teval-rmse:4.50411\ttrain-rmse:2.43468\n",
      "[1961]\teval-rmse:4.50545\ttrain-rmse:2.43467\n",
      "[1962]\teval-rmse:4.50783\ttrain-rmse:2.43465\n",
      "[1963]\teval-rmse:4.51044\ttrain-rmse:2.43464\n",
      "[1964]\teval-rmse:4.51131\ttrain-rmse:2.43462\n",
      "[1965]\teval-rmse:4.51293\ttrain-rmse:2.43463\n",
      "[1966]\teval-rmse:4.51483\ttrain-rmse:2.43461\n",
      "[1967]\teval-rmse:4.51277\ttrain-rmse:2.43454\n",
      "[1968]\teval-rmse:4.51101\ttrain-rmse:2.43446\n",
      "[1969]\teval-rmse:4.50974\ttrain-rmse:2.43446\n",
      "[1970]\teval-rmse:4.5089\ttrain-rmse:2.43442\n",
      "[1971]\teval-rmse:4.50541\ttrain-rmse:2.43289\n",
      "[1972]\teval-rmse:4.50178\ttrain-rmse:2.43176\n",
      "[1973]\teval-rmse:4.50228\ttrain-rmse:2.43173\n",
      "[1974]\teval-rmse:4.49908\ttrain-rmse:2.43174\n",
      "[1975]\teval-rmse:4.49847\ttrain-rmse:2.43171\n",
      "[1976]\teval-rmse:4.49614\ttrain-rmse:2.43092\n",
      "[1977]\teval-rmse:4.49779\ttrain-rmse:2.43089\n",
      "[1978]\teval-rmse:4.49439\ttrain-rmse:2.43091\n",
      "[1979]\teval-rmse:4.49199\ttrain-rmse:2.43093\n",
      "[1980]\teval-rmse:4.49005\ttrain-rmse:2.4299\n",
      "[1981]\teval-rmse:4.49103\ttrain-rmse:2.42992\n",
      "[1982]\teval-rmse:4.49212\ttrain-rmse:2.42987\n",
      "[1983]\teval-rmse:4.48887\ttrain-rmse:2.4299\n",
      "[1984]\teval-rmse:4.48982\ttrain-rmse:2.42988\n",
      "[1985]\teval-rmse:4.48703\ttrain-rmse:2.42992\n",
      "[1986]\teval-rmse:4.48908\ttrain-rmse:2.42988\n",
      "[1987]\teval-rmse:4.4914\ttrain-rmse:2.42982\n",
      "[1988]\teval-rmse:4.48788\ttrain-rmse:2.4268\n",
      "[1989]\teval-rmse:4.48835\ttrain-rmse:2.42678\n",
      "[1990]\teval-rmse:4.48457\ttrain-rmse:2.42681\n",
      "[1991]\teval-rmse:4.47961\ttrain-rmse:2.42678\n",
      "[1992]\teval-rmse:4.48156\ttrain-rmse:2.4267\n",
      "[1993]\teval-rmse:4.48238\ttrain-rmse:2.42672\n",
      "[1994]\teval-rmse:4.48522\ttrain-rmse:2.42665\n",
      "[1995]\teval-rmse:4.48645\ttrain-rmse:2.42661\n",
      "[1996]\teval-rmse:4.48604\ttrain-rmse:2.4266\n",
      "[1997]\teval-rmse:4.48275\ttrain-rmse:2.425\n",
      "[1998]\teval-rmse:4.48114\ttrain-rmse:2.42495\n",
      "[1999]\teval-rmse:4.48332\ttrain-rmse:2.4249\n",
      "[2000]\teval-rmse:4.48501\ttrain-rmse:2.42485\n",
      "[2001]\teval-rmse:4.4811\ttrain-rmse:2.42489\n",
      "[2002]\teval-rmse:4.47894\ttrain-rmse:2.42333\n",
      "[2003]\teval-rmse:4.48229\ttrain-rmse:2.42325\n",
      "[2004]\teval-rmse:4.47804\ttrain-rmse:2.42332\n",
      "[2005]\teval-rmse:4.47475\ttrain-rmse:2.42188\n",
      "[2006]\teval-rmse:4.47174\ttrain-rmse:2.42182\n",
      "[2007]\teval-rmse:4.4707\ttrain-rmse:2.42182\n",
      "[2008]\teval-rmse:4.47148\ttrain-rmse:2.42178\n",
      "[2009]\teval-rmse:4.47329\ttrain-rmse:2.42171\n",
      "[2010]\teval-rmse:4.46944\ttrain-rmse:2.42178\n",
      "[2011]\teval-rmse:4.46626\ttrain-rmse:2.42022\n",
      "[2012]\teval-rmse:4.46741\ttrain-rmse:2.42023\n",
      "[2013]\teval-rmse:4.4683\ttrain-rmse:2.42019\n",
      "[2014]\teval-rmse:4.47098\ttrain-rmse:2.4201\n",
      "[2015]\teval-rmse:4.47351\ttrain-rmse:2.42002\n",
      "[2016]\teval-rmse:4.47575\ttrain-rmse:2.41996\n",
      "[2017]\teval-rmse:4.47802\ttrain-rmse:2.41991\n",
      "[2018]\teval-rmse:4.47931\ttrain-rmse:2.41995\n",
      "[2019]\teval-rmse:4.48135\ttrain-rmse:2.41989\n",
      "[2020]\teval-rmse:4.47864\ttrain-rmse:2.4199\n",
      "[2021]\teval-rmse:4.47975\ttrain-rmse:2.41988\n",
      "[2022]\teval-rmse:4.47698\ttrain-rmse:2.41992\n",
      "[2023]\teval-rmse:4.47938\ttrain-rmse:2.41986\n",
      "[2024]\teval-rmse:4.48145\ttrain-rmse:2.41981\n",
      "[2025]\teval-rmse:4.48168\ttrain-rmse:2.4198\n",
      "[2026]\teval-rmse:4.48234\ttrain-rmse:2.41979\n",
      "[2027]\teval-rmse:4.47997\ttrain-rmse:2.41981\n",
      "[2028]\teval-rmse:4.4779\ttrain-rmse:2.41858\n",
      "[2029]\teval-rmse:4.47487\ttrain-rmse:2.41851\n",
      "[2030]\teval-rmse:4.47786\ttrain-rmse:2.41844\n",
      "[2031]\teval-rmse:4.47527\ttrain-rmse:2.41846\n",
      "[2032]\teval-rmse:4.47249\ttrain-rmse:2.4185\n",
      "[2033]\teval-rmse:4.47445\ttrain-rmse:2.41845\n",
      "[2034]\teval-rmse:4.4755\ttrain-rmse:2.41842\n",
      "[2035]\teval-rmse:4.47654\ttrain-rmse:2.41839\n",
      "[2036]\teval-rmse:4.47687\ttrain-rmse:2.41838\n",
      "[2037]\teval-rmse:4.47738\ttrain-rmse:2.41837\n",
      "[2038]\teval-rmse:4.47958\ttrain-rmse:2.41833\n",
      "[2039]\teval-rmse:4.48127\ttrain-rmse:2.41829\n",
      "[2040]\teval-rmse:4.48386\ttrain-rmse:2.41825\n",
      "[2041]\teval-rmse:4.48189\ttrain-rmse:2.41826\n",
      "[2042]\teval-rmse:4.47839\ttrain-rmse:2.41717\n",
      "[2043]\teval-rmse:4.47489\ttrain-rmse:2.41405\n",
      "[2044]\teval-rmse:4.47598\ttrain-rmse:2.414\n",
      "[2045]\teval-rmse:4.47307\ttrain-rmse:2.41403\n",
      "[2046]\teval-rmse:4.47001\ttrain-rmse:2.41343\n",
      "[2047]\teval-rmse:4.46667\ttrain-rmse:2.41228\n",
      "[2048]\teval-rmse:4.46323\ttrain-rmse:2.41111\n",
      "[2049]\teval-rmse:4.46104\ttrain-rmse:2.41039\n",
      "[2050]\teval-rmse:4.46275\ttrain-rmse:2.41034\n",
      "[2051]\teval-rmse:4.4597\ttrain-rmse:2.41038\n",
      "[2052]\teval-rmse:4.45572\ttrain-rmse:2.41037\n",
      "[2053]\teval-rmse:4.45472\ttrain-rmse:2.41037\n",
      "[2054]\teval-rmse:4.45314\ttrain-rmse:2.41034\n",
      "[2055]\teval-rmse:4.45368\ttrain-rmse:2.41031\n",
      "[2056]\teval-rmse:4.45143\ttrain-rmse:2.41036\n",
      "[2057]\teval-rmse:4.44822\ttrain-rmse:2.40905\n",
      "[2058]\teval-rmse:4.45071\ttrain-rmse:2.40897\n",
      "[2059]\teval-rmse:4.45373\ttrain-rmse:2.40888\n",
      "[2060]\teval-rmse:4.45647\ttrain-rmse:2.40879\n",
      "[2061]\teval-rmse:4.45424\ttrain-rmse:2.40824\n",
      "[2062]\teval-rmse:4.4522\ttrain-rmse:2.40675\n",
      "[2063]\teval-rmse:4.45294\ttrain-rmse:2.40677\n",
      "[2064]\teval-rmse:4.45463\ttrain-rmse:2.40671\n",
      "[2065]\teval-rmse:4.45185\ttrain-rmse:2.40677\n",
      "[2066]\teval-rmse:4.45148\ttrain-rmse:2.40676\n",
      "[2067]\teval-rmse:4.45095\ttrain-rmse:2.40676\n",
      "[2068]\teval-rmse:4.45456\ttrain-rmse:2.40665\n",
      "[2069]\teval-rmse:4.45735\ttrain-rmse:2.40661\n",
      "[2070]\teval-rmse:4.4603\ttrain-rmse:2.40654\n",
      "[2071]\teval-rmse:4.46178\ttrain-rmse:2.40659\n",
      "[2072]\teval-rmse:4.4638\ttrain-rmse:2.40654\n",
      "[2073]\teval-rmse:4.46092\ttrain-rmse:2.40658\n",
      "[2074]\teval-rmse:4.45845\ttrain-rmse:2.40661\n",
      "[2075]\teval-rmse:4.46164\ttrain-rmse:2.40657\n",
      "[2076]\teval-rmse:4.45972\ttrain-rmse:2.40654\n",
      "[2077]\teval-rmse:4.45778\ttrain-rmse:2.40574\n",
      "[2078]\teval-rmse:4.45816\ttrain-rmse:2.40572\n",
      "[2079]\teval-rmse:4.4598\ttrain-rmse:2.40568\n",
      "[2080]\teval-rmse:4.46255\ttrain-rmse:2.40563\n",
      "[2081]\teval-rmse:4.46475\ttrain-rmse:2.40557\n",
      "[2082]\teval-rmse:4.46619\ttrain-rmse:2.40554\n",
      "[2083]\teval-rmse:4.46854\ttrain-rmse:2.4055\n",
      "[2084]\teval-rmse:4.46516\ttrain-rmse:2.40442\n",
      "[2085]\teval-rmse:4.46403\ttrain-rmse:2.40442\n",
      "[2086]\teval-rmse:4.46191\ttrain-rmse:2.40308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2087]\teval-rmse:4.45962\ttrain-rmse:2.40302\n",
      "[2088]\teval-rmse:4.46078\ttrain-rmse:2.40301\n",
      "[2089]\teval-rmse:4.45871\ttrain-rmse:2.40212\n",
      "[2090]\teval-rmse:4.46094\ttrain-rmse:2.40221\n",
      "[2091]\teval-rmse:4.45752\ttrain-rmse:2.39921\n",
      "[2092]\teval-rmse:4.4584\ttrain-rmse:2.39918\n",
      "[2093]\teval-rmse:4.45666\ttrain-rmse:2.39914\n",
      "[2094]\teval-rmse:4.45508\ttrain-rmse:2.39908\n",
      "[2095]\teval-rmse:4.45289\ttrain-rmse:2.39777\n",
      "[2096]\teval-rmse:4.44973\ttrain-rmse:2.39647\n",
      "[2097]\teval-rmse:4.44722\ttrain-rmse:2.39643\n",
      "[2098]\teval-rmse:4.44923\ttrain-rmse:2.39639\n",
      "[2099]\teval-rmse:4.44587\ttrain-rmse:2.39468\n",
      "[2100]\teval-rmse:4.44653\ttrain-rmse:2.39468\n",
      "[2101]\teval-rmse:4.44822\ttrain-rmse:2.39465\n",
      "[2102]\teval-rmse:4.44488\ttrain-rmse:2.39465\n",
      "[2103]\teval-rmse:4.44342\ttrain-rmse:2.39439\n",
      "[2104]\teval-rmse:4.44128\ttrain-rmse:2.39441\n",
      "[2105]\teval-rmse:4.44251\ttrain-rmse:2.3944\n",
      "[2106]\teval-rmse:4.43935\ttrain-rmse:2.39315\n",
      "[2107]\teval-rmse:4.43773\ttrain-rmse:2.39289\n",
      "[2108]\teval-rmse:4.44064\ttrain-rmse:2.39282\n",
      "[2109]\teval-rmse:4.43731\ttrain-rmse:2.39051\n",
      "[2110]\teval-rmse:4.43541\ttrain-rmse:2.38943\n",
      "[2111]\teval-rmse:4.43747\ttrain-rmse:2.38941\n",
      "[2112]\teval-rmse:4.43932\ttrain-rmse:2.38936\n",
      "[2113]\teval-rmse:4.44128\ttrain-rmse:2.3893\n",
      "[2114]\teval-rmse:4.4395\ttrain-rmse:2.38932\n",
      "[2115]\teval-rmse:4.44066\ttrain-rmse:2.38931\n",
      "[2116]\teval-rmse:4.44415\ttrain-rmse:2.38923\n",
      "[2117]\teval-rmse:4.4463\ttrain-rmse:2.38918\n",
      "[2118]\teval-rmse:4.44343\ttrain-rmse:2.38871\n",
      "[2119]\teval-rmse:4.44524\ttrain-rmse:2.38877\n",
      "[2120]\teval-rmse:4.44302\ttrain-rmse:2.38879\n",
      "[2121]\teval-rmse:4.44051\ttrain-rmse:2.38878\n",
      "[2122]\teval-rmse:4.44128\ttrain-rmse:2.3888\n",
      "[2123]\teval-rmse:4.44537\ttrain-rmse:2.38888\n",
      "[2124]\teval-rmse:4.44824\ttrain-rmse:2.38884\n",
      "[2125]\teval-rmse:4.44969\ttrain-rmse:2.38884\n",
      "[2126]\teval-rmse:4.45261\ttrain-rmse:2.38893\n",
      "[2127]\teval-rmse:4.45047\ttrain-rmse:2.38826\n",
      "[2128]\teval-rmse:4.44778\ttrain-rmse:2.38824\n",
      "[2129]\teval-rmse:4.45183\ttrain-rmse:2.38836\n",
      "[2130]\teval-rmse:4.45015\ttrain-rmse:2.38835\n",
      "[2131]\teval-rmse:4.4499\ttrain-rmse:2.38833\n",
      "[2132]\teval-rmse:4.45109\ttrain-rmse:2.38839\n",
      "[2133]\teval-rmse:4.44881\ttrain-rmse:2.38833\n",
      "[2134]\teval-rmse:4.45056\ttrain-rmse:2.3883\n",
      "[2135]\teval-rmse:4.44789\ttrain-rmse:2.38828\n",
      "[2136]\teval-rmse:4.44596\ttrain-rmse:2.38724\n",
      "[2137]\teval-rmse:4.44767\ttrain-rmse:2.38722\n",
      "[2138]\teval-rmse:4.44954\ttrain-rmse:2.38717\n",
      "[2139]\teval-rmse:4.45021\ttrain-rmse:2.38717\n",
      "[2140]\teval-rmse:4.44683\ttrain-rmse:2.38707\n",
      "[2141]\teval-rmse:4.44974\ttrain-rmse:2.38715\n",
      "[2142]\teval-rmse:4.45147\ttrain-rmse:2.38712\n",
      "[2143]\teval-rmse:4.45432\ttrain-rmse:2.38712\n",
      "[2144]\teval-rmse:4.45594\ttrain-rmse:2.38713\n",
      "[2145]\teval-rmse:4.45254\ttrain-rmse:2.38548\n",
      "[2146]\teval-rmse:4.456\ttrain-rmse:2.38565\n",
      "[2147]\teval-rmse:4.45671\ttrain-rmse:2.38565\n",
      "[2148]\teval-rmse:4.4547\ttrain-rmse:2.38556\n",
      "[2149]\teval-rmse:4.45134\ttrain-rmse:2.38423\n",
      "[2150]\teval-rmse:4.45408\ttrain-rmse:2.38433\n",
      "[2151]\teval-rmse:4.45622\ttrain-rmse:2.38432\n",
      "[2152]\teval-rmse:4.45691\ttrain-rmse:2.38434\n",
      "[2153]\teval-rmse:4.45838\ttrain-rmse:2.38436\n",
      "[2154]\teval-rmse:4.45633\ttrain-rmse:2.38348\n",
      "[2155]\teval-rmse:4.45437\ttrain-rmse:2.38343\n",
      "[2156]\teval-rmse:4.45558\ttrain-rmse:2.38345\n",
      "[2157]\teval-rmse:4.45212\ttrain-rmse:2.38203\n",
      "[2158]\teval-rmse:4.45144\ttrain-rmse:2.382\n",
      "[2159]\teval-rmse:4.45413\ttrain-rmse:2.3821\n",
      "[2160]\teval-rmse:4.45247\ttrain-rmse:2.38174\n",
      "[2161]\teval-rmse:4.44914\ttrain-rmse:2.37928\n",
      "[2162]\teval-rmse:4.4518\ttrain-rmse:2.37927\n",
      "[2163]\teval-rmse:4.45222\ttrain-rmse:2.37927\n",
      "[2164]\teval-rmse:4.45429\ttrain-rmse:2.37931\n",
      "[2165]\teval-rmse:4.45771\ttrain-rmse:2.37932\n",
      "[2166]\teval-rmse:4.45739\ttrain-rmse:2.37929\n",
      "[2167]\teval-rmse:4.45906\ttrain-rmse:2.37929\n",
      "[2168]\teval-rmse:4.45965\ttrain-rmse:2.37931\n",
      "[2169]\teval-rmse:4.45789\ttrain-rmse:2.379\n",
      "[2170]\teval-rmse:4.45454\ttrain-rmse:2.37707\n",
      "[2171]\teval-rmse:4.45233\ttrain-rmse:2.37704\n",
      "[2172]\teval-rmse:4.45511\ttrain-rmse:2.37708\n",
      "[2173]\teval-rmse:4.45302\ttrain-rmse:2.37652\n",
      "[2174]\teval-rmse:4.45589\ttrain-rmse:2.37665\n",
      "[2175]\teval-rmse:4.45705\ttrain-rmse:2.37673\n",
      "[2176]\teval-rmse:4.45764\ttrain-rmse:2.37673\n",
      "[2177]\teval-rmse:4.45546\ttrain-rmse:2.3755\n",
      "[2178]\teval-rmse:4.45833\ttrain-rmse:2.37564\n",
      "[2179]\teval-rmse:4.45884\ttrain-rmse:2.37564\n",
      "[2180]\teval-rmse:4.46019\ttrain-rmse:2.37564\n",
      "[2181]\teval-rmse:4.4568\ttrain-rmse:2.3728\n",
      "[2182]\teval-rmse:4.45365\ttrain-rmse:2.37267\n",
      "[2183]\teval-rmse:4.45026\ttrain-rmse:2.37035\n",
      "[2184]\teval-rmse:4.44818\ttrain-rmse:2.37027\n",
      "[2185]\teval-rmse:4.45017\ttrain-rmse:2.37032\n",
      "[2186]\teval-rmse:4.44799\ttrain-rmse:2.36922\n",
      "[2187]\teval-rmse:4.44934\ttrain-rmse:2.36923\n",
      "[2188]\teval-rmse:4.45106\ttrain-rmse:2.36928\n",
      "[2189]\teval-rmse:4.44804\ttrain-rmse:2.36917\n",
      "[2190]\teval-rmse:4.44914\ttrain-rmse:2.36918\n",
      "[2191]\teval-rmse:4.45061\ttrain-rmse:2.36921\n",
      "[2192]\teval-rmse:4.452\ttrain-rmse:2.36929\n",
      "[2193]\teval-rmse:4.45388\ttrain-rmse:2.36932\n",
      "[2194]\teval-rmse:4.45057\ttrain-rmse:2.36803\n",
      "[2195]\teval-rmse:4.44837\ttrain-rmse:2.36711\n",
      "[2196]\teval-rmse:4.44634\ttrain-rmse:2.36625\n",
      "[2197]\teval-rmse:4.44814\ttrain-rmse:2.36626\n",
      "[2198]\teval-rmse:4.44487\ttrain-rmse:2.36524\n",
      "[2199]\teval-rmse:4.44169\ttrain-rmse:2.36398\n",
      "[2200]\teval-rmse:4.43928\ttrain-rmse:2.36394\n",
      "[2201]\teval-rmse:4.43726\ttrain-rmse:2.36382\n",
      "[2202]\teval-rmse:4.43855\ttrain-rmse:2.36383\n",
      "[2203]\teval-rmse:4.43635\ttrain-rmse:2.3638\n",
      "[2204]\teval-rmse:4.43879\ttrain-rmse:2.3639\n",
      "[2205]\teval-rmse:4.44042\ttrain-rmse:2.36389\n",
      "[2206]\teval-rmse:4.44166\ttrain-rmse:2.3639\n",
      "[2207]\teval-rmse:4.44212\ttrain-rmse:2.36391\n",
      "[2208]\teval-rmse:4.44435\ttrain-rmse:2.36392\n",
      "[2209]\teval-rmse:4.44728\ttrain-rmse:2.36405\n",
      "[2210]\teval-rmse:4.44393\ttrain-rmse:2.36262\n",
      "[2211]\teval-rmse:4.44243\ttrain-rmse:2.36256\n",
      "[2212]\teval-rmse:4.44337\ttrain-rmse:2.36262\n",
      "[2213]\teval-rmse:4.44568\ttrain-rmse:2.3627\n",
      "[2214]\teval-rmse:4.4423\ttrain-rmse:2.36108\n",
      "[2215]\teval-rmse:4.44414\ttrain-rmse:2.36114\n",
      "[2216]\teval-rmse:4.44598\ttrain-rmse:2.36126\n",
      "[2217]\teval-rmse:4.44364\ttrain-rmse:2.36118\n",
      "[2218]\teval-rmse:4.44557\ttrain-rmse:2.36121\n",
      "[2219]\teval-rmse:4.44668\ttrain-rmse:2.3613\n",
      "[2220]\teval-rmse:4.44495\ttrain-rmse:2.36126\n",
      "[2221]\teval-rmse:4.44604\ttrain-rmse:2.36132\n",
      "[2222]\teval-rmse:4.44433\ttrain-rmse:2.36101\n",
      "[2223]\teval-rmse:4.4458\ttrain-rmse:2.36103\n",
      "[2224]\teval-rmse:4.44755\ttrain-rmse:2.36118\n",
      "[2225]\teval-rmse:4.44911\ttrain-rmse:2.3612\n",
      "[2226]\teval-rmse:4.44605\ttrain-rmse:2.36105\n",
      "[2227]\teval-rmse:4.44674\ttrain-rmse:2.36106\n",
      "[2228]\teval-rmse:4.44524\ttrain-rmse:2.361\n",
      "[2229]\teval-rmse:4.44445\ttrain-rmse:2.36094\n",
      "[2230]\teval-rmse:4.44244\ttrain-rmse:2.36035\n",
      "[2231]\teval-rmse:4.4386\ttrain-rmse:2.3602\n",
      "[2232]\teval-rmse:4.43672\ttrain-rmse:2.3599\n",
      "[2233]\teval-rmse:4.4384\ttrain-rmse:2.36001\n",
      "[2234]\teval-rmse:4.44108\ttrain-rmse:2.36013\n",
      "[2235]\teval-rmse:4.43889\ttrain-rmse:2.36007\n",
      "[2236]\teval-rmse:4.43569\ttrain-rmse:2.35889\n",
      "[2237]\teval-rmse:4.43194\ttrain-rmse:2.35876\n",
      "[2238]\teval-rmse:4.42894\ttrain-rmse:2.35866\n",
      "[2239]\teval-rmse:4.43121\ttrain-rmse:2.35867\n",
      "[2240]\teval-rmse:4.42912\ttrain-rmse:2.35859\n",
      "[2241]\teval-rmse:4.43179\ttrain-rmse:2.35866\n",
      "[2242]\teval-rmse:4.43459\ttrain-rmse:2.35878\n",
      "[2243]\teval-rmse:4.43051\ttrain-rmse:2.35871\n",
      "[2244]\teval-rmse:4.4314\ttrain-rmse:2.35876\n",
      "[2245]\teval-rmse:4.43332\ttrain-rmse:2.35881\n",
      "[2246]\teval-rmse:4.43283\ttrain-rmse:2.35878\n",
      "[2247]\teval-rmse:4.42935\ttrain-rmse:2.35864\n",
      "[2248]\teval-rmse:4.43101\ttrain-rmse:2.35868\n",
      "[2249]\teval-rmse:4.43335\ttrain-rmse:2.35869\n",
      "[2250]\teval-rmse:4.43081\ttrain-rmse:2.3586\n",
      "[2251]\teval-rmse:4.43362\ttrain-rmse:2.35862\n",
      "[2252]\teval-rmse:4.43032\ttrain-rmse:2.35704\n",
      "[2253]\teval-rmse:4.42627\ttrain-rmse:2.35699\n",
      "[2254]\teval-rmse:4.42414\ttrain-rmse:2.35689\n",
      "[2255]\teval-rmse:4.42715\ttrain-rmse:2.357\n",
      "[2256]\teval-rmse:4.42614\ttrain-rmse:2.35698\n",
      "[2257]\teval-rmse:4.42343\ttrain-rmse:2.35689\n",
      "[2258]\teval-rmse:4.42017\ttrain-rmse:2.35458\n",
      "[2259]\teval-rmse:4.41762\ttrain-rmse:2.35452\n",
      "[2260]\teval-rmse:4.41444\ttrain-rmse:2.3524\n",
      "[2261]\teval-rmse:4.41453\ttrain-rmse:2.3524\n",
      "[2262]\teval-rmse:4.41713\ttrain-rmse:2.3524\n",
      "[2263]\teval-rmse:4.42001\ttrain-rmse:2.35241\n",
      "[2264]\teval-rmse:4.41965\ttrain-rmse:2.35232\n",
      "[2265]\teval-rmse:4.41569\ttrain-rmse:2.35228\n",
      "[2266]\teval-rmse:4.41193\ttrain-rmse:2.35206\n",
      "[2267]\teval-rmse:4.41277\ttrain-rmse:2.35206\n",
      "[2268]\teval-rmse:4.41068\ttrain-rmse:2.35084\n",
      "[2269]\teval-rmse:4.40831\ttrain-rmse:2.35082\n",
      "[2270]\teval-rmse:4.4095\ttrain-rmse:2.35081\n",
      "[2271]\teval-rmse:4.41233\ttrain-rmse:2.3508\n",
      "[2272]\teval-rmse:4.41407\ttrain-rmse:2.35084\n",
      "[2273]\teval-rmse:4.41143\ttrain-rmse:2.35077\n",
      "[2274]\teval-rmse:4.4135\ttrain-rmse:2.35075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2275]\teval-rmse:4.41474\ttrain-rmse:2.35079\n",
      "[2276]\teval-rmse:4.41655\ttrain-rmse:2.35082\n",
      "[2277]\teval-rmse:4.41339\ttrain-rmse:2.34939\n",
      "[2278]\teval-rmse:4.41193\ttrain-rmse:2.34932\n",
      "[2279]\teval-rmse:4.41035\ttrain-rmse:2.3493\n",
      "[2280]\teval-rmse:4.40891\ttrain-rmse:2.34929\n",
      "[2281]\teval-rmse:4.41024\ttrain-rmse:2.34927\n",
      "[2282]\teval-rmse:4.40835\ttrain-rmse:2.34925\n",
      "[2283]\teval-rmse:4.40532\ttrain-rmse:2.3481\n",
      "[2284]\teval-rmse:4.40725\ttrain-rmse:2.34808\n",
      "[2285]\teval-rmse:4.4089\ttrain-rmse:2.3481\n",
      "[2286]\teval-rmse:4.41037\ttrain-rmse:2.34809\n",
      "[2287]\teval-rmse:4.41108\ttrain-rmse:2.34809\n",
      "[2288]\teval-rmse:4.40951\ttrain-rmse:2.34802\n",
      "[2289]\teval-rmse:4.40714\ttrain-rmse:2.34792\n",
      "[2290]\teval-rmse:4.4055\ttrain-rmse:2.34787\n",
      "[2291]\teval-rmse:4.40266\ttrain-rmse:2.34571\n",
      "[2292]\teval-rmse:4.39959\ttrain-rmse:2.3437\n",
      "[2293]\teval-rmse:4.40113\ttrain-rmse:2.34368\n",
      "[2294]\teval-rmse:4.39801\ttrain-rmse:2.34226\n",
      "[2295]\teval-rmse:4.39907\ttrain-rmse:2.34228\n",
      "[2296]\teval-rmse:4.39981\ttrain-rmse:2.34229\n",
      "[2297]\teval-rmse:4.39725\ttrain-rmse:2.34223\n",
      "[2298]\teval-rmse:4.39987\ttrain-rmse:2.3422\n",
      "[2299]\teval-rmse:4.39711\ttrain-rmse:2.34217\n",
      "[2300]\teval-rmse:4.40101\ttrain-rmse:2.34227\n",
      "[2301]\teval-rmse:4.40155\ttrain-rmse:2.34228\n",
      "[2302]\teval-rmse:4.39986\ttrain-rmse:2.34152\n",
      "[2303]\teval-rmse:4.40157\ttrain-rmse:2.34155\n",
      "[2304]\teval-rmse:4.40357\ttrain-rmse:2.34154\n",
      "[2305]\teval-rmse:4.40489\ttrain-rmse:2.34157\n",
      "[2306]\teval-rmse:4.40304\ttrain-rmse:2.34069\n",
      "[2307]\teval-rmse:4.40381\ttrain-rmse:2.34074\n",
      "[2308]\teval-rmse:4.40586\ttrain-rmse:2.34079\n",
      "[2309]\teval-rmse:4.40579\ttrain-rmse:2.34077\n",
      "[2310]\teval-rmse:4.40782\ttrain-rmse:2.34084\n",
      "[2311]\teval-rmse:4.41018\ttrain-rmse:2.34092\n",
      "[2312]\teval-rmse:4.40727\ttrain-rmse:2.34048\n",
      "[2313]\teval-rmse:4.40859\ttrain-rmse:2.34052\n",
      "[2314]\teval-rmse:4.41145\ttrain-rmse:2.34054\n",
      "[2315]\teval-rmse:4.41198\ttrain-rmse:2.34056\n",
      "[2316]\teval-rmse:4.41303\ttrain-rmse:2.34054\n",
      "[2317]\teval-rmse:4.41494\ttrain-rmse:2.34062\n",
      "[2318]\teval-rmse:4.41287\ttrain-rmse:2.34057\n",
      "[2319]\teval-rmse:4.40891\ttrain-rmse:2.34049\n",
      "[2320]\teval-rmse:4.40588\ttrain-rmse:2.33941\n",
      "[2321]\teval-rmse:4.40423\ttrain-rmse:2.33934\n",
      "[2322]\teval-rmse:4.40246\ttrain-rmse:2.33837\n",
      "[2323]\teval-rmse:4.40343\ttrain-rmse:2.3384\n",
      "[2324]\teval-rmse:4.40604\ttrain-rmse:2.33842\n",
      "[2325]\teval-rmse:4.40817\ttrain-rmse:2.33849\n",
      "[2326]\teval-rmse:4.40503\ttrain-rmse:2.33758\n",
      "[2327]\teval-rmse:4.40654\ttrain-rmse:2.33759\n",
      "[2328]\teval-rmse:4.40452\ttrain-rmse:2.33655\n",
      "[2329]\teval-rmse:4.40646\ttrain-rmse:2.33662\n",
      "[2330]\teval-rmse:4.40471\ttrain-rmse:2.33637\n",
      "[2331]\teval-rmse:4.40769\ttrain-rmse:2.33641\n",
      "[2332]\teval-rmse:4.41034\ttrain-rmse:2.33651\n",
      "[2333]\teval-rmse:4.40855\ttrain-rmse:2.33586\n",
      "[2334]\teval-rmse:4.40779\ttrain-rmse:2.33583\n",
      "[2335]\teval-rmse:4.40465\ttrain-rmse:2.3346\n",
      "[2336]\teval-rmse:4.40656\ttrain-rmse:2.33475\n",
      "[2337]\teval-rmse:4.40802\ttrain-rmse:2.33487\n",
      "[2338]\teval-rmse:4.40488\ttrain-rmse:2.33361\n",
      "[2339]\teval-rmse:4.40676\ttrain-rmse:2.33361\n",
      "[2340]\teval-rmse:4.40846\ttrain-rmse:2.33363\n",
      "[2341]\teval-rmse:4.41035\ttrain-rmse:2.33367\n",
      "[2342]\teval-rmse:4.40868\ttrain-rmse:2.33339\n",
      "[2343]\teval-rmse:4.40776\ttrain-rmse:2.33332\n",
      "[2344]\teval-rmse:4.40542\ttrain-rmse:2.33319\n",
      "[2345]\teval-rmse:4.40639\ttrain-rmse:2.33323\n",
      "[2346]\teval-rmse:4.40263\ttrain-rmse:2.33304\n",
      "[2347]\teval-rmse:4.40541\ttrain-rmse:2.33315\n",
      "[2348]\teval-rmse:4.40186\ttrain-rmse:2.33298\n",
      "[2349]\teval-rmse:4.3987\ttrain-rmse:2.33214\n",
      "[2350]\teval-rmse:4.39825\ttrain-rmse:2.33202\n",
      "[2351]\teval-rmse:4.39787\ttrain-rmse:2.33194\n",
      "[2352]\teval-rmse:4.40037\ttrain-rmse:2.33202\n",
      "[2353]\teval-rmse:4.40241\ttrain-rmse:2.3321\n",
      "[2354]\teval-rmse:4.39935\ttrain-rmse:2.33097\n",
      "[2355]\teval-rmse:4.40189\ttrain-rmse:2.33108\n",
      "[2356]\teval-rmse:4.39974\ttrain-rmse:2.33101\n",
      "[2357]\teval-rmse:4.40078\ttrain-rmse:2.33109\n",
      "[2358]\teval-rmse:4.40071\ttrain-rmse:2.33108\n",
      "[2359]\teval-rmse:4.40157\ttrain-rmse:2.33115\n",
      "[2360]\teval-rmse:4.39879\ttrain-rmse:2.32917\n",
      "[2361]\teval-rmse:4.39843\ttrain-rmse:2.32913\n",
      "[2362]\teval-rmse:4.39528\ttrain-rmse:2.32829\n",
      "[2363]\teval-rmse:4.39342\ttrain-rmse:2.32817\n",
      "[2364]\teval-rmse:4.39563\ttrain-rmse:2.32827\n",
      "[2365]\teval-rmse:4.39384\ttrain-rmse:2.3278\n",
      "[2366]\teval-rmse:4.39238\ttrain-rmse:2.32759\n",
      "[2367]\teval-rmse:4.38957\ttrain-rmse:2.32635\n",
      "[2368]\teval-rmse:4.39086\ttrain-rmse:2.3264\n",
      "[2369]\teval-rmse:4.39328\ttrain-rmse:2.32641\n",
      "[2370]\teval-rmse:4.39239\ttrain-rmse:2.32637\n",
      "[2371]\teval-rmse:4.395\ttrain-rmse:2.32649\n",
      "[2372]\teval-rmse:4.39222\ttrain-rmse:2.32634\n",
      "[2373]\teval-rmse:4.39186\ttrain-rmse:2.32631\n",
      "[2374]\teval-rmse:4.39299\ttrain-rmse:2.32636\n",
      "[2375]\teval-rmse:4.39119\ttrain-rmse:2.32573\n",
      "[2376]\teval-rmse:4.39042\ttrain-rmse:2.32569\n",
      "[2377]\teval-rmse:4.38784\ttrain-rmse:2.32557\n",
      "[2378]\teval-rmse:4.38623\ttrain-rmse:2.32551\n",
      "[2379]\teval-rmse:4.3865\ttrain-rmse:2.32549\n",
      "[2380]\teval-rmse:4.38247\ttrain-rmse:2.32534\n",
      "[2381]\teval-rmse:4.38062\ttrain-rmse:2.3248\n",
      "[2382]\teval-rmse:4.38312\ttrain-rmse:2.32497\n",
      "[2383]\teval-rmse:4.38571\ttrain-rmse:2.32504\n",
      "[2384]\teval-rmse:4.38867\ttrain-rmse:2.32504\n",
      "[2385]\teval-rmse:4.39063\ttrain-rmse:2.32517\n",
      "[2386]\teval-rmse:4.38754\ttrain-rmse:2.32307\n",
      "[2387]\teval-rmse:4.38582\ttrain-rmse:2.32249\n",
      "[2388]\teval-rmse:4.38805\ttrain-rmse:2.32268\n",
      "[2389]\teval-rmse:4.38582\ttrain-rmse:2.32261\n",
      "[2390]\teval-rmse:4.38412\ttrain-rmse:2.32255\n",
      "[2391]\teval-rmse:4.3821\ttrain-rmse:2.32249\n",
      "[2392]\teval-rmse:4.384\ttrain-rmse:2.32251\n",
      "[2393]\teval-rmse:4.38557\ttrain-rmse:2.32253\n",
      "[2394]\teval-rmse:4.3874\ttrain-rmse:2.32265\n",
      "[2395]\teval-rmse:4.3846\ttrain-rmse:2.32229\n",
      "[2396]\teval-rmse:4.387\ttrain-rmse:2.32235\n",
      "[2397]\teval-rmse:4.3847\ttrain-rmse:2.32226\n",
      "[2398]\teval-rmse:4.38662\ttrain-rmse:2.32231\n",
      "[2399]\teval-rmse:4.38485\ttrain-rmse:2.32156\n",
      "[2400]\teval-rmse:4.38327\ttrain-rmse:2.32149\n",
      "[2401]\teval-rmse:4.38522\ttrain-rmse:2.32158\n",
      "[2402]\teval-rmse:4.38226\ttrain-rmse:2.32049\n",
      "[2403]\teval-rmse:4.37977\ttrain-rmse:2.32044\n",
      "[2404]\teval-rmse:4.38163\ttrain-rmse:2.32057\n",
      "[2405]\teval-rmse:4.38018\ttrain-rmse:2.32048\n",
      "[2406]\teval-rmse:4.3783\ttrain-rmse:2.31979\n",
      "[2407]\teval-rmse:4.37533\ttrain-rmse:2.31801\n",
      "[2408]\teval-rmse:4.37371\ttrain-rmse:2.31735\n",
      "[2409]\teval-rmse:4.37393\ttrain-rmse:2.31734\n",
      "[2410]\teval-rmse:4.37118\ttrain-rmse:2.31721\n",
      "[2411]\teval-rmse:4.37079\ttrain-rmse:2.31717\n",
      "[2412]\teval-rmse:4.36747\ttrain-rmse:2.31704\n",
      "[2413]\teval-rmse:4.36986\ttrain-rmse:2.31703\n",
      "[2414]\teval-rmse:4.372\ttrain-rmse:2.3171\n",
      "[2415]\teval-rmse:4.36837\ttrain-rmse:2.31696\n",
      "[2416]\teval-rmse:4.36553\ttrain-rmse:2.31549\n",
      "[2417]\teval-rmse:4.36385\ttrain-rmse:2.31485\n",
      "[2418]\teval-rmse:4.36646\ttrain-rmse:2.31489\n",
      "[2419]\teval-rmse:4.3694\ttrain-rmse:2.31488\n",
      "[2420]\teval-rmse:4.36652\ttrain-rmse:2.31384\n",
      "[2421]\teval-rmse:4.36684\ttrain-rmse:2.31386\n",
      "[2422]\teval-rmse:4.36804\ttrain-rmse:2.31385\n",
      "[2423]\teval-rmse:4.36533\ttrain-rmse:2.31374\n",
      "[2424]\teval-rmse:4.36704\ttrain-rmse:2.3138\n",
      "[2425]\teval-rmse:4.36831\ttrain-rmse:2.31391\n",
      "[2426]\teval-rmse:4.36793\ttrain-rmse:2.31388\n",
      "[2427]\teval-rmse:4.37164\ttrain-rmse:2.31397\n",
      "[2428]\teval-rmse:4.36862\ttrain-rmse:2.31321\n",
      "[2429]\teval-rmse:4.37147\ttrain-rmse:2.31322\n",
      "[2430]\teval-rmse:4.37292\ttrain-rmse:2.31327\n",
      "[2431]\teval-rmse:4.37384\ttrain-rmse:2.31331\n",
      "[2432]\teval-rmse:4.37678\ttrain-rmse:2.31341\n",
      "[2433]\teval-rmse:4.37929\ttrain-rmse:2.31343\n",
      "[2434]\teval-rmse:4.37892\ttrain-rmse:2.3134\n",
      "[2435]\teval-rmse:4.38042\ttrain-rmse:2.31385\n",
      "[2436]\teval-rmse:4.38167\ttrain-rmse:2.31385\n",
      "[2437]\teval-rmse:4.38006\ttrain-rmse:2.31379\n",
      "[2438]\teval-rmse:4.3807\ttrain-rmse:2.31383\n",
      "[2439]\teval-rmse:4.37779\ttrain-rmse:2.31277\n",
      "[2440]\teval-rmse:4.37613\ttrain-rmse:2.31254\n",
      "[2441]\teval-rmse:4.3786\ttrain-rmse:2.31256\n",
      "[2442]\teval-rmse:4.37563\ttrain-rmse:2.31175\n",
      "[2443]\teval-rmse:4.37214\ttrain-rmse:2.3115\n",
      "[2444]\teval-rmse:4.37023\ttrain-rmse:2.31143\n",
      "[2445]\teval-rmse:4.37121\ttrain-rmse:2.31147\n",
      "[2446]\teval-rmse:4.36891\ttrain-rmse:2.3114\n",
      "[2447]\teval-rmse:4.3662\ttrain-rmse:2.31038\n",
      "[2448]\teval-rmse:4.36263\ttrain-rmse:2.3101\n",
      "[2449]\teval-rmse:4.36011\ttrain-rmse:2.31\n",
      "[2450]\teval-rmse:4.35823\ttrain-rmse:2.30995\n",
      "[2451]\teval-rmse:4.35507\ttrain-rmse:2.30985\n",
      "[2452]\teval-rmse:4.35575\ttrain-rmse:2.30988\n",
      "[2453]\teval-rmse:4.35297\ttrain-rmse:2.30891\n",
      "[2454]\teval-rmse:4.35529\ttrain-rmse:2.30894\n",
      "[2455]\teval-rmse:4.35351\ttrain-rmse:2.30889\n",
      "[2456]\teval-rmse:4.35649\ttrain-rmse:2.30892\n",
      "[2457]\teval-rmse:4.35627\ttrain-rmse:2.30886\n",
      "[2458]\teval-rmse:4.3574\ttrain-rmse:2.30888\n",
      "[2459]\teval-rmse:4.35891\ttrain-rmse:2.30886\n",
      "[2460]\teval-rmse:4.3615\ttrain-rmse:2.30893\n",
      "[2461]\teval-rmse:4.36317\ttrain-rmse:2.30894\n",
      "[2462]\teval-rmse:4.35993\ttrain-rmse:2.30885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2463]\teval-rmse:4.35727\ttrain-rmse:2.30876\n",
      "[2464]\teval-rmse:4.3576\ttrain-rmse:2.30876\n",
      "[2465]\teval-rmse:4.36025\ttrain-rmse:2.30877\n",
      "[2466]\teval-rmse:4.3611\ttrain-rmse:2.30879\n",
      "[2467]\teval-rmse:4.35838\ttrain-rmse:2.30779\n",
      "[2468]\teval-rmse:4.35945\ttrain-rmse:2.30783\n",
      "[2469]\teval-rmse:4.35658\ttrain-rmse:2.3069\n",
      "[2470]\teval-rmse:4.35949\ttrain-rmse:2.30691\n",
      "[2471]\teval-rmse:4.35751\ttrain-rmse:2.30686\n",
      "[2472]\teval-rmse:4.3531\ttrain-rmse:2.30658\n",
      "[2473]\teval-rmse:4.35492\ttrain-rmse:2.30664\n",
      "[2474]\teval-rmse:4.35358\ttrain-rmse:2.30663\n",
      "[2475]\teval-rmse:4.35512\ttrain-rmse:2.30672\n",
      "[2476]\teval-rmse:4.35632\ttrain-rmse:2.30676\n",
      "[2477]\teval-rmse:4.35999\ttrain-rmse:2.30676\n",
      "[2478]\teval-rmse:4.35826\ttrain-rmse:2.30632\n",
      "[2479]\teval-rmse:4.35542\ttrain-rmse:2.30482\n",
      "[2480]\teval-rmse:4.35822\ttrain-rmse:2.30488\n",
      "[2481]\teval-rmse:4.35679\ttrain-rmse:2.30483\n",
      "[2482]\teval-rmse:4.35631\ttrain-rmse:2.3048\n",
      "[2483]\teval-rmse:4.3556\ttrain-rmse:2.30477\n",
      "[2484]\teval-rmse:4.35514\ttrain-rmse:2.30475\n",
      "[2485]\teval-rmse:4.35351\ttrain-rmse:2.30471\n",
      "[2486]\teval-rmse:4.35568\ttrain-rmse:2.30469\n",
      "[2487]\teval-rmse:4.35301\ttrain-rmse:2.30458\n",
      "[2488]\teval-rmse:4.35125\ttrain-rmse:2.30414\n",
      "[2489]\teval-rmse:4.35255\ttrain-rmse:2.30416\n",
      "[2490]\teval-rmse:4.35455\ttrain-rmse:2.30415\n",
      "[2491]\teval-rmse:4.35653\ttrain-rmse:2.30428\n",
      "[2492]\teval-rmse:4.35442\ttrain-rmse:2.30421\n",
      "[2493]\teval-rmse:4.35367\ttrain-rmse:2.30417\n",
      "[2494]\teval-rmse:4.35443\ttrain-rmse:2.30419\n",
      "[2495]\teval-rmse:4.35705\ttrain-rmse:2.30428\n",
      "[2496]\teval-rmse:4.35309\ttrain-rmse:2.30413\n",
      "[2497]\teval-rmse:4.35489\ttrain-rmse:2.30416\n",
      "[2498]\teval-rmse:4.35754\ttrain-rmse:2.30426\n",
      "[2499]\teval-rmse:4.35472\ttrain-rmse:2.30414\n",
      "[2500]\teval-rmse:4.35732\ttrain-rmse:2.3042\n",
      "[2501]\teval-rmse:4.35823\ttrain-rmse:2.30427\n",
      "[2502]\teval-rmse:4.35606\ttrain-rmse:2.3042\n",
      "[2503]\teval-rmse:4.35789\ttrain-rmse:2.30419\n",
      "[2504]\teval-rmse:4.3571\ttrain-rmse:2.30414\n",
      "[2505]\teval-rmse:4.35435\ttrain-rmse:2.30271\n",
      "[2506]\teval-rmse:4.35154\ttrain-rmse:2.3026\n",
      "[2507]\teval-rmse:4.34902\ttrain-rmse:2.30251\n",
      "[2508]\teval-rmse:4.34598\ttrain-rmse:2.30242\n",
      "[2509]\teval-rmse:4.3489\ttrain-rmse:2.30246\n",
      "[2510]\teval-rmse:4.34969\ttrain-rmse:2.30247\n",
      "[2511]\teval-rmse:4.35244\ttrain-rmse:2.30247\n",
      "[2512]\teval-rmse:4.35006\ttrain-rmse:2.30239\n",
      "[2513]\teval-rmse:4.35184\ttrain-rmse:2.30249\n",
      "[2514]\teval-rmse:4.35031\ttrain-rmse:2.30228\n",
      "[2515]\teval-rmse:4.35211\ttrain-rmse:2.30227\n",
      "[2516]\teval-rmse:4.35046\ttrain-rmse:2.30157\n",
      "[2517]\teval-rmse:4.35265\ttrain-rmse:2.3017\n",
      "[2518]\teval-rmse:4.34975\ttrain-rmse:2.30167\n",
      "[2519]\teval-rmse:4.34898\ttrain-rmse:2.30163\n",
      "[2520]\teval-rmse:4.35052\ttrain-rmse:2.30166\n",
      "[2521]\teval-rmse:4.34915\ttrain-rmse:2.30161\n",
      "[2522]\teval-rmse:4.3479\ttrain-rmse:2.30154\n",
      "[2523]\teval-rmse:4.3507\ttrain-rmse:2.30158\n",
      "[2524]\teval-rmse:4.34905\ttrain-rmse:2.30119\n",
      "[2525]\teval-rmse:4.3527\ttrain-rmse:2.30125\n",
      "[2526]\teval-rmse:4.35389\ttrain-rmse:2.30132\n",
      "[2527]\teval-rmse:4.35105\ttrain-rmse:2.30017\n",
      "[2528]\teval-rmse:4.35292\ttrain-rmse:2.3003\n",
      "[2529]\teval-rmse:4.35345\ttrain-rmse:2.30031\n",
      "[2530]\teval-rmse:4.35528\ttrain-rmse:2.30037\n",
      "[2531]\teval-rmse:4.35771\ttrain-rmse:2.30044\n",
      "[2532]\teval-rmse:4.35618\ttrain-rmse:2.30038\n",
      "[2533]\teval-rmse:4.35449\ttrain-rmse:2.2998\n",
      "[2534]\teval-rmse:4.35241\ttrain-rmse:2.29976\n",
      "[2535]\teval-rmse:4.35471\ttrain-rmse:2.29975\n",
      "[2536]\teval-rmse:4.35257\ttrain-rmse:2.29972\n",
      "[2537]\teval-rmse:4.35001\ttrain-rmse:2.29962\n",
      "[2538]\teval-rmse:4.34869\ttrain-rmse:2.29957\n",
      "[2539]\teval-rmse:4.3504\ttrain-rmse:2.29959\n",
      "[2540]\teval-rmse:4.34767\ttrain-rmse:2.29954\n",
      "[2541]\teval-rmse:4.34465\ttrain-rmse:2.2995\n",
      "[2542]\teval-rmse:4.3465\ttrain-rmse:2.29953\n",
      "[2543]\teval-rmse:4.34683\ttrain-rmse:2.29955\n",
      "[2544]\teval-rmse:4.34911\ttrain-rmse:2.29954\n",
      "[2545]\teval-rmse:4.35023\ttrain-rmse:2.29952\n",
      "[2546]\teval-rmse:4.34884\ttrain-rmse:2.29943\n",
      "[2547]\teval-rmse:4.34723\ttrain-rmse:2.29941\n",
      "[2548]\teval-rmse:4.34433\ttrain-rmse:2.29829\n",
      "[2549]\teval-rmse:4.34487\ttrain-rmse:2.2983\n",
      "[2550]\teval-rmse:4.34678\ttrain-rmse:2.29833\n",
      "[2551]\teval-rmse:4.34752\ttrain-rmse:2.29835\n",
      "[2552]\teval-rmse:4.3434\ttrain-rmse:2.29811\n",
      "[2553]\teval-rmse:4.34182\ttrain-rmse:2.29773\n",
      "[2554]\teval-rmse:4.33988\ttrain-rmse:2.2977\n",
      "[2555]\teval-rmse:4.33707\ttrain-rmse:2.29653\n",
      "[2556]\teval-rmse:4.3355\ttrain-rmse:2.29653\n",
      "[2557]\teval-rmse:4.33279\ttrain-rmse:2.29647\n",
      "[2558]\teval-rmse:4.33157\ttrain-rmse:2.29647\n",
      "[2559]\teval-rmse:4.33081\ttrain-rmse:2.29643\n",
      "[2560]\teval-rmse:4.3329\ttrain-rmse:2.29646\n",
      "[2561]\teval-rmse:4.3287\ttrain-rmse:2.29627\n",
      "[2562]\teval-rmse:4.32593\ttrain-rmse:2.29624\n",
      "[2563]\teval-rmse:4.32534\ttrain-rmse:2.29622\n",
      "[2564]\teval-rmse:4.32818\ttrain-rmse:2.29617\n",
      "[2565]\teval-rmse:4.32974\ttrain-rmse:2.29667\n",
      "[2566]\teval-rmse:4.32866\ttrain-rmse:2.29663\n",
      "[2567]\teval-rmse:4.33009\ttrain-rmse:2.29669\n",
      "[2568]\teval-rmse:4.32874\ttrain-rmse:2.29654\n",
      "[2569]\teval-rmse:4.32606\ttrain-rmse:2.29585\n",
      "[2570]\teval-rmse:4.32335\ttrain-rmse:2.29394\n",
      "[2571]\teval-rmse:4.32521\ttrain-rmse:2.29391\n",
      "[2572]\teval-rmse:4.32367\ttrain-rmse:2.29392\n",
      "[2573]\teval-rmse:4.32105\ttrain-rmse:2.29389\n",
      "[2574]\teval-rmse:4.32303\ttrain-rmse:2.29397\n",
      "[2575]\teval-rmse:4.31942\ttrain-rmse:2.29403\n",
      "[2576]\teval-rmse:4.32054\ttrain-rmse:2.29402\n",
      "[2577]\teval-rmse:4.31775\ttrain-rmse:2.29296\n",
      "[2578]\teval-rmse:4.32047\ttrain-rmse:2.29306\n",
      "[2579]\teval-rmse:4.31769\ttrain-rmse:2.29303\n",
      "[2580]\teval-rmse:4.31915\ttrain-rmse:2.29304\n",
      "[2581]\teval-rmse:4.32031\ttrain-rmse:2.29304\n",
      "[2582]\teval-rmse:4.31858\ttrain-rmse:2.29306\n",
      "[2583]\teval-rmse:4.31961\ttrain-rmse:2.29306\n",
      "[2584]\teval-rmse:4.31769\ttrain-rmse:2.29306\n",
      "[2585]\teval-rmse:4.32055\ttrain-rmse:2.29299\n",
      "[2586]\teval-rmse:4.31855\ttrain-rmse:2.293\n",
      "[2587]\teval-rmse:4.31724\ttrain-rmse:2.29299\n",
      "[2588]\teval-rmse:4.31688\ttrain-rmse:2.29297\n",
      "[2589]\teval-rmse:4.31921\ttrain-rmse:2.2929\n",
      "[2590]\teval-rmse:4.321\ttrain-rmse:2.29289\n",
      "[2591]\teval-rmse:4.32387\ttrain-rmse:2.29285\n",
      "[2592]\teval-rmse:4.32633\ttrain-rmse:2.2928\n",
      "[2593]\teval-rmse:4.32362\ttrain-rmse:2.29214\n",
      "[2594]\teval-rmse:4.3217\ttrain-rmse:2.29216\n",
      "[2595]\teval-rmse:4.32428\ttrain-rmse:2.29219\n",
      "[2596]\teval-rmse:4.32173\ttrain-rmse:2.29192\n",
      "[2597]\teval-rmse:4.31876\ttrain-rmse:2.29189\n",
      "[2598]\teval-rmse:4.32061\ttrain-rmse:2.29188\n",
      "[2599]\teval-rmse:4.31859\ttrain-rmse:2.29187\n",
      "[2600]\teval-rmse:4.31709\ttrain-rmse:2.29121\n",
      "[2601]\teval-rmse:4.31811\ttrain-rmse:2.29122\n",
      "[2602]\teval-rmse:4.32067\ttrain-rmse:2.29117\n",
      "[2603]\teval-rmse:4.31888\ttrain-rmse:2.29117\n",
      "[2604]\teval-rmse:4.32072\ttrain-rmse:2.29119\n",
      "[2605]\teval-rmse:4.3224\ttrain-rmse:2.29116\n",
      "[2606]\teval-rmse:4.32228\ttrain-rmse:2.29115\n",
      "[2607]\teval-rmse:4.3239\ttrain-rmse:2.29123\n",
      "[2608]\teval-rmse:4.32538\ttrain-rmse:2.29125\n",
      "[2609]\teval-rmse:4.32376\ttrain-rmse:2.29083\n",
      "[2610]\teval-rmse:4.32627\ttrain-rmse:2.29085\n",
      "[2611]\teval-rmse:4.32352\ttrain-rmse:2.28971\n",
      "[2612]\teval-rmse:4.32637\ttrain-rmse:2.28973\n",
      "[2613]\teval-rmse:4.32501\ttrain-rmse:2.28956\n",
      "[2614]\teval-rmse:4.32294\ttrain-rmse:2.28957\n",
      "[2615]\teval-rmse:4.32215\ttrain-rmse:2.28955\n",
      "[2616]\teval-rmse:4.32065\ttrain-rmse:2.28938\n",
      "[2617]\teval-rmse:4.32202\ttrain-rmse:2.28941\n",
      "[2618]\teval-rmse:4.31947\ttrain-rmse:2.28936\n",
      "[2619]\teval-rmse:4.32232\ttrain-rmse:2.28936\n",
      "[2620]\teval-rmse:4.31971\ttrain-rmse:2.28934\n",
      "[2621]\teval-rmse:4.32158\ttrain-rmse:2.28937\n",
      "[2622]\teval-rmse:4.32245\ttrain-rmse:2.28941\n",
      "[2623]\teval-rmse:4.32055\ttrain-rmse:2.28941\n",
      "[2624]\teval-rmse:4.32315\ttrain-rmse:2.28936\n",
      "[2625]\teval-rmse:4.32377\ttrain-rmse:2.28938\n",
      "[2626]\teval-rmse:4.3241\ttrain-rmse:2.28938\n",
      "[2627]\teval-rmse:4.32161\ttrain-rmse:2.28836\n",
      "[2628]\teval-rmse:4.31949\ttrain-rmse:2.28831\n",
      "[2629]\teval-rmse:4.318\ttrain-rmse:2.28831\n",
      "[2630]\teval-rmse:4.31879\ttrain-rmse:2.28831\n",
      "[2631]\teval-rmse:4.3201\ttrain-rmse:2.28828\n",
      "[2632]\teval-rmse:4.32113\ttrain-rmse:2.2883\n",
      "[2633]\teval-rmse:4.32294\ttrain-rmse:2.28839\n",
      "[2634]\teval-rmse:4.32438\ttrain-rmse:2.28835\n",
      "[2635]\teval-rmse:4.3273\ttrain-rmse:2.28832\n",
      "[2636]\teval-rmse:4.32408\ttrain-rmse:2.28823\n",
      "[2637]\teval-rmse:4.32548\ttrain-rmse:2.2882\n",
      "[2638]\teval-rmse:4.32612\ttrain-rmse:2.28821\n",
      "[2639]\teval-rmse:4.32457\ttrain-rmse:2.28819\n",
      "[2640]\teval-rmse:4.32376\ttrain-rmse:2.28818\n",
      "[2641]\teval-rmse:4.3211\ttrain-rmse:2.28744\n",
      "[2642]\teval-rmse:4.32218\ttrain-rmse:2.2875\n",
      "[2643]\teval-rmse:4.32278\ttrain-rmse:2.28753\n",
      "[2644]\teval-rmse:4.32015\ttrain-rmse:2.2875\n",
      "[2645]\teval-rmse:4.32206\ttrain-rmse:2.28755\n",
      "[2646]\teval-rmse:4.3189\ttrain-rmse:2.28746\n",
      "[2647]\teval-rmse:4.32092\ttrain-rmse:2.28743\n",
      "[2648]\teval-rmse:4.31837\ttrain-rmse:2.28718\n",
      "[2649]\teval-rmse:4.31687\ttrain-rmse:2.28702\n",
      "[2650]\teval-rmse:4.31483\ttrain-rmse:2.28698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2651]\teval-rmse:4.31209\ttrain-rmse:2.28589\n",
      "[2652]\teval-rmse:4.31137\ttrain-rmse:2.28586\n",
      "[2653]\teval-rmse:4.30881\ttrain-rmse:2.28512\n",
      "[2654]\teval-rmse:4.30618\ttrain-rmse:2.28451\n",
      "[2655]\teval-rmse:4.30751\ttrain-rmse:2.28451\n",
      "[2656]\teval-rmse:4.30992\ttrain-rmse:2.28449\n",
      "[2657]\teval-rmse:4.30747\ttrain-rmse:2.28451\n",
      "[2658]\teval-rmse:4.30527\ttrain-rmse:2.28447\n",
      "[2659]\teval-rmse:4.3036\ttrain-rmse:2.28448\n",
      "[2660]\teval-rmse:4.30534\ttrain-rmse:2.28449\n",
      "[2661]\teval-rmse:4.30362\ttrain-rmse:2.2845\n",
      "[2662]\teval-rmse:4.30453\ttrain-rmse:2.28454\n",
      "[2663]\teval-rmse:4.30312\ttrain-rmse:2.28453\n",
      "[2664]\teval-rmse:4.30022\ttrain-rmse:2.28443\n",
      "[2665]\teval-rmse:4.29754\ttrain-rmse:2.28441\n",
      "[2666]\teval-rmse:4.29728\ttrain-rmse:2.2844\n",
      "[2667]\teval-rmse:4.29437\ttrain-rmse:2.28441\n",
      "[2668]\teval-rmse:4.29624\ttrain-rmse:2.28432\n",
      "[2669]\teval-rmse:4.29887\ttrain-rmse:2.28423\n",
      "[2670]\teval-rmse:4.29976\ttrain-rmse:2.28426\n",
      "[2671]\teval-rmse:4.29786\ttrain-rmse:2.28425\n",
      "[2672]\teval-rmse:4.29655\ttrain-rmse:2.28414\n",
      "[2673]\teval-rmse:4.29907\ttrain-rmse:2.28406\n",
      "[2674]\teval-rmse:4.29775\ttrain-rmse:2.28347\n",
      "[2675]\teval-rmse:4.29472\ttrain-rmse:2.28351\n",
      "[2676]\teval-rmse:4.29643\ttrain-rmse:2.28398\n",
      "[2677]\teval-rmse:4.29235\ttrain-rmse:2.28386\n",
      "[2678]\teval-rmse:4.29495\ttrain-rmse:2.28374\n",
      "[2679]\teval-rmse:4.2938\ttrain-rmse:2.28375\n",
      "[2680]\teval-rmse:4.2953\ttrain-rmse:2.28373\n",
      "[2681]\teval-rmse:4.29729\ttrain-rmse:2.2837\n",
      "[2682]\teval-rmse:4.29476\ttrain-rmse:2.28221\n",
      "[2683]\teval-rmse:4.29302\ttrain-rmse:2.28225\n",
      "[2684]\teval-rmse:4.29485\ttrain-rmse:2.28224\n",
      "[2685]\teval-rmse:4.2924\ttrain-rmse:2.28138\n",
      "[2686]\teval-rmse:4.29341\ttrain-rmse:2.28137\n",
      "[2687]\teval-rmse:4.29523\ttrain-rmse:2.2813\n",
      "[2688]\teval-rmse:4.29573\ttrain-rmse:2.28131\n",
      "[2689]\teval-rmse:4.29228\ttrain-rmse:2.28139\n",
      "[2690]\teval-rmse:4.28822\ttrain-rmse:2.28131\n",
      "[2691]\teval-rmse:4.286\ttrain-rmse:2.28138\n",
      "[2692]\teval-rmse:4.28611\ttrain-rmse:2.28137\n",
      "[2693]\teval-rmse:4.2837\ttrain-rmse:2.28069\n",
      "[2694]\teval-rmse:4.28632\ttrain-rmse:2.28057\n",
      "[2695]\teval-rmse:4.28483\ttrain-rmse:2.28028\n",
      "[2696]\teval-rmse:4.2848\ttrain-rmse:2.28028\n",
      "[2697]\teval-rmse:4.28646\ttrain-rmse:2.28025\n",
      "[2698]\teval-rmse:4.28885\ttrain-rmse:2.28032\n",
      "[2699]\teval-rmse:4.29026\ttrain-rmse:2.28031\n",
      "[2700]\teval-rmse:4.28909\ttrain-rmse:2.28029\n",
      "[2701]\teval-rmse:4.28571\ttrain-rmse:2.28031\n",
      "[2702]\teval-rmse:4.28329\ttrain-rmse:2.28026\n",
      "[2703]\teval-rmse:4.28526\ttrain-rmse:2.28022\n",
      "[2704]\teval-rmse:4.28615\ttrain-rmse:2.28017\n",
      "[2705]\teval-rmse:4.28887\ttrain-rmse:2.28022\n",
      "[2706]\teval-rmse:4.28658\ttrain-rmse:2.27929\n",
      "[2707]\teval-rmse:4.28742\ttrain-rmse:2.27928\n",
      "[2708]\teval-rmse:4.28681\ttrain-rmse:2.27926\n",
      "[2709]\teval-rmse:4.28816\ttrain-rmse:2.27925\n",
      "[2710]\teval-rmse:4.28944\ttrain-rmse:2.27923\n",
      "[2711]\teval-rmse:4.29201\ttrain-rmse:2.27918\n",
      "[2712]\teval-rmse:4.29044\ttrain-rmse:2.27922\n",
      "[2713]\teval-rmse:4.29194\ttrain-rmse:2.27917\n",
      "[2714]\teval-rmse:4.2928\ttrain-rmse:2.27913\n",
      "[2715]\teval-rmse:4.28999\ttrain-rmse:2.27913\n",
      "[2716]\teval-rmse:4.28714\ttrain-rmse:2.27913\n",
      "[2717]\teval-rmse:4.28514\ttrain-rmse:2.27919\n",
      "[2718]\teval-rmse:4.28254\ttrain-rmse:2.27848\n",
      "[2719]\teval-rmse:4.28361\ttrain-rmse:2.27846\n",
      "[2720]\teval-rmse:4.28561\ttrain-rmse:2.27837\n",
      "[2721]\teval-rmse:4.28367\ttrain-rmse:2.2784\n",
      "[2722]\teval-rmse:4.28553\ttrain-rmse:2.27838\n",
      "[2723]\teval-rmse:4.28307\ttrain-rmse:2.27755\n",
      "[2724]\teval-rmse:4.28208\ttrain-rmse:2.27753\n",
      "[2725]\teval-rmse:4.28333\ttrain-rmse:2.27751\n",
      "[2726]\teval-rmse:4.28372\ttrain-rmse:2.2775\n",
      "[2727]\teval-rmse:4.28108\ttrain-rmse:2.27746\n",
      "[2728]\teval-rmse:4.28347\ttrain-rmse:2.27736\n",
      "[2729]\teval-rmse:4.28199\ttrain-rmse:2.27738\n",
      "[2730]\teval-rmse:4.28296\ttrain-rmse:2.2774\n",
      "[2731]\teval-rmse:4.28058\ttrain-rmse:2.27746\n",
      "[2732]\teval-rmse:4.28083\ttrain-rmse:2.27745\n",
      "[2733]\teval-rmse:4.27839\ttrain-rmse:2.2761\n",
      "[2734]\teval-rmse:4.28044\ttrain-rmse:2.27608\n",
      "[2735]\teval-rmse:4.28282\ttrain-rmse:2.27603\n",
      "[2736]\teval-rmse:4.28135\ttrain-rmse:2.27527\n",
      "[2737]\teval-rmse:4.28399\ttrain-rmse:2.27526\n",
      "[2738]\teval-rmse:4.28257\ttrain-rmse:2.27527\n",
      "[2739]\teval-rmse:4.28118\ttrain-rmse:2.27529\n",
      "[2740]\teval-rmse:4.28378\ttrain-rmse:2.27524\n",
      "[2741]\teval-rmse:4.2804\ttrain-rmse:2.27524\n",
      "[2742]\teval-rmse:4.27868\ttrain-rmse:2.27528\n",
      "[2743]\teval-rmse:4.27588\ttrain-rmse:2.27531\n",
      "[2744]\teval-rmse:4.27669\ttrain-rmse:2.2753\n",
      "[2745]\teval-rmse:4.27701\ttrain-rmse:2.27528\n",
      "[2746]\teval-rmse:4.27933\ttrain-rmse:2.27516\n",
      "[2747]\teval-rmse:4.27588\ttrain-rmse:2.27528\n",
      "[2748]\teval-rmse:4.2773\ttrain-rmse:2.27521\n",
      "[2749]\teval-rmse:4.27717\ttrain-rmse:2.27519\n",
      "[2750]\teval-rmse:4.27585\ttrain-rmse:2.27521\n",
      "[2751]\teval-rmse:4.2761\ttrain-rmse:2.27518\n",
      "[2752]\teval-rmse:4.27339\ttrain-rmse:2.27527\n",
      "[2753]\teval-rmse:4.27202\ttrain-rmse:2.27498\n",
      "[2754]\teval-rmse:4.27467\ttrain-rmse:2.27494\n",
      "[2755]\teval-rmse:4.27664\ttrain-rmse:2.27484\n",
      "[2756]\teval-rmse:4.27857\ttrain-rmse:2.27482\n",
      "[2757]\teval-rmse:4.2774\ttrain-rmse:2.27471\n",
      "[2758]\teval-rmse:4.27815\ttrain-rmse:2.27467\n",
      "[2759]\teval-rmse:4.27684\ttrain-rmse:2.27468\n",
      "[2760]\teval-rmse:4.27437\ttrain-rmse:2.27312\n",
      "[2761]\teval-rmse:4.27481\ttrain-rmse:2.27312\n",
      "[2762]\teval-rmse:4.27233\ttrain-rmse:2.27242\n",
      "[2763]\teval-rmse:4.27413\ttrain-rmse:2.27241\n",
      "[2764]\teval-rmse:4.27275\ttrain-rmse:2.27195\n",
      "[2765]\teval-rmse:4.27522\ttrain-rmse:2.27185\n",
      "[2766]\teval-rmse:4.2734\ttrain-rmse:2.27189\n",
      "[2767]\teval-rmse:4.27045\ttrain-rmse:2.27199\n",
      "[2768]\teval-rmse:4.26915\ttrain-rmse:2.27147\n",
      "[2769]\teval-rmse:4.26622\ttrain-rmse:2.27158\n",
      "[2770]\teval-rmse:4.26396\ttrain-rmse:2.27081\n",
      "[2771]\teval-rmse:4.26167\ttrain-rmse:2.27011\n",
      "[2772]\teval-rmse:4.26056\ttrain-rmse:2.26964\n",
      "[2773]\teval-rmse:4.25952\ttrain-rmse:2.26905\n",
      "[2774]\teval-rmse:4.25984\ttrain-rmse:2.26906\n",
      "[2775]\teval-rmse:4.25737\ttrain-rmse:2.26909\n",
      "[2776]\teval-rmse:4.25774\ttrain-rmse:2.26905\n",
      "[2777]\teval-rmse:4.26071\ttrain-rmse:2.2689\n",
      "[2778]\teval-rmse:4.26153\ttrain-rmse:2.26889\n",
      "[2779]\teval-rmse:4.26225\ttrain-rmse:2.2689\n",
      "[2780]\teval-rmse:4.25894\ttrain-rmse:2.26905\n",
      "[2781]\teval-rmse:4.25657\ttrain-rmse:2.2684\n",
      "[2782]\teval-rmse:4.25645\ttrain-rmse:2.26839\n",
      "[2783]\teval-rmse:4.25626\ttrain-rmse:2.26837\n",
      "[2784]\teval-rmse:4.25708\ttrain-rmse:2.26836\n",
      "[2785]\teval-rmse:4.25863\ttrain-rmse:2.26831\n",
      "[2786]\teval-rmse:4.25738\ttrain-rmse:2.2683\n",
      "[2787]\teval-rmse:4.25353\ttrain-rmse:2.26827\n",
      "[2788]\teval-rmse:4.25516\ttrain-rmse:2.26824\n",
      "[2789]\teval-rmse:4.2529\ttrain-rmse:2.26834\n",
      "[2790]\teval-rmse:4.25431\ttrain-rmse:2.2683\n",
      "[2791]\teval-rmse:4.25637\ttrain-rmse:2.26817\n",
      "[2792]\teval-rmse:4.25629\ttrain-rmse:2.26816\n",
      "[2793]\teval-rmse:4.25475\ttrain-rmse:2.26822\n",
      "[2794]\teval-rmse:4.25306\ttrain-rmse:2.26829\n",
      "[2795]\teval-rmse:4.25272\ttrain-rmse:2.26828\n",
      "[2796]\teval-rmse:4.25459\ttrain-rmse:2.26816\n",
      "[2797]\teval-rmse:4.25759\ttrain-rmse:2.26805\n",
      "[2798]\teval-rmse:4.25737\ttrain-rmse:2.26804\n",
      "[2799]\teval-rmse:4.25674\ttrain-rmse:2.26804\n",
      "[2800]\teval-rmse:4.25908\ttrain-rmse:2.26808\n",
      "[2801]\teval-rmse:4.25799\ttrain-rmse:2.26801\n",
      "[2802]\teval-rmse:4.25558\ttrain-rmse:2.26631\n",
      "[2803]\teval-rmse:4.25437\ttrain-rmse:2.26637\n",
      "[2804]\teval-rmse:4.25316\ttrain-rmse:2.26629\n",
      "[2805]\teval-rmse:4.25161\ttrain-rmse:2.26636\n",
      "[2806]\teval-rmse:4.24933\ttrain-rmse:2.26573\n",
      "[2807]\teval-rmse:4.24834\ttrain-rmse:2.26567\n",
      "[2808]\teval-rmse:4.2514\ttrain-rmse:2.26553\n",
      "[2809]\teval-rmse:4.2491\ttrain-rmse:2.26541\n",
      "[2810]\teval-rmse:4.24799\ttrain-rmse:2.26535\n",
      "[2811]\teval-rmse:4.24838\ttrain-rmse:2.26534\n",
      "[2812]\teval-rmse:4.25006\ttrain-rmse:2.26524\n",
      "[2813]\teval-rmse:4.24801\ttrain-rmse:2.26528\n",
      "[2814]\teval-rmse:4.24895\ttrain-rmse:2.26529\n",
      "[2815]\teval-rmse:4.25134\ttrain-rmse:2.26533\n",
      "[2816]\teval-rmse:4.25369\ttrain-rmse:2.26524\n",
      "[2817]\teval-rmse:4.25568\ttrain-rmse:2.26516\n",
      "[2818]\teval-rmse:4.25404\ttrain-rmse:2.26523\n",
      "[2819]\teval-rmse:4.25683\ttrain-rmse:2.26512\n",
      "[2820]\teval-rmse:4.25882\ttrain-rmse:2.26501\n",
      "[2821]\teval-rmse:4.25645\ttrain-rmse:2.26437\n",
      "[2822]\teval-rmse:4.25835\ttrain-rmse:2.26435\n",
      "[2823]\teval-rmse:4.25556\ttrain-rmse:2.26437\n",
      "[2824]\teval-rmse:4.25328\ttrain-rmse:2.26363\n",
      "[2825]\teval-rmse:4.25413\ttrain-rmse:2.26356\n",
      "[2826]\teval-rmse:4.25292\ttrain-rmse:2.26294\n",
      "[2827]\teval-rmse:4.25491\ttrain-rmse:2.26292\n",
      "[2828]\teval-rmse:4.25746\ttrain-rmse:2.26283\n",
      "[2829]\teval-rmse:4.25866\ttrain-rmse:2.26286\n",
      "[2830]\teval-rmse:4.25907\ttrain-rmse:2.26285\n",
      "[2831]\teval-rmse:4.26112\ttrain-rmse:2.26285\n",
      "[2832]\teval-rmse:4.25755\ttrain-rmse:2.26286\n",
      "[2833]\teval-rmse:4.25959\ttrain-rmse:2.26285\n",
      "[2834]\teval-rmse:4.26012\ttrain-rmse:2.26285\n",
      "[2835]\teval-rmse:4.26211\ttrain-rmse:2.26275\n",
      "[2836]\teval-rmse:4.26445\ttrain-rmse:2.26266\n",
      "[2837]\teval-rmse:4.26416\ttrain-rmse:2.26265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2838]\teval-rmse:4.26193\ttrain-rmse:2.26262\n",
      "[2839]\teval-rmse:4.26334\ttrain-rmse:2.26255\n",
      "[2840]\teval-rmse:4.26136\ttrain-rmse:2.26254\n",
      "[2841]\teval-rmse:4.25892\ttrain-rmse:2.26259\n",
      "[2842]\teval-rmse:4.25974\ttrain-rmse:2.26259\n",
      "[2843]\teval-rmse:4.25952\ttrain-rmse:2.26257\n",
      "[2844]\teval-rmse:4.25819\ttrain-rmse:2.26257\n",
      "[2845]\teval-rmse:4.25664\ttrain-rmse:2.26257\n",
      "[2846]\teval-rmse:4.25516\ttrain-rmse:2.26258\n",
      "[2847]\teval-rmse:4.25385\ttrain-rmse:2.2625\n",
      "[2848]\teval-rmse:4.25479\ttrain-rmse:2.26245\n",
      "[2849]\teval-rmse:4.25244\ttrain-rmse:2.2608\n",
      "[2850]\teval-rmse:4.25222\ttrain-rmse:2.26077\n",
      "[2851]\teval-rmse:4.25419\ttrain-rmse:2.26066\n",
      "[2852]\teval-rmse:4.25189\ttrain-rmse:2.25885\n",
      "[2853]\teval-rmse:4.25213\ttrain-rmse:2.25885\n",
      "[2854]\teval-rmse:4.25333\ttrain-rmse:2.25879\n",
      "[2855]\teval-rmse:4.25479\ttrain-rmse:2.25878\n",
      "[2856]\teval-rmse:4.25298\ttrain-rmse:2.25878\n",
      "[2857]\teval-rmse:4.2507\ttrain-rmse:2.25884\n",
      "[2858]\teval-rmse:4.24835\ttrain-rmse:2.25838\n",
      "[2859]\teval-rmse:4.25025\ttrain-rmse:2.25827\n",
      "[2860]\teval-rmse:4.25146\ttrain-rmse:2.25822\n",
      "[2861]\teval-rmse:4.25331\ttrain-rmse:2.25821\n",
      "[2862]\teval-rmse:4.25509\ttrain-rmse:2.25866\n",
      "[2863]\teval-rmse:4.25277\ttrain-rmse:2.25852\n",
      "[2864]\teval-rmse:4.25579\ttrain-rmse:2.25851\n",
      "[2865]\teval-rmse:4.25664\ttrain-rmse:2.25851\n",
      "[2866]\teval-rmse:4.25766\ttrain-rmse:2.25854\n",
      "[2867]\teval-rmse:4.25883\ttrain-rmse:2.25847\n",
      "[2868]\teval-rmse:4.25565\ttrain-rmse:2.25835\n",
      "[2869]\teval-rmse:4.25549\ttrain-rmse:2.25833\n",
      "[2870]\teval-rmse:4.25726\ttrain-rmse:2.25877\n",
      "[2871]\teval-rmse:4.26026\ttrain-rmse:2.25868\n",
      "[2872]\teval-rmse:4.25797\ttrain-rmse:2.25808\n",
      "[2873]\teval-rmse:4.25429\ttrain-rmse:2.25801\n",
      "[2874]\teval-rmse:4.25494\ttrain-rmse:2.258\n",
      "[2875]\teval-rmse:4.25389\ttrain-rmse:2.25746\n",
      "[2876]\teval-rmse:4.25527\ttrain-rmse:2.2575\n",
      "[2877]\teval-rmse:4.25555\ttrain-rmse:2.2575\n",
      "[2878]\teval-rmse:4.25736\ttrain-rmse:2.2575\n",
      "[2879]\teval-rmse:4.25875\ttrain-rmse:2.25754\n",
      "[2880]\teval-rmse:4.258\ttrain-rmse:2.25752\n",
      "[2881]\teval-rmse:4.25654\ttrain-rmse:2.25753\n",
      "[2882]\teval-rmse:4.25364\ttrain-rmse:2.2576\n",
      "[2883]\teval-rmse:4.2555\ttrain-rmse:2.25755\n",
      "[2884]\teval-rmse:4.25411\ttrain-rmse:2.2573\n",
      "[2885]\teval-rmse:4.256\ttrain-rmse:2.25721\n",
      "[2886]\teval-rmse:4.25682\ttrain-rmse:2.25724\n",
      "[2887]\teval-rmse:4.25971\ttrain-rmse:2.25718\n",
      "[2888]\teval-rmse:4.25903\ttrain-rmse:2.25715\n",
      "[2889]\teval-rmse:4.26095\ttrain-rmse:2.25707\n",
      "[2890]\teval-rmse:4.2623\ttrain-rmse:2.25709\n",
      "[2891]\teval-rmse:4.25995\ttrain-rmse:2.25706\n",
      "[2892]\teval-rmse:4.25799\ttrain-rmse:2.25708\n",
      "[2893]\teval-rmse:4.25563\ttrain-rmse:2.25657\n",
      "[2894]\teval-rmse:4.25441\ttrain-rmse:2.25599\n",
      "[2895]\teval-rmse:4.25208\ttrain-rmse:2.25513\n",
      "[2896]\teval-rmse:4.24965\ttrain-rmse:2.25518\n",
      "[2897]\teval-rmse:4.24682\ttrain-rmse:2.25519\n",
      "[2898]\teval-rmse:4.24575\ttrain-rmse:2.25517\n",
      "[2899]\teval-rmse:4.24891\ttrain-rmse:2.25503\n",
      "[2900]\teval-rmse:4.24759\ttrain-rmse:2.25471\n",
      "[2901]\teval-rmse:4.24948\ttrain-rmse:2.25461\n",
      "[2902]\teval-rmse:4.24714\ttrain-rmse:2.25468\n",
      "[2903]\teval-rmse:4.24743\ttrain-rmse:2.25468\n",
      "[2904]\teval-rmse:4.2462\ttrain-rmse:2.25459\n",
      "[2905]\teval-rmse:4.24456\ttrain-rmse:2.25463\n",
      "[2906]\teval-rmse:4.24235\ttrain-rmse:2.25404\n",
      "[2907]\teval-rmse:4.241\ttrain-rmse:2.25408\n",
      "[2908]\teval-rmse:4.24337\ttrain-rmse:2.254\n",
      "[2909]\teval-rmse:4.24416\ttrain-rmse:2.25399\n",
      "[2910]\teval-rmse:4.24606\ttrain-rmse:2.25391\n",
      "[2911]\teval-rmse:4.24693\ttrain-rmse:2.25391\n",
      "[2912]\teval-rmse:4.24506\ttrain-rmse:2.25395\n",
      "[2913]\teval-rmse:4.24533\ttrain-rmse:2.25395\n",
      "[2914]\teval-rmse:4.24728\ttrain-rmse:2.25387\n",
      "[2915]\teval-rmse:4.24987\ttrain-rmse:2.25377\n",
      "[2916]\teval-rmse:4.24721\ttrain-rmse:2.25376\n",
      "[2917]\teval-rmse:4.24485\ttrain-rmse:2.25377\n",
      "[2918]\teval-rmse:4.24457\ttrain-rmse:2.25376\n",
      "[2919]\teval-rmse:4.24224\ttrain-rmse:2.25383\n",
      "[2920]\teval-rmse:4.24009\ttrain-rmse:2.25315\n",
      "[2921]\teval-rmse:4.23845\ttrain-rmse:2.25321\n",
      "[2922]\teval-rmse:4.23719\ttrain-rmse:2.25319\n",
      "[2923]\teval-rmse:4.23903\ttrain-rmse:2.25316\n",
      "[2924]\teval-rmse:4.23993\ttrain-rmse:2.25318\n",
      "[2925]\teval-rmse:4.23766\ttrain-rmse:2.2519\n",
      "[2926]\teval-rmse:4.24072\ttrain-rmse:2.25175\n",
      "[2927]\teval-rmse:4.23951\ttrain-rmse:2.25133\n",
      "[2928]\teval-rmse:4.23716\ttrain-rmse:2.25082\n",
      "[2929]\teval-rmse:4.23852\ttrain-rmse:2.25075\n",
      "[2930]\teval-rmse:4.24045\ttrain-rmse:2.25065\n",
      "[2931]\teval-rmse:4.23822\ttrain-rmse:2.25072\n",
      "[2932]\teval-rmse:4.24062\ttrain-rmse:2.25061\n",
      "[2933]\teval-rmse:4.24127\ttrain-rmse:2.25062\n",
      "[2934]\teval-rmse:4.24338\ttrain-rmse:2.25054\n",
      "[2935]\teval-rmse:4.24185\ttrain-rmse:2.2505\n",
      "[2936]\teval-rmse:4.24211\ttrain-rmse:2.2505\n",
      "[2937]\teval-rmse:4.23876\ttrain-rmse:2.25052\n",
      "[2938]\teval-rmse:4.23816\ttrain-rmse:2.25053\n",
      "[2939]\teval-rmse:4.23593\ttrain-rmse:2.24985\n",
      "[2940]\teval-rmse:4.2377\ttrain-rmse:2.24983\n",
      "[2941]\teval-rmse:4.23609\ttrain-rmse:2.2499\n",
      "[2942]\teval-rmse:4.23768\ttrain-rmse:2.24983\n",
      "[2943]\teval-rmse:4.23913\ttrain-rmse:2.24975\n",
      "[2944]\teval-rmse:4.23657\ttrain-rmse:2.24971\n",
      "[2945]\teval-rmse:4.23779\ttrain-rmse:2.2497\n",
      "[2946]\teval-rmse:4.23976\ttrain-rmse:2.24961\n",
      "[2947]\teval-rmse:4.23863\ttrain-rmse:2.24963\n",
      "[2948]\teval-rmse:4.24152\ttrain-rmse:2.24951\n",
      "[2949]\teval-rmse:4.24022\ttrain-rmse:2.24943\n",
      "[2950]\teval-rmse:4.24225\ttrain-rmse:2.24948\n",
      "[2951]\teval-rmse:4.24046\ttrain-rmse:2.24952\n",
      "[2952]\teval-rmse:4.23874\ttrain-rmse:2.24955\n",
      "[2953]\teval-rmse:4.24068\ttrain-rmse:2.2495\n",
      "[2954]\teval-rmse:4.2416\ttrain-rmse:2.24952\n",
      "[2955]\teval-rmse:4.24296\ttrain-rmse:2.24952\n",
      "[2956]\teval-rmse:4.24063\ttrain-rmse:2.24959\n",
      "[2957]\teval-rmse:4.23893\ttrain-rmse:2.24962\n",
      "[2958]\teval-rmse:4.24014\ttrain-rmse:2.24957\n",
      "[2959]\teval-rmse:4.24306\ttrain-rmse:2.24956\n",
      "[2960]\teval-rmse:4.24182\ttrain-rmse:2.2492\n",
      "[2961]\teval-rmse:4.23946\ttrain-rmse:2.24845\n",
      "[2962]\teval-rmse:4.23713\ttrain-rmse:2.248\n",
      "[2963]\teval-rmse:4.23546\ttrain-rmse:2.24803\n",
      "[2964]\teval-rmse:4.23632\ttrain-rmse:2.24806\n",
      "[2965]\teval-rmse:4.23399\ttrain-rmse:2.24754\n",
      "[2966]\teval-rmse:4.23584\ttrain-rmse:2.24754\n",
      "[2967]\teval-rmse:4.23811\ttrain-rmse:2.24745\n",
      "[2968]\teval-rmse:4.23987\ttrain-rmse:2.24746\n",
      "[2969]\teval-rmse:4.2376\ttrain-rmse:2.2456\n",
      "[2970]\teval-rmse:4.23883\ttrain-rmse:2.24554\n",
      "[2971]\teval-rmse:4.23655\ttrain-rmse:2.24368\n",
      "[2972]\teval-rmse:4.23849\ttrain-rmse:2.24362\n",
      "[2973]\teval-rmse:4.23905\ttrain-rmse:2.24364\n",
      "[2974]\teval-rmse:4.23743\ttrain-rmse:2.24362\n",
      "[2975]\teval-rmse:4.23981\ttrain-rmse:2.24364\n",
      "[2976]\teval-rmse:4.2377\ttrain-rmse:2.24291\n",
      "[2977]\teval-rmse:4.23951\ttrain-rmse:2.24292\n",
      "[2978]\teval-rmse:4.23736\ttrain-rmse:2.24289\n",
      "[2979]\teval-rmse:4.23428\ttrain-rmse:2.24282\n",
      "[2980]\teval-rmse:4.23293\ttrain-rmse:2.24285\n",
      "[2981]\teval-rmse:4.23216\ttrain-rmse:2.24285\n",
      "[2982]\teval-rmse:4.22986\ttrain-rmse:2.24286\n",
      "[2983]\teval-rmse:4.22756\ttrain-rmse:2.2423\n",
      "[2984]\teval-rmse:4.22432\ttrain-rmse:2.24242\n",
      "[2985]\teval-rmse:4.22518\ttrain-rmse:2.24238\n",
      "[2986]\teval-rmse:4.22416\ttrain-rmse:2.24222\n",
      "[2987]\teval-rmse:4.22501\ttrain-rmse:2.24221\n",
      "[2988]\teval-rmse:4.22686\ttrain-rmse:2.24264\n",
      "[2989]\teval-rmse:4.2247\ttrain-rmse:2.2421\n",
      "[2990]\teval-rmse:4.22302\ttrain-rmse:2.24212\n",
      "[2991]\teval-rmse:4.22389\ttrain-rmse:2.2421\n",
      "[2992]\teval-rmse:4.22228\ttrain-rmse:2.24216\n",
      "[2993]\teval-rmse:4.22165\ttrain-rmse:2.24214\n",
      "[2994]\teval-rmse:4.2193\ttrain-rmse:2.24218\n",
      "[2995]\teval-rmse:4.22104\ttrain-rmse:2.24218\n",
      "[2996]\teval-rmse:4.22297\ttrain-rmse:2.24216\n",
      "[2997]\teval-rmse:4.22186\ttrain-rmse:2.2421\n",
      "[2998]\teval-rmse:4.22077\ttrain-rmse:2.2417\n",
      "[2999]\teval-rmse:4.22141\ttrain-rmse:2.24169\n",
      "[3000]\teval-rmse:4.22429\ttrain-rmse:2.24155\n",
      "[3001]\teval-rmse:4.22247\ttrain-rmse:2.24156\n",
      "[3002]\teval-rmse:4.22282\ttrain-rmse:2.24154\n",
      "[3003]\teval-rmse:4.22188\ttrain-rmse:2.24109\n",
      "[3004]\teval-rmse:4.22426\ttrain-rmse:2.24098\n",
      "[3005]\teval-rmse:4.22727\ttrain-rmse:2.24084\n",
      "[3006]\teval-rmse:4.22589\ttrain-rmse:2.24077\n",
      "[3007]\teval-rmse:4.22934\ttrain-rmse:2.24065\n",
      "[3008]\teval-rmse:4.22766\ttrain-rmse:2.24068\n",
      "[3009]\teval-rmse:4.22923\ttrain-rmse:2.24067\n",
      "[3010]\teval-rmse:4.23123\ttrain-rmse:2.24059\n",
      "[3011]\teval-rmse:4.22895\ttrain-rmse:2.24058\n",
      "[3012]\teval-rmse:4.23088\ttrain-rmse:2.24051\n",
      "[3013]\teval-rmse:4.23027\ttrain-rmse:2.24051\n",
      "[3014]\teval-rmse:4.23057\ttrain-rmse:2.2405\n",
      "[3015]\teval-rmse:4.22779\ttrain-rmse:2.24049\n",
      "[3016]\teval-rmse:4.22672\ttrain-rmse:2.2405\n",
      "[3017]\teval-rmse:4.22344\ttrain-rmse:2.24061\n",
      "[3018]\teval-rmse:4.22379\ttrain-rmse:2.24061\n",
      "[3019]\teval-rmse:4.22149\ttrain-rmse:2.24069\n",
      "[3020]\teval-rmse:4.2244\ttrain-rmse:2.24058\n",
      "[3021]\teval-rmse:4.22424\ttrain-rmse:2.24057\n",
      "[3022]\teval-rmse:4.22644\ttrain-rmse:2.24048\n",
      "[3023]\teval-rmse:4.22633\ttrain-rmse:2.24046\n",
      "[3024]\teval-rmse:4.22424\ttrain-rmse:2.23983\n",
      "[3025]\teval-rmse:4.22197\ttrain-rmse:2.23932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3026]\teval-rmse:4.22546\ttrain-rmse:2.2392\n",
      "[3027]\teval-rmse:4.22418\ttrain-rmse:2.23913\n",
      "[3028]\teval-rmse:4.22495\ttrain-rmse:2.23913\n",
      "[3029]\teval-rmse:4.22675\ttrain-rmse:2.23904\n",
      "[3030]\teval-rmse:4.22561\ttrain-rmse:2.23863\n",
      "[3031]\teval-rmse:4.22236\ttrain-rmse:2.23863\n",
      "[3032]\teval-rmse:4.22022\ttrain-rmse:2.23789\n",
      "[3033]\teval-rmse:4.22305\ttrain-rmse:2.23776\n",
      "[3034]\teval-rmse:4.22449\ttrain-rmse:2.23775\n",
      "[3035]\teval-rmse:4.22328\ttrain-rmse:2.2377\n",
      "[3036]\teval-rmse:4.22222\ttrain-rmse:2.23749\n",
      "[3037]\teval-rmse:4.2226\ttrain-rmse:2.23749\n",
      "[3038]\teval-rmse:4.22045\ttrain-rmse:2.23684\n",
      "[3039]\teval-rmse:4.21657\ttrain-rmse:2.23676\n",
      "[3040]\teval-rmse:4.21787\ttrain-rmse:2.23676\n",
      "[3041]\teval-rmse:4.22003\ttrain-rmse:2.23681\n",
      "[3042]\teval-rmse:4.21826\ttrain-rmse:2.23681\n",
      "[3043]\teval-rmse:4.21859\ttrain-rmse:2.2368\n",
      "[3044]\teval-rmse:4.2216\ttrain-rmse:2.23667\n",
      "[3045]\teval-rmse:4.22337\ttrain-rmse:2.2366\n",
      "[3046]\teval-rmse:4.22222\ttrain-rmse:2.2362\n",
      "[3047]\teval-rmse:4.22125\ttrain-rmse:2.23581\n",
      "[3048]\teval-rmse:4.2232\ttrain-rmse:2.23573\n",
      "[3049]\teval-rmse:4.22406\ttrain-rmse:2.23573\n",
      "[3050]\teval-rmse:4.22692\ttrain-rmse:2.23563\n",
      "[3051]\teval-rmse:4.22358\ttrain-rmse:2.23561\n",
      "[3052]\teval-rmse:4.22236\ttrain-rmse:2.23563\n",
      "[3053]\teval-rmse:4.22378\ttrain-rmse:2.23564\n",
      "[3054]\teval-rmse:4.2234\ttrain-rmse:2.23562\n",
      "[3055]\teval-rmse:4.22131\ttrain-rmse:2.23562\n",
      "[3056]\teval-rmse:4.22314\ttrain-rmse:2.23604\n",
      "[3057]\teval-rmse:4.22141\ttrain-rmse:2.23604\n",
      "[3058]\teval-rmse:4.21967\ttrain-rmse:2.23609\n",
      "[3059]\teval-rmse:4.21861\ttrain-rmse:2.23603\n",
      "[3060]\teval-rmse:4.21754\ttrain-rmse:2.23565\n",
      "[3061]\teval-rmse:4.21835\ttrain-rmse:2.23566\n",
      "[3062]\teval-rmse:4.21807\ttrain-rmse:2.23565\n",
      "[3063]\teval-rmse:4.21992\ttrain-rmse:2.23558\n",
      "[3064]\teval-rmse:4.22136\ttrain-rmse:2.23552\n",
      "[3065]\teval-rmse:4.22267\ttrain-rmse:2.23551\n",
      "[3066]\teval-rmse:4.2214\ttrain-rmse:2.2353\n",
      "[3067]\teval-rmse:4.21774\ttrain-rmse:2.23521\n",
      "[3068]\teval-rmse:4.21978\ttrain-rmse:2.23513\n",
      "[3069]\teval-rmse:4.22071\ttrain-rmse:2.23512\n",
      "[3070]\teval-rmse:4.21717\ttrain-rmse:2.23503\n",
      "[3071]\teval-rmse:4.21612\ttrain-rmse:2.23502\n",
      "[3072]\teval-rmse:4.2171\ttrain-rmse:2.23501\n",
      "[3073]\teval-rmse:4.22\ttrain-rmse:2.23488\n",
      "[3074]\teval-rmse:4.22294\ttrain-rmse:2.23478\n",
      "[3075]\teval-rmse:4.22161\ttrain-rmse:2.23482\n",
      "[3076]\teval-rmse:4.22278\ttrain-rmse:2.23485\n",
      "[3077]\teval-rmse:4.22078\ttrain-rmse:2.23413\n",
      "[3078]\teval-rmse:4.22165\ttrain-rmse:2.23413\n",
      "[3079]\teval-rmse:4.22138\ttrain-rmse:2.23412\n",
      "[3080]\teval-rmse:4.22238\ttrain-rmse:2.23415\n",
      "[3081]\teval-rmse:4.22134\ttrain-rmse:2.23388\n",
      "[3082]\teval-rmse:4.21957\ttrain-rmse:2.23393\n",
      "[3083]\teval-rmse:4.2219\ttrain-rmse:2.23385\n",
      "[3084]\teval-rmse:4.2203\ttrain-rmse:2.23388\n",
      "[3085]\teval-rmse:4.218\ttrain-rmse:2.23315\n",
      "[3086]\teval-rmse:4.21997\ttrain-rmse:2.23308\n",
      "[3087]\teval-rmse:4.21893\ttrain-rmse:2.23283\n",
      "[3088]\teval-rmse:4.21922\ttrain-rmse:2.23283\n",
      "[3089]\teval-rmse:4.2206\ttrain-rmse:2.23277\n",
      "[3090]\teval-rmse:4.2225\ttrain-rmse:2.23272\n",
      "[3091]\teval-rmse:4.22023\ttrain-rmse:2.2327\n",
      "[3092]\teval-rmse:4.22208\ttrain-rmse:2.23271\n",
      "[3093]\teval-rmse:4.22043\ttrain-rmse:2.23273\n",
      "[3094]\teval-rmse:4.22056\ttrain-rmse:2.23272\n",
      "[3095]\teval-rmse:4.21935\ttrain-rmse:2.2327\n",
      "[3096]\teval-rmse:4.22016\ttrain-rmse:2.23271\n",
      "[3097]\teval-rmse:4.22158\ttrain-rmse:2.23272\n",
      "[3098]\teval-rmse:4.22044\ttrain-rmse:2.23229\n",
      "[3099]\teval-rmse:4.22235\ttrain-rmse:2.23231\n",
      "[3100]\teval-rmse:4.22196\ttrain-rmse:2.23229\n",
      "[3101]\teval-rmse:4.22074\ttrain-rmse:2.23223\n",
      "[3102]\teval-rmse:4.21986\ttrain-rmse:2.23222\n",
      "[3103]\teval-rmse:4.22182\ttrain-rmse:2.23214\n",
      "[3104]\teval-rmse:4.22107\ttrain-rmse:2.23211\n",
      "[3105]\teval-rmse:4.21883\ttrain-rmse:2.2321\n",
      "[3106]\teval-rmse:4.21969\ttrain-rmse:2.2321\n",
      "[3107]\teval-rmse:4.22033\ttrain-rmse:2.23212\n",
      "[3108]\teval-rmse:4.22109\ttrain-rmse:2.23212\n",
      "[3109]\teval-rmse:4.22244\ttrain-rmse:2.23214\n",
      "[3110]\teval-rmse:4.22377\ttrain-rmse:2.23208\n",
      "[3111]\teval-rmse:4.22578\ttrain-rmse:2.23203\n",
      "[3112]\teval-rmse:4.22358\ttrain-rmse:2.232\n",
      "[3113]\teval-rmse:4.22495\ttrain-rmse:2.23205\n",
      "[3114]\teval-rmse:4.22448\ttrain-rmse:2.23204\n",
      "[3115]\teval-rmse:4.22227\ttrain-rmse:2.23202\n",
      "[3116]\teval-rmse:4.22025\ttrain-rmse:2.23076\n",
      "[3117]\teval-rmse:4.21886\ttrain-rmse:2.23078\n",
      "[3118]\teval-rmse:4.21531\ttrain-rmse:2.23072\n",
      "[3119]\teval-rmse:4.218\ttrain-rmse:2.23063\n",
      "[3120]\teval-rmse:4.21481\ttrain-rmse:2.23054\n",
      "[3121]\teval-rmse:4.2126\ttrain-rmse:2.23003\n",
      "[3122]\teval-rmse:4.21439\ttrain-rmse:2.22995\n",
      "[3123]\teval-rmse:4.21562\ttrain-rmse:2.22995\n",
      "[3124]\teval-rmse:4.2176\ttrain-rmse:2.22987\n",
      "[3125]\teval-rmse:4.21987\ttrain-rmse:2.22982\n",
      "[3126]\teval-rmse:4.21625\ttrain-rmse:2.22972\n",
      "[3127]\teval-rmse:4.21864\ttrain-rmse:2.22964\n",
      "[3128]\teval-rmse:4.21636\ttrain-rmse:2.22913\n",
      "[3129]\teval-rmse:4.21458\ttrain-rmse:2.22916\n",
      "[3130]\teval-rmse:4.21431\ttrain-rmse:2.22916\n",
      "[3131]\teval-rmse:4.21561\ttrain-rmse:2.22916\n",
      "[3132]\teval-rmse:4.2175\ttrain-rmse:2.2291\n",
      "[3133]\teval-rmse:4.21953\ttrain-rmse:2.22904\n",
      "[3134]\teval-rmse:4.21723\ttrain-rmse:2.2284\n",
      "[3135]\teval-rmse:4.2191\ttrain-rmse:2.22836\n",
      "[3136]\teval-rmse:4.21691\ttrain-rmse:2.2284\n",
      "[3137]\teval-rmse:4.21328\ttrain-rmse:2.22831\n",
      "[3138]\teval-rmse:4.21234\ttrain-rmse:2.22828\n",
      "[3139]\teval-rmse:4.20897\ttrain-rmse:2.22823\n",
      "[3140]\teval-rmse:4.20686\ttrain-rmse:2.22661\n",
      "[3141]\teval-rmse:4.20894\ttrain-rmse:2.22665\n",
      "[3142]\teval-rmse:4.20629\ttrain-rmse:2.22666\n",
      "[3143]\teval-rmse:4.20749\ttrain-rmse:2.22661\n",
      "[3144]\teval-rmse:4.20648\ttrain-rmse:2.22662\n",
      "[3145]\teval-rmse:4.20533\ttrain-rmse:2.22665\n",
      "[3146]\teval-rmse:4.20637\ttrain-rmse:2.22664\n",
      "[3147]\teval-rmse:4.20852\ttrain-rmse:2.22657\n",
      "[3148]\teval-rmse:4.20641\ttrain-rmse:2.22658\n",
      "[3149]\teval-rmse:4.20485\ttrain-rmse:2.22659\n",
      "[3150]\teval-rmse:4.20573\ttrain-rmse:2.22658\n",
      "[3151]\teval-rmse:4.20776\ttrain-rmse:2.22657\n",
      "[3152]\teval-rmse:4.2055\ttrain-rmse:2.22664\n",
      "[3153]\teval-rmse:4.20686\ttrain-rmse:2.22666\n",
      "[3154]\teval-rmse:4.20912\ttrain-rmse:2.22658\n",
      "[3155]\teval-rmse:4.20622\ttrain-rmse:2.22657\n",
      "[3156]\teval-rmse:4.20814\ttrain-rmse:2.22655\n",
      "[3157]\teval-rmse:4.2106\ttrain-rmse:2.22646\n",
      "[3158]\teval-rmse:4.20953\ttrain-rmse:2.2262\n",
      "[3159]\teval-rmse:4.20793\ttrain-rmse:2.22624\n",
      "[3160]\teval-rmse:4.20998\ttrain-rmse:2.22617\n",
      "[3161]\teval-rmse:4.20784\ttrain-rmse:2.22623\n",
      "[3162]\teval-rmse:4.20623\ttrain-rmse:2.22629\n",
      "[3163]\teval-rmse:4.20833\ttrain-rmse:2.2262\n",
      "[3164]\teval-rmse:4.20608\ttrain-rmse:2.22579\n",
      "[3165]\teval-rmse:4.20395\ttrain-rmse:2.2252\n",
      "[3166]\teval-rmse:4.20599\ttrain-rmse:2.22519\n",
      "[3167]\teval-rmse:4.20868\ttrain-rmse:2.2251\n",
      "[3168]\teval-rmse:4.20995\ttrain-rmse:2.2251\n",
      "[3169]\teval-rmse:4.20806\ttrain-rmse:2.22514\n",
      "[3170]\teval-rmse:4.20693\ttrain-rmse:2.22512\n",
      "[3171]\teval-rmse:4.20628\ttrain-rmse:2.22511\n",
      "[3172]\teval-rmse:4.20346\ttrain-rmse:2.22519\n",
      "[3173]\teval-rmse:4.2059\ttrain-rmse:2.2251\n",
      "[3174]\teval-rmse:4.20715\ttrain-rmse:2.22509\n",
      "[3175]\teval-rmse:4.20702\ttrain-rmse:2.22509\n",
      "[3176]\teval-rmse:4.2051\ttrain-rmse:2.22509\n",
      "[3177]\teval-rmse:4.20218\ttrain-rmse:2.22511\n",
      "[3178]\teval-rmse:4.20308\ttrain-rmse:2.22511\n",
      "[3179]\teval-rmse:4.20309\ttrain-rmse:2.22511\n",
      "[3180]\teval-rmse:4.20086\ttrain-rmse:2.22513\n",
      "[3181]\teval-rmse:4.19962\ttrain-rmse:2.22508\n",
      "[3182]\teval-rmse:4.19855\ttrain-rmse:2.22511\n",
      "[3183]\teval-rmse:4.19674\ttrain-rmse:2.22517\n",
      "[3184]\teval-rmse:4.19592\ttrain-rmse:2.22519\n",
      "[3185]\teval-rmse:4.19674\ttrain-rmse:2.22518\n",
      "[3186]\teval-rmse:4.19806\ttrain-rmse:2.2251\n",
      "[3187]\teval-rmse:4.19591\ttrain-rmse:2.22519\n",
      "[3188]\teval-rmse:4.19376\ttrain-rmse:2.2245\n",
      "[3189]\teval-rmse:4.1956\ttrain-rmse:2.22446\n",
      "[3190]\teval-rmse:4.1936\ttrain-rmse:2.22338\n",
      "[3191]\teval-rmse:4.19243\ttrain-rmse:2.22334\n",
      "[3192]\teval-rmse:4.19074\ttrain-rmse:2.22341\n",
      "[3193]\teval-rmse:4.1927\ttrain-rmse:2.2238\n",
      "[3194]\teval-rmse:4.19459\ttrain-rmse:2.22377\n",
      "[3195]\teval-rmse:4.19231\ttrain-rmse:2.22381\n",
      "[3196]\teval-rmse:4.19194\ttrain-rmse:2.22381\n",
      "[3197]\teval-rmse:4.18923\ttrain-rmse:2.22393\n",
      "[3198]\teval-rmse:4.19053\ttrain-rmse:2.22386\n",
      "[3199]\teval-rmse:4.18957\ttrain-rmse:2.22386\n",
      "[3200]\teval-rmse:4.18743\ttrain-rmse:2.22319\n",
      "[3201]\teval-rmse:4.1862\ttrain-rmse:2.22325\n",
      "[3202]\teval-rmse:4.18558\ttrain-rmse:2.22328\n",
      "[3203]\teval-rmse:4.18355\ttrain-rmse:2.22285\n",
      "[3204]\teval-rmse:4.18166\ttrain-rmse:2.2229\n",
      "[3205]\teval-rmse:4.18056\ttrain-rmse:2.22294\n",
      "[3206]\teval-rmse:4.17952\ttrain-rmse:2.22291\n",
      "[3207]\teval-rmse:4.1815\ttrain-rmse:2.22289\n",
      "[3208]\teval-rmse:4.18187\ttrain-rmse:2.22288\n",
      "[3209]\teval-rmse:4.18\ttrain-rmse:2.22236\n",
      "[3210]\teval-rmse:4.18179\ttrain-rmse:2.22223\n",
      "[3211]\teval-rmse:4.18503\ttrain-rmse:2.22222\n",
      "[3212]\teval-rmse:4.18776\ttrain-rmse:2.22208\n",
      "[3213]\teval-rmse:4.18852\ttrain-rmse:2.22206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3214]\teval-rmse:4.18617\ttrain-rmse:2.22206\n",
      "[3215]\teval-rmse:4.18812\ttrain-rmse:2.22196\n",
      "[3216]\teval-rmse:4.19048\ttrain-rmse:2.22183\n",
      "[3217]\teval-rmse:4.19117\ttrain-rmse:2.22181\n",
      "[3218]\teval-rmse:4.19142\ttrain-rmse:2.22181\n",
      "[3219]\teval-rmse:4.18924\ttrain-rmse:2.22135\n",
      "[3220]\teval-rmse:4.18888\ttrain-rmse:2.22134\n",
      "[3221]\teval-rmse:4.18937\ttrain-rmse:2.22133\n",
      "[3222]\teval-rmse:4.18764\ttrain-rmse:2.22136\n",
      "[3223]\teval-rmse:4.18783\ttrain-rmse:2.22136\n",
      "[3224]\teval-rmse:4.18974\ttrain-rmse:2.22126\n",
      "[3225]\teval-rmse:4.18789\ttrain-rmse:2.22011\n",
      "[3226]\teval-rmse:4.18681\ttrain-rmse:2.22008\n",
      "[3227]\teval-rmse:4.18852\ttrain-rmse:2.22005\n",
      "[3228]\teval-rmse:4.19036\ttrain-rmse:2.22002\n",
      "[3229]\teval-rmse:4.18814\ttrain-rmse:2.22005\n",
      "[3230]\teval-rmse:4.19009\ttrain-rmse:2.21996\n",
      "[3231]\teval-rmse:4.19251\ttrain-rmse:2.21985\n",
      "[3232]\teval-rmse:4.19341\ttrain-rmse:2.21985\n",
      "[3233]\teval-rmse:4.19154\ttrain-rmse:2.21991\n",
      "[3234]\teval-rmse:4.19388\ttrain-rmse:2.21989\n",
      "[3235]\teval-rmse:4.19072\ttrain-rmse:2.22001\n",
      "[3236]\teval-rmse:4.19311\ttrain-rmse:2.21989\n",
      "[3237]\teval-rmse:4.18949\ttrain-rmse:2.21985\n",
      "[3238]\teval-rmse:4.19144\ttrain-rmse:2.21976\n",
      "[3239]\teval-rmse:4.1894\ttrain-rmse:2.21866\n",
      "[3240]\teval-rmse:4.19015\ttrain-rmse:2.21865\n",
      "[3241]\teval-rmse:4.18822\ttrain-rmse:2.21813\n",
      "[3242]\teval-rmse:4.1901\ttrain-rmse:2.21811\n",
      "[3243]\teval-rmse:4.18732\ttrain-rmse:2.21821\n",
      "[3244]\teval-rmse:4.18519\ttrain-rmse:2.21823\n",
      "[3245]\teval-rmse:4.18246\ttrain-rmse:2.21828\n",
      "[3246]\teval-rmse:4.17939\ttrain-rmse:2.21844\n",
      "[3247]\teval-rmse:4.18081\ttrain-rmse:2.21836\n",
      "[3248]\teval-rmse:4.1826\ttrain-rmse:2.21826\n",
      "[3249]\teval-rmse:4.17953\ttrain-rmse:2.21833\n",
      "[3250]\teval-rmse:4.17859\ttrain-rmse:2.21812\n",
      "[3251]\teval-rmse:4.17552\ttrain-rmse:2.21815\n",
      "[3252]\teval-rmse:4.17581\ttrain-rmse:2.21814\n",
      "[3253]\teval-rmse:4.17382\ttrain-rmse:2.21689\n",
      "[3254]\teval-rmse:4.17277\ttrain-rmse:2.21654\n",
      "[3255]\teval-rmse:4.16998\ttrain-rmse:2.21664\n",
      "[3256]\teval-rmse:4.17178\ttrain-rmse:2.21656\n",
      "[3257]\teval-rmse:4.17154\ttrain-rmse:2.21656\n",
      "[3258]\teval-rmse:4.16863\ttrain-rmse:2.21661\n",
      "[3259]\teval-rmse:4.16583\ttrain-rmse:2.21667\n",
      "[3260]\teval-rmse:4.16428\ttrain-rmse:2.21677\n",
      "[3261]\teval-rmse:4.16545\ttrain-rmse:2.21668\n",
      "[3262]\teval-rmse:4.1677\ttrain-rmse:2.21651\n",
      "[3263]\teval-rmse:4.16655\ttrain-rmse:2.21649\n",
      "[3264]\teval-rmse:4.16902\ttrain-rmse:2.21638\n",
      "[3265]\teval-rmse:4.16941\ttrain-rmse:2.21637\n",
      "[3266]\teval-rmse:4.16849\ttrain-rmse:2.21623\n",
      "[3267]\teval-rmse:4.17074\ttrain-rmse:2.21608\n",
      "[3268]\teval-rmse:4.17109\ttrain-rmse:2.21607\n",
      "[3269]\teval-rmse:4.17295\ttrain-rmse:2.21601\n",
      "[3270]\teval-rmse:4.17371\ttrain-rmse:2.21598\n",
      "[3271]\teval-rmse:4.17611\ttrain-rmse:2.21584\n",
      "[3272]\teval-rmse:4.17802\ttrain-rmse:2.21574\n",
      "[3273]\teval-rmse:4.17943\ttrain-rmse:2.21571\n",
      "[3274]\teval-rmse:4.18137\ttrain-rmse:2.21566\n",
      "[3275]\teval-rmse:4.17816\ttrain-rmse:2.21573\n",
      "[3276]\teval-rmse:4.17907\ttrain-rmse:2.21572\n",
      "[3277]\teval-rmse:4.17997\ttrain-rmse:2.2157\n",
      "[3278]\teval-rmse:4.18186\ttrain-rmse:2.2156\n",
      "[3279]\teval-rmse:4.17876\ttrain-rmse:2.21561\n",
      "[3280]\teval-rmse:4.17964\ttrain-rmse:2.21561\n",
      "[3281]\teval-rmse:4.17764\ttrain-rmse:2.21528\n",
      "[3282]\teval-rmse:4.17788\ttrain-rmse:2.21525\n",
      "[3283]\teval-rmse:4.17967\ttrain-rmse:2.21516\n",
      "[3284]\teval-rmse:4.17758\ttrain-rmse:2.2148\n",
      "[3285]\teval-rmse:4.17555\ttrain-rmse:2.21489\n",
      "[3286]\teval-rmse:4.17786\ttrain-rmse:2.21476\n",
      "[3287]\teval-rmse:4.1762\ttrain-rmse:2.21483\n",
      "[3288]\teval-rmse:4.1751\ttrain-rmse:2.2148\n",
      "[3289]\teval-rmse:4.17345\ttrain-rmse:2.21488\n",
      "[3290]\teval-rmse:4.17622\ttrain-rmse:2.21471\n",
      "[3291]\teval-rmse:4.17809\ttrain-rmse:2.21461\n",
      "[3292]\teval-rmse:4.17879\ttrain-rmse:2.2146\n",
      "[3293]\teval-rmse:4.17696\ttrain-rmse:2.21468\n",
      "[3294]\teval-rmse:4.17919\ttrain-rmse:2.21456\n",
      "[3295]\teval-rmse:4.17757\ttrain-rmse:2.21464\n",
      "[3296]\teval-rmse:4.17901\ttrain-rmse:2.2146\n",
      "[3297]\teval-rmse:4.17703\ttrain-rmse:2.21408\n",
      "[3298]\teval-rmse:4.17809\ttrain-rmse:2.21408\n",
      "[3299]\teval-rmse:4.17711\ttrain-rmse:2.21408\n",
      "[3300]\teval-rmse:4.17701\ttrain-rmse:2.21408\n",
      "[3301]\teval-rmse:4.17609\ttrain-rmse:2.21412\n",
      "[3302]\teval-rmse:4.17307\ttrain-rmse:2.2142\n",
      "[3303]\teval-rmse:4.17333\ttrain-rmse:2.21419\n",
      "[3304]\teval-rmse:4.17136\ttrain-rmse:2.21319\n",
      "[3305]\teval-rmse:4.16851\ttrain-rmse:2.21323\n",
      "[3306]\teval-rmse:4.17097\ttrain-rmse:2.21308\n",
      "[3307]\teval-rmse:4.17181\ttrain-rmse:2.21305\n",
      "[3308]\teval-rmse:4.17359\ttrain-rmse:2.21294\n",
      "[3309]\teval-rmse:4.1726\ttrain-rmse:2.21272\n",
      "[3310]\teval-rmse:4.17493\ttrain-rmse:2.2126\n",
      "[3311]\teval-rmse:4.17266\ttrain-rmse:2.21266\n",
      "[3312]\teval-rmse:4.17347\ttrain-rmse:2.21263\n",
      "[3313]\teval-rmse:4.17133\ttrain-rmse:2.21269\n",
      "[3314]\teval-rmse:4.17309\ttrain-rmse:2.21259\n",
      "[3315]\teval-rmse:4.17489\ttrain-rmse:2.21253\n",
      "[3316]\teval-rmse:4.17608\ttrain-rmse:2.21251\n",
      "[3317]\teval-rmse:4.17442\ttrain-rmse:2.21254\n",
      "[3318]\teval-rmse:4.17721\ttrain-rmse:2.2124\n",
      "[3319]\teval-rmse:4.17652\ttrain-rmse:2.21242\n",
      "[3320]\teval-rmse:4.17833\ttrain-rmse:2.21238\n",
      "[3321]\teval-rmse:4.17915\ttrain-rmse:2.21233\n",
      "[3322]\teval-rmse:4.17706\ttrain-rmse:2.21238\n",
      "[3323]\teval-rmse:4.17605\ttrain-rmse:2.21215\n",
      "[3324]\teval-rmse:4.17486\ttrain-rmse:2.21211\n",
      "[3325]\teval-rmse:4.17292\ttrain-rmse:2.21094\n",
      "[3326]\teval-rmse:4.17085\ttrain-rmse:2.21032\n",
      "[3327]\teval-rmse:4.1698\ttrain-rmse:2.21029\n",
      "[3328]\teval-rmse:4.17209\ttrain-rmse:2.21017\n",
      "[3329]\teval-rmse:4.17386\ttrain-rmse:2.21013\n",
      "[3330]\teval-rmse:4.17167\ttrain-rmse:2.21022\n",
      "[3331]\teval-rmse:4.16977\ttrain-rmse:2.20983\n",
      "[3332]\teval-rmse:4.16662\ttrain-rmse:2.20992\n",
      "[3333]\teval-rmse:4.16553\ttrain-rmse:2.20989\n",
      "[3334]\teval-rmse:4.16394\ttrain-rmse:2.20997\n",
      "[3335]\teval-rmse:4.16238\ttrain-rmse:2.21007\n",
      "[3336]\teval-rmse:4.16359\ttrain-rmse:2.21005\n",
      "[3337]\teval-rmse:4.16155\ttrain-rmse:2.21012\n",
      "[3338]\teval-rmse:4.16191\ttrain-rmse:2.21011\n",
      "[3339]\teval-rmse:4.1642\ttrain-rmse:2.20996\n",
      "[3340]\teval-rmse:4.16665\ttrain-rmse:2.20988\n",
      "[3341]\teval-rmse:4.16468\ttrain-rmse:2.20998\n",
      "[3342]\teval-rmse:4.16168\ttrain-rmse:2.21016\n",
      "[3343]\teval-rmse:4.16353\ttrain-rmse:2.21004\n",
      "[3344]\teval-rmse:4.16619\ttrain-rmse:2.20995\n",
      "[3345]\teval-rmse:4.16431\ttrain-rmse:2.20884\n",
      "[3346]\teval-rmse:4.16688\ttrain-rmse:2.20881\n",
      "[3347]\teval-rmse:4.16819\ttrain-rmse:2.20874\n",
      "[3348]\teval-rmse:4.17064\ttrain-rmse:2.20861\n",
      "[3349]\teval-rmse:4.17039\ttrain-rmse:2.20861\n",
      "[3350]\teval-rmse:4.16934\ttrain-rmse:2.2082\n",
      "[3351]\teval-rmse:4.16834\ttrain-rmse:2.20822\n",
      "[3352]\teval-rmse:4.17067\ttrain-rmse:2.20817\n",
      "[3353]\teval-rmse:4.17291\ttrain-rmse:2.20807\n",
      "[3354]\teval-rmse:4.17278\ttrain-rmse:2.20807\n",
      "[3355]\teval-rmse:4.17512\ttrain-rmse:2.20795\n",
      "[3356]\teval-rmse:4.17676\ttrain-rmse:2.20793\n",
      "[3357]\teval-rmse:4.17642\ttrain-rmse:2.20793\n",
      "[3358]\teval-rmse:4.17732\ttrain-rmse:2.20793\n",
      "[3359]\teval-rmse:4.17908\ttrain-rmse:2.20786\n",
      "[3360]\teval-rmse:4.18104\ttrain-rmse:2.20789\n",
      "[3361]\teval-rmse:4.17879\ttrain-rmse:2.20785\n",
      "[3362]\teval-rmse:4.17698\ttrain-rmse:2.20791\n",
      "[3363]\teval-rmse:4.17437\ttrain-rmse:2.20802\n",
      "[3364]\teval-rmse:4.17724\ttrain-rmse:2.20789\n",
      "[3365]\teval-rmse:4.17638\ttrain-rmse:2.20758\n",
      "[3366]\teval-rmse:4.17548\ttrain-rmse:2.20716\n",
      "[3367]\teval-rmse:4.17791\ttrain-rmse:2.20704\n",
      "[3368]\teval-rmse:4.17705\ttrain-rmse:2.20673\n",
      "[3369]\teval-rmse:4.17678\ttrain-rmse:2.20673\n",
      "[3370]\teval-rmse:4.17968\ttrain-rmse:2.20661\n",
      "[3371]\teval-rmse:4.17988\ttrain-rmse:2.2066\n",
      "[3372]\teval-rmse:4.18204\ttrain-rmse:2.20652\n",
      "[3373]\teval-rmse:4.183\ttrain-rmse:2.20652\n",
      "[3374]\teval-rmse:4.18353\ttrain-rmse:2.20653\n",
      "[3375]\teval-rmse:4.18334\ttrain-rmse:2.20652\n",
      "[3376]\teval-rmse:4.18324\ttrain-rmse:2.20652\n",
      "[3377]\teval-rmse:4.18214\ttrain-rmse:2.20628\n",
      "[3378]\teval-rmse:4.18288\ttrain-rmse:2.20625\n",
      "[3379]\teval-rmse:4.18281\ttrain-rmse:2.20624\n",
      "[3380]\teval-rmse:4.181\ttrain-rmse:2.20628\n",
      "[3381]\teval-rmse:4.18005\ttrain-rmse:2.20628\n",
      "[3382]\teval-rmse:4.1813\ttrain-rmse:2.20628\n",
      "[3383]\teval-rmse:4.17934\ttrain-rmse:2.20589\n",
      "[3384]\teval-rmse:4.18006\ttrain-rmse:2.2059\n",
      "[3385]\teval-rmse:4.18179\ttrain-rmse:2.20583\n",
      "[3386]\teval-rmse:4.18272\ttrain-rmse:2.20584\n",
      "[3387]\teval-rmse:4.18057\ttrain-rmse:2.20541\n",
      "[3388]\teval-rmse:4.1786\ttrain-rmse:2.20499\n",
      "[3389]\teval-rmse:4.17614\ttrain-rmse:2.20499\n",
      "[3390]\teval-rmse:4.17499\ttrain-rmse:2.20502\n",
      "[3391]\teval-rmse:4.17551\ttrain-rmse:2.20501\n",
      "[3392]\teval-rmse:4.17773\ttrain-rmse:2.20493\n",
      "[3393]\teval-rmse:4.17606\ttrain-rmse:2.20499\n",
      "[3394]\teval-rmse:4.17805\ttrain-rmse:2.20492\n",
      "[3395]\teval-rmse:4.17577\ttrain-rmse:2.20492\n",
      "[3396]\teval-rmse:4.17368\ttrain-rmse:2.2044\n",
      "[3397]\teval-rmse:4.17096\ttrain-rmse:2.20451\n",
      "[3398]\teval-rmse:4.16826\ttrain-rmse:2.20453\n",
      "[3399]\teval-rmse:4.1674\ttrain-rmse:2.20421\n",
      "[3400]\teval-rmse:4.16929\ttrain-rmse:2.20413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3401]\teval-rmse:4.16727\ttrain-rmse:2.20419\n",
      "[3402]\teval-rmse:4.16985\ttrain-rmse:2.20421\n",
      "[3403]\teval-rmse:4.17127\ttrain-rmse:2.20414\n",
      "[3404]\teval-rmse:4.16941\ttrain-rmse:2.20421\n",
      "[3405]\teval-rmse:4.16773\ttrain-rmse:2.20426\n",
      "[3406]\teval-rmse:4.16993\ttrain-rmse:2.20417\n",
      "[3407]\teval-rmse:4.1701\ttrain-rmse:2.20417\n",
      "[3408]\teval-rmse:4.16887\ttrain-rmse:2.20422\n",
      "[3409]\teval-rmse:4.17095\ttrain-rmse:2.20412\n",
      "[3410]\teval-rmse:4.17282\ttrain-rmse:2.20405\n",
      "[3411]\teval-rmse:4.17167\ttrain-rmse:2.20402\n",
      "[3412]\teval-rmse:4.17352\ttrain-rmse:2.20393\n",
      "[3413]\teval-rmse:4.17475\ttrain-rmse:2.20389\n",
      "[3414]\teval-rmse:4.17623\ttrain-rmse:2.20389\n",
      "[3415]\teval-rmse:4.17348\ttrain-rmse:2.20388\n",
      "[3416]\teval-rmse:4.17153\ttrain-rmse:2.20332\n",
      "[3417]\teval-rmse:4.17133\ttrain-rmse:2.20332\n",
      "[3418]\teval-rmse:4.17038\ttrain-rmse:2.20335\n",
      "[3419]\teval-rmse:4.16804\ttrain-rmse:2.20332\n",
      "[3420]\teval-rmse:4.16616\ttrain-rmse:2.20293\n",
      "[3421]\teval-rmse:4.16626\ttrain-rmse:2.20293\n",
      "[3422]\teval-rmse:4.16347\ttrain-rmse:2.20296\n",
      "[3423]\teval-rmse:4.16187\ttrain-rmse:2.20303\n",
      "[3424]\teval-rmse:4.15992\ttrain-rmse:2.20313\n",
      "[3425]\teval-rmse:4.1617\ttrain-rmse:2.20303\n",
      "[3426]\teval-rmse:4.15979\ttrain-rmse:2.20307\n",
      "[3427]\teval-rmse:4.15796\ttrain-rmse:2.20261\n",
      "[3428]\teval-rmse:4.1603\ttrain-rmse:2.20248\n",
      "[3429]\teval-rmse:4.1605\ttrain-rmse:2.20246\n",
      "[3430]\teval-rmse:4.16372\ttrain-rmse:2.2023\n",
      "[3431]\teval-rmse:4.16451\ttrain-rmse:2.20227\n",
      "[3432]\teval-rmse:4.16745\ttrain-rmse:2.20213\n",
      "[3433]\teval-rmse:4.16856\ttrain-rmse:2.20211\n",
      "[3434]\teval-rmse:4.17076\ttrain-rmse:2.20203\n",
      "[3435]\teval-rmse:4.1689\ttrain-rmse:2.20111\n",
      "[3436]\teval-rmse:4.16742\ttrain-rmse:2.20115\n",
      "[3437]\teval-rmse:4.16555\ttrain-rmse:2.20117\n",
      "[3438]\teval-rmse:4.16638\ttrain-rmse:2.20116\n",
      "[3439]\teval-rmse:4.16826\ttrain-rmse:2.20107\n",
      "[3440]\teval-rmse:4.16942\ttrain-rmse:2.20103\n",
      "[3441]\teval-rmse:4.16727\ttrain-rmse:2.20103\n",
      "[3442]\teval-rmse:4.16511\ttrain-rmse:2.20106\n",
      "[3443]\teval-rmse:4.16407\ttrain-rmse:2.20103\n",
      "[3444]\teval-rmse:4.16516\ttrain-rmse:2.20104\n",
      "[3445]\teval-rmse:4.16418\ttrain-rmse:2.20074\n",
      "[3446]\teval-rmse:4.16192\ttrain-rmse:2.20073\n",
      "[3447]\teval-rmse:4.16425\ttrain-rmse:2.20062\n",
      "[3448]\teval-rmse:4.16629\ttrain-rmse:2.20053\n",
      "[3449]\teval-rmse:4.16509\ttrain-rmse:2.2005\n",
      "[3450]\teval-rmse:4.16778\ttrain-rmse:2.20039\n",
      "[3451]\teval-rmse:4.1646\ttrain-rmse:2.20043\n",
      "[3452]\teval-rmse:4.16653\ttrain-rmse:2.20035\n",
      "[3453]\teval-rmse:4.16336\ttrain-rmse:2.20039\n",
      "[3454]\teval-rmse:4.16449\ttrain-rmse:2.20038\n",
      "[3455]\teval-rmse:4.16436\ttrain-rmse:2.20038\n",
      "[3456]\teval-rmse:4.16349\ttrain-rmse:2.20009\n",
      "[3457]\teval-rmse:4.16628\ttrain-rmse:2.20005\n",
      "[3458]\teval-rmse:4.16525\ttrain-rmse:2.20009\n",
      "[3459]\teval-rmse:4.166\ttrain-rmse:2.20005\n",
      "[3460]\teval-rmse:4.16392\ttrain-rmse:2.19965\n",
      "[3461]\teval-rmse:4.1654\ttrain-rmse:2.19966\n",
      "[3462]\teval-rmse:4.16552\ttrain-rmse:2.19965\n",
      "[3463]\teval-rmse:4.1645\ttrain-rmse:2.19927\n",
      "[3464]\teval-rmse:4.16148\ttrain-rmse:2.19938\n",
      "[3465]\teval-rmse:4.15989\ttrain-rmse:2.19943\n",
      "[3466]\teval-rmse:4.15773\ttrain-rmse:2.19952\n",
      "[3467]\teval-rmse:4.15854\ttrain-rmse:2.1995\n",
      "[3468]\teval-rmse:4.15705\ttrain-rmse:2.19957\n",
      "[3469]\teval-rmse:4.15508\ttrain-rmse:2.19917\n",
      "[3470]\teval-rmse:4.15248\ttrain-rmse:2.19929\n",
      "[3471]\teval-rmse:4.14987\ttrain-rmse:2.19943\n",
      "[3472]\teval-rmse:4.14973\ttrain-rmse:2.19943\n",
      "[3473]\teval-rmse:4.15245\ttrain-rmse:2.19927\n",
      "[3474]\teval-rmse:4.15369\ttrain-rmse:2.19925\n",
      "[3475]\teval-rmse:4.15545\ttrain-rmse:2.19921\n",
      "[3476]\teval-rmse:4.155\ttrain-rmse:2.19922\n",
      "[3477]\teval-rmse:4.15622\ttrain-rmse:2.19919\n",
      "[3478]\teval-rmse:4.15762\ttrain-rmse:2.19917\n",
      "[3479]\teval-rmse:4.15978\ttrain-rmse:2.19905\n",
      "[3480]\teval-rmse:4.15671\ttrain-rmse:2.19909\n",
      "[3481]\teval-rmse:4.159\ttrain-rmse:2.19897\n",
      "[3482]\teval-rmse:4.15793\ttrain-rmse:2.19895\n",
      "[3483]\teval-rmse:4.15767\ttrain-rmse:2.19895\n",
      "[3484]\teval-rmse:4.15902\ttrain-rmse:2.19889\n",
      "[3485]\teval-rmse:4.16199\ttrain-rmse:2.19885\n",
      "[3486]\teval-rmse:4.15989\ttrain-rmse:2.19893\n",
      "[3487]\teval-rmse:4.15928\ttrain-rmse:2.19893\n",
      "[3488]\teval-rmse:4.15828\ttrain-rmse:2.19878\n",
      "[3489]\teval-rmse:4.15553\ttrain-rmse:2.19883\n",
      "[3490]\teval-rmse:4.15382\ttrain-rmse:2.19891\n",
      "[3491]\teval-rmse:4.15276\ttrain-rmse:2.19896\n",
      "[3492]\teval-rmse:4.15362\ttrain-rmse:2.19895\n",
      "[3493]\teval-rmse:4.15275\ttrain-rmse:2.19884\n",
      "[3494]\teval-rmse:4.15104\ttrain-rmse:2.19892\n",
      "[3495]\teval-rmse:4.1531\ttrain-rmse:2.19887\n",
      "[3496]\teval-rmse:4.15112\ttrain-rmse:2.19833\n",
      "[3497]\teval-rmse:4.15139\ttrain-rmse:2.19831\n",
      "[3498]\teval-rmse:4.15226\ttrain-rmse:2.19829\n",
      "[3499]\teval-rmse:4.14924\ttrain-rmse:2.1983\n",
      "[3500]\teval-rmse:4.14727\ttrain-rmse:2.19836\n",
      "[3501]\teval-rmse:4.14746\ttrain-rmse:2.19835\n",
      "[3502]\teval-rmse:4.14814\ttrain-rmse:2.19833\n",
      "[3503]\teval-rmse:4.14732\ttrain-rmse:2.19825\n",
      "[3504]\teval-rmse:4.14572\ttrain-rmse:2.19833\n",
      "[3505]\teval-rmse:4.14381\ttrain-rmse:2.19844\n",
      "[3506]\teval-rmse:4.14202\ttrain-rmse:2.1985\n",
      "[3507]\teval-rmse:4.14481\ttrain-rmse:2.19833\n",
      "[3508]\teval-rmse:4.14595\ttrain-rmse:2.19825\n",
      "[3509]\teval-rmse:4.14693\ttrain-rmse:2.19821\n",
      "[3510]\teval-rmse:4.1493\ttrain-rmse:2.19808\n",
      "[3511]\teval-rmse:4.14761\ttrain-rmse:2.19813\n",
      "[3512]\teval-rmse:4.14543\ttrain-rmse:2.19816\n",
      "[3513]\teval-rmse:4.14538\ttrain-rmse:2.19816\n",
      "[3514]\teval-rmse:4.14355\ttrain-rmse:2.19823\n",
      "[3515]\teval-rmse:4.143\ttrain-rmse:2.19825\n",
      "[3516]\teval-rmse:4.14284\ttrain-rmse:2.19825\n",
      "[3517]\teval-rmse:4.14325\ttrain-rmse:2.19823\n",
      "[3518]\teval-rmse:4.14519\ttrain-rmse:2.19816\n",
      "[3519]\teval-rmse:4.14363\ttrain-rmse:2.19825\n",
      "[3520]\teval-rmse:4.14582\ttrain-rmse:2.19809\n",
      "[3521]\teval-rmse:4.14467\ttrain-rmse:2.19814\n",
      "[3522]\teval-rmse:4.14283\ttrain-rmse:2.19762\n",
      "[3523]\teval-rmse:4.13985\ttrain-rmse:2.19775\n",
      "[3524]\teval-rmse:4.14013\ttrain-rmse:2.19772\n",
      "[3525]\teval-rmse:4.13919\ttrain-rmse:2.19772\n",
      "[3526]\teval-rmse:4.13749\ttrain-rmse:2.19783\n",
      "[3527]\teval-rmse:4.13548\ttrain-rmse:2.19789\n",
      "[3528]\teval-rmse:4.13459\ttrain-rmse:2.19791\n",
      "[3529]\teval-rmse:4.13665\ttrain-rmse:2.19825\n",
      "[3530]\teval-rmse:4.13835\ttrain-rmse:2.19817\n",
      "[3531]\teval-rmse:4.1366\ttrain-rmse:2.19687\n",
      "[3532]\teval-rmse:4.13493\ttrain-rmse:2.19698\n",
      "[3533]\teval-rmse:4.13427\ttrain-rmse:2.19672\n",
      "[3534]\teval-rmse:4.13564\ttrain-rmse:2.19665\n",
      "[3535]\teval-rmse:4.13836\ttrain-rmse:2.19646\n",
      "[3536]\teval-rmse:4.13865\ttrain-rmse:2.19643\n",
      "[3537]\teval-rmse:4.1408\ttrain-rmse:2.19628\n",
      "[3538]\teval-rmse:4.13968\ttrain-rmse:2.19629\n",
      "[3539]\teval-rmse:4.14198\ttrain-rmse:2.19612\n",
      "[3540]\teval-rmse:4.14032\ttrain-rmse:2.19622\n",
      "[3541]\teval-rmse:4.14043\ttrain-rmse:2.19621\n",
      "[3542]\teval-rmse:4.14257\ttrain-rmse:2.19613\n",
      "[3543]\teval-rmse:4.14426\ttrain-rmse:2.19608\n",
      "[3544]\teval-rmse:4.14326\ttrain-rmse:2.19608\n",
      "[3545]\teval-rmse:4.14329\ttrain-rmse:2.19607\n",
      "[3546]\teval-rmse:4.14126\ttrain-rmse:2.19611\n",
      "[3547]\teval-rmse:4.14277\ttrain-rmse:2.19609\n",
      "[3548]\teval-rmse:4.14105\ttrain-rmse:2.19515\n",
      "[3549]\teval-rmse:4.14021\ttrain-rmse:2.1949\n",
      "[3550]\teval-rmse:4.13918\ttrain-rmse:2.19489\n",
      "[3551]\teval-rmse:4.13747\ttrain-rmse:2.19401\n",
      "[3552]\teval-rmse:4.13871\ttrain-rmse:2.19392\n",
      "[3553]\teval-rmse:4.13994\ttrain-rmse:2.19383\n",
      "[3554]\teval-rmse:4.14187\ttrain-rmse:2.19369\n",
      "[3555]\teval-rmse:4.1417\ttrain-rmse:2.19369\n",
      "[3556]\teval-rmse:4.14051\ttrain-rmse:2.19376\n",
      "[3557]\teval-rmse:4.1385\ttrain-rmse:2.19376\n",
      "[3558]\teval-rmse:4.14029\ttrain-rmse:2.1937\n",
      "[3559]\teval-rmse:4.14018\ttrain-rmse:2.1937\n",
      "[3560]\teval-rmse:4.14156\ttrain-rmse:2.19368\n",
      "[3561]\teval-rmse:4.13969\ttrain-rmse:2.19325\n",
      "[3562]\teval-rmse:4.13939\ttrain-rmse:2.19325\n",
      "[3563]\teval-rmse:4.14168\ttrain-rmse:2.19323\n",
      "[3564]\teval-rmse:4.13984\ttrain-rmse:2.19328\n",
      "[3565]\teval-rmse:4.14203\ttrain-rmse:2.19316\n",
      "[3566]\teval-rmse:4.14222\ttrain-rmse:2.19313\n",
      "[3567]\teval-rmse:4.14508\ttrain-rmse:2.19299\n",
      "[3568]\teval-rmse:4.14499\ttrain-rmse:2.19299\n",
      "[3569]\teval-rmse:4.14489\ttrain-rmse:2.19298\n",
      "[3570]\teval-rmse:4.14678\ttrain-rmse:2.19287\n",
      "[3571]\teval-rmse:4.14894\ttrain-rmse:2.19274\n",
      "[3572]\teval-rmse:4.15131\ttrain-rmse:2.19262\n",
      "[3573]\teval-rmse:4.14865\ttrain-rmse:2.19273\n",
      "[3574]\teval-rmse:4.14758\ttrain-rmse:2.19277\n",
      "[3575]\teval-rmse:4.14964\ttrain-rmse:2.19268\n",
      "[3576]\teval-rmse:4.14877\ttrain-rmse:2.19267\n",
      "[3577]\teval-rmse:4.15157\ttrain-rmse:2.19254\n",
      "[3578]\teval-rmse:4.14993\ttrain-rmse:2.19256\n",
      "[3579]\teval-rmse:4.14912\ttrain-rmse:2.19256\n",
      "[3580]\teval-rmse:4.1484\ttrain-rmse:2.19258\n",
      "[3581]\teval-rmse:4.14784\ttrain-rmse:2.19259\n",
      "[3582]\teval-rmse:4.14728\ttrain-rmse:2.19259\n",
      "[3583]\teval-rmse:4.15023\ttrain-rmse:2.19246\n",
      "[3584]\teval-rmse:4.15225\ttrain-rmse:2.19237\n",
      "[3585]\teval-rmse:4.15012\ttrain-rmse:2.19236\n",
      "[3586]\teval-rmse:4.152\ttrain-rmse:2.19227\n",
      "[3587]\teval-rmse:4.15477\ttrain-rmse:2.19217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3588]\teval-rmse:4.15386\ttrain-rmse:2.19218\n",
      "[3589]\teval-rmse:4.15228\ttrain-rmse:2.19224\n",
      "[3590]\teval-rmse:4.1504\ttrain-rmse:2.19229\n",
      "[3591]\teval-rmse:4.1532\ttrain-rmse:2.19217\n",
      "[3592]\teval-rmse:4.15463\ttrain-rmse:2.19218\n",
      "[3593]\teval-rmse:4.1557\ttrain-rmse:2.19219\n",
      "[3594]\teval-rmse:4.15372\ttrain-rmse:2.1922\n",
      "[3595]\teval-rmse:4.15285\ttrain-rmse:2.19187\n",
      "[3596]\teval-rmse:4.15489\ttrain-rmse:2.19223\n",
      "[3597]\teval-rmse:4.15311\ttrain-rmse:2.19131\n",
      "[3598]\teval-rmse:4.1551\ttrain-rmse:2.19124\n",
      "[3599]\teval-rmse:4.15355\ttrain-rmse:2.19125\n",
      "[3600]\teval-rmse:4.15555\ttrain-rmse:2.19117\n",
      "[3601]\teval-rmse:4.15469\ttrain-rmse:2.1912\n",
      "[3602]\teval-rmse:4.15554\ttrain-rmse:2.1912\n",
      "[3603]\teval-rmse:4.15644\ttrain-rmse:2.19119\n",
      "[3604]\teval-rmse:4.15666\ttrain-rmse:2.19118\n",
      "[3605]\teval-rmse:4.15582\ttrain-rmse:2.19085\n",
      "[3606]\teval-rmse:4.15772\ttrain-rmse:2.19079\n",
      "[3607]\teval-rmse:4.15964\ttrain-rmse:2.19079\n",
      "[3608]\teval-rmse:4.15942\ttrain-rmse:2.19079\n",
      "[3609]\teval-rmse:4.16114\ttrain-rmse:2.19074\n",
      "[3610]\teval-rmse:4.15907\ttrain-rmse:2.19026\n",
      "[3611]\teval-rmse:4.1575\ttrain-rmse:2.19026\n",
      "[3612]\teval-rmse:4.15949\ttrain-rmse:2.19021\n",
      "[3613]\teval-rmse:4.1604\ttrain-rmse:2.19021\n",
      "[3614]\teval-rmse:4.16243\ttrain-rmse:2.19016\n",
      "[3615]\teval-rmse:4.16062\ttrain-rmse:2.18973\n",
      "[3616]\teval-rmse:4.16239\ttrain-rmse:2.1897\n",
      "[3617]\teval-rmse:4.16462\ttrain-rmse:2.18964\n",
      "[3618]\teval-rmse:4.16625\ttrain-rmse:2.1896\n",
      "[3619]\teval-rmse:4.16848\ttrain-rmse:2.18965\n",
      "[3620]\teval-rmse:4.16649\ttrain-rmse:2.18965\n",
      "[3621]\teval-rmse:4.16565\ttrain-rmse:2.18965\n",
      "[3622]\teval-rmse:4.16279\ttrain-rmse:2.18961\n",
      "[3623]\teval-rmse:4.1618\ttrain-rmse:2.18933\n",
      "[3624]\teval-rmse:4.1631\ttrain-rmse:2.18934\n",
      "[3625]\teval-rmse:4.16602\ttrain-rmse:2.1893\n",
      "[3626]\teval-rmse:4.16269\ttrain-rmse:2.18925\n",
      "[3627]\teval-rmse:4.16139\ttrain-rmse:2.18923\n",
      "[3628]\teval-rmse:4.16223\ttrain-rmse:2.18925\n",
      "[3629]\teval-rmse:4.16282\ttrain-rmse:2.18926\n",
      "[3630]\teval-rmse:4.1627\ttrain-rmse:2.18925\n",
      "[3631]\teval-rmse:4.16406\ttrain-rmse:2.18927\n",
      "[3632]\teval-rmse:4.16543\ttrain-rmse:2.18925\n",
      "[3633]\teval-rmse:4.16322\ttrain-rmse:2.18927\n",
      "[3634]\teval-rmse:4.16202\ttrain-rmse:2.18928\n",
      "[3635]\teval-rmse:4.16106\ttrain-rmse:2.18926\n",
      "[3636]\teval-rmse:4.15876\ttrain-rmse:2.18924\n",
      "[3637]\teval-rmse:4.15763\ttrain-rmse:2.18925\n",
      "[3638]\teval-rmse:4.15787\ttrain-rmse:2.18925\n",
      "[3639]\teval-rmse:4.15582\ttrain-rmse:2.18873\n",
      "[3640]\teval-rmse:4.15376\ttrain-rmse:2.18877\n",
      "[3641]\teval-rmse:4.15197\ttrain-rmse:2.18784\n",
      "[3642]\teval-rmse:4.15299\ttrain-rmse:2.18784\n",
      "[3643]\teval-rmse:4.15193\ttrain-rmse:2.18782\n",
      "[3644]\teval-rmse:4.14992\ttrain-rmse:2.18779\n",
      "[3645]\teval-rmse:4.14728\ttrain-rmse:2.18788\n",
      "[3646]\teval-rmse:4.14634\ttrain-rmse:2.18775\n",
      "[3647]\teval-rmse:4.14777\ttrain-rmse:2.18774\n",
      "[3648]\teval-rmse:4.14575\ttrain-rmse:2.18776\n",
      "[3649]\teval-rmse:4.14464\ttrain-rmse:2.18779\n",
      "[3650]\teval-rmse:4.14563\ttrain-rmse:2.1878\n",
      "[3651]\teval-rmse:4.147\ttrain-rmse:2.18775\n",
      "[3652]\teval-rmse:4.14808\ttrain-rmse:2.18774\n",
      "[3653]\teval-rmse:4.15033\ttrain-rmse:2.18767\n",
      "[3654]\teval-rmse:4.15255\ttrain-rmse:2.18757\n",
      "[3655]\teval-rmse:4.15265\ttrain-rmse:2.18756\n",
      "[3656]\teval-rmse:4.15387\ttrain-rmse:2.18751\n",
      "[3657]\teval-rmse:4.15216\ttrain-rmse:2.18756\n",
      "[3658]\teval-rmse:4.15365\ttrain-rmse:2.18758\n",
      "[3659]\teval-rmse:4.15254\ttrain-rmse:2.1876\n",
      "[3660]\teval-rmse:4.15154\ttrain-rmse:2.18744\n",
      "[3661]\teval-rmse:4.14975\ttrain-rmse:2.18748\n",
      "[3662]\teval-rmse:4.14698\ttrain-rmse:2.1875\n",
      "[3663]\teval-rmse:4.14853\ttrain-rmse:2.18749\n",
      "[3664]\teval-rmse:4.15075\ttrain-rmse:2.18739\n",
      "[3665]\teval-rmse:4.14774\ttrain-rmse:2.18748\n",
      "[3666]\teval-rmse:4.14799\ttrain-rmse:2.18746\n",
      "[3667]\teval-rmse:4.14903\ttrain-rmse:2.18742\n",
      "[3668]\teval-rmse:4.14693\ttrain-rmse:2.18749\n",
      "[3669]\teval-rmse:4.14485\ttrain-rmse:2.18746\n",
      "[3670]\teval-rmse:4.14591\ttrain-rmse:2.18747\n",
      "[3671]\teval-rmse:4.14796\ttrain-rmse:2.18745\n",
      "[3672]\teval-rmse:4.15016\ttrain-rmse:2.18735\n",
      "[3673]\teval-rmse:4.14936\ttrain-rmse:2.18718\n",
      "[3674]\teval-rmse:4.1496\ttrain-rmse:2.18717\n",
      "[3675]\teval-rmse:4.15066\ttrain-rmse:2.18714\n",
      "[3676]\teval-rmse:4.15059\ttrain-rmse:2.18714\n",
      "[3677]\teval-rmse:4.14871\ttrain-rmse:2.18719\n",
      "[3678]\teval-rmse:4.15095\ttrain-rmse:2.18712\n",
      "[3679]\teval-rmse:4.14988\ttrain-rmse:2.1871\n",
      "[3680]\teval-rmse:4.15167\ttrain-rmse:2.1871\n",
      "[3681]\teval-rmse:4.1511\ttrain-rmse:2.18709\n",
      "[3682]\teval-rmse:4.15247\ttrain-rmse:2.18704\n",
      "[3683]\teval-rmse:4.1537\ttrain-rmse:2.18701\n",
      "[3684]\teval-rmse:4.15076\ttrain-rmse:2.187\n",
      "[3685]\teval-rmse:4.14923\ttrain-rmse:2.18704\n",
      "[3686]\teval-rmse:4.14762\ttrain-rmse:2.18708\n",
      "[3687]\teval-rmse:4.14854\ttrain-rmse:2.18708\n",
      "[3688]\teval-rmse:4.14676\ttrain-rmse:2.18712\n",
      "[3689]\teval-rmse:4.14661\ttrain-rmse:2.18712\n",
      "[3690]\teval-rmse:4.14839\ttrain-rmse:2.18707\n",
      "[3691]\teval-rmse:4.14752\ttrain-rmse:2.18709\n",
      "[3692]\teval-rmse:4.14944\ttrain-rmse:2.18708\n",
      "[3693]\teval-rmse:4.14935\ttrain-rmse:2.18708\n",
      "[3694]\teval-rmse:4.15097\ttrain-rmse:2.18708\n",
      "[3695]\teval-rmse:4.1491\ttrain-rmse:2.18589\n",
      "[3696]\teval-rmse:4.15072\ttrain-rmse:2.18589\n",
      "[3697]\teval-rmse:4.15298\ttrain-rmse:2.18584\n",
      "[3698]\teval-rmse:4.15487\ttrain-rmse:2.1858\n",
      "[3699]\teval-rmse:4.15369\ttrain-rmse:2.18577\n",
      "[3700]\teval-rmse:4.15521\ttrain-rmse:2.18579\n",
      "[3701]\teval-rmse:4.15622\ttrain-rmse:2.1858\n",
      "[3702]\teval-rmse:4.15426\ttrain-rmse:2.18578\n",
      "[3703]\teval-rmse:4.15197\ttrain-rmse:2.18582\n",
      "[3704]\teval-rmse:4.15045\ttrain-rmse:2.18585\n",
      "[3705]\teval-rmse:4.15229\ttrain-rmse:2.18579\n",
      "[3706]\teval-rmse:4.1505\ttrain-rmse:2.18537\n",
      "[3707]\teval-rmse:4.14749\ttrain-rmse:2.18535\n",
      "[3708]\teval-rmse:4.1464\ttrain-rmse:2.18538\n",
      "[3709]\teval-rmse:4.14918\ttrain-rmse:2.18539\n",
      "[3710]\teval-rmse:4.14691\ttrain-rmse:2.18539\n",
      "[3711]\teval-rmse:4.1443\ttrain-rmse:2.18548\n",
      "[3712]\teval-rmse:4.14335\ttrain-rmse:2.18536\n",
      "[3713]\teval-rmse:4.14445\ttrain-rmse:2.18536\n",
      "[3714]\teval-rmse:4.14252\ttrain-rmse:2.18496\n",
      "[3715]\teval-rmse:4.13972\ttrain-rmse:2.18498\n",
      "[3716]\teval-rmse:4.14248\ttrain-rmse:2.18488\n",
      "[3717]\teval-rmse:4.14082\ttrain-rmse:2.18493\n",
      "[3718]\teval-rmse:4.14199\ttrain-rmse:2.18489\n",
      "[3719]\teval-rmse:4.1411\ttrain-rmse:2.18492\n",
      "[3720]\teval-rmse:4.13963\ttrain-rmse:2.18497\n",
      "[3721]\teval-rmse:4.13844\ttrain-rmse:2.18501\n",
      "[3722]\teval-rmse:4.14155\ttrain-rmse:2.1849\n",
      "[3723]\teval-rmse:4.13975\ttrain-rmse:2.18496\n",
      "[3724]\teval-rmse:4.1387\ttrain-rmse:2.18495\n",
      "[3725]\teval-rmse:4.13944\ttrain-rmse:2.18494\n",
      "[3726]\teval-rmse:4.14178\ttrain-rmse:2.18481\n",
      "[3727]\teval-rmse:4.13969\ttrain-rmse:2.1848\n",
      "[3728]\teval-rmse:4.1388\ttrain-rmse:2.18449\n",
      "[3729]\teval-rmse:4.14159\ttrain-rmse:2.18436\n",
      "[3730]\teval-rmse:4.14156\ttrain-rmse:2.18436\n",
      "[3731]\teval-rmse:4.14049\ttrain-rmse:2.18434\n",
      "[3732]\teval-rmse:4.13975\ttrain-rmse:2.18436\n",
      "[3733]\teval-rmse:4.13784\ttrain-rmse:2.18438\n",
      "[3734]\teval-rmse:4.136\ttrain-rmse:2.18393\n",
      "[3735]\teval-rmse:4.13586\ttrain-rmse:2.18393\n",
      "[3736]\teval-rmse:4.13412\ttrain-rmse:2.18276\n",
      "[3737]\teval-rmse:4.13187\ttrain-rmse:2.18284\n",
      "[3738]\teval-rmse:4.13077\ttrain-rmse:2.18286\n",
      "[3739]\teval-rmse:4.13008\ttrain-rmse:2.18262\n",
      "[3740]\teval-rmse:4.132\ttrain-rmse:2.18253\n",
      "[3741]\teval-rmse:4.13293\ttrain-rmse:2.18252\n",
      "[3742]\teval-rmse:4.13482\ttrain-rmse:2.18241\n",
      "[3743]\teval-rmse:4.13632\ttrain-rmse:2.18239\n",
      "[3744]\teval-rmse:4.1384\ttrain-rmse:2.18232\n",
      "[3745]\teval-rmse:4.1403\ttrain-rmse:2.18231\n",
      "[3746]\teval-rmse:4.137\ttrain-rmse:2.18227\n",
      "[3747]\teval-rmse:4.13979\ttrain-rmse:2.18229\n",
      "[3748]\teval-rmse:4.13765\ttrain-rmse:2.18237\n",
      "[3749]\teval-rmse:4.13683\ttrain-rmse:2.18209\n",
      "[3750]\teval-rmse:4.13619\ttrain-rmse:2.18208\n",
      "[3751]\teval-rmse:4.13636\ttrain-rmse:2.18208\n",
      "[3752]\teval-rmse:4.13845\ttrain-rmse:2.18244\n",
      "[3753]\teval-rmse:4.13647\ttrain-rmse:2.18216\n",
      "[3754]\teval-rmse:4.13437\ttrain-rmse:2.18215\n",
      "[3755]\teval-rmse:4.13621\ttrain-rmse:2.18215\n",
      "[3756]\teval-rmse:4.13634\ttrain-rmse:2.18215\n",
      "[3757]\teval-rmse:4.13531\ttrain-rmse:2.18215\n",
      "[3758]\teval-rmse:4.13724\ttrain-rmse:2.18205\n",
      "[3759]\teval-rmse:4.13914\ttrain-rmse:2.18196\n",
      "[3760]\teval-rmse:4.14191\ttrain-rmse:2.18199\n",
      "[3761]\teval-rmse:4.13991\ttrain-rmse:2.18199\n",
      "[3762]\teval-rmse:4.13957\ttrain-rmse:2.18199\n",
      "[3763]\teval-rmse:4.14182\ttrain-rmse:2.18189\n",
      "[3764]\teval-rmse:4.13972\ttrain-rmse:2.18194\n",
      "[3765]\teval-rmse:4.13867\ttrain-rmse:2.18194\n",
      "[3766]\teval-rmse:4.13926\ttrain-rmse:2.18193\n",
      "[3767]\teval-rmse:4.13614\ttrain-rmse:2.18194\n",
      "[3768]\teval-rmse:4.13507\ttrain-rmse:2.18199\n",
      "[3769]\teval-rmse:4.13434\ttrain-rmse:2.18175\n",
      "[3770]\teval-rmse:4.13444\ttrain-rmse:2.18175\n",
      "[3771]\teval-rmse:4.1368\ttrain-rmse:2.18166\n",
      "[3772]\teval-rmse:4.13579\ttrain-rmse:2.18165\n",
      "[3773]\teval-rmse:4.13781\ttrain-rmse:2.18158\n",
      "[3774]\teval-rmse:4.1386\ttrain-rmse:2.18157\n",
      "[3775]\teval-rmse:4.14071\ttrain-rmse:2.18151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3776]\teval-rmse:4.13966\ttrain-rmse:2.18153\n",
      "[3777]\teval-rmse:4.13909\ttrain-rmse:2.18153\n",
      "[3778]\teval-rmse:4.13749\ttrain-rmse:2.1816\n",
      "[3779]\teval-rmse:4.13559\ttrain-rmse:2.18161\n",
      "[3780]\teval-rmse:4.13347\ttrain-rmse:2.18169\n",
      "[3781]\teval-rmse:4.13044\ttrain-rmse:2.18173\n",
      "[3782]\teval-rmse:4.13117\ttrain-rmse:2.18172\n",
      "[3783]\teval-rmse:4.13185\ttrain-rmse:2.18171\n",
      "[3784]\teval-rmse:4.13203\ttrain-rmse:2.18169\n",
      "[3785]\teval-rmse:4.1303\ttrain-rmse:2.18129\n",
      "[3786]\teval-rmse:4.13103\ttrain-rmse:2.18128\n",
      "[3787]\teval-rmse:4.13011\ttrain-rmse:2.18131\n",
      "[3788]\teval-rmse:4.12923\ttrain-rmse:2.18132\n",
      "[3789]\teval-rmse:4.12736\ttrain-rmse:2.18091\n",
      "[3790]\teval-rmse:4.12568\ttrain-rmse:2.18008\n",
      "[3791]\teval-rmse:4.12396\ttrain-rmse:2.17894\n",
      "[3792]\teval-rmse:4.12214\ttrain-rmse:2.17897\n",
      "[3793]\teval-rmse:4.12401\ttrain-rmse:2.17894\n",
      "[3794]\teval-rmse:4.12585\ttrain-rmse:2.17886\n",
      "[3795]\teval-rmse:4.12501\ttrain-rmse:2.17889\n",
      "[3796]\teval-rmse:4.12488\ttrain-rmse:2.17889\n",
      "[3797]\teval-rmse:4.1247\ttrain-rmse:2.17889\n",
      "[3798]\teval-rmse:4.12664\ttrain-rmse:2.17877\n",
      "[3799]\teval-rmse:4.12542\ttrain-rmse:2.17877\n",
      "[3800]\teval-rmse:4.1261\ttrain-rmse:2.17877\n",
      "[3801]\teval-rmse:4.12777\ttrain-rmse:2.17874\n",
      "[3802]\teval-rmse:4.12655\ttrain-rmse:2.17876\n",
      "[3803]\teval-rmse:4.1245\ttrain-rmse:2.17884\n",
      "[3804]\teval-rmse:4.12299\ttrain-rmse:2.17891\n",
      "[3805]\teval-rmse:4.12508\ttrain-rmse:2.17922\n",
      "[3806]\teval-rmse:4.1242\ttrain-rmse:2.17898\n",
      "[3807]\teval-rmse:4.12251\ttrain-rmse:2.17905\n",
      "[3808]\teval-rmse:4.12083\ttrain-rmse:2.17865\n",
      "[3809]\teval-rmse:4.11965\ttrain-rmse:2.17871\n",
      "[3810]\teval-rmse:4.11865\ttrain-rmse:2.17877\n",
      "[3811]\teval-rmse:4.12088\ttrain-rmse:2.17865\n",
      "[3812]\teval-rmse:4.12107\ttrain-rmse:2.17863\n",
      "[3813]\teval-rmse:4.12211\ttrain-rmse:2.17863\n",
      "[3814]\teval-rmse:4.12449\ttrain-rmse:2.17852\n",
      "[3815]\teval-rmse:4.12724\ttrain-rmse:2.17841\n",
      "[3816]\teval-rmse:4.12551\ttrain-rmse:2.17812\n",
      "[3817]\teval-rmse:4.12572\ttrain-rmse:2.1781\n",
      "[3818]\teval-rmse:4.12397\ttrain-rmse:2.17813\n",
      "[3819]\teval-rmse:4.12571\ttrain-rmse:2.17811\n",
      "[3820]\teval-rmse:4.12761\ttrain-rmse:2.178\n",
      "[3821]\teval-rmse:4.1275\ttrain-rmse:2.178\n",
      "[3822]\teval-rmse:4.12865\ttrain-rmse:2.17799\n",
      "[3823]\teval-rmse:4.13056\ttrain-rmse:2.17789\n",
      "[3824]\teval-rmse:4.13035\ttrain-rmse:2.17789\n",
      "[3825]\teval-rmse:4.13036\ttrain-rmse:2.17789\n",
      "[3826]\teval-rmse:4.12859\ttrain-rmse:2.17796\n",
      "[3827]\teval-rmse:4.13065\ttrain-rmse:2.17789\n",
      "[3828]\teval-rmse:4.12916\ttrain-rmse:2.1779\n",
      "[3829]\teval-rmse:4.12807\ttrain-rmse:2.17793\n",
      "[3830]\teval-rmse:4.13016\ttrain-rmse:2.17828\n",
      "[3831]\teval-rmse:4.12836\ttrain-rmse:2.1783\n",
      "[3832]\teval-rmse:4.12667\ttrain-rmse:2.17743\n",
      "[3833]\teval-rmse:4.12742\ttrain-rmse:2.17742\n",
      "[3834]\teval-rmse:4.1284\ttrain-rmse:2.17741\n",
      "[3835]\teval-rmse:4.12615\ttrain-rmse:2.17741\n",
      "[3836]\teval-rmse:4.12437\ttrain-rmse:2.17748\n",
      "[3837]\teval-rmse:4.12333\ttrain-rmse:2.17754\n",
      "[3838]\teval-rmse:4.12534\ttrain-rmse:2.17745\n",
      "[3839]\teval-rmse:4.12371\ttrain-rmse:2.1766\n",
      "[3840]\teval-rmse:4.12477\ttrain-rmse:2.17656\n",
      "[3841]\teval-rmse:4.12483\ttrain-rmse:2.17656\n",
      "[3842]\teval-rmse:4.12642\ttrain-rmse:2.1765\n",
      "[3843]\teval-rmse:4.12802\ttrain-rmse:2.17648\n",
      "[3844]\teval-rmse:4.12616\ttrain-rmse:2.17603\n",
      "[3845]\teval-rmse:4.12529\ttrain-rmse:2.17603\n",
      "[3846]\teval-rmse:4.12734\ttrain-rmse:2.17596\n",
      "[3847]\teval-rmse:4.12552\ttrain-rmse:2.17559\n",
      "[3848]\teval-rmse:4.12393\ttrain-rmse:2.17566\n",
      "[3849]\teval-rmse:4.12673\ttrain-rmse:2.17565\n",
      "[3850]\teval-rmse:4.12446\ttrain-rmse:2.17564\n",
      "[3851]\teval-rmse:4.12523\ttrain-rmse:2.17563\n",
      "[3852]\teval-rmse:4.12533\ttrain-rmse:2.17563\n",
      "[3853]\teval-rmse:4.12328\ttrain-rmse:2.17572\n",
      "[3854]\teval-rmse:4.12067\ttrain-rmse:2.17585\n",
      "[3855]\teval-rmse:4.11983\ttrain-rmse:2.17575\n",
      "[3856]\teval-rmse:4.12004\ttrain-rmse:2.17574\n",
      "[3857]\teval-rmse:4.12121\ttrain-rmse:2.17567\n",
      "[3858]\teval-rmse:4.12038\ttrain-rmse:2.17567\n",
      "[3859]\teval-rmse:4.12054\ttrain-rmse:2.17565\n",
      "[3860]\teval-rmse:4.12141\ttrain-rmse:2.17564\n",
      "[3861]\teval-rmse:4.12231\ttrain-rmse:2.17563\n",
      "[3862]\teval-rmse:4.12137\ttrain-rmse:2.17566\n",
      "[3863]\teval-rmse:4.12044\ttrain-rmse:2.17569\n",
      "[3864]\teval-rmse:4.11944\ttrain-rmse:2.1757\n",
      "[3865]\teval-rmse:4.12136\ttrain-rmse:2.17561\n",
      "[3866]\teval-rmse:4.1236\ttrain-rmse:2.17549\n",
      "[3867]\teval-rmse:4.12178\ttrain-rmse:2.17551\n",
      "[3868]\teval-rmse:4.12076\ttrain-rmse:2.17555\n",
      "[3869]\teval-rmse:4.12196\ttrain-rmse:2.17547\n",
      "[3870]\teval-rmse:4.12185\ttrain-rmse:2.17547\n",
      "[3871]\teval-rmse:4.11982\ttrain-rmse:2.1755\n",
      "[3872]\teval-rmse:4.1226\ttrain-rmse:2.1754\n",
      "[3873]\teval-rmse:4.12361\ttrain-rmse:2.17538\n",
      "[3874]\teval-rmse:4.12257\ttrain-rmse:2.17539\n",
      "[3875]\teval-rmse:4.12373\ttrain-rmse:2.17539\n",
      "[3876]\teval-rmse:4.1213\ttrain-rmse:2.17542\n",
      "[3877]\teval-rmse:4.12049\ttrain-rmse:2.17527\n",
      "[3878]\teval-rmse:4.11776\ttrain-rmse:2.17531\n",
      "[3879]\teval-rmse:4.11764\ttrain-rmse:2.17532\n",
      "[3880]\teval-rmse:4.11559\ttrain-rmse:2.1754\n",
      "[3881]\teval-rmse:4.11747\ttrain-rmse:2.17535\n",
      "[3882]\teval-rmse:4.11643\ttrain-rmse:2.17536\n",
      "[3883]\teval-rmse:4.11571\ttrain-rmse:2.17524\n",
      "[3884]\teval-rmse:4.1175\ttrain-rmse:2.17523\n",
      "[3885]\teval-rmse:4.11884\ttrain-rmse:2.17523\n",
      "[3886]\teval-rmse:4.11781\ttrain-rmse:2.17527\n",
      "[3887]\teval-rmse:4.11977\ttrain-rmse:2.17514\n",
      "[3888]\teval-rmse:4.11811\ttrain-rmse:2.17393\n",
      "[3889]\teval-rmse:4.11816\ttrain-rmse:2.17392\n",
      "[3890]\teval-rmse:4.11952\ttrain-rmse:2.17386\n",
      "[3891]\teval-rmse:4.11949\ttrain-rmse:2.17386\n",
      "[3892]\teval-rmse:4.12008\ttrain-rmse:2.17386\n",
      "[3893]\teval-rmse:4.12068\ttrain-rmse:2.17385\n",
      "[3894]\teval-rmse:4.11892\ttrain-rmse:2.17345\n",
      "[3895]\teval-rmse:4.11961\ttrain-rmse:2.17345\n",
      "[3896]\teval-rmse:4.12185\ttrain-rmse:2.17347\n",
      "[3897]\teval-rmse:4.11933\ttrain-rmse:2.17347\n",
      "[3898]\teval-rmse:4.12068\ttrain-rmse:2.17342\n",
      "[3899]\teval-rmse:4.12081\ttrain-rmse:2.17342\n",
      "[3900]\teval-rmse:4.12386\ttrain-rmse:2.17341\n",
      "[3901]\teval-rmse:4.1247\ttrain-rmse:2.17343\n",
      "[3902]\teval-rmse:4.12566\ttrain-rmse:2.17343\n",
      "[3903]\teval-rmse:4.12638\ttrain-rmse:2.17343\n",
      "[3904]\teval-rmse:4.12853\ttrain-rmse:2.17333\n",
      "[3905]\teval-rmse:4.12732\ttrain-rmse:2.17337\n",
      "[3906]\teval-rmse:4.12823\ttrain-rmse:2.17338\n",
      "[3907]\teval-rmse:4.13016\ttrain-rmse:2.17334\n",
      "[3908]\teval-rmse:4.12842\ttrain-rmse:2.17225\n",
      "[3909]\teval-rmse:4.12634\ttrain-rmse:2.17223\n",
      "[3910]\teval-rmse:4.12428\ttrain-rmse:2.17222\n",
      "[3911]\teval-rmse:4.12598\ttrain-rmse:2.17223\n",
      "[3912]\teval-rmse:4.12789\ttrain-rmse:2.17215\n",
      "[3913]\teval-rmse:4.1297\ttrain-rmse:2.17217\n",
      "[3914]\teval-rmse:4.12891\ttrain-rmse:2.17215\n",
      "[3915]\teval-rmse:4.13109\ttrain-rmse:2.17211\n",
      "[3916]\teval-rmse:4.12912\ttrain-rmse:2.17182\n",
      "[3917]\teval-rmse:4.12828\ttrain-rmse:2.17167\n",
      "[3918]\teval-rmse:4.12811\ttrain-rmse:2.17167\n",
      "[3919]\teval-rmse:4.12734\ttrain-rmse:2.17166\n",
      "[3920]\teval-rmse:4.12469\ttrain-rmse:2.17162\n",
      "[3921]\teval-rmse:4.12401\ttrain-rmse:2.17162\n",
      "[3922]\teval-rmse:4.12224\ttrain-rmse:2.17165\n",
      "[3923]\teval-rmse:4.12073\ttrain-rmse:2.17057\n",
      "[3924]\teval-rmse:4.12257\ttrain-rmse:2.17052\n",
      "[3925]\teval-rmse:4.12365\ttrain-rmse:2.17053\n",
      "[3926]\teval-rmse:4.12481\ttrain-rmse:2.17054\n",
      "[3927]\teval-rmse:4.12645\ttrain-rmse:2.17051\n",
      "[3928]\teval-rmse:4.12584\ttrain-rmse:2.1705\n",
      "[3929]\teval-rmse:4.128\ttrain-rmse:2.17041\n",
      "[3930]\teval-rmse:4.12787\ttrain-rmse:2.17041\n",
      "[3931]\teval-rmse:4.12859\ttrain-rmse:2.1704\n",
      "[3932]\teval-rmse:4.13019\ttrain-rmse:2.17043\n",
      "[3933]\teval-rmse:4.13289\ttrain-rmse:2.17033\n",
      "[3934]\teval-rmse:4.13187\ttrain-rmse:2.17033\n",
      "[3935]\teval-rmse:4.13286\ttrain-rmse:2.17032\n",
      "[3936]\teval-rmse:4.13133\ttrain-rmse:2.17035\n",
      "[3937]\teval-rmse:4.132\ttrain-rmse:2.17036\n",
      "[3938]\teval-rmse:4.13408\ttrain-rmse:2.17072\n",
      "[3939]\teval-rmse:4.13319\ttrain-rmse:2.17054\n",
      "[3940]\teval-rmse:4.13144\ttrain-rmse:2.16964\n",
      "[3941]\teval-rmse:4.13373\ttrain-rmse:2.16956\n",
      "[3942]\teval-rmse:4.13544\ttrain-rmse:2.16961\n",
      "[3943]\teval-rmse:4.1343\ttrain-rmse:2.16962\n",
      "[3944]\teval-rmse:4.13433\ttrain-rmse:2.16962\n",
      "[3945]\teval-rmse:4.13305\ttrain-rmse:2.16962\n",
      "[3946]\teval-rmse:4.13413\ttrain-rmse:2.16961\n",
      "[3947]\teval-rmse:4.13596\ttrain-rmse:2.16966\n",
      "[3948]\teval-rmse:4.13667\ttrain-rmse:2.16969\n",
      "[3949]\teval-rmse:4.13863\ttrain-rmse:2.16963\n",
      "[3950]\teval-rmse:4.13651\ttrain-rmse:2.16967\n",
      "[3951]\teval-rmse:4.13485\ttrain-rmse:2.16967\n",
      "[3952]\teval-rmse:4.13309\ttrain-rmse:2.16874\n",
      "[3953]\teval-rmse:4.13131\ttrain-rmse:2.16875\n",
      "[3954]\teval-rmse:4.13322\ttrain-rmse:2.16868\n",
      "[3955]\teval-rmse:4.13342\ttrain-rmse:2.16869\n",
      "[3956]\teval-rmse:4.13206\ttrain-rmse:2.16869\n",
      "[3957]\teval-rmse:4.13381\ttrain-rmse:2.16864\n",
      "[3958]\teval-rmse:4.13141\ttrain-rmse:2.16855\n",
      "[3959]\teval-rmse:4.13062\ttrain-rmse:2.16836\n",
      "[3960]\teval-rmse:4.13258\ttrain-rmse:2.16833\n",
      "[3961]\teval-rmse:4.13082\ttrain-rmse:2.16805\n",
      "[3962]\teval-rmse:4.13\ttrain-rmse:2.16803\n",
      "[3963]\teval-rmse:4.13207\ttrain-rmse:2.16802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3964]\teval-rmse:4.13032\ttrain-rmse:2.1668\n",
      "[3965]\teval-rmse:4.13128\ttrain-rmse:2.16683\n",
      "[3966]\teval-rmse:4.13361\ttrain-rmse:2.16683\n",
      "[3967]\teval-rmse:4.13249\ttrain-rmse:2.16681\n",
      "[3968]\teval-rmse:4.13064\ttrain-rmse:2.16672\n",
      "[3969]\teval-rmse:4.13271\ttrain-rmse:2.16707\n",
      "[3970]\teval-rmse:4.13059\ttrain-rmse:2.16703\n",
      "[3971]\teval-rmse:4.12948\ttrain-rmse:2.167\n",
      "[3972]\teval-rmse:4.1296\ttrain-rmse:2.16701\n",
      "[3973]\teval-rmse:4.12802\ttrain-rmse:2.16696\n",
      "[3974]\teval-rmse:4.12634\ttrain-rmse:2.16608\n",
      "[3975]\teval-rmse:4.12825\ttrain-rmse:2.16607\n",
      "[3976]\teval-rmse:4.12639\ttrain-rmse:2.16607\n",
      "[3977]\teval-rmse:4.12871\ttrain-rmse:2.16604\n",
      "[3978]\teval-rmse:4.12991\ttrain-rmse:2.16609\n",
      "[3979]\teval-rmse:4.13177\ttrain-rmse:2.16604\n",
      "[3980]\teval-rmse:4.13043\ttrain-rmse:2.16604\n",
      "[3981]\teval-rmse:4.12906\ttrain-rmse:2.16603\n",
      "[3982]\teval-rmse:4.12925\ttrain-rmse:2.16604\n",
      "[3983]\teval-rmse:4.13044\ttrain-rmse:2.16603\n",
      "[3984]\teval-rmse:4.13238\ttrain-rmse:2.16602\n",
      "[3985]\teval-rmse:4.13371\ttrain-rmse:2.16606\n",
      "[3986]\teval-rmse:4.13432\ttrain-rmse:2.16608\n",
      "[3987]\teval-rmse:4.13357\ttrain-rmse:2.16608\n",
      "[3988]\teval-rmse:4.13184\ttrain-rmse:2.16569\n",
      "[3989]\teval-rmse:4.12868\ttrain-rmse:2.16556\n",
      "[3990]\teval-rmse:4.1278\ttrain-rmse:2.16541\n",
      "[3991]\teval-rmse:4.12797\ttrain-rmse:2.16542\n",
      "[3992]\teval-rmse:4.12935\ttrain-rmse:2.16546\n",
      "[3993]\teval-rmse:4.12722\ttrain-rmse:2.16538\n",
      "[3994]\teval-rmse:4.12504\ttrain-rmse:2.16532\n",
      "[3995]\teval-rmse:4.12735\ttrain-rmse:2.16535\n",
      "[3996]\teval-rmse:4.12926\ttrain-rmse:2.1653\n",
      "[3997]\teval-rmse:4.13089\ttrain-rmse:2.16534\n",
      "[3998]\teval-rmse:4.13159\ttrain-rmse:2.16536\n",
      "[3999]\teval-rmse:4.13247\ttrain-rmse:2.16539\n",
      "[4000]\teval-rmse:4.13225\ttrain-rmse:2.16538\n",
      "[4001]\teval-rmse:4.13313\ttrain-rmse:2.16542\n",
      "[4002]\teval-rmse:4.13232\ttrain-rmse:2.16517\n",
      "[4003]\teval-rmse:4.13457\ttrain-rmse:2.16512\n",
      "[4004]\teval-rmse:4.13263\ttrain-rmse:2.16478\n",
      "[4005]\teval-rmse:4.1307\ttrain-rmse:2.16435\n",
      "[4006]\teval-rmse:4.12871\ttrain-rmse:2.16434\n",
      "[4007]\teval-rmse:4.13085\ttrain-rmse:2.16429\n",
      "[4008]\teval-rmse:4.13244\ttrain-rmse:2.16429\n",
      "[4009]\teval-rmse:4.13338\ttrain-rmse:2.16429\n",
      "[4010]\teval-rmse:4.13256\ttrain-rmse:2.16426\n",
      "[4011]\teval-rmse:4.13171\ttrain-rmse:2.16402\n",
      "[4012]\teval-rmse:4.13287\ttrain-rmse:2.16407\n",
      "[4013]\teval-rmse:4.13481\ttrain-rmse:2.16408\n",
      "[4014]\teval-rmse:4.13582\ttrain-rmse:2.16412\n",
      "[4015]\teval-rmse:4.13345\ttrain-rmse:2.16402\n",
      "[4016]\teval-rmse:4.13353\ttrain-rmse:2.16402\n",
      "[4017]\teval-rmse:4.13538\ttrain-rmse:2.1641\n",
      "[4018]\teval-rmse:4.13368\ttrain-rmse:2.16373\n",
      "[4019]\teval-rmse:4.13196\ttrain-rmse:2.16255\n",
      "[4020]\teval-rmse:4.13306\ttrain-rmse:2.16261\n",
      "[4021]\teval-rmse:4.13436\ttrain-rmse:2.16258\n",
      "[4022]\teval-rmse:4.13301\ttrain-rmse:2.16255\n",
      "[4023]\teval-rmse:4.13204\ttrain-rmse:2.16253\n",
      "[4024]\teval-rmse:4.13119\ttrain-rmse:2.16249\n",
      "[4025]\teval-rmse:4.13347\ttrain-rmse:2.16245\n",
      "[4026]\teval-rmse:4.13426\ttrain-rmse:2.16248\n",
      "[4027]\teval-rmse:4.13357\ttrain-rmse:2.16245\n",
      "[4028]\teval-rmse:4.13504\ttrain-rmse:2.16245\n",
      "[4029]\teval-rmse:4.13707\ttrain-rmse:2.16255\n",
      "[4030]\teval-rmse:4.13798\ttrain-rmse:2.1626\n",
      "[4031]\teval-rmse:4.13841\ttrain-rmse:2.16262\n",
      "[4032]\teval-rmse:4.13948\ttrain-rmse:2.16264\n",
      "[4033]\teval-rmse:4.13855\ttrain-rmse:2.1624\n",
      "[4034]\teval-rmse:4.14041\ttrain-rmse:2.16244\n",
      "[4035]\teval-rmse:4.14305\ttrain-rmse:2.1626\n",
      "[4036]\teval-rmse:4.14212\ttrain-rmse:2.16238\n",
      "[4037]\teval-rmse:4.14022\ttrain-rmse:2.16231\n",
      "[4038]\teval-rmse:4.13918\ttrain-rmse:2.16228\n",
      "[4039]\teval-rmse:4.13714\ttrain-rmse:2.16223\n",
      "[4040]\teval-rmse:4.13542\ttrain-rmse:2.16188\n",
      "[4041]\teval-rmse:4.13448\ttrain-rmse:2.16173\n",
      "[4042]\teval-rmse:4.1334\ttrain-rmse:2.16171\n",
      "[4043]\teval-rmse:4.13157\ttrain-rmse:2.16167\n",
      "[4044]\teval-rmse:4.12983\ttrain-rmse:2.16062\n",
      "[4045]\teval-rmse:4.13248\ttrain-rmse:2.16068\n",
      "[4046]\teval-rmse:4.13346\ttrain-rmse:2.16069\n",
      "[4047]\teval-rmse:4.13351\ttrain-rmse:2.16067\n",
      "[4048]\teval-rmse:4.13177\ttrain-rmse:2.15958\n",
      "[4049]\teval-rmse:4.13085\ttrain-rmse:2.15956\n",
      "[4050]\teval-rmse:4.12763\ttrain-rmse:2.15938\n",
      "[4051]\teval-rmse:4.12587\ttrain-rmse:2.15902\n",
      "[4052]\teval-rmse:4.12772\ttrain-rmse:2.15897\n",
      "[4053]\teval-rmse:4.13051\ttrain-rmse:2.159\n",
      "[4054]\teval-rmse:4.13227\ttrain-rmse:2.15902\n",
      "[4055]\teval-rmse:4.13114\ttrain-rmse:2.15899\n",
      "[4056]\teval-rmse:4.13094\ttrain-rmse:2.15898\n",
      "[4057]\teval-rmse:4.13079\ttrain-rmse:2.15897\n",
      "[4058]\teval-rmse:4.13182\ttrain-rmse:2.15902\n",
      "[4059]\teval-rmse:4.13105\ttrain-rmse:2.15888\n",
      "[4060]\teval-rmse:4.13232\ttrain-rmse:2.15886\n",
      "[4061]\teval-rmse:4.13494\ttrain-rmse:2.15891\n",
      "[4062]\teval-rmse:4.13211\ttrain-rmse:2.15875\n",
      "[4063]\teval-rmse:4.13046\ttrain-rmse:2.15786\n",
      "[4064]\teval-rmse:4.13176\ttrain-rmse:2.15783\n",
      "[4065]\teval-rmse:4.13\ttrain-rmse:2.15779\n",
      "[4066]\teval-rmse:4.12898\ttrain-rmse:2.15777\n",
      "[4067]\teval-rmse:4.1272\ttrain-rmse:2.15774\n",
      "[4068]\teval-rmse:4.12948\ttrain-rmse:2.1577\n",
      "[4069]\teval-rmse:4.13012\ttrain-rmse:2.15773\n",
      "[4070]\teval-rmse:4.13097\ttrain-rmse:2.15778\n",
      "[4071]\teval-rmse:4.13282\ttrain-rmse:2.15783\n",
      "[4072]\teval-rmse:4.13189\ttrain-rmse:2.15762\n",
      "[4073]\teval-rmse:4.13256\ttrain-rmse:2.15765\n",
      "[4074]\teval-rmse:4.13091\ttrain-rmse:2.15729\n",
      "[4075]\teval-rmse:4.13275\ttrain-rmse:2.15733\n",
      "[4076]\teval-rmse:4.13164\ttrain-rmse:2.15727\n",
      "[4077]\teval-rmse:4.13045\ttrain-rmse:2.15724\n",
      "[4078]\teval-rmse:4.13191\ttrain-rmse:2.15732\n",
      "[4079]\teval-rmse:4.13016\ttrain-rmse:2.15722\n",
      "[4080]\teval-rmse:4.13206\ttrain-rmse:2.1572\n",
      "[4081]\teval-rmse:4.13282\ttrain-rmse:2.15724\n",
      "[4082]\teval-rmse:4.13179\ttrain-rmse:2.15718\n",
      "[4083]\teval-rmse:4.12983\ttrain-rmse:2.15714\n",
      "[4084]\teval-rmse:4.12818\ttrain-rmse:2.15634\n",
      "[4085]\teval-rmse:4.12648\ttrain-rmse:2.15607\n",
      "[4086]\teval-rmse:4.12859\ttrain-rmse:2.15619\n",
      "[4087]\teval-rmse:4.12692\ttrain-rmse:2.15616\n",
      "[4088]\teval-rmse:4.12738\ttrain-rmse:2.15618\n",
      "[4089]\teval-rmse:4.12632\ttrain-rmse:2.15616\n",
      "[4090]\teval-rmse:4.12458\ttrain-rmse:2.15581\n",
      "[4091]\teval-rmse:4.12364\ttrain-rmse:2.15568\n",
      "[4092]\teval-rmse:4.1234\ttrain-rmse:2.15566\n",
      "[4093]\teval-rmse:4.12139\ttrain-rmse:2.15556\n",
      "[4094]\teval-rmse:4.11851\ttrain-rmse:2.15553\n",
      "[4095]\teval-rmse:4.11683\ttrain-rmse:2.15552\n",
      "[4096]\teval-rmse:4.11868\ttrain-rmse:2.15552\n",
      "[4097]\teval-rmse:4.12067\ttrain-rmse:2.15561\n",
      "[4098]\teval-rmse:4.12135\ttrain-rmse:2.15564\n",
      "[4099]\teval-rmse:4.11975\ttrain-rmse:2.15485\n",
      "[4100]\teval-rmse:4.12132\ttrain-rmse:2.15487\n",
      "[4101]\teval-rmse:4.12279\ttrain-rmse:2.15494\n",
      "[4102]\teval-rmse:4.12089\ttrain-rmse:2.15492\n",
      "[4103]\teval-rmse:4.11921\ttrain-rmse:2.1546\n",
      "[4104]\teval-rmse:4.12019\ttrain-rmse:2.1546\n",
      "[4105]\teval-rmse:4.12131\ttrain-rmse:2.15465\n",
      "[4106]\teval-rmse:4.12025\ttrain-rmse:2.15464\n",
      "[4107]\teval-rmse:4.12234\ttrain-rmse:2.15459\n",
      "[4108]\teval-rmse:4.11998\ttrain-rmse:2.15447\n",
      "[4109]\teval-rmse:4.12083\ttrain-rmse:2.15451\n",
      "[4110]\teval-rmse:4.11951\ttrain-rmse:2.15449\n",
      "[4111]\teval-rmse:4.11877\ttrain-rmse:2.15437\n",
      "[4112]\teval-rmse:4.11882\ttrain-rmse:2.15436\n",
      "[4113]\teval-rmse:4.11949\ttrain-rmse:2.15439\n",
      "[4114]\teval-rmse:4.11758\ttrain-rmse:2.15412\n",
      "[4115]\teval-rmse:4.11763\ttrain-rmse:2.15412\n",
      "[4116]\teval-rmse:4.11755\ttrain-rmse:2.15411\n",
      "[4117]\teval-rmse:4.11524\ttrain-rmse:2.15398\n",
      "[4118]\teval-rmse:4.11642\ttrain-rmse:2.15398\n",
      "[4119]\teval-rmse:4.11925\ttrain-rmse:2.15393\n",
      "[4120]\teval-rmse:4.12001\ttrain-rmse:2.15397\n",
      "[4121]\teval-rmse:4.11892\ttrain-rmse:2.15391\n",
      "[4122]\teval-rmse:4.11815\ttrain-rmse:2.15387\n",
      "[4123]\teval-rmse:4.12025\ttrain-rmse:2.15388\n",
      "[4124]\teval-rmse:4.12162\ttrain-rmse:2.15395\n",
      "[4125]\teval-rmse:4.12441\ttrain-rmse:2.154\n",
      "[4126]\teval-rmse:4.1253\ttrain-rmse:2.15405\n",
      "[4127]\teval-rmse:4.12378\ttrain-rmse:2.15401\n",
      "[4128]\teval-rmse:4.12107\ttrain-rmse:2.15396\n",
      "[4129]\teval-rmse:4.11987\ttrain-rmse:2.15394\n",
      "[4130]\teval-rmse:4.11871\ttrain-rmse:2.15392\n",
      "[4131]\teval-rmse:4.1185\ttrain-rmse:2.15391\n",
      "[4132]\teval-rmse:4.11942\ttrain-rmse:2.15396\n",
      "[4133]\teval-rmse:4.11735\ttrain-rmse:2.15394\n",
      "[4134]\teval-rmse:4.11551\ttrain-rmse:2.15385\n",
      "[4135]\teval-rmse:4.11716\ttrain-rmse:2.15388\n",
      "[4136]\teval-rmse:4.11801\ttrain-rmse:2.15393\n",
      "[4137]\teval-rmse:4.11981\ttrain-rmse:2.15403\n",
      "[4138]\teval-rmse:4.12064\ttrain-rmse:2.15408\n",
      "[4139]\teval-rmse:4.12186\ttrain-rmse:2.15414\n",
      "[4140]\teval-rmse:4.1239\ttrain-rmse:2.15446\n",
      "[4141]\teval-rmse:4.12297\ttrain-rmse:2.15444\n",
      "[4142]\teval-rmse:4.1236\ttrain-rmse:2.15447\n",
      "[4143]\teval-rmse:4.12279\ttrain-rmse:2.15442\n",
      "[4144]\teval-rmse:4.1242\ttrain-rmse:2.15451\n",
      "[4145]\teval-rmse:4.12687\ttrain-rmse:2.15457\n",
      "[4146]\teval-rmse:4.12498\ttrain-rmse:2.15452\n",
      "[4147]\teval-rmse:4.12676\ttrain-rmse:2.15464\n",
      "[4148]\teval-rmse:4.12879\ttrain-rmse:2.15499\n",
      "[4149]\teval-rmse:4.12788\ttrain-rmse:2.15493\n",
      "[4150]\teval-rmse:4.12886\ttrain-rmse:2.15499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4151]\teval-rmse:4.12668\ttrain-rmse:2.15494\n",
      "[4152]\teval-rmse:4.12364\ttrain-rmse:2.15478\n",
      "[4153]\teval-rmse:4.12167\ttrain-rmse:2.15468\n",
      "[4154]\teval-rmse:4.12371\ttrain-rmse:2.15465\n",
      "[4155]\teval-rmse:4.12453\ttrain-rmse:2.15466\n",
      "[4156]\teval-rmse:4.12622\ttrain-rmse:2.15475\n",
      "[4157]\teval-rmse:4.12537\ttrain-rmse:2.15454\n",
      "[4158]\teval-rmse:4.12515\ttrain-rmse:2.15452\n",
      "[4159]\teval-rmse:4.12364\ttrain-rmse:2.15452\n",
      "[4160]\teval-rmse:4.12208\ttrain-rmse:2.15356\n",
      "[4161]\teval-rmse:4.12039\ttrain-rmse:2.15322\n",
      "[4162]\teval-rmse:4.12307\ttrain-rmse:2.15327\n",
      "[4163]\teval-rmse:4.1239\ttrain-rmse:2.15332\n",
      "[4164]\teval-rmse:4.12472\ttrain-rmse:2.15337\n",
      "[4165]\teval-rmse:4.12649\ttrain-rmse:2.15341\n",
      "[4166]\teval-rmse:4.12627\ttrain-rmse:2.15339\n",
      "[4167]\teval-rmse:4.12455\ttrain-rmse:2.15255\n",
      "[4168]\teval-rmse:4.12343\ttrain-rmse:2.15252\n",
      "[4169]\teval-rmse:4.12115\ttrain-rmse:2.15237\n",
      "[4170]\teval-rmse:4.12037\ttrain-rmse:2.15218\n",
      "[4171]\teval-rmse:4.12239\ttrain-rmse:2.15253\n",
      "[4172]\teval-rmse:4.12333\ttrain-rmse:2.15259\n",
      "[4173]\teval-rmse:4.12474\ttrain-rmse:2.15262\n",
      "[4174]\teval-rmse:4.12304\ttrain-rmse:2.15259\n",
      "[4175]\teval-rmse:4.1211\ttrain-rmse:2.15223\n",
      "[4176]\teval-rmse:4.11821\ttrain-rmse:2.15209\n",
      "[4177]\teval-rmse:4.11635\ttrain-rmse:2.15199\n",
      "[4178]\teval-rmse:4.11392\ttrain-rmse:2.15188\n",
      "[4179]\teval-rmse:4.11124\ttrain-rmse:2.15186\n",
      "[4180]\teval-rmse:4.11191\ttrain-rmse:2.15186\n",
      "[4181]\teval-rmse:4.11478\ttrain-rmse:2.15188\n",
      "[4182]\teval-rmse:4.11576\ttrain-rmse:2.15191\n",
      "[4183]\teval-rmse:4.11676\ttrain-rmse:2.15191\n",
      "[4184]\teval-rmse:4.11467\ttrain-rmse:2.15181\n",
      "[4185]\teval-rmse:4.11259\ttrain-rmse:2.15172\n",
      "[4186]\teval-rmse:4.11248\ttrain-rmse:2.15171\n",
      "[4187]\teval-rmse:4.1138\ttrain-rmse:2.15167\n",
      "[4188]\teval-rmse:4.11597\ttrain-rmse:2.15177\n",
      "[4189]\teval-rmse:4.11867\ttrain-rmse:2.15182\n",
      "[4190]\teval-rmse:4.1167\ttrain-rmse:2.15179\n",
      "[4191]\teval-rmse:4.11846\ttrain-rmse:2.15181\n",
      "[4192]\teval-rmse:4.1193\ttrain-rmse:2.15185\n",
      "[4193]\teval-rmse:4.1202\ttrain-rmse:2.1519\n",
      "[4194]\teval-rmse:4.11724\ttrain-rmse:2.15175\n",
      "[4195]\teval-rmse:4.11768\ttrain-rmse:2.15177\n",
      "[4196]\teval-rmse:4.116\ttrain-rmse:2.15169\n",
      "[4197]\teval-rmse:4.11527\ttrain-rmse:2.15166\n",
      "[4198]\teval-rmse:4.1126\ttrain-rmse:2.15153\n",
      "[4199]\teval-rmse:4.11042\ttrain-rmse:2.15152\n",
      "[4200]\teval-rmse:4.10756\ttrain-rmse:2.15141\n",
      "[4201]\teval-rmse:4.10905\ttrain-rmse:2.15146\n",
      "[4202]\teval-rmse:4.10989\ttrain-rmse:2.15148\n",
      "[4203]\teval-rmse:4.11065\ttrain-rmse:2.15151\n",
      "[4204]\teval-rmse:4.10898\ttrain-rmse:2.15127\n",
      "[4205]\teval-rmse:4.10878\ttrain-rmse:2.15126\n",
      "[4206]\teval-rmse:4.10696\ttrain-rmse:2.151\n",
      "[4207]\teval-rmse:4.10525\ttrain-rmse:2.15101\n",
      "[4208]\teval-rmse:4.10711\ttrain-rmse:2.15099\n",
      "[4209]\teval-rmse:4.10987\ttrain-rmse:2.15101\n",
      "[4210]\teval-rmse:4.11062\ttrain-rmse:2.15104\n",
      "[4211]\teval-rmse:4.1125\ttrain-rmse:2.15111\n",
      "[4212]\teval-rmse:4.11039\ttrain-rmse:2.15103\n",
      "[4213]\teval-rmse:4.11245\ttrain-rmse:2.1511\n",
      "[4214]\teval-rmse:4.11016\ttrain-rmse:2.15099\n",
      "[4215]\teval-rmse:4.1085\ttrain-rmse:2.15019\n",
      "[4216]\teval-rmse:4.10657\ttrain-rmse:2.15018\n",
      "[4217]\teval-rmse:4.10584\ttrain-rmse:2.15002\n",
      "[4218]\teval-rmse:4.10844\ttrain-rmse:2.15011\n",
      "[4219]\teval-rmse:4.10772\ttrain-rmse:2.15008\n",
      "[4220]\teval-rmse:4.10506\ttrain-rmse:2.15008\n",
      "[4221]\teval-rmse:4.1069\ttrain-rmse:2.15002\n",
      "[4222]\teval-rmse:4.1085\ttrain-rmse:2.15008\n",
      "[4223]\teval-rmse:4.10758\ttrain-rmse:2.15007\n",
      "[4224]\teval-rmse:4.10811\ttrain-rmse:2.15008\n",
      "[4225]\teval-rmse:4.10717\ttrain-rmse:2.15007\n",
      "[4226]\teval-rmse:4.10995\ttrain-rmse:2.1501\n",
      "[4227]\teval-rmse:4.10832\ttrain-rmse:2.14907\n",
      "[4228]\teval-rmse:4.10668\ttrain-rmse:2.14875\n",
      "[4229]\teval-rmse:4.10465\ttrain-rmse:2.14867\n",
      "[4230]\teval-rmse:4.10302\ttrain-rmse:2.14773\n",
      "[4231]\teval-rmse:4.10155\ttrain-rmse:2.14681\n",
      "[4232]\teval-rmse:4.10164\ttrain-rmse:2.14681\n",
      "[4233]\teval-rmse:4.10322\ttrain-rmse:2.14687\n",
      "[4234]\teval-rmse:4.10216\ttrain-rmse:2.14686\n",
      "[4235]\teval-rmse:4.10216\ttrain-rmse:2.14685\n",
      "[4236]\teval-rmse:4.10022\ttrain-rmse:2.14675\n",
      "[4237]\teval-rmse:4.10187\ttrain-rmse:2.14681\n",
      "[4238]\teval-rmse:4.10452\ttrain-rmse:2.14681\n",
      "[4239]\teval-rmse:4.10604\ttrain-rmse:2.14682\n",
      "[4240]\teval-rmse:4.10755\ttrain-rmse:2.1469\n",
      "[4241]\teval-rmse:4.1096\ttrain-rmse:2.14691\n",
      "[4242]\teval-rmse:4.11156\ttrain-rmse:2.14687\n",
      "[4243]\teval-rmse:4.11202\ttrain-rmse:2.14689\n",
      "[4244]\teval-rmse:4.11287\ttrain-rmse:2.14686\n",
      "[4245]\teval-rmse:4.11103\ttrain-rmse:2.14651\n",
      "[4246]\teval-rmse:4.10984\ttrain-rmse:2.14648\n",
      "[4247]\teval-rmse:4.1075\ttrain-rmse:2.14634\n",
      "[4248]\teval-rmse:4.10594\ttrain-rmse:2.14603\n",
      "[4249]\teval-rmse:4.10592\ttrain-rmse:2.14602\n",
      "[4250]\teval-rmse:4.10695\ttrain-rmse:2.14607\n",
      "[4251]\teval-rmse:4.10736\ttrain-rmse:2.14608\n",
      "[4252]\teval-rmse:4.10532\ttrain-rmse:2.14606\n",
      "[4253]\teval-rmse:4.10693\ttrain-rmse:2.14603\n",
      "[4254]\teval-rmse:4.10564\ttrain-rmse:2.14602\n",
      "[4255]\teval-rmse:4.10705\ttrain-rmse:2.14603\n",
      "[4256]\teval-rmse:4.10628\ttrain-rmse:2.146\n",
      "[4257]\teval-rmse:4.10344\ttrain-rmse:2.14587\n",
      "[4258]\teval-rmse:4.10533\ttrain-rmse:2.14595\n",
      "[4259]\teval-rmse:4.10525\ttrain-rmse:2.14595\n",
      "[4260]\teval-rmse:4.10584\ttrain-rmse:2.14597\n",
      "[4261]\teval-rmse:4.10428\ttrain-rmse:2.14568\n",
      "[4262]\teval-rmse:4.10164\ttrain-rmse:2.14556\n",
      "[4263]\teval-rmse:4.10221\ttrain-rmse:2.14558\n",
      "[4264]\teval-rmse:4.10099\ttrain-rmse:2.14557\n",
      "[4265]\teval-rmse:4.09917\ttrain-rmse:2.14556\n",
      "[4266]\teval-rmse:4.10102\ttrain-rmse:2.14564\n",
      "[4267]\teval-rmse:4.10191\ttrain-rmse:2.14567\n",
      "[4268]\teval-rmse:4.10411\ttrain-rmse:2.14568\n",
      "[4269]\teval-rmse:4.10564\ttrain-rmse:2.14569\n",
      "[4270]\teval-rmse:4.10503\ttrain-rmse:2.14565\n",
      "[4271]\teval-rmse:4.10219\ttrain-rmse:2.14563\n",
      "[4272]\teval-rmse:4.10156\ttrain-rmse:2.14561\n",
      "[4273]\teval-rmse:4.10077\ttrain-rmse:2.14557\n",
      "[4274]\teval-rmse:4.10188\ttrain-rmse:2.14562\n",
      "[4275]\teval-rmse:4.10229\ttrain-rmse:2.14563\n",
      "[4276]\teval-rmse:4.10317\ttrain-rmse:2.14559\n",
      "[4277]\teval-rmse:4.10291\ttrain-rmse:2.14558\n",
      "[4278]\teval-rmse:4.10396\ttrain-rmse:2.14562\n",
      "[4279]\teval-rmse:4.1028\ttrain-rmse:2.1456\n",
      "[4280]\teval-rmse:4.10209\ttrain-rmse:2.14544\n",
      "[4281]\teval-rmse:4.09968\ttrain-rmse:2.14531\n",
      "[4282]\teval-rmse:4.10149\ttrain-rmse:2.14531\n",
      "[4283]\teval-rmse:4.10049\ttrain-rmse:2.1453\n",
      "[4284]\teval-rmse:4.09843\ttrain-rmse:2.14533\n",
      "[4285]\teval-rmse:4.09922\ttrain-rmse:2.14536\n",
      "[4286]\teval-rmse:4.10032\ttrain-rmse:2.1454\n",
      "[4287]\teval-rmse:4.1012\ttrain-rmse:2.14544\n",
      "[4288]\teval-rmse:4.10105\ttrain-rmse:2.14544\n",
      "[4289]\teval-rmse:4.10238\ttrain-rmse:2.14551\n",
      "[4290]\teval-rmse:4.10512\ttrain-rmse:2.14552\n",
      "[4291]\teval-rmse:4.10614\ttrain-rmse:2.14557\n",
      "[4292]\teval-rmse:4.1046\ttrain-rmse:2.14481\n",
      "[4293]\teval-rmse:4.10278\ttrain-rmse:2.14446\n",
      "[4294]\teval-rmse:4.10447\ttrain-rmse:2.14456\n",
      "[4295]\teval-rmse:4.10375\ttrain-rmse:2.14444\n",
      "[4296]\teval-rmse:4.1029\ttrain-rmse:2.1444\n",
      "[4297]\teval-rmse:4.10077\ttrain-rmse:2.14437\n",
      "[4298]\teval-rmse:4.1026\ttrain-rmse:2.14438\n",
      "[4299]\teval-rmse:4.10367\ttrain-rmse:2.14433\n",
      "[4300]\teval-rmse:4.10466\ttrain-rmse:2.14439\n",
      "[4301]\teval-rmse:4.10296\ttrain-rmse:2.14429\n",
      "[4302]\teval-rmse:4.10265\ttrain-rmse:2.14427\n",
      "[4303]\teval-rmse:4.10333\ttrain-rmse:2.14431\n",
      "[4304]\teval-rmse:4.10148\ttrain-rmse:2.144\n",
      "[4305]\teval-rmse:4.09968\ttrain-rmse:2.14369\n",
      "[4306]\teval-rmse:4.10178\ttrain-rmse:2.14371\n",
      "[4307]\teval-rmse:4.0996\ttrain-rmse:2.14368\n",
      "[4308]\teval-rmse:4.09801\ttrain-rmse:2.14294\n",
      "[4309]\teval-rmse:4.0978\ttrain-rmse:2.14293\n",
      "[4310]\teval-rmse:4.09828\ttrain-rmse:2.14296\n",
      "[4311]\teval-rmse:4.10094\ttrain-rmse:2.14298\n",
      "[4312]\teval-rmse:4.10009\ttrain-rmse:2.14279\n",
      "[4313]\teval-rmse:4.10015\ttrain-rmse:2.1428\n",
      "[4314]\teval-rmse:4.09905\ttrain-rmse:2.14273\n",
      "[4315]\teval-rmse:4.1001\ttrain-rmse:2.1428\n",
      "[4316]\teval-rmse:4.09942\ttrain-rmse:2.14276\n",
      "[4317]\teval-rmse:4.10015\ttrain-rmse:2.1428\n",
      "[4318]\teval-rmse:4.1\ttrain-rmse:2.14279\n",
      "[4319]\teval-rmse:4.10175\ttrain-rmse:2.14289\n",
      "[4320]\teval-rmse:4.10035\ttrain-rmse:2.14287\n",
      "[4321]\teval-rmse:4.10167\ttrain-rmse:2.14294\n",
      "[4322]\teval-rmse:4.10245\ttrain-rmse:2.14294\n",
      "[4323]\teval-rmse:4.10164\ttrain-rmse:2.14277\n",
      "[4324]\teval-rmse:4.09933\ttrain-rmse:2.14273\n",
      "[4325]\teval-rmse:4.10117\ttrain-rmse:2.14268\n",
      "[4326]\teval-rmse:4.10105\ttrain-rmse:2.14267\n",
      "[4327]\teval-rmse:4.10034\ttrain-rmse:2.14257\n",
      "[4328]\teval-rmse:4.10113\ttrain-rmse:2.14261\n",
      "[4329]\teval-rmse:4.10222\ttrain-rmse:2.14268\n",
      "[4330]\teval-rmse:4.10349\ttrain-rmse:2.14277\n",
      "[4331]\teval-rmse:4.10552\ttrain-rmse:2.14309\n",
      "[4332]\teval-rmse:4.10734\ttrain-rmse:2.14305\n",
      "[4333]\teval-rmse:4.1086\ttrain-rmse:2.14301\n",
      "[4334]\teval-rmse:4.10837\ttrain-rmse:2.14299\n",
      "[4335]\teval-rmse:4.11031\ttrain-rmse:2.14305\n",
      "[4336]\teval-rmse:4.10911\ttrain-rmse:2.14301\n",
      "[4337]\teval-rmse:4.10824\ttrain-rmse:2.14295\n",
      "[4338]\teval-rmse:4.10806\ttrain-rmse:2.14293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4339]\teval-rmse:4.10629\ttrain-rmse:2.14283\n",
      "[4340]\teval-rmse:4.10365\ttrain-rmse:2.14277\n",
      "[4341]\teval-rmse:4.10575\ttrain-rmse:2.14281\n",
      "[4342]\teval-rmse:4.10677\ttrain-rmse:2.14283\n",
      "[4343]\teval-rmse:4.10487\ttrain-rmse:2.14271\n",
      "[4344]\teval-rmse:4.1069\ttrain-rmse:2.14302\n",
      "[4345]\teval-rmse:4.10482\ttrain-rmse:2.14298\n",
      "[4346]\teval-rmse:4.10569\ttrain-rmse:2.14303\n",
      "[4347]\teval-rmse:4.10546\ttrain-rmse:2.14302\n",
      "[4348]\teval-rmse:4.10273\ttrain-rmse:2.14296\n",
      "[4349]\teval-rmse:4.10448\ttrain-rmse:2.14298\n",
      "[4350]\teval-rmse:4.10266\ttrain-rmse:2.14288\n",
      "[4351]\teval-rmse:4.10061\ttrain-rmse:2.14276\n",
      "[4352]\teval-rmse:4.09992\ttrain-rmse:2.14262\n",
      "[4353]\teval-rmse:4.10033\ttrain-rmse:2.14264\n",
      "[4354]\teval-rmse:4.09861\ttrain-rmse:2.14261\n",
      "[4355]\teval-rmse:4.09792\ttrain-rmse:2.14257\n",
      "[4356]\teval-rmse:4.1007\ttrain-rmse:2.14251\n",
      "[4357]\teval-rmse:4.09942\ttrain-rmse:2.14249\n",
      "[4358]\teval-rmse:4.09858\ttrain-rmse:2.14233\n",
      "[4359]\teval-rmse:4.09673\ttrain-rmse:2.14208\n",
      "[4360]\teval-rmse:4.09761\ttrain-rmse:2.14213\n",
      "[4361]\teval-rmse:4.09965\ttrain-rmse:2.14245\n",
      "[4362]\teval-rmse:4.1003\ttrain-rmse:2.14249\n",
      "[4363]\teval-rmse:4.09736\ttrain-rmse:2.14237\n",
      "[4364]\teval-rmse:4.09939\ttrain-rmse:2.1427\n",
      "[4365]\teval-rmse:4.0978\ttrain-rmse:2.14202\n",
      "[4366]\teval-rmse:4.09861\ttrain-rmse:2.14206\n",
      "[4367]\teval-rmse:4.10035\ttrain-rmse:2.14207\n",
      "[4368]\teval-rmse:4.10122\ttrain-rmse:2.14208\n",
      "[4369]\teval-rmse:4.10188\ttrain-rmse:2.14212\n",
      "[4370]\teval-rmse:4.10399\ttrain-rmse:2.14225\n",
      "[4371]\teval-rmse:4.10216\ttrain-rmse:2.14213\n",
      "[4372]\teval-rmse:4.10155\ttrain-rmse:2.14197\n",
      "[4373]\teval-rmse:4.09973\ttrain-rmse:2.14187\n",
      "[4374]\teval-rmse:4.09979\ttrain-rmse:2.14187\n",
      "[4375]\teval-rmse:4.10241\ttrain-rmse:2.1419\n",
      "[4376]\teval-rmse:4.10164\ttrain-rmse:2.14172\n",
      "[4377]\teval-rmse:4.10251\ttrain-rmse:2.14177\n",
      "[4378]\teval-rmse:4.10045\ttrain-rmse:2.14177\n",
      "[4379]\teval-rmse:4.09775\ttrain-rmse:2.14162\n",
      "[4380]\teval-rmse:4.09569\ttrain-rmse:2.1416\n",
      "[4381]\teval-rmse:4.09731\ttrain-rmse:2.14161\n",
      "[4382]\teval-rmse:4.09742\ttrain-rmse:2.14161\n",
      "[4383]\teval-rmse:4.09452\ttrain-rmse:2.14148\n",
      "[4384]\teval-rmse:4.09367\ttrain-rmse:2.14144\n",
      "[4385]\teval-rmse:4.09263\ttrain-rmse:2.1414\n",
      "[4386]\teval-rmse:4.09322\ttrain-rmse:2.14139\n",
      "[4387]\teval-rmse:4.09198\ttrain-rmse:2.14133\n",
      "[4388]\teval-rmse:4.09115\ttrain-rmse:2.1413\n",
      "[4389]\teval-rmse:4.0928\ttrain-rmse:2.14131\n",
      "[4390]\teval-rmse:4.0918\ttrain-rmse:2.1413\n",
      "[4391]\teval-rmse:4.09066\ttrain-rmse:2.14129\n",
      "[4392]\teval-rmse:4.092\ttrain-rmse:2.14129\n",
      "[4393]\teval-rmse:4.0948\ttrain-rmse:2.1413\n",
      "[4394]\teval-rmse:4.09654\ttrain-rmse:2.14132\n",
      "[4395]\teval-rmse:4.09739\ttrain-rmse:2.14136\n",
      "[4396]\teval-rmse:4.09943\ttrain-rmse:2.14148\n",
      "[4397]\teval-rmse:4.09735\ttrain-rmse:2.14145\n",
      "[4398]\teval-rmse:4.09724\ttrain-rmse:2.14144\n",
      "[4399]\teval-rmse:4.09705\ttrain-rmse:2.14143\n",
      "[4400]\teval-rmse:4.09515\ttrain-rmse:2.14141\n",
      "[4401]\teval-rmse:4.09301\ttrain-rmse:2.14139\n",
      "[4402]\teval-rmse:4.09016\ttrain-rmse:2.14127\n",
      "[4403]\teval-rmse:4.08903\ttrain-rmse:2.14126\n",
      "[4404]\teval-rmse:4.09087\ttrain-rmse:2.14133\n",
      "[4405]\teval-rmse:4.09363\ttrain-rmse:2.14134\n",
      "[4406]\teval-rmse:4.09296\ttrain-rmse:2.14131\n",
      "[4407]\teval-rmse:4.09471\ttrain-rmse:2.14131\n",
      "[4408]\teval-rmse:4.09302\ttrain-rmse:2.14129\n",
      "[4409]\teval-rmse:4.09017\ttrain-rmse:2.14119\n",
      "[4410]\teval-rmse:4.08837\ttrain-rmse:2.14094\n",
      "[4411]\teval-rmse:4.0895\ttrain-rmse:2.14094\n",
      "[4412]\teval-rmse:4.09162\ttrain-rmse:2.14123\n",
      "[4413]\teval-rmse:4.08913\ttrain-rmse:2.14115\n",
      "[4414]\teval-rmse:4.09109\ttrain-rmse:2.14114\n",
      "[4415]\teval-rmse:4.09307\ttrain-rmse:2.14107\n",
      "[4416]\teval-rmse:4.09409\ttrain-rmse:2.14111\n",
      "[4417]\teval-rmse:4.09605\ttrain-rmse:2.14112\n",
      "[4418]\teval-rmse:4.09713\ttrain-rmse:2.14115\n",
      "[4419]\teval-rmse:4.09644\ttrain-rmse:2.14107\n",
      "[4420]\teval-rmse:4.09578\ttrain-rmse:2.14095\n",
      "[4421]\teval-rmse:4.09798\ttrain-rmse:2.1409\n",
      "[4422]\teval-rmse:4.09901\ttrain-rmse:2.14086\n",
      "[4423]\teval-rmse:4.09824\ttrain-rmse:2.14067\n",
      "[4424]\teval-rmse:4.09812\ttrain-rmse:2.14067\n",
      "[4425]\teval-rmse:4.09796\ttrain-rmse:2.14066\n",
      "[4426]\teval-rmse:4.10058\ttrain-rmse:2.14062\n",
      "[4427]\teval-rmse:4.09941\ttrain-rmse:2.1406\n",
      "[4428]\teval-rmse:4.10016\ttrain-rmse:2.14064\n",
      "[4429]\teval-rmse:4.09931\ttrain-rmse:2.14045\n",
      "[4430]\teval-rmse:4.09996\ttrain-rmse:2.14049\n",
      "[4431]\teval-rmse:4.10218\ttrain-rmse:2.14062\n",
      "[4432]\teval-rmse:4.10489\ttrain-rmse:2.14067\n",
      "[4433]\teval-rmse:4.1032\ttrain-rmse:2.14057\n",
      "[4434]\teval-rmse:4.10152\ttrain-rmse:2.14053\n",
      "[4435]\teval-rmse:4.10402\ttrain-rmse:2.14058\n",
      "[4436]\teval-rmse:4.10471\ttrain-rmse:2.14062\n",
      "[4437]\teval-rmse:4.10649\ttrain-rmse:2.14073\n",
      "[4438]\teval-rmse:4.10902\ttrain-rmse:2.14071\n",
      "[4439]\teval-rmse:4.111\ttrain-rmse:2.14077\n",
      "[4440]\teval-rmse:4.11322\ttrain-rmse:2.14077\n",
      "[4441]\teval-rmse:4.115\ttrain-rmse:2.1409\n",
      "[4442]\teval-rmse:4.11512\ttrain-rmse:2.14091\n",
      "[4443]\teval-rmse:4.11285\ttrain-rmse:2.14081\n",
      "[4444]\teval-rmse:4.11122\ttrain-rmse:2.1405\n",
      "[4445]\teval-rmse:4.10911\ttrain-rmse:2.14035\n",
      "[4446]\teval-rmse:4.10718\ttrain-rmse:2.14022\n",
      "[4447]\teval-rmse:4.10529\ttrain-rmse:2.14011\n",
      "[4448]\teval-rmse:4.1063\ttrain-rmse:2.14017\n",
      "[4449]\teval-rmse:4.10348\ttrain-rmse:2.14\n",
      "[4450]\teval-rmse:4.10618\ttrain-rmse:2.13998\n",
      "[4451]\teval-rmse:4.10395\ttrain-rmse:2.13992\n",
      "[4452]\teval-rmse:4.10548\ttrain-rmse:2.13996\n",
      "[4453]\teval-rmse:4.10371\ttrain-rmse:2.13993\n",
      "[4454]\teval-rmse:4.10568\ttrain-rmse:2.13998\n",
      "[4455]\teval-rmse:4.10367\ttrain-rmse:2.13986\n",
      "[4456]\teval-rmse:4.10208\ttrain-rmse:2.13963\n",
      "[4457]\teval-rmse:4.10367\ttrain-rmse:2.13965\n",
      "[4458]\teval-rmse:4.1056\ttrain-rmse:2.13969\n",
      "[4459]\teval-rmse:4.10473\ttrain-rmse:2.13967\n",
      "[4460]\teval-rmse:4.10698\ttrain-rmse:2.13972\n",
      "[4461]\teval-rmse:4.10688\ttrain-rmse:2.1397\n",
      "[4462]\teval-rmse:4.10754\ttrain-rmse:2.13974\n",
      "[4463]\teval-rmse:4.10561\ttrain-rmse:2.13969\n",
      "[4464]\teval-rmse:4.10471\ttrain-rmse:2.13965\n",
      "[4465]\teval-rmse:4.10361\ttrain-rmse:2.13962\n",
      "[4466]\teval-rmse:4.10557\ttrain-rmse:2.13959\n",
      "[4467]\teval-rmse:4.10593\ttrain-rmse:2.13961\n",
      "[4468]\teval-rmse:4.10851\ttrain-rmse:2.1396\n",
      "[4469]\teval-rmse:4.10645\ttrain-rmse:2.13954\n",
      "[4470]\teval-rmse:4.10405\ttrain-rmse:2.13941\n",
      "[4471]\teval-rmse:4.10496\ttrain-rmse:2.13946\n",
      "[4472]\teval-rmse:4.10583\ttrain-rmse:2.1395\n",
      "[4473]\teval-rmse:4.10373\ttrain-rmse:2.13945\n",
      "[4474]\teval-rmse:4.10165\ttrain-rmse:2.1394\n",
      "[4475]\teval-rmse:4.10415\ttrain-rmse:2.13945\n",
      "[4476]\teval-rmse:4.10327\ttrain-rmse:2.13933\n",
      "[4477]\teval-rmse:4.10192\ttrain-rmse:2.13933\n",
      "[4478]\teval-rmse:4.10126\ttrain-rmse:2.13929\n",
      "[4479]\teval-rmse:4.10349\ttrain-rmse:2.13934\n",
      "[4480]\teval-rmse:4.10507\ttrain-rmse:2.13937\n",
      "[4481]\teval-rmse:4.10665\ttrain-rmse:2.13946\n",
      "[4482]\teval-rmse:4.1043\ttrain-rmse:2.13939\n",
      "[4483]\teval-rmse:4.10271\ttrain-rmse:2.13915\n",
      "[4484]\teval-rmse:4.10117\ttrain-rmse:2.13844\n",
      "[4485]\teval-rmse:4.10011\ttrain-rmse:2.13842\n",
      "[4486]\teval-rmse:4.0992\ttrain-rmse:2.1384\n",
      "[4487]\teval-rmse:4.09855\ttrain-rmse:2.13837\n",
      "[4488]\teval-rmse:4.09693\ttrain-rmse:2.13829\n",
      "[4489]\teval-rmse:4.09614\ttrain-rmse:2.13813\n",
      "[4490]\teval-rmse:4.09521\ttrain-rmse:2.13811\n",
      "[4491]\teval-rmse:4.09374\ttrain-rmse:2.13809\n",
      "[4492]\teval-rmse:4.09295\ttrain-rmse:2.13793\n",
      "[4493]\teval-rmse:4.09456\ttrain-rmse:2.13789\n",
      "[4494]\teval-rmse:4.09465\ttrain-rmse:2.1379\n",
      "[4495]\teval-rmse:4.09457\ttrain-rmse:2.13789\n",
      "[4496]\teval-rmse:4.09558\ttrain-rmse:2.13786\n",
      "[4497]\teval-rmse:4.09748\ttrain-rmse:2.13795\n",
      "[4498]\teval-rmse:4.09587\ttrain-rmse:2.13772\n",
      "[4499]\teval-rmse:4.0959\ttrain-rmse:2.13772\n",
      "[4500]\teval-rmse:4.09703\ttrain-rmse:2.13777\n",
      "[4501]\teval-rmse:4.09885\ttrain-rmse:2.13779\n",
      "[4502]\teval-rmse:4.10006\ttrain-rmse:2.13785\n",
      "[4503]\teval-rmse:4.09731\ttrain-rmse:2.13771\n",
      "[4504]\teval-rmse:4.09883\ttrain-rmse:2.13773\n",
      "[4505]\teval-rmse:4.0989\ttrain-rmse:2.13773\n",
      "[4506]\teval-rmse:4.09894\ttrain-rmse:2.13773\n",
      "[4507]\teval-rmse:4.09833\ttrain-rmse:2.13759\n",
      "[4508]\teval-rmse:4.09732\ttrain-rmse:2.13754\n",
      "[4509]\teval-rmse:4.09498\ttrain-rmse:2.13743\n",
      "[4510]\teval-rmse:4.09398\ttrain-rmse:2.13741\n",
      "[4511]\teval-rmse:4.09211\ttrain-rmse:2.13739\n",
      "[4512]\teval-rmse:4.09142\ttrain-rmse:2.13736\n",
      "[4513]\teval-rmse:4.09073\ttrain-rmse:2.13721\n",
      "[4514]\teval-rmse:4.09062\ttrain-rmse:2.13721\n",
      "[4515]\teval-rmse:4.08769\ttrain-rmse:2.1371\n",
      "[4516]\teval-rmse:4.08665\ttrain-rmse:2.1371\n",
      "[4517]\teval-rmse:4.08396\ttrain-rmse:2.13703\n",
      "[4518]\teval-rmse:4.0838\ttrain-rmse:2.13703\n",
      "[4519]\teval-rmse:4.08612\ttrain-rmse:2.13702\n",
      "[4520]\teval-rmse:4.08795\ttrain-rmse:2.13707\n",
      "[4521]\teval-rmse:4.08738\ttrain-rmse:2.13706\n",
      "[4522]\teval-rmse:4.08562\ttrain-rmse:2.13701\n",
      "[4523]\teval-rmse:4.08646\ttrain-rmse:2.13697\n",
      "[4524]\teval-rmse:4.08755\ttrain-rmse:2.137\n",
      "[4525]\teval-rmse:4.08663\ttrain-rmse:2.13697\n",
      "[4526]\teval-rmse:4.08664\ttrain-rmse:2.13697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4527]\teval-rmse:4.08742\ttrain-rmse:2.13699\n",
      "[4528]\teval-rmse:4.08594\ttrain-rmse:2.13604\n",
      "[4529]\teval-rmse:4.08533\ttrain-rmse:2.1359\n",
      "[4530]\teval-rmse:4.08349\ttrain-rmse:2.13591\n",
      "[4531]\teval-rmse:4.08275\ttrain-rmse:2.13589\n",
      "[4532]\teval-rmse:4.07978\ttrain-rmse:2.13586\n",
      "[4533]\teval-rmse:4.08128\ttrain-rmse:2.1359\n",
      "[4534]\teval-rmse:4.07966\ttrain-rmse:2.13594\n",
      "[4535]\teval-rmse:4.0779\ttrain-rmse:2.13572\n",
      "[4536]\teval-rmse:4.08049\ttrain-rmse:2.13577\n",
      "[4537]\teval-rmse:4.079\ttrain-rmse:2.13552\n",
      "[4538]\teval-rmse:4.07997\ttrain-rmse:2.13551\n",
      "[4539]\teval-rmse:4.07856\ttrain-rmse:2.1348\n",
      "[4540]\teval-rmse:4.07584\ttrain-rmse:2.13477\n",
      "[4541]\teval-rmse:4.07754\ttrain-rmse:2.1348\n",
      "[4542]\teval-rmse:4.07654\ttrain-rmse:2.13478\n",
      "[4543]\teval-rmse:4.07381\ttrain-rmse:2.13481\n",
      "[4544]\teval-rmse:4.07111\ttrain-rmse:2.13485\n",
      "[4545]\teval-rmse:4.07302\ttrain-rmse:2.13488\n",
      "[4546]\teval-rmse:4.07239\ttrain-rmse:2.13487\n",
      "[4547]\teval-rmse:4.07082\ttrain-rmse:2.1349\n",
      "[4548]\teval-rmse:4.07273\ttrain-rmse:2.13486\n",
      "[4549]\teval-rmse:4.07004\ttrain-rmse:2.13484\n",
      "[4550]\teval-rmse:4.06933\ttrain-rmse:2.13483\n",
      "[4551]\teval-rmse:4.06752\ttrain-rmse:2.1349\n",
      "[4552]\teval-rmse:4.06939\ttrain-rmse:2.13485\n",
      "[4553]\teval-rmse:4.07059\ttrain-rmse:2.13486\n",
      "[4554]\teval-rmse:4.07106\ttrain-rmse:2.13486\n",
      "[4555]\teval-rmse:4.06976\ttrain-rmse:2.13485\n",
      "[4556]\teval-rmse:4.06907\ttrain-rmse:2.13475\n",
      "[4557]\teval-rmse:4.068\ttrain-rmse:2.13477\n",
      "[4558]\teval-rmse:4.06977\ttrain-rmse:2.13472\n",
      "[4559]\teval-rmse:4.07169\ttrain-rmse:2.13474\n",
      "[4560]\teval-rmse:4.07379\ttrain-rmse:2.13501\n",
      "[4561]\teval-rmse:4.07543\ttrain-rmse:2.13498\n",
      "[4562]\teval-rmse:4.07348\ttrain-rmse:2.135\n",
      "[4563]\teval-rmse:4.07171\ttrain-rmse:2.13498\n",
      "[4564]\teval-rmse:4.07035\ttrain-rmse:2.1343\n",
      "[4565]\teval-rmse:4.07177\ttrain-rmse:2.13431\n",
      "[4566]\teval-rmse:4.0704\ttrain-rmse:2.13356\n",
      "[4567]\teval-rmse:4.07037\ttrain-rmse:2.13356\n",
      "[4568]\teval-rmse:4.0674\ttrain-rmse:2.1335\n",
      "[4569]\teval-rmse:4.07\ttrain-rmse:2.13344\n",
      "[4570]\teval-rmse:4.07277\ttrain-rmse:2.1334\n",
      "[4571]\teval-rmse:4.07365\ttrain-rmse:2.13342\n",
      "[4572]\teval-rmse:4.07455\ttrain-rmse:2.13343\n",
      "[4573]\teval-rmse:4.07558\ttrain-rmse:2.13345\n",
      "[4574]\teval-rmse:4.07463\ttrain-rmse:2.13346\n",
      "[4575]\teval-rmse:4.07184\ttrain-rmse:2.13341\n",
      "[4576]\teval-rmse:4.07296\ttrain-rmse:2.13335\n",
      "[4577]\teval-rmse:4.07009\ttrain-rmse:2.13332\n",
      "[4578]\teval-rmse:4.0712\ttrain-rmse:2.13327\n",
      "[4579]\teval-rmse:4.0721\ttrain-rmse:2.13323\n",
      "[4580]\teval-rmse:4.07205\ttrain-rmse:2.13322\n",
      "[4581]\teval-rmse:4.07127\ttrain-rmse:2.13323\n",
      "[4582]\teval-rmse:4.07207\ttrain-rmse:2.13323\n",
      "[4583]\teval-rmse:4.06999\ttrain-rmse:2.13321\n",
      "[4584]\teval-rmse:4.07225\ttrain-rmse:2.13311\n",
      "[4585]\teval-rmse:4.07131\ttrain-rmse:2.13312\n",
      "[4586]\teval-rmse:4.07129\ttrain-rmse:2.13312\n",
      "[4587]\teval-rmse:4.07188\ttrain-rmse:2.13313\n",
      "[4588]\teval-rmse:4.07097\ttrain-rmse:2.13312\n",
      "[4589]\teval-rmse:4.06865\ttrain-rmse:2.1331\n",
      "[4590]\teval-rmse:4.06722\ttrain-rmse:2.13293\n",
      "[4591]\teval-rmse:4.06758\ttrain-rmse:2.13293\n",
      "[4592]\teval-rmse:4.06897\ttrain-rmse:2.13293\n",
      "[4593]\teval-rmse:4.0708\ttrain-rmse:2.13295\n",
      "[4594]\teval-rmse:4.07021\ttrain-rmse:2.13286\n",
      "[4595]\teval-rmse:4.07185\ttrain-rmse:2.13284\n",
      "[4596]\teval-rmse:4.06991\ttrain-rmse:2.13286\n",
      "[4597]\teval-rmse:4.06739\ttrain-rmse:2.13285\n",
      "[4598]\teval-rmse:4.06925\ttrain-rmse:2.13281\n",
      "[4599]\teval-rmse:4.06946\ttrain-rmse:2.13281\n",
      "[4600]\teval-rmse:4.06787\ttrain-rmse:2.13284\n",
      "[4601]\teval-rmse:4.06851\ttrain-rmse:2.13284\n",
      "[4602]\teval-rmse:4.06558\ttrain-rmse:2.13282\n",
      "[4603]\teval-rmse:4.06814\ttrain-rmse:2.13277\n",
      "[4604]\teval-rmse:4.06866\ttrain-rmse:2.13277\n",
      "[4605]\teval-rmse:4.0703\ttrain-rmse:2.13275\n",
      "[4606]\teval-rmse:4.069\ttrain-rmse:2.13277\n",
      "[4607]\teval-rmse:4.06756\ttrain-rmse:2.13251\n",
      "[4608]\teval-rmse:4.06671\ttrain-rmse:2.13252\n",
      "[4609]\teval-rmse:4.06598\ttrain-rmse:2.13252\n",
      "[4610]\teval-rmse:4.0653\ttrain-rmse:2.13253\n",
      "[4611]\teval-rmse:4.06371\ttrain-rmse:2.13254\n",
      "[4612]\teval-rmse:4.06454\ttrain-rmse:2.13254\n",
      "[4613]\teval-rmse:4.06299\ttrain-rmse:2.13257\n",
      "[4614]\teval-rmse:4.06577\ttrain-rmse:2.13251\n",
      "[4615]\teval-rmse:4.06439\ttrain-rmse:2.13184\n",
      "[4616]\teval-rmse:4.06623\ttrain-rmse:2.13185\n",
      "[4617]\teval-rmse:4.06535\ttrain-rmse:2.13186\n",
      "[4618]\teval-rmse:4.06364\ttrain-rmse:2.13192\n",
      "[4619]\teval-rmse:4.06353\ttrain-rmse:2.13192\n",
      "[4620]\teval-rmse:4.06257\ttrain-rmse:2.13194\n",
      "[4621]\teval-rmse:4.06046\ttrain-rmse:2.132\n",
      "[4622]\teval-rmse:4.0616\ttrain-rmse:2.13198\n",
      "[4623]\teval-rmse:4.06157\ttrain-rmse:2.13198\n",
      "[4624]\teval-rmse:4.05997\ttrain-rmse:2.13199\n",
      "[4625]\teval-rmse:4.05786\ttrain-rmse:2.13201\n",
      "[4626]\teval-rmse:4.05659\ttrain-rmse:2.13203\n",
      "[4627]\teval-rmse:4.05532\ttrain-rmse:2.13118\n",
      "[4628]\teval-rmse:4.0564\ttrain-rmse:2.13116\n",
      "[4629]\teval-rmse:4.05585\ttrain-rmse:2.13104\n",
      "[4630]\teval-rmse:4.05681\ttrain-rmse:2.13103\n",
      "[4631]\teval-rmse:4.05502\ttrain-rmse:2.13112\n",
      "[4632]\teval-rmse:4.05506\ttrain-rmse:2.13111\n",
      "[4633]\teval-rmse:4.05341\ttrain-rmse:2.1312\n",
      "[4634]\teval-rmse:4.05386\ttrain-rmse:2.1312\n",
      "[4635]\teval-rmse:4.05599\ttrain-rmse:2.13107\n",
      "[4636]\teval-rmse:4.05363\ttrain-rmse:2.1311\n",
      "[4637]\teval-rmse:4.05194\ttrain-rmse:2.13117\n",
      "[4638]\teval-rmse:4.0518\ttrain-rmse:2.13117\n",
      "[4639]\teval-rmse:4.05295\ttrain-rmse:2.13115\n",
      "[4640]\teval-rmse:4.05277\ttrain-rmse:2.13115\n",
      "[4641]\teval-rmse:4.05089\ttrain-rmse:2.13119\n",
      "[4642]\teval-rmse:4.05295\ttrain-rmse:2.1311\n",
      "[4643]\teval-rmse:4.05171\ttrain-rmse:2.13023\n",
      "[4644]\teval-rmse:4.05311\ttrain-rmse:2.13021\n",
      "[4645]\teval-rmse:4.05262\ttrain-rmse:2.13009\n",
      "[4646]\teval-rmse:4.04963\ttrain-rmse:2.13015\n",
      "[4647]\teval-rmse:4.04776\ttrain-rmse:2.13019\n",
      "[4648]\teval-rmse:4.04642\ttrain-rmse:2.13006\n",
      "[4649]\teval-rmse:4.04518\ttrain-rmse:2.12941\n",
      "[4650]\teval-rmse:4.04406\ttrain-rmse:2.12946\n",
      "[4651]\teval-rmse:4.04578\ttrain-rmse:2.12939\n",
      "[4652]\teval-rmse:4.04498\ttrain-rmse:2.12942\n",
      "[4653]\teval-rmse:4.04582\ttrain-rmse:2.12938\n",
      "[4654]\teval-rmse:4.04733\ttrain-rmse:2.1293\n",
      "[4655]\teval-rmse:4.04826\ttrain-rmse:2.12926\n",
      "[4656]\teval-rmse:4.04707\ttrain-rmse:2.12928\n",
      "[4657]\teval-rmse:4.04512\ttrain-rmse:2.12937\n",
      "[4658]\teval-rmse:4.04606\ttrain-rmse:2.12933\n",
      "[4659]\teval-rmse:4.04773\ttrain-rmse:2.12925\n",
      "[4660]\teval-rmse:4.04664\ttrain-rmse:2.12929\n",
      "[4661]\teval-rmse:4.04507\ttrain-rmse:2.12936\n",
      "[4662]\teval-rmse:4.04729\ttrain-rmse:2.12932\n",
      "[4663]\teval-rmse:4.04575\ttrain-rmse:2.12915\n",
      "[4664]\teval-rmse:4.04529\ttrain-rmse:2.12916\n",
      "[4665]\teval-rmse:4.04464\ttrain-rmse:2.12918\n",
      "[4666]\teval-rmse:4.04262\ttrain-rmse:2.12924\n",
      "[4667]\teval-rmse:4.04087\ttrain-rmse:2.12928\n",
      "[4668]\teval-rmse:4.04198\ttrain-rmse:2.12924\n",
      "[4669]\teval-rmse:4.04125\ttrain-rmse:2.12927\n",
      "[4670]\teval-rmse:4.04198\ttrain-rmse:2.12925\n",
      "[4671]\teval-rmse:4.04286\ttrain-rmse:2.12922\n",
      "[4672]\teval-rmse:4.04368\ttrain-rmse:2.12919\n",
      "[4673]\teval-rmse:4.04552\ttrain-rmse:2.12914\n",
      "[4674]\teval-rmse:4.04394\ttrain-rmse:2.129\n",
      "[4675]\teval-rmse:4.04576\ttrain-rmse:2.12896\n",
      "[4676]\teval-rmse:4.04517\ttrain-rmse:2.12888\n",
      "[4677]\teval-rmse:4.04333\ttrain-rmse:2.12896\n",
      "[4678]\teval-rmse:4.04259\ttrain-rmse:2.12899\n",
      "[4679]\teval-rmse:4.04078\ttrain-rmse:2.12908\n",
      "[4680]\teval-rmse:4.04293\ttrain-rmse:2.1293\n",
      "[4681]\teval-rmse:4.0457\ttrain-rmse:2.12917\n",
      "[4682]\teval-rmse:4.04414\ttrain-rmse:2.12902\n",
      "[4683]\teval-rmse:4.04248\ttrain-rmse:2.12911\n",
      "[4684]\teval-rmse:4.04125\ttrain-rmse:2.12892\n",
      "[4685]\teval-rmse:4.04349\ttrain-rmse:2.12879\n",
      "[4686]\teval-rmse:4.04537\ttrain-rmse:2.12865\n",
      "[4687]\teval-rmse:4.04489\ttrain-rmse:2.12852\n",
      "[4688]\teval-rmse:4.04333\ttrain-rmse:2.12859\n",
      "[4689]\teval-rmse:4.04411\ttrain-rmse:2.12857\n",
      "[4690]\teval-rmse:4.04433\ttrain-rmse:2.12857\n",
      "[4691]\teval-rmse:4.04514\ttrain-rmse:2.12854\n",
      "[4692]\teval-rmse:4.04445\ttrain-rmse:2.12858\n",
      "[4693]\teval-rmse:4.04195\ttrain-rmse:2.1287\n",
      "[4694]\teval-rmse:4.04015\ttrain-rmse:2.12883\n",
      "[4695]\teval-rmse:4.0421\ttrain-rmse:2.12872\n",
      "[4696]\teval-rmse:4.0432\ttrain-rmse:2.12869\n",
      "[4697]\teval-rmse:4.04391\ttrain-rmse:2.12865\n",
      "[4698]\teval-rmse:4.04471\ttrain-rmse:2.12864\n",
      "[4699]\teval-rmse:4.04314\ttrain-rmse:2.12875\n",
      "[4700]\teval-rmse:4.04483\ttrain-rmse:2.12867\n",
      "[4701]\teval-rmse:4.04413\ttrain-rmse:2.1287\n",
      "[4702]\teval-rmse:4.04351\ttrain-rmse:2.12867\n",
      "[4703]\teval-rmse:4.04463\ttrain-rmse:2.12864\n",
      "[4704]\teval-rmse:4.04303\ttrain-rmse:2.12849\n",
      "[4705]\teval-rmse:4.04383\ttrain-rmse:2.12847\n",
      "[4706]\teval-rmse:4.04524\ttrain-rmse:2.12844\n",
      "[4707]\teval-rmse:4.04607\ttrain-rmse:2.1284\n",
      "[4708]\teval-rmse:4.04783\ttrain-rmse:2.12827\n",
      "[4709]\teval-rmse:4.04973\ttrain-rmse:2.12819\n",
      "[4710]\teval-rmse:4.05207\ttrain-rmse:2.12811\n",
      "[4711]\teval-rmse:4.05394\ttrain-rmse:2.12805\n",
      "[4712]\teval-rmse:4.05511\ttrain-rmse:2.12801\n",
      "[4713]\teval-rmse:4.05506\ttrain-rmse:2.12801\n",
      "[4714]\teval-rmse:4.05392\ttrain-rmse:2.12803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4715]\teval-rmse:4.05266\ttrain-rmse:2.12804\n",
      "[4716]\teval-rmse:4.05526\ttrain-rmse:2.12788\n",
      "[4717]\teval-rmse:4.0547\ttrain-rmse:2.12788\n",
      "[4718]\teval-rmse:4.05588\ttrain-rmse:2.12788\n",
      "[4719]\teval-rmse:4.05752\ttrain-rmse:2.12784\n",
      "[4720]\teval-rmse:4.05939\ttrain-rmse:2.12779\n",
      "[4721]\teval-rmse:4.06131\ttrain-rmse:2.12775\n",
      "[4722]\teval-rmse:4.06199\ttrain-rmse:2.12773\n",
      "[4723]\teval-rmse:4.0593\ttrain-rmse:2.12772\n",
      "[4724]\teval-rmse:4.06184\ttrain-rmse:2.12772\n",
      "[4725]\teval-rmse:4.06103\ttrain-rmse:2.12774\n",
      "[4726]\teval-rmse:4.05962\ttrain-rmse:2.12779\n",
      "[4727]\teval-rmse:4.05875\ttrain-rmse:2.12781\n",
      "[4728]\teval-rmse:4.06085\ttrain-rmse:2.12808\n",
      "[4729]\teval-rmse:4.05983\ttrain-rmse:2.1281\n",
      "[4730]\teval-rmse:4.05816\ttrain-rmse:2.12785\n",
      "[4731]\teval-rmse:4.05913\ttrain-rmse:2.12785\n",
      "[4732]\teval-rmse:4.06126\ttrain-rmse:2.12811\n",
      "[4733]\teval-rmse:4.06324\ttrain-rmse:2.12807\n",
      "[4734]\teval-rmse:4.06593\ttrain-rmse:2.12796\n",
      "[4735]\teval-rmse:4.06649\ttrain-rmse:2.12796\n",
      "[4736]\teval-rmse:4.06733\ttrain-rmse:2.12795\n",
      "[4737]\teval-rmse:4.06813\ttrain-rmse:2.12796\n",
      "[4738]\teval-rmse:4.067\ttrain-rmse:2.12797\n",
      "[4739]\teval-rmse:4.06866\ttrain-rmse:2.128\n",
      "[4740]\teval-rmse:4.06603\ttrain-rmse:2.12795\n",
      "[4741]\teval-rmse:4.0673\ttrain-rmse:2.12794\n",
      "[4742]\teval-rmse:4.06879\ttrain-rmse:2.12792\n",
      "[4743]\teval-rmse:4.06809\ttrain-rmse:2.12784\n",
      "[4744]\teval-rmse:4.06679\ttrain-rmse:2.12782\n",
      "[4745]\teval-rmse:4.06624\ttrain-rmse:2.12775\n",
      "[4746]\teval-rmse:4.0678\ttrain-rmse:2.12773\n",
      "[4747]\teval-rmse:4.06658\ttrain-rmse:2.12776\n",
      "[4748]\teval-rmse:4.06484\ttrain-rmse:2.12781\n",
      "[4749]\teval-rmse:4.06384\ttrain-rmse:2.12782\n",
      "[4750]\teval-rmse:4.06581\ttrain-rmse:2.12779\n",
      "[4751]\teval-rmse:4.06643\ttrain-rmse:2.1278\n",
      "[4752]\teval-rmse:4.06575\ttrain-rmse:2.12766\n",
      "[4753]\teval-rmse:4.0644\ttrain-rmse:2.12768\n",
      "[4754]\teval-rmse:4.06301\ttrain-rmse:2.1275\n",
      "[4755]\teval-rmse:4.06429\ttrain-rmse:2.12751\n",
      "[4756]\teval-rmse:4.06237\ttrain-rmse:2.12753\n",
      "[4757]\teval-rmse:4.06065\ttrain-rmse:2.12758\n",
      "[4758]\teval-rmse:4.05851\ttrain-rmse:2.12757\n",
      "[4759]\teval-rmse:4.0595\ttrain-rmse:2.12755\n",
      "[4760]\teval-rmse:4.05683\ttrain-rmse:2.12751\n",
      "[4761]\teval-rmse:4.05621\ttrain-rmse:2.12752\n",
      "[4762]\teval-rmse:4.05745\ttrain-rmse:2.12752\n",
      "[4763]\teval-rmse:4.05485\ttrain-rmse:2.12758\n",
      "[4764]\teval-rmse:4.0564\ttrain-rmse:2.12759\n",
      "[4765]\teval-rmse:4.05586\ttrain-rmse:2.12754\n",
      "[4766]\teval-rmse:4.05679\ttrain-rmse:2.12754\n",
      "[4767]\teval-rmse:4.05412\ttrain-rmse:2.12754\n",
      "[4768]\teval-rmse:4.05574\ttrain-rmse:2.12753\n",
      "[4769]\teval-rmse:4.05762\ttrain-rmse:2.12749\n",
      "[4770]\teval-rmse:4.05645\ttrain-rmse:2.12751\n",
      "[4771]\teval-rmse:4.05541\ttrain-rmse:2.12753\n",
      "[4772]\teval-rmse:4.05412\ttrain-rmse:2.12685\n",
      "[4773]\teval-rmse:4.05674\ttrain-rmse:2.12679\n",
      "[4774]\teval-rmse:4.05598\ttrain-rmse:2.12679\n",
      "[4775]\teval-rmse:4.05435\ttrain-rmse:2.12659\n",
      "[4776]\teval-rmse:4.05511\ttrain-rmse:2.12659\n",
      "[4777]\teval-rmse:4.0574\ttrain-rmse:2.12653\n",
      "[4778]\teval-rmse:4.05837\ttrain-rmse:2.12655\n",
      "[4779]\teval-rmse:4.05646\ttrain-rmse:2.12659\n",
      "[4780]\teval-rmse:4.05386\ttrain-rmse:2.12665\n",
      "[4781]\teval-rmse:4.05406\ttrain-rmse:2.12664\n",
      "[4782]\teval-rmse:4.05271\ttrain-rmse:2.12649\n",
      "[4783]\teval-rmse:4.0543\ttrain-rmse:2.12649\n",
      "[4784]\teval-rmse:4.05587\ttrain-rmse:2.1265\n",
      "[4785]\teval-rmse:4.05427\ttrain-rmse:2.12649\n",
      "[4786]\teval-rmse:4.05258\ttrain-rmse:2.12656\n",
      "[4787]\teval-rmse:4.05528\ttrain-rmse:2.12641\n",
      "[4788]\teval-rmse:4.0531\ttrain-rmse:2.12641\n",
      "[4789]\teval-rmse:4.05534\ttrain-rmse:2.12641\n",
      "[4790]\teval-rmse:4.05746\ttrain-rmse:2.12667\n",
      "[4791]\teval-rmse:4.0568\ttrain-rmse:2.12654\n",
      "[4792]\teval-rmse:4.05855\ttrain-rmse:2.1265\n",
      "[4793]\teval-rmse:4.05665\ttrain-rmse:2.12654\n",
      "[4794]\teval-rmse:4.0553\ttrain-rmse:2.12593\n",
      "[4795]\teval-rmse:4.05614\ttrain-rmse:2.12594\n",
      "[4796]\teval-rmse:4.05538\ttrain-rmse:2.12595\n",
      "[4797]\teval-rmse:4.05799\ttrain-rmse:2.12589\n",
      "[4798]\teval-rmse:4.05682\ttrain-rmse:2.12592\n",
      "[4799]\teval-rmse:4.05674\ttrain-rmse:2.1259\n",
      "[4800]\teval-rmse:4.05434\ttrain-rmse:2.12595\n",
      "[4801]\teval-rmse:4.05464\ttrain-rmse:2.12595\n",
      "[4802]\teval-rmse:4.05624\ttrain-rmse:2.12591\n",
      "[4803]\teval-rmse:4.05545\ttrain-rmse:2.12593\n",
      "[4804]\teval-rmse:4.05417\ttrain-rmse:2.12531\n",
      "[4805]\teval-rmse:4.05211\ttrain-rmse:2.12536\n",
      "[4806]\teval-rmse:4.05026\ttrain-rmse:2.12536\n",
      "[4807]\teval-rmse:4.05163\ttrain-rmse:2.12532\n",
      "[4808]\teval-rmse:4.05178\ttrain-rmse:2.12532\n",
      "[4809]\teval-rmse:4.0519\ttrain-rmse:2.12532\n",
      "[4810]\teval-rmse:4.05391\ttrain-rmse:2.12521\n",
      "[4811]\teval-rmse:4.05373\ttrain-rmse:2.12521\n",
      "[4812]\teval-rmse:4.05204\ttrain-rmse:2.12521\n",
      "[4813]\teval-rmse:4.05297\ttrain-rmse:2.12521\n",
      "[4814]\teval-rmse:4.05058\ttrain-rmse:2.12532\n",
      "[4815]\teval-rmse:4.04927\ttrain-rmse:2.12513\n",
      "[4816]\teval-rmse:4.04843\ttrain-rmse:2.12515\n",
      "[4817]\teval-rmse:4.04782\ttrain-rmse:2.12507\n",
      "[4818]\teval-rmse:4.05001\ttrain-rmse:2.12493\n",
      "[4819]\teval-rmse:4.05145\ttrain-rmse:2.12489\n",
      "[4820]\teval-rmse:4.04906\ttrain-rmse:2.12489\n",
      "[4821]\teval-rmse:4.04967\ttrain-rmse:2.12489\n",
      "[4822]\teval-rmse:4.04965\ttrain-rmse:2.12489\n",
      "[4823]\teval-rmse:4.04963\ttrain-rmse:2.12489\n",
      "[4824]\teval-rmse:4.04816\ttrain-rmse:2.1249\n",
      "[4825]\teval-rmse:4.04739\ttrain-rmse:2.12492\n",
      "[4826]\teval-rmse:4.04737\ttrain-rmse:2.12491\n",
      "[4827]\teval-rmse:4.04589\ttrain-rmse:2.125\n",
      "[4828]\teval-rmse:4.04436\ttrain-rmse:2.12477\n",
      "[4829]\teval-rmse:4.04551\ttrain-rmse:2.12472\n",
      "[4830]\teval-rmse:4.04606\ttrain-rmse:2.12472\n",
      "[4831]\teval-rmse:4.04869\ttrain-rmse:2.12463\n",
      "[4832]\teval-rmse:4.0489\ttrain-rmse:2.12463\n",
      "[4833]\teval-rmse:4.05099\ttrain-rmse:2.12451\n",
      "[4834]\teval-rmse:4.05315\ttrain-rmse:2.12474\n",
      "[4835]\teval-rmse:4.05544\ttrain-rmse:2.12462\n",
      "[4836]\teval-rmse:4.05534\ttrain-rmse:2.12462\n",
      "[4837]\teval-rmse:4.05694\ttrain-rmse:2.12459\n",
      "[4838]\teval-rmse:4.05795\ttrain-rmse:2.12457\n",
      "[4839]\teval-rmse:4.05629\ttrain-rmse:2.12459\n",
      "[4840]\teval-rmse:4.05695\ttrain-rmse:2.1246\n",
      "[4841]\teval-rmse:4.05858\ttrain-rmse:2.12456\n",
      "[4842]\teval-rmse:4.05995\ttrain-rmse:2.12454\n",
      "[4843]\teval-rmse:4.06213\ttrain-rmse:2.12445\n",
      "[4844]\teval-rmse:4.0605\ttrain-rmse:2.12427\n",
      "[4845]\teval-rmse:4.05941\ttrain-rmse:2.12428\n",
      "[4846]\teval-rmse:4.05754\ttrain-rmse:2.1243\n",
      "[4847]\teval-rmse:4.05967\ttrain-rmse:2.12434\n",
      "[4848]\teval-rmse:4.05834\ttrain-rmse:2.12413\n",
      "[4849]\teval-rmse:4.06061\ttrain-rmse:2.1241\n",
      "[4850]\teval-rmse:4.05992\ttrain-rmse:2.12403\n",
      "[4851]\teval-rmse:4.06091\ttrain-rmse:2.12402\n",
      "[4852]\teval-rmse:4.06357\ttrain-rmse:2.12392\n",
      "[4853]\teval-rmse:4.06615\ttrain-rmse:2.12398\n",
      "[4854]\teval-rmse:4.06737\ttrain-rmse:2.12401\n",
      "[4855]\teval-rmse:4.06571\ttrain-rmse:2.12403\n",
      "[4856]\teval-rmse:4.06654\ttrain-rmse:2.12399\n",
      "[4857]\teval-rmse:4.06727\ttrain-rmse:2.12401\n",
      "[4858]\teval-rmse:4.06711\ttrain-rmse:2.12401\n",
      "[4859]\teval-rmse:4.06535\ttrain-rmse:2.12396\n",
      "[4860]\teval-rmse:4.06616\ttrain-rmse:2.12398\n",
      "[4861]\teval-rmse:4.06507\ttrain-rmse:2.12398\n",
      "[4862]\teval-rmse:4.06455\ttrain-rmse:2.12397\n",
      "[4863]\teval-rmse:4.06521\ttrain-rmse:2.12398\n",
      "[4864]\teval-rmse:4.06606\ttrain-rmse:2.124\n",
      "[4865]\teval-rmse:4.06461\ttrain-rmse:2.124\n",
      "[4866]\teval-rmse:4.06269\ttrain-rmse:2.12402\n",
      "[4867]\teval-rmse:4.06159\ttrain-rmse:2.12402\n",
      "[4868]\teval-rmse:4.06314\ttrain-rmse:2.12396\n",
      "[4869]\teval-rmse:4.06218\ttrain-rmse:2.12396\n",
      "[4870]\teval-rmse:4.0633\ttrain-rmse:2.12395\n",
      "[4871]\teval-rmse:4.06395\ttrain-rmse:2.12397\n",
      "[4872]\teval-rmse:4.06303\ttrain-rmse:2.12396\n",
      "[4873]\teval-rmse:4.06417\ttrain-rmse:2.12399\n",
      "[4874]\teval-rmse:4.06424\ttrain-rmse:2.12399\n",
      "[4875]\teval-rmse:4.06437\ttrain-rmse:2.12399\n",
      "[4876]\teval-rmse:4.0628\ttrain-rmse:2.12396\n",
      "[4877]\teval-rmse:4.06276\ttrain-rmse:2.12395\n",
      "[4878]\teval-rmse:4.06461\ttrain-rmse:2.12393\n",
      "[4879]\teval-rmse:4.06405\ttrain-rmse:2.12382\n",
      "[4880]\teval-rmse:4.06633\ttrain-rmse:2.1239\n",
      "[4881]\teval-rmse:4.06753\ttrain-rmse:2.1239\n",
      "[4882]\teval-rmse:4.06745\ttrain-rmse:2.12389\n",
      "[4883]\teval-rmse:4.06933\ttrain-rmse:2.12395\n",
      "[4884]\teval-rmse:4.06859\ttrain-rmse:2.12387\n",
      "[4885]\teval-rmse:4.07006\ttrain-rmse:2.12392\n",
      "[4886]\teval-rmse:4.0673\ttrain-rmse:2.12382\n",
      "[4887]\teval-rmse:4.06762\ttrain-rmse:2.12383\n",
      "[4888]\teval-rmse:4.06774\ttrain-rmse:2.12383\n",
      "[4889]\teval-rmse:4.06585\ttrain-rmse:2.12376\n",
      "[4890]\teval-rmse:4.06731\ttrain-rmse:2.12376\n",
      "[4891]\teval-rmse:4.06893\ttrain-rmse:2.12376\n",
      "[4892]\teval-rmse:4.06889\ttrain-rmse:2.12376\n",
      "[4893]\teval-rmse:4.06583\ttrain-rmse:2.12365\n",
      "[4894]\teval-rmse:4.06308\ttrain-rmse:2.12366\n",
      "[4895]\teval-rmse:4.06036\ttrain-rmse:2.1236\n",
      "[4896]\teval-rmse:4.06104\ttrain-rmse:2.12362\n",
      "[4897]\teval-rmse:4.05909\ttrain-rmse:2.12365\n",
      "[4898]\teval-rmse:4.0607\ttrain-rmse:2.12363\n",
      "[4899]\teval-rmse:4.05974\ttrain-rmse:2.12364\n",
      "[4900]\teval-rmse:4.05979\ttrain-rmse:2.12364\n",
      "[4901]\teval-rmse:4.059\ttrain-rmse:2.12364\n",
      "[4902]\teval-rmse:4.06089\ttrain-rmse:2.12363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4903]\teval-rmse:4.05953\ttrain-rmse:2.12341\n",
      "[4904]\teval-rmse:4.05827\ttrain-rmse:2.1226\n",
      "[4905]\teval-rmse:4.06087\ttrain-rmse:2.12256\n",
      "[4906]\teval-rmse:4.06077\ttrain-rmse:2.12256\n",
      "[4907]\teval-rmse:4.06346\ttrain-rmse:2.12247\n",
      "[4908]\teval-rmse:4.06484\ttrain-rmse:2.1225\n",
      "[4909]\teval-rmse:4.06349\ttrain-rmse:2.1225\n",
      "[4910]\teval-rmse:4.06466\ttrain-rmse:2.12253\n",
      "[4911]\teval-rmse:4.06333\ttrain-rmse:2.12253\n",
      "[4912]\teval-rmse:4.06221\ttrain-rmse:2.12253\n",
      "[4913]\teval-rmse:4.06232\ttrain-rmse:2.12253\n",
      "[4914]\teval-rmse:4.06164\ttrain-rmse:2.12246\n",
      "[4915]\teval-rmse:4.06374\ttrain-rmse:2.12251\n",
      "[4916]\teval-rmse:4.06364\ttrain-rmse:2.1225\n",
      "[4917]\teval-rmse:4.06488\ttrain-rmse:2.1225\n",
      "[4918]\teval-rmse:4.06431\ttrain-rmse:2.12237\n",
      "[4919]\teval-rmse:4.0632\ttrain-rmse:2.12233\n",
      "[4920]\teval-rmse:4.06177\ttrain-rmse:2.12217\n",
      "[4921]\teval-rmse:4.06444\ttrain-rmse:2.12208\n",
      "[4922]\teval-rmse:4.06339\ttrain-rmse:2.12205\n",
      "[4923]\teval-rmse:4.06217\ttrain-rmse:2.12204\n",
      "[4924]\teval-rmse:4.06272\ttrain-rmse:2.12206\n",
      "[4925]\teval-rmse:4.06108\ttrain-rmse:2.12182\n",
      "[4926]\teval-rmse:4.06379\ttrain-rmse:2.12179\n",
      "[4927]\teval-rmse:4.06601\ttrain-rmse:2.12188\n",
      "[4928]\teval-rmse:4.06826\ttrain-rmse:2.1219\n",
      "[4929]\teval-rmse:4.06743\ttrain-rmse:2.12188\n",
      "[4930]\teval-rmse:4.06936\ttrain-rmse:2.1219\n",
      "[4931]\teval-rmse:4.07194\ttrain-rmse:2.1219\n",
      "[4932]\teval-rmse:4.07353\ttrain-rmse:2.12197\n",
      "[4933]\teval-rmse:4.074\ttrain-rmse:2.12199\n",
      "[4934]\teval-rmse:4.07285\ttrain-rmse:2.12199\n",
      "[4935]\teval-rmse:4.07549\ttrain-rmse:2.12203\n",
      "[4936]\teval-rmse:4.07458\ttrain-rmse:2.12201\n",
      "[4937]\teval-rmse:4.07463\ttrain-rmse:2.122\n",
      "[4938]\teval-rmse:4.0732\ttrain-rmse:2.12134\n",
      "[4939]\teval-rmse:4.07163\ttrain-rmse:2.12127\n",
      "[4940]\teval-rmse:4.07068\ttrain-rmse:2.12123\n",
      "[4941]\teval-rmse:4.07158\ttrain-rmse:2.12126\n",
      "[4942]\teval-rmse:4.07154\ttrain-rmse:2.12126\n",
      "[4943]\teval-rmse:4.06954\ttrain-rmse:2.12122\n",
      "[4944]\teval-rmse:4.07166\ttrain-rmse:2.12118\n",
      "[4945]\teval-rmse:4.06886\ttrain-rmse:2.12106\n",
      "[4946]\teval-rmse:4.0676\ttrain-rmse:2.12105\n",
      "[4947]\teval-rmse:4.06632\ttrain-rmse:2.12023\n",
      "[4948]\teval-rmse:4.06548\ttrain-rmse:2.12022\n",
      "[4949]\teval-rmse:4.06245\ttrain-rmse:2.1201\n",
      "[4950]\teval-rmse:4.06457\ttrain-rmse:2.12037\n",
      "[4951]\teval-rmse:4.06372\ttrain-rmse:2.12037\n",
      "[4952]\teval-rmse:4.06566\ttrain-rmse:2.12037\n",
      "[4953]\teval-rmse:4.06674\ttrain-rmse:2.12034\n",
      "[4954]\teval-rmse:4.06739\ttrain-rmse:2.12036\n",
      "[4955]\teval-rmse:4.06833\ttrain-rmse:2.1204\n",
      "[4956]\teval-rmse:4.06893\ttrain-rmse:2.12043\n",
      "[4957]\teval-rmse:4.06971\ttrain-rmse:2.12046\n",
      "[4958]\teval-rmse:4.06793\ttrain-rmse:2.12043\n",
      "[4959]\teval-rmse:4.06852\ttrain-rmse:2.12044\n",
      "[4960]\teval-rmse:4.06952\ttrain-rmse:2.12047\n",
      "[4961]\teval-rmse:4.06786\ttrain-rmse:2.12045\n",
      "[4962]\teval-rmse:4.06677\ttrain-rmse:2.12045\n",
      "[4963]\teval-rmse:4.06618\ttrain-rmse:2.12037\n",
      "[4964]\teval-rmse:4.06711\ttrain-rmse:2.12041\n",
      "[4965]\teval-rmse:4.06653\ttrain-rmse:2.12038\n",
      "[4966]\teval-rmse:4.06757\ttrain-rmse:2.12042\n",
      "[4967]\teval-rmse:4.06647\ttrain-rmse:2.12041\n",
      "[4968]\teval-rmse:4.06716\ttrain-rmse:2.12044\n",
      "[4969]\teval-rmse:4.06982\ttrain-rmse:2.12046\n",
      "[4970]\teval-rmse:4.07201\ttrain-rmse:2.12047\n",
      "[4971]\teval-rmse:4.07041\ttrain-rmse:2.12044\n",
      "[4972]\teval-rmse:4.07116\ttrain-rmse:2.12047\n",
      "[4973]\teval-rmse:4.06888\ttrain-rmse:2.12037\n",
      "[4974]\teval-rmse:4.06994\ttrain-rmse:2.12041\n",
      "[4975]\teval-rmse:4.06909\ttrain-rmse:2.1204\n",
      "[4976]\teval-rmse:4.07098\ttrain-rmse:2.12042\n",
      "[4977]\teval-rmse:4.06943\ttrain-rmse:2.12039\n",
      "[4978]\teval-rmse:4.07084\ttrain-rmse:2.1204\n",
      "[4979]\teval-rmse:4.07222\ttrain-rmse:2.12047\n",
      "[4980]\teval-rmse:4.07321\ttrain-rmse:2.12052\n",
      "[4981]\teval-rmse:4.07119\ttrain-rmse:2.12048\n",
      "[4982]\teval-rmse:4.07049\ttrain-rmse:2.12034\n",
      "[4983]\teval-rmse:4.06936\ttrain-rmse:2.12034\n",
      "[4984]\teval-rmse:4.06863\ttrain-rmse:2.1202\n",
      "[4985]\teval-rmse:4.06995\ttrain-rmse:2.12026\n",
      "[4986]\teval-rmse:4.0715\ttrain-rmse:2.12028\n",
      "[4987]\teval-rmse:4.07234\ttrain-rmse:2.12032\n",
      "[4988]\teval-rmse:4.07037\ttrain-rmse:2.1203\n",
      "[4989]\teval-rmse:4.07223\ttrain-rmse:2.12033\n",
      "[4990]\teval-rmse:4.07289\ttrain-rmse:2.12036\n",
      "[4991]\teval-rmse:4.0726\ttrain-rmse:2.12034\n",
      "[4992]\teval-rmse:4.07196\ttrain-rmse:2.12027\n",
      "[4993]\teval-rmse:4.06965\ttrain-rmse:2.12014\n",
      "[4994]\teval-rmse:4.06876\ttrain-rmse:2.12013\n",
      "[4995]\teval-rmse:4.0676\ttrain-rmse:2.12008\n",
      "[4996]\teval-rmse:4.0665\ttrain-rmse:2.12006\n",
      "[4997]\teval-rmse:4.06581\ttrain-rmse:2.12004\n",
      "[4998]\teval-rmse:4.06632\ttrain-rmse:2.12006\n",
      "[4999]\teval-rmse:4.0648\ttrain-rmse:2.12004\n",
      "[5000]\teval-rmse:4.06347\ttrain-rmse:2.11999\n",
      "[5001]\teval-rmse:4.06232\ttrain-rmse:2.11998\n",
      "[5002]\teval-rmse:4.0637\ttrain-rmse:2.12003\n",
      "[5003]\teval-rmse:4.06591\ttrain-rmse:2.12002\n",
      "[5004]\teval-rmse:4.06429\ttrain-rmse:2.11995\n",
      "[5005]\teval-rmse:4.06246\ttrain-rmse:2.11989\n",
      "[5006]\teval-rmse:4.06107\ttrain-rmse:2.11971\n",
      "[5007]\teval-rmse:4.05942\ttrain-rmse:2.11951\n",
      "[5008]\teval-rmse:4.06077\ttrain-rmse:2.11955\n",
      "[5009]\teval-rmse:4.06295\ttrain-rmse:2.11949\n",
      "[5010]\teval-rmse:4.06213\ttrain-rmse:2.11949\n",
      "[5011]\teval-rmse:4.0639\ttrain-rmse:2.11949\n",
      "[5012]\teval-rmse:4.06221\ttrain-rmse:2.11925\n",
      "[5013]\teval-rmse:4.06133\ttrain-rmse:2.11924\n",
      "[5014]\teval-rmse:4.06186\ttrain-rmse:2.11926\n",
      "[5015]\teval-rmse:4.06342\ttrain-rmse:2.11924\n",
      "[5016]\teval-rmse:4.06491\ttrain-rmse:2.11921\n",
      "[5017]\teval-rmse:4.06695\ttrain-rmse:2.11923\n",
      "[5018]\teval-rmse:4.06699\ttrain-rmse:2.11923\n",
      "[5019]\teval-rmse:4.06969\ttrain-rmse:2.11935\n",
      "[5020]\teval-rmse:4.06901\ttrain-rmse:2.11931\n",
      "[5021]\teval-rmse:4.06981\ttrain-rmse:2.11936\n",
      "[5022]\teval-rmse:4.06972\ttrain-rmse:2.11935\n",
      "[5023]\teval-rmse:4.07087\ttrain-rmse:2.11941\n",
      "[5024]\teval-rmse:4.07183\ttrain-rmse:2.11946\n",
      "[5025]\teval-rmse:4.07392\ttrain-rmse:2.11975\n",
      "[5026]\teval-rmse:4.07513\ttrain-rmse:2.11982\n",
      "[5027]\teval-rmse:4.07692\ttrain-rmse:2.11993\n",
      "[5028]\teval-rmse:4.07949\ttrain-rmse:2.11993\n",
      "[5029]\teval-rmse:4.08126\ttrain-rmse:2.11995\n",
      "[5030]\teval-rmse:4.08058\ttrain-rmse:2.1199\n",
      "[5031]\teval-rmse:4.08148\ttrain-rmse:2.11996\n",
      "[5032]\teval-rmse:4.0808\ttrain-rmse:2.11985\n",
      "[5033]\teval-rmse:4.0791\ttrain-rmse:2.11978\n",
      "[5034]\teval-rmse:4.0801\ttrain-rmse:2.11978\n",
      "[5035]\teval-rmse:4.07873\ttrain-rmse:2.11969\n",
      "[5036]\teval-rmse:4.07694\ttrain-rmse:2.11958\n",
      "[5037]\teval-rmse:4.0776\ttrain-rmse:2.11962\n",
      "[5038]\teval-rmse:4.07681\ttrain-rmse:2.11952\n",
      "[5039]\teval-rmse:4.07942\ttrain-rmse:2.11959\n",
      "[5040]\teval-rmse:4.07831\ttrain-rmse:2.11952\n",
      "[5041]\teval-rmse:4.08081\ttrain-rmse:2.1196\n",
      "[5042]\teval-rmse:4.08065\ttrain-rmse:2.11958\n",
      "[5043]\teval-rmse:4.08247\ttrain-rmse:2.11957\n",
      "[5044]\teval-rmse:4.08434\ttrain-rmse:2.11964\n",
      "[5045]\teval-rmse:4.08261\ttrain-rmse:2.11935\n",
      "[5046]\teval-rmse:4.08114\ttrain-rmse:2.11932\n",
      "[5047]\teval-rmse:4.0822\ttrain-rmse:2.1194\n",
      "[5048]\teval-rmse:4.08042\ttrain-rmse:2.11927\n",
      "[5049]\teval-rmse:4.07869\ttrain-rmse:2.11921\n",
      "[5050]\teval-rmse:4.07788\ttrain-rmse:2.1191\n",
      "[5051]\teval-rmse:4.07996\ttrain-rmse:2.11941\n",
      "[5052]\teval-rmse:4.08253\ttrain-rmse:2.1195\n",
      "[5053]\teval-rmse:4.08403\ttrain-rmse:2.1196\n",
      "[5054]\teval-rmse:4.08575\ttrain-rmse:2.11973\n",
      "[5055]\teval-rmse:4.08727\ttrain-rmse:2.11973\n",
      "[5056]\teval-rmse:4.0843\ttrain-rmse:2.11951\n",
      "[5057]\teval-rmse:4.08221\ttrain-rmse:2.11946\n",
      "[5058]\teval-rmse:4.08014\ttrain-rmse:2.11941\n",
      "[5059]\teval-rmse:4.08187\ttrain-rmse:2.11947\n",
      "[5060]\teval-rmse:4.08038\ttrain-rmse:2.11923\n",
      "[5061]\teval-rmse:4.07883\ttrain-rmse:2.11902\n",
      "[5062]\teval-rmse:4.0774\ttrain-rmse:2.11878\n",
      "[5063]\teval-rmse:4.07817\ttrain-rmse:2.11877\n",
      "[5064]\teval-rmse:4.07916\ttrain-rmse:2.11884\n",
      "[5065]\teval-rmse:4.08177\ttrain-rmse:2.11885\n",
      "[5066]\teval-rmse:4.07967\ttrain-rmse:2.11881\n",
      "[5067]\teval-rmse:4.08129\ttrain-rmse:2.11887\n",
      "[5068]\teval-rmse:4.08388\ttrain-rmse:2.11889\n",
      "[5069]\teval-rmse:4.08516\ttrain-rmse:2.11898\n",
      "[5070]\teval-rmse:4.08514\ttrain-rmse:2.11898\n",
      "[5071]\teval-rmse:4.08505\ttrain-rmse:2.11897\n",
      "[5072]\teval-rmse:4.08722\ttrain-rmse:2.11907\n",
      "[5073]\teval-rmse:4.08759\ttrain-rmse:2.1191\n",
      "[5074]\teval-rmse:4.08585\ttrain-rmse:2.1188\n",
      "[5075]\teval-rmse:4.08414\ttrain-rmse:2.11867\n",
      "[5076]\teval-rmse:4.08446\ttrain-rmse:2.11869\n",
      "[5077]\teval-rmse:4.08153\ttrain-rmse:2.11847\n",
      "[5078]\teval-rmse:4.0818\ttrain-rmse:2.11849\n",
      "[5079]\teval-rmse:4.08447\ttrain-rmse:2.1186\n",
      "[5080]\teval-rmse:4.08546\ttrain-rmse:2.11868\n",
      "[5081]\teval-rmse:4.08441\ttrain-rmse:2.11863\n",
      "[5082]\teval-rmse:4.08435\ttrain-rmse:2.11862\n",
      "[5083]\teval-rmse:4.08585\ttrain-rmse:2.11866\n",
      "[5084]\teval-rmse:4.08479\ttrain-rmse:2.11858\n",
      "[5085]\teval-rmse:4.08662\ttrain-rmse:2.11866\n",
      "[5086]\teval-rmse:4.08882\ttrain-rmse:2.11872\n",
      "[5087]\teval-rmse:4.08588\ttrain-rmse:2.11849\n",
      "[5088]\teval-rmse:4.08433\ttrain-rmse:2.11762\n",
      "[5089]\teval-rmse:4.08405\ttrain-rmse:2.1176\n",
      "[5090]\teval-rmse:4.08667\ttrain-rmse:2.11764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5091]\teval-rmse:4.08927\ttrain-rmse:2.11777\n",
      "[5092]\teval-rmse:4.09002\ttrain-rmse:2.11781\n",
      "[5093]\teval-rmse:4.09072\ttrain-rmse:2.11784\n",
      "[5094]\teval-rmse:4.08971\ttrain-rmse:2.1178\n",
      "[5095]\teval-rmse:4.08805\ttrain-rmse:2.1177\n",
      "[5096]\teval-rmse:4.09018\ttrain-rmse:2.11775\n",
      "[5097]\teval-rmse:4.08832\ttrain-rmse:2.1176\n",
      "[5098]\teval-rmse:4.08813\ttrain-rmse:2.11759\n",
      "[5099]\teval-rmse:4.08633\ttrain-rmse:2.11754\n",
      "[5100]\teval-rmse:4.08419\ttrain-rmse:2.11749\n",
      "[5101]\teval-rmse:4.08329\ttrain-rmse:2.11745\n",
      "[5102]\teval-rmse:4.08176\ttrain-rmse:2.11738\n",
      "[5103]\teval-rmse:4.08248\ttrain-rmse:2.11742\n",
      "[5104]\teval-rmse:4.08425\ttrain-rmse:2.11755\n",
      "[5105]\teval-rmse:4.08596\ttrain-rmse:2.11757\n",
      "[5106]\teval-rmse:4.08421\ttrain-rmse:2.11748\n",
      "[5107]\teval-rmse:4.08573\ttrain-rmse:2.11751\n",
      "[5108]\teval-rmse:4.08549\ttrain-rmse:2.11749\n",
      "[5109]\teval-rmse:4.08363\ttrain-rmse:2.11739\n",
      "[5110]\teval-rmse:4.08172\ttrain-rmse:2.11726\n",
      "[5111]\teval-rmse:4.08226\ttrain-rmse:2.1173\n",
      "[5112]\teval-rmse:4.0839\ttrain-rmse:2.11741\n",
      "[5113]\teval-rmse:4.0824\ttrain-rmse:2.11737\n",
      "[5114]\teval-rmse:4.08391\ttrain-rmse:2.11737\n",
      "[5115]\teval-rmse:4.08527\ttrain-rmse:2.11747\n",
      "[5116]\teval-rmse:4.08774\ttrain-rmse:2.11754\n",
      "[5117]\teval-rmse:4.08812\ttrain-rmse:2.11757\n",
      "[5118]\teval-rmse:4.08662\ttrain-rmse:2.11753\n",
      "[5119]\teval-rmse:4.08633\ttrain-rmse:2.11751\n",
      "[5120]\teval-rmse:4.08481\ttrain-rmse:2.11743\n",
      "[5121]\teval-rmse:4.08554\ttrain-rmse:2.11748\n",
      "[5122]\teval-rmse:4.08568\ttrain-rmse:2.11749\n",
      "[5123]\teval-rmse:4.08717\ttrain-rmse:2.11756\n",
      "[5124]\teval-rmse:4.08399\ttrain-rmse:2.11732\n",
      "[5125]\teval-rmse:4.08104\ttrain-rmse:2.11712\n",
      "[5126]\teval-rmse:4.08157\ttrain-rmse:2.11716\n",
      "[5127]\teval-rmse:4.08216\ttrain-rmse:2.11718\n",
      "[5128]\teval-rmse:4.08469\ttrain-rmse:2.11721\n",
      "[5129]\teval-rmse:4.08554\ttrain-rmse:2.11724\n",
      "[5130]\teval-rmse:4.0874\ttrain-rmse:2.11733\n",
      "[5131]\teval-rmse:4.08588\ttrain-rmse:2.11653\n",
      "[5132]\teval-rmse:4.0866\ttrain-rmse:2.11658\n",
      "[5133]\teval-rmse:4.08467\ttrain-rmse:2.11652\n",
      "[5134]\teval-rmse:4.08373\ttrain-rmse:2.11647\n",
      "[5135]\teval-rmse:4.08154\ttrain-rmse:2.11637\n",
      "[5136]\teval-rmse:4.08331\ttrain-rmse:2.11649\n",
      "[5137]\teval-rmse:4.08547\ttrain-rmse:2.1166\n",
      "[5138]\teval-rmse:4.08258\ttrain-rmse:2.11639\n",
      "[5139]\teval-rmse:4.08384\ttrain-rmse:2.11648\n",
      "[5140]\teval-rmse:4.08277\ttrain-rmse:2.11645\n",
      "[5141]\teval-rmse:4.08342\ttrain-rmse:2.11649\n",
      "[5142]\teval-rmse:4.08413\ttrain-rmse:2.11654\n",
      "[5143]\teval-rmse:4.08394\ttrain-rmse:2.11653\n",
      "[5144]\teval-rmse:4.08461\ttrain-rmse:2.11653\n",
      "[5145]\teval-rmse:4.08392\ttrain-rmse:2.11643\n",
      "[5146]\teval-rmse:4.08485\ttrain-rmse:2.11644\n",
      "[5147]\teval-rmse:4.08597\ttrain-rmse:2.11652\n",
      "[5148]\teval-rmse:4.08701\ttrain-rmse:2.11657\n",
      "[5149]\teval-rmse:4.08547\ttrain-rmse:2.11635\n",
      "[5150]\teval-rmse:4.08785\ttrain-rmse:2.11654\n",
      "[5151]\teval-rmse:4.08906\ttrain-rmse:2.1166\n",
      "[5152]\teval-rmse:4.08801\ttrain-rmse:2.11654\n",
      "[5153]\teval-rmse:4.08793\ttrain-rmse:2.11653\n",
      "[5154]\teval-rmse:4.08521\ttrain-rmse:2.11632\n",
      "[5155]\teval-rmse:4.08664\ttrain-rmse:2.11643\n",
      "[5156]\teval-rmse:4.08693\ttrain-rmse:2.11645\n",
      "[5157]\teval-rmse:4.08423\ttrain-rmse:2.11624\n",
      "[5158]\teval-rmse:4.08517\ttrain-rmse:2.11632\n",
      "[5159]\teval-rmse:4.08624\ttrain-rmse:2.11637\n",
      "[5160]\teval-rmse:4.08626\ttrain-rmse:2.11637\n",
      "[5161]\teval-rmse:4.08449\ttrain-rmse:2.11606\n",
      "[5162]\teval-rmse:4.0815\ttrain-rmse:2.11583\n",
      "[5163]\teval-rmse:4.08397\ttrain-rmse:2.11595\n",
      "[5164]\teval-rmse:4.08244\ttrain-rmse:2.1151\n",
      "[5165]\teval-rmse:4.08096\ttrain-rmse:2.11502\n",
      "[5166]\teval-rmse:4.08191\ttrain-rmse:2.11502\n",
      "[5167]\teval-rmse:4.08062\ttrain-rmse:2.11498\n",
      "[5168]\teval-rmse:4.07906\ttrain-rmse:2.11487\n",
      "[5169]\teval-rmse:4.07771\ttrain-rmse:2.11483\n",
      "[5170]\teval-rmse:4.07566\ttrain-rmse:2.11474\n",
      "[5171]\teval-rmse:4.0776\ttrain-rmse:2.11486\n",
      "[5172]\teval-rmse:4.07844\ttrain-rmse:2.1149\n",
      "[5173]\teval-rmse:4.0767\ttrain-rmse:2.11461\n",
      "[5174]\teval-rmse:4.0783\ttrain-rmse:2.11472\n",
      "[5175]\teval-rmse:4.07963\ttrain-rmse:2.11482\n",
      "[5176]\teval-rmse:4.08141\ttrain-rmse:2.1149\n",
      "[5177]\teval-rmse:4.08048\ttrain-rmse:2.11485\n",
      "[5178]\teval-rmse:4.07927\ttrain-rmse:2.11479\n",
      "[5179]\teval-rmse:4.07658\ttrain-rmse:2.11467\n",
      "[5180]\teval-rmse:4.0758\ttrain-rmse:2.11453\n",
      "[5181]\teval-rmse:4.07824\ttrain-rmse:2.11471\n",
      "[5182]\teval-rmse:4.07708\ttrain-rmse:2.11465\n",
      "[5183]\teval-rmse:4.07595\ttrain-rmse:2.1146\n",
      "[5184]\teval-rmse:4.07664\ttrain-rmse:2.11464\n",
      "[5185]\teval-rmse:4.07529\ttrain-rmse:2.11386\n",
      "[5186]\teval-rmse:4.07383\ttrain-rmse:2.11325\n",
      "[5187]\teval-rmse:4.07531\ttrain-rmse:2.11325\n",
      "[5188]\teval-rmse:4.0767\ttrain-rmse:2.11326\n",
      "[5189]\teval-rmse:4.07611\ttrain-rmse:2.11321\n",
      "[5190]\teval-rmse:4.07862\ttrain-rmse:2.11333\n",
      "[5191]\teval-rmse:4.0771\ttrain-rmse:2.1131\n",
      "[5192]\teval-rmse:4.07717\ttrain-rmse:2.1131\n",
      "[5193]\teval-rmse:4.07703\ttrain-rmse:2.11309\n",
      "[5194]\teval-rmse:4.07801\ttrain-rmse:2.11314\n",
      "[5195]\teval-rmse:4.07948\ttrain-rmse:2.11326\n",
      "[5196]\teval-rmse:4.07748\ttrain-rmse:2.11309\n",
      "[5197]\teval-rmse:4.07662\ttrain-rmse:2.11303\n",
      "[5198]\teval-rmse:4.07587\ttrain-rmse:2.11299\n",
      "[5199]\teval-rmse:4.07738\ttrain-rmse:2.11301\n",
      "[5200]\teval-rmse:4.07886\ttrain-rmse:2.11308\n",
      "[5201]\teval-rmse:4.0794\ttrain-rmse:2.1131\n",
      "[5202]\teval-rmse:4.07974\ttrain-rmse:2.11313\n",
      "[5203]\teval-rmse:4.07715\ttrain-rmse:2.11306\n",
      "[5204]\teval-rmse:4.07575\ttrain-rmse:2.11299\n",
      "[5205]\teval-rmse:4.07672\ttrain-rmse:2.11303\n",
      "[5206]\teval-rmse:4.07683\ttrain-rmse:2.11304\n",
      "[5207]\teval-rmse:4.07682\ttrain-rmse:2.11304\n",
      "[5208]\teval-rmse:4.07771\ttrain-rmse:2.11311\n",
      "[5209]\teval-rmse:4.07624\ttrain-rmse:2.11247\n",
      "[5210]\teval-rmse:4.07634\ttrain-rmse:2.11247\n",
      "[5211]\teval-rmse:4.07772\ttrain-rmse:2.11259\n",
      "[5212]\teval-rmse:4.08022\ttrain-rmse:2.11263\n",
      "[5213]\teval-rmse:4.07727\ttrain-rmse:2.11239\n",
      "[5214]\teval-rmse:4.07933\ttrain-rmse:2.11256\n",
      "[5215]\teval-rmse:4.07716\ttrain-rmse:2.11244\n",
      "[5216]\teval-rmse:4.07806\ttrain-rmse:2.11251\n",
      "[5217]\teval-rmse:4.07973\ttrain-rmse:2.11259\n",
      "[5218]\teval-rmse:4.07825\ttrain-rmse:2.11236\n",
      "[5219]\teval-rmse:4.07883\ttrain-rmse:2.11241\n",
      "[5220]\teval-rmse:4.08079\ttrain-rmse:2.11258\n",
      "[5221]\teval-rmse:4.0805\ttrain-rmse:2.11255\n",
      "[5222]\teval-rmse:4.07896\ttrain-rmse:2.11246\n",
      "[5223]\teval-rmse:4.08064\ttrain-rmse:2.11255\n",
      "[5224]\teval-rmse:4.07913\ttrain-rmse:2.11177\n",
      "[5225]\teval-rmse:4.08036\ttrain-rmse:2.11179\n",
      "[5226]\teval-rmse:4.07949\ttrain-rmse:2.11171\n",
      "[5227]\teval-rmse:4.08044\ttrain-rmse:2.11176\n",
      "[5228]\teval-rmse:4.07969\ttrain-rmse:2.11163\n",
      "[5229]\teval-rmse:4.07813\ttrain-rmse:2.11139\n",
      "[5230]\teval-rmse:4.07673\ttrain-rmse:2.1107\n",
      "[5231]\teval-rmse:4.07732\ttrain-rmse:2.11076\n",
      "[5232]\teval-rmse:4.07663\ttrain-rmse:2.11066\n",
      "[5233]\teval-rmse:4.07555\ttrain-rmse:2.11062\n",
      "[5234]\teval-rmse:4.07259\ttrain-rmse:2.11036\n",
      "[5235]\teval-rmse:4.07122\ttrain-rmse:2.11032\n",
      "[5236]\teval-rmse:4.06973\ttrain-rmse:2.11024\n",
      "[5237]\teval-rmse:4.07178\ttrain-rmse:2.11054\n",
      "[5238]\teval-rmse:4.07071\ttrain-rmse:2.11051\n",
      "[5239]\teval-rmse:4.06854\ttrain-rmse:2.11041\n",
      "[5240]\teval-rmse:4.06678\ttrain-rmse:2.11019\n",
      "[5241]\teval-rmse:4.06514\ttrain-rmse:2.11007\n",
      "[5242]\teval-rmse:4.06562\ttrain-rmse:2.1101\n",
      "[5243]\teval-rmse:4.0661\ttrain-rmse:2.11013\n",
      "[5244]\teval-rmse:4.06651\ttrain-rmse:2.11014\n",
      "[5245]\teval-rmse:4.06721\ttrain-rmse:2.11017\n",
      "[5246]\teval-rmse:4.06566\ttrain-rmse:2.1101\n",
      "[5247]\teval-rmse:4.06497\ttrain-rmse:2.10997\n",
      "[5248]\teval-rmse:4.06663\ttrain-rmse:2.11009\n",
      "[5249]\teval-rmse:4.06766\ttrain-rmse:2.11017\n",
      "[5250]\teval-rmse:4.06512\ttrain-rmse:2.11013\n",
      "[5251]\teval-rmse:4.06326\ttrain-rmse:2.11005\n",
      "[5252]\teval-rmse:4.06077\ttrain-rmse:2.10996\n",
      "[5253]\teval-rmse:4.06239\ttrain-rmse:2.11001\n",
      "[5254]\teval-rmse:4.06328\ttrain-rmse:2.11007\n",
      "[5255]\teval-rmse:4.0642\ttrain-rmse:2.11014\n",
      "[5256]\teval-rmse:4.06259\ttrain-rmse:2.11007\n",
      "[5257]\teval-rmse:4.0635\ttrain-rmse:2.11014\n",
      "[5258]\teval-rmse:4.06476\ttrain-rmse:2.11018\n",
      "[5259]\teval-rmse:4.06177\ttrain-rmse:2.10996\n",
      "[5260]\teval-rmse:4.05958\ttrain-rmse:2.10982\n",
      "[5261]\teval-rmse:4.05819\ttrain-rmse:2.10974\n",
      "[5262]\teval-rmse:4.05545\ttrain-rmse:2.1096\n",
      "[5263]\teval-rmse:4.05303\ttrain-rmse:2.10948\n",
      "[5264]\teval-rmse:4.05117\ttrain-rmse:2.10938\n",
      "[5265]\teval-rmse:4.0511\ttrain-rmse:2.10937\n",
      "[5266]\teval-rmse:4.05016\ttrain-rmse:2.10936\n",
      "[5267]\teval-rmse:4.04994\ttrain-rmse:2.10935\n",
      "[5268]\teval-rmse:4.04973\ttrain-rmse:2.10934\n",
      "[5269]\teval-rmse:4.04972\ttrain-rmse:2.10934\n",
      "[5270]\teval-rmse:4.05197\ttrain-rmse:2.1093\n",
      "[5271]\teval-rmse:4.05068\ttrain-rmse:2.1093\n",
      "[5272]\teval-rmse:4.05172\ttrain-rmse:2.10934\n",
      "[5273]\teval-rmse:4.05358\ttrain-rmse:2.10931\n",
      "[5274]\teval-rmse:4.05099\ttrain-rmse:2.10926\n",
      "[5275]\teval-rmse:4.04933\ttrain-rmse:2.10907\n",
      "[5276]\teval-rmse:4.04798\ttrain-rmse:2.10832\n",
      "[5277]\teval-rmse:4.04603\ttrain-rmse:2.10835\n",
      "[5278]\teval-rmse:4.04728\ttrain-rmse:2.10839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5279]\teval-rmse:4.04745\ttrain-rmse:2.1084\n",
      "[5280]\teval-rmse:4.04979\ttrain-rmse:2.10843\n",
      "[5281]\teval-rmse:4.04995\ttrain-rmse:2.10844\n",
      "[5282]\teval-rmse:4.04752\ttrain-rmse:2.10839\n",
      "[5283]\teval-rmse:4.04971\ttrain-rmse:2.10837\n",
      "[5284]\teval-rmse:4.0484\ttrain-rmse:2.10817\n",
      "[5285]\teval-rmse:4.04712\ttrain-rmse:2.10798\n",
      "[5286]\teval-rmse:4.04896\ttrain-rmse:2.10801\n",
      "[5287]\teval-rmse:4.04784\ttrain-rmse:2.10801\n",
      "[5288]\teval-rmse:4.0462\ttrain-rmse:2.10779\n",
      "[5289]\teval-rmse:4.04571\ttrain-rmse:2.1077\n",
      "[5290]\teval-rmse:4.04686\ttrain-rmse:2.10775\n",
      "[5291]\teval-rmse:4.0463\ttrain-rmse:2.1077\n",
      "[5292]\teval-rmse:4.04694\ttrain-rmse:2.10772\n",
      "[5293]\teval-rmse:4.04827\ttrain-rmse:2.10769\n",
      "[5294]\teval-rmse:4.04635\ttrain-rmse:2.10766\n",
      "[5295]\teval-rmse:4.04855\ttrain-rmse:2.1077\n",
      "[5296]\teval-rmse:4.04966\ttrain-rmse:2.10775\n",
      "[5297]\teval-rmse:4.04853\ttrain-rmse:2.10772\n",
      "[5298]\teval-rmse:4.05085\ttrain-rmse:2.10777\n",
      "[5299]\teval-rmse:4.05251\ttrain-rmse:2.10786\n",
      "[5300]\teval-rmse:4.05059\ttrain-rmse:2.10781\n",
      "[5301]\teval-rmse:4.05069\ttrain-rmse:2.10781\n",
      "[5302]\teval-rmse:4.04938\ttrain-rmse:2.10725\n",
      "[5303]\teval-rmse:4.0505\ttrain-rmse:2.10731\n",
      "[5304]\teval-rmse:4.04883\ttrain-rmse:2.10712\n",
      "[5305]\teval-rmse:4.04716\ttrain-rmse:2.10694\n",
      "[5306]\teval-rmse:4.04665\ttrain-rmse:2.10684\n",
      "[5307]\teval-rmse:4.04521\ttrain-rmse:2.10681\n",
      "[5308]\teval-rmse:4.04502\ttrain-rmse:2.1068\n",
      "[5309]\teval-rmse:4.04419\ttrain-rmse:2.1068\n",
      "[5310]\teval-rmse:4.0423\ttrain-rmse:2.10677\n",
      "[5311]\teval-rmse:4.04429\ttrain-rmse:2.10679\n",
      "[5312]\teval-rmse:4.0468\ttrain-rmse:2.10675\n",
      "[5313]\teval-rmse:4.0483\ttrain-rmse:2.10674\n",
      "[5314]\teval-rmse:4.04948\ttrain-rmse:2.10682\n",
      "[5315]\teval-rmse:4.0506\ttrain-rmse:2.10688\n",
      "[5316]\teval-rmse:4.05206\ttrain-rmse:2.10685\n",
      "[5317]\teval-rmse:4.05154\ttrain-rmse:2.10682\n",
      "[5318]\teval-rmse:4.05184\ttrain-rmse:2.10684\n",
      "[5319]\teval-rmse:4.05048\ttrain-rmse:2.10617\n",
      "[5320]\teval-rmse:4.0495\ttrain-rmse:2.10614\n",
      "[5321]\teval-rmse:4.05077\ttrain-rmse:2.10611\n",
      "[5322]\teval-rmse:4.04961\ttrain-rmse:2.10608\n",
      "[5323]\teval-rmse:4.05116\ttrain-rmse:2.10612\n",
      "[5324]\teval-rmse:4.04992\ttrain-rmse:2.10604\n",
      "[5325]\teval-rmse:4.05173\ttrain-rmse:2.10609\n",
      "[5326]\teval-rmse:4.05418\ttrain-rmse:2.10608\n",
      "[5327]\teval-rmse:4.05274\ttrain-rmse:2.10602\n",
      "[5328]\teval-rmse:4.05211\ttrain-rmse:2.10591\n",
      "[5329]\teval-rmse:4.05337\ttrain-rmse:2.10599\n",
      "[5330]\teval-rmse:4.05519\ttrain-rmse:2.10604\n",
      "[5331]\teval-rmse:4.05344\ttrain-rmse:2.10593\n",
      "[5332]\teval-rmse:4.05416\ttrain-rmse:2.10598\n",
      "[5333]\teval-rmse:4.05584\ttrain-rmse:2.10609\n",
      "[5334]\teval-rmse:4.0567\ttrain-rmse:2.10615\n",
      "[5335]\teval-rmse:4.05675\ttrain-rmse:2.10615\n",
      "[5336]\teval-rmse:4.05793\ttrain-rmse:2.10623\n",
      "[5337]\teval-rmse:4.05928\ttrain-rmse:2.10633\n",
      "[5338]\teval-rmse:4.05785\ttrain-rmse:2.10556\n",
      "[5339]\teval-rmse:4.0586\ttrain-rmse:2.10562\n",
      "[5340]\teval-rmse:4.0573\ttrain-rmse:2.10559\n",
      "[5341]\teval-rmse:4.05551\ttrain-rmse:2.10546\n",
      "[5342]\teval-rmse:4.05381\ttrain-rmse:2.10525\n",
      "[5343]\teval-rmse:4.05361\ttrain-rmse:2.10524\n",
      "[5344]\teval-rmse:4.0554\ttrain-rmse:2.1053\n",
      "[5345]\teval-rmse:4.05454\ttrain-rmse:2.10526\n",
      "[5346]\teval-rmse:4.05687\ttrain-rmse:2.10535\n",
      "[5347]\teval-rmse:4.05745\ttrain-rmse:2.1054\n",
      "[5348]\teval-rmse:4.05813\ttrain-rmse:2.10545\n",
      "[5349]\teval-rmse:4.05645\ttrain-rmse:2.10522\n",
      "[5350]\teval-rmse:4.05754\ttrain-rmse:2.10527\n",
      "[5351]\teval-rmse:4.05685\ttrain-rmse:2.10516\n",
      "[5352]\teval-rmse:4.05549\ttrain-rmse:2.10496\n",
      "[5353]\teval-rmse:4.05289\ttrain-rmse:2.10477\n",
      "[5354]\teval-rmse:4.05056\ttrain-rmse:2.10461\n",
      "[5355]\teval-rmse:4.05067\ttrain-rmse:2.10462\n",
      "[5356]\teval-rmse:4.04931\ttrain-rmse:2.10447\n",
      "[5357]\teval-rmse:4.04705\ttrain-rmse:2.10439\n",
      "[5358]\teval-rmse:4.04797\ttrain-rmse:2.10445\n",
      "[5359]\teval-rmse:4.04808\ttrain-rmse:2.10445\n",
      "[5360]\teval-rmse:4.04648\ttrain-rmse:2.10439\n",
      "[5361]\teval-rmse:4.04407\ttrain-rmse:2.10425\n",
      "[5362]\teval-rmse:4.04378\ttrain-rmse:2.10424\n",
      "[5363]\teval-rmse:4.04261\ttrain-rmse:2.10421\n",
      "[5364]\teval-rmse:4.04118\ttrain-rmse:2.10418\n",
      "[5365]\teval-rmse:4.03903\ttrain-rmse:2.10405\n",
      "[5366]\teval-rmse:4.04017\ttrain-rmse:2.1041\n",
      "[5367]\teval-rmse:4.04117\ttrain-rmse:2.10412\n",
      "[5368]\teval-rmse:4.04205\ttrain-rmse:2.10414\n",
      "[5369]\teval-rmse:4.04046\ttrain-rmse:2.10396\n",
      "[5370]\teval-rmse:4.03873\ttrain-rmse:2.10392\n",
      "[5371]\teval-rmse:4.03886\ttrain-rmse:2.10393\n",
      "[5372]\teval-rmse:4.04118\ttrain-rmse:2.10397\n",
      "[5373]\teval-rmse:4.03989\ttrain-rmse:2.10343\n",
      "[5374]\teval-rmse:4.03863\ttrain-rmse:2.1034\n",
      "[5375]\teval-rmse:4.03932\ttrain-rmse:2.10342\n",
      "[5376]\teval-rmse:4.04064\ttrain-rmse:2.10338\n",
      "[5377]\teval-rmse:4.04016\ttrain-rmse:2.1033\n",
      "[5378]\teval-rmse:4.0407\ttrain-rmse:2.10333\n",
      "[5379]\teval-rmse:4.04203\ttrain-rmse:2.1033\n",
      "[5380]\teval-rmse:4.04071\ttrain-rmse:2.10323\n",
      "[5381]\teval-rmse:4.04024\ttrain-rmse:2.10321\n",
      "[5382]\teval-rmse:4.03929\ttrain-rmse:2.10319\n",
      "[5383]\teval-rmse:4.03847\ttrain-rmse:2.10317\n",
      "[5384]\teval-rmse:4.03789\ttrain-rmse:2.10314\n",
      "[5385]\teval-rmse:4.03627\ttrain-rmse:2.10297\n",
      "[5386]\teval-rmse:4.03431\ttrain-rmse:2.10299\n",
      "[5387]\teval-rmse:4.03309\ttrain-rmse:2.10297\n",
      "[5388]\teval-rmse:4.03187\ttrain-rmse:2.10299\n",
      "[5389]\teval-rmse:4.03341\ttrain-rmse:2.103\n",
      "[5390]\teval-rmse:4.0342\ttrain-rmse:2.10303\n",
      "[5391]\teval-rmse:4.03308\ttrain-rmse:2.10304\n",
      "[5392]\teval-rmse:4.03288\ttrain-rmse:2.10303\n",
      "[5393]\teval-rmse:4.03289\ttrain-rmse:2.10303\n",
      "[5394]\teval-rmse:4.03403\ttrain-rmse:2.10308\n",
      "[5395]\teval-rmse:4.0349\ttrain-rmse:2.10311\n",
      "[5396]\teval-rmse:4.03372\ttrain-rmse:2.10309\n",
      "[5397]\teval-rmse:4.03354\ttrain-rmse:2.10308\n",
      "[5398]\teval-rmse:4.03093\ttrain-rmse:2.10299\n",
      "[5399]\teval-rmse:4.0323\ttrain-rmse:2.10304\n",
      "[5400]\teval-rmse:4.03079\ttrain-rmse:2.10285\n",
      "[5401]\teval-rmse:4.03028\ttrain-rmse:2.10278\n",
      "[5402]\teval-rmse:4.02907\ttrain-rmse:2.1028\n",
      "[5403]\teval-rmse:4.02902\ttrain-rmse:2.1028\n",
      "[5404]\teval-rmse:4.03151\ttrain-rmse:2.10282\n",
      "[5405]\teval-rmse:4.02957\ttrain-rmse:2.10274\n",
      "[5406]\teval-rmse:4.0272\ttrain-rmse:2.10279\n",
      "[5407]\teval-rmse:4.02508\ttrain-rmse:2.10274\n",
      "[5408]\teval-rmse:4.02388\ttrain-rmse:2.10221\n",
      "[5409]\teval-rmse:4.02447\ttrain-rmse:2.1022\n",
      "[5410]\teval-rmse:4.02303\ttrain-rmse:2.1022\n",
      "[5411]\teval-rmse:4.02391\ttrain-rmse:2.10222\n",
      "[5412]\teval-rmse:4.02111\ttrain-rmse:2.10216\n",
      "[5413]\teval-rmse:4.0215\ttrain-rmse:2.10217\n",
      "[5414]\teval-rmse:4.0212\ttrain-rmse:2.10216\n",
      "[5415]\teval-rmse:4.01995\ttrain-rmse:2.10214\n",
      "[5416]\teval-rmse:4.01878\ttrain-rmse:2.10218\n",
      "[5417]\teval-rmse:4.02019\ttrain-rmse:2.10217\n",
      "[5418]\teval-rmse:4.01872\ttrain-rmse:2.10204\n",
      "[5419]\teval-rmse:4.01719\ttrain-rmse:2.10203\n",
      "[5420]\teval-rmse:4.01535\ttrain-rmse:2.10205\n",
      "[5421]\teval-rmse:4.01399\ttrain-rmse:2.10211\n",
      "[5422]\teval-rmse:4.01467\ttrain-rmse:2.10211\n",
      "[5423]\teval-rmse:4.0172\ttrain-rmse:2.10201\n",
      "[5424]\teval-rmse:4.01574\ttrain-rmse:2.10187\n",
      "[5425]\teval-rmse:4.01581\ttrain-rmse:2.10187\n",
      "[5426]\teval-rmse:4.01464\ttrain-rmse:2.10175\n",
      "[5427]\teval-rmse:4.01408\ttrain-rmse:2.10172\n",
      "[5428]\teval-rmse:4.01591\ttrain-rmse:2.10169\n",
      "[5429]\teval-rmse:4.0154\ttrain-rmse:2.10161\n",
      "[5430]\teval-rmse:4.01283\ttrain-rmse:2.10165\n",
      "[5431]\teval-rmse:4.01438\ttrain-rmse:2.10162\n",
      "[5432]\teval-rmse:4.01703\ttrain-rmse:2.1015\n",
      "[5433]\teval-rmse:4.01446\ttrain-rmse:2.10147\n",
      "[5434]\teval-rmse:4.01406\ttrain-rmse:2.10146\n",
      "[5435]\teval-rmse:4.01259\ttrain-rmse:2.10131\n",
      "[5436]\teval-rmse:4.0117\ttrain-rmse:2.10132\n",
      "[5437]\teval-rmse:4.01119\ttrain-rmse:2.10128\n",
      "[5438]\teval-rmse:4.01002\ttrain-rmse:2.1013\n",
      "[5439]\teval-rmse:4.01263\ttrain-rmse:2.10125\n",
      "[5440]\teval-rmse:4.01113\ttrain-rmse:2.10128\n",
      "[5441]\teval-rmse:4.01254\ttrain-rmse:2.10125\n",
      "[5442]\teval-rmse:4.01287\ttrain-rmse:2.10125\n",
      "[5443]\teval-rmse:4.01498\ttrain-rmse:2.10114\n",
      "[5444]\teval-rmse:4.0165\ttrain-rmse:2.10112\n",
      "[5445]\teval-rmse:4.01742\ttrain-rmse:2.10113\n",
      "[5446]\teval-rmse:4.01925\ttrain-rmse:2.10106\n",
      "[5447]\teval-rmse:4.01692\ttrain-rmse:2.10114\n",
      "[5448]\teval-rmse:4.01527\ttrain-rmse:2.10113\n",
      "[5449]\teval-rmse:4.01682\ttrain-rmse:2.10115\n",
      "[5450]\teval-rmse:4.01818\ttrain-rmse:2.10108\n",
      "[5451]\teval-rmse:4.02083\ttrain-rmse:2.10098\n",
      "[5452]\teval-rmse:4.02301\ttrain-rmse:2.10119\n",
      "[5453]\teval-rmse:4.02296\ttrain-rmse:2.10118\n",
      "[5454]\teval-rmse:4.02519\ttrain-rmse:2.10113\n",
      "[5455]\teval-rmse:4.02704\ttrain-rmse:2.10108\n",
      "[5456]\teval-rmse:4.02776\ttrain-rmse:2.10108\n",
      "[5457]\teval-rmse:4.02665\ttrain-rmse:2.10107\n",
      "[5458]\teval-rmse:4.02877\ttrain-rmse:2.10129\n",
      "[5459]\teval-rmse:4.02991\ttrain-rmse:2.10133\n",
      "[5460]\teval-rmse:4.03144\ttrain-rmse:2.1013\n",
      "[5461]\teval-rmse:4.03335\ttrain-rmse:2.10136\n",
      "[5462]\teval-rmse:4.03163\ttrain-rmse:2.1013\n",
      "[5463]\teval-rmse:4.03232\ttrain-rmse:2.10132\n",
      "[5464]\teval-rmse:4.03107\ttrain-rmse:2.10131\n",
      "[5465]\teval-rmse:4.02979\ttrain-rmse:2.10118\n",
      "[5466]\teval-rmse:4.0316\ttrain-rmse:2.10113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5467]\teval-rmse:4.03331\ttrain-rmse:2.10119\n",
      "[5468]\teval-rmse:4.03318\ttrain-rmse:2.10119\n",
      "[5469]\teval-rmse:4.0352\ttrain-rmse:2.10115\n",
      "[5470]\teval-rmse:4.03318\ttrain-rmse:2.10108\n",
      "[5471]\teval-rmse:4.03061\ttrain-rmse:2.10098\n",
      "[5472]\teval-rmse:4.03137\ttrain-rmse:2.101\n",
      "[5473]\teval-rmse:4.03013\ttrain-rmse:2.10097\n",
      "[5474]\teval-rmse:4.03127\ttrain-rmse:2.10101\n",
      "[5475]\teval-rmse:4.03214\ttrain-rmse:2.10101\n",
      "[5476]\teval-rmse:4.03298\ttrain-rmse:2.10105\n",
      "[5477]\teval-rmse:4.03174\ttrain-rmse:2.10106\n",
      "[5478]\teval-rmse:4.02998\ttrain-rmse:2.10101\n",
      "[5479]\teval-rmse:4.02717\ttrain-rmse:2.10094\n",
      "[5480]\teval-rmse:4.02515\ttrain-rmse:2.10099\n",
      "[5481]\teval-rmse:4.02457\ttrain-rmse:2.10092\n",
      "[5482]\teval-rmse:4.02612\ttrain-rmse:2.10087\n",
      "[5483]\teval-rmse:4.02534\ttrain-rmse:2.10089\n",
      "[5484]\teval-rmse:4.02482\ttrain-rmse:2.10081\n",
      "[5485]\teval-rmse:4.02746\ttrain-rmse:2.10075\n",
      "[5486]\teval-rmse:4.02701\ttrain-rmse:2.10067\n",
      "[5487]\teval-rmse:4.02919\ttrain-rmse:2.10089\n",
      "[5488]\teval-rmse:4.02732\ttrain-rmse:2.10092\n",
      "[5489]\teval-rmse:4.02953\ttrain-rmse:2.10088\n",
      "[5490]\teval-rmse:4.02907\ttrain-rmse:2.1008\n",
      "[5491]\teval-rmse:4.02796\ttrain-rmse:2.10079\n",
      "[5492]\teval-rmse:4.02848\ttrain-rmse:2.1008\n",
      "[5493]\teval-rmse:4.02934\ttrain-rmse:2.1008\n",
      "[5494]\teval-rmse:4.03071\ttrain-rmse:2.10076\n",
      "[5495]\teval-rmse:4.0293\ttrain-rmse:2.10075\n",
      "[5496]\teval-rmse:4.02945\ttrain-rmse:2.10076\n",
      "[5497]\teval-rmse:4.0302\ttrain-rmse:2.10078\n",
      "[5498]\teval-rmse:4.02818\ttrain-rmse:2.10082\n",
      "[5499]\teval-rmse:4.02758\ttrain-rmse:2.10073\n",
      "[5500]\teval-rmse:4.02937\ttrain-rmse:2.10069\n",
      "[5501]\teval-rmse:4.02787\ttrain-rmse:2.10065\n",
      "[5502]\teval-rmse:4.02862\ttrain-rmse:2.10065\n",
      "[5503]\teval-rmse:4.02743\ttrain-rmse:2.10068\n",
      "[5504]\teval-rmse:4.02682\ttrain-rmse:2.10067\n",
      "[5505]\teval-rmse:4.02912\ttrain-rmse:2.10068\n",
      "[5506]\teval-rmse:4.03114\ttrain-rmse:2.1007\n",
      "[5507]\teval-rmse:4.02968\ttrain-rmse:2.10068\n",
      "[5508]\teval-rmse:4.03034\ttrain-rmse:2.1007\n",
      "[5509]\teval-rmse:4.03182\ttrain-rmse:2.10074\n",
      "[5510]\teval-rmse:4.03123\ttrain-rmse:2.10065\n",
      "[5511]\teval-rmse:4.03238\ttrain-rmse:2.10069\n",
      "[5512]\teval-rmse:4.03288\ttrain-rmse:2.10071\n",
      "[5513]\teval-rmse:4.03442\ttrain-rmse:2.10073\n",
      "[5514]\teval-rmse:4.03443\ttrain-rmse:2.10073\n",
      "[5515]\teval-rmse:4.03234\ttrain-rmse:2.10069\n",
      "[5516]\teval-rmse:4.02934\ttrain-rmse:2.10061\n",
      "[5517]\teval-rmse:4.02806\ttrain-rmse:2.09989\n",
      "[5518]\teval-rmse:4.02913\ttrain-rmse:2.0999\n",
      "[5519]\teval-rmse:4.03036\ttrain-rmse:2.09993\n",
      "[5520]\teval-rmse:4.02783\ttrain-rmse:2.09986\n",
      "[5521]\teval-rmse:4.02967\ttrain-rmse:2.09988\n",
      "[5522]\teval-rmse:4.02773\ttrain-rmse:2.09982\n",
      "[5523]\teval-rmse:4.02838\ttrain-rmse:2.09984\n",
      "[5524]\teval-rmse:4.02622\ttrain-rmse:2.09983\n",
      "[5525]\teval-rmse:4.02435\ttrain-rmse:2.09986\n",
      "[5526]\teval-rmse:4.02617\ttrain-rmse:2.09986\n",
      "[5527]\teval-rmse:4.024\ttrain-rmse:2.09985\n",
      "[5528]\teval-rmse:4.02229\ttrain-rmse:2.09985\n",
      "[5529]\teval-rmse:4.02421\ttrain-rmse:2.0999\n",
      "[5530]\teval-rmse:4.02345\ttrain-rmse:2.09991\n",
      "[5531]\teval-rmse:4.02252\ttrain-rmse:2.09991\n",
      "[5532]\teval-rmse:4.02066\ttrain-rmse:2.09995\n",
      "[5533]\teval-rmse:4.0192\ttrain-rmse:2.09993\n",
      "[5534]\teval-rmse:4.01673\ttrain-rmse:2.09996\n",
      "[5535]\teval-rmse:4.01874\ttrain-rmse:2.09994\n",
      "[5536]\teval-rmse:4.02078\ttrain-rmse:2.09996\n",
      "[5537]\teval-rmse:4.02056\ttrain-rmse:2.09995\n",
      "[5538]\teval-rmse:4.0224\ttrain-rmse:2.09995\n",
      "[5539]\teval-rmse:4.02318\ttrain-rmse:2.09994\n",
      "[5540]\teval-rmse:4.02184\ttrain-rmse:2.09994\n",
      "[5541]\teval-rmse:4.02128\ttrain-rmse:2.09987\n",
      "[5542]\teval-rmse:4.02066\ttrain-rmse:2.09986\n",
      "[5543]\teval-rmse:4.01883\ttrain-rmse:2.09991\n",
      "[5544]\teval-rmse:4.01896\ttrain-rmse:2.09991\n",
      "[5545]\teval-rmse:4.01841\ttrain-rmse:2.09984\n",
      "[5546]\teval-rmse:4.0179\ttrain-rmse:2.09975\n",
      "[5547]\teval-rmse:4.02003\ttrain-rmse:2.09974\n",
      "[5548]\teval-rmse:4.02158\ttrain-rmse:2.09968\n",
      "[5549]\teval-rmse:4.02349\ttrain-rmse:2.09971\n",
      "[5550]\teval-rmse:4.02482\ttrain-rmse:2.09972\n",
      "[5551]\teval-rmse:4.02743\ttrain-rmse:2.09966\n",
      "[5552]\teval-rmse:4.02588\ttrain-rmse:2.09952\n",
      "[5553]\teval-rmse:4.02802\ttrain-rmse:2.09947\n",
      "[5554]\teval-rmse:4.03004\ttrain-rmse:2.09943\n",
      "[5555]\teval-rmse:4.02882\ttrain-rmse:2.09926\n",
      "[5556]\teval-rmse:4.02618\ttrain-rmse:2.09923\n",
      "[5557]\teval-rmse:4.0257\ttrain-rmse:2.09922\n",
      "[5558]\teval-rmse:4.024\ttrain-rmse:2.09925\n",
      "[5559]\teval-rmse:4.02448\ttrain-rmse:2.09926\n",
      "[5560]\teval-rmse:4.02307\ttrain-rmse:2.09925\n",
      "[5561]\teval-rmse:4.02185\ttrain-rmse:2.09914\n",
      "[5562]\teval-rmse:4.02385\ttrain-rmse:2.09908\n",
      "[5563]\teval-rmse:4.02568\ttrain-rmse:2.09911\n",
      "[5564]\teval-rmse:4.02748\ttrain-rmse:2.09906\n",
      "[5565]\teval-rmse:4.02701\ttrain-rmse:2.099\n",
      "[5566]\teval-rmse:4.02524\ttrain-rmse:2.09894\n",
      "[5567]\teval-rmse:4.0253\ttrain-rmse:2.09894\n",
      "[5568]\teval-rmse:4.02585\ttrain-rmse:2.09895\n",
      "[5569]\teval-rmse:4.02752\ttrain-rmse:2.09896\n",
      "[5570]\teval-rmse:4.02491\ttrain-rmse:2.09889\n",
      "[5571]\teval-rmse:4.02701\ttrain-rmse:2.09895\n",
      "[5572]\teval-rmse:4.02753\ttrain-rmse:2.09896\n",
      "[5573]\teval-rmse:4.02857\ttrain-rmse:2.09899\n",
      "[5574]\teval-rmse:4.02798\ttrain-rmse:2.09891\n",
      "[5575]\teval-rmse:4.02751\ttrain-rmse:2.09888\n",
      "[5576]\teval-rmse:4.02931\ttrain-rmse:2.09885\n",
      "[5577]\teval-rmse:4.02806\ttrain-rmse:2.09873\n",
      "[5578]\teval-rmse:4.03012\ttrain-rmse:2.09881\n",
      "[5579]\teval-rmse:4.03233\ttrain-rmse:2.09877\n",
      "[5580]\teval-rmse:4.03489\ttrain-rmse:2.09882\n",
      "[5581]\teval-rmse:4.0364\ttrain-rmse:2.09886\n",
      "[5582]\teval-rmse:4.03445\ttrain-rmse:2.09886\n",
      "[5583]\teval-rmse:4.03319\ttrain-rmse:2.09832\n",
      "[5584]\teval-rmse:4.03463\ttrain-rmse:2.09836\n",
      "[5585]\teval-rmse:4.03271\ttrain-rmse:2.09827\n",
      "[5586]\teval-rmse:4.03179\ttrain-rmse:2.09828\n",
      "[5587]\teval-rmse:4.03006\ttrain-rmse:2.09829\n",
      "[5588]\teval-rmse:4.02885\ttrain-rmse:2.09772\n",
      "[5589]\teval-rmse:4.02983\ttrain-rmse:2.09776\n",
      "[5590]\teval-rmse:4.03037\ttrain-rmse:2.09778\n",
      "[5591]\teval-rmse:4.03021\ttrain-rmse:2.09777\n",
      "[5592]\teval-rmse:4.03268\ttrain-rmse:2.09788\n",
      "[5593]\teval-rmse:4.03276\ttrain-rmse:2.09788\n",
      "[5594]\teval-rmse:4.03226\ttrain-rmse:2.09786\n",
      "[5595]\teval-rmse:4.03407\ttrain-rmse:2.0979\n",
      "[5596]\teval-rmse:4.03345\ttrain-rmse:2.09784\n",
      "[5597]\teval-rmse:4.03448\ttrain-rmse:2.09789\n",
      "[5598]\teval-rmse:4.03496\ttrain-rmse:2.09791\n",
      "[5599]\teval-rmse:4.03367\ttrain-rmse:2.09728\n",
      "[5600]\teval-rmse:4.03564\ttrain-rmse:2.09734\n",
      "[5601]\teval-rmse:4.03819\ttrain-rmse:2.09733\n",
      "[5602]\teval-rmse:4.03904\ttrain-rmse:2.09736\n",
      "[5603]\teval-rmse:4.03966\ttrain-rmse:2.09735\n",
      "[5604]\teval-rmse:4.03809\ttrain-rmse:2.09725\n",
      "[5605]\teval-rmse:4.03807\ttrain-rmse:2.09725\n",
      "[5606]\teval-rmse:4.03643\ttrain-rmse:2.09708\n",
      "[5607]\teval-rmse:4.03641\ttrain-rmse:2.09708\n",
      "[5608]\teval-rmse:4.03674\ttrain-rmse:2.0971\n",
      "[5609]\teval-rmse:4.0389\ttrain-rmse:2.09709\n",
      "[5610]\teval-rmse:4.0374\ttrain-rmse:2.09699\n",
      "[5611]\teval-rmse:4.03541\ttrain-rmse:2.09693\n",
      "[5612]\teval-rmse:4.03408\ttrain-rmse:2.09686\n",
      "[5613]\teval-rmse:4.03214\ttrain-rmse:2.09686\n",
      "[5614]\teval-rmse:4.03444\ttrain-rmse:2.09696\n",
      "[5615]\teval-rmse:4.03438\ttrain-rmse:2.09696\n",
      "[5616]\teval-rmse:4.03252\ttrain-rmse:2.0969\n",
      "[5617]\teval-rmse:4.03493\ttrain-rmse:2.09688\n",
      "[5618]\teval-rmse:4.03395\ttrain-rmse:2.09687\n",
      "[5619]\teval-rmse:4.03524\ttrain-rmse:2.09694\n",
      "[5620]\teval-rmse:4.03676\ttrain-rmse:2.09703\n",
      "[5621]\teval-rmse:4.03614\ttrain-rmse:2.09694\n",
      "[5622]\teval-rmse:4.03485\ttrain-rmse:2.09629\n",
      "[5623]\teval-rmse:4.03531\ttrain-rmse:2.09631\n",
      "[5624]\teval-rmse:4.03772\ttrain-rmse:2.0963\n",
      "[5625]\teval-rmse:4.03931\ttrain-rmse:2.09636\n",
      "[5626]\teval-rmse:4.03843\ttrain-rmse:2.09635\n",
      "[5627]\teval-rmse:4.03891\ttrain-rmse:2.09638\n",
      "[5628]\teval-rmse:4.04015\ttrain-rmse:2.09647\n",
      "[5629]\teval-rmse:4.04063\ttrain-rmse:2.0965\n",
      "[5630]\teval-rmse:4.04058\ttrain-rmse:2.0965\n",
      "[5631]\teval-rmse:4.03875\ttrain-rmse:2.09642\n",
      "[5632]\teval-rmse:4.03724\ttrain-rmse:2.09632\n",
      "[5633]\teval-rmse:4.03884\ttrain-rmse:2.09641\n",
      "[5634]\teval-rmse:4.03959\ttrain-rmse:2.09647\n",
      "[5635]\teval-rmse:4.03831\ttrain-rmse:2.09645\n",
      "[5636]\teval-rmse:4.03917\ttrain-rmse:2.0965\n",
      "[5637]\teval-rmse:4.04016\ttrain-rmse:2.09649\n",
      "[5638]\teval-rmse:4.04141\ttrain-rmse:2.09658\n",
      "[5639]\teval-rmse:4.03995\ttrain-rmse:2.09651\n",
      "[5640]\teval-rmse:4.03848\ttrain-rmse:2.09641\n",
      "[5641]\teval-rmse:4.03912\ttrain-rmse:2.0964\n",
      "[5642]\teval-rmse:4.0398\ttrain-rmse:2.09644\n",
      "[5643]\teval-rmse:4.04167\ttrain-rmse:2.09657\n",
      "[5644]\teval-rmse:4.04276\ttrain-rmse:2.09665\n",
      "[5645]\teval-rmse:4.0414\ttrain-rmse:2.09658\n",
      "[5646]\teval-rmse:4.03858\ttrain-rmse:2.0964\n",
      "[5647]\teval-rmse:4.03736\ttrain-rmse:2.09635\n",
      "[5648]\teval-rmse:4.03848\ttrain-rmse:2.09643\n",
      "[5649]\teval-rmse:4.03685\ttrain-rmse:2.09624\n",
      "[5650]\teval-rmse:4.03487\ttrain-rmse:2.09611\n",
      "[5651]\teval-rmse:4.03437\ttrain-rmse:2.09605\n",
      "[5652]\teval-rmse:4.03309\ttrain-rmse:2.09589\n",
      "[5653]\teval-rmse:4.03131\ttrain-rmse:2.09578\n",
      "[5654]\teval-rmse:4.0313\ttrain-rmse:2.09578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5655]\teval-rmse:4.03142\ttrain-rmse:2.09579\n",
      "[5656]\teval-rmse:4.02948\ttrain-rmse:2.09573\n",
      "[5657]\teval-rmse:4.02734\ttrain-rmse:2.09563\n",
      "[5658]\teval-rmse:4.02946\ttrain-rmse:2.09568\n",
      "[5659]\teval-rmse:4.03192\ttrain-rmse:2.09566\n",
      "[5660]\teval-rmse:4.03109\ttrain-rmse:2.09564\n",
      "[5661]\teval-rmse:4.02917\ttrain-rmse:2.09563\n",
      "[5662]\teval-rmse:4.02934\ttrain-rmse:2.09564\n",
      "[5663]\teval-rmse:4.02744\ttrain-rmse:2.09559\n",
      "[5664]\teval-rmse:4.02998\ttrain-rmse:2.09556\n",
      "[5665]\teval-rmse:4.02861\ttrain-rmse:2.09549\n",
      "[5666]\teval-rmse:4.02744\ttrain-rmse:2.09546\n",
      "[5667]\teval-rmse:4.02962\ttrain-rmse:2.09543\n",
      "[5668]\teval-rmse:4.02807\ttrain-rmse:2.09527\n",
      "[5669]\teval-rmse:4.02797\ttrain-rmse:2.09527\n",
      "[5670]\teval-rmse:4.0301\ttrain-rmse:2.0955\n",
      "[5671]\teval-rmse:4.02899\ttrain-rmse:2.09547\n",
      "[5672]\teval-rmse:4.02894\ttrain-rmse:2.09547\n",
      "[5673]\teval-rmse:4.0298\ttrain-rmse:2.09551\n",
      "[5674]\teval-rmse:4.02788\ttrain-rmse:2.09552\n",
      "[5675]\teval-rmse:4.02665\ttrain-rmse:2.09498\n",
      "[5676]\teval-rmse:4.02445\ttrain-rmse:2.09488\n",
      "[5677]\teval-rmse:4.02655\ttrain-rmse:2.09492\n",
      "[5678]\teval-rmse:4.02475\ttrain-rmse:2.09484\n",
      "[5679]\teval-rmse:4.02561\ttrain-rmse:2.09487\n",
      "[5680]\teval-rmse:4.02786\ttrain-rmse:2.09492\n",
      "[5681]\teval-rmse:4.03024\ttrain-rmse:2.09497\n",
      "[5682]\teval-rmse:4.02758\ttrain-rmse:2.09486\n",
      "[5683]\teval-rmse:4.02643\ttrain-rmse:2.09417\n",
      "[5684]\teval-rmse:4.02351\ttrain-rmse:2.09407\n",
      "[5685]\teval-rmse:4.02355\ttrain-rmse:2.09407\n",
      "[5686]\teval-rmse:4.02264\ttrain-rmse:2.09405\n",
      "[5687]\teval-rmse:4.02055\ttrain-rmse:2.09399\n",
      "[5688]\teval-rmse:4.02126\ttrain-rmse:2.09401\n",
      "[5689]\teval-rmse:4.02275\ttrain-rmse:2.09398\n",
      "[5690]\teval-rmse:4.02319\ttrain-rmse:2.09399\n",
      "[5691]\teval-rmse:4.02368\ttrain-rmse:2.094\n",
      "[5692]\teval-rmse:4.02114\ttrain-rmse:2.09392\n",
      "[5693]\teval-rmse:4.02126\ttrain-rmse:2.09393\n",
      "[5694]\teval-rmse:4.02346\ttrain-rmse:2.09388\n",
      "[5695]\teval-rmse:4.02223\ttrain-rmse:2.09376\n",
      "[5696]\teval-rmse:4.02171\ttrain-rmse:2.09368\n",
      "[5697]\teval-rmse:4.02383\ttrain-rmse:2.0939\n",
      "[5698]\teval-rmse:4.02422\ttrain-rmse:2.09391\n",
      "[5699]\teval-rmse:4.02307\ttrain-rmse:2.09336\n",
      "[5700]\teval-rmse:4.02487\ttrain-rmse:2.0934\n",
      "[5701]\teval-rmse:4.02219\ttrain-rmse:2.09331\n",
      "[5702]\teval-rmse:4.02012\ttrain-rmse:2.09324\n",
      "[5703]\teval-rmse:4.01896\ttrain-rmse:2.09308\n",
      "[5704]\teval-rmse:4.02014\ttrain-rmse:2.0931\n",
      "[5705]\teval-rmse:4.02257\ttrain-rmse:2.09305\n",
      "[5706]\teval-rmse:4.02304\ttrain-rmse:2.09307\n",
      "[5707]\teval-rmse:4.02036\ttrain-rmse:2.09301\n",
      "[5708]\teval-rmse:4.01772\ttrain-rmse:2.09295\n",
      "[5709]\teval-rmse:4.01913\ttrain-rmse:2.09298\n",
      "[5710]\teval-rmse:4.01964\ttrain-rmse:2.09298\n",
      "[5711]\teval-rmse:4.02207\ttrain-rmse:2.09294\n",
      "[5712]\teval-rmse:4.02402\ttrain-rmse:2.09296\n",
      "[5713]\teval-rmse:4.02275\ttrain-rmse:2.09294\n",
      "[5714]\teval-rmse:4.02285\ttrain-rmse:2.09294\n",
      "[5715]\teval-rmse:4.02137\ttrain-rmse:2.09276\n",
      "[5716]\teval-rmse:4.02352\ttrain-rmse:2.09298\n",
      "[5717]\teval-rmse:4.02294\ttrain-rmse:2.09297\n",
      "[5718]\teval-rmse:4.022\ttrain-rmse:2.09296\n",
      "[5719]\teval-rmse:4.01928\ttrain-rmse:2.09291\n",
      "[5720]\teval-rmse:4.02061\ttrain-rmse:2.09294\n",
      "[5721]\teval-rmse:4.02015\ttrain-rmse:2.0929\n",
      "[5722]\teval-rmse:4.02036\ttrain-rmse:2.09291\n",
      "[5723]\teval-rmse:4.02282\ttrain-rmse:2.09286\n",
      "[5724]\teval-rmse:4.02412\ttrain-rmse:2.09288\n",
      "[5725]\teval-rmse:4.02153\ttrain-rmse:2.09282\n",
      "[5726]\teval-rmse:4.0221\ttrain-rmse:2.09283\n",
      "[5727]\teval-rmse:4.02421\ttrain-rmse:2.09288\n",
      "[5728]\teval-rmse:4.02583\ttrain-rmse:2.09292\n",
      "[5729]\teval-rmse:4.02522\ttrain-rmse:2.09286\n",
      "[5730]\teval-rmse:4.02623\ttrain-rmse:2.09289\n",
      "[5731]\teval-rmse:4.02491\ttrain-rmse:2.09283\n",
      "[5732]\teval-rmse:4.02615\ttrain-rmse:2.09288\n",
      "[5733]\teval-rmse:4.02806\ttrain-rmse:2.09296\n",
      "[5734]\teval-rmse:4.02664\ttrain-rmse:2.09293\n",
      "[5735]\teval-rmse:4.02615\ttrain-rmse:2.09291\n",
      "[5736]\teval-rmse:4.02775\ttrain-rmse:2.09295\n",
      "[5737]\teval-rmse:4.02624\ttrain-rmse:2.0929\n",
      "[5738]\teval-rmse:4.02566\ttrain-rmse:2.09281\n",
      "[5739]\teval-rmse:4.02447\ttrain-rmse:2.09279\n",
      "[5740]\teval-rmse:4.02658\ttrain-rmse:2.09301\n",
      "[5741]\teval-rmse:4.02644\ttrain-rmse:2.09301\n",
      "[5742]\teval-rmse:4.02899\ttrain-rmse:2.09299\n",
      "[5743]\teval-rmse:4.0271\ttrain-rmse:2.09294\n",
      "[5744]\teval-rmse:4.02555\ttrain-rmse:2.09279\n",
      "[5745]\teval-rmse:4.0277\ttrain-rmse:2.09276\n",
      "[5746]\teval-rmse:4.02662\ttrain-rmse:2.09273\n",
      "[5747]\teval-rmse:4.02442\ttrain-rmse:2.09268\n",
      "[5748]\teval-rmse:4.02319\ttrain-rmse:2.09252\n",
      "[5749]\teval-rmse:4.02505\ttrain-rmse:2.09256\n",
      "[5750]\teval-rmse:4.02692\ttrain-rmse:2.09262\n",
      "[5751]\teval-rmse:4.0278\ttrain-rmse:2.09266\n",
      "[5752]\teval-rmse:4.02962\ttrain-rmse:2.09271\n",
      "[5753]\teval-rmse:4.02783\ttrain-rmse:2.09264\n",
      "[5754]\teval-rmse:4.02702\ttrain-rmse:2.09261\n",
      "[5755]\teval-rmse:4.02436\ttrain-rmse:2.09255\n",
      "[5756]\teval-rmse:4.02267\ttrain-rmse:2.09251\n",
      "[5757]\teval-rmse:4.02189\ttrain-rmse:2.09249\n",
      "[5758]\teval-rmse:4.01925\ttrain-rmse:2.09244\n",
      "[5759]\teval-rmse:4.0197\ttrain-rmse:2.09245\n",
      "[5760]\teval-rmse:4.01913\ttrain-rmse:2.09238\n",
      "[5761]\teval-rmse:4.01762\ttrain-rmse:2.09224\n",
      "[5762]\teval-rmse:4.01767\ttrain-rmse:2.09224\n",
      "[5763]\teval-rmse:4.01819\ttrain-rmse:2.09224\n",
      "[5764]\teval-rmse:4.01945\ttrain-rmse:2.09227\n",
      "[5765]\teval-rmse:4.02021\ttrain-rmse:2.09227\n",
      "[5766]\teval-rmse:4.02089\ttrain-rmse:2.09226\n",
      "[5767]\teval-rmse:4.02266\ttrain-rmse:2.09223\n",
      "[5768]\teval-rmse:4.02396\ttrain-rmse:2.09225\n",
      "[5769]\teval-rmse:4.02496\ttrain-rmse:2.09228\n",
      "[5770]\teval-rmse:4.02434\ttrain-rmse:2.09223\n",
      "[5771]\teval-rmse:4.02533\ttrain-rmse:2.09222\n",
      "[5772]\teval-rmse:4.02527\ttrain-rmse:2.09221\n",
      "[5773]\teval-rmse:4.02294\ttrain-rmse:2.09214\n",
      "[5774]\teval-rmse:4.02238\ttrain-rmse:2.09204\n",
      "[5775]\teval-rmse:4.02378\ttrain-rmse:2.09207\n",
      "[5776]\teval-rmse:4.02329\ttrain-rmse:2.09206\n",
      "[5777]\teval-rmse:4.02221\ttrain-rmse:2.09204\n",
      "[5778]\teval-rmse:4.02333\ttrain-rmse:2.09207\n",
      "[5779]\teval-rmse:4.02203\ttrain-rmse:2.09202\n",
      "[5780]\teval-rmse:4.02095\ttrain-rmse:2.092\n",
      "[5781]\teval-rmse:4.02292\ttrain-rmse:2.09203\n",
      "[5782]\teval-rmse:4.02107\ttrain-rmse:2.09199\n",
      "[5783]\teval-rmse:4.01983\ttrain-rmse:2.09198\n",
      "[5784]\teval-rmse:4.01897\ttrain-rmse:2.09196\n",
      "[5785]\teval-rmse:4.01787\ttrain-rmse:2.09195\n",
      "[5786]\teval-rmse:4.01617\ttrain-rmse:2.09192\n",
      "[5787]\teval-rmse:4.01674\ttrain-rmse:2.09193\n",
      "[5788]\teval-rmse:4.01871\ttrain-rmse:2.09195\n",
      "[5789]\teval-rmse:4.01981\ttrain-rmse:2.09196\n",
      "[5790]\teval-rmse:4.02135\ttrain-rmse:2.09199\n",
      "[5791]\teval-rmse:4.02041\ttrain-rmse:2.092\n",
      "[5792]\teval-rmse:4.02016\ttrain-rmse:2.09199\n",
      "[5793]\teval-rmse:4.01887\ttrain-rmse:2.092\n",
      "[5794]\teval-rmse:4.01903\ttrain-rmse:2.092\n",
      "[5795]\teval-rmse:4.02159\ttrain-rmse:2.09196\n",
      "[5796]\teval-rmse:4.02102\ttrain-rmse:2.09191\n",
      "[5797]\teval-rmse:4.02112\ttrain-rmse:2.09191\n",
      "[5798]\teval-rmse:4.02286\ttrain-rmse:2.09194\n",
      "[5799]\teval-rmse:4.02321\ttrain-rmse:2.09194\n",
      "[5800]\teval-rmse:4.02533\ttrain-rmse:2.09192\n",
      "[5801]\teval-rmse:4.02712\ttrain-rmse:2.09197\n",
      "[5802]\teval-rmse:4.02536\ttrain-rmse:2.09191\n",
      "[5803]\teval-rmse:4.02331\ttrain-rmse:2.09192\n",
      "[5804]\teval-rmse:4.02326\ttrain-rmse:2.09192\n",
      "[5805]\teval-rmse:4.0254\ttrain-rmse:2.0919\n",
      "[5806]\teval-rmse:4.02367\ttrain-rmse:2.09186\n",
      "[5807]\teval-rmse:4.02468\ttrain-rmse:2.09188\n",
      "[5808]\teval-rmse:4.02502\ttrain-rmse:2.09189\n",
      "[5809]\teval-rmse:4.02382\ttrain-rmse:2.09175\n",
      "[5810]\teval-rmse:4.02472\ttrain-rmse:2.09178\n",
      "[5811]\teval-rmse:4.02302\ttrain-rmse:2.09172\n",
      "[5812]\teval-rmse:4.02406\ttrain-rmse:2.09175\n",
      "[5813]\teval-rmse:4.02508\ttrain-rmse:2.09178\n",
      "[5814]\teval-rmse:4.02715\ttrain-rmse:2.09177\n",
      "[5815]\teval-rmse:4.02592\ttrain-rmse:2.09162\n",
      "[5816]\teval-rmse:4.02479\ttrain-rmse:2.09159\n",
      "[5817]\teval-rmse:4.02434\ttrain-rmse:2.09152\n",
      "[5818]\teval-rmse:4.02303\ttrain-rmse:2.09149\n",
      "[5819]\teval-rmse:4.02149\ttrain-rmse:2.09144\n",
      "[5820]\teval-rmse:4.02218\ttrain-rmse:2.09146\n",
      "[5821]\teval-rmse:4.02028\ttrain-rmse:2.09148\n",
      "[5822]\teval-rmse:4.02006\ttrain-rmse:2.09147\n",
      "[5823]\teval-rmse:4.02224\ttrain-rmse:2.09169\n",
      "[5824]\teval-rmse:4.01975\ttrain-rmse:2.09167\n",
      "[5825]\teval-rmse:4.02012\ttrain-rmse:2.09167\n",
      "[5826]\teval-rmse:4.02096\ttrain-rmse:2.09169\n",
      "[5827]\teval-rmse:4.01877\ttrain-rmse:2.09166\n",
      "[5828]\teval-rmse:4.01976\ttrain-rmse:2.09168\n",
      "[5829]\teval-rmse:4.02113\ttrain-rmse:2.09171\n",
      "[5830]\teval-rmse:4.02286\ttrain-rmse:2.09176\n",
      "[5831]\teval-rmse:4.02103\ttrain-rmse:2.09172\n",
      "[5832]\teval-rmse:4.02203\ttrain-rmse:2.09175\n",
      "[5833]\teval-rmse:4.02143\ttrain-rmse:2.09166\n",
      "[5834]\teval-rmse:4.02023\ttrain-rmse:2.09152\n",
      "[5835]\teval-rmse:4.02125\ttrain-rmse:2.0915\n",
      "[5836]\teval-rmse:4.02263\ttrain-rmse:2.09154\n",
      "[5837]\teval-rmse:4.02428\ttrain-rmse:2.09161\n",
      "[5838]\teval-rmse:4.02306\ttrain-rmse:2.09112\n",
      "[5839]\teval-rmse:4.02152\ttrain-rmse:2.09095\n",
      "[5840]\teval-rmse:4.02019\ttrain-rmse:2.0909\n",
      "[5841]\teval-rmse:4.02217\ttrain-rmse:2.09088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5842]\teval-rmse:4.02313\ttrain-rmse:2.09091\n",
      "[5843]\teval-rmse:4.02144\ttrain-rmse:2.09087\n",
      "[5844]\teval-rmse:4.02389\ttrain-rmse:2.09085\n",
      "[5845]\teval-rmse:4.0227\ttrain-rmse:2.0907\n",
      "[5846]\teval-rmse:4.02386\ttrain-rmse:2.09073\n",
      "[5847]\teval-rmse:4.02277\ttrain-rmse:2.09069\n",
      "[5848]\teval-rmse:4.02513\ttrain-rmse:2.09075\n",
      "[5849]\teval-rmse:4.02557\ttrain-rmse:2.09076\n",
      "[5850]\teval-rmse:4.02347\ttrain-rmse:2.0907\n",
      "[5851]\teval-rmse:4.02155\ttrain-rmse:2.09071\n",
      "[5852]\teval-rmse:4.02324\ttrain-rmse:2.09077\n",
      "[5853]\teval-rmse:4.02452\ttrain-rmse:2.09076\n",
      "[5854]\teval-rmse:4.02327\ttrain-rmse:2.09009\n",
      "[5855]\teval-rmse:4.02474\ttrain-rmse:2.09013\n",
      "[5856]\teval-rmse:4.02325\ttrain-rmse:2.08994\n",
      "[5857]\teval-rmse:4.0217\ttrain-rmse:2.08977\n",
      "[5858]\teval-rmse:4.02058\ttrain-rmse:2.08974\n",
      "[5859]\teval-rmse:4.02179\ttrain-rmse:2.08977\n",
      "[5860]\teval-rmse:4.02261\ttrain-rmse:2.08981\n",
      "[5861]\teval-rmse:4.02108\ttrain-rmse:2.08964\n",
      "[5862]\teval-rmse:4.0236\ttrain-rmse:2.08963\n",
      "[5863]\teval-rmse:4.02366\ttrain-rmse:2.08963\n",
      "[5864]\teval-rmse:4.02435\ttrain-rmse:2.08965\n",
      "[5865]\teval-rmse:4.02583\ttrain-rmse:2.08972\n",
      "[5866]\teval-rmse:4.0239\ttrain-rmse:2.08963\n",
      "[5867]\teval-rmse:4.02249\ttrain-rmse:2.08959\n",
      "[5868]\teval-rmse:4.025\ttrain-rmse:2.08966\n",
      "[5869]\teval-rmse:4.02439\ttrain-rmse:2.0896\n",
      "[5870]\teval-rmse:4.02337\ttrain-rmse:2.08955\n",
      "[5871]\teval-rmse:4.02155\ttrain-rmse:2.08948\n",
      "[5872]\teval-rmse:4.02102\ttrain-rmse:2.08946\n",
      "[5873]\teval-rmse:4.02188\ttrain-rmse:2.08949\n",
      "[5874]\teval-rmse:4.02143\ttrain-rmse:2.08943\n",
      "[5875]\teval-rmse:4.01979\ttrain-rmse:2.08936\n",
      "[5876]\teval-rmse:4.01828\ttrain-rmse:2.08922\n",
      "[5877]\teval-rmse:4.01674\ttrain-rmse:2.08907\n",
      "[5878]\teval-rmse:4.01402\ttrain-rmse:2.08899\n",
      "[5879]\teval-rmse:4.01252\ttrain-rmse:2.08887\n",
      "[5880]\teval-rmse:4.01384\ttrain-rmse:2.08885\n",
      "[5881]\teval-rmse:4.0127\ttrain-rmse:2.08883\n",
      "[5882]\teval-rmse:4.01258\ttrain-rmse:2.08882\n",
      "[5883]\teval-rmse:4.01141\ttrain-rmse:2.08832\n",
      "[5884]\teval-rmse:4.0103\ttrain-rmse:2.08781\n",
      "[5885]\teval-rmse:4.00843\ttrain-rmse:2.08779\n",
      "[5886]\teval-rmse:4.00606\ttrain-rmse:2.08778\n",
      "[5887]\teval-rmse:4.00691\ttrain-rmse:2.08779\n",
      "[5888]\teval-rmse:4.00784\ttrain-rmse:2.0878\n",
      "[5889]\teval-rmse:4.00669\ttrain-rmse:2.08771\n",
      "[5890]\teval-rmse:4.00886\ttrain-rmse:2.08765\n",
      "[5891]\teval-rmse:4.01086\ttrain-rmse:2.08767\n",
      "[5892]\teval-rmse:4.01328\ttrain-rmse:2.08762\n",
      "[5893]\teval-rmse:4.01076\ttrain-rmse:2.08756\n",
      "[5894]\teval-rmse:4.01216\ttrain-rmse:2.08753\n",
      "[5895]\teval-rmse:4.0107\ttrain-rmse:2.08751\n",
      "[5896]\teval-rmse:4.0097\ttrain-rmse:2.0875\n",
      "[5897]\teval-rmse:4.00972\ttrain-rmse:2.0875\n",
      "[5898]\teval-rmse:4.01109\ttrain-rmse:2.08752\n",
      "[5899]\teval-rmse:4.01156\ttrain-rmse:2.08752\n",
      "[5900]\teval-rmse:4.00905\ttrain-rmse:2.08745\n",
      "[5901]\teval-rmse:4.01032\ttrain-rmse:2.08748\n",
      "[5902]\teval-rmse:4.01204\ttrain-rmse:2.08745\n",
      "[5903]\teval-rmse:4.01102\ttrain-rmse:2.08743\n",
      "[5904]\teval-rmse:4.01297\ttrain-rmse:2.08739\n",
      "[5905]\teval-rmse:4.0142\ttrain-rmse:2.08742\n",
      "[5906]\teval-rmse:4.01214\ttrain-rmse:2.08744\n",
      "[5907]\teval-rmse:4.01005\ttrain-rmse:2.0874\n",
      "[5908]\teval-rmse:4.01182\ttrain-rmse:2.08736\n",
      "[5909]\teval-rmse:4.01372\ttrain-rmse:2.0874\n",
      "[5910]\teval-rmse:4.0139\ttrain-rmse:2.08741\n",
      "[5911]\teval-rmse:4.01502\ttrain-rmse:2.08744\n",
      "[5912]\teval-rmse:4.01445\ttrain-rmse:2.08743\n",
      "[5913]\teval-rmse:4.01402\ttrain-rmse:2.08737\n",
      "[5914]\teval-rmse:4.01355\ttrain-rmse:2.08736\n",
      "[5915]\teval-rmse:4.0112\ttrain-rmse:2.08729\n",
      "[5916]\teval-rmse:4.01003\ttrain-rmse:2.08672\n",
      "[5917]\teval-rmse:4.0095\ttrain-rmse:2.08667\n",
      "[5918]\teval-rmse:4.00977\ttrain-rmse:2.08667\n",
      "[5919]\teval-rmse:4.00924\ttrain-rmse:2.08666\n",
      "[5920]\teval-rmse:4.01105\ttrain-rmse:2.08663\n",
      "[5921]\teval-rmse:4.00966\ttrain-rmse:2.08661\n",
      "[5922]\teval-rmse:4.01181\ttrain-rmse:2.08657\n",
      "[5923]\teval-rmse:4.01311\ttrain-rmse:2.08658\n",
      "[5924]\teval-rmse:4.01259\ttrain-rmse:2.08651\n",
      "[5925]\teval-rmse:4.01028\ttrain-rmse:2.08645\n",
      "[5926]\teval-rmse:4.01223\ttrain-rmse:2.08648\n",
      "[5927]\teval-rmse:4.01071\ttrain-rmse:2.08635\n",
      "[5928]\teval-rmse:4.01268\ttrain-rmse:2.08637\n",
      "[5929]\teval-rmse:4.01485\ttrain-rmse:2.08634\n",
      "[5930]\teval-rmse:4.01577\ttrain-rmse:2.08636\n",
      "[5931]\teval-rmse:4.01403\ttrain-rmse:2.08637\n",
      "[5932]\teval-rmse:4.01286\ttrain-rmse:2.0859\n",
      "[5933]\teval-rmse:4.0106\ttrain-rmse:2.08582\n",
      "[5934]\teval-rmse:4.00876\ttrain-rmse:2.08586\n",
      "[5935]\teval-rmse:4.007\ttrain-rmse:2.08584\n",
      "[5936]\teval-rmse:4.00871\ttrain-rmse:2.0858\n",
      "[5937]\teval-rmse:4.01031\ttrain-rmse:2.08582\n",
      "[5938]\teval-rmse:4.00939\ttrain-rmse:2.08583\n",
      "[5939]\teval-rmse:4.01157\ttrain-rmse:2.08603\n",
      "[5940]\teval-rmse:4.01038\ttrain-rmse:2.08593\n",
      "[5941]\teval-rmse:4.01183\ttrain-rmse:2.08591\n",
      "[5942]\teval-rmse:4.01244\ttrain-rmse:2.08592\n",
      "[5943]\teval-rmse:4.01374\ttrain-rmse:2.08595\n",
      "[5944]\teval-rmse:4.01109\ttrain-rmse:2.08586\n",
      "[5945]\teval-rmse:4.0088\ttrain-rmse:2.08583\n",
      "[5946]\teval-rmse:4.01054\ttrain-rmse:2.08585\n",
      "[5947]\teval-rmse:4.012\ttrain-rmse:2.08583\n",
      "[5948]\teval-rmse:4.01378\ttrain-rmse:2.08587\n",
      "[5949]\teval-rmse:4.01262\ttrain-rmse:2.08576\n",
      "[5950]\teval-rmse:4.0114\ttrain-rmse:2.08574\n",
      "[5951]\teval-rmse:4.00998\ttrain-rmse:2.08572\n",
      "[5952]\teval-rmse:4.00758\ttrain-rmse:2.0857\n",
      "[5953]\teval-rmse:4.00862\ttrain-rmse:2.08572\n",
      "[5954]\teval-rmse:4.00929\ttrain-rmse:2.08573\n",
      "[5955]\teval-rmse:4.00696\ttrain-rmse:2.08568\n",
      "[5956]\teval-rmse:4.00891\ttrain-rmse:2.0857\n",
      "[5957]\teval-rmse:4.0104\ttrain-rmse:2.08571\n",
      "[5958]\teval-rmse:4.00808\ttrain-rmse:2.08569\n",
      "[5959]\teval-rmse:4.00941\ttrain-rmse:2.0857\n",
      "[5960]\teval-rmse:4.00968\ttrain-rmse:2.0857\n",
      "[5961]\teval-rmse:4.00695\ttrain-rmse:2.08567\n",
      "[5962]\teval-rmse:4.00947\ttrain-rmse:2.08569\n",
      "[5963]\teval-rmse:4.01201\ttrain-rmse:2.08566\n",
      "[5964]\teval-rmse:4.01031\ttrain-rmse:2.08563\n",
      "[5965]\teval-rmse:4.01107\ttrain-rmse:2.08565\n",
      "[5966]\teval-rmse:4.01289\ttrain-rmse:2.08568\n",
      "[5967]\teval-rmse:4.01114\ttrain-rmse:2.08564\n",
      "[5968]\teval-rmse:4.01166\ttrain-rmse:2.08565\n",
      "[5969]\teval-rmse:4.01047\ttrain-rmse:2.08502\n",
      "[5970]\teval-rmse:4.01282\ttrain-rmse:2.085\n",
      "[5971]\teval-rmse:4.01367\ttrain-rmse:2.08502\n",
      "[5972]\teval-rmse:4.0121\ttrain-rmse:2.08499\n",
      "[5973]\teval-rmse:4.01055\ttrain-rmse:2.08497\n",
      "[5974]\teval-rmse:4.01104\ttrain-rmse:2.08498\n",
      "[5975]\teval-rmse:4.00996\ttrain-rmse:2.08496\n",
      "[5976]\teval-rmse:4.01166\ttrain-rmse:2.08499\n",
      "[5977]\teval-rmse:4.01332\ttrain-rmse:2.08503\n",
      "[5978]\teval-rmse:4.01278\ttrain-rmse:2.08496\n",
      "[5979]\teval-rmse:4.01168\ttrain-rmse:2.08494\n",
      "[5980]\teval-rmse:4.01051\ttrain-rmse:2.08442\n",
      "[5981]\teval-rmse:4.01009\ttrain-rmse:2.08441\n",
      "[5982]\teval-rmse:4.01071\ttrain-rmse:2.0844\n",
      "[5983]\teval-rmse:4.00931\ttrain-rmse:2.08438\n",
      "[5984]\teval-rmse:4.0104\ttrain-rmse:2.0844\n",
      "[5985]\teval-rmse:4.00854\ttrain-rmse:2.08437\n",
      "[5986]\teval-rmse:4.01069\ttrain-rmse:2.08434\n",
      "[5987]\teval-rmse:4.01208\ttrain-rmse:2.08436\n",
      "[5988]\teval-rmse:4.01216\ttrain-rmse:2.08436\n",
      "[5989]\teval-rmse:4.01164\ttrain-rmse:2.08428\n",
      "[5990]\teval-rmse:4.01162\ttrain-rmse:2.08428\n",
      "[5991]\teval-rmse:4.00915\ttrain-rmse:2.08423\n",
      "[5992]\teval-rmse:4.01006\ttrain-rmse:2.08425\n",
      "[5993]\teval-rmse:4.00744\ttrain-rmse:2.08419\n",
      "[5994]\teval-rmse:4.00743\ttrain-rmse:2.08419\n",
      "[5995]\teval-rmse:4.00483\ttrain-rmse:2.08415\n",
      "[5996]\teval-rmse:4.00359\ttrain-rmse:2.08417\n",
      "[5997]\teval-rmse:4.00573\ttrain-rmse:2.08412\n",
      "[5998]\teval-rmse:4.00749\ttrain-rmse:2.08408\n",
      "[5999]\teval-rmse:4.00908\ttrain-rmse:2.0841\n",
      "[6000]\teval-rmse:4.00994\ttrain-rmse:2.08411\n",
      "[6001]\teval-rmse:4.01216\ttrain-rmse:2.08414\n",
      "[6002]\teval-rmse:4.01298\ttrain-rmse:2.08416\n",
      "[6003]\teval-rmse:4.01444\ttrain-rmse:2.08419\n",
      "[6004]\teval-rmse:4.01622\ttrain-rmse:2.08418\n",
      "[6005]\teval-rmse:4.01505\ttrain-rmse:2.08414\n",
      "[6006]\teval-rmse:4.01251\ttrain-rmse:2.08408\n",
      "[6007]\teval-rmse:4.01351\ttrain-rmse:2.08407\n",
      "[6008]\teval-rmse:4.01405\ttrain-rmse:2.08408\n",
      "[6009]\teval-rmse:4.01361\ttrain-rmse:2.08401\n",
      "[6010]\teval-rmse:4.01586\ttrain-rmse:2.08407\n",
      "[6011]\teval-rmse:4.01371\ttrain-rmse:2.08401\n",
      "[6012]\teval-rmse:4.0157\ttrain-rmse:2.08406\n",
      "[6013]\teval-rmse:4.01337\ttrain-rmse:2.08398\n",
      "[6014]\teval-rmse:4.01401\ttrain-rmse:2.08399\n",
      "[6015]\teval-rmse:4.01305\ttrain-rmse:2.08397\n",
      "[6016]\teval-rmse:4.01355\ttrain-rmse:2.08399\n",
      "[6017]\teval-rmse:4.01088\ttrain-rmse:2.0839\n",
      "[6018]\teval-rmse:4.01187\ttrain-rmse:2.08389\n",
      "[6019]\teval-rmse:4.01402\ttrain-rmse:2.08393\n",
      "[6020]\teval-rmse:4.01134\ttrain-rmse:2.08388\n",
      "[6021]\teval-rmse:4.01232\ttrain-rmse:2.08388\n",
      "[6022]\teval-rmse:4.01335\ttrain-rmse:2.0839\n",
      "[6023]\teval-rmse:4.01228\ttrain-rmse:2.08388\n",
      "[6024]\teval-rmse:4.01353\ttrain-rmse:2.08392\n",
      "[6025]\teval-rmse:4.01314\ttrain-rmse:2.08391\n",
      "[6026]\teval-rmse:4.01309\ttrain-rmse:2.08391\n",
      "[6027]\teval-rmse:4.01156\ttrain-rmse:2.08377\n",
      "[6028]\teval-rmse:4.01157\ttrain-rmse:2.08377\n",
      "[6029]\teval-rmse:4.01103\ttrain-rmse:2.0837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6030]\teval-rmse:4.00996\ttrain-rmse:2.08303\n",
      "[6031]\teval-rmse:4.00882\ttrain-rmse:2.0829\n",
      "[6032]\teval-rmse:4.00827\ttrain-rmse:2.08284\n",
      "[6033]\teval-rmse:4.00891\ttrain-rmse:2.08285\n",
      "[6034]\teval-rmse:4.00776\ttrain-rmse:2.08275\n",
      "[6035]\teval-rmse:4.0065\ttrain-rmse:2.08276\n",
      "[6036]\teval-rmse:4.005\ttrain-rmse:2.08274\n",
      "[6037]\teval-rmse:4.00447\ttrain-rmse:2.0827\n",
      "[6038]\teval-rmse:4.00639\ttrain-rmse:2.08274\n",
      "[6039]\teval-rmse:4.00665\ttrain-rmse:2.08275\n",
      "[6040]\teval-rmse:4.00824\ttrain-rmse:2.08277\n",
      "[6041]\teval-rmse:4.01019\ttrain-rmse:2.08276\n",
      "[6042]\teval-rmse:4.00832\ttrain-rmse:2.08272\n",
      "[6043]\teval-rmse:4.00791\ttrain-rmse:2.08266\n",
      "[6044]\teval-rmse:4.00826\ttrain-rmse:2.08267\n",
      "[6045]\teval-rmse:4.01056\ttrain-rmse:2.08265\n",
      "[6046]\teval-rmse:4.01309\ttrain-rmse:2.08272\n",
      "[6047]\teval-rmse:4.01085\ttrain-rmse:2.08263\n",
      "[6048]\teval-rmse:4.01045\ttrain-rmse:2.08262\n",
      "[6049]\teval-rmse:4.01137\ttrain-rmse:2.08265\n",
      "[6050]\teval-rmse:4.01022\ttrain-rmse:2.08266\n",
      "[6051]\teval-rmse:4.01235\ttrain-rmse:2.08263\n",
      "[6052]\teval-rmse:4.01326\ttrain-rmse:2.08265\n",
      "[6053]\teval-rmse:4.01176\ttrain-rmse:2.0825\n",
      "[6054]\teval-rmse:4.01028\ttrain-rmse:2.08234\n",
      "[6055]\teval-rmse:4.01228\ttrain-rmse:2.08239\n",
      "[6056]\teval-rmse:4.01081\ttrain-rmse:2.08233\n",
      "[6057]\teval-rmse:4.01059\ttrain-rmse:2.08232\n",
      "[6058]\teval-rmse:4.00947\ttrain-rmse:2.08228\n",
      "[6059]\teval-rmse:4.01154\ttrain-rmse:2.08233\n",
      "[6060]\teval-rmse:4.01042\ttrain-rmse:2.08177\n",
      "[6061]\teval-rmse:4.00918\ttrain-rmse:2.08177\n",
      "[6062]\teval-rmse:4.00708\ttrain-rmse:2.08172\n",
      "[6063]\teval-rmse:4.00835\ttrain-rmse:2.08171\n",
      "[6064]\teval-rmse:4.00969\ttrain-rmse:2.08174\n",
      "[6065]\teval-rmse:4.00694\ttrain-rmse:2.08169\n",
      "[6066]\teval-rmse:4.0067\ttrain-rmse:2.08168\n",
      "[6067]\teval-rmse:4.00617\ttrain-rmse:2.08167\n",
      "[6068]\teval-rmse:4.00467\ttrain-rmse:2.08164\n",
      "[6069]\teval-rmse:4.00405\ttrain-rmse:2.08163\n",
      "[6070]\teval-rmse:4.003\ttrain-rmse:2.08109\n",
      "[6071]\teval-rmse:4.00371\ttrain-rmse:2.08109\n",
      "[6072]\teval-rmse:4.00519\ttrain-rmse:2.08112\n",
      "[6073]\teval-rmse:4.00624\ttrain-rmse:2.08114\n",
      "[6074]\teval-rmse:4.00556\ttrain-rmse:2.08112\n",
      "[6075]\teval-rmse:4.00649\ttrain-rmse:2.08114\n",
      "[6076]\teval-rmse:4.00791\ttrain-rmse:2.08112\n",
      "[6077]\teval-rmse:4.00559\ttrain-rmse:2.08113\n",
      "[6078]\teval-rmse:4.00642\ttrain-rmse:2.08114\n",
      "[6079]\teval-rmse:4.0058\ttrain-rmse:2.08113\n",
      "[6080]\teval-rmse:4.00653\ttrain-rmse:2.08115\n",
      "[6081]\teval-rmse:4.00529\ttrain-rmse:2.08112\n",
      "[6082]\teval-rmse:4.00399\ttrain-rmse:2.0811\n",
      "[6083]\teval-rmse:4.00583\ttrain-rmse:2.08112\n",
      "[6084]\teval-rmse:4.00437\ttrain-rmse:2.0811\n",
      "[6085]\teval-rmse:4.00623\ttrain-rmse:2.08113\n",
      "[6086]\teval-rmse:4.00762\ttrain-rmse:2.08116\n",
      "[6087]\teval-rmse:4.00876\ttrain-rmse:2.0812\n",
      "[6088]\teval-rmse:4.00731\ttrain-rmse:2.08116\n",
      "[6089]\teval-rmse:4.00523\ttrain-rmse:2.08117\n",
      "[6090]\teval-rmse:4.00764\ttrain-rmse:2.08115\n",
      "[6091]\teval-rmse:4.00708\ttrain-rmse:2.0811\n",
      "[6092]\teval-rmse:4.00731\ttrain-rmse:2.08111\n",
      "[6093]\teval-rmse:4.00741\ttrain-rmse:2.08111\n",
      "[6094]\teval-rmse:4.00916\ttrain-rmse:2.08109\n",
      "[6095]\teval-rmse:4.00959\ttrain-rmse:2.0811\n",
      "[6096]\teval-rmse:4.00808\ttrain-rmse:2.08106\n",
      "[6097]\teval-rmse:4.00619\ttrain-rmse:2.08108\n",
      "[6098]\teval-rmse:4.00565\ttrain-rmse:2.08107\n",
      "[6099]\teval-rmse:4.00591\ttrain-rmse:2.08107\n",
      "[6100]\teval-rmse:4.00676\ttrain-rmse:2.0811\n",
      "[6101]\teval-rmse:4.00461\ttrain-rmse:2.08106\n",
      "[6102]\teval-rmse:4.00586\ttrain-rmse:2.08108\n",
      "[6103]\teval-rmse:4.00778\ttrain-rmse:2.08113\n",
      "[6104]\teval-rmse:4.00699\ttrain-rmse:2.08111\n",
      "[6105]\teval-rmse:4.00594\ttrain-rmse:2.08109\n",
      "[6106]\teval-rmse:4.00613\ttrain-rmse:2.08109\n",
      "[6107]\teval-rmse:4.00666\ttrain-rmse:2.08111\n",
      "[6108]\teval-rmse:4.00429\ttrain-rmse:2.08106\n",
      "[6109]\teval-rmse:4.00153\ttrain-rmse:2.081\n",
      "[6110]\teval-rmse:4.00201\ttrain-rmse:2.081\n",
      "[6111]\teval-rmse:4.00183\ttrain-rmse:2.081\n",
      "[6112]\teval-rmse:4.0006\ttrain-rmse:2.08102\n",
      "[6113]\teval-rmse:4.00273\ttrain-rmse:2.08098\n",
      "[6114]\teval-rmse:4.00364\ttrain-rmse:2.081\n",
      "[6115]\teval-rmse:4.00548\ttrain-rmse:2.08105\n",
      "[6116]\teval-rmse:4.00401\ttrain-rmse:2.0809\n",
      "[6117]\teval-rmse:4.00253\ttrain-rmse:2.08077\n",
      "[6118]\teval-rmse:4.00364\ttrain-rmse:2.08079\n",
      "[6119]\teval-rmse:4.005\ttrain-rmse:2.08084\n",
      "[6120]\teval-rmse:4.00634\ttrain-rmse:2.08087\n",
      "[6121]\teval-rmse:4.00447\ttrain-rmse:2.08089\n",
      "[6122]\teval-rmse:4.00547\ttrain-rmse:2.08092\n",
      "[6123]\teval-rmse:4.00666\ttrain-rmse:2.08095\n",
      "[6124]\teval-rmse:4.00903\ttrain-rmse:2.08094\n",
      "[6125]\teval-rmse:4.01116\ttrain-rmse:2.08114\n",
      "[6126]\teval-rmse:4.01052\ttrain-rmse:2.08112\n",
      "[6127]\teval-rmse:4.01227\ttrain-rmse:2.08118\n",
      "[6128]\teval-rmse:4.01119\ttrain-rmse:2.08114\n",
      "[6129]\teval-rmse:4.00992\ttrain-rmse:2.0811\n",
      "[6130]\teval-rmse:4.00774\ttrain-rmse:2.08104\n",
      "[6131]\teval-rmse:4.00882\ttrain-rmse:2.08107\n",
      "[6132]\teval-rmse:4.0095\ttrain-rmse:2.08109\n",
      "[6133]\teval-rmse:4.00901\ttrain-rmse:2.08107\n",
      "[6134]\teval-rmse:4.01148\ttrain-rmse:2.08107\n",
      "[6135]\teval-rmse:4.00998\ttrain-rmse:2.0809\n",
      "[6136]\teval-rmse:4.00748\ttrain-rmse:2.08083\n",
      "[6137]\teval-rmse:4.00828\ttrain-rmse:2.08087\n",
      "[6138]\teval-rmse:4.00679\ttrain-rmse:2.08073\n",
      "[6139]\teval-rmse:4.00553\ttrain-rmse:2.08074\n",
      "[6140]\teval-rmse:4.00601\ttrain-rmse:2.08076\n",
      "[6141]\teval-rmse:4.00357\ttrain-rmse:2.08069\n",
      "[6142]\teval-rmse:4.00235\ttrain-rmse:2.08071\n",
      "[6143]\teval-rmse:4.00215\ttrain-rmse:2.0807\n",
      "[6144]\teval-rmse:4.00071\ttrain-rmse:2.08057\n",
      "[6145]\teval-rmse:4.00196\ttrain-rmse:2.08059\n",
      "[6146]\teval-rmse:4.00113\ttrain-rmse:2.08057\n",
      "[6147]\teval-rmse:3.99958\ttrain-rmse:2.08054\n",
      "[6148]\teval-rmse:3.99846\ttrain-rmse:2.08045\n",
      "[6149]\teval-rmse:4.00043\ttrain-rmse:2.08047\n",
      "[6150]\teval-rmse:3.99796\ttrain-rmse:2.08043\n",
      "[6151]\teval-rmse:4.00012\ttrain-rmse:2.08061\n",
      "[6152]\teval-rmse:3.99938\ttrain-rmse:2.08061\n",
      "[6153]\teval-rmse:4.00122\ttrain-rmse:2.08066\n",
      "[6154]\teval-rmse:4.00163\ttrain-rmse:2.08066\n",
      "[6155]\teval-rmse:4.00286\ttrain-rmse:2.08068\n",
      "[6156]\teval-rmse:4.00402\ttrain-rmse:2.08071\n",
      "[6157]\teval-rmse:4.00425\ttrain-rmse:2.08071\n",
      "[6158]\teval-rmse:4.0028\ttrain-rmse:2.08057\n",
      "[6159]\teval-rmse:4.00178\ttrain-rmse:2.08055\n",
      "[6160]\teval-rmse:4.00022\ttrain-rmse:2.08056\n",
      "[6161]\teval-rmse:4.00061\ttrain-rmse:2.08057\n",
      "[6162]\teval-rmse:3.99836\ttrain-rmse:2.08054\n",
      "[6163]\teval-rmse:3.99814\ttrain-rmse:2.08053\n",
      "[6164]\teval-rmse:3.99762\ttrain-rmse:2.08049\n",
      "[6165]\teval-rmse:3.99649\ttrain-rmse:2.08042\n",
      "[6166]\teval-rmse:3.99506\ttrain-rmse:2.08032\n",
      "[6167]\teval-rmse:3.99501\ttrain-rmse:2.08032\n",
      "[6168]\teval-rmse:3.99631\ttrain-rmse:2.08033\n",
      "[6169]\teval-rmse:3.99534\ttrain-rmse:2.08031\n",
      "[6170]\teval-rmse:3.99522\ttrain-rmse:2.08031\n",
      "[6171]\teval-rmse:3.99504\ttrain-rmse:2.08031\n",
      "[6172]\teval-rmse:3.9955\ttrain-rmse:2.08031\n",
      "[6173]\teval-rmse:3.99756\ttrain-rmse:2.08033\n",
      "[6174]\teval-rmse:3.99818\ttrain-rmse:2.08034\n",
      "[6175]\teval-rmse:4.00069\ttrain-rmse:2.08031\n",
      "[6176]\teval-rmse:4.00078\ttrain-rmse:2.08031\n",
      "[6177]\teval-rmse:4.00291\ttrain-rmse:2.08027\n",
      "[6178]\teval-rmse:4.00433\ttrain-rmse:2.08024\n",
      "[6179]\teval-rmse:4.00383\ttrain-rmse:2.08019\n",
      "[6180]\teval-rmse:4.00481\ttrain-rmse:2.08022\n",
      "[6181]\teval-rmse:4.0052\ttrain-rmse:2.08023\n",
      "[6182]\teval-rmse:4.003\ttrain-rmse:2.08015\n",
      "[6183]\teval-rmse:4.00394\ttrain-rmse:2.08017\n",
      "[6184]\teval-rmse:4.00287\ttrain-rmse:2.07957\n",
      "[6185]\teval-rmse:4.00029\ttrain-rmse:2.07952\n",
      "[6186]\teval-rmse:3.99921\ttrain-rmse:2.0794\n",
      "[6187]\teval-rmse:4.00036\ttrain-rmse:2.07942\n",
      "[6188]\teval-rmse:4.00224\ttrain-rmse:2.07949\n",
      "[6189]\teval-rmse:4.00288\ttrain-rmse:2.07951\n",
      "[6190]\teval-rmse:4.00187\ttrain-rmse:2.07888\n",
      "[6191]\teval-rmse:4.00428\ttrain-rmse:2.07887\n",
      "[6192]\teval-rmse:4.00271\ttrain-rmse:2.07883\n",
      "[6193]\teval-rmse:4.00003\ttrain-rmse:2.07876\n",
      "[6194]\teval-rmse:4.0012\ttrain-rmse:2.07879\n",
      "[6195]\teval-rmse:4.00016\ttrain-rmse:2.07877\n",
      "[6196]\teval-rmse:3.99868\ttrain-rmse:2.07874\n",
      "[6197]\teval-rmse:3.99717\ttrain-rmse:2.07871\n",
      "[6198]\teval-rmse:3.99607\ttrain-rmse:2.07812\n",
      "[6199]\teval-rmse:3.99384\ttrain-rmse:2.07809\n",
      "[6200]\teval-rmse:3.99245\ttrain-rmse:2.07796\n",
      "[6201]\teval-rmse:3.99461\ttrain-rmse:2.07812\n",
      "[6202]\teval-rmse:3.9952\ttrain-rmse:2.07813\n",
      "[6203]\teval-rmse:3.99388\ttrain-rmse:2.07812\n",
      "[6204]\teval-rmse:3.99287\ttrain-rmse:2.07762\n",
      "[6205]\teval-rmse:3.99266\ttrain-rmse:2.07761\n",
      "[6206]\teval-rmse:3.99253\ttrain-rmse:2.07761\n",
      "[6207]\teval-rmse:3.98997\ttrain-rmse:2.07759\n",
      "[6208]\teval-rmse:3.99102\ttrain-rmse:2.07759\n",
      "[6209]\teval-rmse:3.99279\ttrain-rmse:2.07761\n",
      "[6210]\teval-rmse:3.9913\ttrain-rmse:2.0776\n",
      "[6211]\teval-rmse:3.99189\ttrain-rmse:2.0776\n",
      "[6212]\teval-rmse:3.98955\ttrain-rmse:2.07758\n",
      "[6213]\teval-rmse:3.98753\ttrain-rmse:2.07763\n",
      "[6214]\teval-rmse:3.98969\ttrain-rmse:2.07755\n",
      "[6215]\teval-rmse:3.99195\ttrain-rmse:2.0775\n",
      "[6216]\teval-rmse:3.9941\ttrain-rmse:2.07767\n",
      "[6217]\teval-rmse:3.99175\ttrain-rmse:2.07764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6218]\teval-rmse:3.99125\ttrain-rmse:2.07761\n",
      "[6219]\teval-rmse:3.98934\ttrain-rmse:2.07765\n",
      "[6220]\teval-rmse:3.98703\ttrain-rmse:2.07766\n",
      "[6221]\teval-rmse:3.98814\ttrain-rmse:2.07765\n",
      "[6222]\teval-rmse:3.98767\ttrain-rmse:2.0776\n",
      "[6223]\teval-rmse:3.98982\ttrain-rmse:2.0776\n",
      "[6224]\teval-rmse:3.99221\ttrain-rmse:2.07752\n",
      "[6225]\teval-rmse:3.99245\ttrain-rmse:2.07752\n",
      "[6226]\teval-rmse:3.99439\ttrain-rmse:2.07754\n",
      "[6227]\teval-rmse:3.99399\ttrain-rmse:2.07753\n",
      "[6228]\teval-rmse:3.9947\ttrain-rmse:2.07754\n",
      "[6229]\teval-rmse:3.99583\ttrain-rmse:2.07755\n",
      "[6230]\teval-rmse:3.99597\ttrain-rmse:2.07755\n",
      "[6231]\teval-rmse:3.99467\ttrain-rmse:2.07757\n",
      "[6232]\teval-rmse:3.99521\ttrain-rmse:2.07758\n",
      "[6233]\teval-rmse:3.99485\ttrain-rmse:2.07753\n",
      "[6234]\teval-rmse:3.99578\ttrain-rmse:2.07755\n",
      "[6235]\teval-rmse:3.99772\ttrain-rmse:2.07752\n",
      "[6236]\teval-rmse:3.99722\ttrain-rmse:2.07746\n",
      "[6237]\teval-rmse:3.99465\ttrain-rmse:2.07742\n",
      "[6238]\teval-rmse:3.99652\ttrain-rmse:2.07745\n",
      "[6239]\teval-rmse:3.99713\ttrain-rmse:2.07744\n",
      "[6240]\teval-rmse:3.99951\ttrain-rmse:2.07748\n",
      "[6241]\teval-rmse:3.99828\ttrain-rmse:2.0775\n",
      "[6242]\teval-rmse:3.99909\ttrain-rmse:2.07752\n",
      "[6243]\teval-rmse:4.00125\ttrain-rmse:2.07771\n",
      "[6244]\teval-rmse:4.00021\ttrain-rmse:2.0772\n",
      "[6245]\teval-rmse:3.99874\ttrain-rmse:2.07705\n",
      "[6246]\teval-rmse:3.99922\ttrain-rmse:2.07706\n",
      "[6247]\teval-rmse:3.99972\ttrain-rmse:2.07707\n",
      "[6248]\teval-rmse:4.00187\ttrain-rmse:2.07726\n",
      "[6249]\teval-rmse:4.00254\ttrain-rmse:2.07728\n",
      "[6250]\teval-rmse:4.0013\ttrain-rmse:2.07728\n",
      "[6251]\teval-rmse:4.00306\ttrain-rmse:2.07733\n",
      "[6252]\teval-rmse:4.0035\ttrain-rmse:2.07735\n",
      "[6253]\teval-rmse:4.00238\ttrain-rmse:2.07723\n",
      "[6254]\teval-rmse:4.0005\ttrain-rmse:2.07723\n",
      "[6255]\teval-rmse:4.00208\ttrain-rmse:2.07727\n",
      "[6256]\teval-rmse:4.00368\ttrain-rmse:2.07732\n",
      "[6257]\teval-rmse:4.00471\ttrain-rmse:2.07736\n",
      "[6258]\teval-rmse:4.00283\ttrain-rmse:2.07735\n",
      "[6259]\teval-rmse:4.00153\ttrain-rmse:2.07731\n",
      "[6260]\teval-rmse:3.99885\ttrain-rmse:2.0772\n",
      "[6261]\teval-rmse:3.99782\ttrain-rmse:2.07718\n",
      "[6262]\teval-rmse:3.99732\ttrain-rmse:2.07713\n",
      "[6263]\teval-rmse:3.99714\ttrain-rmse:2.07712\n",
      "[6264]\teval-rmse:3.99613\ttrain-rmse:2.0771\n",
      "[6265]\teval-rmse:3.99511\ttrain-rmse:2.07708\n",
      "[6266]\teval-rmse:3.99745\ttrain-rmse:2.07703\n",
      "[6267]\teval-rmse:3.99615\ttrain-rmse:2.07699\n",
      "[6268]\teval-rmse:3.99625\ttrain-rmse:2.07699\n",
      "[6269]\teval-rmse:3.99658\ttrain-rmse:2.077\n",
      "[6270]\teval-rmse:3.9979\ttrain-rmse:2.07698\n",
      "[6271]\teval-rmse:3.99779\ttrain-rmse:2.07698\n",
      "[6272]\teval-rmse:3.99629\ttrain-rmse:2.07694\n",
      "[6273]\teval-rmse:3.99766\ttrain-rmse:2.07697\n",
      "[6274]\teval-rmse:3.99509\ttrain-rmse:2.07693\n",
      "[6275]\teval-rmse:3.99554\ttrain-rmse:2.07694\n",
      "[6276]\teval-rmse:3.99597\ttrain-rmse:2.07694\n",
      "[6277]\teval-rmse:3.99505\ttrain-rmse:2.07696\n",
      "[6278]\teval-rmse:3.99609\ttrain-rmse:2.07697\n",
      "[6279]\teval-rmse:3.99422\ttrain-rmse:2.07694\n",
      "[6280]\teval-rmse:3.994\ttrain-rmse:2.07694\n",
      "[6281]\teval-rmse:3.99267\ttrain-rmse:2.07692\n",
      "[6282]\teval-rmse:3.99391\ttrain-rmse:2.07695\n",
      "[6283]\teval-rmse:3.99468\ttrain-rmse:2.07697\n",
      "[6284]\teval-rmse:3.99478\ttrain-rmse:2.07697\n",
      "[6285]\teval-rmse:3.99474\ttrain-rmse:2.07697\n",
      "[6286]\teval-rmse:3.99415\ttrain-rmse:2.07696\n",
      "[6287]\teval-rmse:3.99307\ttrain-rmse:2.0765\n",
      "[6288]\teval-rmse:3.99162\ttrain-rmse:2.07649\n",
      "[6289]\teval-rmse:3.99309\ttrain-rmse:2.07651\n",
      "[6290]\teval-rmse:3.9956\ttrain-rmse:2.07655\n",
      "[6291]\teval-rmse:3.99553\ttrain-rmse:2.07655\n",
      "[6292]\teval-rmse:3.99663\ttrain-rmse:2.07657\n",
      "[6293]\teval-rmse:3.99511\ttrain-rmse:2.07654\n",
      "[6294]\teval-rmse:3.99348\ttrain-rmse:2.07652\n",
      "[6295]\teval-rmse:3.99227\ttrain-rmse:2.07653\n",
      "[6296]\teval-rmse:3.99121\ttrain-rmse:2.07643\n",
      "[6297]\teval-rmse:3.99181\ttrain-rmse:2.07644\n",
      "[6298]\teval-rmse:3.98963\ttrain-rmse:2.07648\n",
      "[6299]\teval-rmse:3.98862\ttrain-rmse:2.07601\n",
      "[6300]\teval-rmse:3.98755\ttrain-rmse:2.07593\n",
      "[6301]\teval-rmse:3.98651\ttrain-rmse:2.07583\n",
      "[6302]\teval-rmse:3.98798\ttrain-rmse:2.07585\n",
      "[6303]\teval-rmse:3.98585\ttrain-rmse:2.07583\n",
      "[6304]\teval-rmse:3.98438\ttrain-rmse:2.07582\n",
      "[6305]\teval-rmse:3.98251\ttrain-rmse:2.07587\n",
      "[6306]\teval-rmse:3.98313\ttrain-rmse:2.07587\n",
      "[6307]\teval-rmse:3.98461\ttrain-rmse:2.07588\n",
      "[6308]\teval-rmse:3.98527\ttrain-rmse:2.07588\n",
      "[6309]\teval-rmse:3.98264\ttrain-rmse:2.07585\n",
      "[6310]\teval-rmse:3.98138\ttrain-rmse:2.07585\n",
      "[6311]\teval-rmse:3.98387\ttrain-rmse:2.07577\n",
      "[6312]\teval-rmse:3.98182\ttrain-rmse:2.07577\n",
      "[6313]\teval-rmse:3.97935\ttrain-rmse:2.0758\n",
      "[6314]\teval-rmse:3.97965\ttrain-rmse:2.0758\n",
      "[6315]\teval-rmse:3.97863\ttrain-rmse:2.07584\n",
      "[6316]\teval-rmse:3.9776\ttrain-rmse:2.07584\n",
      "[6317]\teval-rmse:3.97897\ttrain-rmse:2.07583\n",
      "[6318]\teval-rmse:3.97741\ttrain-rmse:2.07585\n",
      "[6319]\teval-rmse:3.97714\ttrain-rmse:2.0758\n",
      "[6320]\teval-rmse:3.97897\ttrain-rmse:2.07578\n",
      "[6321]\teval-rmse:3.97885\ttrain-rmse:2.07578\n",
      "[6322]\teval-rmse:3.98103\ttrain-rmse:2.07591\n",
      "[6323]\teval-rmse:3.98031\ttrain-rmse:2.07593\n",
      "[6324]\teval-rmse:3.97948\ttrain-rmse:2.07597\n",
      "[6325]\teval-rmse:3.98092\ttrain-rmse:2.0759\n",
      "[6326]\teval-rmse:3.98241\ttrain-rmse:2.07585\n",
      "[6327]\teval-rmse:3.98021\ttrain-rmse:2.07592\n",
      "[6328]\teval-rmse:3.97775\ttrain-rmse:2.07596\n",
      "[6329]\teval-rmse:3.97869\ttrain-rmse:2.07594\n",
      "[6330]\teval-rmse:3.97692\ttrain-rmse:2.07595\n",
      "[6331]\teval-rmse:3.9753\ttrain-rmse:2.07597\n",
      "[6332]\teval-rmse:3.97676\ttrain-rmse:2.0759\n",
      "[6333]\teval-rmse:3.97577\ttrain-rmse:2.07582\n",
      "[6334]\teval-rmse:3.97477\ttrain-rmse:2.07536\n",
      "[6335]\teval-rmse:3.97241\ttrain-rmse:2.07542\n",
      "[6336]\teval-rmse:3.971\ttrain-rmse:2.07545\n",
      "[6337]\teval-rmse:3.97216\ttrain-rmse:2.07542\n",
      "[6338]\teval-rmse:3.97324\ttrain-rmse:2.0754\n",
      "[6339]\teval-rmse:3.9756\ttrain-rmse:2.07535\n",
      "[6340]\teval-rmse:3.97672\ttrain-rmse:2.07533\n",
      "[6341]\teval-rmse:3.97493\ttrain-rmse:2.07534\n",
      "[6342]\teval-rmse:3.97391\ttrain-rmse:2.07539\n",
      "[6343]\teval-rmse:3.97276\ttrain-rmse:2.07544\n",
      "[6344]\teval-rmse:3.97066\ttrain-rmse:2.07547\n",
      "[6345]\teval-rmse:3.96855\ttrain-rmse:2.07553\n",
      "[6346]\teval-rmse:3.96747\ttrain-rmse:2.07557\n",
      "[6347]\teval-rmse:3.96886\ttrain-rmse:2.07548\n",
      "[6348]\teval-rmse:3.96789\ttrain-rmse:2.07504\n",
      "[6349]\teval-rmse:3.9657\ttrain-rmse:2.07512\n",
      "[6350]\teval-rmse:3.96419\ttrain-rmse:2.07521\n",
      "[6351]\teval-rmse:3.96425\ttrain-rmse:2.07521\n",
      "[6352]\teval-rmse:3.96644\ttrain-rmse:2.07531\n",
      "[6353]\teval-rmse:3.96823\ttrain-rmse:2.07525\n",
      "[6354]\teval-rmse:3.97006\ttrain-rmse:2.07514\n",
      "[6355]\teval-rmse:3.96909\ttrain-rmse:2.07458\n",
      "[6356]\teval-rmse:3.96882\ttrain-rmse:2.07457\n",
      "[6357]\teval-rmse:3.96762\ttrain-rmse:2.07461\n",
      "[6358]\teval-rmse:3.96518\ttrain-rmse:2.07471\n",
      "[6359]\teval-rmse:3.96707\ttrain-rmse:2.07466\n",
      "[6360]\teval-rmse:3.96703\ttrain-rmse:2.07466\n",
      "[6361]\teval-rmse:3.96689\ttrain-rmse:2.07466\n",
      "[6362]\teval-rmse:3.9662\ttrain-rmse:2.0747\n",
      "[6363]\teval-rmse:3.96675\ttrain-rmse:2.07468\n",
      "[6364]\teval-rmse:3.96638\ttrain-rmse:2.07464\n",
      "[6365]\teval-rmse:3.96524\ttrain-rmse:2.07467\n",
      "[6366]\teval-rmse:3.96559\ttrain-rmse:2.07465\n",
      "[6367]\teval-rmse:3.96575\ttrain-rmse:2.07464\n",
      "[6368]\teval-rmse:3.96481\ttrain-rmse:2.07421\n",
      "[6369]\teval-rmse:3.96355\ttrain-rmse:2.07412\n",
      "[6370]\teval-rmse:3.9626\ttrain-rmse:2.07416\n",
      "[6371]\teval-rmse:3.96088\ttrain-rmse:2.07424\n",
      "[6372]\teval-rmse:3.95937\ttrain-rmse:2.07434\n",
      "[6373]\teval-rmse:3.95763\ttrain-rmse:2.07446\n",
      "[6374]\teval-rmse:3.95573\ttrain-rmse:2.07454\n",
      "[6375]\teval-rmse:3.95681\ttrain-rmse:2.07446\n",
      "[6376]\teval-rmse:3.95604\ttrain-rmse:2.0745\n",
      "[6377]\teval-rmse:3.95446\ttrain-rmse:2.07459\n",
      "[6378]\teval-rmse:3.95223\ttrain-rmse:2.07472\n",
      "[6379]\teval-rmse:3.95326\ttrain-rmse:2.07465\n",
      "[6380]\teval-rmse:3.95382\ttrain-rmse:2.07462\n",
      "[6381]\teval-rmse:3.95339\ttrain-rmse:2.07465\n",
      "[6382]\teval-rmse:3.95351\ttrain-rmse:2.07464\n",
      "[6383]\teval-rmse:3.95352\ttrain-rmse:2.07464\n",
      "[6384]\teval-rmse:3.95266\ttrain-rmse:2.07456\n",
      "[6385]\teval-rmse:3.95291\ttrain-rmse:2.07454\n",
      "[6386]\teval-rmse:3.95175\ttrain-rmse:2.07461\n",
      "[6387]\teval-rmse:3.95206\ttrain-rmse:2.07458\n",
      "[6388]\teval-rmse:3.95351\ttrain-rmse:2.0745\n",
      "[6389]\teval-rmse:3.95471\ttrain-rmse:2.07443\n",
      "[6390]\teval-rmse:3.95358\ttrain-rmse:2.07449\n",
      "[6391]\teval-rmse:3.95139\ttrain-rmse:2.07462\n",
      "[6392]\teval-rmse:3.95348\ttrain-rmse:2.07444\n",
      "[6393]\teval-rmse:3.95255\ttrain-rmse:2.07451\n",
      "[6394]\teval-rmse:3.95098\ttrain-rmse:2.07462\n",
      "[6395]\teval-rmse:3.95206\ttrain-rmse:2.07455\n",
      "[6396]\teval-rmse:3.95396\ttrain-rmse:2.07445\n",
      "[6397]\teval-rmse:3.95185\ttrain-rmse:2.07457\n",
      "[6398]\teval-rmse:3.95133\ttrain-rmse:2.0746\n",
      "[6399]\teval-rmse:3.94962\ttrain-rmse:2.07472\n",
      "[6400]\teval-rmse:3.9488\ttrain-rmse:2.07477\n",
      "[6401]\teval-rmse:3.94794\ttrain-rmse:2.07436\n",
      "[6402]\teval-rmse:3.94675\ttrain-rmse:2.07444\n",
      "[6403]\teval-rmse:3.94492\ttrain-rmse:2.07456\n",
      "[6404]\teval-rmse:3.94637\ttrain-rmse:2.07445\n",
      "[6405]\teval-rmse:3.94549\ttrain-rmse:2.07443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6406]\teval-rmse:3.94801\ttrain-rmse:2.07426\n",
      "[6407]\teval-rmse:3.94827\ttrain-rmse:2.07424\n",
      "[6408]\teval-rmse:3.94752\ttrain-rmse:2.07429\n",
      "[6409]\teval-rmse:3.94776\ttrain-rmse:2.07427\n",
      "[6410]\teval-rmse:3.94675\ttrain-rmse:2.07436\n",
      "[6411]\teval-rmse:3.94591\ttrain-rmse:2.07434\n",
      "[6412]\teval-rmse:3.94728\ttrain-rmse:2.07425\n",
      "[6413]\teval-rmse:3.94891\ttrain-rmse:2.07413\n",
      "[6414]\teval-rmse:3.94775\ttrain-rmse:2.0742\n",
      "[6415]\teval-rmse:3.94943\ttrain-rmse:2.07409\n",
      "[6416]\teval-rmse:3.95083\ttrain-rmse:2.07397\n",
      "[6417]\teval-rmse:3.95285\ttrain-rmse:2.07381\n",
      "[6418]\teval-rmse:3.95284\ttrain-rmse:2.07381\n",
      "[6419]\teval-rmse:3.95182\ttrain-rmse:2.07389\n",
      "[6420]\teval-rmse:3.95094\ttrain-rmse:2.07387\n",
      "[6421]\teval-rmse:3.95064\ttrain-rmse:2.07385\n",
      "[6422]\teval-rmse:3.94907\ttrain-rmse:2.07398\n",
      "[6423]\teval-rmse:3.9483\ttrain-rmse:2.07404\n",
      "[6424]\teval-rmse:3.94836\ttrain-rmse:2.07404\n",
      "[6425]\teval-rmse:3.94749\ttrain-rmse:2.0735\n",
      "[6426]\teval-rmse:3.94692\ttrain-rmse:2.07353\n",
      "[6427]\teval-rmse:3.94599\ttrain-rmse:2.07361\n",
      "[6428]\teval-rmse:3.94638\ttrain-rmse:2.07359\n",
      "[6429]\teval-rmse:3.94712\ttrain-rmse:2.07352\n",
      "[6430]\teval-rmse:3.94562\ttrain-rmse:2.07362\n",
      "[6431]\teval-rmse:3.94656\ttrain-rmse:2.07356\n",
      "[6432]\teval-rmse:3.94636\ttrain-rmse:2.07353\n",
      "[6433]\teval-rmse:3.94662\ttrain-rmse:2.07351\n",
      "[6434]\teval-rmse:3.9461\ttrain-rmse:2.07355\n",
      "[6435]\teval-rmse:3.94527\ttrain-rmse:2.07314\n",
      "[6436]\teval-rmse:3.94669\ttrain-rmse:2.07304\n",
      "[6437]\teval-rmse:3.94531\ttrain-rmse:2.07313\n",
      "[6438]\teval-rmse:3.94683\ttrain-rmse:2.07304\n",
      "[6439]\teval-rmse:3.9476\ttrain-rmse:2.07299\n",
      "[6440]\teval-rmse:3.9454\ttrain-rmse:2.07313\n",
      "[6441]\teval-rmse:3.94413\ttrain-rmse:2.07322\n",
      "[6442]\teval-rmse:3.94328\ttrain-rmse:2.07328\n",
      "[6443]\teval-rmse:3.94131\ttrain-rmse:2.07342\n",
      "[6444]\teval-rmse:3.94078\ttrain-rmse:2.07346\n",
      "[6445]\teval-rmse:3.94175\ttrain-rmse:2.07338\n",
      "[6446]\teval-rmse:3.94378\ttrain-rmse:2.07323\n",
      "[6447]\teval-rmse:3.94494\ttrain-rmse:2.07316\n",
      "[6448]\teval-rmse:3.94476\ttrain-rmse:2.07311\n",
      "[6449]\teval-rmse:3.94391\ttrain-rmse:2.07269\n",
      "[6450]\teval-rmse:3.94545\ttrain-rmse:2.07254\n",
      "[6451]\teval-rmse:3.94441\ttrain-rmse:2.07261\n",
      "[6452]\teval-rmse:3.94364\ttrain-rmse:2.07219\n",
      "[6453]\teval-rmse:3.94479\ttrain-rmse:2.07212\n",
      "[6454]\teval-rmse:3.94397\ttrain-rmse:2.07206\n",
      "[6455]\teval-rmse:3.94409\ttrain-rmse:2.07205\n",
      "[6456]\teval-rmse:3.94276\ttrain-rmse:2.07217\n",
      "[6457]\teval-rmse:3.94261\ttrain-rmse:2.07216\n",
      "[6458]\teval-rmse:3.94166\ttrain-rmse:2.07223\n",
      "[6459]\teval-rmse:3.94089\ttrain-rmse:2.07228\n",
      "[6460]\teval-rmse:3.94277\ttrain-rmse:2.07216\n",
      "[6461]\teval-rmse:3.94336\ttrain-rmse:2.07213\n",
      "[6462]\teval-rmse:3.94544\ttrain-rmse:2.07199\n",
      "[6463]\teval-rmse:3.94769\ttrain-rmse:2.07204\n",
      "[6464]\teval-rmse:3.94905\ttrain-rmse:2.07192\n",
      "[6465]\teval-rmse:3.95036\ttrain-rmse:2.07186\n",
      "[6466]\teval-rmse:3.94952\ttrain-rmse:2.0718\n",
      "[6467]\teval-rmse:3.95037\ttrain-rmse:2.07175\n",
      "[6468]\teval-rmse:3.95024\ttrain-rmse:2.07176\n",
      "[6469]\teval-rmse:3.9509\ttrain-rmse:2.07172\n",
      "[6470]\teval-rmse:3.9502\ttrain-rmse:2.07178\n",
      "[6471]\teval-rmse:3.95013\ttrain-rmse:2.07178\n",
      "[6472]\teval-rmse:3.95171\ttrain-rmse:2.07165\n",
      "[6473]\teval-rmse:3.95093\ttrain-rmse:2.07169\n",
      "[6474]\teval-rmse:3.95111\ttrain-rmse:2.07168\n",
      "[6475]\teval-rmse:3.95057\ttrain-rmse:2.07171\n",
      "[6476]\teval-rmse:3.94987\ttrain-rmse:2.07174\n",
      "[6477]\teval-rmse:3.94905\ttrain-rmse:2.07168\n",
      "[6478]\teval-rmse:3.94787\ttrain-rmse:2.07175\n",
      "[6479]\teval-rmse:3.94627\ttrain-rmse:2.07184\n",
      "[6480]\teval-rmse:3.94667\ttrain-rmse:2.07181\n",
      "[6481]\teval-rmse:3.94458\ttrain-rmse:2.07192\n",
      "[6482]\teval-rmse:3.94401\ttrain-rmse:2.07196\n",
      "[6483]\teval-rmse:3.94293\ttrain-rmse:2.07202\n",
      "[6484]\teval-rmse:3.94178\ttrain-rmse:2.07198\n",
      "[6485]\teval-rmse:3.94432\ttrain-rmse:2.07174\n",
      "[6486]\teval-rmse:3.94346\ttrain-rmse:2.07133\n",
      "[6487]\teval-rmse:3.94457\ttrain-rmse:2.07125\n",
      "[6488]\teval-rmse:3.94631\ttrain-rmse:2.07115\n",
      "[6489]\teval-rmse:3.94448\ttrain-rmse:2.07126\n",
      "[6490]\teval-rmse:3.94479\ttrain-rmse:2.07124\n",
      "[6491]\teval-rmse:3.94425\ttrain-rmse:2.07129\n",
      "[6492]\teval-rmse:3.94666\ttrain-rmse:2.07115\n",
      "[6493]\teval-rmse:3.94755\ttrain-rmse:2.0711\n",
      "[6494]\teval-rmse:3.94768\ttrain-rmse:2.07109\n",
      "[6495]\teval-rmse:3.94568\ttrain-rmse:2.0712\n",
      "[6496]\teval-rmse:3.94351\ttrain-rmse:2.07134\n",
      "[6497]\teval-rmse:3.94183\ttrain-rmse:2.07146\n",
      "[6498]\teval-rmse:3.94028\ttrain-rmse:2.07157\n",
      "[6499]\teval-rmse:3.94091\ttrain-rmse:2.07152\n",
      "[6500]\teval-rmse:3.94313\ttrain-rmse:2.07156\n",
      "[6501]\teval-rmse:3.94501\ttrain-rmse:2.07139\n",
      "[6502]\teval-rmse:3.94698\ttrain-rmse:2.07121\n",
      "[6503]\teval-rmse:3.94574\ttrain-rmse:2.07129\n",
      "[6504]\teval-rmse:3.94487\ttrain-rmse:2.07128\n",
      "[6505]\teval-rmse:3.94525\ttrain-rmse:2.07125\n",
      "[6506]\teval-rmse:3.94677\ttrain-rmse:2.07116\n",
      "[6507]\teval-rmse:3.94607\ttrain-rmse:2.07122\n",
      "[6508]\teval-rmse:3.94601\ttrain-rmse:2.07122\n",
      "[6509]\teval-rmse:3.94491\ttrain-rmse:2.07129\n",
      "[6510]\teval-rmse:3.94635\ttrain-rmse:2.07119\n",
      "[6511]\teval-rmse:3.94812\ttrain-rmse:2.07108\n",
      "[6512]\teval-rmse:3.94569\ttrain-rmse:2.07123\n",
      "[6513]\teval-rmse:3.94452\ttrain-rmse:2.07117\n",
      "[6514]\teval-rmse:3.94263\ttrain-rmse:2.07129\n",
      "[6515]\teval-rmse:3.94389\ttrain-rmse:2.0712\n",
      "[6516]\teval-rmse:3.94517\ttrain-rmse:2.07113\n",
      "[6517]\teval-rmse:3.94709\ttrain-rmse:2.07102\n",
      "[6518]\teval-rmse:3.94622\ttrain-rmse:2.07097\n",
      "[6519]\teval-rmse:3.94391\ttrain-rmse:2.07111\n",
      "[6520]\teval-rmse:3.94365\ttrain-rmse:2.07107\n",
      "[6521]\teval-rmse:3.94284\ttrain-rmse:2.07112\n",
      "[6522]\teval-rmse:3.94127\ttrain-rmse:2.07123\n",
      "[6523]\teval-rmse:3.94271\ttrain-rmse:2.07115\n",
      "[6524]\teval-rmse:3.9451\ttrain-rmse:2.07094\n",
      "[6525]\teval-rmse:3.94629\ttrain-rmse:2.07086\n",
      "[6526]\teval-rmse:3.94469\ttrain-rmse:2.07099\n",
      "[6527]\teval-rmse:3.94584\ttrain-rmse:2.07092\n",
      "[6528]\teval-rmse:3.94637\ttrain-rmse:2.07089\n",
      "[6529]\teval-rmse:3.94626\ttrain-rmse:2.0709\n",
      "[6530]\teval-rmse:3.94676\ttrain-rmse:2.07087\n",
      "[6531]\teval-rmse:3.94684\ttrain-rmse:2.07087\n",
      "[6532]\teval-rmse:3.94827\ttrain-rmse:2.07079\n",
      "[6533]\teval-rmse:3.94949\ttrain-rmse:2.07073\n",
      "[6534]\teval-rmse:3.95131\ttrain-rmse:2.07058\n",
      "[6535]\teval-rmse:3.95041\ttrain-rmse:2.07056\n",
      "[6536]\teval-rmse:3.95014\ttrain-rmse:2.07057\n",
      "[6537]\teval-rmse:3.95082\ttrain-rmse:2.07055\n",
      "[6538]\teval-rmse:3.94892\ttrain-rmse:2.07062\n",
      "[6539]\teval-rmse:3.94919\ttrain-rmse:2.07061\n",
      "[6540]\teval-rmse:3.95034\ttrain-rmse:2.07056\n",
      "[6541]\teval-rmse:3.95162\ttrain-rmse:2.07051\n",
      "[6542]\teval-rmse:3.95369\ttrain-rmse:2.07036\n",
      "[6543]\teval-rmse:3.95504\ttrain-rmse:2.07031\n",
      "[6544]\teval-rmse:3.95382\ttrain-rmse:2.07039\n",
      "[6545]\teval-rmse:3.95478\ttrain-rmse:2.07037\n",
      "[6546]\teval-rmse:3.9522\ttrain-rmse:2.07047\n",
      "[6547]\teval-rmse:3.95378\ttrain-rmse:2.07036\n",
      "[6548]\teval-rmse:3.95322\ttrain-rmse:2.07038\n",
      "[6549]\teval-rmse:3.95309\ttrain-rmse:2.07038\n",
      "[6550]\teval-rmse:3.95221\ttrain-rmse:2.07033\n",
      "[6551]\teval-rmse:3.95104\ttrain-rmse:2.07038\n",
      "[6552]\teval-rmse:3.94978\ttrain-rmse:2.07036\n",
      "[6553]\teval-rmse:3.94957\ttrain-rmse:2.07037\n",
      "[6554]\teval-rmse:3.94836\ttrain-rmse:2.07031\n",
      "[6555]\teval-rmse:3.94715\ttrain-rmse:2.07037\n",
      "[6556]\teval-rmse:3.94892\ttrain-rmse:2.07029\n",
      "[6557]\teval-rmse:3.95035\ttrain-rmse:2.07023\n",
      "[6558]\teval-rmse:3.94875\ttrain-rmse:2.0703\n",
      "[6559]\teval-rmse:3.94848\ttrain-rmse:2.07031\n",
      "[6560]\teval-rmse:3.94992\ttrain-rmse:2.07025\n",
      "[6561]\teval-rmse:3.95128\ttrain-rmse:2.0702\n",
      "[6562]\teval-rmse:3.95215\ttrain-rmse:2.07018\n",
      "[6563]\teval-rmse:3.94957\ttrain-rmse:2.07028\n",
      "[6564]\teval-rmse:3.94843\ttrain-rmse:2.07036\n",
      "[6565]\teval-rmse:3.94728\ttrain-rmse:2.07042\n",
      "[6566]\teval-rmse:3.94516\ttrain-rmse:2.07051\n",
      "[6567]\teval-rmse:3.94409\ttrain-rmse:2.07058\n",
      "[6568]\teval-rmse:3.94593\ttrain-rmse:2.07048\n",
      "[6569]\teval-rmse:3.94395\ttrain-rmse:2.07056\n",
      "[6570]\teval-rmse:3.94225\ttrain-rmse:2.07067\n",
      "[6571]\teval-rmse:3.94263\ttrain-rmse:2.07065\n",
      "[6572]\teval-rmse:3.94489\ttrain-rmse:2.07068\n",
      "[6573]\teval-rmse:3.9437\ttrain-rmse:2.07063\n",
      "[6574]\teval-rmse:3.9451\ttrain-rmse:2.07057\n",
      "[6575]\teval-rmse:3.94359\ttrain-rmse:2.07065\n",
      "[6576]\teval-rmse:3.94511\ttrain-rmse:2.07056\n",
      "[6577]\teval-rmse:3.94253\ttrain-rmse:2.07071\n",
      "[6578]\teval-rmse:3.94393\ttrain-rmse:2.07063\n",
      "[6579]\teval-rmse:3.94272\ttrain-rmse:2.07062\n",
      "[6580]\teval-rmse:3.94298\ttrain-rmse:2.07061\n",
      "[6581]\teval-rmse:3.9441\ttrain-rmse:2.07054\n",
      "[6582]\teval-rmse:3.94302\ttrain-rmse:2.0706\n",
      "[6583]\teval-rmse:3.9422\ttrain-rmse:2.07055\n",
      "[6584]\teval-rmse:3.94324\ttrain-rmse:2.07049\n",
      "[6585]\teval-rmse:3.94415\ttrain-rmse:2.07044\n",
      "[6586]\teval-rmse:3.94523\ttrain-rmse:2.07035\n",
      "[6587]\teval-rmse:3.94366\ttrain-rmse:2.07042\n",
      "[6588]\teval-rmse:3.94382\ttrain-rmse:2.07041\n",
      "[6589]\teval-rmse:3.94411\ttrain-rmse:2.07039\n",
      "[6590]\teval-rmse:3.94396\ttrain-rmse:2.0704\n",
      "[6591]\teval-rmse:3.94377\ttrain-rmse:2.07038\n",
      "[6592]\teval-rmse:3.94156\ttrain-rmse:2.07051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6593]\teval-rmse:3.94016\ttrain-rmse:2.07061\n",
      "[6594]\teval-rmse:3.93931\ttrain-rmse:2.07022\n",
      "[6595]\teval-rmse:3.93837\ttrain-rmse:2.0703\n",
      "[6596]\teval-rmse:3.93834\ttrain-rmse:2.07031\n",
      "[6597]\teval-rmse:3.93828\ttrain-rmse:2.07031\n",
      "[6598]\teval-rmse:3.93706\ttrain-rmse:2.07039\n",
      "[6599]\teval-rmse:3.93505\ttrain-rmse:2.07054\n",
      "[6600]\teval-rmse:3.93451\ttrain-rmse:2.07058\n",
      "[6601]\teval-rmse:3.93291\ttrain-rmse:2.07069\n",
      "[6602]\teval-rmse:3.9349\ttrain-rmse:2.07049\n",
      "[6603]\teval-rmse:3.93708\ttrain-rmse:2.07027\n",
      "[6604]\teval-rmse:3.9386\ttrain-rmse:2.07013\n",
      "[6605]\teval-rmse:3.93776\ttrain-rmse:2.07012\n",
      "[6606]\teval-rmse:3.93834\ttrain-rmse:2.07008\n",
      "[6607]\teval-rmse:3.93754\ttrain-rmse:2.07003\n",
      "[6608]\teval-rmse:3.93599\ttrain-rmse:2.07019\n",
      "[6609]\teval-rmse:3.93712\ttrain-rmse:2.07012\n",
      "[6610]\teval-rmse:3.93517\ttrain-rmse:2.07026\n",
      "[6611]\teval-rmse:3.93509\ttrain-rmse:2.07026\n",
      "[6612]\teval-rmse:3.93491\ttrain-rmse:2.07027\n",
      "[6613]\teval-rmse:3.93615\ttrain-rmse:2.07018\n",
      "[6614]\teval-rmse:3.93702\ttrain-rmse:2.07009\n",
      "[6615]\teval-rmse:3.93794\ttrain-rmse:2.07003\n",
      "[6616]\teval-rmse:3.93627\ttrain-rmse:2.07014\n",
      "[6617]\teval-rmse:3.93876\ttrain-rmse:2.0699\n",
      "[6618]\teval-rmse:3.94079\ttrain-rmse:2.06976\n",
      "[6619]\teval-rmse:3.93997\ttrain-rmse:2.06936\n",
      "[6620]\teval-rmse:3.93916\ttrain-rmse:2.06886\n",
      "[6621]\teval-rmse:3.94029\ttrain-rmse:2.0688\n",
      "[6622]\teval-rmse:3.93939\ttrain-rmse:2.06888\n",
      "[6623]\teval-rmse:3.93942\ttrain-rmse:2.06888\n",
      "[6624]\teval-rmse:3.94054\ttrain-rmse:2.06881\n",
      "[6625]\teval-rmse:3.94301\ttrain-rmse:2.0686\n",
      "[6626]\teval-rmse:3.94471\ttrain-rmse:2.06851\n",
      "[6627]\teval-rmse:3.94354\ttrain-rmse:2.0686\n",
      "[6628]\teval-rmse:3.94219\ttrain-rmse:2.06866\n",
      "[6629]\teval-rmse:3.94115\ttrain-rmse:2.06875\n",
      "[6630]\teval-rmse:3.9401\ttrain-rmse:2.06883\n",
      "[6631]\teval-rmse:3.93902\ttrain-rmse:2.06892\n",
      "[6632]\teval-rmse:3.93781\ttrain-rmse:2.06899\n",
      "[6633]\teval-rmse:3.93916\ttrain-rmse:2.06891\n",
      "[6634]\teval-rmse:3.94065\ttrain-rmse:2.06878\n",
      "[6635]\teval-rmse:3.94233\ttrain-rmse:2.06868\n",
      "[6636]\teval-rmse:3.94149\ttrain-rmse:2.06865\n",
      "[6637]\teval-rmse:3.93967\ttrain-rmse:2.06875\n",
      "[6638]\teval-rmse:3.93897\ttrain-rmse:2.06881\n",
      "[6639]\teval-rmse:3.94046\ttrain-rmse:2.06868\n",
      "[6640]\teval-rmse:3.93864\ttrain-rmse:2.06879\n",
      "[6641]\teval-rmse:3.93962\ttrain-rmse:2.06873\n",
      "[6642]\teval-rmse:3.93858\ttrain-rmse:2.0688\n",
      "[6643]\teval-rmse:3.94046\ttrain-rmse:2.06869\n",
      "[6644]\teval-rmse:3.93977\ttrain-rmse:2.06874\n",
      "[6645]\teval-rmse:3.939\ttrain-rmse:2.06879\n",
      "[6646]\teval-rmse:3.93761\ttrain-rmse:2.06888\n",
      "[6647]\teval-rmse:3.93872\ttrain-rmse:2.06881\n",
      "[6648]\teval-rmse:3.93967\ttrain-rmse:2.06876\n",
      "[6649]\teval-rmse:3.93946\ttrain-rmse:2.06877\n",
      "[6650]\teval-rmse:3.93843\ttrain-rmse:2.06884\n",
      "[6651]\teval-rmse:3.94091\ttrain-rmse:2.0687\n",
      "[6652]\teval-rmse:3.9404\ttrain-rmse:2.06873\n",
      "[6653]\teval-rmse:3.94145\ttrain-rmse:2.06864\n",
      "[6654]\teval-rmse:3.9437\ttrain-rmse:2.06869\n",
      "[6655]\teval-rmse:3.94618\ttrain-rmse:2.06848\n",
      "[6656]\teval-rmse:3.9453\ttrain-rmse:2.06844\n",
      "[6657]\teval-rmse:3.94359\ttrain-rmse:2.06857\n",
      "[6658]\teval-rmse:3.94467\ttrain-rmse:2.06852\n",
      "[6659]\teval-rmse:3.94323\ttrain-rmse:2.06863\n",
      "[6660]\teval-rmse:3.94371\ttrain-rmse:2.06861\n",
      "[6661]\teval-rmse:3.94592\ttrain-rmse:2.06867\n",
      "[6662]\teval-rmse:3.944\ttrain-rmse:2.06875\n",
      "[6663]\teval-rmse:3.94329\ttrain-rmse:2.06881\n",
      "[6664]\teval-rmse:3.94213\ttrain-rmse:2.06876\n",
      "[6665]\teval-rmse:3.94223\ttrain-rmse:2.06875\n",
      "[6666]\teval-rmse:3.94331\ttrain-rmse:2.06871\n",
      "[6667]\teval-rmse:3.9455\ttrain-rmse:2.0686\n",
      "[6668]\teval-rmse:3.94532\ttrain-rmse:2.0686\n",
      "[6669]\teval-rmse:3.94357\ttrain-rmse:2.06869\n",
      "[6670]\teval-rmse:3.94292\ttrain-rmse:2.06873\n",
      "[6671]\teval-rmse:3.94272\ttrain-rmse:2.06873\n",
      "[6672]\teval-rmse:3.94388\ttrain-rmse:2.06868\n",
      "[6673]\teval-rmse:3.94317\ttrain-rmse:2.06872\n",
      "[6674]\teval-rmse:3.94186\ttrain-rmse:2.06877\n",
      "[6675]\teval-rmse:3.94212\ttrain-rmse:2.06875\n",
      "[6676]\teval-rmse:3.94302\ttrain-rmse:2.0687\n",
      "[6677]\teval-rmse:3.94217\ttrain-rmse:2.06874\n",
      "[6678]\teval-rmse:3.94023\ttrain-rmse:2.06884\n",
      "[6679]\teval-rmse:3.93881\ttrain-rmse:2.06893\n",
      "[6680]\teval-rmse:3.93687\ttrain-rmse:2.06906\n",
      "[6681]\teval-rmse:3.93545\ttrain-rmse:2.06918\n",
      "[6682]\teval-rmse:3.93488\ttrain-rmse:2.06923\n",
      "[6683]\teval-rmse:3.93671\ttrain-rmse:2.06905\n",
      "[6684]\teval-rmse:3.93858\ttrain-rmse:2.06887\n",
      "[6685]\teval-rmse:3.94082\ttrain-rmse:2.06867\n",
      "[6686]\teval-rmse:3.94184\ttrain-rmse:2.06862\n",
      "[6687]\teval-rmse:3.94155\ttrain-rmse:2.06859\n",
      "[6688]\teval-rmse:3.94351\ttrain-rmse:2.06842\n",
      "[6689]\teval-rmse:3.94123\ttrain-rmse:2.06853\n",
      "[6690]\teval-rmse:3.94347\ttrain-rmse:2.06858\n",
      "[6691]\teval-rmse:3.9423\ttrain-rmse:2.06864\n",
      "[6692]\teval-rmse:3.94325\ttrain-rmse:2.06859\n",
      "[6693]\teval-rmse:3.94469\ttrain-rmse:2.0685\n",
      "[6694]\teval-rmse:3.94618\ttrain-rmse:2.06843\n",
      "[6695]\teval-rmse:3.94557\ttrain-rmse:2.06846\n",
      "[6696]\teval-rmse:3.94681\ttrain-rmse:2.06837\n",
      "[6697]\teval-rmse:3.947\ttrain-rmse:2.06836\n",
      "[6698]\teval-rmse:3.94613\ttrain-rmse:2.06785\n",
      "[6699]\teval-rmse:3.94493\ttrain-rmse:2.06783\n",
      "[6700]\teval-rmse:3.94522\ttrain-rmse:2.06782\n",
      "[6701]\teval-rmse:3.94642\ttrain-rmse:2.06777\n",
      "[6702]\teval-rmse:3.94461\ttrain-rmse:2.06786\n",
      "[6703]\teval-rmse:3.94584\ttrain-rmse:2.06779\n",
      "[6704]\teval-rmse:3.94418\ttrain-rmse:2.06788\n",
      "[6705]\teval-rmse:3.94263\ttrain-rmse:2.06795\n",
      "[6706]\teval-rmse:3.94321\ttrain-rmse:2.06793\n",
      "[6707]\teval-rmse:3.94401\ttrain-rmse:2.06789\n",
      "[6708]\teval-rmse:3.94306\ttrain-rmse:2.06797\n",
      "[6709]\teval-rmse:3.94233\ttrain-rmse:2.068\n",
      "[6710]\teval-rmse:3.94037\ttrain-rmse:2.06812\n",
      "[6711]\teval-rmse:3.93878\ttrain-rmse:2.06826\n",
      "[6712]\teval-rmse:3.93895\ttrain-rmse:2.06825\n",
      "[6713]\teval-rmse:3.9385\ttrain-rmse:2.06827\n",
      "[6714]\teval-rmse:3.93684\ttrain-rmse:2.06838\n",
      "[6715]\teval-rmse:3.93536\ttrain-rmse:2.06848\n",
      "[6716]\teval-rmse:3.93612\ttrain-rmse:2.06842\n",
      "[6717]\teval-rmse:3.93431\ttrain-rmse:2.06859\n",
      "[6718]\teval-rmse:3.93252\ttrain-rmse:2.06876\n",
      "[6719]\teval-rmse:3.93333\ttrain-rmse:2.0687\n",
      "[6720]\teval-rmse:3.9352\ttrain-rmse:2.06856\n",
      "[6721]\teval-rmse:3.93706\ttrain-rmse:2.06838\n",
      "[6722]\teval-rmse:3.93623\ttrain-rmse:2.06798\n",
      "[6723]\teval-rmse:3.93737\ttrain-rmse:2.06791\n",
      "[6724]\teval-rmse:3.93551\ttrain-rmse:2.068\n",
      "[6725]\teval-rmse:3.93486\ttrain-rmse:2.06806\n",
      "[6726]\teval-rmse:3.93352\ttrain-rmse:2.06816\n",
      "[6727]\teval-rmse:3.932\ttrain-rmse:2.06831\n",
      "[6728]\teval-rmse:3.93173\ttrain-rmse:2.06829\n",
      "[6729]\teval-rmse:3.93193\ttrain-rmse:2.06827\n",
      "[6730]\teval-rmse:3.93115\ttrain-rmse:2.06834\n",
      "[6731]\teval-rmse:3.93061\ttrain-rmse:2.06839\n",
      "[6732]\teval-rmse:3.92982\ttrain-rmse:2.06789\n",
      "[6733]\teval-rmse:3.92943\ttrain-rmse:2.06792\n",
      "[6734]\teval-rmse:3.93072\ttrain-rmse:2.06783\n",
      "[6735]\teval-rmse:3.93297\ttrain-rmse:2.06785\n",
      "[6736]\teval-rmse:3.93223\ttrain-rmse:2.06791\n",
      "[6737]\teval-rmse:3.93205\ttrain-rmse:2.06792\n",
      "[6738]\teval-rmse:3.93124\ttrain-rmse:2.06742\n",
      "[6739]\teval-rmse:3.93295\ttrain-rmse:2.06729\n",
      "[6740]\teval-rmse:3.93215\ttrain-rmse:2.0669\n",
      "[6741]\teval-rmse:3.93256\ttrain-rmse:2.06687\n",
      "[6742]\teval-rmse:3.93327\ttrain-rmse:2.06683\n",
      "[6743]\teval-rmse:3.9355\ttrain-rmse:2.06686\n",
      "[6744]\teval-rmse:3.9356\ttrain-rmse:2.06685\n",
      "[6745]\teval-rmse:3.9362\ttrain-rmse:2.06681\n",
      "[6746]\teval-rmse:3.93607\ttrain-rmse:2.06682\n",
      "[6747]\teval-rmse:3.93734\ttrain-rmse:2.06676\n",
      "[6748]\teval-rmse:3.93493\ttrain-rmse:2.0669\n",
      "[6749]\teval-rmse:3.93368\ttrain-rmse:2.06697\n",
      "[6750]\teval-rmse:3.93176\ttrain-rmse:2.06711\n",
      "[6751]\teval-rmse:3.93373\ttrain-rmse:2.06692\n",
      "[6752]\teval-rmse:3.93407\ttrain-rmse:2.0669\n",
      "[6753]\teval-rmse:3.93205\ttrain-rmse:2.06704\n",
      "[6754]\teval-rmse:3.93119\ttrain-rmse:2.06713\n",
      "[6755]\teval-rmse:3.93296\ttrain-rmse:2.06702\n",
      "[6756]\teval-rmse:3.93135\ttrain-rmse:2.06714\n",
      "[6757]\teval-rmse:3.93121\ttrain-rmse:2.06715\n",
      "[6758]\teval-rmse:3.92987\ttrain-rmse:2.06724\n",
      "[6759]\teval-rmse:3.92875\ttrain-rmse:2.06721\n",
      "[6760]\teval-rmse:3.92966\ttrain-rmse:2.06714\n",
      "[6761]\teval-rmse:3.93052\ttrain-rmse:2.06708\n",
      "[6762]\teval-rmse:3.92954\ttrain-rmse:2.06718\n",
      "[6763]\teval-rmse:3.92956\ttrain-rmse:2.06718\n",
      "[6764]\teval-rmse:3.93072\ttrain-rmse:2.06709\n",
      "[6765]\teval-rmse:3.93173\ttrain-rmse:2.06702\n",
      "[6766]\teval-rmse:3.9298\ttrain-rmse:2.06717\n",
      "[6767]\teval-rmse:3.9314\ttrain-rmse:2.06704\n",
      "[6768]\teval-rmse:3.93377\ttrain-rmse:2.0668\n",
      "[6769]\teval-rmse:3.93262\ttrain-rmse:2.06677\n",
      "[6770]\teval-rmse:3.93066\ttrain-rmse:2.06695\n",
      "[6771]\teval-rmse:3.92928\ttrain-rmse:2.06704\n",
      "[6772]\teval-rmse:3.93026\ttrain-rmse:2.06698\n",
      "[6773]\teval-rmse:3.92942\ttrain-rmse:2.06707\n",
      "[6774]\teval-rmse:3.92968\ttrain-rmse:2.06705\n",
      "[6775]\teval-rmse:3.9289\ttrain-rmse:2.06711\n",
      "[6776]\teval-rmse:3.93007\ttrain-rmse:2.06703\n",
      "[6777]\teval-rmse:3.92919\ttrain-rmse:2.0671\n",
      "[6778]\teval-rmse:3.92851\ttrain-rmse:2.06658\n",
      "[6779]\teval-rmse:3.93064\ttrain-rmse:2.06643\n",
      "[6780]\teval-rmse:3.92857\ttrain-rmse:2.06657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6781]\teval-rmse:3.92722\ttrain-rmse:2.06668\n",
      "[6782]\teval-rmse:3.92648\ttrain-rmse:2.06665\n",
      "[6783]\teval-rmse:3.92833\ttrain-rmse:2.06644\n",
      "[6784]\teval-rmse:3.9308\ttrain-rmse:2.06627\n",
      "[6785]\teval-rmse:3.93227\ttrain-rmse:2.06613\n",
      "[6786]\teval-rmse:3.93465\ttrain-rmse:2.06597\n",
      "[6787]\teval-rmse:3.93505\ttrain-rmse:2.06595\n",
      "[6788]\teval-rmse:3.93521\ttrain-rmse:2.06593\n",
      "[6789]\teval-rmse:3.93768\ttrain-rmse:2.0657\n",
      "[6790]\teval-rmse:3.93569\ttrain-rmse:2.06582\n",
      "[6791]\teval-rmse:3.93766\ttrain-rmse:2.0657\n",
      "[6792]\teval-rmse:3.93772\ttrain-rmse:2.06569\n",
      "[6793]\teval-rmse:3.94006\ttrain-rmse:2.06548\n",
      "[6794]\teval-rmse:3.93883\ttrain-rmse:2.06555\n",
      "[6795]\teval-rmse:3.94105\ttrain-rmse:2.06559\n",
      "[6796]\teval-rmse:3.93865\ttrain-rmse:2.06568\n",
      "[6797]\teval-rmse:3.93854\ttrain-rmse:2.06569\n",
      "[6798]\teval-rmse:3.9375\ttrain-rmse:2.06574\n",
      "[6799]\teval-rmse:3.93878\ttrain-rmse:2.06567\n",
      "[6800]\teval-rmse:3.93687\ttrain-rmse:2.06577\n",
      "[6801]\teval-rmse:3.93838\ttrain-rmse:2.06569\n",
      "[6802]\teval-rmse:3.93873\ttrain-rmse:2.06567\n",
      "[6803]\teval-rmse:3.94055\ttrain-rmse:2.06556\n",
      "[6804]\teval-rmse:3.94241\ttrain-rmse:2.06547\n",
      "[6805]\teval-rmse:3.94141\ttrain-rmse:2.06554\n",
      "[6806]\teval-rmse:3.94244\ttrain-rmse:2.06549\n",
      "[6807]\teval-rmse:3.94129\ttrain-rmse:2.06544\n",
      "[6808]\teval-rmse:3.93961\ttrain-rmse:2.06552\n",
      "[6809]\teval-rmse:3.9413\ttrain-rmse:2.06544\n",
      "[6810]\teval-rmse:3.943\ttrain-rmse:2.06538\n",
      "[6811]\teval-rmse:3.94513\ttrain-rmse:2.06522\n",
      "[6812]\teval-rmse:3.94746\ttrain-rmse:2.06506\n",
      "[6813]\teval-rmse:3.9477\ttrain-rmse:2.06505\n",
      "[6814]\teval-rmse:3.94912\ttrain-rmse:2.06502\n",
      "[6815]\teval-rmse:3.95017\ttrain-rmse:2.065\n",
      "[6816]\teval-rmse:3.94873\ttrain-rmse:2.06505\n",
      "[6817]\teval-rmse:3.94754\ttrain-rmse:2.065\n",
      "[6818]\teval-rmse:3.94732\ttrain-rmse:2.065\n",
      "[6819]\teval-rmse:3.9463\ttrain-rmse:2.06502\n",
      "[6820]\teval-rmse:3.94672\ttrain-rmse:2.06501\n",
      "[6821]\teval-rmse:3.94572\ttrain-rmse:2.06506\n",
      "[6822]\teval-rmse:3.94724\ttrain-rmse:2.06499\n",
      "[6823]\teval-rmse:3.94545\ttrain-rmse:2.06507\n",
      "[6824]\teval-rmse:3.94654\ttrain-rmse:2.06502\n",
      "[6825]\teval-rmse:3.94796\ttrain-rmse:2.06498\n",
      "[6826]\teval-rmse:3.94883\ttrain-rmse:2.06495\n",
      "[6827]\teval-rmse:3.94782\ttrain-rmse:2.06498\n",
      "[6828]\teval-rmse:3.94882\ttrain-rmse:2.06494\n",
      "[6829]\teval-rmse:3.94756\ttrain-rmse:2.06491\n",
      "[6830]\teval-rmse:3.94634\ttrain-rmse:2.06495\n",
      "[6831]\teval-rmse:3.94489\ttrain-rmse:2.06501\n",
      "[6832]\teval-rmse:3.94707\ttrain-rmse:2.06487\n",
      "[6833]\teval-rmse:3.94808\ttrain-rmse:2.06483\n",
      "[6834]\teval-rmse:3.95005\ttrain-rmse:2.06478\n",
      "[6835]\teval-rmse:3.94908\ttrain-rmse:2.06481\n",
      "[6836]\teval-rmse:3.95033\ttrain-rmse:2.06477\n",
      "[6837]\teval-rmse:3.95277\ttrain-rmse:2.06461\n",
      "[6838]\teval-rmse:3.95318\ttrain-rmse:2.0646\n",
      "[6839]\teval-rmse:3.95151\ttrain-rmse:2.06469\n",
      "[6840]\teval-rmse:3.95068\ttrain-rmse:2.06428\n",
      "[6841]\teval-rmse:3.95282\ttrain-rmse:2.06416\n",
      "[6842]\teval-rmse:3.9515\ttrain-rmse:2.06418\n",
      "[6843]\teval-rmse:3.95289\ttrain-rmse:2.06416\n",
      "[6844]\teval-rmse:3.95392\ttrain-rmse:2.06413\n",
      "[6845]\teval-rmse:3.95411\ttrain-rmse:2.06413\n",
      "[6846]\teval-rmse:3.9551\ttrain-rmse:2.0641\n",
      "[6847]\teval-rmse:3.95691\ttrain-rmse:2.0641\n",
      "[6848]\teval-rmse:3.95552\ttrain-rmse:2.06413\n",
      "[6849]\teval-rmse:3.9549\ttrain-rmse:2.06414\n",
      "[6850]\teval-rmse:3.95256\ttrain-rmse:2.06415\n",
      "[6851]\teval-rmse:3.95199\ttrain-rmse:2.06416\n",
      "[6852]\teval-rmse:3.95335\ttrain-rmse:2.06414\n",
      "[6853]\teval-rmse:3.95245\ttrain-rmse:2.06409\n",
      "[6854]\teval-rmse:3.95096\ttrain-rmse:2.06413\n",
      "[6855]\teval-rmse:3.9502\ttrain-rmse:2.06418\n",
      "[6856]\teval-rmse:3.94801\ttrain-rmse:2.06422\n",
      "[6857]\teval-rmse:3.9496\ttrain-rmse:2.06417\n",
      "[6858]\teval-rmse:3.95192\ttrain-rmse:2.06401\n",
      "[6859]\teval-rmse:3.95192\ttrain-rmse:2.06401\n",
      "[6860]\teval-rmse:3.95253\ttrain-rmse:2.064\n",
      "[6861]\teval-rmse:3.95315\ttrain-rmse:2.06399\n",
      "[6862]\teval-rmse:3.95473\ttrain-rmse:2.06395\n",
      "[6863]\teval-rmse:3.95268\ttrain-rmse:2.06398\n",
      "[6864]\teval-rmse:3.95043\ttrain-rmse:2.06404\n",
      "[6865]\teval-rmse:3.94855\ttrain-rmse:2.06408\n",
      "[6866]\teval-rmse:3.94843\ttrain-rmse:2.06409\n",
      "[6867]\teval-rmse:3.94744\ttrain-rmse:2.06415\n",
      "[6868]\teval-rmse:3.94874\ttrain-rmse:2.06412\n",
      "[6869]\teval-rmse:3.94793\ttrain-rmse:2.06361\n",
      "[6870]\teval-rmse:3.94612\ttrain-rmse:2.06368\n",
      "[6871]\teval-rmse:3.9472\ttrain-rmse:2.06364\n",
      "[6872]\teval-rmse:3.94932\ttrain-rmse:2.06359\n",
      "[6873]\teval-rmse:3.94859\ttrain-rmse:2.06364\n",
      "[6874]\teval-rmse:3.9467\ttrain-rmse:2.06374\n",
      "[6875]\teval-rmse:3.9459\ttrain-rmse:2.06338\n",
      "[6876]\teval-rmse:3.94631\ttrain-rmse:2.06337\n",
      "[6877]\teval-rmse:3.94781\ttrain-rmse:2.06333\n",
      "[6878]\teval-rmse:3.94682\ttrain-rmse:2.06337\n",
      "[6879]\teval-rmse:3.9465\ttrain-rmse:2.06337\n",
      "[6880]\teval-rmse:3.94473\ttrain-rmse:2.06348\n",
      "[6881]\teval-rmse:3.94353\ttrain-rmse:2.06344\n",
      "[6882]\teval-rmse:3.94233\ttrain-rmse:2.06348\n",
      "[6883]\teval-rmse:3.94206\ttrain-rmse:2.06349\n",
      "[6884]\teval-rmse:3.94423\ttrain-rmse:2.0634\n",
      "[6885]\teval-rmse:3.9447\ttrain-rmse:2.06339\n",
      "[6886]\teval-rmse:3.94372\ttrain-rmse:2.06345\n",
      "[6887]\teval-rmse:3.9416\ttrain-rmse:2.0635\n",
      "[6888]\teval-rmse:3.94305\ttrain-rmse:2.06339\n",
      "[6889]\teval-rmse:3.9409\ttrain-rmse:2.06347\n",
      "[6890]\teval-rmse:3.94086\ttrain-rmse:2.06347\n",
      "[6891]\teval-rmse:3.94189\ttrain-rmse:2.06342\n",
      "[6892]\teval-rmse:3.94334\ttrain-rmse:2.06331\n",
      "[6893]\teval-rmse:3.94441\ttrain-rmse:2.06327\n",
      "[6894]\teval-rmse:3.94538\ttrain-rmse:2.06325\n",
      "[6895]\teval-rmse:3.94757\ttrain-rmse:2.06332\n",
      "[6896]\teval-rmse:3.94593\ttrain-rmse:2.06343\n",
      "[6897]\teval-rmse:3.94657\ttrain-rmse:2.06341\n",
      "[6898]\teval-rmse:3.94538\ttrain-rmse:2.06345\n",
      "[6899]\teval-rmse:3.94452\ttrain-rmse:2.06344\n",
      "[6900]\teval-rmse:3.94595\ttrain-rmse:2.06334\n",
      "[6901]\teval-rmse:3.9453\ttrain-rmse:2.06338\n",
      "[6902]\teval-rmse:3.94611\ttrain-rmse:2.06336\n",
      "[6903]\teval-rmse:3.94474\ttrain-rmse:2.0634\n",
      "[6904]\teval-rmse:3.94337\ttrain-rmse:2.06344\n",
      "[6905]\teval-rmse:3.944\ttrain-rmse:2.06342\n",
      "[6906]\teval-rmse:3.942\ttrain-rmse:2.06355\n",
      "[6907]\teval-rmse:3.94217\ttrain-rmse:2.06354\n",
      "[6908]\teval-rmse:3.94227\ttrain-rmse:2.06354\n",
      "[6909]\teval-rmse:3.94276\ttrain-rmse:2.06352\n",
      "[6910]\teval-rmse:3.94507\ttrain-rmse:2.06347\n",
      "[6911]\teval-rmse:3.94421\ttrain-rmse:2.06299\n",
      "[6912]\teval-rmse:3.94342\ttrain-rmse:2.06261\n",
      "[6913]\teval-rmse:3.94467\ttrain-rmse:2.06258\n",
      "[6914]\teval-rmse:3.94546\ttrain-rmse:2.06257\n",
      "[6915]\teval-rmse:3.9472\ttrain-rmse:2.06251\n",
      "[6916]\teval-rmse:3.94633\ttrain-rmse:2.06204\n",
      "[6917]\teval-rmse:3.94401\ttrain-rmse:2.06207\n",
      "[6918]\teval-rmse:3.94438\ttrain-rmse:2.06207\n",
      "[6919]\teval-rmse:3.94555\ttrain-rmse:2.06204\n",
      "[6920]\teval-rmse:3.94787\ttrain-rmse:2.06188\n",
      "[6921]\teval-rmse:3.94704\ttrain-rmse:2.0619\n",
      "[6922]\teval-rmse:3.94531\ttrain-rmse:2.06193\n",
      "[6923]\teval-rmse:3.94544\ttrain-rmse:2.06193\n",
      "[6924]\teval-rmse:3.94635\ttrain-rmse:2.06191\n",
      "[6925]\teval-rmse:3.94547\ttrain-rmse:2.06187\n",
      "[6926]\teval-rmse:3.94467\ttrain-rmse:2.0619\n",
      "[6927]\teval-rmse:3.94712\ttrain-rmse:2.06182\n",
      "[6928]\teval-rmse:3.94747\ttrain-rmse:2.06182\n",
      "[6929]\teval-rmse:3.94631\ttrain-rmse:2.06185\n",
      "[6930]\teval-rmse:3.94763\ttrain-rmse:2.06181\n",
      "[6931]\teval-rmse:3.94755\ttrain-rmse:2.06181\n",
      "[6932]\teval-rmse:3.94934\ttrain-rmse:2.06169\n",
      "[6933]\teval-rmse:3.95063\ttrain-rmse:2.06166\n",
      "[6934]\teval-rmse:3.9494\ttrain-rmse:2.06162\n",
      "[6935]\teval-rmse:3.9512\ttrain-rmse:2.06159\n",
      "[6936]\teval-rmse:3.95086\ttrain-rmse:2.06159\n",
      "[6937]\teval-rmse:3.9522\ttrain-rmse:2.06159\n",
      "[6938]\teval-rmse:3.95231\ttrain-rmse:2.06158\n",
      "[6939]\teval-rmse:3.95384\ttrain-rmse:2.06151\n",
      "[6940]\teval-rmse:3.95196\ttrain-rmse:2.06154\n",
      "[6941]\teval-rmse:3.94971\ttrain-rmse:2.06155\n",
      "[6942]\teval-rmse:3.94876\ttrain-rmse:2.06157\n",
      "[6943]\teval-rmse:3.9478\ttrain-rmse:2.06157\n",
      "[6944]\teval-rmse:3.94648\ttrain-rmse:2.06161\n",
      "[6945]\teval-rmse:3.94767\ttrain-rmse:2.06154\n",
      "[6946]\teval-rmse:3.94909\ttrain-rmse:2.06144\n",
      "[6947]\teval-rmse:3.94835\ttrain-rmse:2.06146\n",
      "[6948]\teval-rmse:3.9475\ttrain-rmse:2.06141\n",
      "[6949]\teval-rmse:3.94719\ttrain-rmse:2.06141\n",
      "[6950]\teval-rmse:3.94742\ttrain-rmse:2.06141\n",
      "[6951]\teval-rmse:3.94929\ttrain-rmse:2.06136\n",
      "[6952]\teval-rmse:3.94809\ttrain-rmse:2.06137\n",
      "[6953]\teval-rmse:3.94648\ttrain-rmse:2.06146\n",
      "[6954]\teval-rmse:3.94553\ttrain-rmse:2.06148\n",
      "[6955]\teval-rmse:3.94618\ttrain-rmse:2.06147\n",
      "[6956]\teval-rmse:3.94669\ttrain-rmse:2.06146\n",
      "[6957]\teval-rmse:3.94751\ttrain-rmse:2.06145\n",
      "[6958]\teval-rmse:3.94629\ttrain-rmse:2.06141\n",
      "[6959]\teval-rmse:3.94541\ttrain-rmse:2.06139\n",
      "[6960]\teval-rmse:3.94359\ttrain-rmse:2.06145\n",
      "[6961]\teval-rmse:3.94459\ttrain-rmse:2.06141\n",
      "[6962]\teval-rmse:3.9431\ttrain-rmse:2.06146\n",
      "[6963]\teval-rmse:3.94406\ttrain-rmse:2.06143\n",
      "[6964]\teval-rmse:3.945\ttrain-rmse:2.06141\n",
      "[6965]\teval-rmse:3.94289\ttrain-rmse:2.06146\n",
      "[6966]\teval-rmse:3.94205\ttrain-rmse:2.06142\n",
      "[6967]\teval-rmse:3.94349\ttrain-rmse:2.06139\n",
      "[6968]\teval-rmse:3.94469\ttrain-rmse:2.06135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6969]\teval-rmse:3.94496\ttrain-rmse:2.06134\n",
      "[6970]\teval-rmse:3.94416\ttrain-rmse:2.06097\n",
      "[6971]\teval-rmse:3.94319\ttrain-rmse:2.06097\n",
      "[6972]\teval-rmse:3.94382\ttrain-rmse:2.06093\n",
      "[6973]\teval-rmse:3.94296\ttrain-rmse:2.06047\n",
      "[6974]\teval-rmse:3.94119\ttrain-rmse:2.06053\n",
      "[6975]\teval-rmse:3.94038\ttrain-rmse:2.0605\n",
      "[6976]\teval-rmse:3.94192\ttrain-rmse:2.0604\n",
      "[6977]\teval-rmse:3.94071\ttrain-rmse:2.06035\n",
      "[6978]\teval-rmse:3.93884\ttrain-rmse:2.06042\n",
      "[6979]\teval-rmse:3.93802\ttrain-rmse:2.06001\n",
      "[6980]\teval-rmse:3.93685\ttrain-rmse:2.06006\n",
      "[6981]\teval-rmse:3.93578\ttrain-rmse:2.06011\n",
      "[6982]\teval-rmse:3.93647\ttrain-rmse:2.06008\n",
      "[6983]\teval-rmse:3.936\ttrain-rmse:2.0601\n",
      "[6984]\teval-rmse:3.9374\ttrain-rmse:2.05999\n",
      "[6985]\teval-rmse:3.93644\ttrain-rmse:2.06006\n",
      "[6986]\teval-rmse:3.9374\ttrain-rmse:2.06005\n",
      "[6987]\teval-rmse:3.93937\ttrain-rmse:2.05997\n",
      "[6988]\teval-rmse:3.93996\ttrain-rmse:2.05994\n",
      "[6989]\teval-rmse:3.94237\ttrain-rmse:2.05979\n",
      "[6990]\teval-rmse:3.93998\ttrain-rmse:2.05983\n",
      "[6991]\teval-rmse:3.94037\ttrain-rmse:2.05982\n",
      "[6992]\teval-rmse:3.93906\ttrain-rmse:2.05985\n",
      "[6993]\teval-rmse:3.93912\ttrain-rmse:2.05985\n",
      "[6994]\teval-rmse:3.938\ttrain-rmse:2.05991\n",
      "[6995]\teval-rmse:3.93699\ttrain-rmse:2.05995\n",
      "[6996]\teval-rmse:3.93477\ttrain-rmse:2.06003\n",
      "[6997]\teval-rmse:3.93219\ttrain-rmse:2.0601\n",
      "[6998]\teval-rmse:3.93031\ttrain-rmse:2.06019\n",
      "[6999]\teval-rmse:3.93005\ttrain-rmse:2.06017\n",
      "[7000]\teval-rmse:3.93072\ttrain-rmse:2.06013\n",
      "[7001]\teval-rmse:3.92909\ttrain-rmse:2.06022\n",
      "[7002]\teval-rmse:3.92925\ttrain-rmse:2.0602\n",
      "[7003]\teval-rmse:3.93167\ttrain-rmse:2.05999\n",
      "[7004]\teval-rmse:3.93143\ttrain-rmse:2.05997\n",
      "[7005]\teval-rmse:3.93114\ttrain-rmse:2.05997\n",
      "[7006]\teval-rmse:3.93296\ttrain-rmse:2.05981\n",
      "[7007]\teval-rmse:3.93309\ttrain-rmse:2.0598\n",
      "[7008]\teval-rmse:3.93418\ttrain-rmse:2.05975\n",
      "[7009]\teval-rmse:3.93516\ttrain-rmse:2.05971\n",
      "[7010]\teval-rmse:3.9367\ttrain-rmse:2.05966\n",
      "[7011]\teval-rmse:3.93643\ttrain-rmse:2.05967\n",
      "[7012]\teval-rmse:3.93743\ttrain-rmse:2.05963\n",
      "[7013]\teval-rmse:3.9375\ttrain-rmse:2.05962\n",
      "[7014]\teval-rmse:3.93756\ttrain-rmse:2.05962\n",
      "[7015]\teval-rmse:3.93687\ttrain-rmse:2.05967\n",
      "[7016]\teval-rmse:3.93583\ttrain-rmse:2.05972\n",
      "[7017]\teval-rmse:3.93515\ttrain-rmse:2.05925\n",
      "[7018]\teval-rmse:3.93734\ttrain-rmse:2.0593\n",
      "[7019]\teval-rmse:3.93585\ttrain-rmse:2.05937\n",
      "[7020]\teval-rmse:3.93659\ttrain-rmse:2.05933\n",
      "[7021]\teval-rmse:3.93841\ttrain-rmse:2.05918\n",
      "[7022]\teval-rmse:3.93832\ttrain-rmse:2.05919\n",
      "[7023]\teval-rmse:3.93974\ttrain-rmse:2.05907\n",
      "[7024]\teval-rmse:3.93818\ttrain-rmse:2.05911\n",
      "[7025]\teval-rmse:3.93763\ttrain-rmse:2.05913\n",
      "[7026]\teval-rmse:3.93627\ttrain-rmse:2.05919\n",
      "[7027]\teval-rmse:3.93515\ttrain-rmse:2.05924\n",
      "[7028]\teval-rmse:3.93508\ttrain-rmse:2.05925\n",
      "[7029]\teval-rmse:3.93412\ttrain-rmse:2.05931\n",
      "[7030]\teval-rmse:3.93654\ttrain-rmse:2.05919\n",
      "[7031]\teval-rmse:3.93582\ttrain-rmse:2.05925\n",
      "[7032]\teval-rmse:3.93344\ttrain-rmse:2.05934\n",
      "[7033]\teval-rmse:3.93275\ttrain-rmse:2.05938\n",
      "[7034]\teval-rmse:3.93297\ttrain-rmse:2.05937\n",
      "[7035]\teval-rmse:3.934\ttrain-rmse:2.05932\n",
      "[7036]\teval-rmse:3.93263\ttrain-rmse:2.05939\n",
      "[7037]\teval-rmse:3.93478\ttrain-rmse:2.05921\n",
      "[7038]\teval-rmse:3.93504\ttrain-rmse:2.0592\n",
      "[7039]\teval-rmse:3.93535\ttrain-rmse:2.05919\n",
      "[7040]\teval-rmse:3.9329\ttrain-rmse:2.0593\n",
      "[7041]\teval-rmse:3.93455\ttrain-rmse:2.05921\n",
      "[7042]\teval-rmse:3.93219\ttrain-rmse:2.05933\n",
      "[7043]\teval-rmse:3.93127\ttrain-rmse:2.0594\n",
      "[7044]\teval-rmse:3.93035\ttrain-rmse:2.05948\n",
      "[7045]\teval-rmse:3.93022\ttrain-rmse:2.05948\n",
      "[7046]\teval-rmse:3.9293\ttrain-rmse:2.05954\n",
      "[7047]\teval-rmse:3.93042\ttrain-rmse:2.05948\n",
      "[7048]\teval-rmse:3.92874\ttrain-rmse:2.05961\n",
      "[7049]\teval-rmse:3.92827\ttrain-rmse:2.05964\n",
      "[7050]\teval-rmse:3.92896\ttrain-rmse:2.05958\n",
      "[7051]\teval-rmse:3.93079\ttrain-rmse:2.05947\n",
      "[7052]\teval-rmse:3.92902\ttrain-rmse:2.05957\n",
      "[7053]\teval-rmse:3.92826\ttrain-rmse:2.05958\n",
      "[7054]\teval-rmse:3.92731\ttrain-rmse:2.05965\n",
      "[7055]\teval-rmse:3.92795\ttrain-rmse:2.05961\n",
      "[7056]\teval-rmse:3.92939\ttrain-rmse:2.05952\n",
      "[7057]\teval-rmse:3.92741\ttrain-rmse:2.05965\n",
      "[7058]\teval-rmse:3.92749\ttrain-rmse:2.05964\n",
      "[7059]\teval-rmse:3.92874\ttrain-rmse:2.05956\n",
      "[7060]\teval-rmse:3.93038\ttrain-rmse:2.05942\n",
      "[7061]\teval-rmse:3.93022\ttrain-rmse:2.05943\n",
      "[7062]\teval-rmse:3.92905\ttrain-rmse:2.05942\n",
      "[7063]\teval-rmse:3.92751\ttrain-rmse:2.05951\n",
      "[7064]\teval-rmse:3.92754\ttrain-rmse:2.05951\n",
      "[7065]\teval-rmse:3.9263\ttrain-rmse:2.05959\n",
      "[7066]\teval-rmse:3.92476\ttrain-rmse:2.0597\n",
      "[7067]\teval-rmse:3.92578\ttrain-rmse:2.05964\n",
      "[7068]\teval-rmse:3.92608\ttrain-rmse:2.05962\n",
      "[7069]\teval-rmse:3.92541\ttrain-rmse:2.05968\n",
      "[7070]\teval-rmse:3.92536\ttrain-rmse:2.05968\n",
      "[7071]\teval-rmse:3.9251\ttrain-rmse:2.05965\n",
      "[7072]\teval-rmse:3.92625\ttrain-rmse:2.05957\n",
      "[7073]\teval-rmse:3.9246\ttrain-rmse:2.05967\n",
      "[7074]\teval-rmse:3.92368\ttrain-rmse:2.05974\n",
      "[7075]\teval-rmse:3.92443\ttrain-rmse:2.05968\n",
      "[7076]\teval-rmse:3.92375\ttrain-rmse:2.05973\n",
      "[7077]\teval-rmse:3.92461\ttrain-rmse:2.05967\n",
      "[7078]\teval-rmse:3.92455\ttrain-rmse:2.05968\n",
      "[7079]\teval-rmse:3.92379\ttrain-rmse:2.05929\n",
      "[7080]\teval-rmse:3.9215\ttrain-rmse:2.05946\n",
      "[7081]\teval-rmse:3.9204\ttrain-rmse:2.05943\n",
      "[7082]\teval-rmse:3.92188\ttrain-rmse:2.05933\n",
      "[7083]\teval-rmse:3.92199\ttrain-rmse:2.05933\n",
      "[7084]\teval-rmse:3.92231\ttrain-rmse:2.05931\n",
      "[7085]\teval-rmse:3.921\ttrain-rmse:2.0594\n",
      "[7086]\teval-rmse:3.91912\ttrain-rmse:2.05953\n",
      "[7087]\teval-rmse:3.91981\ttrain-rmse:2.05949\n",
      "[7088]\teval-rmse:3.91881\ttrain-rmse:2.05957\n",
      "[7089]\teval-rmse:3.92128\ttrain-rmse:2.0593\n",
      "[7090]\teval-rmse:3.91913\ttrain-rmse:2.05947\n",
      "[7091]\teval-rmse:3.91796\ttrain-rmse:2.05957\n",
      "[7092]\teval-rmse:3.91639\ttrain-rmse:2.0597\n",
      "[7093]\teval-rmse:3.91412\ttrain-rmse:2.05994\n",
      "[7094]\teval-rmse:3.91293\ttrain-rmse:2.06005\n",
      "[7095]\teval-rmse:3.91296\ttrain-rmse:2.06005\n",
      "[7096]\teval-rmse:3.91481\ttrain-rmse:2.05983\n",
      "[7097]\teval-rmse:3.91492\ttrain-rmse:2.05982\n",
      "[7098]\teval-rmse:3.91311\ttrain-rmse:2.06\n",
      "[7099]\teval-rmse:3.91227\ttrain-rmse:2.0601\n",
      "[7100]\teval-rmse:3.91364\ttrain-rmse:2.05997\n",
      "[7101]\teval-rmse:3.91292\ttrain-rmse:2.05997\n",
      "[7102]\teval-rmse:3.91408\ttrain-rmse:2.05987\n",
      "[7103]\teval-rmse:3.9152\ttrain-rmse:2.05976\n",
      "[7104]\teval-rmse:3.91451\ttrain-rmse:2.05974\n",
      "[7105]\teval-rmse:3.91221\ttrain-rmse:2.05997\n",
      "[7106]\teval-rmse:3.91138\ttrain-rmse:2.06005\n",
      "[7107]\teval-rmse:3.91033\ttrain-rmse:2.06004\n",
      "[7108]\teval-rmse:3.91115\ttrain-rmse:2.05995\n",
      "[7109]\teval-rmse:3.91009\ttrain-rmse:2.05998\n",
      "[7110]\teval-rmse:3.91053\ttrain-rmse:2.05993\n",
      "[7111]\teval-rmse:3.90909\ttrain-rmse:2.06011\n",
      "[7112]\teval-rmse:3.91059\ttrain-rmse:2.05996\n",
      "[7113]\teval-rmse:3.90988\ttrain-rmse:2.05998\n",
      "[7114]\teval-rmse:3.90973\ttrain-rmse:2.05996\n",
      "[7115]\teval-rmse:3.91217\ttrain-rmse:2.05971\n",
      "[7116]\teval-rmse:3.91434\ttrain-rmse:2.05951\n",
      "[7117]\teval-rmse:3.91596\ttrain-rmse:2.05937\n",
      "[7118]\teval-rmse:3.91476\ttrain-rmse:2.05947\n",
      "[7119]\teval-rmse:3.91587\ttrain-rmse:2.05935\n",
      "[7120]\teval-rmse:3.91773\ttrain-rmse:2.05918\n",
      "[7121]\teval-rmse:3.91837\ttrain-rmse:2.05914\n",
      "[7122]\teval-rmse:3.92009\ttrain-rmse:2.05902\n",
      "[7123]\teval-rmse:3.92223\ttrain-rmse:2.05879\n",
      "[7124]\teval-rmse:3.9216\ttrain-rmse:2.05886\n",
      "[7125]\teval-rmse:3.92192\ttrain-rmse:2.05884\n",
      "[7126]\teval-rmse:3.92094\ttrain-rmse:2.05894\n",
      "[7127]\teval-rmse:3.92223\ttrain-rmse:2.05886\n",
      "[7128]\teval-rmse:3.92116\ttrain-rmse:2.05885\n",
      "[7129]\teval-rmse:3.92105\ttrain-rmse:2.05886\n",
      "[7130]\teval-rmse:3.91998\ttrain-rmse:2.05894\n",
      "[7131]\teval-rmse:3.92213\ttrain-rmse:2.05873\n",
      "[7132]\teval-rmse:3.92186\ttrain-rmse:2.05875\n",
      "[7133]\teval-rmse:3.92054\ttrain-rmse:2.05884\n",
      "[7134]\teval-rmse:3.92173\ttrain-rmse:2.05877\n",
      "[7135]\teval-rmse:3.92119\ttrain-rmse:2.05882\n",
      "[7136]\teval-rmse:3.9197\ttrain-rmse:2.05897\n",
      "[7137]\teval-rmse:3.91786\ttrain-rmse:2.05916\n",
      "[7138]\teval-rmse:3.91804\ttrain-rmse:2.05914\n",
      "[7139]\teval-rmse:3.91554\ttrain-rmse:2.05933\n",
      "[7140]\teval-rmse:3.91572\ttrain-rmse:2.0593\n",
      "[7141]\teval-rmse:3.91551\ttrain-rmse:2.05931\n",
      "[7142]\teval-rmse:3.91513\ttrain-rmse:2.05934\n",
      "[7143]\teval-rmse:3.91738\ttrain-rmse:2.05932\n",
      "[7144]\teval-rmse:3.91828\ttrain-rmse:2.05925\n",
      "[7145]\teval-rmse:3.9206\ttrain-rmse:2.05907\n",
      "[7146]\teval-rmse:3.91908\ttrain-rmse:2.05917\n",
      "[7147]\teval-rmse:3.91856\ttrain-rmse:2.05921\n",
      "[7148]\teval-rmse:3.92039\ttrain-rmse:2.05907\n",
      "[7149]\teval-rmse:3.92019\ttrain-rmse:2.05905\n",
      "[7150]\teval-rmse:3.92125\ttrain-rmse:2.05898\n",
      "[7151]\teval-rmse:3.92138\ttrain-rmse:2.05897\n",
      "[7152]\teval-rmse:3.9237\ttrain-rmse:2.0588\n",
      "[7153]\teval-rmse:3.92277\ttrain-rmse:2.05888\n",
      "[7154]\teval-rmse:3.92347\ttrain-rmse:2.05884\n",
      "[7155]\teval-rmse:3.92238\ttrain-rmse:2.05882\n",
      "[7156]\teval-rmse:3.92238\ttrain-rmse:2.05882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7157]\teval-rmse:3.92213\ttrain-rmse:2.05881\n",
      "[7158]\teval-rmse:3.92146\ttrain-rmse:2.05885\n",
      "[7159]\teval-rmse:3.92294\ttrain-rmse:2.05876\n",
      "[7160]\teval-rmse:3.92417\ttrain-rmse:2.05868\n",
      "[7161]\teval-rmse:3.92393\ttrain-rmse:2.05867\n",
      "[7162]\teval-rmse:3.92516\ttrain-rmse:2.05859\n",
      "[7163]\teval-rmse:3.92449\ttrain-rmse:2.05814\n",
      "[7164]\teval-rmse:3.9265\ttrain-rmse:2.05802\n",
      "[7165]\teval-rmse:3.92574\ttrain-rmse:2.05758\n",
      "[7166]\teval-rmse:3.92517\ttrain-rmse:2.05763\n",
      "[7167]\teval-rmse:3.92389\ttrain-rmse:2.05768\n",
      "[7168]\teval-rmse:3.92596\ttrain-rmse:2.05756\n",
      "[7169]\teval-rmse:3.92421\ttrain-rmse:2.05765\n",
      "[7170]\teval-rmse:3.92345\ttrain-rmse:2.05763\n",
      "[7171]\teval-rmse:3.92253\ttrain-rmse:2.05769\n",
      "[7172]\teval-rmse:3.92055\ttrain-rmse:2.05782\n",
      "[7173]\teval-rmse:3.92198\ttrain-rmse:2.05773\n",
      "[7174]\teval-rmse:3.92157\ttrain-rmse:2.05776\n",
      "[7175]\teval-rmse:3.9232\ttrain-rmse:2.05768\n",
      "[7176]\teval-rmse:3.92501\ttrain-rmse:2.05753\n",
      "[7177]\teval-rmse:3.92359\ttrain-rmse:2.05764\n",
      "[7178]\teval-rmse:3.9238\ttrain-rmse:2.05763\n",
      "[7179]\teval-rmse:3.926\ttrain-rmse:2.05764\n",
      "[7180]\teval-rmse:3.92459\ttrain-rmse:2.05772\n",
      "[7181]\teval-rmse:3.92349\ttrain-rmse:2.05778\n",
      "[7182]\teval-rmse:3.92188\ttrain-rmse:2.05788\n",
      "[7183]\teval-rmse:3.92217\ttrain-rmse:2.05787\n",
      "[7184]\teval-rmse:3.92205\ttrain-rmse:2.05787\n",
      "[7185]\teval-rmse:3.92034\ttrain-rmse:2.05799\n",
      "[7186]\teval-rmse:3.91836\ttrain-rmse:2.0581\n",
      "[7187]\teval-rmse:3.92068\ttrain-rmse:2.05786\n",
      "[7188]\teval-rmse:3.92233\ttrain-rmse:2.05771\n",
      "[7189]\teval-rmse:3.92064\ttrain-rmse:2.05785\n",
      "[7190]\teval-rmse:3.92009\ttrain-rmse:2.05791\n",
      "[7191]\teval-rmse:3.92063\ttrain-rmse:2.05788\n",
      "[7192]\teval-rmse:3.92158\ttrain-rmse:2.05782\n",
      "[7193]\teval-rmse:3.92256\ttrain-rmse:2.05776\n",
      "[7194]\teval-rmse:3.92351\ttrain-rmse:2.0577\n",
      "[7195]\teval-rmse:3.92546\ttrain-rmse:2.0576\n",
      "[7196]\teval-rmse:3.92534\ttrain-rmse:2.05761\n",
      "[7197]\teval-rmse:3.92323\ttrain-rmse:2.05773\n",
      "[7198]\teval-rmse:3.92351\ttrain-rmse:2.05771\n",
      "[7199]\teval-rmse:3.92562\ttrain-rmse:2.05751\n",
      "[7200]\teval-rmse:3.92434\ttrain-rmse:2.05757\n",
      "[7201]\teval-rmse:3.92357\ttrain-rmse:2.05755\n",
      "[7202]\teval-rmse:3.92472\ttrain-rmse:2.05748\n",
      "[7203]\teval-rmse:3.92664\ttrain-rmse:2.05732\n",
      "[7204]\teval-rmse:3.92607\ttrain-rmse:2.05737\n",
      "[7205]\teval-rmse:3.92771\ttrain-rmse:2.05728\n",
      "[7206]\teval-rmse:3.92755\ttrain-rmse:2.05729\n",
      "[7207]\teval-rmse:3.92934\ttrain-rmse:2.05715\n",
      "[7208]\teval-rmse:3.92833\ttrain-rmse:2.0572\n",
      "[7209]\teval-rmse:3.92839\ttrain-rmse:2.0572\n",
      "[7210]\teval-rmse:3.92943\ttrain-rmse:2.05711\n",
      "[7211]\teval-rmse:3.92829\ttrain-rmse:2.05708\n",
      "[7212]\teval-rmse:3.93041\ttrain-rmse:2.05698\n",
      "[7213]\teval-rmse:3.92991\ttrain-rmse:2.057\n",
      "[7214]\teval-rmse:3.92858\ttrain-rmse:2.0571\n",
      "[7215]\teval-rmse:3.9279\ttrain-rmse:2.05713\n",
      "[7216]\teval-rmse:3.92894\ttrain-rmse:2.05708\n",
      "[7217]\teval-rmse:3.92906\ttrain-rmse:2.05708\n",
      "[7218]\teval-rmse:3.92793\ttrain-rmse:2.05713\n",
      "[7219]\teval-rmse:3.92704\ttrain-rmse:2.05717\n",
      "[7220]\teval-rmse:3.92853\ttrain-rmse:2.0571\n",
      "[7221]\teval-rmse:3.9272\ttrain-rmse:2.05717\n",
      "[7222]\teval-rmse:3.92723\ttrain-rmse:2.05716\n",
      "[7223]\teval-rmse:3.92918\ttrain-rmse:2.05709\n",
      "[7224]\teval-rmse:3.93148\ttrain-rmse:2.05689\n",
      "[7225]\teval-rmse:3.93161\ttrain-rmse:2.05689\n",
      "[7226]\teval-rmse:3.93082\ttrain-rmse:2.05687\n",
      "[7227]\teval-rmse:3.93085\ttrain-rmse:2.05687\n",
      "[7228]\teval-rmse:3.92927\ttrain-rmse:2.05694\n",
      "[7229]\teval-rmse:3.93037\ttrain-rmse:2.0569\n",
      "[7230]\teval-rmse:3.93076\ttrain-rmse:2.05689\n",
      "[7231]\teval-rmse:3.93286\ttrain-rmse:2.05674\n",
      "[7232]\teval-rmse:3.9327\ttrain-rmse:2.05674\n",
      "[7233]\teval-rmse:3.93397\ttrain-rmse:2.05669\n",
      "[7234]\teval-rmse:3.93159\ttrain-rmse:2.05676\n",
      "[7235]\teval-rmse:3.93122\ttrain-rmse:2.05678\n",
      "[7236]\teval-rmse:3.93189\ttrain-rmse:2.05675\n",
      "[7237]\teval-rmse:3.93196\ttrain-rmse:2.05674\n",
      "[7238]\teval-rmse:3.93264\ttrain-rmse:2.05672\n",
      "[7239]\teval-rmse:3.93057\ttrain-rmse:2.05681\n",
      "[7240]\teval-rmse:3.92945\ttrain-rmse:2.05678\n",
      "[7241]\teval-rmse:3.92819\ttrain-rmse:2.05684\n",
      "[7242]\teval-rmse:3.92743\ttrain-rmse:2.05681\n",
      "[7243]\teval-rmse:3.92946\ttrain-rmse:2.05666\n",
      "[7244]\teval-rmse:3.93127\ttrain-rmse:2.05651\n",
      "[7245]\teval-rmse:3.93013\ttrain-rmse:2.05647\n",
      "[7246]\teval-rmse:3.93212\ttrain-rmse:2.05639\n",
      "[7247]\teval-rmse:3.93185\ttrain-rmse:2.05637\n",
      "[7248]\teval-rmse:3.93306\ttrain-rmse:2.05634\n",
      "[7249]\teval-rmse:3.93356\ttrain-rmse:2.05633\n",
      "[7250]\teval-rmse:3.9322\ttrain-rmse:2.05641\n",
      "[7251]\teval-rmse:3.93119\ttrain-rmse:2.05644\n",
      "[7252]\teval-rmse:3.93104\ttrain-rmse:2.05642\n",
      "[7253]\teval-rmse:3.93308\ttrain-rmse:2.05629\n",
      "[7254]\teval-rmse:3.9354\ttrain-rmse:2.05612\n",
      "[7255]\teval-rmse:3.93333\ttrain-rmse:2.05616\n",
      "[7256]\teval-rmse:3.93453\ttrain-rmse:2.05611\n",
      "[7257]\teval-rmse:3.93441\ttrain-rmse:2.05612\n",
      "[7258]\teval-rmse:3.93683\ttrain-rmse:2.05598\n",
      "[7259]\teval-rmse:3.93534\ttrain-rmse:2.05603\n",
      "[7260]\teval-rmse:3.93698\ttrain-rmse:2.056\n",
      "[7261]\teval-rmse:3.93635\ttrain-rmse:2.05604\n",
      "[7262]\teval-rmse:3.93408\ttrain-rmse:2.05612\n",
      "[7263]\teval-rmse:3.93587\ttrain-rmse:2.05598\n",
      "[7264]\teval-rmse:3.93792\ttrain-rmse:2.05592\n",
      "[7265]\teval-rmse:3.93682\ttrain-rmse:2.05597\n",
      "[7266]\teval-rmse:3.93525\ttrain-rmse:2.05602\n",
      "[7267]\teval-rmse:3.93558\ttrain-rmse:2.05601\n",
      "[7268]\teval-rmse:3.93768\ttrain-rmse:2.05594\n",
      "[7269]\teval-rmse:3.93647\ttrain-rmse:2.05591\n",
      "[7270]\teval-rmse:3.93549\ttrain-rmse:2.05594\n",
      "[7271]\teval-rmse:3.93472\ttrain-rmse:2.05591\n",
      "[7272]\teval-rmse:3.93671\ttrain-rmse:2.05584\n",
      "[7273]\teval-rmse:3.93699\ttrain-rmse:2.05584\n",
      "[7274]\teval-rmse:3.9357\ttrain-rmse:2.05588\n",
      "[7275]\teval-rmse:3.93792\ttrain-rmse:2.05593\n",
      "[7276]\teval-rmse:3.93834\ttrain-rmse:2.05592\n",
      "[7277]\teval-rmse:3.94011\ttrain-rmse:2.05587\n",
      "[7278]\teval-rmse:3.94163\ttrain-rmse:2.05583\n",
      "[7279]\teval-rmse:3.93948\ttrain-rmse:2.05587\n",
      "[7280]\teval-rmse:3.93982\ttrain-rmse:2.05586\n",
      "[7281]\teval-rmse:3.93731\ttrain-rmse:2.0559\n",
      "[7282]\teval-rmse:3.9365\ttrain-rmse:2.05587\n",
      "[7283]\teval-rmse:3.93717\ttrain-rmse:2.05586\n",
      "[7284]\teval-rmse:3.93781\ttrain-rmse:2.05584\n",
      "[7285]\teval-rmse:3.93829\ttrain-rmse:2.05582\n",
      "[7286]\teval-rmse:3.9386\ttrain-rmse:2.05582\n",
      "[7287]\teval-rmse:3.9392\ttrain-rmse:2.0558\n",
      "[7288]\teval-rmse:3.93992\ttrain-rmse:2.05579\n",
      "[7289]\teval-rmse:3.94062\ttrain-rmse:2.05577\n",
      "[7290]\teval-rmse:3.94272\ttrain-rmse:2.05573\n",
      "[7291]\teval-rmse:3.94349\ttrain-rmse:2.05573\n",
      "[7292]\teval-rmse:3.94264\ttrain-rmse:2.05571\n",
      "[7293]\teval-rmse:3.94083\ttrain-rmse:2.05579\n",
      "[7294]\teval-rmse:3.93961\ttrain-rmse:2.05576\n",
      "[7295]\teval-rmse:3.93721\ttrain-rmse:2.0558\n",
      "[7296]\teval-rmse:3.93607\ttrain-rmse:2.05583\n",
      "[7297]\teval-rmse:3.93519\ttrain-rmse:2.05586\n",
      "[7298]\teval-rmse:3.93399\ttrain-rmse:2.0559\n",
      "[7299]\teval-rmse:3.93464\ttrain-rmse:2.05588\n",
      "[7300]\teval-rmse:3.93547\ttrain-rmse:2.05585\n",
      "[7301]\teval-rmse:3.93678\ttrain-rmse:2.05581\n",
      "[7302]\teval-rmse:3.93907\ttrain-rmse:2.05569\n",
      "[7303]\teval-rmse:3.94114\ttrain-rmse:2.05555\n",
      "[7304]\teval-rmse:3.94062\ttrain-rmse:2.05556\n",
      "[7305]\teval-rmse:3.94289\ttrain-rmse:2.05546\n",
      "[7306]\teval-rmse:3.94448\ttrain-rmse:2.05544\n",
      "[7307]\teval-rmse:3.94617\ttrain-rmse:2.05542\n",
      "[7308]\teval-rmse:3.94494\ttrain-rmse:2.05536\n",
      "[7309]\teval-rmse:3.9431\ttrain-rmse:2.05536\n",
      "[7310]\teval-rmse:3.94448\ttrain-rmse:2.05536\n",
      "[7311]\teval-rmse:3.94232\ttrain-rmse:2.05539\n",
      "[7312]\teval-rmse:3.94371\ttrain-rmse:2.05533\n",
      "[7313]\teval-rmse:3.94394\ttrain-rmse:2.05532\n",
      "[7314]\teval-rmse:3.94427\ttrain-rmse:2.05532\n",
      "[7315]\teval-rmse:3.94321\ttrain-rmse:2.05533\n",
      "[7316]\teval-rmse:3.94236\ttrain-rmse:2.05531\n",
      "[7317]\teval-rmse:3.94416\ttrain-rmse:2.05531\n",
      "[7318]\teval-rmse:3.94621\ttrain-rmse:2.05523\n",
      "[7319]\teval-rmse:3.94478\ttrain-rmse:2.05524\n",
      "[7320]\teval-rmse:3.94636\ttrain-rmse:2.05523\n",
      "[7321]\teval-rmse:3.94428\ttrain-rmse:2.05525\n",
      "[7322]\teval-rmse:3.94314\ttrain-rmse:2.05529\n",
      "[7323]\teval-rmse:3.9421\ttrain-rmse:2.05531\n",
      "[7324]\teval-rmse:3.94182\ttrain-rmse:2.05531\n",
      "[7325]\teval-rmse:3.94365\ttrain-rmse:2.0553\n",
      "[7326]\teval-rmse:3.94423\ttrain-rmse:2.05529\n",
      "[7327]\teval-rmse:3.94241\ttrain-rmse:2.05532\n",
      "[7328]\teval-rmse:3.94267\ttrain-rmse:2.05531\n",
      "[7329]\teval-rmse:3.94278\ttrain-rmse:2.05531\n",
      "[7330]\teval-rmse:3.94183\ttrain-rmse:2.05533\n",
      "[7331]\teval-rmse:3.9408\ttrain-rmse:2.05535\n",
      "[7332]\teval-rmse:3.93997\ttrain-rmse:2.05531\n",
      "[7333]\teval-rmse:3.93834\ttrain-rmse:2.0554\n",
      "[7334]\teval-rmse:3.93656\ttrain-rmse:2.05545\n",
      "[7335]\teval-rmse:3.93641\ttrain-rmse:2.05545\n",
      "[7336]\teval-rmse:3.9352\ttrain-rmse:2.05543\n",
      "[7337]\teval-rmse:3.93759\ttrain-rmse:2.0553\n",
      "[7338]\teval-rmse:3.93673\ttrain-rmse:2.05487\n",
      "[7339]\teval-rmse:3.93798\ttrain-rmse:2.05485\n",
      "[7340]\teval-rmse:3.93753\ttrain-rmse:2.05485\n",
      "[7341]\teval-rmse:3.93633\ttrain-rmse:2.05482\n",
      "[7342]\teval-rmse:3.93502\ttrain-rmse:2.05488\n",
      "[7343]\teval-rmse:3.93625\ttrain-rmse:2.05485\n",
      "[7344]\teval-rmse:3.93433\ttrain-rmse:2.0549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7345]\teval-rmse:3.93354\ttrain-rmse:2.05487\n",
      "[7346]\teval-rmse:3.93581\ttrain-rmse:2.05475\n",
      "[7347]\teval-rmse:3.93818\ttrain-rmse:2.05463\n",
      "[7348]\teval-rmse:3.9368\ttrain-rmse:2.05466\n",
      "[7349]\teval-rmse:3.93906\ttrain-rmse:2.05452\n",
      "[7350]\teval-rmse:3.93717\ttrain-rmse:2.05456\n",
      "[7351]\teval-rmse:3.93746\ttrain-rmse:2.05456\n",
      "[7352]\teval-rmse:3.93953\ttrain-rmse:2.05442\n",
      "[7353]\teval-rmse:3.93985\ttrain-rmse:2.05441\n",
      "[7354]\teval-rmse:3.94065\ttrain-rmse:2.0544\n",
      "[7355]\teval-rmse:3.94178\ttrain-rmse:2.05438\n",
      "[7356]\teval-rmse:3.94055\ttrain-rmse:2.05435\n",
      "[7357]\teval-rmse:3.94192\ttrain-rmse:2.05427\n",
      "[7358]\teval-rmse:3.94352\ttrain-rmse:2.05425\n",
      "[7359]\teval-rmse:3.94269\ttrain-rmse:2.05425\n",
      "[7360]\teval-rmse:3.94328\ttrain-rmse:2.05424\n",
      "[7361]\teval-rmse:3.94439\ttrain-rmse:2.05423\n",
      "[7362]\teval-rmse:3.94665\ttrain-rmse:2.05411\n",
      "[7363]\teval-rmse:3.9481\ttrain-rmse:2.05406\n",
      "[7364]\teval-rmse:3.94725\ttrain-rmse:2.05402\n",
      "[7365]\teval-rmse:3.9495\ttrain-rmse:2.05391\n",
      "[7366]\teval-rmse:3.95165\ttrain-rmse:2.05401\n",
      "[7367]\teval-rmse:3.95346\ttrain-rmse:2.05402\n",
      "[7368]\teval-rmse:3.95149\ttrain-rmse:2.05401\n",
      "[7369]\teval-rmse:3.95122\ttrain-rmse:2.054\n",
      "[7370]\teval-rmse:3.95281\ttrain-rmse:2.054\n",
      "[7371]\teval-rmse:3.95288\ttrain-rmse:2.054\n",
      "[7372]\teval-rmse:3.95207\ttrain-rmse:2.05403\n",
      "[7373]\teval-rmse:3.94976\ttrain-rmse:2.05404\n",
      "[7374]\teval-rmse:3.95196\ttrain-rmse:2.05414\n",
      "[7375]\teval-rmse:3.95086\ttrain-rmse:2.05417\n",
      "[7376]\teval-rmse:3.94916\ttrain-rmse:2.05424\n",
      "[7377]\teval-rmse:3.94713\ttrain-rmse:2.05426\n",
      "[7378]\teval-rmse:3.94843\ttrain-rmse:2.05425\n",
      "[7379]\teval-rmse:3.94964\ttrain-rmse:2.05422\n",
      "[7380]\teval-rmse:3.94855\ttrain-rmse:2.05422\n",
      "[7381]\teval-rmse:3.94646\ttrain-rmse:2.05422\n",
      "[7382]\teval-rmse:3.94618\ttrain-rmse:2.05422\n",
      "[7383]\teval-rmse:3.9472\ttrain-rmse:2.05421\n",
      "[7384]\teval-rmse:3.94623\ttrain-rmse:2.05421\n",
      "[7385]\teval-rmse:3.94658\ttrain-rmse:2.05421\n",
      "[7386]\teval-rmse:3.9468\ttrain-rmse:2.0542\n",
      "[7387]\teval-rmse:3.94664\ttrain-rmse:2.0542\n",
      "[7388]\teval-rmse:3.94529\ttrain-rmse:2.05424\n",
      "[7389]\teval-rmse:3.94315\ttrain-rmse:2.05427\n",
      "[7390]\teval-rmse:3.94203\ttrain-rmse:2.05431\n",
      "[7391]\teval-rmse:3.94023\ttrain-rmse:2.05436\n",
      "[7392]\teval-rmse:3.94249\ttrain-rmse:2.05423\n",
      "[7393]\teval-rmse:3.94486\ttrain-rmse:2.05414\n",
      "[7394]\teval-rmse:3.94248\ttrain-rmse:2.05416\n",
      "[7395]\teval-rmse:3.94015\ttrain-rmse:2.05424\n",
      "[7396]\teval-rmse:3.9385\ttrain-rmse:2.05433\n",
      "[7397]\teval-rmse:3.93952\ttrain-rmse:2.0543\n",
      "[7398]\teval-rmse:3.93741\ttrain-rmse:2.05439\n",
      "[7399]\teval-rmse:3.93949\ttrain-rmse:2.05433\n",
      "[7400]\teval-rmse:3.93865\ttrain-rmse:2.05384\n",
      "[7401]\teval-rmse:3.9382\ttrain-rmse:2.05385\n",
      "[7402]\teval-rmse:3.93945\ttrain-rmse:2.05382\n",
      "[7403]\teval-rmse:3.94086\ttrain-rmse:2.05376\n",
      "[7404]\teval-rmse:3.93947\ttrain-rmse:2.05382\n",
      "[7405]\teval-rmse:3.94098\ttrain-rmse:2.05378\n",
      "[7406]\teval-rmse:3.94308\ttrain-rmse:2.05375\n",
      "[7407]\teval-rmse:3.94356\ttrain-rmse:2.05374\n",
      "[7408]\teval-rmse:3.94556\ttrain-rmse:2.05371\n",
      "[7409]\teval-rmse:3.94441\ttrain-rmse:2.05375\n",
      "[7410]\teval-rmse:3.94357\ttrain-rmse:2.05371\n",
      "[7411]\teval-rmse:3.94582\ttrain-rmse:2.0536\n",
      "[7412]\teval-rmse:3.94769\ttrain-rmse:2.05357\n",
      "[7413]\teval-rmse:3.9489\ttrain-rmse:2.05355\n",
      "[7414]\teval-rmse:3.95008\ttrain-rmse:2.05352\n",
      "[7415]\teval-rmse:3.95134\ttrain-rmse:2.05351\n",
      "[7416]\teval-rmse:3.95111\ttrain-rmse:2.0535\n",
      "[7417]\teval-rmse:3.9521\ttrain-rmse:2.0535\n",
      "[7418]\teval-rmse:3.95284\ttrain-rmse:2.05351\n",
      "[7419]\teval-rmse:3.95206\ttrain-rmse:2.05351\n",
      "[7420]\teval-rmse:3.95281\ttrain-rmse:2.05351\n",
      "[7421]\teval-rmse:3.95288\ttrain-rmse:2.05351\n",
      "[7422]\teval-rmse:3.95399\ttrain-rmse:2.05351\n",
      "[7423]\teval-rmse:3.95573\ttrain-rmse:2.05353\n",
      "[7424]\teval-rmse:3.95791\ttrain-rmse:2.05364\n",
      "[7425]\teval-rmse:3.95703\ttrain-rmse:2.05358\n",
      "[7426]\teval-rmse:3.9583\ttrain-rmse:2.0536\n",
      "[7427]\teval-rmse:3.95935\ttrain-rmse:2.05362\n",
      "[7428]\teval-rmse:3.95941\ttrain-rmse:2.05362\n",
      "[7429]\teval-rmse:3.95915\ttrain-rmse:2.05361\n",
      "[7430]\teval-rmse:3.96032\ttrain-rmse:2.05363\n",
      "[7431]\teval-rmse:3.9592\ttrain-rmse:2.05361\n",
      "[7432]\teval-rmse:3.95658\ttrain-rmse:2.05358\n",
      "[7433]\teval-rmse:3.95718\ttrain-rmse:2.05358\n",
      "[7434]\teval-rmse:3.95657\ttrain-rmse:2.05357\n",
      "[7435]\teval-rmse:3.95449\ttrain-rmse:2.0536\n",
      "[7436]\teval-rmse:3.95393\ttrain-rmse:2.05359\n",
      "[7437]\teval-rmse:3.95248\ttrain-rmse:2.05359\n",
      "[7438]\teval-rmse:3.95388\ttrain-rmse:2.0536\n",
      "[7439]\teval-rmse:3.95507\ttrain-rmse:2.05361\n",
      "[7440]\teval-rmse:3.95303\ttrain-rmse:2.05359\n",
      "[7441]\teval-rmse:3.95196\ttrain-rmse:2.05361\n",
      "[7442]\teval-rmse:3.9522\ttrain-rmse:2.05361\n",
      "[7443]\teval-rmse:3.9508\ttrain-rmse:2.05359\n",
      "[7444]\teval-rmse:3.95009\ttrain-rmse:2.05359\n",
      "[7445]\teval-rmse:3.95206\ttrain-rmse:2.0536\n",
      "[7446]\teval-rmse:3.95182\ttrain-rmse:2.05359\n",
      "[7447]\teval-rmse:3.95091\ttrain-rmse:2.05316\n",
      "[7448]\teval-rmse:3.95105\ttrain-rmse:2.05316\n",
      "[7449]\teval-rmse:3.94936\ttrain-rmse:2.05315\n",
      "[7450]\teval-rmse:3.95172\ttrain-rmse:2.0531\n",
      "[7451]\teval-rmse:3.95233\ttrain-rmse:2.05311\n",
      "[7452]\teval-rmse:3.95244\ttrain-rmse:2.05311\n",
      "[7453]\teval-rmse:3.95218\ttrain-rmse:2.05308\n",
      "[7454]\teval-rmse:3.94951\ttrain-rmse:2.05307\n",
      "[7455]\teval-rmse:3.95177\ttrain-rmse:2.05298\n",
      "[7456]\teval-rmse:3.9514\ttrain-rmse:2.05295\n",
      "[7457]\teval-rmse:3.95068\ttrain-rmse:2.05298\n",
      "[7458]\teval-rmse:3.95088\ttrain-rmse:2.05298\n",
      "[7459]\teval-rmse:3.94967\ttrain-rmse:2.05298\n",
      "[7460]\teval-rmse:3.95039\ttrain-rmse:2.05297\n",
      "[7461]\teval-rmse:3.9491\ttrain-rmse:2.05292\n",
      "[7462]\teval-rmse:3.94884\ttrain-rmse:2.0529\n",
      "[7463]\teval-rmse:3.94846\ttrain-rmse:2.0529\n",
      "[7464]\teval-rmse:3.95072\ttrain-rmse:2.05281\n",
      "[7465]\teval-rmse:3.94871\ttrain-rmse:2.05282\n",
      "[7466]\teval-rmse:3.94835\ttrain-rmse:2.05282\n",
      "[7467]\teval-rmse:3.94987\ttrain-rmse:2.05281\n",
      "[7468]\teval-rmse:3.94927\ttrain-rmse:2.05281\n",
      "[7469]\teval-rmse:3.94789\ttrain-rmse:2.05281\n",
      "[7470]\teval-rmse:3.94762\ttrain-rmse:2.05281\n",
      "[7471]\teval-rmse:3.94728\ttrain-rmse:2.05279\n",
      "[7472]\teval-rmse:3.94601\ttrain-rmse:2.05274\n",
      "[7473]\teval-rmse:3.94578\ttrain-rmse:2.05272\n",
      "[7474]\teval-rmse:3.94527\ttrain-rmse:2.05272\n",
      "[7475]\teval-rmse:3.94718\ttrain-rmse:2.05271\n",
      "[7476]\teval-rmse:3.94504\ttrain-rmse:2.0527\n",
      "[7477]\teval-rmse:3.94401\ttrain-rmse:2.05271\n",
      "[7478]\teval-rmse:3.94482\ttrain-rmse:2.0527\n",
      "[7479]\teval-rmse:3.94663\ttrain-rmse:2.05268\n",
      "[7480]\teval-rmse:3.94547\ttrain-rmse:2.05271\n",
      "[7481]\teval-rmse:3.94766\ttrain-rmse:2.0528\n",
      "[7482]\teval-rmse:3.94762\ttrain-rmse:2.0528\n",
      "[7483]\teval-rmse:3.94744\ttrain-rmse:2.0528\n",
      "[7484]\teval-rmse:3.94821\ttrain-rmse:2.05281\n",
      "[7485]\teval-rmse:3.94741\ttrain-rmse:2.05242\n",
      "[7486]\teval-rmse:3.94602\ttrain-rmse:2.05246\n",
      "[7487]\teval-rmse:3.94711\ttrain-rmse:2.05245\n",
      "[7488]\teval-rmse:3.94865\ttrain-rmse:2.05245\n",
      "[7489]\teval-rmse:3.95001\ttrain-rmse:2.05246\n",
      "[7490]\teval-rmse:3.94906\ttrain-rmse:2.05245\n",
      "[7491]\teval-rmse:3.95141\ttrain-rmse:2.05246\n",
      "[7492]\teval-rmse:3.95341\ttrain-rmse:2.05242\n",
      "[7493]\teval-rmse:3.9525\ttrain-rmse:2.05199\n",
      "[7494]\teval-rmse:3.95266\ttrain-rmse:2.05199\n",
      "[7495]\teval-rmse:3.9541\ttrain-rmse:2.05201\n",
      "[7496]\teval-rmse:3.9558\ttrain-rmse:2.05199\n",
      "[7497]\teval-rmse:3.95371\ttrain-rmse:2.05201\n",
      "[7498]\teval-rmse:3.95329\ttrain-rmse:2.052\n",
      "[7499]\teval-rmse:3.95533\ttrain-rmse:2.05197\n",
      "[7500]\teval-rmse:3.95638\ttrain-rmse:2.05199\n",
      "[7501]\teval-rmse:3.95677\ttrain-rmse:2.052\n",
      "[7502]\teval-rmse:3.95562\ttrain-rmse:2.05202\n",
      "[7503]\teval-rmse:3.95524\ttrain-rmse:2.05199\n",
      "[7504]\teval-rmse:3.95634\ttrain-rmse:2.05203\n",
      "[7505]\teval-rmse:3.9582\ttrain-rmse:2.05208\n",
      "[7506]\teval-rmse:3.95587\ttrain-rmse:2.05202\n",
      "[7507]\teval-rmse:3.95474\ttrain-rmse:2.05204\n",
      "[7508]\teval-rmse:3.95591\ttrain-rmse:2.05206\n",
      "[7509]\teval-rmse:3.9568\ttrain-rmse:2.05208\n",
      "[7510]\teval-rmse:3.95681\ttrain-rmse:2.05208\n",
      "[7511]\teval-rmse:3.95564\ttrain-rmse:2.0521\n",
      "[7512]\teval-rmse:3.95605\ttrain-rmse:2.05211\n",
      "[7513]\teval-rmse:3.95437\ttrain-rmse:2.05208\n",
      "[7514]\teval-rmse:3.95463\ttrain-rmse:2.05208\n",
      "[7515]\teval-rmse:3.95334\ttrain-rmse:2.05201\n",
      "[7516]\teval-rmse:3.95434\ttrain-rmse:2.05203\n",
      "[7517]\teval-rmse:3.95253\ttrain-rmse:2.052\n",
      "[7518]\teval-rmse:3.95289\ttrain-rmse:2.052\n",
      "[7519]\teval-rmse:3.95178\ttrain-rmse:2.05199\n",
      "[7520]\teval-rmse:3.95414\ttrain-rmse:2.0519\n",
      "[7521]\teval-rmse:3.95184\ttrain-rmse:2.05187\n",
      "[7522]\teval-rmse:3.95359\ttrain-rmse:2.05189\n",
      "[7523]\teval-rmse:3.95218\ttrain-rmse:2.05191\n",
      "[7524]\teval-rmse:3.95129\ttrain-rmse:2.05186\n",
      "[7525]\teval-rmse:3.95267\ttrain-rmse:2.05188\n",
      "[7526]\teval-rmse:3.95281\ttrain-rmse:2.05188\n",
      "[7527]\teval-rmse:3.95453\ttrain-rmse:2.05182\n",
      "[7528]\teval-rmse:3.95537\ttrain-rmse:2.05183\n",
      "[7529]\teval-rmse:3.95634\ttrain-rmse:2.05185\n",
      "[7530]\teval-rmse:3.95393\ttrain-rmse:2.0518\n",
      "[7531]\teval-rmse:3.95219\ttrain-rmse:2.05184\n",
      "[7532]\teval-rmse:3.9527\ttrain-rmse:2.05183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7533]\teval-rmse:3.9538\ttrain-rmse:2.05186\n",
      "[7534]\teval-rmse:3.95596\ttrain-rmse:2.05197\n",
      "[7535]\teval-rmse:3.95453\ttrain-rmse:2.05194\n",
      "[7536]\teval-rmse:3.95455\ttrain-rmse:2.05194\n",
      "[7537]\teval-rmse:3.95365\ttrain-rmse:2.05189\n",
      "[7538]\teval-rmse:3.95295\ttrain-rmse:2.05188\n",
      "[7539]\teval-rmse:3.95186\ttrain-rmse:2.05189\n",
      "[7540]\teval-rmse:3.95087\ttrain-rmse:2.05188\n",
      "[7541]\teval-rmse:3.94847\ttrain-rmse:2.05187\n",
      "[7542]\teval-rmse:3.95081\ttrain-rmse:2.05183\n",
      "[7543]\teval-rmse:3.95269\ttrain-rmse:2.05185\n",
      "[7544]\teval-rmse:3.95378\ttrain-rmse:2.05187\n",
      "[7545]\teval-rmse:3.95445\ttrain-rmse:2.05187\n",
      "[7546]\teval-rmse:3.95242\ttrain-rmse:2.05185\n",
      "[7547]\teval-rmse:3.95201\ttrain-rmse:2.05183\n",
      "[7548]\teval-rmse:3.95435\ttrain-rmse:2.05186\n",
      "[7549]\teval-rmse:3.95209\ttrain-rmse:2.05183\n",
      "[7550]\teval-rmse:3.95018\ttrain-rmse:2.05181\n",
      "[7551]\teval-rmse:3.9483\ttrain-rmse:2.05179\n",
      "[7552]\teval-rmse:3.94795\ttrain-rmse:2.05179\n",
      "[7553]\teval-rmse:3.94672\ttrain-rmse:2.05172\n",
      "[7554]\teval-rmse:3.94666\ttrain-rmse:2.05172\n",
      "[7555]\teval-rmse:3.94611\ttrain-rmse:2.05172\n",
      "[7556]\teval-rmse:3.94537\ttrain-rmse:2.05172\n",
      "[7557]\teval-rmse:3.94744\ttrain-rmse:2.05173\n",
      "[7558]\teval-rmse:3.94812\ttrain-rmse:2.05173\n",
      "[7559]\teval-rmse:3.94843\ttrain-rmse:2.05173\n",
      "[7560]\teval-rmse:3.94736\ttrain-rmse:2.05172\n",
      "[7561]\teval-rmse:3.94773\ttrain-rmse:2.05172\n",
      "[7562]\teval-rmse:3.94976\ttrain-rmse:2.05168\n",
      "[7563]\teval-rmse:3.95192\ttrain-rmse:2.05179\n",
      "[7564]\teval-rmse:3.95244\ttrain-rmse:2.05178\n",
      "[7565]\teval-rmse:3.95432\ttrain-rmse:2.0518\n",
      "[7566]\teval-rmse:3.95348\ttrain-rmse:2.05179\n",
      "[7567]\teval-rmse:3.95256\ttrain-rmse:2.05139\n",
      "[7568]\teval-rmse:3.95166\ttrain-rmse:2.05134\n",
      "[7569]\teval-rmse:3.9532\ttrain-rmse:2.05137\n",
      "[7570]\teval-rmse:3.95207\ttrain-rmse:2.05137\n",
      "[7571]\teval-rmse:3.9505\ttrain-rmse:2.05135\n",
      "[7572]\teval-rmse:3.94968\ttrain-rmse:2.05134\n",
      "[7573]\teval-rmse:3.95023\ttrain-rmse:2.05135\n",
      "[7574]\teval-rmse:3.95214\ttrain-rmse:2.05138\n",
      "[7575]\teval-rmse:3.95104\ttrain-rmse:2.05137\n",
      "[7576]\teval-rmse:3.94979\ttrain-rmse:2.0513\n",
      "[7577]\teval-rmse:3.94877\ttrain-rmse:2.05129\n",
      "[7578]\teval-rmse:3.9477\ttrain-rmse:2.05128\n",
      "[7579]\teval-rmse:3.94599\ttrain-rmse:2.05128\n",
      "[7580]\teval-rmse:3.94745\ttrain-rmse:2.05125\n",
      "[7581]\teval-rmse:3.9492\ttrain-rmse:2.05128\n",
      "[7582]\teval-rmse:3.94792\ttrain-rmse:2.05122\n",
      "[7583]\teval-rmse:3.94573\ttrain-rmse:2.0512\n",
      "[7584]\teval-rmse:3.94626\ttrain-rmse:2.0512\n",
      "[7585]\teval-rmse:3.9452\ttrain-rmse:2.0512\n",
      "[7586]\teval-rmse:3.94639\ttrain-rmse:2.0512\n",
      "[7587]\teval-rmse:3.94412\ttrain-rmse:2.0512\n",
      "[7588]\teval-rmse:3.9451\ttrain-rmse:2.05119\n",
      "[7589]\teval-rmse:3.94336\ttrain-rmse:2.05121\n",
      "[7590]\teval-rmse:3.94552\ttrain-rmse:2.0513\n",
      "[7591]\teval-rmse:3.94501\ttrain-rmse:2.0513\n",
      "[7592]\teval-rmse:3.94636\ttrain-rmse:2.05126\n",
      "[7593]\teval-rmse:3.94607\ttrain-rmse:2.05126\n",
      "[7594]\teval-rmse:3.94711\ttrain-rmse:2.05126\n",
      "[7595]\teval-rmse:3.94719\ttrain-rmse:2.05126\n",
      "[7596]\teval-rmse:3.9485\ttrain-rmse:2.05127\n",
      "[7597]\teval-rmse:3.94788\ttrain-rmse:2.05126\n",
      "[7598]\teval-rmse:3.94821\ttrain-rmse:2.05126\n",
      "[7599]\teval-rmse:3.94908\ttrain-rmse:2.05127\n",
      "[7600]\teval-rmse:3.95018\ttrain-rmse:2.0513\n",
      "[7601]\teval-rmse:3.95115\ttrain-rmse:2.05131\n",
      "[7602]\teval-rmse:3.95041\ttrain-rmse:2.0513\n",
      "[7603]\teval-rmse:3.94934\ttrain-rmse:2.05131\n",
      "[7604]\teval-rmse:3.95157\ttrain-rmse:2.05128\n",
      "[7605]\teval-rmse:3.95177\ttrain-rmse:2.05128\n",
      "[7606]\teval-rmse:3.94979\ttrain-rmse:2.05126\n",
      "[7607]\teval-rmse:3.94952\ttrain-rmse:2.05125\n",
      "[7608]\teval-rmse:3.94923\ttrain-rmse:2.05123\n",
      "[7609]\teval-rmse:3.94796\ttrain-rmse:2.05121\n",
      "[7610]\teval-rmse:3.94706\ttrain-rmse:2.05118\n",
      "[7611]\teval-rmse:3.9465\ttrain-rmse:2.05118\n",
      "[7612]\teval-rmse:3.94754\ttrain-rmse:2.05118\n",
      "[7613]\teval-rmse:3.94614\ttrain-rmse:2.0512\n",
      "[7614]\teval-rmse:3.94394\ttrain-rmse:2.0512\n",
      "[7615]\teval-rmse:3.94486\ttrain-rmse:2.0512\n",
      "[7616]\teval-rmse:3.94524\ttrain-rmse:2.0512\n",
      "[7617]\teval-rmse:3.94712\ttrain-rmse:2.0512\n",
      "[7618]\teval-rmse:3.94581\ttrain-rmse:2.0512\n",
      "[7619]\teval-rmse:3.94662\ttrain-rmse:2.0512\n",
      "[7620]\teval-rmse:3.94599\ttrain-rmse:2.0512\n",
      "[7621]\teval-rmse:3.94733\ttrain-rmse:2.05114\n",
      "[7622]\teval-rmse:3.94484\ttrain-rmse:2.05114\n",
      "[7623]\teval-rmse:3.94571\ttrain-rmse:2.05114\n",
      "[7624]\teval-rmse:3.94717\ttrain-rmse:2.05114\n",
      "[7625]\teval-rmse:3.94875\ttrain-rmse:2.05117\n",
      "[7626]\teval-rmse:3.95111\ttrain-rmse:2.05119\n",
      "[7627]\teval-rmse:3.95315\ttrain-rmse:2.05112\n",
      "[7628]\teval-rmse:3.95142\ttrain-rmse:2.05109\n",
      "[7629]\teval-rmse:3.9524\ttrain-rmse:2.0511\n",
      "[7630]\teval-rmse:3.94985\ttrain-rmse:2.05108\n",
      "[7631]\teval-rmse:3.9519\ttrain-rmse:2.0511\n",
      "[7632]\teval-rmse:3.95213\ttrain-rmse:2.0511\n",
      "[7633]\teval-rmse:3.95247\ttrain-rmse:2.0511\n",
      "[7634]\teval-rmse:3.95035\ttrain-rmse:2.05108\n",
      "[7635]\teval-rmse:3.95159\ttrain-rmse:2.05108\n",
      "[7636]\teval-rmse:3.95302\ttrain-rmse:2.05111\n",
      "[7637]\teval-rmse:3.95374\ttrain-rmse:2.05113\n",
      "[7638]\teval-rmse:3.95309\ttrain-rmse:2.05112\n",
      "[7639]\teval-rmse:3.95363\ttrain-rmse:2.05113\n",
      "[7640]\teval-rmse:3.95568\ttrain-rmse:2.05117\n",
      "[7641]\teval-rmse:3.95438\ttrain-rmse:2.0511\n",
      "[7642]\teval-rmse:3.95406\ttrain-rmse:2.05109\n",
      "[7643]\teval-rmse:3.9524\ttrain-rmse:2.05106\n",
      "[7644]\teval-rmse:3.95363\ttrain-rmse:2.05108\n",
      "[7645]\teval-rmse:3.95496\ttrain-rmse:2.05111\n",
      "[7646]\teval-rmse:3.95392\ttrain-rmse:2.05107\n",
      "[7647]\teval-rmse:3.95408\ttrain-rmse:2.05108\n",
      "[7648]\teval-rmse:3.95465\ttrain-rmse:2.05109\n",
      "[7649]\teval-rmse:3.95316\ttrain-rmse:2.05106\n",
      "[7650]\teval-rmse:3.95539\ttrain-rmse:2.05104\n",
      "[7651]\teval-rmse:3.95512\ttrain-rmse:2.05102\n",
      "[7652]\teval-rmse:3.95544\ttrain-rmse:2.05102\n",
      "[7653]\teval-rmse:3.95638\ttrain-rmse:2.05104\n",
      "[7654]\teval-rmse:3.95727\ttrain-rmse:2.05107\n",
      "[7655]\teval-rmse:3.95574\ttrain-rmse:2.05103\n",
      "[7656]\teval-rmse:3.95601\ttrain-rmse:2.05104\n",
      "[7657]\teval-rmse:3.95659\ttrain-rmse:2.05106\n",
      "[7658]\teval-rmse:3.95778\ttrain-rmse:2.0511\n",
      "[7659]\teval-rmse:3.95598\ttrain-rmse:2.05106\n",
      "[7660]\teval-rmse:3.95732\ttrain-rmse:2.0511\n",
      "[7661]\teval-rmse:3.95947\ttrain-rmse:2.05122\n",
      "[7662]\teval-rmse:3.9569\ttrain-rmse:2.05115\n",
      "[7663]\teval-rmse:3.95575\ttrain-rmse:2.05117\n",
      "[7664]\teval-rmse:3.95563\ttrain-rmse:2.05117\n",
      "[7665]\teval-rmse:3.95583\ttrain-rmse:2.05117\n",
      "[7666]\teval-rmse:3.95384\ttrain-rmse:2.05113\n",
      "[7667]\teval-rmse:3.95161\ttrain-rmse:2.05109\n",
      "[7668]\teval-rmse:3.9507\ttrain-rmse:2.05104\n",
      "[7669]\teval-rmse:3.95276\ttrain-rmse:2.05107\n",
      "[7670]\teval-rmse:3.95192\ttrain-rmse:2.05071\n",
      "[7671]\teval-rmse:3.95306\ttrain-rmse:2.05073\n",
      "[7672]\teval-rmse:3.95491\ttrain-rmse:2.05077\n",
      "[7673]\teval-rmse:3.95591\ttrain-rmse:2.05077\n",
      "[7674]\teval-rmse:3.95623\ttrain-rmse:2.05078\n",
      "[7675]\teval-rmse:3.95534\ttrain-rmse:2.05072\n",
      "[7676]\teval-rmse:3.9556\ttrain-rmse:2.05073\n",
      "[7677]\teval-rmse:3.95382\ttrain-rmse:2.05077\n",
      "[7678]\teval-rmse:3.95458\ttrain-rmse:2.05079\n",
      "[7679]\teval-rmse:3.95627\ttrain-rmse:2.05074\n",
      "[7680]\teval-rmse:3.95428\ttrain-rmse:2.05066\n",
      "[7681]\teval-rmse:3.95388\ttrain-rmse:2.05064\n",
      "[7682]\teval-rmse:3.95296\ttrain-rmse:2.05062\n",
      "[7683]\teval-rmse:3.95237\ttrain-rmse:2.0506\n",
      "[7684]\teval-rmse:3.95397\ttrain-rmse:2.05064\n",
      "[7685]\teval-rmse:3.95338\ttrain-rmse:2.05062\n",
      "[7686]\teval-rmse:3.95522\ttrain-rmse:2.05067\n",
      "[7687]\teval-rmse:3.954\ttrain-rmse:2.05064\n",
      "[7688]\teval-rmse:3.95359\ttrain-rmse:2.05063\n",
      "[7689]\teval-rmse:3.95242\ttrain-rmse:2.05061\n",
      "[7690]\teval-rmse:3.95358\ttrain-rmse:2.05063\n",
      "[7691]\teval-rmse:3.95427\ttrain-rmse:2.05064\n",
      "[7692]\teval-rmse:3.95545\ttrain-rmse:2.05067\n",
      "[7693]\teval-rmse:3.95515\ttrain-rmse:2.05064\n",
      "[7694]\teval-rmse:3.95487\ttrain-rmse:2.05063\n",
      "[7695]\teval-rmse:3.95584\ttrain-rmse:2.05066\n",
      "[7696]\teval-rmse:3.95451\ttrain-rmse:2.05058\n",
      "[7697]\teval-rmse:3.95572\ttrain-rmse:2.05063\n",
      "[7698]\teval-rmse:3.95584\ttrain-rmse:2.05063\n",
      "[7699]\teval-rmse:3.95717\ttrain-rmse:2.05061\n",
      "[7700]\teval-rmse:3.95611\ttrain-rmse:2.0506\n",
      "[7701]\teval-rmse:3.9554\ttrain-rmse:2.05058\n",
      "[7702]\teval-rmse:3.95688\ttrain-rmse:2.05063\n",
      "[7703]\teval-rmse:3.95855\ttrain-rmse:2.05069\n",
      "[7704]\teval-rmse:3.95739\ttrain-rmse:2.0507\n",
      "[7705]\teval-rmse:3.95972\ttrain-rmse:2.05071\n",
      "[7706]\teval-rmse:3.96171\ttrain-rmse:2.05078\n",
      "[7707]\teval-rmse:3.96079\ttrain-rmse:2.05073\n",
      "[7708]\teval-rmse:3.95821\ttrain-rmse:2.05065\n",
      "[7709]\teval-rmse:3.95942\ttrain-rmse:2.0507\n",
      "[7710]\teval-rmse:3.95847\ttrain-rmse:2.05064\n",
      "[7711]\teval-rmse:3.9567\ttrain-rmse:2.05063\n",
      "[7712]\teval-rmse:3.95578\ttrain-rmse:2.05058\n",
      "[7713]\teval-rmse:3.95792\ttrain-rmse:2.0507\n",
      "[7714]\teval-rmse:3.95994\ttrain-rmse:2.05078\n",
      "[7715]\teval-rmse:3.95907\ttrain-rmse:2.05036\n",
      "[7716]\teval-rmse:3.96075\ttrain-rmse:2.05032\n",
      "[7717]\teval-rmse:3.95996\ttrain-rmse:2.05029\n",
      "[7718]\teval-rmse:3.95786\ttrain-rmse:2.05027\n",
      "[7719]\teval-rmse:3.95634\ttrain-rmse:2.05021\n",
      "[7720]\teval-rmse:3.95609\ttrain-rmse:2.0502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7721]\teval-rmse:3.95433\ttrain-rmse:2.0502\n",
      "[7722]\teval-rmse:3.95611\ttrain-rmse:2.05026\n",
      "[7723]\teval-rmse:3.95742\ttrain-rmse:2.05023\n",
      "[7724]\teval-rmse:3.95942\ttrain-rmse:2.05032\n",
      "[7725]\teval-rmse:3.9579\ttrain-rmse:2.05031\n",
      "[7726]\teval-rmse:3.95832\ttrain-rmse:2.05033\n",
      "[7727]\teval-rmse:3.95972\ttrain-rmse:2.05039\n",
      "[7728]\teval-rmse:3.96076\ttrain-rmse:2.05043\n",
      "[7729]\teval-rmse:3.96306\ttrain-rmse:2.0504\n",
      "[7730]\teval-rmse:3.96323\ttrain-rmse:2.05041\n",
      "[7731]\teval-rmse:3.96168\ttrain-rmse:2.05034\n",
      "[7732]\teval-rmse:3.9632\ttrain-rmse:2.0504\n",
      "[7733]\teval-rmse:3.96412\ttrain-rmse:2.05044\n",
      "[7734]\teval-rmse:3.96461\ttrain-rmse:2.05047\n",
      "[7735]\teval-rmse:3.96692\ttrain-rmse:2.05045\n",
      "[7736]\teval-rmse:3.96738\ttrain-rmse:2.05047\n",
      "[7737]\teval-rmse:3.96462\ttrain-rmse:2.0503\n",
      "[7738]\teval-rmse:3.96681\ttrain-rmse:2.0504\n",
      "[7739]\teval-rmse:3.96572\ttrain-rmse:2.05033\n",
      "[7740]\teval-rmse:3.96425\ttrain-rmse:2.05023\n",
      "[7741]\teval-rmse:3.96644\ttrain-rmse:2.05022\n",
      "[7742]\teval-rmse:3.96513\ttrain-rmse:2.05021\n",
      "[7743]\teval-rmse:3.96375\ttrain-rmse:2.05012\n",
      "[7744]\teval-rmse:3.96425\ttrain-rmse:2.05013\n",
      "[7745]\teval-rmse:3.96396\ttrain-rmse:2.05011\n",
      "[7746]\teval-rmse:3.96162\ttrain-rmse:2.05\n",
      "[7747]\teval-rmse:3.96049\ttrain-rmse:2.04996\n",
      "[7748]\teval-rmse:3.96136\ttrain-rmse:2.05\n",
      "[7749]\teval-rmse:3.96239\ttrain-rmse:2.05006\n",
      "[7750]\teval-rmse:3.96295\ttrain-rmse:2.05009\n",
      "[7751]\teval-rmse:3.96214\ttrain-rmse:2.05006\n",
      "[7752]\teval-rmse:3.96142\ttrain-rmse:2.05002\n",
      "[7753]\teval-rmse:3.96154\ttrain-rmse:2.05003\n",
      "[7754]\teval-rmse:3.96357\ttrain-rmse:2.05011\n",
      "[7755]\teval-rmse:3.96571\ttrain-rmse:2.05025\n",
      "[7756]\teval-rmse:3.96374\ttrain-rmse:2.05015\n",
      "[7757]\teval-rmse:3.96587\ttrain-rmse:2.05029\n",
      "[7758]\teval-rmse:3.96684\ttrain-rmse:2.05035\n",
      "[7759]\teval-rmse:3.96466\ttrain-rmse:2.05024\n",
      "[7760]\teval-rmse:3.96575\ttrain-rmse:2.05029\n",
      "[7761]\teval-rmse:3.96457\ttrain-rmse:2.05024\n",
      "[7762]\teval-rmse:3.96362\ttrain-rmse:2.05017\n",
      "[7763]\teval-rmse:3.96274\ttrain-rmse:2.04973\n",
      "[7764]\teval-rmse:3.9633\ttrain-rmse:2.04975\n",
      "[7765]\teval-rmse:3.96339\ttrain-rmse:2.04976\n",
      "[7766]\teval-rmse:3.96569\ttrain-rmse:2.04979\n",
      "[7767]\teval-rmse:3.96642\ttrain-rmse:2.04983\n",
      "[7768]\teval-rmse:3.96634\ttrain-rmse:2.04983\n",
      "[7769]\teval-rmse:3.96774\ttrain-rmse:2.04989\n",
      "[7770]\teval-rmse:3.96903\ttrain-rmse:2.04997\n",
      "[7771]\teval-rmse:3.97061\ttrain-rmse:2.05006\n",
      "[7772]\teval-rmse:3.97171\ttrain-rmse:2.05012\n",
      "[7773]\teval-rmse:3.97035\ttrain-rmse:2.05011\n",
      "[7774]\teval-rmse:3.9681\ttrain-rmse:2.04996\n",
      "[7775]\teval-rmse:3.96974\ttrain-rmse:2.05004\n",
      "[7776]\teval-rmse:3.96891\ttrain-rmse:2.05\n",
      "[7777]\teval-rmse:3.97076\ttrain-rmse:2.05009\n",
      "[7778]\teval-rmse:3.97275\ttrain-rmse:2.05009\n",
      "[7779]\teval-rmse:3.97042\ttrain-rmse:2.04997\n",
      "[7780]\teval-rmse:3.96791\ttrain-rmse:2.04984\n",
      "[7781]\teval-rmse:3.969\ttrain-rmse:2.0499\n",
      "[7782]\teval-rmse:3.96933\ttrain-rmse:2.04992\n",
      "[7783]\teval-rmse:3.9685\ttrain-rmse:2.04987\n",
      "[7784]\teval-rmse:3.96751\ttrain-rmse:2.04981\n",
      "[7785]\teval-rmse:3.96717\ttrain-rmse:2.04979\n",
      "[7786]\teval-rmse:3.96473\ttrain-rmse:2.04967\n",
      "[7787]\teval-rmse:3.96703\ttrain-rmse:2.04971\n",
      "[7788]\teval-rmse:3.96549\ttrain-rmse:2.04963\n",
      "[7789]\teval-rmse:3.9635\ttrain-rmse:2.04955\n",
      "[7790]\teval-rmse:3.96518\ttrain-rmse:2.04953\n",
      "[7791]\teval-rmse:3.96384\ttrain-rmse:2.04953\n",
      "[7792]\teval-rmse:3.96387\ttrain-rmse:2.04953\n",
      "[7793]\teval-rmse:3.96556\ttrain-rmse:2.04955\n",
      "[7794]\teval-rmse:3.96789\ttrain-rmse:2.04966\n",
      "[7795]\teval-rmse:3.96807\ttrain-rmse:2.04967\n",
      "[7796]\teval-rmse:3.9664\ttrain-rmse:2.04959\n",
      "[7797]\teval-rmse:3.96728\ttrain-rmse:2.04964\n",
      "[7798]\teval-rmse:3.9681\ttrain-rmse:2.04968\n",
      "[7799]\teval-rmse:3.9695\ttrain-rmse:2.04975\n",
      "[7800]\teval-rmse:3.96799\ttrain-rmse:2.04968\n",
      "[7801]\teval-rmse:3.96751\ttrain-rmse:2.04964\n",
      "[7802]\teval-rmse:3.96551\ttrain-rmse:2.0496\n",
      "[7803]\teval-rmse:3.96414\ttrain-rmse:2.04951\n",
      "[7804]\teval-rmse:3.96557\ttrain-rmse:2.04957\n",
      "[7805]\teval-rmse:3.96435\ttrain-rmse:2.04955\n",
      "[7806]\teval-rmse:3.96601\ttrain-rmse:2.04962\n",
      "[7807]\teval-rmse:3.96794\ttrain-rmse:2.04966\n",
      "[7808]\teval-rmse:3.96754\ttrain-rmse:2.04964\n",
      "[7809]\teval-rmse:3.96835\ttrain-rmse:2.04968\n",
      "[7810]\teval-rmse:3.9684\ttrain-rmse:2.04968\n",
      "[7811]\teval-rmse:3.96805\ttrain-rmse:2.04967\n",
      "[7812]\teval-rmse:3.97004\ttrain-rmse:2.04966\n",
      "[7813]\teval-rmse:3.97104\ttrain-rmse:2.04971\n",
      "[7814]\teval-rmse:3.97158\ttrain-rmse:2.04975\n",
      "[7815]\teval-rmse:3.97247\ttrain-rmse:2.04981\n",
      "[7816]\teval-rmse:3.97115\ttrain-rmse:2.04976\n",
      "[7817]\teval-rmse:3.97242\ttrain-rmse:2.04983\n",
      "[7818]\teval-rmse:3.97334\ttrain-rmse:2.04989\n",
      "[7819]\teval-rmse:3.9721\ttrain-rmse:2.04981\n",
      "[7820]\teval-rmse:3.97123\ttrain-rmse:2.04977\n",
      "[7821]\teval-rmse:3.96985\ttrain-rmse:2.04966\n",
      "[7822]\teval-rmse:3.96736\ttrain-rmse:2.04953\n",
      "[7823]\teval-rmse:3.96675\ttrain-rmse:2.04949\n",
      "[7824]\teval-rmse:3.96458\ttrain-rmse:2.0494\n",
      "[7825]\teval-rmse:3.96337\ttrain-rmse:2.04935\n",
      "[7826]\teval-rmse:3.96511\ttrain-rmse:2.04942\n",
      "[7827]\teval-rmse:3.96474\ttrain-rmse:2.0494\n",
      "[7828]\teval-rmse:3.96604\ttrain-rmse:2.04945\n",
      "[7829]\teval-rmse:3.96557\ttrain-rmse:2.04943\n",
      "[7830]\teval-rmse:3.96523\ttrain-rmse:2.04941\n",
      "[7831]\teval-rmse:3.9649\ttrain-rmse:2.04939\n",
      "[7832]\teval-rmse:3.9657\ttrain-rmse:2.04943\n",
      "[7833]\teval-rmse:3.96367\ttrain-rmse:2.04934\n",
      "[7834]\teval-rmse:3.96414\ttrain-rmse:2.04936\n",
      "[7835]\teval-rmse:3.96449\ttrain-rmse:2.04937\n",
      "[7836]\teval-rmse:3.96651\ttrain-rmse:2.04947\n",
      "[7837]\teval-rmse:3.96501\ttrain-rmse:2.04938\n",
      "[7838]\teval-rmse:3.96359\ttrain-rmse:2.04932\n",
      "[7839]\teval-rmse:3.96374\ttrain-rmse:2.04932\n",
      "[7840]\teval-rmse:3.96479\ttrain-rmse:2.04937\n",
      "[7841]\teval-rmse:3.96645\ttrain-rmse:2.04944\n",
      "[7842]\teval-rmse:3.96673\ttrain-rmse:2.04946\n",
      "[7843]\teval-rmse:3.96531\ttrain-rmse:2.04937\n",
      "[7844]\teval-rmse:3.96395\ttrain-rmse:2.04928\n",
      "[7845]\teval-rmse:3.96301\ttrain-rmse:2.04921\n",
      "[7846]\teval-rmse:3.96219\ttrain-rmse:2.04917\n",
      "[7847]\teval-rmse:3.96111\ttrain-rmse:2.04915\n",
      "[7848]\teval-rmse:3.96237\ttrain-rmse:2.04913\n",
      "[7849]\teval-rmse:3.9614\ttrain-rmse:2.04907\n",
      "[7850]\teval-rmse:3.96067\ttrain-rmse:2.04904\n",
      "[7851]\teval-rmse:3.96269\ttrain-rmse:2.04913\n",
      "[7852]\teval-rmse:3.96499\ttrain-rmse:2.04916\n",
      "[7853]\teval-rmse:3.9624\ttrain-rmse:2.04902\n",
      "[7854]\teval-rmse:3.9603\ttrain-rmse:2.04894\n",
      "[7855]\teval-rmse:3.95807\ttrain-rmse:2.04887\n",
      "[7856]\teval-rmse:3.96021\ttrain-rmse:2.049\n",
      "[7857]\teval-rmse:3.95815\ttrain-rmse:2.04893\n",
      "[7858]\teval-rmse:3.95537\ttrain-rmse:2.04885\n",
      "[7859]\teval-rmse:3.95496\ttrain-rmse:2.04883\n",
      "[7860]\teval-rmse:3.95719\ttrain-rmse:2.04878\n",
      "[7861]\teval-rmse:3.95735\ttrain-rmse:2.04878\n",
      "[7862]\teval-rmse:3.95644\ttrain-rmse:2.04838\n",
      "[7863]\teval-rmse:3.9556\ttrain-rmse:2.04835\n",
      "[7864]\teval-rmse:3.95469\ttrain-rmse:2.04797\n",
      "[7865]\teval-rmse:3.9567\ttrain-rmse:2.04802\n",
      "[7866]\teval-rmse:3.95666\ttrain-rmse:2.04802\n",
      "[7867]\teval-rmse:3.95834\ttrain-rmse:2.04799\n",
      "[7868]\teval-rmse:3.95747\ttrain-rmse:2.04761\n",
      "[7869]\teval-rmse:3.95712\ttrain-rmse:2.0476\n",
      "[7870]\teval-rmse:3.95846\ttrain-rmse:2.04761\n",
      "[7871]\teval-rmse:3.95761\ttrain-rmse:2.04757\n",
      "[7872]\teval-rmse:3.9582\ttrain-rmse:2.04759\n",
      "[7873]\teval-rmse:3.9592\ttrain-rmse:2.04764\n",
      "[7874]\teval-rmse:3.95786\ttrain-rmse:2.0476\n",
      "[7875]\teval-rmse:3.95925\ttrain-rmse:2.04764\n",
      "[7876]\teval-rmse:3.96001\ttrain-rmse:2.04767\n",
      "[7877]\teval-rmse:3.96095\ttrain-rmse:2.04771\n",
      "[7878]\teval-rmse:3.96102\ttrain-rmse:2.04771\n",
      "[7879]\teval-rmse:3.96239\ttrain-rmse:2.04773\n",
      "[7880]\teval-rmse:3.96111\ttrain-rmse:2.04771\n",
      "[7881]\teval-rmse:3.96019\ttrain-rmse:2.04767\n",
      "[7882]\teval-rmse:3.96148\ttrain-rmse:2.04766\n",
      "[7883]\teval-rmse:3.96229\ttrain-rmse:2.04769\n",
      "[7884]\teval-rmse:3.96217\ttrain-rmse:2.04769\n",
      "[7885]\teval-rmse:3.96353\ttrain-rmse:2.04771\n",
      "[7886]\teval-rmse:3.96222\ttrain-rmse:2.04765\n",
      "[7887]\teval-rmse:3.9619\ttrain-rmse:2.04763\n",
      "[7888]\teval-rmse:3.95948\ttrain-rmse:2.04755\n",
      "[7889]\teval-rmse:3.96023\ttrain-rmse:2.04758\n",
      "[7890]\teval-rmse:3.9622\ttrain-rmse:2.04756\n",
      "[7891]\teval-rmse:3.96391\ttrain-rmse:2.04759\n",
      "[7892]\teval-rmse:3.96476\ttrain-rmse:2.04763\n",
      "[7893]\teval-rmse:3.96704\ttrain-rmse:2.04762\n",
      "[7894]\teval-rmse:3.96873\ttrain-rmse:2.04771\n",
      "[7895]\teval-rmse:3.96886\ttrain-rmse:2.04771\n",
      "[7896]\teval-rmse:3.96788\ttrain-rmse:2.04764\n",
      "[7897]\teval-rmse:3.96839\ttrain-rmse:2.04766\n",
      "[7898]\teval-rmse:3.96747\ttrain-rmse:2.04719\n",
      "[7899]\teval-rmse:3.96758\ttrain-rmse:2.0472\n",
      "[7900]\teval-rmse:3.9672\ttrain-rmse:2.04717\n",
      "[7901]\teval-rmse:3.96936\ttrain-rmse:2.04718\n",
      "[7902]\teval-rmse:3.96861\ttrain-rmse:2.04714\n",
      "[7903]\teval-rmse:3.96725\ttrain-rmse:2.04712\n",
      "[7904]\teval-rmse:3.96686\ttrain-rmse:2.0471\n",
      "[7905]\teval-rmse:3.96854\ttrain-rmse:2.04718\n",
      "[7906]\teval-rmse:3.96756\ttrain-rmse:2.0471\n",
      "[7907]\teval-rmse:3.96847\ttrain-rmse:2.04713\n",
      "[7908]\teval-rmse:3.9668\ttrain-rmse:2.04704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7909]\teval-rmse:3.96744\ttrain-rmse:2.04707\n",
      "[7910]\teval-rmse:3.96607\ttrain-rmse:2.04698\n",
      "[7911]\teval-rmse:3.96711\ttrain-rmse:2.04704\n",
      "[7912]\teval-rmse:3.9647\ttrain-rmse:2.04692\n",
      "[7913]\teval-rmse:3.96587\ttrain-rmse:2.04698\n",
      "[7914]\teval-rmse:3.96476\ttrain-rmse:2.04692\n",
      "[7915]\teval-rmse:3.96325\ttrain-rmse:2.04689\n",
      "[7916]\teval-rmse:3.96331\ttrain-rmse:2.04689\n",
      "[7917]\teval-rmse:3.9613\ttrain-rmse:2.04685\n",
      "[7918]\teval-rmse:3.96148\ttrain-rmse:2.04685\n",
      "[7919]\teval-rmse:3.96211\ttrain-rmse:2.04688\n",
      "[7920]\teval-rmse:3.96281\ttrain-rmse:2.04691\n",
      "[7921]\teval-rmse:3.96414\ttrain-rmse:2.04697\n",
      "[7922]\teval-rmse:3.96334\ttrain-rmse:2.04693\n",
      "[7923]\teval-rmse:3.96237\ttrain-rmse:2.04687\n",
      "[7924]\teval-rmse:3.96022\ttrain-rmse:2.04677\n",
      "[7925]\teval-rmse:3.95928\ttrain-rmse:2.04672\n",
      "[7926]\teval-rmse:3.95894\ttrain-rmse:2.04671\n",
      "[7927]\teval-rmse:3.95851\ttrain-rmse:2.04668\n",
      "[7928]\teval-rmse:3.95699\ttrain-rmse:2.04663\n",
      "[7929]\teval-rmse:3.95566\ttrain-rmse:2.04655\n",
      "[7930]\teval-rmse:3.95586\ttrain-rmse:2.04655\n",
      "[7931]\teval-rmse:3.95685\ttrain-rmse:2.04658\n",
      "[7932]\teval-rmse:3.95644\ttrain-rmse:2.04655\n",
      "[7933]\teval-rmse:3.95398\ttrain-rmse:2.04645\n",
      "[7934]\teval-rmse:3.9534\ttrain-rmse:2.04643\n",
      "[7935]\teval-rmse:3.95424\ttrain-rmse:2.04645\n",
      "[7936]\teval-rmse:3.95507\ttrain-rmse:2.04648\n",
      "[7937]\teval-rmse:3.95657\ttrain-rmse:2.04653\n",
      "[7938]\teval-rmse:3.95765\ttrain-rmse:2.04657\n",
      "[7939]\teval-rmse:3.95872\ttrain-rmse:2.04662\n",
      "[7940]\teval-rmse:3.95735\ttrain-rmse:2.04657\n",
      "[7941]\teval-rmse:3.95642\ttrain-rmse:2.04623\n",
      "[7942]\teval-rmse:3.95647\ttrain-rmse:2.04623\n",
      "[7943]\teval-rmse:3.95751\ttrain-rmse:2.04627\n",
      "[7944]\teval-rmse:3.95632\ttrain-rmse:2.04628\n",
      "[7945]\teval-rmse:3.95741\ttrain-rmse:2.0463\n",
      "[7946]\teval-rmse:3.95743\ttrain-rmse:2.0463\n",
      "[7947]\teval-rmse:3.9585\ttrain-rmse:2.04634\n",
      "[7948]\teval-rmse:3.95675\ttrain-rmse:2.04625\n",
      "[7949]\teval-rmse:3.95827\ttrain-rmse:2.04631\n",
      "[7950]\teval-rmse:3.96023\ttrain-rmse:2.04639\n",
      "[7951]\teval-rmse:3.96201\ttrain-rmse:2.04649\n",
      "[7952]\teval-rmse:3.96065\ttrain-rmse:2.0464\n",
      "[7953]\teval-rmse:3.96021\ttrain-rmse:2.04638\n",
      "[7954]\teval-rmse:3.95812\ttrain-rmse:2.04627\n",
      "[7955]\teval-rmse:3.95631\ttrain-rmse:2.04624\n",
      "[7956]\teval-rmse:3.95527\ttrain-rmse:2.04621\n",
      "[7957]\teval-rmse:3.95495\ttrain-rmse:2.04619\n",
      "[7958]\teval-rmse:3.95521\ttrain-rmse:2.0462\n",
      "[7959]\teval-rmse:3.95664\ttrain-rmse:2.04626\n",
      "[7960]\teval-rmse:3.95484\ttrain-rmse:2.04628\n",
      "[7961]\teval-rmse:3.95343\ttrain-rmse:2.04623\n",
      "[7962]\teval-rmse:3.95493\ttrain-rmse:2.04628\n",
      "[7963]\teval-rmse:3.95505\ttrain-rmse:2.04629\n",
      "[7964]\teval-rmse:3.95299\ttrain-rmse:2.04627\n",
      "[7965]\teval-rmse:3.95467\ttrain-rmse:2.04624\n",
      "[7966]\teval-rmse:3.95287\ttrain-rmse:2.04625\n",
      "[7967]\teval-rmse:3.95371\ttrain-rmse:2.04629\n",
      "[7968]\teval-rmse:3.95503\ttrain-rmse:2.04634\n",
      "[7969]\teval-rmse:3.9524\ttrain-rmse:2.04627\n",
      "[7970]\teval-rmse:3.95457\ttrain-rmse:2.04634\n",
      "[7971]\teval-rmse:3.95461\ttrain-rmse:2.04634\n",
      "[7972]\teval-rmse:3.95306\ttrain-rmse:2.04629\n",
      "[7973]\teval-rmse:3.95075\ttrain-rmse:2.04623\n",
      "[7974]\teval-rmse:3.95106\ttrain-rmse:2.04624\n",
      "[7975]\teval-rmse:3.9493\ttrain-rmse:2.04619\n",
      "[7976]\teval-rmse:3.9485\ttrain-rmse:2.04617\n",
      "[7977]\teval-rmse:3.94782\ttrain-rmse:2.04616\n",
      "[7978]\teval-rmse:3.94612\ttrain-rmse:2.04614\n",
      "[7979]\teval-rmse:3.94583\ttrain-rmse:2.04613\n",
      "[7980]\teval-rmse:3.94367\ttrain-rmse:2.04612\n",
      "[7981]\teval-rmse:3.94143\ttrain-rmse:2.04609\n",
      "[7982]\teval-rmse:3.94018\ttrain-rmse:2.04609\n",
      "[7983]\teval-rmse:3.94036\ttrain-rmse:2.04609\n",
      "[7984]\teval-rmse:3.93914\ttrain-rmse:2.04614\n",
      "[7985]\teval-rmse:3.94036\ttrain-rmse:2.04614\n",
      "[7986]\teval-rmse:3.9394\ttrain-rmse:2.04615\n",
      "[7987]\teval-rmse:3.94078\ttrain-rmse:2.04615\n",
      "[7988]\teval-rmse:3.94146\ttrain-rmse:2.04615\n",
      "[7989]\teval-rmse:3.94367\ttrain-rmse:2.04612\n",
      "[7990]\teval-rmse:3.94243\ttrain-rmse:2.04613\n",
      "[7991]\teval-rmse:3.94212\ttrain-rmse:2.04613\n",
      "[7992]\teval-rmse:3.94298\ttrain-rmse:2.04613\n",
      "[7993]\teval-rmse:3.94514\ttrain-rmse:2.04622\n",
      "[7994]\teval-rmse:3.94303\ttrain-rmse:2.04622\n",
      "[7995]\teval-rmse:3.94357\ttrain-rmse:2.04622\n",
      "[7996]\teval-rmse:3.94244\ttrain-rmse:2.04626\n",
      "[7997]\teval-rmse:3.94132\ttrain-rmse:2.0463\n",
      "[7998]\teval-rmse:3.94038\ttrain-rmse:2.0463\n",
      "[7999]\teval-rmse:3.94093\ttrain-rmse:2.0463\n",
      "[8000]\teval-rmse:3.94314\ttrain-rmse:2.04622\n",
      "[8001]\teval-rmse:3.94198\ttrain-rmse:2.04622\n",
      "[8002]\teval-rmse:3.94319\ttrain-rmse:2.04623\n",
      "[8003]\teval-rmse:3.9428\ttrain-rmse:2.04623\n",
      "[8004]\teval-rmse:3.94115\ttrain-rmse:2.04624\n",
      "[8005]\teval-rmse:3.94168\ttrain-rmse:2.04623\n",
      "[8006]\teval-rmse:3.94044\ttrain-rmse:2.04618\n",
      "[8007]\teval-rmse:3.94054\ttrain-rmse:2.04618\n",
      "[8008]\teval-rmse:3.94028\ttrain-rmse:2.04617\n",
      "[8009]\teval-rmse:3.94004\ttrain-rmse:2.04616\n",
      "[8010]\teval-rmse:3.94035\ttrain-rmse:2.04615\n",
      "[8011]\teval-rmse:3.94008\ttrain-rmse:2.04615\n",
      "[8012]\teval-rmse:3.94147\ttrain-rmse:2.04616\n",
      "[8013]\teval-rmse:3.94065\ttrain-rmse:2.04616\n",
      "[8014]\teval-rmse:3.93897\ttrain-rmse:2.04615\n",
      "[8015]\teval-rmse:3.93822\ttrain-rmse:2.04616\n",
      "[8016]\teval-rmse:3.93939\ttrain-rmse:2.04615\n",
      "[8017]\teval-rmse:3.93957\ttrain-rmse:2.04615\n",
      "[8018]\teval-rmse:3.94159\ttrain-rmse:2.04616\n",
      "[8019]\teval-rmse:3.94376\ttrain-rmse:2.04613\n",
      "[8020]\teval-rmse:3.94137\ttrain-rmse:2.04614\n",
      "[8021]\teval-rmse:3.94254\ttrain-rmse:2.04615\n",
      "[8022]\teval-rmse:3.94297\ttrain-rmse:2.04615\n",
      "[8023]\teval-rmse:3.9421\ttrain-rmse:2.04575\n",
      "[8024]\teval-rmse:3.94125\ttrain-rmse:2.04572\n",
      "[8025]\teval-rmse:3.9397\ttrain-rmse:2.04571\n",
      "[8026]\teval-rmse:3.94116\ttrain-rmse:2.04572\n",
      "[8027]\teval-rmse:3.94337\ttrain-rmse:2.04569\n",
      "[8028]\teval-rmse:3.94405\ttrain-rmse:2.0457\n",
      "[8029]\teval-rmse:3.946\ttrain-rmse:2.04572\n",
      "[8030]\teval-rmse:3.94375\ttrain-rmse:2.04568\n",
      "[8031]\teval-rmse:3.94427\ttrain-rmse:2.04568\n",
      "[8032]\teval-rmse:3.94401\ttrain-rmse:2.04566\n",
      "[8033]\teval-rmse:3.94503\ttrain-rmse:2.04566\n",
      "[8034]\teval-rmse:3.94631\ttrain-rmse:2.04562\n",
      "[8035]\teval-rmse:3.94635\ttrain-rmse:2.04562\n",
      "[8036]\teval-rmse:3.94557\ttrain-rmse:2.0456\n",
      "[8037]\teval-rmse:3.94623\ttrain-rmse:2.04561\n",
      "[8038]\teval-rmse:3.94418\ttrain-rmse:2.04557\n",
      "[8039]\teval-rmse:3.94305\ttrain-rmse:2.0456\n",
      "[8040]\teval-rmse:3.94501\ttrain-rmse:2.04563\n",
      "[8041]\teval-rmse:3.94376\ttrain-rmse:2.04557\n",
      "[8042]\teval-rmse:3.94241\ttrain-rmse:2.04556\n",
      "[8043]\teval-rmse:3.94256\ttrain-rmse:2.04556\n",
      "[8044]\teval-rmse:3.94172\ttrain-rmse:2.04551\n",
      "[8045]\teval-rmse:3.94325\ttrain-rmse:2.0455\n",
      "[8046]\teval-rmse:3.9424\ttrain-rmse:2.04546\n",
      "[8047]\teval-rmse:3.9426\ttrain-rmse:2.04546\n",
      "[8048]\teval-rmse:3.94124\ttrain-rmse:2.04546\n",
      "[8049]\teval-rmse:3.93937\ttrain-rmse:2.04547\n",
      "[8050]\teval-rmse:3.9381\ttrain-rmse:2.04549\n",
      "[8051]\teval-rmse:3.93852\ttrain-rmse:2.04548\n",
      "[8052]\teval-rmse:3.93869\ttrain-rmse:2.04548\n",
      "[8053]\teval-rmse:3.93699\ttrain-rmse:2.04554\n",
      "[8054]\teval-rmse:3.939\ttrain-rmse:2.04555\n",
      "[8055]\teval-rmse:3.9407\ttrain-rmse:2.04552\n",
      "[8056]\teval-rmse:3.94202\ttrain-rmse:2.04548\n",
      "[8057]\teval-rmse:3.94059\ttrain-rmse:2.04546\n",
      "[8058]\teval-rmse:3.9417\ttrain-rmse:2.04547\n",
      "[8059]\teval-rmse:3.94389\ttrain-rmse:2.0454\n",
      "[8060]\teval-rmse:3.9431\ttrain-rmse:2.04501\n",
      "[8061]\teval-rmse:3.9454\ttrain-rmse:2.045\n",
      "[8062]\teval-rmse:3.94415\ttrain-rmse:2.045\n",
      "[8063]\teval-rmse:3.9439\ttrain-rmse:2.04499\n",
      "[8064]\teval-rmse:3.94424\ttrain-rmse:2.04499\n",
      "[8065]\teval-rmse:3.94639\ttrain-rmse:2.04508\n",
      "[8066]\teval-rmse:3.94659\ttrain-rmse:2.04508\n",
      "[8067]\teval-rmse:3.94531\ttrain-rmse:2.04503\n",
      "[8068]\teval-rmse:3.94302\ttrain-rmse:2.04502\n",
      "[8069]\teval-rmse:3.94275\ttrain-rmse:2.04501\n",
      "[8070]\teval-rmse:3.9413\ttrain-rmse:2.04499\n",
      "[8071]\teval-rmse:3.94257\ttrain-rmse:2.04494\n",
      "[8072]\teval-rmse:3.94276\ttrain-rmse:2.04494\n",
      "[8073]\teval-rmse:3.94302\ttrain-rmse:2.04494\n",
      "[8074]\teval-rmse:3.94228\ttrain-rmse:2.04493\n",
      "[8075]\teval-rmse:3.94101\ttrain-rmse:2.04487\n",
      "[8076]\teval-rmse:3.942\ttrain-rmse:2.04486\n",
      "[8077]\teval-rmse:3.94089\ttrain-rmse:2.0449\n",
      "[8078]\teval-rmse:3.93975\ttrain-rmse:2.04488\n",
      "[8079]\teval-rmse:3.94079\ttrain-rmse:2.04489\n",
      "[8080]\teval-rmse:3.94231\ttrain-rmse:2.04491\n",
      "[8081]\teval-rmse:3.94202\ttrain-rmse:2.04491\n",
      "[8082]\teval-rmse:3.94287\ttrain-rmse:2.04492\n",
      "[8083]\teval-rmse:3.94381\ttrain-rmse:2.04491\n",
      "[8084]\teval-rmse:3.94581\ttrain-rmse:2.04486\n",
      "[8085]\teval-rmse:3.94676\ttrain-rmse:2.04486\n",
      "[8086]\teval-rmse:3.94533\ttrain-rmse:2.04483\n",
      "[8087]\teval-rmse:3.94447\ttrain-rmse:2.04478\n",
      "[8088]\teval-rmse:3.94674\ttrain-rmse:2.04472\n",
      "[8089]\teval-rmse:3.94816\ttrain-rmse:2.04474\n",
      "[8090]\teval-rmse:3.95012\ttrain-rmse:2.04479\n",
      "[8091]\teval-rmse:3.94929\ttrain-rmse:2.04443\n",
      "[8092]\teval-rmse:3.95026\ttrain-rmse:2.04443\n",
      "[8093]\teval-rmse:3.95059\ttrain-rmse:2.04444\n",
      "[8094]\teval-rmse:3.95263\ttrain-rmse:2.04448\n",
      "[8095]\teval-rmse:3.9528\ttrain-rmse:2.04449\n",
      "[8096]\teval-rmse:3.95167\ttrain-rmse:2.04446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8097]\teval-rmse:3.95303\ttrain-rmse:2.04451\n",
      "[8098]\teval-rmse:3.95106\ttrain-rmse:2.04444\n",
      "[8099]\teval-rmse:3.95165\ttrain-rmse:2.04445\n",
      "[8100]\teval-rmse:3.95077\ttrain-rmse:2.04441\n",
      "[8101]\teval-rmse:3.95292\ttrain-rmse:2.04448\n",
      "[8102]\teval-rmse:3.95074\ttrain-rmse:2.0444\n",
      "[8103]\teval-rmse:3.95111\ttrain-rmse:2.04441\n",
      "[8104]\teval-rmse:3.95022\ttrain-rmse:2.04402\n",
      "[8105]\teval-rmse:3.9498\ttrain-rmse:2.044\n",
      "[8106]\teval-rmse:3.95172\ttrain-rmse:2.04407\n",
      "[8107]\teval-rmse:3.94965\ttrain-rmse:2.044\n",
      "[8108]\teval-rmse:3.9506\ttrain-rmse:2.04402\n",
      "[8109]\teval-rmse:3.94878\ttrain-rmse:2.04397\n",
      "[8110]\teval-rmse:3.95004\ttrain-rmse:2.04394\n",
      "[8111]\teval-rmse:3.9497\ttrain-rmse:2.04393\n",
      "[8112]\teval-rmse:3.95096\ttrain-rmse:2.04394\n",
      "[8113]\teval-rmse:3.94966\ttrain-rmse:2.04393\n",
      "[8114]\teval-rmse:3.94783\ttrain-rmse:2.04386\n",
      "[8115]\teval-rmse:3.94663\ttrain-rmse:2.04383\n",
      "[8116]\teval-rmse:3.94861\ttrain-rmse:2.04379\n",
      "[8117]\teval-rmse:3.9469\ttrain-rmse:2.04374\n",
      "[8118]\teval-rmse:3.9481\ttrain-rmse:2.04376\n",
      "[8119]\teval-rmse:3.94722\ttrain-rmse:2.04341\n",
      "[8120]\teval-rmse:3.94635\ttrain-rmse:2.04337\n",
      "[8121]\teval-rmse:3.94429\ttrain-rmse:2.04337\n",
      "[8122]\teval-rmse:3.94255\ttrain-rmse:2.04337\n",
      "[8123]\teval-rmse:3.94323\ttrain-rmse:2.04338\n",
      "[8124]\teval-rmse:3.94284\ttrain-rmse:2.04338\n",
      "[8125]\teval-rmse:3.94044\ttrain-rmse:2.04337\n",
      "[8126]\teval-rmse:3.94118\ttrain-rmse:2.04337\n",
      "[8127]\teval-rmse:3.94299\ttrain-rmse:2.04337\n",
      "[8128]\teval-rmse:3.94393\ttrain-rmse:2.04339\n",
      "[8129]\teval-rmse:3.94366\ttrain-rmse:2.04339\n",
      "[8130]\teval-rmse:3.94191\ttrain-rmse:2.04336\n",
      "[8131]\teval-rmse:3.94325\ttrain-rmse:2.04338\n",
      "[8132]\teval-rmse:3.94426\ttrain-rmse:2.04339\n",
      "[8133]\teval-rmse:3.94643\ttrain-rmse:2.04343\n",
      "[8134]\teval-rmse:3.94537\ttrain-rmse:2.0434\n",
      "[8135]\teval-rmse:3.9448\ttrain-rmse:2.04339\n",
      "[8136]\teval-rmse:3.9461\ttrain-rmse:2.04339\n",
      "[8137]\teval-rmse:3.94808\ttrain-rmse:2.04345\n",
      "[8138]\teval-rmse:3.94723\ttrain-rmse:2.04339\n",
      "[8139]\teval-rmse:3.94606\ttrain-rmse:2.04342\n",
      "[8140]\teval-rmse:3.94476\ttrain-rmse:2.04336\n",
      "[8141]\teval-rmse:3.94437\ttrain-rmse:2.04334\n",
      "[8142]\teval-rmse:3.94311\ttrain-rmse:2.04327\n",
      "[8143]\teval-rmse:3.94143\ttrain-rmse:2.04323\n",
      "[8144]\teval-rmse:3.94259\ttrain-rmse:2.04325\n",
      "[8145]\teval-rmse:3.94357\ttrain-rmse:2.04327\n",
      "[8146]\teval-rmse:3.94463\ttrain-rmse:2.0433\n",
      "[8147]\teval-rmse:3.94688\ttrain-rmse:2.04331\n",
      "[8148]\teval-rmse:3.94801\ttrain-rmse:2.04334\n",
      "[8149]\teval-rmse:3.9467\ttrain-rmse:2.04327\n",
      "[8150]\teval-rmse:3.94644\ttrain-rmse:2.04326\n",
      "[8151]\teval-rmse:3.9487\ttrain-rmse:2.04322\n",
      "[8152]\teval-rmse:3.94743\ttrain-rmse:2.04315\n",
      "[8153]\teval-rmse:3.94566\ttrain-rmse:2.04317\n",
      "[8154]\teval-rmse:3.94315\ttrain-rmse:2.04311\n",
      "[8155]\teval-rmse:3.94448\ttrain-rmse:2.04313\n",
      "[8156]\teval-rmse:3.94242\ttrain-rmse:2.04313\n",
      "[8157]\teval-rmse:3.94116\ttrain-rmse:2.04315\n",
      "[8158]\teval-rmse:3.94129\ttrain-rmse:2.04315\n",
      "[8159]\teval-rmse:3.94321\ttrain-rmse:2.04319\n",
      "[8160]\teval-rmse:3.94392\ttrain-rmse:2.04321\n",
      "[8161]\teval-rmse:3.94365\ttrain-rmse:2.0432\n",
      "[8162]\teval-rmse:3.94145\ttrain-rmse:2.04313\n",
      "[8163]\teval-rmse:3.94037\ttrain-rmse:2.0431\n",
      "[8164]\teval-rmse:3.94142\ttrain-rmse:2.04312\n",
      "[8165]\teval-rmse:3.94292\ttrain-rmse:2.04312\n",
      "[8166]\teval-rmse:3.94418\ttrain-rmse:2.04314\n",
      "[8167]\teval-rmse:3.94646\ttrain-rmse:2.04316\n",
      "[8168]\teval-rmse:3.94774\ttrain-rmse:2.0432\n",
      "[8169]\teval-rmse:3.94913\ttrain-rmse:2.04324\n",
      "[8170]\teval-rmse:3.94754\ttrain-rmse:2.04319\n",
      "[8171]\teval-rmse:3.94861\ttrain-rmse:2.04323\n",
      "[8172]\teval-rmse:3.9465\ttrain-rmse:2.04321\n",
      "[8173]\teval-rmse:3.94665\ttrain-rmse:2.04321\n",
      "[8174]\teval-rmse:3.9458\ttrain-rmse:2.04319\n",
      "[8175]\teval-rmse:3.94706\ttrain-rmse:2.04315\n",
      "[8176]\teval-rmse:3.94707\ttrain-rmse:2.04316\n",
      "[8177]\teval-rmse:3.94904\ttrain-rmse:2.04322\n",
      "[8178]\teval-rmse:3.94922\ttrain-rmse:2.04323\n",
      "[8179]\teval-rmse:3.94833\ttrain-rmse:2.04287\n",
      "[8180]\teval-rmse:3.94744\ttrain-rmse:2.04283\n",
      "[8181]\teval-rmse:3.94668\ttrain-rmse:2.0428\n",
      "[8182]\teval-rmse:3.94806\ttrain-rmse:2.04285\n",
      "[8183]\teval-rmse:3.95032\ttrain-rmse:2.04294\n",
      "[8184]\teval-rmse:3.95001\ttrain-rmse:2.04292\n",
      "[8185]\teval-rmse:3.94921\ttrain-rmse:2.04254\n",
      "[8186]\teval-rmse:3.94906\ttrain-rmse:2.04254\n",
      "[8187]\teval-rmse:3.95102\ttrain-rmse:2.04257\n",
      "[8188]\teval-rmse:3.95317\ttrain-rmse:2.04262\n",
      "[8189]\teval-rmse:3.95531\ttrain-rmse:2.04274\n",
      "[8190]\teval-rmse:3.95468\ttrain-rmse:2.04271\n",
      "[8191]\teval-rmse:3.95569\ttrain-rmse:2.04277\n",
      "[8192]\teval-rmse:3.95639\ttrain-rmse:2.0428\n",
      "[8193]\teval-rmse:3.95427\ttrain-rmse:2.0427\n",
      "[8194]\teval-rmse:3.95341\ttrain-rmse:2.04235\n",
      "[8195]\teval-rmse:3.95435\ttrain-rmse:2.0424\n",
      "[8196]\teval-rmse:3.95344\ttrain-rmse:2.04234\n",
      "[8197]\teval-rmse:3.9514\ttrain-rmse:2.04226\n",
      "[8198]\teval-rmse:3.95156\ttrain-rmse:2.04226\n",
      "[8199]\teval-rmse:3.9529\ttrain-rmse:2.04233\n",
      "[8200]\teval-rmse:3.95462\ttrain-rmse:2.04243\n",
      "[8201]\teval-rmse:3.95554\ttrain-rmse:2.04245\n",
      "[8202]\teval-rmse:3.95397\ttrain-rmse:2.04241\n",
      "[8203]\teval-rmse:3.95488\ttrain-rmse:2.04246\n",
      "[8204]\teval-rmse:3.95305\ttrain-rmse:2.04236\n",
      "[8205]\teval-rmse:3.95181\ttrain-rmse:2.04236\n",
      "[8206]\teval-rmse:3.95282\ttrain-rmse:2.04241\n",
      "[8207]\teval-rmse:3.95452\ttrain-rmse:2.04251\n",
      "[8208]\teval-rmse:3.9524\ttrain-rmse:2.04241\n",
      "[8209]\teval-rmse:3.9506\ttrain-rmse:2.0424\n",
      "[8210]\teval-rmse:3.95255\ttrain-rmse:2.04238\n",
      "[8211]\teval-rmse:3.95211\ttrain-rmse:2.04236\n",
      "[8212]\teval-rmse:3.95179\ttrain-rmse:2.04234\n",
      "[8213]\teval-rmse:3.94967\ttrain-rmse:2.04224\n",
      "[8214]\teval-rmse:3.95057\ttrain-rmse:2.04228\n",
      "[8215]\teval-rmse:3.94815\ttrain-rmse:2.04218\n",
      "[8216]\teval-rmse:3.94618\ttrain-rmse:2.04211\n",
      "[8217]\teval-rmse:3.94519\ttrain-rmse:2.04207\n",
      "[8218]\teval-rmse:3.94362\ttrain-rmse:2.042\n",
      "[8219]\teval-rmse:3.94374\ttrain-rmse:2.04201\n",
      "[8220]\teval-rmse:3.94317\ttrain-rmse:2.04199\n",
      "[8221]\teval-rmse:3.9419\ttrain-rmse:2.04193\n",
      "[8222]\teval-rmse:3.94295\ttrain-rmse:2.04196\n",
      "[8223]\teval-rmse:3.94242\ttrain-rmse:2.04195\n",
      "[8224]\teval-rmse:3.94002\ttrain-rmse:2.0419\n",
      "[8225]\teval-rmse:3.9405\ttrain-rmse:2.04191\n",
      "[8226]\teval-rmse:3.9383\ttrain-rmse:2.04188\n",
      "[8227]\teval-rmse:3.93791\ttrain-rmse:2.04187\n",
      "[8228]\teval-rmse:3.9389\ttrain-rmse:2.04189\n",
      "[8229]\teval-rmse:3.93966\ttrain-rmse:2.04191\n",
      "[8230]\teval-rmse:3.93859\ttrain-rmse:2.04191\n",
      "[8231]\teval-rmse:3.93776\ttrain-rmse:2.04187\n",
      "[8232]\teval-rmse:3.9362\ttrain-rmse:2.04186\n",
      "[8233]\teval-rmse:3.93543\ttrain-rmse:2.04185\n",
      "[8234]\teval-rmse:3.93438\ttrain-rmse:2.04183\n",
      "[8235]\teval-rmse:3.93555\ttrain-rmse:2.04183\n",
      "[8236]\teval-rmse:3.93341\ttrain-rmse:2.04183\n",
      "[8237]\teval-rmse:3.93181\ttrain-rmse:2.04184\n",
      "[8238]\teval-rmse:3.931\ttrain-rmse:2.04182\n",
      "[8239]\teval-rmse:3.93133\ttrain-rmse:2.04181\n",
      "[8240]\teval-rmse:3.9332\ttrain-rmse:2.04181\n",
      "[8241]\teval-rmse:3.93407\ttrain-rmse:2.04181\n",
      "[8242]\teval-rmse:3.93603\ttrain-rmse:2.04183\n",
      "[8243]\teval-rmse:3.937\ttrain-rmse:2.04185\n",
      "[8244]\teval-rmse:3.93595\ttrain-rmse:2.04185\n",
      "[8245]\teval-rmse:3.93671\ttrain-rmse:2.04186\n",
      "[8246]\teval-rmse:3.93601\ttrain-rmse:2.04185\n",
      "[8247]\teval-rmse:3.93518\ttrain-rmse:2.04154\n",
      "[8248]\teval-rmse:3.93733\ttrain-rmse:2.04162\n",
      "[8249]\teval-rmse:3.93961\ttrain-rmse:2.04166\n",
      "[8250]\teval-rmse:3.94145\ttrain-rmse:2.04171\n",
      "[8251]\teval-rmse:3.94113\ttrain-rmse:2.0417\n",
      "[8252]\teval-rmse:3.9414\ttrain-rmse:2.0417\n",
      "[8253]\teval-rmse:3.94259\ttrain-rmse:2.04174\n",
      "[8254]\teval-rmse:3.94455\ttrain-rmse:2.04176\n",
      "[8255]\teval-rmse:3.94369\ttrain-rmse:2.04144\n",
      "[8256]\teval-rmse:3.94472\ttrain-rmse:2.04147\n",
      "[8257]\teval-rmse:3.94663\ttrain-rmse:2.04155\n",
      "[8258]\teval-rmse:3.94753\ttrain-rmse:2.0416\n",
      "[8259]\teval-rmse:3.94966\ttrain-rmse:2.04163\n",
      "[8260]\teval-rmse:3.94815\ttrain-rmse:2.04157\n",
      "[8261]\teval-rmse:3.94569\ttrain-rmse:2.04148\n",
      "[8262]\teval-rmse:3.94374\ttrain-rmse:2.04143\n",
      "[8263]\teval-rmse:3.94511\ttrain-rmse:2.04146\n",
      "[8264]\teval-rmse:3.94541\ttrain-rmse:2.04147\n",
      "[8265]\teval-rmse:3.94731\ttrain-rmse:2.04156\n",
      "[8266]\teval-rmse:3.94534\ttrain-rmse:2.04148\n",
      "[8267]\teval-rmse:3.94434\ttrain-rmse:2.04145\n",
      "[8268]\teval-rmse:3.94374\ttrain-rmse:2.04143\n",
      "[8269]\teval-rmse:3.94346\ttrain-rmse:2.04142\n",
      "[8270]\teval-rmse:3.94481\ttrain-rmse:2.04147\n",
      "[8271]\teval-rmse:3.94402\ttrain-rmse:2.04144\n",
      "[8272]\teval-rmse:3.9437\ttrain-rmse:2.04143\n",
      "[8273]\teval-rmse:3.94134\ttrain-rmse:2.04137\n",
      "[8274]\teval-rmse:3.94011\ttrain-rmse:2.04132\n",
      "[8275]\teval-rmse:3.94195\ttrain-rmse:2.04137\n",
      "[8276]\teval-rmse:3.94205\ttrain-rmse:2.04137\n",
      "[8277]\teval-rmse:3.93981\ttrain-rmse:2.04133\n",
      "[8278]\teval-rmse:3.94108\ttrain-rmse:2.04129\n",
      "[8279]\teval-rmse:3.93949\ttrain-rmse:2.04125\n",
      "[8280]\teval-rmse:3.93825\ttrain-rmse:2.0412\n",
      "[8281]\teval-rmse:3.93874\ttrain-rmse:2.0412\n",
      "[8282]\teval-rmse:3.93747\ttrain-rmse:2.04123\n",
      "[8283]\teval-rmse:3.93974\ttrain-rmse:2.04128\n",
      "[8284]\teval-rmse:3.9407\ttrain-rmse:2.04131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8285]\teval-rmse:3.93943\ttrain-rmse:2.04126\n",
      "[8286]\teval-rmse:3.9387\ttrain-rmse:2.04124\n",
      "[8287]\teval-rmse:3.93964\ttrain-rmse:2.04127\n",
      "[8288]\teval-rmse:3.9377\ttrain-rmse:2.04124\n",
      "[8289]\teval-rmse:3.93834\ttrain-rmse:2.04125\n",
      "[8290]\teval-rmse:3.93632\ttrain-rmse:2.04123\n",
      "[8291]\teval-rmse:3.93436\ttrain-rmse:2.04119\n",
      "[8292]\teval-rmse:3.93651\ttrain-rmse:2.04127\n",
      "[8293]\teval-rmse:3.9357\ttrain-rmse:2.04124\n",
      "[8294]\teval-rmse:3.93678\ttrain-rmse:2.04124\n",
      "[8295]\teval-rmse:3.93781\ttrain-rmse:2.04127\n",
      "[8296]\teval-rmse:3.93919\ttrain-rmse:2.0413\n",
      "[8297]\teval-rmse:3.94087\ttrain-rmse:2.0413\n",
      "[8298]\teval-rmse:3.94075\ttrain-rmse:2.0413\n",
      "[8299]\teval-rmse:3.94073\ttrain-rmse:2.0413\n",
      "[8300]\teval-rmse:3.94269\ttrain-rmse:2.04126\n",
      "[8301]\teval-rmse:3.94237\ttrain-rmse:2.04125\n",
      "[8302]\teval-rmse:3.94001\ttrain-rmse:2.04118\n",
      "[8303]\teval-rmse:3.93936\ttrain-rmse:2.04116\n",
      "[8304]\teval-rmse:3.94084\ttrain-rmse:2.0412\n",
      "[8305]\teval-rmse:3.94051\ttrain-rmse:2.04119\n",
      "[8306]\teval-rmse:3.94125\ttrain-rmse:2.0412\n",
      "[8307]\teval-rmse:3.94\ttrain-rmse:2.04115\n",
      "[8308]\teval-rmse:3.9406\ttrain-rmse:2.04115\n",
      "[8309]\teval-rmse:3.9403\ttrain-rmse:2.04115\n",
      "[8310]\teval-rmse:3.93915\ttrain-rmse:2.04117\n",
      "[8311]\teval-rmse:3.93758\ttrain-rmse:2.04113\n",
      "[8312]\teval-rmse:3.93678\ttrain-rmse:2.04111\n",
      "[8313]\teval-rmse:3.93758\ttrain-rmse:2.04112\n",
      "[8314]\teval-rmse:3.93962\ttrain-rmse:2.04114\n",
      "[8315]\teval-rmse:3.93937\ttrain-rmse:2.04114\n",
      "[8316]\teval-rmse:3.94082\ttrain-rmse:2.04116\n",
      "[8317]\teval-rmse:3.94247\ttrain-rmse:2.04117\n",
      "[8318]\teval-rmse:3.94167\ttrain-rmse:2.04085\n",
      "[8319]\teval-rmse:3.93916\ttrain-rmse:2.04081\n",
      "[8320]\teval-rmse:3.93929\ttrain-rmse:2.04082\n",
      "[8321]\teval-rmse:3.93934\ttrain-rmse:2.04082\n",
      "[8322]\teval-rmse:3.94104\ttrain-rmse:2.04087\n",
      "[8323]\teval-rmse:3.94306\ttrain-rmse:2.04092\n",
      "[8324]\teval-rmse:3.94503\ttrain-rmse:2.04094\n",
      "[8325]\teval-rmse:3.94429\ttrain-rmse:2.04091\n",
      "[8326]\teval-rmse:3.94653\ttrain-rmse:2.04088\n",
      "[8327]\teval-rmse:3.94673\ttrain-rmse:2.04088\n",
      "[8328]\teval-rmse:3.94585\ttrain-rmse:2.04084\n",
      "[8329]\teval-rmse:3.94386\ttrain-rmse:2.04075\n",
      "[8330]\teval-rmse:3.94297\ttrain-rmse:2.04072\n",
      "[8331]\teval-rmse:3.94357\ttrain-rmse:2.04074\n",
      "[8332]\teval-rmse:3.94426\ttrain-rmse:2.04075\n",
      "[8333]\teval-rmse:3.94298\ttrain-rmse:2.04072\n",
      "[8334]\teval-rmse:3.94384\ttrain-rmse:2.04074\n",
      "[8335]\teval-rmse:3.94306\ttrain-rmse:2.04034\n",
      "[8336]\teval-rmse:3.94446\ttrain-rmse:2.04039\n",
      "[8337]\teval-rmse:3.94516\ttrain-rmse:2.04041\n",
      "[8338]\teval-rmse:3.9431\ttrain-rmse:2.04033\n",
      "[8339]\teval-rmse:3.94168\ttrain-rmse:2.04027\n",
      "[8340]\teval-rmse:3.93972\ttrain-rmse:2.04021\n",
      "[8341]\teval-rmse:3.94197\ttrain-rmse:2.04016\n",
      "[8342]\teval-rmse:3.94318\ttrain-rmse:2.0402\n",
      "[8343]\teval-rmse:3.94531\ttrain-rmse:2.0403\n",
      "[8344]\teval-rmse:3.94753\ttrain-rmse:2.04027\n",
      "[8345]\teval-rmse:3.94897\ttrain-rmse:2.04032\n",
      "[8346]\teval-rmse:3.94768\ttrain-rmse:2.04025\n",
      "[8347]\teval-rmse:3.94532\ttrain-rmse:2.04015\n",
      "[8348]\teval-rmse:3.94681\ttrain-rmse:2.0402\n",
      "[8349]\teval-rmse:3.94488\ttrain-rmse:2.04011\n",
      "[8350]\teval-rmse:3.94282\ttrain-rmse:2.04003\n",
      "[8351]\teval-rmse:3.94163\ttrain-rmse:2.04002\n",
      "[8352]\teval-rmse:3.94262\ttrain-rmse:2.04005\n",
      "[8353]\teval-rmse:3.94485\ttrain-rmse:2.04001\n",
      "[8354]\teval-rmse:3.94425\ttrain-rmse:2.03999\n",
      "[8355]\teval-rmse:3.94603\ttrain-rmse:2.04006\n",
      "[8356]\teval-rmse:3.94389\ttrain-rmse:2.04\n",
      "[8357]\teval-rmse:3.94261\ttrain-rmse:2.03995\n",
      "[8358]\teval-rmse:3.94233\ttrain-rmse:2.03994\n",
      "[8359]\teval-rmse:3.94275\ttrain-rmse:2.03995\n",
      "[8360]\teval-rmse:3.94145\ttrain-rmse:2.03996\n",
      "[8361]\teval-rmse:3.94292\ttrain-rmse:2.04001\n",
      "[8362]\teval-rmse:3.94328\ttrain-rmse:2.04002\n",
      "[8363]\teval-rmse:3.9412\ttrain-rmse:2.04\n",
      "[8364]\teval-rmse:3.94093\ttrain-rmse:2.03998\n",
      "[8365]\teval-rmse:3.94067\ttrain-rmse:2.03997\n",
      "[8366]\teval-rmse:3.93937\ttrain-rmse:2.03998\n",
      "[8367]\teval-rmse:3.93968\ttrain-rmse:2.03999\n",
      "[8368]\teval-rmse:3.93886\ttrain-rmse:2.03995\n",
      "[8369]\teval-rmse:3.93652\ttrain-rmse:2.03991\n",
      "[8370]\teval-rmse:3.93849\ttrain-rmse:2.03992\n",
      "[8371]\teval-rmse:3.93774\ttrain-rmse:2.0399\n",
      "[8372]\teval-rmse:3.93646\ttrain-rmse:2.03992\n",
      "[8373]\teval-rmse:3.9352\ttrain-rmse:2.03995\n",
      "[8374]\teval-rmse:3.93413\ttrain-rmse:2.03994\n",
      "[8375]\teval-rmse:3.93507\ttrain-rmse:2.03996\n",
      "[8376]\teval-rmse:3.93517\ttrain-rmse:2.03996\n",
      "[8377]\teval-rmse:3.93325\ttrain-rmse:2.03992\n",
      "[8378]\teval-rmse:3.93529\ttrain-rmse:2.03993\n",
      "[8379]\teval-rmse:3.93467\ttrain-rmse:2.03992\n",
      "[8380]\teval-rmse:3.9334\ttrain-rmse:2.03991\n",
      "[8381]\teval-rmse:3.93315\ttrain-rmse:2.0399\n",
      "[8382]\teval-rmse:3.93241\ttrain-rmse:2.03956\n",
      "[8383]\teval-rmse:3.93213\ttrain-rmse:2.03955\n",
      "[8384]\teval-rmse:3.93\ttrain-rmse:2.03952\n",
      "[8385]\teval-rmse:3.92919\ttrain-rmse:2.03918\n",
      "[8386]\teval-rmse:3.92939\ttrain-rmse:2.03918\n",
      "[8387]\teval-rmse:3.92904\ttrain-rmse:2.03918\n",
      "[8388]\teval-rmse:3.92707\ttrain-rmse:2.03916\n",
      "[8389]\teval-rmse:3.92876\ttrain-rmse:2.03914\n",
      "[8390]\teval-rmse:3.92842\ttrain-rmse:2.03913\n",
      "[8391]\teval-rmse:3.92913\ttrain-rmse:2.03914\n",
      "[8392]\teval-rmse:3.92791\ttrain-rmse:2.03911\n",
      "[8393]\teval-rmse:3.92821\ttrain-rmse:2.03911\n",
      "[8394]\teval-rmse:3.92698\ttrain-rmse:2.03915\n",
      "[8395]\teval-rmse:3.92914\ttrain-rmse:2.03921\n",
      "[8396]\teval-rmse:3.93039\ttrain-rmse:2.03916\n",
      "[8397]\teval-rmse:3.92834\ttrain-rmse:2.03913\n",
      "[8398]\teval-rmse:3.92984\ttrain-rmse:2.03914\n",
      "[8399]\teval-rmse:3.92874\ttrain-rmse:2.03915\n",
      "[8400]\teval-rmse:3.92754\ttrain-rmse:2.03911\n",
      "[8401]\teval-rmse:3.92814\ttrain-rmse:2.03911\n",
      "[8402]\teval-rmse:3.92788\ttrain-rmse:2.03911\n",
      "[8403]\teval-rmse:3.92975\ttrain-rmse:2.03912\n",
      "[8404]\teval-rmse:3.92855\ttrain-rmse:2.03909\n",
      "[8405]\teval-rmse:3.92786\ttrain-rmse:2.03908\n",
      "[8406]\teval-rmse:3.92863\ttrain-rmse:2.03908\n",
      "[8407]\teval-rmse:3.92718\ttrain-rmse:2.0391\n",
      "[8408]\teval-rmse:3.92799\ttrain-rmse:2.03909\n",
      "[8409]\teval-rmse:3.92987\ttrain-rmse:2.03911\n",
      "[8410]\teval-rmse:3.92913\ttrain-rmse:2.0388\n",
      "[8411]\teval-rmse:3.92917\ttrain-rmse:2.0388\n",
      "[8412]\teval-rmse:3.93043\ttrain-rmse:2.03875\n",
      "[8413]\teval-rmse:3.92924\ttrain-rmse:2.03871\n",
      "[8414]\teval-rmse:3.93016\ttrain-rmse:2.0387\n",
      "[8415]\teval-rmse:3.92947\ttrain-rmse:2.03869\n",
      "[8416]\teval-rmse:3.92937\ttrain-rmse:2.03869\n",
      "[8417]\teval-rmse:3.93008\ttrain-rmse:2.03869\n",
      "[8418]\teval-rmse:3.93235\ttrain-rmse:2.03871\n",
      "[8419]\teval-rmse:3.93046\ttrain-rmse:2.03868\n",
      "[8420]\teval-rmse:3.92835\ttrain-rmse:2.03865\n",
      "[8421]\teval-rmse:3.92755\ttrain-rmse:2.03863\n",
      "[8422]\teval-rmse:3.92633\ttrain-rmse:2.0386\n",
      "[8423]\teval-rmse:3.92661\ttrain-rmse:2.0386\n",
      "[8424]\teval-rmse:3.92788\ttrain-rmse:2.0386\n",
      "[8425]\teval-rmse:3.92709\ttrain-rmse:2.03827\n",
      "[8426]\teval-rmse:3.9263\ttrain-rmse:2.03824\n",
      "[8427]\teval-rmse:3.92845\ttrain-rmse:2.03816\n",
      "[8428]\teval-rmse:3.92848\ttrain-rmse:2.03816\n",
      "[8429]\teval-rmse:3.92823\ttrain-rmse:2.03815\n",
      "[8430]\teval-rmse:3.92608\ttrain-rmse:2.03812\n",
      "[8431]\teval-rmse:3.92703\ttrain-rmse:2.03813\n",
      "[8432]\teval-rmse:3.92641\ttrain-rmse:2.03812\n",
      "[8433]\teval-rmse:3.92621\ttrain-rmse:2.03812\n",
      "[8434]\teval-rmse:3.92585\ttrain-rmse:2.03811\n",
      "[8435]\teval-rmse:3.92362\ttrain-rmse:2.03811\n",
      "[8436]\teval-rmse:3.92339\ttrain-rmse:2.03811\n",
      "[8437]\teval-rmse:3.92393\ttrain-rmse:2.03811\n",
      "[8438]\teval-rmse:3.92472\ttrain-rmse:2.03811\n",
      "[8439]\teval-rmse:3.92467\ttrain-rmse:2.03811\n",
      "[8440]\teval-rmse:3.92266\ttrain-rmse:2.0381\n",
      "[8441]\teval-rmse:3.9246\ttrain-rmse:2.03809\n",
      "[8442]\teval-rmse:3.92512\ttrain-rmse:2.0381\n",
      "[8443]\teval-rmse:3.92709\ttrain-rmse:2.03811\n",
      "[8444]\teval-rmse:3.92823\ttrain-rmse:2.03811\n",
      "[8445]\teval-rmse:3.92744\ttrain-rmse:2.03777\n",
      "[8446]\teval-rmse:3.92712\ttrain-rmse:2.03776\n",
      "[8447]\teval-rmse:3.92858\ttrain-rmse:2.03777\n",
      "[8448]\teval-rmse:3.93054\ttrain-rmse:2.03781\n",
      "[8449]\teval-rmse:3.9309\ttrain-rmse:2.03782\n",
      "[8450]\teval-rmse:3.93235\ttrain-rmse:2.03785\n",
      "[8451]\teval-rmse:3.93248\ttrain-rmse:2.03785\n",
      "[8452]\teval-rmse:3.93076\ttrain-rmse:2.03789\n",
      "[8453]\teval-rmse:3.93079\ttrain-rmse:2.03789\n",
      "[8454]\teval-rmse:3.92856\ttrain-rmse:2.03785\n",
      "[8455]\teval-rmse:3.93073\ttrain-rmse:2.03792\n",
      "[8456]\teval-rmse:3.92865\ttrain-rmse:2.03789\n",
      "[8457]\teval-rmse:3.92982\ttrain-rmse:2.03791\n",
      "[8458]\teval-rmse:3.92793\ttrain-rmse:2.03788\n",
      "[8459]\teval-rmse:3.92639\ttrain-rmse:2.03789\n",
      "[8460]\teval-rmse:3.92711\ttrain-rmse:2.0379\n",
      "[8461]\teval-rmse:3.92589\ttrain-rmse:2.03787\n",
      "[8462]\teval-rmse:3.92554\ttrain-rmse:2.03786\n",
      "[8463]\teval-rmse:3.92331\ttrain-rmse:2.03785\n",
      "[8464]\teval-rmse:3.92164\ttrain-rmse:2.03791\n",
      "[8465]\teval-rmse:3.9218\ttrain-rmse:2.03791\n",
      "[8466]\teval-rmse:3.92264\ttrain-rmse:2.03792\n",
      "[8467]\teval-rmse:3.92359\ttrain-rmse:2.03792\n",
      "[8468]\teval-rmse:3.92584\ttrain-rmse:2.03793\n",
      "[8469]\teval-rmse:3.92367\ttrain-rmse:2.03792\n",
      "[8470]\teval-rmse:3.92292\ttrain-rmse:2.03756\n",
      "[8471]\teval-rmse:3.92367\ttrain-rmse:2.03756\n",
      "[8472]\teval-rmse:3.92245\ttrain-rmse:2.03761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8473]\teval-rmse:3.92172\ttrain-rmse:2.03761\n",
      "[8474]\teval-rmse:3.92063\ttrain-rmse:2.03765\n",
      "[8475]\teval-rmse:3.92191\ttrain-rmse:2.03758\n",
      "[8476]\teval-rmse:3.92169\ttrain-rmse:2.03758\n",
      "[8477]\teval-rmse:3.92048\ttrain-rmse:2.03763\n",
      "[8478]\teval-rmse:3.91874\ttrain-rmse:2.03763\n",
      "[8479]\teval-rmse:3.91894\ttrain-rmse:2.03763\n",
      "[8480]\teval-rmse:3.91766\ttrain-rmse:2.03764\n",
      "[8481]\teval-rmse:3.9198\ttrain-rmse:2.03753\n",
      "[8482]\teval-rmse:3.92194\ttrain-rmse:2.03751\n",
      "[8483]\teval-rmse:3.92291\ttrain-rmse:2.03749\n",
      "[8484]\teval-rmse:3.92461\ttrain-rmse:2.0375\n",
      "[8485]\teval-rmse:3.926\ttrain-rmse:2.03751\n",
      "[8486]\teval-rmse:3.9253\ttrain-rmse:2.0375\n",
      "[8487]\teval-rmse:3.92515\ttrain-rmse:2.0375\n",
      "[8488]\teval-rmse:3.92444\ttrain-rmse:2.03721\n",
      "[8489]\teval-rmse:3.92341\ttrain-rmse:2.03722\n",
      "[8490]\teval-rmse:3.92202\ttrain-rmse:2.03721\n",
      "[8491]\teval-rmse:3.92372\ttrain-rmse:2.03723\n",
      "[8492]\teval-rmse:3.92193\ttrain-rmse:2.03723\n",
      "[8493]\teval-rmse:3.92164\ttrain-rmse:2.03723\n",
      "[8494]\teval-rmse:3.92293\ttrain-rmse:2.03723\n",
      "[8495]\teval-rmse:3.92095\ttrain-rmse:2.03727\n",
      "[8496]\teval-rmse:3.91945\ttrain-rmse:2.03726\n",
      "[8497]\teval-rmse:3.91816\ttrain-rmse:2.03726\n",
      "[8498]\teval-rmse:3.91707\ttrain-rmse:2.03731\n",
      "[8499]\teval-rmse:3.91677\ttrain-rmse:2.03731\n",
      "[8500]\teval-rmse:3.91692\ttrain-rmse:2.03731\n",
      "[8501]\teval-rmse:3.91761\ttrain-rmse:2.0373\n",
      "[8502]\teval-rmse:3.91931\ttrain-rmse:2.03729\n",
      "[8503]\teval-rmse:3.91789\ttrain-rmse:2.0373\n",
      "[8504]\teval-rmse:3.9193\ttrain-rmse:2.03731\n",
      "[8505]\teval-rmse:3.91912\ttrain-rmse:2.0373\n",
      "[8506]\teval-rmse:3.91881\ttrain-rmse:2.0373\n",
      "[8507]\teval-rmse:3.92065\ttrain-rmse:2.03725\n",
      "[8508]\teval-rmse:3.91808\ttrain-rmse:2.03725\n",
      "[8509]\teval-rmse:3.91777\ttrain-rmse:2.03725\n",
      "[8510]\teval-rmse:3.91702\ttrain-rmse:2.03724\n",
      "[8511]\teval-rmse:3.91902\ttrain-rmse:2.03713\n",
      "[8512]\teval-rmse:3.92009\ttrain-rmse:2.03713\n",
      "[8513]\teval-rmse:3.91831\ttrain-rmse:2.03714\n",
      "[8514]\teval-rmse:3.92047\ttrain-rmse:2.03715\n",
      "[8515]\teval-rmse:3.91905\ttrain-rmse:2.03718\n",
      "[8516]\teval-rmse:3.91957\ttrain-rmse:2.03718\n",
      "[8517]\teval-rmse:3.92105\ttrain-rmse:2.03718\n",
      "[8518]\teval-rmse:3.9222\ttrain-rmse:2.03718\n",
      "[8519]\teval-rmse:3.92241\ttrain-rmse:2.03719\n",
      "[8520]\teval-rmse:3.92132\ttrain-rmse:2.0372\n",
      "[8521]\teval-rmse:3.92098\ttrain-rmse:2.0372\n",
      "[8522]\teval-rmse:3.92069\ttrain-rmse:2.03719\n",
      "[8523]\teval-rmse:3.91871\ttrain-rmse:2.03724\n",
      "[8524]\teval-rmse:3.91706\ttrain-rmse:2.03732\n",
      "[8525]\teval-rmse:3.91836\ttrain-rmse:2.03724\n",
      "[8526]\teval-rmse:3.91659\ttrain-rmse:2.03724\n",
      "[8527]\teval-rmse:3.91788\ttrain-rmse:2.03724\n",
      "[8528]\teval-rmse:3.92004\ttrain-rmse:2.03727\n",
      "[8529]\teval-rmse:3.9223\ttrain-rmse:2.03728\n",
      "[8530]\teval-rmse:3.92335\ttrain-rmse:2.03729\n",
      "[8531]\teval-rmse:3.92332\ttrain-rmse:2.03729\n",
      "[8532]\teval-rmse:3.92545\ttrain-rmse:2.0372\n",
      "[8533]\teval-rmse:3.92526\ttrain-rmse:2.03719\n",
      "[8534]\teval-rmse:3.92372\ttrain-rmse:2.03721\n",
      "[8535]\teval-rmse:3.92177\ttrain-rmse:2.0372\n",
      "[8536]\teval-rmse:3.92402\ttrain-rmse:2.03709\n",
      "[8537]\teval-rmse:3.92587\ttrain-rmse:2.03711\n",
      "[8538]\teval-rmse:3.92622\ttrain-rmse:2.03712\n",
      "[8539]\teval-rmse:3.92511\ttrain-rmse:2.0371\n",
      "[8540]\teval-rmse:3.92649\ttrain-rmse:2.03708\n",
      "[8541]\teval-rmse:3.92571\ttrain-rmse:2.03679\n",
      "[8542]\teval-rmse:3.92506\ttrain-rmse:2.03679\n",
      "[8543]\teval-rmse:3.92394\ttrain-rmse:2.03678\n",
      "[8544]\teval-rmse:3.92132\ttrain-rmse:2.03675\n",
      "[8545]\teval-rmse:3.9218\ttrain-rmse:2.03676\n",
      "[8546]\teval-rmse:3.92294\ttrain-rmse:2.03677\n",
      "[8547]\teval-rmse:3.924\ttrain-rmse:2.03675\n",
      "[8548]\teval-rmse:3.92282\ttrain-rmse:2.03672\n",
      "[8549]\teval-rmse:3.92259\ttrain-rmse:2.03672\n",
      "[8550]\teval-rmse:3.92356\ttrain-rmse:2.03672\n",
      "[8551]\teval-rmse:3.92325\ttrain-rmse:2.03671\n",
      "[8552]\teval-rmse:3.92309\ttrain-rmse:2.03671\n",
      "[8553]\teval-rmse:3.92396\ttrain-rmse:2.03672\n",
      "[8554]\teval-rmse:3.92179\ttrain-rmse:2.03671\n",
      "[8555]\teval-rmse:3.92223\ttrain-rmse:2.03671\n",
      "[8556]\teval-rmse:3.92111\ttrain-rmse:2.03673\n",
      "[8557]\teval-rmse:3.91937\ttrain-rmse:2.03673\n",
      "[8558]\teval-rmse:3.9188\ttrain-rmse:2.03673\n",
      "[8559]\teval-rmse:3.92097\ttrain-rmse:2.03677\n",
      "[8560]\teval-rmse:3.92294\ttrain-rmse:2.03677\n",
      "[8561]\teval-rmse:3.92415\ttrain-rmse:2.03679\n",
      "[8562]\teval-rmse:3.9246\ttrain-rmse:2.03679\n",
      "[8563]\teval-rmse:3.92456\ttrain-rmse:2.03679\n",
      "[8564]\teval-rmse:3.92438\ttrain-rmse:2.03678\n",
      "[8565]\teval-rmse:3.92345\ttrain-rmse:2.03678\n",
      "[8566]\teval-rmse:3.92206\ttrain-rmse:2.03678\n",
      "[8567]\teval-rmse:3.92098\ttrain-rmse:2.03677\n",
      "[8568]\teval-rmse:3.9224\ttrain-rmse:2.03679\n",
      "[8569]\teval-rmse:3.92131\ttrain-rmse:2.03681\n",
      "[8570]\teval-rmse:3.91981\ttrain-rmse:2.03681\n",
      "[8571]\teval-rmse:3.92118\ttrain-rmse:2.03681\n",
      "[8572]\teval-rmse:3.92146\ttrain-rmse:2.03681\n",
      "[8573]\teval-rmse:3.92296\ttrain-rmse:2.03682\n",
      "[8574]\teval-rmse:3.92435\ttrain-rmse:2.03683\n",
      "[8575]\teval-rmse:3.92507\ttrain-rmse:2.03683\n",
      "[8576]\teval-rmse:3.92387\ttrain-rmse:2.03681\n",
      "[8577]\teval-rmse:3.92354\ttrain-rmse:2.0368\n",
      "[8578]\teval-rmse:3.92461\ttrain-rmse:2.03681\n",
      "[8579]\teval-rmse:3.92464\ttrain-rmse:2.03681\n",
      "[8580]\teval-rmse:3.92404\ttrain-rmse:2.03681\n",
      "[8581]\teval-rmse:3.92281\ttrain-rmse:2.03679\n",
      "[8582]\teval-rmse:3.92064\ttrain-rmse:2.03679\n",
      "[8583]\teval-rmse:3.91996\ttrain-rmse:2.03679\n",
      "[8584]\teval-rmse:3.91927\ttrain-rmse:2.03649\n",
      "[8585]\teval-rmse:3.91865\ttrain-rmse:2.03649\n",
      "[8586]\teval-rmse:3.91941\ttrain-rmse:2.03649\n",
      "[8587]\teval-rmse:3.91779\ttrain-rmse:2.03648\n",
      "[8588]\teval-rmse:3.91682\ttrain-rmse:2.03649\n",
      "[8589]\teval-rmse:3.91735\ttrain-rmse:2.03648\n",
      "[8590]\teval-rmse:3.91921\ttrain-rmse:2.03648\n",
      "[8591]\teval-rmse:3.91847\ttrain-rmse:2.03614\n",
      "[8592]\teval-rmse:3.92062\ttrain-rmse:2.03615\n",
      "[8593]\teval-rmse:3.92138\ttrain-rmse:2.03616\n",
      "[8594]\teval-rmse:3.92238\ttrain-rmse:2.03617\n",
      "[8595]\teval-rmse:3.92043\ttrain-rmse:2.03616\n",
      "[8596]\teval-rmse:3.92028\ttrain-rmse:2.03616\n",
      "[8597]\teval-rmse:3.91858\ttrain-rmse:2.03617\n",
      "[8598]\teval-rmse:3.91631\ttrain-rmse:2.03617\n",
      "[8599]\teval-rmse:3.91611\ttrain-rmse:2.03616\n",
      "[8600]\teval-rmse:3.91749\ttrain-rmse:2.03612\n",
      "[8601]\teval-rmse:3.91609\ttrain-rmse:2.03613\n",
      "[8602]\teval-rmse:3.91517\ttrain-rmse:2.03613\n",
      "[8603]\teval-rmse:3.91357\ttrain-rmse:2.03615\n",
      "[8604]\teval-rmse:3.91432\ttrain-rmse:2.03615\n",
      "[8605]\teval-rmse:3.9141\ttrain-rmse:2.03615\n",
      "[8606]\teval-rmse:3.91527\ttrain-rmse:2.03614\n",
      "[8607]\teval-rmse:3.91366\ttrain-rmse:2.03619\n",
      "[8608]\teval-rmse:3.91207\ttrain-rmse:2.03628\n",
      "[8609]\teval-rmse:3.91348\ttrain-rmse:2.03626\n",
      "[8610]\teval-rmse:3.91173\ttrain-rmse:2.03629\n",
      "[8611]\teval-rmse:3.91067\ttrain-rmse:2.03631\n",
      "[8612]\teval-rmse:3.91143\ttrain-rmse:2.0363\n",
      "[8613]\teval-rmse:3.91167\ttrain-rmse:2.03629\n",
      "[8614]\teval-rmse:3.91063\ttrain-rmse:2.03631\n",
      "[8615]\teval-rmse:3.91196\ttrain-rmse:2.03628\n",
      "[8616]\teval-rmse:3.91009\ttrain-rmse:2.03631\n",
      "[8617]\teval-rmse:3.91154\ttrain-rmse:2.03629\n",
      "[8618]\teval-rmse:3.91038\ttrain-rmse:2.03636\n",
      "[8619]\teval-rmse:3.91024\ttrain-rmse:2.03635\n",
      "[8620]\teval-rmse:3.90918\ttrain-rmse:2.03638\n",
      "[8621]\teval-rmse:3.91088\ttrain-rmse:2.03633\n",
      "[8622]\teval-rmse:3.90942\ttrain-rmse:2.03635\n",
      "[8623]\teval-rmse:3.90746\ttrain-rmse:2.03639\n",
      "[8624]\teval-rmse:3.90934\ttrain-rmse:2.03634\n",
      "[8625]\teval-rmse:3.91083\ttrain-rmse:2.03632\n",
      "[8626]\teval-rmse:3.91071\ttrain-rmse:2.03631\n",
      "[8627]\teval-rmse:3.90844\ttrain-rmse:2.03635\n",
      "[8628]\teval-rmse:3.9074\ttrain-rmse:2.03642\n",
      "[8629]\teval-rmse:3.90728\ttrain-rmse:2.03642\n",
      "[8630]\teval-rmse:3.9055\ttrain-rmse:2.0365\n",
      "[8631]\teval-rmse:3.90749\ttrain-rmse:2.03645\n",
      "[8632]\teval-rmse:3.90593\ttrain-rmse:2.0365\n",
      "[8633]\teval-rmse:3.90449\ttrain-rmse:2.03654\n",
      "[8634]\teval-rmse:3.90379\ttrain-rmse:2.03657\n",
      "[8635]\teval-rmse:3.90471\ttrain-rmse:2.03654\n",
      "[8636]\teval-rmse:3.90563\ttrain-rmse:2.03652\n",
      "[8637]\teval-rmse:3.90544\ttrain-rmse:2.03652\n",
      "[8638]\teval-rmse:3.90485\ttrain-rmse:2.03654\n",
      "[8639]\teval-rmse:3.90299\ttrain-rmse:2.0366\n",
      "[8640]\teval-rmse:3.90504\ttrain-rmse:2.03652\n",
      "[8641]\teval-rmse:3.90482\ttrain-rmse:2.03651\n",
      "[8642]\teval-rmse:3.90522\ttrain-rmse:2.0365\n",
      "[8643]\teval-rmse:3.90632\ttrain-rmse:2.03645\n",
      "[8644]\teval-rmse:3.90617\ttrain-rmse:2.03645\n",
      "[8645]\teval-rmse:3.9076\ttrain-rmse:2.03641\n",
      "[8646]\teval-rmse:3.90941\ttrain-rmse:2.03636\n",
      "[8647]\teval-rmse:3.90808\ttrain-rmse:2.03638\n",
      "[8648]\teval-rmse:3.90892\ttrain-rmse:2.03637\n",
      "[8649]\teval-rmse:3.90747\ttrain-rmse:2.03643\n",
      "[8650]\teval-rmse:3.90646\ttrain-rmse:2.03648\n",
      "[8651]\teval-rmse:3.90763\ttrain-rmse:2.03645\n",
      "[8652]\teval-rmse:3.9081\ttrain-rmse:2.03643\n",
      "[8653]\teval-rmse:3.9058\ttrain-rmse:2.0365\n",
      "[8654]\teval-rmse:3.90648\ttrain-rmse:2.03649\n",
      "[8655]\teval-rmse:3.90664\ttrain-rmse:2.03648\n",
      "[8656]\teval-rmse:3.90563\ttrain-rmse:2.03651\n",
      "[8657]\teval-rmse:3.90516\ttrain-rmse:2.03653\n",
      "[8658]\teval-rmse:3.90306\ttrain-rmse:2.03659\n",
      "[8659]\teval-rmse:3.90279\ttrain-rmse:2.0366\n",
      "[8660]\teval-rmse:3.90219\ttrain-rmse:2.03631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8661]\teval-rmse:3.90192\ttrain-rmse:2.03632\n",
      "[8662]\teval-rmse:3.90417\ttrain-rmse:2.0362\n",
      "[8663]\teval-rmse:3.90482\ttrain-rmse:2.03617\n",
      "[8664]\teval-rmse:3.90393\ttrain-rmse:2.0362\n",
      "[8665]\teval-rmse:3.90325\ttrain-rmse:2.03586\n",
      "[8666]\teval-rmse:3.9047\ttrain-rmse:2.03581\n",
      "[8667]\teval-rmse:3.90478\ttrain-rmse:2.03581\n",
      "[8668]\teval-rmse:3.90694\ttrain-rmse:2.03581\n",
      "[8669]\teval-rmse:3.90561\ttrain-rmse:2.03587\n",
      "[8670]\teval-rmse:3.90344\ttrain-rmse:2.03595\n",
      "[8671]\teval-rmse:3.90496\ttrain-rmse:2.0359\n",
      "[8672]\teval-rmse:3.90435\ttrain-rmse:2.03563\n",
      "[8673]\teval-rmse:3.90634\ttrain-rmse:2.03558\n",
      "[8674]\teval-rmse:3.90803\ttrain-rmse:2.03554\n",
      "[8675]\teval-rmse:3.90899\ttrain-rmse:2.0355\n",
      "[8676]\teval-rmse:3.90746\ttrain-rmse:2.03554\n",
      "[8677]\teval-rmse:3.90741\ttrain-rmse:2.03554\n",
      "[8678]\teval-rmse:3.90647\ttrain-rmse:2.03556\n",
      "[8679]\teval-rmse:3.90758\ttrain-rmse:2.03554\n",
      "[8680]\teval-rmse:3.90594\ttrain-rmse:2.03557\n",
      "[8681]\teval-rmse:3.90525\ttrain-rmse:2.03557\n",
      "[8682]\teval-rmse:3.90542\ttrain-rmse:2.03556\n",
      "[8683]\teval-rmse:3.9045\ttrain-rmse:2.0356\n",
      "[8684]\teval-rmse:3.90591\ttrain-rmse:2.03554\n",
      "[8685]\teval-rmse:3.90742\ttrain-rmse:2.0355\n",
      "[8686]\teval-rmse:3.90563\ttrain-rmse:2.03554\n",
      "[8687]\teval-rmse:3.90704\ttrain-rmse:2.03551\n",
      "[8688]\teval-rmse:3.90613\ttrain-rmse:2.03555\n",
      "[8689]\teval-rmse:3.90602\ttrain-rmse:2.03555\n",
      "[8690]\teval-rmse:3.90464\ttrain-rmse:2.03561\n",
      "[8691]\teval-rmse:3.90488\ttrain-rmse:2.0356\n",
      "[8692]\teval-rmse:3.90323\ttrain-rmse:2.03565\n",
      "[8693]\teval-rmse:3.90433\ttrain-rmse:2.03561\n",
      "[8694]\teval-rmse:3.90489\ttrain-rmse:2.03559\n",
      "[8695]\teval-rmse:3.90358\ttrain-rmse:2.03563\n",
      "[8696]\teval-rmse:3.9053\ttrain-rmse:2.03558\n",
      "[8697]\teval-rmse:3.90327\ttrain-rmse:2.03566\n",
      "[8698]\teval-rmse:3.90339\ttrain-rmse:2.03565\n",
      "[8699]\teval-rmse:3.90446\ttrain-rmse:2.03559\n",
      "[8700]\teval-rmse:3.90389\ttrain-rmse:2.03561\n",
      "[8701]\teval-rmse:3.90463\ttrain-rmse:2.03559\n",
      "[8702]\teval-rmse:3.90221\ttrain-rmse:2.03566\n",
      "[8703]\teval-rmse:3.9008\ttrain-rmse:2.03571\n",
      "[8704]\teval-rmse:3.89984\ttrain-rmse:2.03574\n",
      "[8705]\teval-rmse:3.89776\ttrain-rmse:2.03582\n",
      "[8706]\teval-rmse:3.89997\ttrain-rmse:2.0358\n",
      "[8707]\teval-rmse:3.89867\ttrain-rmse:2.03585\n",
      "[8708]\teval-rmse:3.90088\ttrain-rmse:2.03583\n",
      "[8709]\teval-rmse:3.89978\ttrain-rmse:2.03589\n",
      "[8710]\teval-rmse:3.90117\ttrain-rmse:2.03583\n",
      "[8711]\teval-rmse:3.90214\ttrain-rmse:2.03578\n",
      "[8712]\teval-rmse:3.90149\ttrain-rmse:2.03548\n",
      "[8713]\teval-rmse:3.90105\ttrain-rmse:2.03549\n",
      "[8714]\teval-rmse:3.90137\ttrain-rmse:2.03548\n",
      "[8715]\teval-rmse:3.90287\ttrain-rmse:2.03543\n",
      "[8716]\teval-rmse:3.90315\ttrain-rmse:2.03541\n",
      "[8717]\teval-rmse:3.90442\ttrain-rmse:2.03536\n",
      "[8718]\teval-rmse:3.90559\ttrain-rmse:2.03533\n",
      "[8719]\teval-rmse:3.9076\ttrain-rmse:2.03528\n",
      "[8720]\teval-rmse:3.90649\ttrain-rmse:2.03528\n",
      "[8721]\teval-rmse:3.90631\ttrain-rmse:2.03528\n",
      "[8722]\teval-rmse:3.90733\ttrain-rmse:2.03526\n",
      "[8723]\teval-rmse:3.9065\ttrain-rmse:2.03529\n",
      "[8724]\teval-rmse:3.90779\ttrain-rmse:2.03526\n",
      "[8725]\teval-rmse:3.90583\ttrain-rmse:2.0353\n",
      "[8726]\teval-rmse:3.9047\ttrain-rmse:2.0353\n",
      "[8727]\teval-rmse:3.90327\ttrain-rmse:2.03537\n",
      "[8728]\teval-rmse:3.90193\ttrain-rmse:2.03544\n",
      "[8729]\teval-rmse:3.89973\ttrain-rmse:2.03554\n",
      "[8730]\teval-rmse:3.90054\ttrain-rmse:2.0355\n",
      "[8731]\teval-rmse:3.90087\ttrain-rmse:2.03548\n",
      "[8732]\teval-rmse:3.90071\ttrain-rmse:2.03549\n",
      "[8733]\teval-rmse:3.90053\ttrain-rmse:2.0355\n",
      "[8734]\teval-rmse:3.90131\ttrain-rmse:2.03547\n",
      "[8735]\teval-rmse:3.90223\ttrain-rmse:2.03543\n",
      "[8736]\teval-rmse:3.90232\ttrain-rmse:2.03542\n",
      "[8737]\teval-rmse:3.90136\ttrain-rmse:2.03545\n",
      "[8738]\teval-rmse:3.90326\ttrain-rmse:2.03539\n",
      "[8739]\teval-rmse:3.90235\ttrain-rmse:2.03542\n",
      "[8740]\teval-rmse:3.90144\ttrain-rmse:2.03546\n",
      "[8741]\teval-rmse:3.90267\ttrain-rmse:2.0354\n",
      "[8742]\teval-rmse:3.90488\ttrain-rmse:2.03539\n",
      "[8743]\teval-rmse:3.90422\ttrain-rmse:2.03539\n",
      "[8744]\teval-rmse:3.90503\ttrain-rmse:2.03537\n",
      "[8745]\teval-rmse:3.90631\ttrain-rmse:2.03533\n",
      "[8746]\teval-rmse:3.90498\ttrain-rmse:2.03539\n",
      "[8747]\teval-rmse:3.90599\ttrain-rmse:2.03536\n",
      "[8748]\teval-rmse:3.90509\ttrain-rmse:2.03539\n",
      "[8749]\teval-rmse:3.90408\ttrain-rmse:2.03542\n",
      "[8750]\teval-rmse:3.90219\ttrain-rmse:2.03547\n",
      "[8751]\teval-rmse:3.9007\ttrain-rmse:2.03552\n",
      "[8752]\teval-rmse:3.9019\ttrain-rmse:2.03548\n",
      "[8753]\teval-rmse:3.90167\ttrain-rmse:2.03547\n",
      "[8754]\teval-rmse:3.90265\ttrain-rmse:2.03544\n",
      "[8755]\teval-rmse:3.90374\ttrain-rmse:2.0354\n",
      "[8756]\teval-rmse:3.90502\ttrain-rmse:2.03537\n",
      "[8757]\teval-rmse:3.90475\ttrain-rmse:2.03538\n",
      "[8758]\teval-rmse:3.90365\ttrain-rmse:2.03537\n",
      "[8759]\teval-rmse:3.90536\ttrain-rmse:2.03534\n",
      "[8760]\teval-rmse:3.90666\ttrain-rmse:2.0353\n",
      "[8761]\teval-rmse:3.90852\ttrain-rmse:2.03527\n",
      "[8762]\teval-rmse:3.90853\ttrain-rmse:2.03527\n",
      "[8763]\teval-rmse:3.9075\ttrain-rmse:2.03528\n",
      "[8764]\teval-rmse:3.90763\ttrain-rmse:2.03528\n",
      "[8765]\teval-rmse:3.90788\ttrain-rmse:2.03527\n",
      "[8766]\teval-rmse:3.90815\ttrain-rmse:2.03527\n",
      "[8767]\teval-rmse:3.90931\ttrain-rmse:2.03525\n",
      "[8768]\teval-rmse:3.90822\ttrain-rmse:2.03524\n",
      "[8769]\teval-rmse:3.90875\ttrain-rmse:2.03524\n",
      "[8770]\teval-rmse:3.91076\ttrain-rmse:2.03516\n",
      "[8771]\teval-rmse:3.91142\ttrain-rmse:2.03516\n",
      "[8772]\teval-rmse:3.91166\ttrain-rmse:2.03516\n",
      "[8773]\teval-rmse:3.91148\ttrain-rmse:2.03515\n",
      "[8774]\teval-rmse:3.90915\ttrain-rmse:2.03516\n",
      "[8775]\teval-rmse:3.90805\ttrain-rmse:2.03516\n",
      "[8776]\teval-rmse:3.9078\ttrain-rmse:2.03515\n",
      "[8777]\teval-rmse:3.90718\ttrain-rmse:2.03485\n",
      "[8778]\teval-rmse:3.90832\ttrain-rmse:2.03484\n",
      "[8779]\teval-rmse:3.90965\ttrain-rmse:2.03482\n",
      "[8780]\teval-rmse:3.91039\ttrain-rmse:2.03481\n",
      "[8781]\teval-rmse:3.91184\ttrain-rmse:2.0348\n",
      "[8782]\teval-rmse:3.91289\ttrain-rmse:2.0348\n",
      "[8783]\teval-rmse:3.91271\ttrain-rmse:2.0348\n",
      "[8784]\teval-rmse:3.9113\ttrain-rmse:2.0348\n",
      "[8785]\teval-rmse:3.91348\ttrain-rmse:2.03483\n",
      "[8786]\teval-rmse:3.91242\ttrain-rmse:2.03483\n",
      "[8787]\teval-rmse:3.91125\ttrain-rmse:2.03486\n",
      "[8788]\teval-rmse:3.90943\ttrain-rmse:2.03488\n",
      "[8789]\teval-rmse:3.91055\ttrain-rmse:2.03487\n",
      "[8790]\teval-rmse:3.91153\ttrain-rmse:2.03484\n",
      "[8791]\teval-rmse:3.91174\ttrain-rmse:2.03483\n",
      "[8792]\teval-rmse:3.91109\ttrain-rmse:2.03484\n",
      "[8793]\teval-rmse:3.91308\ttrain-rmse:2.03483\n",
      "[8794]\teval-rmse:3.91234\ttrain-rmse:2.03483\n",
      "[8795]\teval-rmse:3.91396\ttrain-rmse:2.03484\n",
      "[8796]\teval-rmse:3.91297\ttrain-rmse:2.03484\n",
      "[8797]\teval-rmse:3.91275\ttrain-rmse:2.03484\n",
      "[8798]\teval-rmse:3.91211\ttrain-rmse:2.03451\n",
      "[8799]\teval-rmse:3.91075\ttrain-rmse:2.03452\n",
      "[8800]\teval-rmse:3.90972\ttrain-rmse:2.03452\n",
      "[8801]\teval-rmse:3.91091\ttrain-rmse:2.03452\n",
      "[8802]\teval-rmse:3.90994\ttrain-rmse:2.03452\n",
      "[8803]\teval-rmse:3.90923\ttrain-rmse:2.03453\n",
      "[8804]\teval-rmse:3.90923\ttrain-rmse:2.03453\n",
      "[8805]\teval-rmse:3.9106\ttrain-rmse:2.03452\n",
      "[8806]\teval-rmse:3.91061\ttrain-rmse:2.03452\n",
      "[8807]\teval-rmse:3.91079\ttrain-rmse:2.03451\n",
      "[8808]\teval-rmse:3.90952\ttrain-rmse:2.03452\n",
      "[8809]\teval-rmse:3.90855\ttrain-rmse:2.03453\n",
      "[8810]\teval-rmse:3.90831\ttrain-rmse:2.03453\n",
      "[8811]\teval-rmse:3.91014\ttrain-rmse:2.03452\n",
      "[8812]\teval-rmse:3.91229\ttrain-rmse:2.03454\n",
      "[8813]\teval-rmse:3.91204\ttrain-rmse:2.03454\n",
      "[8814]\teval-rmse:3.91289\ttrain-rmse:2.03454\n",
      "[8815]\teval-rmse:3.91427\ttrain-rmse:2.03454\n",
      "[8816]\teval-rmse:3.91541\ttrain-rmse:2.03454\n",
      "[8817]\teval-rmse:3.91431\ttrain-rmse:2.03456\n",
      "[8818]\teval-rmse:3.91568\ttrain-rmse:2.03453\n",
      "[8819]\teval-rmse:3.91404\ttrain-rmse:2.03453\n",
      "[8820]\teval-rmse:3.91508\ttrain-rmse:2.0345\n",
      "[8821]\teval-rmse:3.91345\ttrain-rmse:2.03453\n",
      "[8822]\teval-rmse:3.91287\ttrain-rmse:2.03453\n",
      "[8823]\teval-rmse:3.91182\ttrain-rmse:2.03456\n",
      "[8824]\teval-rmse:3.91206\ttrain-rmse:2.03456\n",
      "[8825]\teval-rmse:3.9121\ttrain-rmse:2.03456\n",
      "[8826]\teval-rmse:3.91283\ttrain-rmse:2.03456\n",
      "[8827]\teval-rmse:3.91331\ttrain-rmse:2.03456\n",
      "[8828]\teval-rmse:3.91197\ttrain-rmse:2.03457\n",
      "[8829]\teval-rmse:3.91016\ttrain-rmse:2.03462\n",
      "[8830]\teval-rmse:3.90947\ttrain-rmse:2.03435\n",
      "[8831]\teval-rmse:3.90968\ttrain-rmse:2.03435\n",
      "[8832]\teval-rmse:3.90758\ttrain-rmse:2.03437\n",
      "[8833]\teval-rmse:3.90971\ttrain-rmse:2.03423\n",
      "[8834]\teval-rmse:3.90858\ttrain-rmse:2.03422\n",
      "[8835]\teval-rmse:3.90901\ttrain-rmse:2.03422\n",
      "[8836]\teval-rmse:3.90938\ttrain-rmse:2.03421\n",
      "[8837]\teval-rmse:3.91065\ttrain-rmse:2.03413\n",
      "[8838]\teval-rmse:3.91095\ttrain-rmse:2.03413\n",
      "[8839]\teval-rmse:3.91066\ttrain-rmse:2.03413\n",
      "[8840]\teval-rmse:3.90883\ttrain-rmse:2.03414\n",
      "[8841]\teval-rmse:3.90995\ttrain-rmse:2.03413\n",
      "[8842]\teval-rmse:3.90987\ttrain-rmse:2.03413\n",
      "[8843]\teval-rmse:3.9111\ttrain-rmse:2.03412\n",
      "[8844]\teval-rmse:3.91004\ttrain-rmse:2.03415\n",
      "[8845]\teval-rmse:3.90907\ttrain-rmse:2.03416\n",
      "[8846]\teval-rmse:3.91056\ttrain-rmse:2.03415\n",
      "[8847]\teval-rmse:3.91249\ttrain-rmse:2.03416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8848]\teval-rmse:3.91439\ttrain-rmse:2.03416\n",
      "[8849]\teval-rmse:3.91563\ttrain-rmse:2.03417\n",
      "[8850]\teval-rmse:3.9168\ttrain-rmse:2.03418\n",
      "[8851]\teval-rmse:3.91709\ttrain-rmse:2.03418\n",
      "[8852]\teval-rmse:3.91805\ttrain-rmse:2.03421\n",
      "[8853]\teval-rmse:3.9174\ttrain-rmse:2.0342\n",
      "[8854]\teval-rmse:3.91877\ttrain-rmse:2.03421\n",
      "[8855]\teval-rmse:3.92066\ttrain-rmse:2.03424\n",
      "[8856]\teval-rmse:3.92236\ttrain-rmse:2.03422\n",
      "[8857]\teval-rmse:3.92068\ttrain-rmse:2.03419\n",
      "[8858]\teval-rmse:3.91933\ttrain-rmse:2.03416\n",
      "[8859]\teval-rmse:3.91997\ttrain-rmse:2.03418\n",
      "[8860]\teval-rmse:3.91923\ttrain-rmse:2.03417\n",
      "[8861]\teval-rmse:3.91747\ttrain-rmse:2.03414\n",
      "[8862]\teval-rmse:3.91541\ttrain-rmse:2.03412\n",
      "[8863]\teval-rmse:3.91666\ttrain-rmse:2.03412\n",
      "[8864]\teval-rmse:3.91714\ttrain-rmse:2.03413\n",
      "[8865]\teval-rmse:3.91883\ttrain-rmse:2.03404\n",
      "[8866]\teval-rmse:3.92079\ttrain-rmse:2.03395\n",
      "[8867]\teval-rmse:3.92101\ttrain-rmse:2.03396\n",
      "[8868]\teval-rmse:3.91912\ttrain-rmse:2.03393\n",
      "[8869]\teval-rmse:3.91908\ttrain-rmse:2.03393\n",
      "[8870]\teval-rmse:3.91878\ttrain-rmse:2.03392\n",
      "[8871]\teval-rmse:3.92069\ttrain-rmse:2.03395\n",
      "[8872]\teval-rmse:3.92185\ttrain-rmse:2.03397\n",
      "[8873]\teval-rmse:3.92165\ttrain-rmse:2.03396\n",
      "[8874]\teval-rmse:3.92091\ttrain-rmse:2.03395\n",
      "[8875]\teval-rmse:3.92165\ttrain-rmse:2.03397\n",
      "[8876]\teval-rmse:3.92088\ttrain-rmse:2.03364\n",
      "[8877]\teval-rmse:3.92222\ttrain-rmse:2.03367\n",
      "[8878]\teval-rmse:3.92246\ttrain-rmse:2.03367\n",
      "[8879]\teval-rmse:3.92214\ttrain-rmse:2.03366\n",
      "[8880]\teval-rmse:3.92118\ttrain-rmse:2.03364\n",
      "[8881]\teval-rmse:3.92002\ttrain-rmse:2.03361\n",
      "[8882]\teval-rmse:3.92225\ttrain-rmse:2.03353\n",
      "[8883]\teval-rmse:3.92203\ttrain-rmse:2.03352\n",
      "[8884]\teval-rmse:3.92368\ttrain-rmse:2.03357\n",
      "[8885]\teval-rmse:3.92135\ttrain-rmse:2.03348\n",
      "[8886]\teval-rmse:3.92325\ttrain-rmse:2.03353\n",
      "[8887]\teval-rmse:3.92512\ttrain-rmse:2.03353\n",
      "[8888]\teval-rmse:3.92613\ttrain-rmse:2.03356\n",
      "[8889]\teval-rmse:3.92628\ttrain-rmse:2.03356\n",
      "[8890]\teval-rmse:3.9259\ttrain-rmse:2.03355\n",
      "[8891]\teval-rmse:3.92332\ttrain-rmse:2.03347\n",
      "[8892]\teval-rmse:3.92345\ttrain-rmse:2.03347\n",
      "[8893]\teval-rmse:3.92512\ttrain-rmse:2.03347\n",
      "[8894]\teval-rmse:3.92486\ttrain-rmse:2.03346\n",
      "[8895]\teval-rmse:3.92365\ttrain-rmse:2.03343\n",
      "[8896]\teval-rmse:3.92552\ttrain-rmse:2.03342\n",
      "[8897]\teval-rmse:3.92696\ttrain-rmse:2.03347\n",
      "[8898]\teval-rmse:3.92707\ttrain-rmse:2.03347\n",
      "[8899]\teval-rmse:3.92675\ttrain-rmse:2.03346\n",
      "[8900]\teval-rmse:3.9281\ttrain-rmse:2.0335\n",
      "[8901]\teval-rmse:3.9264\ttrain-rmse:2.03345\n",
      "[8902]\teval-rmse:3.92679\ttrain-rmse:2.03346\n",
      "[8903]\teval-rmse:3.92773\ttrain-rmse:2.03349\n",
      "[8904]\teval-rmse:3.92982\ttrain-rmse:2.0335\n",
      "[8905]\teval-rmse:3.93048\ttrain-rmse:2.03353\n",
      "[8906]\teval-rmse:3.9282\ttrain-rmse:2.03345\n",
      "[8907]\teval-rmse:3.92836\ttrain-rmse:2.03346\n",
      "[8908]\teval-rmse:3.92718\ttrain-rmse:2.03344\n",
      "[8909]\teval-rmse:3.92806\ttrain-rmse:2.03348\n",
      "[8910]\teval-rmse:3.92792\ttrain-rmse:2.03347\n",
      "[8911]\teval-rmse:3.92594\ttrain-rmse:2.03341\n",
      "[8912]\teval-rmse:3.92469\ttrain-rmse:2.03337\n",
      "[8913]\teval-rmse:3.92449\ttrain-rmse:2.03337\n",
      "[8914]\teval-rmse:3.92555\ttrain-rmse:2.0334\n",
      "[8915]\teval-rmse:3.92492\ttrain-rmse:2.03338\n",
      "[8916]\teval-rmse:3.92499\ttrain-rmse:2.03338\n",
      "[8917]\teval-rmse:3.92496\ttrain-rmse:2.03338\n",
      "[8918]\teval-rmse:3.92421\ttrain-rmse:2.03336\n",
      "[8919]\teval-rmse:3.92384\ttrain-rmse:2.03335\n",
      "[8920]\teval-rmse:3.92261\ttrain-rmse:2.03332\n",
      "[8921]\teval-rmse:3.92335\ttrain-rmse:2.03333\n",
      "[8922]\teval-rmse:3.92434\ttrain-rmse:2.03333\n",
      "[8923]\teval-rmse:3.92399\ttrain-rmse:2.03332\n",
      "[8924]\teval-rmse:3.92424\ttrain-rmse:2.03333\n",
      "[8925]\teval-rmse:3.92395\ttrain-rmse:2.03332\n",
      "[8926]\teval-rmse:3.92273\ttrain-rmse:2.03328\n",
      "[8927]\teval-rmse:3.92456\ttrain-rmse:2.03333\n",
      "[8928]\teval-rmse:3.92622\ttrain-rmse:2.03328\n",
      "[8929]\teval-rmse:3.92519\ttrain-rmse:2.03325\n",
      "[8930]\teval-rmse:3.92641\ttrain-rmse:2.03321\n",
      "[8931]\teval-rmse:3.92657\ttrain-rmse:2.03322\n",
      "[8932]\teval-rmse:3.92874\ttrain-rmse:2.03329\n",
      "[8933]\teval-rmse:3.92849\ttrain-rmse:2.03328\n",
      "[8934]\teval-rmse:3.92756\ttrain-rmse:2.03325\n",
      "[8935]\teval-rmse:3.92767\ttrain-rmse:2.03325\n",
      "[8936]\teval-rmse:3.92814\ttrain-rmse:2.03327\n",
      "[8937]\teval-rmse:3.92746\ttrain-rmse:2.03324\n",
      "[8938]\teval-rmse:3.92652\ttrain-rmse:2.03321\n",
      "[8939]\teval-rmse:3.92738\ttrain-rmse:2.03324\n",
      "[8940]\teval-rmse:3.9296\ttrain-rmse:2.03331\n",
      "[8941]\teval-rmse:3.92946\ttrain-rmse:2.03331\n",
      "[8942]\teval-rmse:3.92723\ttrain-rmse:2.03324\n",
      "[8943]\teval-rmse:3.92587\ttrain-rmse:2.0332\n",
      "[8944]\teval-rmse:3.92585\ttrain-rmse:2.0332\n",
      "[8945]\teval-rmse:3.92751\ttrain-rmse:2.03321\n",
      "[8946]\teval-rmse:3.92932\ttrain-rmse:2.03327\n",
      "[8947]\teval-rmse:3.93057\ttrain-rmse:2.03331\n",
      "[8948]\teval-rmse:3.9296\ttrain-rmse:2.03327\n",
      "[8949]\teval-rmse:3.92984\ttrain-rmse:2.03328\n",
      "[8950]\teval-rmse:3.9291\ttrain-rmse:2.03298\n",
      "[8951]\teval-rmse:3.92784\ttrain-rmse:2.03293\n",
      "[8952]\teval-rmse:3.92633\ttrain-rmse:2.03289\n",
      "[8953]\teval-rmse:3.92434\ttrain-rmse:2.03283\n",
      "[8954]\teval-rmse:3.92334\ttrain-rmse:2.03283\n",
      "[8955]\teval-rmse:3.92225\ttrain-rmse:2.03281\n",
      "[8956]\teval-rmse:3.92351\ttrain-rmse:2.03283\n",
      "[8957]\teval-rmse:3.92452\ttrain-rmse:2.03283\n",
      "[8958]\teval-rmse:3.92568\ttrain-rmse:2.03286\n",
      "[8959]\teval-rmse:3.92658\ttrain-rmse:2.03289\n",
      "[8960]\teval-rmse:3.92833\ttrain-rmse:2.03296\n",
      "[8961]\teval-rmse:3.9287\ttrain-rmse:2.03297\n",
      "[8962]\teval-rmse:3.93091\ttrain-rmse:2.03305\n",
      "[8963]\teval-rmse:3.93033\ttrain-rmse:2.03303\n",
      "[8964]\teval-rmse:3.92906\ttrain-rmse:2.03298\n",
      "[8965]\teval-rmse:3.92787\ttrain-rmse:2.03299\n",
      "[8966]\teval-rmse:3.92685\ttrain-rmse:2.03296\n",
      "[8967]\teval-rmse:3.92563\ttrain-rmse:2.03292\n",
      "[8968]\teval-rmse:3.92749\ttrain-rmse:2.03293\n",
      "[8969]\teval-rmse:3.92738\ttrain-rmse:2.03293\n",
      "[8970]\teval-rmse:3.92654\ttrain-rmse:2.0329\n",
      "[8971]\teval-rmse:3.92541\ttrain-rmse:2.03287\n",
      "[8972]\teval-rmse:3.92298\ttrain-rmse:2.03279\n",
      "[8973]\teval-rmse:3.92499\ttrain-rmse:2.03283\n",
      "[8974]\teval-rmse:3.92396\ttrain-rmse:2.0328\n",
      "[8975]\teval-rmse:3.92495\ttrain-rmse:2.0328\n",
      "[8976]\teval-rmse:3.92346\ttrain-rmse:2.03276\n",
      "[8977]\teval-rmse:3.92207\ttrain-rmse:2.03274\n",
      "[8978]\teval-rmse:3.92092\ttrain-rmse:2.03277\n",
      "[8979]\teval-rmse:3.92308\ttrain-rmse:2.03283\n",
      "[8980]\teval-rmse:3.92396\ttrain-rmse:2.03284\n",
      "[8981]\teval-rmse:3.9234\ttrain-rmse:2.03283\n",
      "[8982]\teval-rmse:3.92187\ttrain-rmse:2.0328\n",
      "[8983]\teval-rmse:3.92274\ttrain-rmse:2.03282\n",
      "[8984]\teval-rmse:3.92466\ttrain-rmse:2.03286\n",
      "[8985]\teval-rmse:3.92442\ttrain-rmse:2.03286\n",
      "[8986]\teval-rmse:3.9242\ttrain-rmse:2.03285\n",
      "[8987]\teval-rmse:3.92552\ttrain-rmse:2.03285\n",
      "[8988]\teval-rmse:3.9253\ttrain-rmse:2.03284\n",
      "[8989]\teval-rmse:3.92452\ttrain-rmse:2.03282\n",
      "[8990]\teval-rmse:3.92298\ttrain-rmse:2.03278\n",
      "[8991]\teval-rmse:3.92222\ttrain-rmse:2.03276\n",
      "[8992]\teval-rmse:3.92244\ttrain-rmse:2.03276\n",
      "[8993]\teval-rmse:3.92123\ttrain-rmse:2.03273\n",
      "[8994]\teval-rmse:3.9218\ttrain-rmse:2.03274\n",
      "[8995]\teval-rmse:3.92104\ttrain-rmse:2.03243\n",
      "[8996]\teval-rmse:3.9232\ttrain-rmse:2.03249\n",
      "[8997]\teval-rmse:3.92454\ttrain-rmse:2.03253\n",
      "[8998]\teval-rmse:3.92433\ttrain-rmse:2.03252\n",
      "[8999]\teval-rmse:3.92399\ttrain-rmse:2.03251\n",
      "[9000]\teval-rmse:3.92286\ttrain-rmse:2.03251\n",
      "[9001]\teval-rmse:3.92408\ttrain-rmse:2.03255\n",
      "[9002]\teval-rmse:3.92177\ttrain-rmse:2.0325\n",
      "[9003]\teval-rmse:3.92157\ttrain-rmse:2.03249\n",
      "[9004]\teval-rmse:3.92136\ttrain-rmse:2.03249\n",
      "[9005]\teval-rmse:3.91993\ttrain-rmse:2.03247\n",
      "[9006]\teval-rmse:3.92111\ttrain-rmse:2.03249\n",
      "[9007]\teval-rmse:3.92059\ttrain-rmse:2.03248\n",
      "[9008]\teval-rmse:3.92034\ttrain-rmse:2.03247\n",
      "[9009]\teval-rmse:3.91816\ttrain-rmse:2.03244\n",
      "[9010]\teval-rmse:3.91897\ttrain-rmse:2.03245\n",
      "[9011]\teval-rmse:3.91919\ttrain-rmse:2.03245\n",
      "[9012]\teval-rmse:3.91818\ttrain-rmse:2.03244\n",
      "[9013]\teval-rmse:3.91765\ttrain-rmse:2.03243\n",
      "[9014]\teval-rmse:3.91959\ttrain-rmse:2.03246\n",
      "[9015]\teval-rmse:3.92007\ttrain-rmse:2.03247\n",
      "[9016]\teval-rmse:3.91908\ttrain-rmse:2.03247\n",
      "[9017]\teval-rmse:3.91882\ttrain-rmse:2.03247\n",
      "[9018]\teval-rmse:3.91899\ttrain-rmse:2.03247\n",
      "[9019]\teval-rmse:3.92017\ttrain-rmse:2.0325\n",
      "[9020]\teval-rmse:3.91766\ttrain-rmse:2.03246\n",
      "[9021]\teval-rmse:3.91736\ttrain-rmse:2.03246\n",
      "[9022]\teval-rmse:3.91921\ttrain-rmse:2.03244\n",
      "[9023]\teval-rmse:3.91837\ttrain-rmse:2.03242\n",
      "[9024]\teval-rmse:3.91762\ttrain-rmse:2.03212\n",
      "[9025]\teval-rmse:3.91921\ttrain-rmse:2.03215\n",
      "[9026]\teval-rmse:3.92062\ttrain-rmse:2.03218\n",
      "[9027]\teval-rmse:3.91998\ttrain-rmse:2.03216\n",
      "[9028]\teval-rmse:3.91967\ttrain-rmse:2.03216\n",
      "[9029]\teval-rmse:3.91817\ttrain-rmse:2.03213\n",
      "[9030]\teval-rmse:3.91637\ttrain-rmse:2.0321\n",
      "[9031]\teval-rmse:3.91557\ttrain-rmse:2.03209\n",
      "[9032]\teval-rmse:3.91502\ttrain-rmse:2.03208\n",
      "[9033]\teval-rmse:3.91564\ttrain-rmse:2.03209\n",
      "[9034]\teval-rmse:3.9166\ttrain-rmse:2.03208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9035]\teval-rmse:3.91689\ttrain-rmse:2.03208\n",
      "[9036]\teval-rmse:3.91798\ttrain-rmse:2.03209\n",
      "[9037]\teval-rmse:3.91559\ttrain-rmse:2.03208\n",
      "[9038]\teval-rmse:3.91363\ttrain-rmse:2.03207\n",
      "[9039]\teval-rmse:3.91411\ttrain-rmse:2.03207\n",
      "[9040]\teval-rmse:3.91535\ttrain-rmse:2.03208\n",
      "[9041]\teval-rmse:3.91725\ttrain-rmse:2.03211\n",
      "[9042]\teval-rmse:3.9169\ttrain-rmse:2.03211\n",
      "[9043]\teval-rmse:3.91498\ttrain-rmse:2.03209\n",
      "[9044]\teval-rmse:3.91398\ttrain-rmse:2.03209\n",
      "[9045]\teval-rmse:3.91305\ttrain-rmse:2.03209\n",
      "[9046]\teval-rmse:3.91459\ttrain-rmse:2.03211\n",
      "[9047]\teval-rmse:3.91313\ttrain-rmse:2.03213\n",
      "[9048]\teval-rmse:3.91523\ttrain-rmse:2.03203\n",
      "[9049]\teval-rmse:3.91349\ttrain-rmse:2.03204\n",
      "[9050]\teval-rmse:3.91444\ttrain-rmse:2.03202\n",
      "[9051]\teval-rmse:3.91346\ttrain-rmse:2.03202\n",
      "[9052]\teval-rmse:3.91274\ttrain-rmse:2.03201\n",
      "[9053]\teval-rmse:3.91112\ttrain-rmse:2.03209\n",
      "[9054]\teval-rmse:3.91135\ttrain-rmse:2.03208\n",
      "[9055]\teval-rmse:3.91276\ttrain-rmse:2.03206\n",
      "[9056]\teval-rmse:3.91057\ttrain-rmse:2.03206\n",
      "[9057]\teval-rmse:3.90982\ttrain-rmse:2.03207\n",
      "[9058]\teval-rmse:3.90955\ttrain-rmse:2.03207\n",
      "[9059]\teval-rmse:3.90722\ttrain-rmse:2.0321\n",
      "[9060]\teval-rmse:3.90812\ttrain-rmse:2.03209\n",
      "[9061]\teval-rmse:3.90622\ttrain-rmse:2.03211\n",
      "[9062]\teval-rmse:3.90751\ttrain-rmse:2.03208\n",
      "[9063]\teval-rmse:3.90606\ttrain-rmse:2.03212\n",
      "[9064]\teval-rmse:3.90586\ttrain-rmse:2.03212\n",
      "[9065]\teval-rmse:3.9038\ttrain-rmse:2.03218\n",
      "[9066]\teval-rmse:3.90257\ttrain-rmse:2.03222\n",
      "[9067]\teval-rmse:3.90191\ttrain-rmse:2.03225\n",
      "[9068]\teval-rmse:3.90143\ttrain-rmse:2.03226\n",
      "[9069]\teval-rmse:3.9023\ttrain-rmse:2.03223\n",
      "[9070]\teval-rmse:3.90324\ttrain-rmse:2.03219\n",
      "[9071]\teval-rmse:3.90299\ttrain-rmse:2.03219\n",
      "[9072]\teval-rmse:3.9043\ttrain-rmse:2.03215\n",
      "[9073]\teval-rmse:3.90339\ttrain-rmse:2.03218\n",
      "[9074]\teval-rmse:3.90471\ttrain-rmse:2.03214\n",
      "[9075]\teval-rmse:3.90365\ttrain-rmse:2.0322\n",
      "[9076]\teval-rmse:3.90317\ttrain-rmse:2.03221\n",
      "[9077]\teval-rmse:3.90429\ttrain-rmse:2.03219\n",
      "[9078]\teval-rmse:3.90336\ttrain-rmse:2.03221\n",
      "[9079]\teval-rmse:3.90267\ttrain-rmse:2.03224\n",
      "[9080]\teval-rmse:3.90244\ttrain-rmse:2.03224\n",
      "[9081]\teval-rmse:3.90024\ttrain-rmse:2.03232\n",
      "[9082]\teval-rmse:3.9012\ttrain-rmse:2.03228\n",
      "[9083]\teval-rmse:3.90324\ttrain-rmse:2.03221\n",
      "[9084]\teval-rmse:3.90418\ttrain-rmse:2.0322\n",
      "[9085]\teval-rmse:3.90439\ttrain-rmse:2.03219\n",
      "[9086]\teval-rmse:3.90552\ttrain-rmse:2.03217\n",
      "[9087]\teval-rmse:3.90483\ttrain-rmse:2.03186\n",
      "[9088]\teval-rmse:3.90456\ttrain-rmse:2.03186\n",
      "[9089]\teval-rmse:3.9033\ttrain-rmse:2.03189\n",
      "[9090]\teval-rmse:3.90541\ttrain-rmse:2.03175\n",
      "[9091]\teval-rmse:3.90491\ttrain-rmse:2.03175\n",
      "[9092]\teval-rmse:3.90503\ttrain-rmse:2.03175\n",
      "[9093]\teval-rmse:3.9048\ttrain-rmse:2.03175\n",
      "[9094]\teval-rmse:3.90455\ttrain-rmse:2.03175\n",
      "[9095]\teval-rmse:3.90677\ttrain-rmse:2.03161\n",
      "[9096]\teval-rmse:3.90774\ttrain-rmse:2.03158\n",
      "[9097]\teval-rmse:3.90667\ttrain-rmse:2.03159\n",
      "[9098]\teval-rmse:3.9085\ttrain-rmse:2.03158\n",
      "[9099]\teval-rmse:3.9068\ttrain-rmse:2.03161\n",
      "[9100]\teval-rmse:3.90567\ttrain-rmse:2.03161\n",
      "[9101]\teval-rmse:3.90723\ttrain-rmse:2.03159\n",
      "[9102]\teval-rmse:3.90824\ttrain-rmse:2.03159\n",
      "[9103]\teval-rmse:3.90754\ttrain-rmse:2.03158\n",
      "[9104]\teval-rmse:3.90619\ttrain-rmse:2.03159\n",
      "[9105]\teval-rmse:3.90834\ttrain-rmse:2.0316\n",
      "[9106]\teval-rmse:3.91029\ttrain-rmse:2.03159\n",
      "[9107]\teval-rmse:3.91219\ttrain-rmse:2.03155\n",
      "[9108]\teval-rmse:3.91311\ttrain-rmse:2.03155\n",
      "[9109]\teval-rmse:3.91527\ttrain-rmse:2.03159\n",
      "[9110]\teval-rmse:3.91609\ttrain-rmse:2.0316\n",
      "[9111]\teval-rmse:3.9158\ttrain-rmse:2.03159\n",
      "[9112]\teval-rmse:3.9151\ttrain-rmse:2.03158\n",
      "[9113]\teval-rmse:3.91728\ttrain-rmse:2.03162\n",
      "[9114]\teval-rmse:3.91837\ttrain-rmse:2.03163\n",
      "[9115]\teval-rmse:3.91736\ttrain-rmse:2.03161\n",
      "[9116]\teval-rmse:3.91569\ttrain-rmse:2.03163\n",
      "[9117]\teval-rmse:3.91586\ttrain-rmse:2.03163\n",
      "[9118]\teval-rmse:3.91514\ttrain-rmse:2.03162\n",
      "[9119]\teval-rmse:3.91491\ttrain-rmse:2.03162\n",
      "[9120]\teval-rmse:3.91459\ttrain-rmse:2.03161\n",
      "[9121]\teval-rmse:3.91675\ttrain-rmse:2.03166\n",
      "[9122]\teval-rmse:3.91698\ttrain-rmse:2.03166\n",
      "[9123]\teval-rmse:3.91669\ttrain-rmse:2.03165\n",
      "[9124]\teval-rmse:3.91837\ttrain-rmse:2.03158\n",
      "[9125]\teval-rmse:3.91649\ttrain-rmse:2.03156\n",
      "[9126]\teval-rmse:3.91599\ttrain-rmse:2.03156\n",
      "[9127]\teval-rmse:3.9152\ttrain-rmse:2.03157\n",
      "[9128]\teval-rmse:3.91655\ttrain-rmse:2.03155\n",
      "[9129]\teval-rmse:3.9187\ttrain-rmse:2.03159\n",
      "[9130]\teval-rmse:3.91772\ttrain-rmse:2.0316\n",
      "[9131]\teval-rmse:3.91683\ttrain-rmse:2.0316\n",
      "[9132]\teval-rmse:3.91895\ttrain-rmse:2.03152\n",
      "[9133]\teval-rmse:3.92108\ttrain-rmse:2.03157\n",
      "[9134]\teval-rmse:3.92043\ttrain-rmse:2.03157\n",
      "[9135]\teval-rmse:3.9212\ttrain-rmse:2.03158\n",
      "[9136]\teval-rmse:3.9202\ttrain-rmse:2.03156\n",
      "[9137]\teval-rmse:3.91853\ttrain-rmse:2.03157\n",
      "[9138]\teval-rmse:3.91868\ttrain-rmse:2.03157\n",
      "[9139]\teval-rmse:3.9209\ttrain-rmse:2.03159\n",
      "[9140]\teval-rmse:3.92257\ttrain-rmse:2.03154\n",
      "[9141]\teval-rmse:3.92428\ttrain-rmse:2.03158\n",
      "[9142]\teval-rmse:3.92473\ttrain-rmse:2.03157\n",
      "[9143]\teval-rmse:3.92258\ttrain-rmse:2.03153\n",
      "[9144]\teval-rmse:3.9213\ttrain-rmse:2.03152\n",
      "[9145]\teval-rmse:3.9227\ttrain-rmse:2.03152\n",
      "[9146]\teval-rmse:3.92195\ttrain-rmse:2.03149\n",
      "[9147]\teval-rmse:3.92024\ttrain-rmse:2.03147\n",
      "[9148]\teval-rmse:3.9191\ttrain-rmse:2.0315\n",
      "[9149]\teval-rmse:3.91743\ttrain-rmse:2.03156\n",
      "[9150]\teval-rmse:3.91924\ttrain-rmse:2.03153\n",
      "[9151]\teval-rmse:3.9185\ttrain-rmse:2.03151\n",
      "[9152]\teval-rmse:3.9173\ttrain-rmse:2.03149\n",
      "[9153]\teval-rmse:3.91711\ttrain-rmse:2.03148\n",
      "[9154]\teval-rmse:3.91524\ttrain-rmse:2.03147\n",
      "[9155]\teval-rmse:3.91447\ttrain-rmse:2.03147\n",
      "[9156]\teval-rmse:3.91667\ttrain-rmse:2.03137\n",
      "[9157]\teval-rmse:3.9157\ttrain-rmse:2.03138\n",
      "[9158]\teval-rmse:3.91653\ttrain-rmse:2.03137\n",
      "[9159]\teval-rmse:3.91553\ttrain-rmse:2.03137\n",
      "[9160]\teval-rmse:3.91669\ttrain-rmse:2.03138\n",
      "[9161]\teval-rmse:3.91761\ttrain-rmse:2.03138\n",
      "[9162]\teval-rmse:3.91685\ttrain-rmse:2.03137\n",
      "[9163]\teval-rmse:3.91882\ttrain-rmse:2.03139\n",
      "[9164]\teval-rmse:3.91813\ttrain-rmse:2.03139\n",
      "[9165]\teval-rmse:3.91757\ttrain-rmse:2.03139\n",
      "[9166]\teval-rmse:3.91707\ttrain-rmse:2.03138\n",
      "[9167]\teval-rmse:3.91729\ttrain-rmse:2.03138\n",
      "[9168]\teval-rmse:3.91834\ttrain-rmse:2.0314\n",
      "[9169]\teval-rmse:3.9197\ttrain-rmse:2.0314\n",
      "[9170]\teval-rmse:3.9173\ttrain-rmse:2.03138\n",
      "[9171]\teval-rmse:3.91802\ttrain-rmse:2.03138\n",
      "[9172]\teval-rmse:3.91663\ttrain-rmse:2.03138\n",
      "[9173]\teval-rmse:3.91754\ttrain-rmse:2.03137\n",
      "[9174]\teval-rmse:3.91878\ttrain-rmse:2.03138\n",
      "[9175]\teval-rmse:3.91969\ttrain-rmse:2.03139\n",
      "[9176]\teval-rmse:3.91948\ttrain-rmse:2.03138\n",
      "[9177]\teval-rmse:3.91972\ttrain-rmse:2.03139\n",
      "[9178]\teval-rmse:3.91951\ttrain-rmse:2.03138\n",
      "[9179]\teval-rmse:3.91958\ttrain-rmse:2.03138\n",
      "[9180]\teval-rmse:3.91885\ttrain-rmse:2.03112\n",
      "[9181]\teval-rmse:3.91991\ttrain-rmse:2.03114\n",
      "[9182]\teval-rmse:3.91915\ttrain-rmse:2.03112\n",
      "[9183]\teval-rmse:3.91887\ttrain-rmse:2.03112\n",
      "[9184]\teval-rmse:3.9204\ttrain-rmse:2.03115\n",
      "[9185]\teval-rmse:3.91892\ttrain-rmse:2.03115\n",
      "[9186]\teval-rmse:3.91818\ttrain-rmse:2.03086\n",
      "[9187]\teval-rmse:3.91855\ttrain-rmse:2.03086\n",
      "[9188]\teval-rmse:3.91709\ttrain-rmse:2.03084\n",
      "[9189]\teval-rmse:3.91767\ttrain-rmse:2.03084\n",
      "[9190]\teval-rmse:3.91656\ttrain-rmse:2.03088\n",
      "[9191]\teval-rmse:3.91477\ttrain-rmse:2.03085\n",
      "[9192]\teval-rmse:3.91609\ttrain-rmse:2.03086\n",
      "[9193]\teval-rmse:3.91707\ttrain-rmse:2.03087\n",
      "[9194]\teval-rmse:3.91923\ttrain-rmse:2.03092\n",
      "[9195]\teval-rmse:3.91797\ttrain-rmse:2.03092\n",
      "[9196]\teval-rmse:3.91644\ttrain-rmse:2.03094\n",
      "[9197]\teval-rmse:3.91783\ttrain-rmse:2.03096\n",
      "[9198]\teval-rmse:3.91854\ttrain-rmse:2.03097\n",
      "[9199]\teval-rmse:3.91879\ttrain-rmse:2.03097\n",
      "[9200]\teval-rmse:3.92048\ttrain-rmse:2.03096\n",
      "[9201]\teval-rmse:3.91829\ttrain-rmse:2.03094\n",
      "[9202]\teval-rmse:3.91807\ttrain-rmse:2.03093\n",
      "[9203]\teval-rmse:3.91956\ttrain-rmse:2.03096\n",
      "[9204]\teval-rmse:3.92055\ttrain-rmse:2.03097\n",
      "[9205]\teval-rmse:3.91925\ttrain-rmse:2.03095\n",
      "[9206]\teval-rmse:3.91856\ttrain-rmse:2.03066\n",
      "[9207]\teval-rmse:3.92067\ttrain-rmse:2.03065\n",
      "[9208]\teval-rmse:3.91841\ttrain-rmse:2.03062\n",
      "[9209]\teval-rmse:3.91851\ttrain-rmse:2.03063\n",
      "[9210]\teval-rmse:3.92053\ttrain-rmse:2.03064\n",
      "[9211]\teval-rmse:3.91928\ttrain-rmse:2.03062\n",
      "[9212]\teval-rmse:3.91845\ttrain-rmse:2.03061\n",
      "[9213]\teval-rmse:3.91933\ttrain-rmse:2.03062\n",
      "[9214]\teval-rmse:3.9195\ttrain-rmse:2.03062\n",
      "[9215]\teval-rmse:3.91848\ttrain-rmse:2.0306\n",
      "[9216]\teval-rmse:3.91635\ttrain-rmse:2.03058\n",
      "[9217]\teval-rmse:3.91852\ttrain-rmse:2.03063\n",
      "[9218]\teval-rmse:3.91656\ttrain-rmse:2.03061\n",
      "[9219]\teval-rmse:3.91583\ttrain-rmse:2.03035\n",
      "[9220]\teval-rmse:3.91797\ttrain-rmse:2.03039\n",
      "[9221]\teval-rmse:3.91774\ttrain-rmse:2.03039\n",
      "[9222]\teval-rmse:3.91655\ttrain-rmse:2.03036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9223]\teval-rmse:3.91822\ttrain-rmse:2.03039\n",
      "[9224]\teval-rmse:3.91685\ttrain-rmse:2.03036\n",
      "[9225]\teval-rmse:3.91717\ttrain-rmse:2.03036\n",
      "[9226]\teval-rmse:3.91789\ttrain-rmse:2.03037\n",
      "[9227]\teval-rmse:3.91999\ttrain-rmse:2.0304\n",
      "[9228]\teval-rmse:3.91813\ttrain-rmse:2.03039\n",
      "[9229]\teval-rmse:3.91646\ttrain-rmse:2.0304\n",
      "[9230]\teval-rmse:3.91743\ttrain-rmse:2.03041\n",
      "[9231]\teval-rmse:3.91712\ttrain-rmse:2.03041\n",
      "[9232]\teval-rmse:3.9168\ttrain-rmse:2.0304\n",
      "[9233]\teval-rmse:3.91647\ttrain-rmse:2.0304\n",
      "[9234]\teval-rmse:3.91504\ttrain-rmse:2.03039\n",
      "[9235]\teval-rmse:3.91442\ttrain-rmse:2.03039\n",
      "[9236]\teval-rmse:3.91629\ttrain-rmse:2.03036\n",
      "[9237]\teval-rmse:3.91505\ttrain-rmse:2.03035\n",
      "[9238]\teval-rmse:3.91434\ttrain-rmse:2.03034\n",
      "[9239]\teval-rmse:3.91504\ttrain-rmse:2.03034\n",
      "[9240]\teval-rmse:3.91354\ttrain-rmse:2.03033\n",
      "[9241]\teval-rmse:3.91283\ttrain-rmse:2.03032\n",
      "[9242]\teval-rmse:3.91305\ttrain-rmse:2.03032\n",
      "[9243]\teval-rmse:3.91142\ttrain-rmse:2.03032\n",
      "[9244]\teval-rmse:3.91338\ttrain-rmse:2.03034\n",
      "[9245]\teval-rmse:3.91273\ttrain-rmse:2.03035\n",
      "[9246]\teval-rmse:3.91086\ttrain-rmse:2.03036\n",
      "[9247]\teval-rmse:3.91076\ttrain-rmse:2.03036\n",
      "[9248]\teval-rmse:3.91213\ttrain-rmse:2.03036\n",
      "[9249]\teval-rmse:3.91194\ttrain-rmse:2.03036\n",
      "[9250]\teval-rmse:3.91071\ttrain-rmse:2.03041\n",
      "[9251]\teval-rmse:3.91043\ttrain-rmse:2.03041\n",
      "[9252]\teval-rmse:3.90981\ttrain-rmse:2.03008\n",
      "[9253]\teval-rmse:3.91077\ttrain-rmse:2.03006\n",
      "[9254]\teval-rmse:3.90992\ttrain-rmse:2.03006\n",
      "[9255]\teval-rmse:3.91043\ttrain-rmse:2.03005\n",
      "[9256]\teval-rmse:3.91021\ttrain-rmse:2.03005\n",
      "[9257]\teval-rmse:3.9096\ttrain-rmse:2.03005\n",
      "[9258]\teval-rmse:3.90891\ttrain-rmse:2.03004\n",
      "[9259]\teval-rmse:3.90699\ttrain-rmse:2.03005\n",
      "[9260]\teval-rmse:3.90751\ttrain-rmse:2.03004\n",
      "[9261]\teval-rmse:3.90899\ttrain-rmse:2.03003\n",
      "[9262]\teval-rmse:3.90966\ttrain-rmse:2.03002\n",
      "[9263]\teval-rmse:3.91062\ttrain-rmse:2.03002\n",
      "[9264]\teval-rmse:3.91171\ttrain-rmse:2.03001\n",
      "[9265]\teval-rmse:3.91106\ttrain-rmse:2.03001\n",
      "[9266]\teval-rmse:3.9093\ttrain-rmse:2.03003\n",
      "[9267]\teval-rmse:3.90701\ttrain-rmse:2.03007\n",
      "[9268]\teval-rmse:3.90632\ttrain-rmse:2.03008\n",
      "[9269]\teval-rmse:3.90781\ttrain-rmse:2.03003\n",
      "[9270]\teval-rmse:3.90893\ttrain-rmse:2.03003\n",
      "[9271]\teval-rmse:3.90988\ttrain-rmse:2.03002\n",
      "[9272]\teval-rmse:3.90884\ttrain-rmse:2.03005\n",
      "[9273]\teval-rmse:3.90988\ttrain-rmse:2.03004\n",
      "[9274]\teval-rmse:3.9104\ttrain-rmse:2.03004\n",
      "[9275]\teval-rmse:3.91181\ttrain-rmse:2.03004\n",
      "[9276]\teval-rmse:3.91152\ttrain-rmse:2.03003\n",
      "[9277]\teval-rmse:3.91169\ttrain-rmse:2.03003\n",
      "[9278]\teval-rmse:3.91319\ttrain-rmse:2.03002\n",
      "[9279]\teval-rmse:3.91113\ttrain-rmse:2.03003\n",
      "[9280]\teval-rmse:3.91093\ttrain-rmse:2.03004\n",
      "[9281]\teval-rmse:3.91022\ttrain-rmse:2.03003\n",
      "[9282]\teval-rmse:3.90972\ttrain-rmse:2.03003\n",
      "[9283]\teval-rmse:3.90763\ttrain-rmse:2.03007\n",
      "[9284]\teval-rmse:3.90747\ttrain-rmse:2.03007\n",
      "[9285]\teval-rmse:3.90963\ttrain-rmse:2.03009\n",
      "[9286]\teval-rmse:3.90848\ttrain-rmse:2.03008\n",
      "[9287]\teval-rmse:3.90778\ttrain-rmse:2.03007\n",
      "[9288]\teval-rmse:3.90555\ttrain-rmse:2.03012\n",
      "[9289]\teval-rmse:3.90647\ttrain-rmse:2.0301\n",
      "[9290]\teval-rmse:3.9058\ttrain-rmse:2.0301\n",
      "[9291]\teval-rmse:3.90397\ttrain-rmse:2.03012\n",
      "[9292]\teval-rmse:3.90331\ttrain-rmse:2.03012\n",
      "[9293]\teval-rmse:3.90354\ttrain-rmse:2.03011\n",
      "[9294]\teval-rmse:3.90307\ttrain-rmse:2.03013\n",
      "[9295]\teval-rmse:3.90429\ttrain-rmse:2.03011\n",
      "[9296]\teval-rmse:3.90366\ttrain-rmse:2.03013\n",
      "[9297]\teval-rmse:3.90333\ttrain-rmse:2.03013\n",
      "[9298]\teval-rmse:3.90549\ttrain-rmse:2.03011\n",
      "[9299]\teval-rmse:3.90561\ttrain-rmse:2.0301\n",
      "[9300]\teval-rmse:3.90569\ttrain-rmse:2.0301\n",
      "[9301]\teval-rmse:3.9059\ttrain-rmse:2.0301\n",
      "[9302]\teval-rmse:3.90455\ttrain-rmse:2.03013\n",
      "[9303]\teval-rmse:3.90678\ttrain-rmse:2.0301\n",
      "[9304]\teval-rmse:3.90896\ttrain-rmse:2.03012\n",
      "[9305]\teval-rmse:3.91111\ttrain-rmse:2.03015\n",
      "[9306]\teval-rmse:3.90935\ttrain-rmse:2.03017\n",
      "[9307]\teval-rmse:3.90821\ttrain-rmse:2.03015\n",
      "[9308]\teval-rmse:3.91031\ttrain-rmse:2.03004\n",
      "[9309]\teval-rmse:3.91147\ttrain-rmse:2.03004\n",
      "[9310]\teval-rmse:3.91218\ttrain-rmse:2.03003\n",
      "[9311]\teval-rmse:3.91357\ttrain-rmse:2.03\n",
      "[9312]\teval-rmse:3.91235\ttrain-rmse:2.03005\n",
      "[9313]\teval-rmse:3.91014\ttrain-rmse:2.03006\n",
      "[9314]\teval-rmse:3.91143\ttrain-rmse:2.03004\n",
      "[9315]\teval-rmse:3.91114\ttrain-rmse:2.03004\n",
      "[9316]\teval-rmse:3.90998\ttrain-rmse:2.03003\n",
      "[9317]\teval-rmse:3.90861\ttrain-rmse:2.03004\n",
      "[9318]\teval-rmse:3.90985\ttrain-rmse:2.03001\n",
      "[9319]\teval-rmse:3.9101\ttrain-rmse:2.03001\n",
      "[9320]\teval-rmse:3.91003\ttrain-rmse:2.03001\n",
      "[9321]\teval-rmse:3.90821\ttrain-rmse:2.03002\n",
      "[9322]\teval-rmse:3.90943\ttrain-rmse:2.03001\n",
      "[9323]\teval-rmse:3.90834\ttrain-rmse:2.03006\n",
      "[9324]\teval-rmse:3.90721\ttrain-rmse:2.03004\n",
      "[9325]\teval-rmse:3.90661\ttrain-rmse:2.02971\n",
      "[9326]\teval-rmse:3.90548\ttrain-rmse:2.0297\n",
      "[9327]\teval-rmse:3.90388\ttrain-rmse:2.02979\n",
      "[9328]\teval-rmse:3.90441\ttrain-rmse:2.02978\n",
      "[9329]\teval-rmse:3.90374\ttrain-rmse:2.0298\n",
      "[9330]\teval-rmse:3.90518\ttrain-rmse:2.02979\n",
      "[9331]\teval-rmse:3.90658\ttrain-rmse:2.02977\n",
      "[9332]\teval-rmse:3.90674\ttrain-rmse:2.02977\n",
      "[9333]\teval-rmse:3.90613\ttrain-rmse:2.02947\n",
      "[9334]\teval-rmse:3.9062\ttrain-rmse:2.02947\n",
      "[9335]\teval-rmse:3.90641\ttrain-rmse:2.02946\n",
      "[9336]\teval-rmse:3.9086\ttrain-rmse:2.02934\n",
      "[9337]\teval-rmse:3.90743\ttrain-rmse:2.02936\n",
      "[9338]\teval-rmse:3.90623\ttrain-rmse:2.02937\n",
      "[9339]\teval-rmse:3.90685\ttrain-rmse:2.02936\n",
      "[9340]\teval-rmse:3.90694\ttrain-rmse:2.02936\n",
      "[9341]\teval-rmse:3.90876\ttrain-rmse:2.02932\n",
      "[9342]\teval-rmse:3.90852\ttrain-rmse:2.02932\n",
      "[9343]\teval-rmse:3.90651\ttrain-rmse:2.02934\n",
      "[9344]\teval-rmse:3.90747\ttrain-rmse:2.02934\n",
      "[9345]\teval-rmse:3.9089\ttrain-rmse:2.02934\n",
      "[9346]\teval-rmse:3.90819\ttrain-rmse:2.02933\n",
      "[9347]\teval-rmse:3.90684\ttrain-rmse:2.02933\n",
      "[9348]\teval-rmse:3.90586\ttrain-rmse:2.02934\n",
      "[9349]\teval-rmse:3.90721\ttrain-rmse:2.0293\n",
      "[9350]\teval-rmse:3.90469\ttrain-rmse:2.02934\n",
      "[9351]\teval-rmse:3.90572\ttrain-rmse:2.02931\n",
      "[9352]\teval-rmse:3.9058\ttrain-rmse:2.02931\n",
      "[9353]\teval-rmse:3.90519\ttrain-rmse:2.02904\n",
      "[9354]\teval-rmse:3.90502\ttrain-rmse:2.02903\n",
      "[9355]\teval-rmse:3.90613\ttrain-rmse:2.02901\n",
      "[9356]\teval-rmse:3.90429\ttrain-rmse:2.02905\n",
      "[9357]\teval-rmse:3.90308\ttrain-rmse:2.02907\n",
      "[9358]\teval-rmse:3.90524\ttrain-rmse:2.02908\n",
      "[9359]\teval-rmse:3.90574\ttrain-rmse:2.02907\n",
      "[9360]\teval-rmse:3.90459\ttrain-rmse:2.02908\n",
      "[9361]\teval-rmse:3.90396\ttrain-rmse:2.02908\n",
      "[9362]\teval-rmse:3.90219\ttrain-rmse:2.02911\n",
      "[9363]\teval-rmse:3.90366\ttrain-rmse:2.02906\n",
      "[9364]\teval-rmse:3.90257\ttrain-rmse:2.02912\n",
      "[9365]\teval-rmse:3.90355\ttrain-rmse:2.02909\n",
      "[9366]\teval-rmse:3.90452\ttrain-rmse:2.02908\n",
      "[9367]\teval-rmse:3.90389\ttrain-rmse:2.02909\n",
      "[9368]\teval-rmse:3.9049\ttrain-rmse:2.02908\n",
      "[9369]\teval-rmse:3.90621\ttrain-rmse:2.02905\n",
      "[9370]\teval-rmse:3.90444\ttrain-rmse:2.02907\n",
      "[9371]\teval-rmse:3.90284\ttrain-rmse:2.02912\n",
      "[9372]\teval-rmse:3.90471\ttrain-rmse:2.02909\n",
      "[9373]\teval-rmse:3.90442\ttrain-rmse:2.02909\n",
      "[9374]\teval-rmse:3.90475\ttrain-rmse:2.02908\n",
      "[9375]\teval-rmse:3.90426\ttrain-rmse:2.0291\n",
      "[9376]\teval-rmse:3.90319\ttrain-rmse:2.02915\n",
      "[9377]\teval-rmse:3.90447\ttrain-rmse:2.02914\n",
      "[9378]\teval-rmse:3.90472\ttrain-rmse:2.02914\n",
      "[9379]\teval-rmse:3.90365\ttrain-rmse:2.02917\n",
      "[9380]\teval-rmse:3.90395\ttrain-rmse:2.02916\n",
      "[9381]\teval-rmse:3.90611\ttrain-rmse:2.02917\n",
      "[9382]\teval-rmse:3.90827\ttrain-rmse:2.02919\n",
      "[9383]\teval-rmse:3.90733\ttrain-rmse:2.0292\n",
      "[9384]\teval-rmse:3.90685\ttrain-rmse:2.0292\n",
      "[9385]\teval-rmse:3.9073\ttrain-rmse:2.02919\n",
      "[9386]\teval-rmse:3.90617\ttrain-rmse:2.02918\n",
      "[9387]\teval-rmse:3.90471\ttrain-rmse:2.02922\n",
      "[9388]\teval-rmse:3.90503\ttrain-rmse:2.02921\n",
      "[9389]\teval-rmse:3.90673\ttrain-rmse:2.0292\n",
      "[9390]\teval-rmse:3.90609\ttrain-rmse:2.02922\n",
      "[9391]\teval-rmse:3.90794\ttrain-rmse:2.02919\n",
      "[9392]\teval-rmse:3.90897\ttrain-rmse:2.02916\n",
      "[9393]\teval-rmse:3.9078\ttrain-rmse:2.02915\n",
      "[9394]\teval-rmse:3.90718\ttrain-rmse:2.02915\n",
      "[9395]\teval-rmse:3.90748\ttrain-rmse:2.02915\n",
      "[9396]\teval-rmse:3.90637\ttrain-rmse:2.0292\n",
      "[9397]\teval-rmse:3.90497\ttrain-rmse:2.02923\n",
      "[9398]\teval-rmse:3.90632\ttrain-rmse:2.02919\n",
      "[9399]\teval-rmse:3.90755\ttrain-rmse:2.02912\n",
      "[9400]\teval-rmse:3.90729\ttrain-rmse:2.02912\n",
      "[9401]\teval-rmse:3.90586\ttrain-rmse:2.02916\n",
      "[9402]\teval-rmse:3.90426\ttrain-rmse:2.02917\n",
      "[9403]\teval-rmse:3.90316\ttrain-rmse:2.02917\n",
      "[9404]\teval-rmse:3.90136\ttrain-rmse:2.02923\n",
      "[9405]\teval-rmse:3.90304\ttrain-rmse:2.02917\n",
      "[9406]\teval-rmse:3.90519\ttrain-rmse:2.02918\n",
      "[9407]\teval-rmse:3.90398\ttrain-rmse:2.02919\n",
      "[9408]\teval-rmse:3.90567\ttrain-rmse:2.02909\n",
      "[9409]\teval-rmse:3.90705\ttrain-rmse:2.02907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9410]\teval-rmse:3.90722\ttrain-rmse:2.02906\n",
      "[9411]\teval-rmse:3.90587\ttrain-rmse:2.02907\n",
      "[9412]\teval-rmse:3.90652\ttrain-rmse:2.02906\n",
      "[9413]\teval-rmse:3.90706\ttrain-rmse:2.02906\n",
      "[9414]\teval-rmse:3.90677\ttrain-rmse:2.02905\n",
      "[9415]\teval-rmse:3.9078\ttrain-rmse:2.02903\n",
      "[9416]\teval-rmse:3.90762\ttrain-rmse:2.02902\n",
      "[9417]\teval-rmse:3.90834\ttrain-rmse:2.02902\n",
      "[9418]\teval-rmse:3.90687\ttrain-rmse:2.02905\n",
      "[9419]\teval-rmse:3.90903\ttrain-rmse:2.02907\n",
      "[9420]\teval-rmse:3.91025\ttrain-rmse:2.02906\n",
      "[9421]\teval-rmse:3.90874\ttrain-rmse:2.02909\n",
      "[9422]\teval-rmse:3.90951\ttrain-rmse:2.02909\n",
      "[9423]\teval-rmse:3.90881\ttrain-rmse:2.02909\n",
      "[9424]\teval-rmse:3.90743\ttrain-rmse:2.02912\n",
      "[9425]\teval-rmse:3.90515\ttrain-rmse:2.02913\n",
      "[9426]\teval-rmse:3.90494\ttrain-rmse:2.02913\n",
      "[9427]\teval-rmse:3.90395\ttrain-rmse:2.02916\n",
      "[9428]\teval-rmse:3.90288\ttrain-rmse:2.02919\n",
      "[9429]\teval-rmse:3.90506\ttrain-rmse:2.0292\n",
      "[9430]\teval-rmse:3.90667\ttrain-rmse:2.02916\n",
      "[9431]\teval-rmse:3.90453\ttrain-rmse:2.02919\n",
      "[9432]\teval-rmse:3.9046\ttrain-rmse:2.02919\n",
      "[9433]\teval-rmse:3.90373\ttrain-rmse:2.0292\n",
      "[9434]\teval-rmse:3.90349\ttrain-rmse:2.02921\n",
      "[9435]\teval-rmse:3.90261\ttrain-rmse:2.02922\n",
      "[9436]\teval-rmse:3.90151\ttrain-rmse:2.02922\n",
      "[9437]\teval-rmse:3.90278\ttrain-rmse:2.02919\n",
      "[9438]\teval-rmse:3.9025\ttrain-rmse:2.02919\n",
      "[9439]\teval-rmse:3.90062\ttrain-rmse:2.02923\n",
      "[9440]\teval-rmse:3.90136\ttrain-rmse:2.02921\n",
      "[9441]\teval-rmse:3.90071\ttrain-rmse:2.02921\n",
      "[9442]\teval-rmse:3.89961\ttrain-rmse:2.02921\n",
      "[9443]\teval-rmse:3.90149\ttrain-rmse:2.02914\n",
      "[9444]\teval-rmse:3.90296\ttrain-rmse:2.02911\n",
      "[9445]\teval-rmse:3.90281\ttrain-rmse:2.0291\n",
      "[9446]\teval-rmse:3.90413\ttrain-rmse:2.02909\n",
      "[9447]\teval-rmse:3.90559\ttrain-rmse:2.02908\n",
      "[9448]\teval-rmse:3.90439\ttrain-rmse:2.02913\n",
      "[9449]\teval-rmse:3.90329\ttrain-rmse:2.02916\n",
      "[9450]\teval-rmse:3.90166\ttrain-rmse:2.0292\n",
      "[9451]\teval-rmse:3.89957\ttrain-rmse:2.02924\n",
      "[9452]\teval-rmse:3.90031\ttrain-rmse:2.02923\n",
      "[9453]\teval-rmse:3.89895\ttrain-rmse:2.02926\n",
      "[9454]\teval-rmse:3.89881\ttrain-rmse:2.02926\n",
      "[9455]\teval-rmse:3.89741\ttrain-rmse:2.0293\n",
      "[9456]\teval-rmse:3.8984\ttrain-rmse:2.02926\n",
      "[9457]\teval-rmse:3.89946\ttrain-rmse:2.02921\n",
      "[9458]\teval-rmse:3.89883\ttrain-rmse:2.02921\n",
      "[9459]\teval-rmse:3.8973\ttrain-rmse:2.02928\n",
      "[9460]\teval-rmse:3.89624\ttrain-rmse:2.02934\n",
      "[9461]\teval-rmse:3.89808\ttrain-rmse:2.02927\n",
      "[9462]\teval-rmse:3.89884\ttrain-rmse:2.02925\n",
      "[9463]\teval-rmse:3.89779\ttrain-rmse:2.02931\n",
      "[9464]\teval-rmse:3.8955\ttrain-rmse:2.02938\n",
      "[9465]\teval-rmse:3.89771\ttrain-rmse:2.02922\n",
      "[9466]\teval-rmse:3.89748\ttrain-rmse:2.02922\n",
      "[9467]\teval-rmse:3.8966\ttrain-rmse:2.02925\n",
      "[9468]\teval-rmse:3.89785\ttrain-rmse:2.02919\n",
      "[9469]\teval-rmse:3.8963\ttrain-rmse:2.0293\n",
      "[9470]\teval-rmse:3.89572\ttrain-rmse:2.02933\n",
      "[9471]\teval-rmse:3.89509\ttrain-rmse:2.02933\n",
      "[9472]\teval-rmse:3.89447\ttrain-rmse:2.02899\n",
      "[9473]\teval-rmse:3.89463\ttrain-rmse:2.02898\n",
      "[9474]\teval-rmse:3.89585\ttrain-rmse:2.02895\n",
      "[9475]\teval-rmse:3.89626\ttrain-rmse:2.02893\n",
      "[9476]\teval-rmse:3.8967\ttrain-rmse:2.02892\n",
      "[9477]\teval-rmse:3.89786\ttrain-rmse:2.02889\n",
      "[9478]\teval-rmse:3.90007\ttrain-rmse:2.02874\n",
      "[9479]\teval-rmse:3.90058\ttrain-rmse:2.02873\n",
      "[9480]\teval-rmse:3.90164\ttrain-rmse:2.0287\n",
      "[9481]\teval-rmse:3.89948\ttrain-rmse:2.02875\n",
      "[9482]\teval-rmse:3.89944\ttrain-rmse:2.02875\n",
      "[9483]\teval-rmse:3.89965\ttrain-rmse:2.02874\n",
      "[9484]\teval-rmse:3.90101\ttrain-rmse:2.02869\n",
      "[9485]\teval-rmse:3.90152\ttrain-rmse:2.02867\n",
      "[9486]\teval-rmse:3.9019\ttrain-rmse:2.02866\n",
      "[9487]\teval-rmse:3.89952\ttrain-rmse:2.0287\n",
      "[9488]\teval-rmse:3.90048\ttrain-rmse:2.02867\n",
      "[9489]\teval-rmse:3.89931\ttrain-rmse:2.02874\n",
      "[9490]\teval-rmse:3.89821\ttrain-rmse:2.02875\n",
      "[9491]\teval-rmse:3.89941\ttrain-rmse:2.02871\n",
      "[9492]\teval-rmse:3.90163\ttrain-rmse:2.02867\n",
      "[9493]\teval-rmse:3.90256\ttrain-rmse:2.02866\n",
      "[9494]\teval-rmse:3.90051\ttrain-rmse:2.02869\n",
      "[9495]\teval-rmse:3.90072\ttrain-rmse:2.02868\n",
      "[9496]\teval-rmse:3.90242\ttrain-rmse:2.02866\n",
      "[9497]\teval-rmse:3.9043\ttrain-rmse:2.02864\n",
      "[9498]\teval-rmse:3.9053\ttrain-rmse:2.02863\n",
      "[9499]\teval-rmse:3.90468\ttrain-rmse:2.02836\n",
      "[9500]\teval-rmse:3.90355\ttrain-rmse:2.02835\n",
      "[9501]\teval-rmse:3.90389\ttrain-rmse:2.02835\n",
      "[9502]\teval-rmse:3.90438\ttrain-rmse:2.02835\n",
      "[9503]\teval-rmse:3.9023\ttrain-rmse:2.02837\n",
      "[9504]\teval-rmse:3.90169\ttrain-rmse:2.02809\n",
      "[9505]\teval-rmse:3.90192\ttrain-rmse:2.02809\n",
      "[9506]\teval-rmse:3.90064\ttrain-rmse:2.02811\n",
      "[9507]\teval-rmse:3.90158\ttrain-rmse:2.02811\n",
      "[9508]\teval-rmse:3.90252\ttrain-rmse:2.0281\n",
      "[9509]\teval-rmse:3.9014\ttrain-rmse:2.02809\n",
      "[9510]\teval-rmse:3.89967\ttrain-rmse:2.0281\n",
      "[9511]\teval-rmse:3.89879\ttrain-rmse:2.02813\n",
      "[9512]\teval-rmse:3.89813\ttrain-rmse:2.02813\n",
      "[9513]\teval-rmse:3.89632\ttrain-rmse:2.02817\n",
      "[9514]\teval-rmse:3.89423\ttrain-rmse:2.02823\n",
      "[9515]\teval-rmse:3.89329\ttrain-rmse:2.02826\n",
      "[9516]\teval-rmse:3.89121\ttrain-rmse:2.02834\n",
      "[9517]\teval-rmse:3.89167\ttrain-rmse:2.02832\n",
      "[9518]\teval-rmse:3.89282\ttrain-rmse:2.02828\n",
      "[9519]\teval-rmse:3.8939\ttrain-rmse:2.02824\n",
      "[9520]\teval-rmse:3.89145\ttrain-rmse:2.0283\n",
      "[9521]\teval-rmse:3.88934\ttrain-rmse:2.02838\n",
      "[9522]\teval-rmse:3.89078\ttrain-rmse:2.0283\n",
      "[9523]\teval-rmse:3.89183\ttrain-rmse:2.02827\n",
      "[9524]\teval-rmse:3.89276\ttrain-rmse:2.02823\n",
      "[9525]\teval-rmse:3.89368\ttrain-rmse:2.0282\n",
      "[9526]\teval-rmse:3.89494\ttrain-rmse:2.0281\n",
      "[9527]\teval-rmse:3.89484\ttrain-rmse:2.0281\n",
      "[9528]\teval-rmse:3.89471\ttrain-rmse:2.0281\n",
      "[9529]\teval-rmse:3.89633\ttrain-rmse:2.02807\n",
      "[9530]\teval-rmse:3.89535\ttrain-rmse:2.02809\n",
      "[9531]\teval-rmse:3.89305\ttrain-rmse:2.02816\n",
      "[9532]\teval-rmse:3.89201\ttrain-rmse:2.02817\n",
      "[9533]\teval-rmse:3.89277\ttrain-rmse:2.02814\n",
      "[9534]\teval-rmse:3.89284\ttrain-rmse:2.02813\n",
      "[9535]\teval-rmse:3.89499\ttrain-rmse:2.02812\n",
      "[9536]\teval-rmse:3.89598\ttrain-rmse:2.02808\n",
      "[9537]\teval-rmse:3.8955\ttrain-rmse:2.02809\n",
      "[9538]\teval-rmse:3.89773\ttrain-rmse:2.028\n",
      "[9539]\teval-rmse:3.89645\ttrain-rmse:2.02803\n",
      "[9540]\teval-rmse:3.89814\ttrain-rmse:2.02792\n",
      "[9541]\teval-rmse:3.89779\ttrain-rmse:2.02792\n",
      "[9542]\teval-rmse:3.89996\ttrain-rmse:2.02792\n",
      "[9543]\teval-rmse:3.89954\ttrain-rmse:2.02792\n",
      "[9544]\teval-rmse:3.89772\ttrain-rmse:2.02796\n",
      "[9545]\teval-rmse:3.89971\ttrain-rmse:2.02793\n",
      "[9546]\teval-rmse:3.90029\ttrain-rmse:2.02792\n",
      "[9547]\teval-rmse:3.90026\ttrain-rmse:2.02792\n",
      "[9548]\teval-rmse:3.90217\ttrain-rmse:2.02791\n",
      "[9549]\teval-rmse:3.90321\ttrain-rmse:2.02789\n",
      "[9550]\teval-rmse:3.90255\ttrain-rmse:2.0276\n",
      "[9551]\teval-rmse:3.90474\ttrain-rmse:2.02748\n",
      "[9552]\teval-rmse:3.90331\ttrain-rmse:2.0275\n",
      "[9553]\teval-rmse:3.90219\ttrain-rmse:2.02749\n",
      "[9554]\teval-rmse:3.90028\ttrain-rmse:2.02753\n",
      "[9555]\teval-rmse:3.8987\ttrain-rmse:2.02759\n",
      "[9556]\teval-rmse:3.89952\ttrain-rmse:2.02757\n",
      "[9557]\teval-rmse:3.89935\ttrain-rmse:2.02758\n",
      "[9558]\teval-rmse:3.89752\ttrain-rmse:2.02764\n",
      "[9559]\teval-rmse:3.89625\ttrain-rmse:2.02767\n",
      "[9560]\teval-rmse:3.89511\ttrain-rmse:2.02774\n",
      "[9561]\teval-rmse:3.89674\ttrain-rmse:2.0277\n",
      "[9562]\teval-rmse:3.89687\ttrain-rmse:2.0277\n",
      "[9563]\teval-rmse:3.89908\ttrain-rmse:2.02765\n",
      "[9564]\teval-rmse:3.90054\ttrain-rmse:2.02763\n",
      "[9565]\teval-rmse:3.90034\ttrain-rmse:2.02763\n",
      "[9566]\teval-rmse:3.90229\ttrain-rmse:2.02759\n",
      "[9567]\teval-rmse:3.90324\ttrain-rmse:2.02758\n",
      "[9568]\teval-rmse:3.90188\ttrain-rmse:2.02761\n",
      "[9569]\teval-rmse:3.90402\ttrain-rmse:2.02762\n",
      "[9570]\teval-rmse:3.90334\ttrain-rmse:2.02762\n",
      "[9571]\teval-rmse:3.90385\ttrain-rmse:2.02761\n",
      "[9572]\teval-rmse:3.90361\ttrain-rmse:2.02761\n",
      "[9573]\teval-rmse:3.90225\ttrain-rmse:2.02763\n",
      "[9574]\teval-rmse:3.90078\ttrain-rmse:2.02765\n",
      "[9575]\teval-rmse:3.90169\ttrain-rmse:2.02763\n",
      "[9576]\teval-rmse:3.903\ttrain-rmse:2.02763\n",
      "[9577]\teval-rmse:3.90515\ttrain-rmse:2.02765\n",
      "[9578]\teval-rmse:3.90488\ttrain-rmse:2.02765\n",
      "[9579]\teval-rmse:3.90461\ttrain-rmse:2.02765\n",
      "[9580]\teval-rmse:3.90549\ttrain-rmse:2.02764\n",
      "[9581]\teval-rmse:3.90435\ttrain-rmse:2.02763\n",
      "[9582]\teval-rmse:3.90454\ttrain-rmse:2.02762\n",
      "[9583]\teval-rmse:3.90555\ttrain-rmse:2.02762\n",
      "[9584]\teval-rmse:3.9034\ttrain-rmse:2.02762\n",
      "[9585]\teval-rmse:3.90548\ttrain-rmse:2.0275\n",
      "[9586]\teval-rmse:3.90742\ttrain-rmse:2.02746\n",
      "[9587]\teval-rmse:3.90865\ttrain-rmse:2.02748\n",
      "[9588]\teval-rmse:3.91032\ttrain-rmse:2.02745\n",
      "[9589]\teval-rmse:3.90895\ttrain-rmse:2.02745\n",
      "[9590]\teval-rmse:3.91109\ttrain-rmse:2.02748\n",
      "[9591]\teval-rmse:3.90918\ttrain-rmse:2.02747\n",
      "[9592]\teval-rmse:3.90898\ttrain-rmse:2.02747\n",
      "[9593]\teval-rmse:3.90995\ttrain-rmse:2.02747\n",
      "[9594]\teval-rmse:3.91033\ttrain-rmse:2.02747\n",
      "[9595]\teval-rmse:3.9089\ttrain-rmse:2.02747\n",
      "[9596]\teval-rmse:3.90841\ttrain-rmse:2.02747\n",
      "[9597]\teval-rmse:3.9102\ttrain-rmse:2.02747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9598]\teval-rmse:3.91004\ttrain-rmse:2.02747\n",
      "[9599]\teval-rmse:3.91015\ttrain-rmse:2.02747\n",
      "[9600]\teval-rmse:3.91031\ttrain-rmse:2.02747\n",
      "[9601]\teval-rmse:3.91139\ttrain-rmse:2.02747\n",
      "[9602]\teval-rmse:3.9124\ttrain-rmse:2.02748\n",
      "[9603]\teval-rmse:3.91454\ttrain-rmse:2.02752\n",
      "[9604]\teval-rmse:3.91544\ttrain-rmse:2.02752\n",
      "[9605]\teval-rmse:3.91762\ttrain-rmse:2.02744\n",
      "[9606]\teval-rmse:3.9186\ttrain-rmse:2.02744\n",
      "[9607]\teval-rmse:3.91709\ttrain-rmse:2.02741\n",
      "[9608]\teval-rmse:3.91582\ttrain-rmse:2.02744\n",
      "[9609]\teval-rmse:3.91411\ttrain-rmse:2.02742\n",
      "[9610]\teval-rmse:3.9152\ttrain-rmse:2.02744\n",
      "[9611]\teval-rmse:3.9164\ttrain-rmse:2.02745\n",
      "[9612]\teval-rmse:3.91688\ttrain-rmse:2.02746\n",
      "[9613]\teval-rmse:3.91613\ttrain-rmse:2.02715\n",
      "[9614]\teval-rmse:3.91733\ttrain-rmse:2.02711\n",
      "[9615]\teval-rmse:3.91698\ttrain-rmse:2.0271\n",
      "[9616]\teval-rmse:3.91671\ttrain-rmse:2.02709\n",
      "[9617]\teval-rmse:3.91505\ttrain-rmse:2.02714\n",
      "[9618]\teval-rmse:3.91618\ttrain-rmse:2.02716\n",
      "[9619]\teval-rmse:3.91469\ttrain-rmse:2.02713\n",
      "[9620]\teval-rmse:3.91459\ttrain-rmse:2.02713\n",
      "[9621]\teval-rmse:3.91677\ttrain-rmse:2.02717\n",
      "[9622]\teval-rmse:3.91704\ttrain-rmse:2.02717\n",
      "[9623]\teval-rmse:3.917\ttrain-rmse:2.02717\n",
      "[9624]\teval-rmse:3.91548\ttrain-rmse:2.02714\n",
      "[9625]\teval-rmse:3.914\ttrain-rmse:2.02712\n",
      "[9626]\teval-rmse:3.91448\ttrain-rmse:2.02713\n",
      "[9627]\teval-rmse:3.91375\ttrain-rmse:2.02711\n",
      "[9628]\teval-rmse:3.91268\ttrain-rmse:2.02712\n",
      "[9629]\teval-rmse:3.91288\ttrain-rmse:2.02712\n",
      "[9630]\teval-rmse:3.91256\ttrain-rmse:2.02711\n",
      "[9631]\teval-rmse:3.91292\ttrain-rmse:2.02711\n",
      "[9632]\teval-rmse:3.91221\ttrain-rmse:2.02712\n",
      "[9633]\teval-rmse:3.91366\ttrain-rmse:2.02714\n",
      "[9634]\teval-rmse:3.91441\ttrain-rmse:2.02716\n",
      "[9635]\teval-rmse:3.91657\ttrain-rmse:2.02721\n",
      "[9636]\teval-rmse:3.91457\ttrain-rmse:2.02718\n",
      "[9637]\teval-rmse:3.91467\ttrain-rmse:2.02718\n",
      "[9638]\teval-rmse:3.91347\ttrain-rmse:2.02715\n",
      "[9639]\teval-rmse:3.91561\ttrain-rmse:2.0272\n",
      "[9640]\teval-rmse:3.91728\ttrain-rmse:2.02723\n",
      "[9641]\teval-rmse:3.91578\ttrain-rmse:2.02723\n",
      "[9642]\teval-rmse:3.91503\ttrain-rmse:2.02693\n",
      "[9643]\teval-rmse:3.91431\ttrain-rmse:2.02691\n",
      "[9644]\teval-rmse:3.91248\ttrain-rmse:2.02689\n",
      "[9645]\teval-rmse:3.91055\ttrain-rmse:2.02687\n",
      "[9646]\teval-rmse:3.91024\ttrain-rmse:2.02686\n",
      "[9647]\teval-rmse:3.91119\ttrain-rmse:2.02687\n",
      "[9648]\teval-rmse:3.91236\ttrain-rmse:2.0269\n",
      "[9649]\teval-rmse:3.91142\ttrain-rmse:2.02689\n",
      "[9650]\teval-rmse:3.90993\ttrain-rmse:2.02688\n",
      "[9651]\teval-rmse:3.91211\ttrain-rmse:2.02685\n",
      "[9652]\teval-rmse:3.9118\ttrain-rmse:2.02685\n",
      "[9653]\teval-rmse:3.91016\ttrain-rmse:2.02684\n",
      "[9654]\teval-rmse:3.9092\ttrain-rmse:2.02685\n",
      "[9655]\teval-rmse:3.907\ttrain-rmse:2.02685\n",
      "[9656]\teval-rmse:3.90723\ttrain-rmse:2.02685\n",
      "[9657]\teval-rmse:3.90844\ttrain-rmse:2.02684\n",
      "[9658]\teval-rmse:3.90748\ttrain-rmse:2.02685\n",
      "[9659]\teval-rmse:3.90889\ttrain-rmse:2.02682\n",
      "[9660]\teval-rmse:3.91075\ttrain-rmse:2.02679\n",
      "[9661]\teval-rmse:3.91042\ttrain-rmse:2.02679\n",
      "[9662]\teval-rmse:3.91184\ttrain-rmse:2.0268\n",
      "[9663]\teval-rmse:3.91238\ttrain-rmse:2.02681\n",
      "[9664]\teval-rmse:3.91383\ttrain-rmse:2.02682\n",
      "[9665]\teval-rmse:3.91571\ttrain-rmse:2.02685\n",
      "[9666]\teval-rmse:3.9145\ttrain-rmse:2.02682\n",
      "[9667]\teval-rmse:3.91511\ttrain-rmse:2.02683\n",
      "[9668]\teval-rmse:3.91589\ttrain-rmse:2.02684\n",
      "[9669]\teval-rmse:3.91516\ttrain-rmse:2.02684\n",
      "[9670]\teval-rmse:3.91442\ttrain-rmse:2.02659\n",
      "[9671]\teval-rmse:3.91538\ttrain-rmse:2.02662\n",
      "[9672]\teval-rmse:3.91328\ttrain-rmse:2.02658\n",
      "[9673]\teval-rmse:3.91256\ttrain-rmse:2.02656\n",
      "[9674]\teval-rmse:3.91308\ttrain-rmse:2.02657\n",
      "[9675]\teval-rmse:3.91341\ttrain-rmse:2.02658\n",
      "[9676]\teval-rmse:3.91487\ttrain-rmse:2.0266\n",
      "[9677]\teval-rmse:3.91367\ttrain-rmse:2.02658\n",
      "[9678]\teval-rmse:3.91482\ttrain-rmse:2.02661\n",
      "[9679]\teval-rmse:3.91387\ttrain-rmse:2.0266\n",
      "[9680]\teval-rmse:3.91597\ttrain-rmse:2.02659\n",
      "[9681]\teval-rmse:3.91763\ttrain-rmse:2.02655\n",
      "[9682]\teval-rmse:3.91547\ttrain-rmse:2.0265\n",
      "[9683]\teval-rmse:3.91524\ttrain-rmse:2.0265\n",
      "[9684]\teval-rmse:3.91522\ttrain-rmse:2.0265\n",
      "[9685]\teval-rmse:3.91355\ttrain-rmse:2.0265\n",
      "[9686]\teval-rmse:3.91475\ttrain-rmse:2.02645\n",
      "[9687]\teval-rmse:3.91444\ttrain-rmse:2.02645\n",
      "[9688]\teval-rmse:3.9129\ttrain-rmse:2.02645\n",
      "[9689]\teval-rmse:3.91186\ttrain-rmse:2.02644\n",
      "[9690]\teval-rmse:3.913\ttrain-rmse:2.02645\n",
      "[9691]\teval-rmse:3.91414\ttrain-rmse:2.02647\n",
      "[9692]\teval-rmse:3.91504\ttrain-rmse:2.02649\n",
      "[9693]\teval-rmse:3.91472\ttrain-rmse:2.02648\n",
      "[9694]\teval-rmse:3.91656\ttrain-rmse:2.02648\n",
      "[9695]\teval-rmse:3.91489\ttrain-rmse:2.02652\n",
      "[9696]\teval-rmse:3.91702\ttrain-rmse:2.02658\n",
      "[9697]\teval-rmse:3.91854\ttrain-rmse:2.02661\n",
      "[9698]\teval-rmse:3.92032\ttrain-rmse:2.02666\n",
      "[9699]\teval-rmse:3.92039\ttrain-rmse:2.02666\n",
      "[9700]\teval-rmse:3.92162\ttrain-rmse:2.0267\n",
      "[9701]\teval-rmse:3.92053\ttrain-rmse:2.02667\n",
      "[9702]\teval-rmse:3.91954\ttrain-rmse:2.02665\n",
      "[9703]\teval-rmse:3.91832\ttrain-rmse:2.02662\n",
      "[9704]\teval-rmse:3.91717\ttrain-rmse:2.02664\n",
      "[9705]\teval-rmse:3.91588\ttrain-rmse:2.02663\n",
      "[9706]\teval-rmse:3.91683\ttrain-rmse:2.02664\n",
      "[9707]\teval-rmse:3.91655\ttrain-rmse:2.02663\n",
      "[9708]\teval-rmse:3.91631\ttrain-rmse:2.02662\n",
      "[9709]\teval-rmse:3.91728\ttrain-rmse:2.02664\n",
      "[9710]\teval-rmse:3.91816\ttrain-rmse:2.02666\n",
      "[9711]\teval-rmse:3.9186\ttrain-rmse:2.02667\n",
      "[9712]\teval-rmse:3.91667\ttrain-rmse:2.02663\n",
      "[9713]\teval-rmse:3.91689\ttrain-rmse:2.02663\n",
      "[9714]\teval-rmse:3.9162\ttrain-rmse:2.02663\n",
      "[9715]\teval-rmse:3.91621\ttrain-rmse:2.02663\n",
      "[9716]\teval-rmse:3.91826\ttrain-rmse:2.02664\n",
      "[9717]\teval-rmse:3.91874\ttrain-rmse:2.02664\n",
      "[9718]\teval-rmse:3.91791\ttrain-rmse:2.02662\n",
      "[9719]\teval-rmse:3.91923\ttrain-rmse:2.02665\n",
      "[9720]\teval-rmse:3.92057\ttrain-rmse:2.02669\n",
      "[9721]\teval-rmse:3.92202\ttrain-rmse:2.02676\n",
      "[9722]\teval-rmse:3.92249\ttrain-rmse:2.02678\n",
      "[9723]\teval-rmse:3.92157\ttrain-rmse:2.02674\n",
      "[9724]\teval-rmse:3.92364\ttrain-rmse:2.02682\n",
      "[9725]\teval-rmse:3.92366\ttrain-rmse:2.02682\n",
      "[9726]\teval-rmse:3.92286\ttrain-rmse:2.0268\n",
      "[9727]\teval-rmse:3.92431\ttrain-rmse:2.02685\n",
      "[9728]\teval-rmse:3.92347\ttrain-rmse:2.02682\n",
      "[9729]\teval-rmse:3.92218\ttrain-rmse:2.02677\n",
      "[9730]\teval-rmse:3.92274\ttrain-rmse:2.02679\n",
      "[9731]\teval-rmse:3.92156\ttrain-rmse:2.02675\n",
      "[9732]\teval-rmse:3.9237\ttrain-rmse:2.02682\n",
      "[9733]\teval-rmse:3.92393\ttrain-rmse:2.02683\n",
      "[9734]\teval-rmse:3.92483\ttrain-rmse:2.02684\n",
      "[9735]\teval-rmse:3.92372\ttrain-rmse:2.0268\n",
      "[9736]\teval-rmse:3.92299\ttrain-rmse:2.02653\n",
      "[9737]\teval-rmse:3.92436\ttrain-rmse:2.02659\n",
      "[9738]\teval-rmse:3.9265\ttrain-rmse:2.02668\n",
      "[9739]\teval-rmse:3.92668\ttrain-rmse:2.02668\n",
      "[9740]\teval-rmse:3.92703\ttrain-rmse:2.0267\n",
      "[9741]\teval-rmse:3.92625\ttrain-rmse:2.02667\n",
      "[9742]\teval-rmse:3.92467\ttrain-rmse:2.0266\n",
      "[9743]\teval-rmse:3.92556\ttrain-rmse:2.02664\n",
      "[9744]\teval-rmse:3.92408\ttrain-rmse:2.02658\n",
      "[9745]\teval-rmse:3.92283\ttrain-rmse:2.02653\n",
      "[9746]\teval-rmse:3.92454\ttrain-rmse:2.02661\n",
      "[9747]\teval-rmse:3.92589\ttrain-rmse:2.02663\n",
      "[9748]\teval-rmse:3.92713\ttrain-rmse:2.0267\n",
      "[9749]\teval-rmse:3.92773\ttrain-rmse:2.02672\n",
      "[9750]\teval-rmse:3.92601\ttrain-rmse:2.02663\n",
      "[9751]\teval-rmse:3.92391\ttrain-rmse:2.02653\n",
      "[9752]\teval-rmse:3.92581\ttrain-rmse:2.02662\n",
      "[9753]\teval-rmse:3.92459\ttrain-rmse:2.02662\n",
      "[9754]\teval-rmse:3.92532\ttrain-rmse:2.02666\n",
      "[9755]\teval-rmse:3.92424\ttrain-rmse:2.02662\n",
      "[9756]\teval-rmse:3.92347\ttrain-rmse:2.02633\n",
      "[9757]\teval-rmse:3.92245\ttrain-rmse:2.02629\n",
      "[9758]\teval-rmse:3.92248\ttrain-rmse:2.0263\n",
      "[9759]\teval-rmse:3.92211\ttrain-rmse:2.02628\n",
      "[9760]\teval-rmse:3.9232\ttrain-rmse:2.02633\n",
      "[9761]\teval-rmse:3.92441\ttrain-rmse:2.02639\n",
      "[9762]\teval-rmse:3.92654\ttrain-rmse:2.02648\n",
      "[9763]\teval-rmse:3.92576\ttrain-rmse:2.02619\n",
      "[9764]\teval-rmse:3.92781\ttrain-rmse:2.02624\n",
      "[9765]\teval-rmse:3.92902\ttrain-rmse:2.02631\n",
      "[9766]\teval-rmse:3.92864\ttrain-rmse:2.02629\n",
      "[9767]\teval-rmse:3.92684\ttrain-rmse:2.02619\n",
      "[9768]\teval-rmse:3.92817\ttrain-rmse:2.02627\n",
      "[9769]\teval-rmse:3.92774\ttrain-rmse:2.02624\n",
      "[9770]\teval-rmse:3.92616\ttrain-rmse:2.0262\n",
      "[9771]\teval-rmse:3.92542\ttrain-rmse:2.02618\n",
      "[9772]\teval-rmse:3.92659\ttrain-rmse:2.02625\n",
      "[9773]\teval-rmse:3.92677\ttrain-rmse:2.02626\n",
      "[9774]\teval-rmse:3.92863\ttrain-rmse:2.0263\n",
      "[9775]\teval-rmse:3.92782\ttrain-rmse:2.02627\n",
      "[9776]\teval-rmse:3.92549\ttrain-rmse:2.02615\n",
      "[9777]\teval-rmse:3.92646\ttrain-rmse:2.02621\n",
      "[9778]\teval-rmse:3.92452\ttrain-rmse:2.02612\n",
      "[9779]\teval-rmse:3.92193\ttrain-rmse:2.02598\n",
      "[9780]\teval-rmse:3.92187\ttrain-rmse:2.02598\n",
      "[9781]\teval-rmse:3.92055\ttrain-rmse:2.02593\n",
      "[9782]\teval-rmse:3.92263\ttrain-rmse:2.02601\n",
      "[9783]\teval-rmse:3.92194\ttrain-rmse:2.02599\n",
      "[9784]\teval-rmse:3.92383\ttrain-rmse:2.02606\n",
      "[9785]\teval-rmse:3.92259\ttrain-rmse:2.026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9786]\teval-rmse:3.92136\ttrain-rmse:2.02596\n",
      "[9787]\teval-rmse:3.92112\ttrain-rmse:2.02595\n",
      "[9788]\teval-rmse:3.92204\ttrain-rmse:2.02598\n",
      "[9789]\teval-rmse:3.92421\ttrain-rmse:2.02596\n",
      "[9790]\teval-rmse:3.92348\ttrain-rmse:2.02593\n",
      "[9791]\teval-rmse:3.92441\ttrain-rmse:2.02595\n",
      "[9792]\teval-rmse:3.92607\ttrain-rmse:2.02598\n",
      "[9793]\teval-rmse:3.92519\ttrain-rmse:2.02596\n",
      "[9794]\teval-rmse:3.92654\ttrain-rmse:2.02603\n",
      "[9795]\teval-rmse:3.9252\ttrain-rmse:2.02597\n",
      "[9796]\teval-rmse:3.92686\ttrain-rmse:2.02605\n",
      "[9797]\teval-rmse:3.92706\ttrain-rmse:2.02606\n",
      "[9798]\teval-rmse:3.92788\ttrain-rmse:2.02611\n",
      "[9799]\teval-rmse:3.927\ttrain-rmse:2.02608\n",
      "[9800]\teval-rmse:3.9252\ttrain-rmse:2.026\n",
      "[9801]\teval-rmse:3.92578\ttrain-rmse:2.02603\n",
      "[9802]\teval-rmse:3.92524\ttrain-rmse:2.026\n",
      "[9803]\teval-rmse:3.92272\ttrain-rmse:2.02587\n",
      "[9804]\teval-rmse:3.9241\ttrain-rmse:2.0259\n",
      "[9805]\teval-rmse:3.92372\ttrain-rmse:2.02589\n",
      "[9806]\teval-rmse:3.92136\ttrain-rmse:2.02575\n",
      "[9807]\teval-rmse:3.92098\ttrain-rmse:2.02574\n",
      "[9808]\teval-rmse:3.92064\ttrain-rmse:2.02572\n",
      "[9809]\teval-rmse:3.92107\ttrain-rmse:2.02574\n",
      "[9810]\teval-rmse:3.91897\ttrain-rmse:2.02566\n",
      "[9811]\teval-rmse:3.9211\ttrain-rmse:2.02574\n",
      "[9812]\teval-rmse:3.91918\ttrain-rmse:2.02571\n",
      "[9813]\teval-rmse:3.9178\ttrain-rmse:2.02565\n",
      "[9814]\teval-rmse:3.91758\ttrain-rmse:2.02564\n",
      "[9815]\teval-rmse:3.91876\ttrain-rmse:2.02561\n",
      "[9816]\teval-rmse:3.92062\ttrain-rmse:2.0257\n",
      "[9817]\teval-rmse:3.92093\ttrain-rmse:2.02571\n",
      "[9818]\teval-rmse:3.92018\ttrain-rmse:2.02568\n",
      "[9819]\teval-rmse:3.92221\ttrain-rmse:2.02576\n",
      "[9820]\teval-rmse:3.92288\ttrain-rmse:2.02579\n",
      "[9821]\teval-rmse:3.92202\ttrain-rmse:2.02576\n",
      "[9822]\teval-rmse:3.92406\ttrain-rmse:2.02583\n",
      "[9823]\teval-rmse:3.9257\ttrain-rmse:2.02587\n",
      "[9824]\teval-rmse:3.92494\ttrain-rmse:2.02585\n",
      "[9825]\teval-rmse:3.92467\ttrain-rmse:2.02584\n",
      "[9826]\teval-rmse:3.92432\ttrain-rmse:2.02582\n",
      "[9827]\teval-rmse:3.92572\ttrain-rmse:2.02589\n",
      "[9828]\teval-rmse:3.92327\ttrain-rmse:2.02577\n",
      "[9829]\teval-rmse:3.92465\ttrain-rmse:2.0258\n",
      "[9830]\teval-rmse:3.92362\ttrain-rmse:2.02576\n",
      "[9831]\teval-rmse:3.92543\ttrain-rmse:2.0258\n",
      "[9832]\teval-rmse:3.92388\ttrain-rmse:2.02572\n",
      "[9833]\teval-rmse:3.92529\ttrain-rmse:2.02578\n",
      "[9834]\teval-rmse:3.92712\ttrain-rmse:2.02588\n",
      "[9835]\teval-rmse:3.92673\ttrain-rmse:2.02586\n",
      "[9836]\teval-rmse:3.92633\ttrain-rmse:2.02584\n",
      "[9837]\teval-rmse:3.92479\ttrain-rmse:2.02577\n",
      "[9838]\teval-rmse:3.92453\ttrain-rmse:2.02576\n",
      "[9839]\teval-rmse:3.92375\ttrain-rmse:2.02573\n",
      "[9840]\teval-rmse:3.92267\ttrain-rmse:2.02569\n",
      "[9841]\teval-rmse:3.92206\ttrain-rmse:2.02566\n",
      "[9842]\teval-rmse:3.92076\ttrain-rmse:2.02562\n",
      "[9843]\teval-rmse:3.92008\ttrain-rmse:2.02561\n",
      "[9844]\teval-rmse:3.92125\ttrain-rmse:2.02565\n",
      "[9845]\teval-rmse:3.92005\ttrain-rmse:2.02561\n",
      "[9846]\teval-rmse:3.92192\ttrain-rmse:2.02568\n",
      "[9847]\teval-rmse:3.9209\ttrain-rmse:2.02565\n",
      "[9848]\teval-rmse:3.92209\ttrain-rmse:2.02569\n",
      "[9849]\teval-rmse:3.9215\ttrain-rmse:2.02567\n",
      "[9850]\teval-rmse:3.91979\ttrain-rmse:2.02568\n",
      "[9851]\teval-rmse:3.91856\ttrain-rmse:2.02564\n",
      "[9852]\teval-rmse:3.91746\ttrain-rmse:2.02563\n",
      "[9853]\teval-rmse:3.91672\ttrain-rmse:2.02533\n",
      "[9854]\teval-rmse:3.91476\ttrain-rmse:2.02528\n",
      "[9855]\teval-rmse:3.91443\ttrain-rmse:2.02527\n",
      "[9856]\teval-rmse:3.91322\ttrain-rmse:2.02524\n",
      "[9857]\teval-rmse:3.91089\ttrain-rmse:2.02519\n",
      "[9858]\teval-rmse:3.91257\ttrain-rmse:2.02523\n",
      "[9859]\teval-rmse:3.91019\ttrain-rmse:2.02515\n",
      "[9860]\teval-rmse:3.9092\ttrain-rmse:2.02514\n",
      "[9861]\teval-rmse:3.91017\ttrain-rmse:2.02515\n",
      "[9862]\teval-rmse:3.90903\ttrain-rmse:2.02513\n",
      "[9863]\teval-rmse:3.9098\ttrain-rmse:2.02515\n",
      "[9864]\teval-rmse:3.91101\ttrain-rmse:2.02517\n",
      "[9865]\teval-rmse:3.91199\ttrain-rmse:2.02518\n",
      "[9866]\teval-rmse:3.90976\ttrain-rmse:2.02514\n",
      "[9867]\teval-rmse:3.91142\ttrain-rmse:2.02508\n",
      "[9868]\teval-rmse:3.91336\ttrain-rmse:2.02511\n",
      "[9869]\teval-rmse:3.91336\ttrain-rmse:2.02511\n",
      "[9870]\teval-rmse:3.91164\ttrain-rmse:2.02505\n",
      "[9871]\teval-rmse:3.90993\ttrain-rmse:2.02503\n",
      "[9872]\teval-rmse:3.91121\ttrain-rmse:2.02505\n",
      "[9873]\teval-rmse:3.91043\ttrain-rmse:2.02504\n",
      "[9874]\teval-rmse:3.91256\ttrain-rmse:2.02508\n",
      "[9875]\teval-rmse:3.91367\ttrain-rmse:2.0251\n",
      "[9876]\teval-rmse:3.91204\ttrain-rmse:2.02508\n",
      "[9877]\teval-rmse:3.91038\ttrain-rmse:2.02506\n",
      "[9878]\teval-rmse:3.90911\ttrain-rmse:2.02509\n",
      "[9879]\teval-rmse:3.90713\ttrain-rmse:2.02505\n",
      "[9880]\teval-rmse:3.90516\ttrain-rmse:2.02505\n",
      "[9881]\teval-rmse:3.90564\ttrain-rmse:2.02505\n",
      "[9882]\teval-rmse:3.90531\ttrain-rmse:2.02505\n",
      "[9883]\teval-rmse:3.90464\ttrain-rmse:2.02504\n",
      "[9884]\teval-rmse:3.9068\ttrain-rmse:2.02507\n",
      "[9885]\teval-rmse:3.90886\ttrain-rmse:2.02508\n",
      "[9886]\teval-rmse:3.90855\ttrain-rmse:2.02507\n",
      "[9887]\teval-rmse:3.90739\ttrain-rmse:2.02505\n",
      "[9888]\teval-rmse:3.90615\ttrain-rmse:2.02509\n",
      "[9889]\teval-rmse:3.90588\ttrain-rmse:2.02508\n",
      "[9890]\teval-rmse:3.9065\ttrain-rmse:2.02509\n",
      "[9891]\teval-rmse:3.90855\ttrain-rmse:2.02501\n",
      "[9892]\teval-rmse:3.90777\ttrain-rmse:2.025\n",
      "[9893]\teval-rmse:3.90942\ttrain-rmse:2.02503\n",
      "[9894]\teval-rmse:3.9079\ttrain-rmse:2.02502\n",
      "[9895]\teval-rmse:3.90906\ttrain-rmse:2.02505\n",
      "[9896]\teval-rmse:3.90792\ttrain-rmse:2.02502\n",
      "[9897]\teval-rmse:3.90907\ttrain-rmse:2.02503\n",
      "[9898]\teval-rmse:3.91003\ttrain-rmse:2.02503\n",
      "[9899]\teval-rmse:3.90912\ttrain-rmse:2.02502\n",
      "[9900]\teval-rmse:3.91025\ttrain-rmse:2.02504\n",
      "[9901]\teval-rmse:3.91158\ttrain-rmse:2.02507\n",
      "[9902]\teval-rmse:3.91062\ttrain-rmse:2.02504\n",
      "[9903]\teval-rmse:3.91031\ttrain-rmse:2.02503\n",
      "[9904]\teval-rmse:3.91051\ttrain-rmse:2.02504\n",
      "[9905]\teval-rmse:3.91028\ttrain-rmse:2.02503\n",
      "[9906]\teval-rmse:3.9083\ttrain-rmse:2.02504\n",
      "[9907]\teval-rmse:3.91021\ttrain-rmse:2.02503\n",
      "[9908]\teval-rmse:3.91135\ttrain-rmse:2.02505\n",
      "[9909]\teval-rmse:3.91248\ttrain-rmse:2.02508\n",
      "[9910]\teval-rmse:3.91463\ttrain-rmse:2.02513\n",
      "[9911]\teval-rmse:3.91261\ttrain-rmse:2.02513\n",
      "[9912]\teval-rmse:3.91188\ttrain-rmse:2.02513\n",
      "[9913]\teval-rmse:3.91326\ttrain-rmse:2.02513\n",
      "[9914]\teval-rmse:3.91311\ttrain-rmse:2.02512\n",
      "[9915]\teval-rmse:3.91295\ttrain-rmse:2.02512\n",
      "[9916]\teval-rmse:3.91193\ttrain-rmse:2.02512\n",
      "[9917]\teval-rmse:3.91099\ttrain-rmse:2.02509\n",
      "[9918]\teval-rmse:3.90985\ttrain-rmse:2.02508\n",
      "[9919]\teval-rmse:3.91013\ttrain-rmse:2.02508\n",
      "[9920]\teval-rmse:3.91142\ttrain-rmse:2.02511\n",
      "[9921]\teval-rmse:3.91152\ttrain-rmse:2.02511\n",
      "[9922]\teval-rmse:3.90986\ttrain-rmse:2.02516\n",
      "[9923]\teval-rmse:3.91016\ttrain-rmse:2.02516\n",
      "[9924]\teval-rmse:3.91095\ttrain-rmse:2.02519\n",
      "[9925]\teval-rmse:3.913\ttrain-rmse:2.02511\n",
      "[9926]\teval-rmse:3.91195\ttrain-rmse:2.02509\n",
      "[9927]\teval-rmse:3.91012\ttrain-rmse:2.02507\n",
      "[9928]\teval-rmse:3.90991\ttrain-rmse:2.02507\n",
      "[9929]\teval-rmse:3.90875\ttrain-rmse:2.02504\n",
      "[9930]\teval-rmse:3.91039\ttrain-rmse:2.02497\n",
      "[9931]\teval-rmse:3.90938\ttrain-rmse:2.02496\n",
      "[9932]\teval-rmse:3.90797\ttrain-rmse:2.02495\n",
      "[9933]\teval-rmse:3.90851\ttrain-rmse:2.02496\n",
      "[9934]\teval-rmse:3.9104\ttrain-rmse:2.02494\n",
      "[9935]\teval-rmse:3.91235\ttrain-rmse:2.02497\n",
      "[9936]\teval-rmse:3.91085\ttrain-rmse:2.02497\n",
      "[9937]\teval-rmse:3.90933\ttrain-rmse:2.02495\n",
      "[9938]\teval-rmse:3.91111\ttrain-rmse:2.02494\n",
      "[9939]\teval-rmse:3.91008\ttrain-rmse:2.02493\n",
      "[9940]\teval-rmse:3.90944\ttrain-rmse:2.02466\n",
      "[9941]\teval-rmse:3.90879\ttrain-rmse:2.02466\n",
      "[9942]\teval-rmse:3.90997\ttrain-rmse:2.02468\n",
      "[9943]\teval-rmse:3.91051\ttrain-rmse:2.02469\n",
      "[9944]\teval-rmse:3.91021\ttrain-rmse:2.02468\n",
      "[9945]\teval-rmse:3.90907\ttrain-rmse:2.02467\n",
      "[9946]\teval-rmse:3.9068\ttrain-rmse:2.02463\n",
      "[9947]\teval-rmse:3.9054\ttrain-rmse:2.02462\n",
      "[9948]\teval-rmse:3.90418\ttrain-rmse:2.02462\n",
      "[9949]\teval-rmse:3.90243\ttrain-rmse:2.02461\n",
      "[9950]\teval-rmse:3.90132\ttrain-rmse:2.02461\n",
      "[9951]\teval-rmse:3.90225\ttrain-rmse:2.02462\n",
      "[9952]\teval-rmse:3.90439\ttrain-rmse:2.02464\n",
      "[9953]\teval-rmse:3.90328\ttrain-rmse:2.02465\n",
      "[9954]\teval-rmse:3.90365\ttrain-rmse:2.02465\n",
      "[9955]\teval-rmse:3.90149\ttrain-rmse:2.02467\n",
      "[9956]\teval-rmse:3.90225\ttrain-rmse:2.02467\n",
      "[9957]\teval-rmse:3.90017\ttrain-rmse:2.02469\n",
      "[9958]\teval-rmse:3.89993\ttrain-rmse:2.02469\n",
      "[9959]\teval-rmse:3.90018\ttrain-rmse:2.02469\n",
      "[9960]\teval-rmse:3.90159\ttrain-rmse:2.02468\n",
      "[9961]\teval-rmse:3.89936\ttrain-rmse:2.02468\n",
      "[9962]\teval-rmse:3.89948\ttrain-rmse:2.02467\n",
      "[9963]\teval-rmse:3.89998\ttrain-rmse:2.02466\n",
      "[9964]\teval-rmse:3.89985\ttrain-rmse:2.02466\n",
      "[9965]\teval-rmse:3.902\ttrain-rmse:2.02468\n",
      "[9966]\teval-rmse:3.90087\ttrain-rmse:2.02467\n",
      "[9967]\teval-rmse:3.89908\ttrain-rmse:2.02469\n",
      "[9968]\teval-rmse:3.901\ttrain-rmse:2.02464\n",
      "[9969]\teval-rmse:3.90155\ttrain-rmse:2.02464\n",
      "[9970]\teval-rmse:3.90363\ttrain-rmse:2.02462\n",
      "[9971]\teval-rmse:3.90304\ttrain-rmse:2.02431\n",
      "[9972]\teval-rmse:3.90521\ttrain-rmse:2.02427\n",
      "[9973]\teval-rmse:3.9071\ttrain-rmse:2.02427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9974]\teval-rmse:3.90808\ttrain-rmse:2.02427\n",
      "[9975]\teval-rmse:3.90889\ttrain-rmse:2.02428\n",
      "[9976]\teval-rmse:3.90896\ttrain-rmse:2.02428\n",
      "[9977]\teval-rmse:3.90891\ttrain-rmse:2.02428\n",
      "[9978]\teval-rmse:3.90938\ttrain-rmse:2.02429\n",
      "[9979]\teval-rmse:3.91153\ttrain-rmse:2.02433\n",
      "[9980]\teval-rmse:3.91275\ttrain-rmse:2.02435\n",
      "[9981]\teval-rmse:3.91342\ttrain-rmse:2.02436\n",
      "[9982]\teval-rmse:3.91335\ttrain-rmse:2.02436\n",
      "[9983]\teval-rmse:3.91131\ttrain-rmse:2.02433\n",
      "[9984]\teval-rmse:3.9127\ttrain-rmse:2.02433\n",
      "[9985]\teval-rmse:3.91396\ttrain-rmse:2.02435\n",
      "[9986]\teval-rmse:3.91585\ttrain-rmse:2.02436\n",
      "[9987]\teval-rmse:3.9151\ttrain-rmse:2.02434\n",
      "[9988]\teval-rmse:3.91506\ttrain-rmse:2.02433\n",
      "[9989]\teval-rmse:3.91389\ttrain-rmse:2.02435\n",
      "[9990]\teval-rmse:3.91276\ttrain-rmse:2.02438\n",
      "[9991]\teval-rmse:3.91367\ttrain-rmse:2.02438\n",
      "[9992]\teval-rmse:3.91369\ttrain-rmse:2.02438\n",
      "[9993]\teval-rmse:3.9148\ttrain-rmse:2.0244\n",
      "[9994]\teval-rmse:3.916\ttrain-rmse:2.02443\n",
      "[9995]\teval-rmse:3.91499\ttrain-rmse:2.0244\n",
      "[9996]\teval-rmse:3.91537\ttrain-rmse:2.02441\n",
      "[9997]\teval-rmse:3.91422\ttrain-rmse:2.02444\n",
      "[9998]\teval-rmse:3.91314\ttrain-rmse:2.02443\n",
      "[9999]\teval-rmse:3.91423\ttrain-rmse:2.02446\n",
      "[10000]\teval-rmse:3.91636\ttrain-rmse:2.02452\n",
      "[10001]\teval-rmse:3.91518\ttrain-rmse:2.02449\n",
      "[10002]\teval-rmse:3.91449\ttrain-rmse:2.02423\n",
      "[10003]\teval-rmse:3.91294\ttrain-rmse:2.0242\n",
      "[10004]\teval-rmse:3.9137\ttrain-rmse:2.02422\n",
      "[10005]\teval-rmse:3.91561\ttrain-rmse:2.02426\n",
      "[10006]\teval-rmse:3.91337\ttrain-rmse:2.02421\n",
      "[10007]\teval-rmse:3.91312\ttrain-rmse:2.02421\n",
      "[10008]\teval-rmse:3.91289\ttrain-rmse:2.0242\n",
      "[10009]\teval-rmse:3.91494\ttrain-rmse:2.02424\n",
      "[10010]\teval-rmse:3.91707\ttrain-rmse:2.0243\n",
      "[10011]\teval-rmse:3.91578\ttrain-rmse:2.02433\n",
      "[10012]\teval-rmse:3.91783\ttrain-rmse:2.02428\n",
      "[10013]\teval-rmse:3.9197\ttrain-rmse:2.0243\n",
      "[10014]\teval-rmse:3.92129\ttrain-rmse:2.02435\n",
      "[10015]\teval-rmse:3.91961\ttrain-rmse:2.02429\n",
      "[10016]\teval-rmse:3.91834\ttrain-rmse:2.02425\n",
      "[10017]\teval-rmse:3.91759\ttrain-rmse:2.02423\n",
      "[10018]\teval-rmse:3.91736\ttrain-rmse:2.02422\n",
      "[10019]\teval-rmse:3.9166\ttrain-rmse:2.02396\n",
      "[10020]\teval-rmse:3.91592\ttrain-rmse:2.02368\n",
      "[10021]\teval-rmse:3.91733\ttrain-rmse:2.02372\n",
      "[10022]\teval-rmse:3.91836\ttrain-rmse:2.02377\n",
      "[10023]\teval-rmse:3.91814\ttrain-rmse:2.02376\n",
      "[10024]\teval-rmse:3.91886\ttrain-rmse:2.02379\n",
      "[10025]\teval-rmse:3.91996\ttrain-rmse:2.02383\n",
      "[10026]\teval-rmse:3.9196\ttrain-rmse:2.02382\n",
      "[10027]\teval-rmse:3.91861\ttrain-rmse:2.02379\n",
      "[10028]\teval-rmse:3.91835\ttrain-rmse:2.02378\n",
      "[10029]\teval-rmse:3.91645\ttrain-rmse:2.02373\n",
      "[10030]\teval-rmse:3.9176\ttrain-rmse:2.02369\n",
      "[10031]\teval-rmse:3.91948\ttrain-rmse:2.02376\n",
      "[10032]\teval-rmse:3.91926\ttrain-rmse:2.02375\n",
      "[10033]\teval-rmse:3.92005\ttrain-rmse:2.02379\n",
      "[10034]\teval-rmse:3.9188\ttrain-rmse:2.02374\n",
      "[10035]\teval-rmse:3.91751\ttrain-rmse:2.0237\n",
      "[10036]\teval-rmse:3.91652\ttrain-rmse:2.02367\n",
      "[10037]\teval-rmse:3.91719\ttrain-rmse:2.02368\n",
      "[10038]\teval-rmse:3.91637\ttrain-rmse:2.02367\n",
      "[10039]\teval-rmse:3.91687\ttrain-rmse:2.02368\n",
      "[10040]\teval-rmse:3.91696\ttrain-rmse:2.02369\n",
      "[10041]\teval-rmse:3.91734\ttrain-rmse:2.0237\n",
      "[10042]\teval-rmse:3.91616\ttrain-rmse:2.02369\n",
      "[10043]\teval-rmse:3.91658\ttrain-rmse:2.0237\n",
      "[10044]\teval-rmse:3.91486\ttrain-rmse:2.02363\n",
      "[10045]\teval-rmse:3.91537\ttrain-rmse:2.02365\n",
      "[10046]\teval-rmse:3.91463\ttrain-rmse:2.02342\n",
      "[10047]\teval-rmse:3.91336\ttrain-rmse:2.02341\n",
      "[10048]\teval-rmse:3.9122\ttrain-rmse:2.02338\n",
      "[10049]\teval-rmse:3.91055\ttrain-rmse:2.02335\n",
      "[10050]\teval-rmse:3.90999\ttrain-rmse:2.02335\n",
      "[10051]\teval-rmse:3.9105\ttrain-rmse:2.02335\n",
      "[10052]\teval-rmse:3.91241\ttrain-rmse:2.02335\n",
      "[10053]\teval-rmse:3.91338\ttrain-rmse:2.02337\n",
      "[10054]\teval-rmse:3.91458\ttrain-rmse:2.0234\n",
      "[10055]\teval-rmse:3.91601\ttrain-rmse:2.02343\n",
      "[10056]\teval-rmse:3.91761\ttrain-rmse:2.02347\n",
      "[10057]\teval-rmse:3.91726\ttrain-rmse:2.02346\n",
      "[10058]\teval-rmse:3.91779\ttrain-rmse:2.02348\n",
      "[10059]\teval-rmse:3.91634\ttrain-rmse:2.02346\n",
      "[10060]\teval-rmse:3.9156\ttrain-rmse:2.02344\n",
      "[10061]\teval-rmse:3.91487\ttrain-rmse:2.02342\n",
      "[10062]\teval-rmse:3.91617\ttrain-rmse:2.02346\n",
      "[10063]\teval-rmse:3.91764\ttrain-rmse:2.02354\n",
      "[10064]\teval-rmse:3.9156\ttrain-rmse:2.02351\n",
      "[10065]\teval-rmse:3.91575\ttrain-rmse:2.02351\n",
      "[10066]\teval-rmse:3.91548\ttrain-rmse:2.0235\n",
      "[10067]\teval-rmse:3.91694\ttrain-rmse:2.02354\n",
      "[10068]\teval-rmse:3.9187\ttrain-rmse:2.0236\n",
      "[10069]\teval-rmse:3.9185\ttrain-rmse:2.02359\n",
      "[10070]\teval-rmse:3.91878\ttrain-rmse:2.0236\n",
      "[10071]\teval-rmse:3.91854\ttrain-rmse:2.0236\n",
      "[10072]\teval-rmse:3.92065\ttrain-rmse:2.02367\n",
      "[10073]\teval-rmse:3.91966\ttrain-rmse:2.02363\n",
      "[10074]\teval-rmse:3.92083\ttrain-rmse:2.02365\n",
      "[10075]\teval-rmse:3.92243\ttrain-rmse:2.02374\n",
      "[10076]\teval-rmse:3.9234\ttrain-rmse:2.02378\n",
      "[10077]\teval-rmse:3.9212\ttrain-rmse:2.02367\n",
      "[10078]\teval-rmse:3.9204\ttrain-rmse:2.02364\n",
      "[10079]\teval-rmse:3.91915\ttrain-rmse:2.0236\n",
      "[10080]\teval-rmse:3.91785\ttrain-rmse:2.02361\n",
      "[10081]\teval-rmse:3.9188\ttrain-rmse:2.02364\n",
      "[10082]\teval-rmse:3.91806\ttrain-rmse:2.02362\n",
      "[10083]\teval-rmse:3.91772\ttrain-rmse:2.02361\n",
      "[10084]\teval-rmse:3.91601\ttrain-rmse:2.02358\n",
      "[10085]\teval-rmse:3.91579\ttrain-rmse:2.02357\n",
      "[10086]\teval-rmse:3.91792\ttrain-rmse:2.02352\n",
      "[10087]\teval-rmse:3.91767\ttrain-rmse:2.02352\n",
      "[10088]\teval-rmse:3.91789\ttrain-rmse:2.02352\n",
      "[10089]\teval-rmse:3.91992\ttrain-rmse:2.02356\n",
      "[10090]\teval-rmse:3.91921\ttrain-rmse:2.02328\n",
      "[10091]\teval-rmse:3.91942\ttrain-rmse:2.02329\n",
      "[10092]\teval-rmse:3.91782\ttrain-rmse:2.02323\n",
      "[10093]\teval-rmse:3.9188\ttrain-rmse:2.02326\n",
      "[10094]\teval-rmse:3.92093\ttrain-rmse:2.02334\n",
      "[10095]\teval-rmse:3.92164\ttrain-rmse:2.02336\n",
      "[10096]\teval-rmse:3.92235\ttrain-rmse:2.0234\n",
      "[10097]\teval-rmse:3.92208\ttrain-rmse:2.02339\n",
      "[10098]\teval-rmse:3.92221\ttrain-rmse:2.02339\n",
      "[10099]\teval-rmse:3.921\ttrain-rmse:2.02334\n",
      "[10100]\teval-rmse:3.92065\ttrain-rmse:2.02332\n",
      "[10101]\teval-rmse:3.92136\ttrain-rmse:2.02335\n",
      "[10102]\teval-rmse:3.91965\ttrain-rmse:2.02329\n",
      "[10103]\teval-rmse:3.9179\ttrain-rmse:2.0232\n",
      "[10104]\teval-rmse:3.91872\ttrain-rmse:2.02321\n",
      "[10105]\teval-rmse:3.91801\ttrain-rmse:2.02319\n",
      "[10106]\teval-rmse:3.91578\ttrain-rmse:2.02313\n",
      "[10107]\teval-rmse:3.91728\ttrain-rmse:2.02319\n",
      "[10108]\teval-rmse:3.91623\ttrain-rmse:2.02316\n",
      "[10109]\teval-rmse:3.91432\ttrain-rmse:2.02311\n",
      "[10110]\teval-rmse:3.91497\ttrain-rmse:2.02312\n",
      "[10111]\teval-rmse:3.91378\ttrain-rmse:2.02314\n",
      "[10112]\teval-rmse:3.91342\ttrain-rmse:2.02313\n",
      "[10113]\teval-rmse:3.91545\ttrain-rmse:2.02308\n",
      "[10114]\teval-rmse:3.91599\ttrain-rmse:2.0231\n",
      "[10115]\teval-rmse:3.91406\ttrain-rmse:2.02305\n",
      "[10116]\teval-rmse:3.91213\ttrain-rmse:2.02301\n",
      "[10117]\teval-rmse:3.91114\ttrain-rmse:2.02298\n",
      "[10118]\teval-rmse:3.9128\ttrain-rmse:2.02302\n",
      "[10119]\teval-rmse:3.91461\ttrain-rmse:2.02303\n",
      "[10120]\teval-rmse:3.91638\ttrain-rmse:2.02305\n",
      "[10121]\teval-rmse:3.91474\ttrain-rmse:2.023\n",
      "[10122]\teval-rmse:3.91404\ttrain-rmse:2.02299\n",
      "[10123]\teval-rmse:3.91301\ttrain-rmse:2.02299\n",
      "[10124]\teval-rmse:3.91197\ttrain-rmse:2.02298\n",
      "[10125]\teval-rmse:3.91213\ttrain-rmse:2.02298\n",
      "[10126]\teval-rmse:3.91009\ttrain-rmse:2.02295\n",
      "[10127]\teval-rmse:3.9089\ttrain-rmse:2.02293\n",
      "[10128]\teval-rmse:3.90793\ttrain-rmse:2.02292\n",
      "[10129]\teval-rmse:3.90887\ttrain-rmse:2.02294\n",
      "[10130]\teval-rmse:3.9094\ttrain-rmse:2.02295\n",
      "[10131]\teval-rmse:3.91017\ttrain-rmse:2.02296\n",
      "[10132]\teval-rmse:3.91056\ttrain-rmse:2.02296\n",
      "[10133]\teval-rmse:3.90967\ttrain-rmse:2.02295\n",
      "[10134]\teval-rmse:3.90983\ttrain-rmse:2.02295\n",
      "[10135]\teval-rmse:3.91002\ttrain-rmse:2.02296\n",
      "[10136]\teval-rmse:3.91047\ttrain-rmse:2.02295\n",
      "[10137]\teval-rmse:3.91125\ttrain-rmse:2.02297\n",
      "[10138]\teval-rmse:3.91208\ttrain-rmse:2.02299\n",
      "[10139]\teval-rmse:3.91222\ttrain-rmse:2.02299\n",
      "[10140]\teval-rmse:3.91086\ttrain-rmse:2.02297\n",
      "[10141]\teval-rmse:3.90876\ttrain-rmse:2.02294\n",
      "[10142]\teval-rmse:3.90961\ttrain-rmse:2.02295\n",
      "[10143]\teval-rmse:3.90938\ttrain-rmse:2.02294\n",
      "[10144]\teval-rmse:3.91143\ttrain-rmse:2.02294\n",
      "[10145]\teval-rmse:3.91154\ttrain-rmse:2.02294\n",
      "[10146]\teval-rmse:3.90974\ttrain-rmse:2.0229\n",
      "[10147]\teval-rmse:3.9117\ttrain-rmse:2.02292\n",
      "[10148]\teval-rmse:3.91244\ttrain-rmse:2.02294\n",
      "[10149]\teval-rmse:3.91437\ttrain-rmse:2.02298\n",
      "[10150]\teval-rmse:3.9153\ttrain-rmse:2.023\n",
      "[10151]\teval-rmse:3.91423\ttrain-rmse:2.02299\n",
      "[10152]\teval-rmse:3.91284\ttrain-rmse:2.02296\n",
      "[10153]\teval-rmse:3.91214\ttrain-rmse:2.02294\n",
      "[10154]\teval-rmse:3.91134\ttrain-rmse:2.02294\n",
      "[10155]\teval-rmse:3.9121\ttrain-rmse:2.02295\n",
      "[10156]\teval-rmse:3.91001\ttrain-rmse:2.02289\n",
      "[10157]\teval-rmse:3.9097\ttrain-rmse:2.02289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10158]\teval-rmse:3.91134\ttrain-rmse:2.02283\n",
      "[10159]\teval-rmse:3.91304\ttrain-rmse:2.02286\n",
      "[10160]\teval-rmse:3.91111\ttrain-rmse:2.02282\n",
      "[10161]\teval-rmse:3.9123\ttrain-rmse:2.02282\n",
      "[10162]\teval-rmse:3.91075\ttrain-rmse:2.02282\n",
      "[10163]\teval-rmse:3.91091\ttrain-rmse:2.02282\n",
      "[10164]\teval-rmse:3.91305\ttrain-rmse:2.02282\n",
      "[10165]\teval-rmse:3.91299\ttrain-rmse:2.02282\n",
      "[10166]\teval-rmse:3.91323\ttrain-rmse:2.02283\n",
      "[10167]\teval-rmse:3.91489\ttrain-rmse:2.02279\n",
      "[10168]\teval-rmse:3.91564\ttrain-rmse:2.02282\n",
      "[10169]\teval-rmse:3.9151\ttrain-rmse:2.0228\n",
      "[10170]\teval-rmse:3.91437\ttrain-rmse:2.02251\n",
      "[10171]\teval-rmse:3.91243\ttrain-rmse:2.02247\n",
      "[10172]\teval-rmse:3.91175\ttrain-rmse:2.02221\n",
      "[10173]\teval-rmse:3.90983\ttrain-rmse:2.02218\n",
      "[10174]\teval-rmse:3.91058\ttrain-rmse:2.02219\n",
      "[10175]\teval-rmse:3.912\ttrain-rmse:2.02222\n",
      "[10176]\teval-rmse:3.91129\ttrain-rmse:2.02195\n",
      "[10177]\teval-rmse:3.91264\ttrain-rmse:2.02199\n",
      "[10178]\teval-rmse:3.91298\ttrain-rmse:2.022\n",
      "[10179]\teval-rmse:3.91366\ttrain-rmse:2.02203\n",
      "[10180]\teval-rmse:3.91581\ttrain-rmse:2.02208\n",
      "[10181]\teval-rmse:3.91546\ttrain-rmse:2.02207\n",
      "[10182]\teval-rmse:3.91397\ttrain-rmse:2.02203\n",
      "[10183]\teval-rmse:3.91585\ttrain-rmse:2.02208\n",
      "[10184]\teval-rmse:3.91363\ttrain-rmse:2.02202\n",
      "[10185]\teval-rmse:3.91242\ttrain-rmse:2.02198\n",
      "[10186]\teval-rmse:3.91088\ttrain-rmse:2.02197\n",
      "[10187]\teval-rmse:3.91301\ttrain-rmse:2.02191\n",
      "[10188]\teval-rmse:3.9123\ttrain-rmse:2.02191\n",
      "[10189]\teval-rmse:3.91368\ttrain-rmse:2.02191\n",
      "[10190]\teval-rmse:3.91303\ttrain-rmse:2.0219\n",
      "[10191]\teval-rmse:3.91398\ttrain-rmse:2.02192\n",
      "[10192]\teval-rmse:3.91372\ttrain-rmse:2.02191\n",
      "[10193]\teval-rmse:3.91303\ttrain-rmse:2.02191\n",
      "[10194]\teval-rmse:3.91266\ttrain-rmse:2.0219\n",
      "[10195]\teval-rmse:3.91351\ttrain-rmse:2.02192\n",
      "[10196]\teval-rmse:3.91452\ttrain-rmse:2.02196\n",
      "[10197]\teval-rmse:3.91517\ttrain-rmse:2.02197\n",
      "[10198]\teval-rmse:3.91394\ttrain-rmse:2.02194\n",
      "[10199]\teval-rmse:3.91452\ttrain-rmse:2.02195\n",
      "[10200]\teval-rmse:3.91637\ttrain-rmse:2.02201\n",
      "[10201]\teval-rmse:3.9166\ttrain-rmse:2.02202\n",
      "[10202]\teval-rmse:3.91767\ttrain-rmse:2.02205\n",
      "[10203]\teval-rmse:3.9197\ttrain-rmse:2.02213\n",
      "[10204]\teval-rmse:3.91736\ttrain-rmse:2.02202\n",
      "[10205]\teval-rmse:3.91522\ttrain-rmse:2.02195\n",
      "[10206]\teval-rmse:3.91525\ttrain-rmse:2.02195\n",
      "[10207]\teval-rmse:3.9137\ttrain-rmse:2.02193\n",
      "[10208]\teval-rmse:3.91552\ttrain-rmse:2.02198\n",
      "[10209]\teval-rmse:3.91742\ttrain-rmse:2.02206\n",
      "[10210]\teval-rmse:3.91539\ttrain-rmse:2.02199\n",
      "[10211]\teval-rmse:3.91556\ttrain-rmse:2.022\n",
      "[10212]\teval-rmse:3.91534\ttrain-rmse:2.02199\n",
      "[10213]\teval-rmse:3.91499\ttrain-rmse:2.02198\n",
      "[10214]\teval-rmse:3.91493\ttrain-rmse:2.02198\n",
      "[10215]\teval-rmse:3.9142\ttrain-rmse:2.02196\n",
      "[10216]\teval-rmse:3.9147\ttrain-rmse:2.02197\n",
      "[10217]\teval-rmse:3.91293\ttrain-rmse:2.02191\n",
      "[10218]\teval-rmse:3.91067\ttrain-rmse:2.02183\n",
      "[10219]\teval-rmse:3.91183\ttrain-rmse:2.0218\n",
      "[10220]\teval-rmse:3.91376\ttrain-rmse:2.02184\n",
      "[10221]\teval-rmse:3.91273\ttrain-rmse:2.02183\n",
      "[10222]\teval-rmse:3.91165\ttrain-rmse:2.0218\n",
      "[10223]\teval-rmse:3.91247\ttrain-rmse:2.02183\n",
      "[10224]\teval-rmse:3.91223\ttrain-rmse:2.02182\n",
      "[10225]\teval-rmse:3.91102\ttrain-rmse:2.02178\n",
      "[10226]\teval-rmse:3.91199\ttrain-rmse:2.02182\n",
      "[10227]\teval-rmse:3.91411\ttrain-rmse:2.02188\n",
      "[10228]\teval-rmse:3.91378\ttrain-rmse:2.02187\n",
      "[10229]\teval-rmse:3.91547\ttrain-rmse:2.02192\n",
      "[10230]\teval-rmse:3.91667\ttrain-rmse:2.02198\n",
      "[10231]\teval-rmse:3.91444\ttrain-rmse:2.02191\n",
      "[10232]\teval-rmse:3.91377\ttrain-rmse:2.0219\n",
      "[10233]\teval-rmse:3.9149\ttrain-rmse:2.02196\n",
      "[10234]\teval-rmse:3.91584\ttrain-rmse:2.022\n",
      "[10235]\teval-rmse:3.91387\ttrain-rmse:2.02193\n",
      "[10236]\teval-rmse:3.91418\ttrain-rmse:2.02195\n",
      "[10237]\teval-rmse:3.9135\ttrain-rmse:2.02193\n",
      "[10238]\teval-rmse:3.91229\ttrain-rmse:2.0219\n",
      "[10239]\teval-rmse:3.91321\ttrain-rmse:2.02192\n",
      "[10240]\teval-rmse:3.91513\ttrain-rmse:2.02198\n",
      "[10241]\teval-rmse:3.91628\ttrain-rmse:2.02195\n",
      "[10242]\teval-rmse:3.91751\ttrain-rmse:2.022\n",
      "[10243]\teval-rmse:3.91863\ttrain-rmse:2.02205\n",
      "[10244]\teval-rmse:3.92003\ttrain-rmse:2.0221\n",
      "[10245]\teval-rmse:3.92204\ttrain-rmse:2.02219\n",
      "[10246]\teval-rmse:3.92197\ttrain-rmse:2.02219\n",
      "[10247]\teval-rmse:3.92119\ttrain-rmse:2.02216\n",
      "[10248]\teval-rmse:3.92149\ttrain-rmse:2.02217\n",
      "[10249]\teval-rmse:3.92033\ttrain-rmse:2.02211\n",
      "[10250]\teval-rmse:3.91956\ttrain-rmse:2.02184\n",
      "[10251]\teval-rmse:3.92133\ttrain-rmse:2.02189\n",
      "[10252]\teval-rmse:3.92212\ttrain-rmse:2.02191\n",
      "[10253]\teval-rmse:3.92325\ttrain-rmse:2.02191\n",
      "[10254]\teval-rmse:3.92537\ttrain-rmse:2.02201\n",
      "[10255]\teval-rmse:3.92633\ttrain-rmse:2.02206\n",
      "[10256]\teval-rmse:3.92593\ttrain-rmse:2.02204\n",
      "[10257]\teval-rmse:3.92462\ttrain-rmse:2.02196\n",
      "[10258]\teval-rmse:3.92423\ttrain-rmse:2.02195\n",
      "[10259]\teval-rmse:3.92287\ttrain-rmse:2.0219\n",
      "[10260]\teval-rmse:3.92209\ttrain-rmse:2.02186\n",
      "[10261]\teval-rmse:3.92172\ttrain-rmse:2.02185\n",
      "[10262]\teval-rmse:3.9211\ttrain-rmse:2.02182\n",
      "[10263]\teval-rmse:3.92067\ttrain-rmse:2.0218\n",
      "[10264]\teval-rmse:3.92069\ttrain-rmse:2.0218\n",
      "[10265]\teval-rmse:3.92031\ttrain-rmse:2.02178\n",
      "[10266]\teval-rmse:3.91954\ttrain-rmse:2.0215\n",
      "[10267]\teval-rmse:3.92041\ttrain-rmse:2.02152\n",
      "[10268]\teval-rmse:3.91814\ttrain-rmse:2.02143\n",
      "[10269]\teval-rmse:3.91702\ttrain-rmse:2.02137\n",
      "[10270]\teval-rmse:3.91764\ttrain-rmse:2.0214\n",
      "[10271]\teval-rmse:3.91727\ttrain-rmse:2.02138\n",
      "[10272]\teval-rmse:3.91892\ttrain-rmse:2.02135\n",
      "[10273]\teval-rmse:3.91972\ttrain-rmse:2.0214\n",
      "[10274]\teval-rmse:3.91916\ttrain-rmse:2.02138\n",
      "[10275]\teval-rmse:3.91891\ttrain-rmse:2.02136\n",
      "[10276]\teval-rmse:3.91853\ttrain-rmse:2.02135\n",
      "[10277]\teval-rmse:3.91828\ttrain-rmse:2.02134\n",
      "[10278]\teval-rmse:3.9179\ttrain-rmse:2.02133\n",
      "[10279]\teval-rmse:3.92001\ttrain-rmse:2.02138\n",
      "[10280]\teval-rmse:3.9208\ttrain-rmse:2.0214\n",
      "[10281]\teval-rmse:3.92168\ttrain-rmse:2.02142\n",
      "[10282]\teval-rmse:3.92282\ttrain-rmse:2.02148\n",
      "[10283]\teval-rmse:3.92311\ttrain-rmse:2.0215\n",
      "[10284]\teval-rmse:3.92381\ttrain-rmse:2.02154\n",
      "[10285]\teval-rmse:3.9245\ttrain-rmse:2.02157\n",
      "[10286]\teval-rmse:3.9236\ttrain-rmse:2.02151\n",
      "[10287]\teval-rmse:3.92193\ttrain-rmse:2.02141\n",
      "[10288]\teval-rmse:3.92118\ttrain-rmse:2.02139\n",
      "[10289]\teval-rmse:3.91874\ttrain-rmse:2.02124\n",
      "[10290]\teval-rmse:3.92011\ttrain-rmse:2.02132\n",
      "[10291]\teval-rmse:3.9194\ttrain-rmse:2.02102\n",
      "[10292]\teval-rmse:3.91763\ttrain-rmse:2.02095\n",
      "[10293]\teval-rmse:3.91539\ttrain-rmse:2.02086\n",
      "[10294]\teval-rmse:3.91674\ttrain-rmse:2.02091\n",
      "[10295]\teval-rmse:3.91601\ttrain-rmse:2.02089\n",
      "[10296]\teval-rmse:3.91528\ttrain-rmse:2.02086\n",
      "[10297]\teval-rmse:3.91625\ttrain-rmse:2.02089\n",
      "[10298]\teval-rmse:3.91836\ttrain-rmse:2.02097\n",
      "[10299]\teval-rmse:3.91678\ttrain-rmse:2.02093\n",
      "[10300]\teval-rmse:3.91574\ttrain-rmse:2.02089\n",
      "[10301]\teval-rmse:3.91354\ttrain-rmse:2.02082\n",
      "[10302]\teval-rmse:3.91132\ttrain-rmse:2.02075\n",
      "[10303]\teval-rmse:3.91011\ttrain-rmse:2.02077\n",
      "[10304]\teval-rmse:3.90765\ttrain-rmse:2.0207\n",
      "[10305]\teval-rmse:3.90732\ttrain-rmse:2.02069\n",
      "[10306]\teval-rmse:3.90873\ttrain-rmse:2.02072\n",
      "[10307]\teval-rmse:3.90807\ttrain-rmse:2.02071\n",
      "[10308]\teval-rmse:3.90738\ttrain-rmse:2.02046\n",
      "[10309]\teval-rmse:3.90669\ttrain-rmse:2.02044\n",
      "[10310]\teval-rmse:3.90556\ttrain-rmse:2.02041\n",
      "[10311]\teval-rmse:3.9074\ttrain-rmse:2.02046\n",
      "[10312]\teval-rmse:3.90665\ttrain-rmse:2.02046\n",
      "[10313]\teval-rmse:3.90692\ttrain-rmse:2.02046\n",
      "[10314]\teval-rmse:3.90672\ttrain-rmse:2.02045\n",
      "[10315]\teval-rmse:3.90765\ttrain-rmse:2.02047\n",
      "[10316]\teval-rmse:3.90604\ttrain-rmse:2.02042\n",
      "[10317]\teval-rmse:3.90412\ttrain-rmse:2.02039\n",
      "[10318]\teval-rmse:3.90381\ttrain-rmse:2.02039\n",
      "[10319]\teval-rmse:3.90361\ttrain-rmse:2.02038\n",
      "[10320]\teval-rmse:3.90294\ttrain-rmse:2.02037\n",
      "[10321]\teval-rmse:3.90226\ttrain-rmse:2.02036\n",
      "[10322]\teval-rmse:3.90112\ttrain-rmse:2.0204\n",
      "[10323]\teval-rmse:3.89965\ttrain-rmse:2.02041\n",
      "[10324]\teval-rmse:3.89775\ttrain-rmse:2.02041\n",
      "[10325]\teval-rmse:3.89663\ttrain-rmse:2.0204\n",
      "[10326]\teval-rmse:3.89574\ttrain-rmse:2.02041\n",
      "[10327]\teval-rmse:3.89463\ttrain-rmse:2.0204\n",
      "[10328]\teval-rmse:3.8961\ttrain-rmse:2.0204\n",
      "[10329]\teval-rmse:3.89445\ttrain-rmse:2.0204\n",
      "[10330]\teval-rmse:3.89571\ttrain-rmse:2.02039\n",
      "[10331]\teval-rmse:3.8946\ttrain-rmse:2.02039\n",
      "[10332]\teval-rmse:3.89674\ttrain-rmse:2.02028\n",
      "[10333]\teval-rmse:3.89605\ttrain-rmse:2.0203\n",
      "[10334]\teval-rmse:3.89493\ttrain-rmse:2.0203\n",
      "[10335]\teval-rmse:3.89372\ttrain-rmse:2.02031\n",
      "[10336]\teval-rmse:3.89206\ttrain-rmse:2.02033\n",
      "[10337]\teval-rmse:3.89145\ttrain-rmse:2.02033\n",
      "[10338]\teval-rmse:3.89083\ttrain-rmse:2.02034\n",
      "[10339]\teval-rmse:3.88975\ttrain-rmse:2.02039\n",
      "[10340]\teval-rmse:3.89109\ttrain-rmse:2.02037\n",
      "[10341]\teval-rmse:3.89093\ttrain-rmse:2.02037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10342]\teval-rmse:3.89274\ttrain-rmse:2.02032\n",
      "[10343]\teval-rmse:3.89081\ttrain-rmse:2.02032\n",
      "[10344]\teval-rmse:3.89184\ttrain-rmse:2.02032\n",
      "[10345]\teval-rmse:3.89074\ttrain-rmse:2.02032\n",
      "[10346]\teval-rmse:3.89173\ttrain-rmse:2.02032\n",
      "[10347]\teval-rmse:3.892\ttrain-rmse:2.02032\n",
      "[10348]\teval-rmse:3.89415\ttrain-rmse:2.02032\n",
      "[10349]\teval-rmse:3.89599\ttrain-rmse:2.02031\n",
      "[10350]\teval-rmse:3.89454\ttrain-rmse:2.02033\n",
      "[10351]\teval-rmse:3.8943\ttrain-rmse:2.02034\n",
      "[10352]\teval-rmse:3.89633\ttrain-rmse:2.02024\n",
      "[10353]\teval-rmse:3.8945\ttrain-rmse:2.02025\n",
      "[10354]\teval-rmse:3.89636\ttrain-rmse:2.02026\n",
      "[10355]\teval-rmse:3.89425\ttrain-rmse:2.02026\n",
      "[10356]\teval-rmse:3.89498\ttrain-rmse:2.02025\n",
      "[10357]\teval-rmse:3.89472\ttrain-rmse:2.02025\n",
      "[10358]\teval-rmse:3.89614\ttrain-rmse:2.02024\n",
      "[10359]\teval-rmse:3.89818\ttrain-rmse:2.02024\n",
      "[10360]\teval-rmse:3.89909\ttrain-rmse:2.02024\n",
      "[10361]\teval-rmse:3.9004\ttrain-rmse:2.02025\n",
      "[10362]\teval-rmse:3.90022\ttrain-rmse:2.02024\n",
      "[10363]\teval-rmse:3.90094\ttrain-rmse:2.02025\n",
      "[10364]\teval-rmse:3.90116\ttrain-rmse:2.02025\n",
      "[10365]\teval-rmse:3.90048\ttrain-rmse:2.02\n",
      "[10366]\teval-rmse:3.90018\ttrain-rmse:2.01999\n",
      "[10367]\teval-rmse:3.90156\ttrain-rmse:2.02001\n",
      "[10368]\teval-rmse:3.90006\ttrain-rmse:2.01999\n",
      "[10369]\teval-rmse:3.89857\ttrain-rmse:2.02\n",
      "[10370]\teval-rmse:3.89891\ttrain-rmse:2.02001\n",
      "[10371]\teval-rmse:3.89801\ttrain-rmse:2.02001\n",
      "[10372]\teval-rmse:3.89729\ttrain-rmse:2.02002\n",
      "[10373]\teval-rmse:3.89631\ttrain-rmse:2.02003\n",
      "[10374]\teval-rmse:3.89519\ttrain-rmse:2.02003\n",
      "[10375]\teval-rmse:3.8964\ttrain-rmse:2.02003\n",
      "[10376]\teval-rmse:3.89556\ttrain-rmse:2.02003\n",
      "[10377]\teval-rmse:3.89444\ttrain-rmse:2.02002\n",
      "[10378]\teval-rmse:3.89381\ttrain-rmse:2.01978\n",
      "[10379]\teval-rmse:3.89489\ttrain-rmse:2.01978\n",
      "[10380]\teval-rmse:3.89674\ttrain-rmse:2.01979\n",
      "[10381]\teval-rmse:3.89792\ttrain-rmse:2.0198\n",
      "[10382]\teval-rmse:3.90006\ttrain-rmse:2.01983\n",
      "[10383]\teval-rmse:3.90199\ttrain-rmse:2.01985\n",
      "[10384]\teval-rmse:3.90132\ttrain-rmse:2.01958\n",
      "[10385]\teval-rmse:3.90066\ttrain-rmse:2.01957\n",
      "[10386]\teval-rmse:3.90162\ttrain-rmse:2.01959\n",
      "[10387]\teval-rmse:3.90158\ttrain-rmse:2.01959\n",
      "[10388]\teval-rmse:3.90268\ttrain-rmse:2.0196\n",
      "[10389]\teval-rmse:3.902\ttrain-rmse:2.01935\n",
      "[10390]\teval-rmse:3.90135\ttrain-rmse:2.01934\n",
      "[10391]\teval-rmse:3.90068\ttrain-rmse:2.01934\n",
      "[10392]\teval-rmse:3.90178\ttrain-rmse:2.01936\n",
      "[10393]\teval-rmse:3.90206\ttrain-rmse:2.01937\n",
      "[10394]\teval-rmse:3.90139\ttrain-rmse:2.01936\n",
      "[10395]\teval-rmse:3.9034\ttrain-rmse:2.01936\n",
      "[10396]\teval-rmse:3.90402\ttrain-rmse:2.01938\n",
      "[10397]\teval-rmse:3.90479\ttrain-rmse:2.01941\n",
      "[10398]\teval-rmse:3.90588\ttrain-rmse:2.01945\n",
      "[10399]\teval-rmse:3.90561\ttrain-rmse:2.01944\n",
      "[10400]\teval-rmse:3.90492\ttrain-rmse:2.0192\n",
      "[10401]\teval-rmse:3.90606\ttrain-rmse:2.01917\n",
      "[10402]\teval-rmse:3.90538\ttrain-rmse:2.01916\n",
      "[10403]\teval-rmse:3.90396\ttrain-rmse:2.01912\n",
      "[10404]\teval-rmse:3.90422\ttrain-rmse:2.01913\n",
      "[10405]\teval-rmse:3.90562\ttrain-rmse:2.01918\n",
      "[10406]\teval-rmse:3.90446\ttrain-rmse:2.01916\n",
      "[10407]\teval-rmse:3.90536\ttrain-rmse:2.01916\n",
      "[10408]\teval-rmse:3.90657\ttrain-rmse:2.01923\n",
      "[10409]\teval-rmse:3.90727\ttrain-rmse:2.01925\n",
      "[10410]\teval-rmse:3.90609\ttrain-rmse:2.01922\n",
      "[10411]\teval-rmse:3.90617\ttrain-rmse:2.01922\n",
      "[10412]\teval-rmse:3.90426\ttrain-rmse:2.01916\n",
      "[10413]\teval-rmse:3.90492\ttrain-rmse:2.0192\n",
      "[10414]\teval-rmse:3.90614\ttrain-rmse:2.01926\n",
      "[10415]\teval-rmse:3.90703\ttrain-rmse:2.01931\n",
      "[10416]\teval-rmse:3.9075\ttrain-rmse:2.01933\n",
      "[10417]\teval-rmse:3.90621\ttrain-rmse:2.01928\n",
      "[10418]\teval-rmse:3.9073\ttrain-rmse:2.01932\n",
      "[10419]\teval-rmse:3.90611\ttrain-rmse:2.0193\n",
      "[10420]\teval-rmse:3.90787\ttrain-rmse:2.01936\n",
      "[10421]\teval-rmse:3.90714\ttrain-rmse:2.01934\n",
      "[10422]\teval-rmse:3.90517\ttrain-rmse:2.01923\n",
      "[10423]\teval-rmse:3.90423\ttrain-rmse:2.01922\n",
      "[10424]\teval-rmse:3.90471\ttrain-rmse:2.01923\n",
      "[10425]\teval-rmse:3.90306\ttrain-rmse:2.01926\n",
      "[10426]\teval-rmse:3.90336\ttrain-rmse:2.01928\n",
      "[10427]\teval-rmse:3.90268\ttrain-rmse:2.01926\n",
      "[10428]\teval-rmse:3.90152\ttrain-rmse:2.01921\n",
      "[10429]\teval-rmse:3.90024\ttrain-rmse:2.01924\n",
      "[10430]\teval-rmse:3.90106\ttrain-rmse:2.01926\n",
      "[10431]\teval-rmse:3.90015\ttrain-rmse:2.01925\n",
      "[10432]\teval-rmse:3.89869\ttrain-rmse:2.01922\n",
      "[10433]\teval-rmse:3.90053\ttrain-rmse:2.01928\n",
      "[10434]\teval-rmse:3.90077\ttrain-rmse:2.01928\n",
      "[10435]\teval-rmse:3.90089\ttrain-rmse:2.01929\n",
      "[10436]\teval-rmse:3.89891\ttrain-rmse:2.01925\n",
      "[10437]\teval-rmse:3.9003\ttrain-rmse:2.01927\n",
      "[10438]\teval-rmse:3.90067\ttrain-rmse:2.01928\n",
      "[10439]\teval-rmse:3.90042\ttrain-rmse:2.01927\n",
      "[10440]\teval-rmse:3.90158\ttrain-rmse:2.01932\n",
      "[10441]\teval-rmse:3.9017\ttrain-rmse:2.01932\n",
      "[10442]\teval-rmse:3.90101\ttrain-rmse:2.01931\n",
      "[10443]\teval-rmse:3.89948\ttrain-rmse:2.0193\n",
      "[10444]\teval-rmse:3.9016\ttrain-rmse:2.01934\n",
      "[10445]\teval-rmse:3.9004\ttrain-rmse:2.0193\n",
      "[10446]\teval-rmse:3.89914\ttrain-rmse:2.01927\n",
      "[10447]\teval-rmse:3.90092\ttrain-rmse:2.01931\n",
      "[10448]\teval-rmse:3.90072\ttrain-rmse:2.0193\n",
      "[10449]\teval-rmse:3.90251\ttrain-rmse:2.01935\n",
      "[10450]\teval-rmse:3.90243\ttrain-rmse:2.01934\n",
      "[10451]\teval-rmse:3.90142\ttrain-rmse:2.01931\n",
      "[10452]\teval-rmse:3.90075\ttrain-rmse:2.01906\n",
      "[10453]\teval-rmse:3.90009\ttrain-rmse:2.01881\n",
      "[10454]\teval-rmse:3.89988\ttrain-rmse:2.01881\n",
      "[10455]\teval-rmse:3.89872\ttrain-rmse:2.01883\n",
      "[10456]\teval-rmse:3.89987\ttrain-rmse:2.01883\n",
      "[10457]\teval-rmse:3.89965\ttrain-rmse:2.01882\n",
      "[10458]\teval-rmse:3.90178\ttrain-rmse:2.01885\n",
      "[10459]\teval-rmse:3.90287\ttrain-rmse:2.0189\n",
      "[10460]\teval-rmse:3.90499\ttrain-rmse:2.01894\n",
      "[10461]\teval-rmse:3.90286\ttrain-rmse:2.01885\n",
      "[10462]\teval-rmse:3.90194\ttrain-rmse:2.01881\n",
      "[10463]\teval-rmse:3.90322\ttrain-rmse:2.01885\n",
      "[10464]\teval-rmse:3.90173\ttrain-rmse:2.01881\n",
      "[10465]\teval-rmse:3.89991\ttrain-rmse:2.01873\n",
      "[10466]\teval-rmse:3.90106\ttrain-rmse:2.01868\n",
      "[10467]\teval-rmse:3.89913\ttrain-rmse:2.01862\n",
      "[10468]\teval-rmse:3.89683\ttrain-rmse:2.01856\n",
      "[10469]\teval-rmse:3.8957\ttrain-rmse:2.01856\n",
      "[10470]\teval-rmse:3.8969\ttrain-rmse:2.01858\n",
      "[10471]\teval-rmse:3.89831\ttrain-rmse:2.01861\n",
      "[10472]\teval-rmse:3.90043\ttrain-rmse:2.01864\n",
      "[10473]\teval-rmse:3.8994\ttrain-rmse:2.01864\n",
      "[10474]\teval-rmse:3.89958\ttrain-rmse:2.01864\n",
      "[10475]\teval-rmse:3.89893\ttrain-rmse:2.01863\n",
      "[10476]\teval-rmse:3.89779\ttrain-rmse:2.01862\n",
      "[10477]\teval-rmse:3.89981\ttrain-rmse:2.01865\n",
      "[10478]\teval-rmse:3.89987\ttrain-rmse:2.01865\n",
      "[10479]\teval-rmse:3.89953\ttrain-rmse:2.01864\n",
      "[10480]\teval-rmse:3.89855\ttrain-rmse:2.01862\n",
      "[10481]\teval-rmse:3.89764\ttrain-rmse:2.01861\n",
      "[10482]\teval-rmse:3.89614\ttrain-rmse:2.01859\n",
      "[10483]\teval-rmse:3.89643\ttrain-rmse:2.0186\n",
      "[10484]\teval-rmse:3.89689\ttrain-rmse:2.01859\n",
      "[10485]\teval-rmse:3.89625\ttrain-rmse:2.01832\n",
      "[10486]\teval-rmse:3.89481\ttrain-rmse:2.0183\n",
      "[10487]\teval-rmse:3.89279\ttrain-rmse:2.01827\n",
      "[10488]\teval-rmse:3.89131\ttrain-rmse:2.01827\n",
      "[10489]\teval-rmse:3.89014\ttrain-rmse:2.01827\n",
      "[10490]\teval-rmse:3.88916\ttrain-rmse:2.01827\n",
      "[10491]\teval-rmse:3.88822\ttrain-rmse:2.01828\n",
      "[10492]\teval-rmse:3.88742\ttrain-rmse:2.01828\n",
      "[10493]\teval-rmse:3.88528\ttrain-rmse:2.0183\n",
      "[10494]\teval-rmse:3.88537\ttrain-rmse:2.0183\n",
      "[10495]\teval-rmse:3.88511\ttrain-rmse:2.0183\n",
      "[10496]\teval-rmse:3.88538\ttrain-rmse:2.0183\n",
      "[10497]\teval-rmse:3.88555\ttrain-rmse:2.0183\n",
      "[10498]\teval-rmse:3.88535\ttrain-rmse:2.0183\n",
      "[10499]\teval-rmse:3.8834\ttrain-rmse:2.01832\n",
      "[10500]\teval-rmse:3.88314\ttrain-rmse:2.01833\n",
      "[10501]\teval-rmse:3.88319\ttrain-rmse:2.01833\n",
      "[10502]\teval-rmse:3.88295\ttrain-rmse:2.01833\n",
      "[10503]\teval-rmse:3.88474\ttrain-rmse:2.01827\n",
      "[10504]\teval-rmse:3.88549\ttrain-rmse:2.01826\n",
      "[10505]\teval-rmse:3.88503\ttrain-rmse:2.01826\n",
      "[10506]\teval-rmse:3.88315\ttrain-rmse:2.0183\n",
      "[10507]\teval-rmse:3.88247\ttrain-rmse:2.01831\n",
      "[10508]\teval-rmse:3.88108\ttrain-rmse:2.01837\n",
      "[10509]\teval-rmse:3.88085\ttrain-rmse:2.01837\n",
      "[10510]\teval-rmse:3.88254\ttrain-rmse:2.01825\n",
      "[10511]\teval-rmse:3.8823\ttrain-rmse:2.01825\n",
      "[10512]\teval-rmse:3.88147\ttrain-rmse:2.01827\n",
      "[10513]\teval-rmse:3.88128\ttrain-rmse:2.01828\n",
      "[10514]\teval-rmse:3.87908\ttrain-rmse:2.01831\n",
      "[10515]\teval-rmse:3.88031\ttrain-rmse:2.01825\n",
      "[10516]\teval-rmse:3.87924\ttrain-rmse:2.0183\n",
      "[10517]\teval-rmse:3.88026\ttrain-rmse:2.01826\n",
      "[10518]\teval-rmse:3.88228\ttrain-rmse:2.01812\n",
      "[10519]\teval-rmse:3.88254\ttrain-rmse:2.01811\n",
      "[10520]\teval-rmse:3.88148\ttrain-rmse:2.01813\n",
      "[10521]\teval-rmse:3.88093\ttrain-rmse:2.01814\n",
      "[10522]\teval-rmse:3.87958\ttrain-rmse:2.01818\n",
      "[10523]\teval-rmse:3.87933\ttrain-rmse:2.01819\n",
      "[10524]\teval-rmse:3.87946\ttrain-rmse:2.01819\n",
      "[10525]\teval-rmse:3.88066\ttrain-rmse:2.01817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10526]\teval-rmse:3.88055\ttrain-rmse:2.01817\n",
      "[10527]\teval-rmse:3.87904\ttrain-rmse:2.01822\n",
      "[10528]\teval-rmse:3.8802\ttrain-rmse:2.01818\n",
      "[10529]\teval-rmse:3.882\ttrain-rmse:2.01813\n",
      "[10530]\teval-rmse:3.88082\ttrain-rmse:2.01817\n",
      "[10531]\teval-rmse:3.88249\ttrain-rmse:2.0181\n",
      "[10532]\teval-rmse:3.8826\ttrain-rmse:2.0181\n",
      "[10533]\teval-rmse:3.88119\ttrain-rmse:2.01814\n",
      "[10534]\teval-rmse:3.88286\ttrain-rmse:2.01802\n",
      "[10535]\teval-rmse:3.88132\ttrain-rmse:2.01811\n",
      "[10536]\teval-rmse:3.88109\ttrain-rmse:2.01812\n",
      "[10537]\teval-rmse:3.88139\ttrain-rmse:2.01811\n",
      "[10538]\teval-rmse:3.882\ttrain-rmse:2.0181\n",
      "[10539]\teval-rmse:3.88132\ttrain-rmse:2.01812\n",
      "[10540]\teval-rmse:3.88164\ttrain-rmse:2.01811\n",
      "[10541]\teval-rmse:3.88266\ttrain-rmse:2.01809\n",
      "[10542]\teval-rmse:3.88149\ttrain-rmse:2.01815\n",
      "[10543]\teval-rmse:3.88043\ttrain-rmse:2.01817\n",
      "[10544]\teval-rmse:3.88211\ttrain-rmse:2.01813\n",
      "[10545]\teval-rmse:3.87986\ttrain-rmse:2.01818\n",
      "[10546]\teval-rmse:3.88055\ttrain-rmse:2.01817\n",
      "[10547]\teval-rmse:3.87985\ttrain-rmse:2.01818\n",
      "[10548]\teval-rmse:3.87836\ttrain-rmse:2.01829\n",
      "[10549]\teval-rmse:3.87697\ttrain-rmse:2.01834\n",
      "[10550]\teval-rmse:3.87648\ttrain-rmse:2.01808\n",
      "[10551]\teval-rmse:3.87639\ttrain-rmse:2.01808\n",
      "[10552]\teval-rmse:3.87435\ttrain-rmse:2.01816\n",
      "[10553]\teval-rmse:3.87422\ttrain-rmse:2.01817\n",
      "[10554]\teval-rmse:3.87272\ttrain-rmse:2.01821\n",
      "[10555]\teval-rmse:3.87125\ttrain-rmse:2.0183\n",
      "[10556]\teval-rmse:3.86941\ttrain-rmse:2.01837\n",
      "[10557]\teval-rmse:3.86748\ttrain-rmse:2.01848\n",
      "[10558]\teval-rmse:3.86755\ttrain-rmse:2.01847\n",
      "[10559]\teval-rmse:3.86855\ttrain-rmse:2.01841\n",
      "[10560]\teval-rmse:3.86959\ttrain-rmse:2.01835\n",
      "[10561]\teval-rmse:3.8714\ttrain-rmse:2.01824\n",
      "[10562]\teval-rmse:3.87209\ttrain-rmse:2.01821\n",
      "[10563]\teval-rmse:3.87099\ttrain-rmse:2.01826\n",
      "[10564]\teval-rmse:3.8724\ttrain-rmse:2.01819\n",
      "[10565]\teval-rmse:3.87033\ttrain-rmse:2.01827\n",
      "[10566]\teval-rmse:3.87155\ttrain-rmse:2.01821\n",
      "[10567]\teval-rmse:3.87164\ttrain-rmse:2.0182\n",
      "[10568]\teval-rmse:3.87378\ttrain-rmse:2.01815\n",
      "[10569]\teval-rmse:3.87247\ttrain-rmse:2.01819\n",
      "[10570]\teval-rmse:3.87089\ttrain-rmse:2.01828\n",
      "[10571]\teval-rmse:3.87191\ttrain-rmse:2.01822\n",
      "[10572]\teval-rmse:3.87089\ttrain-rmse:2.01828\n",
      "[10573]\teval-rmse:3.87002\ttrain-rmse:2.01834\n",
      "[10574]\teval-rmse:3.87217\ttrain-rmse:2.0182\n",
      "[10575]\teval-rmse:3.87208\ttrain-rmse:2.0182\n",
      "[10576]\teval-rmse:3.87301\ttrain-rmse:2.01815\n",
      "[10577]\teval-rmse:3.87398\ttrain-rmse:2.0181\n",
      "[10578]\teval-rmse:3.87355\ttrain-rmse:2.01812\n",
      "[10579]\teval-rmse:3.87209\ttrain-rmse:2.01819\n",
      "[10580]\teval-rmse:3.87008\ttrain-rmse:2.0183\n",
      "[10581]\teval-rmse:3.87169\ttrain-rmse:2.01821\n",
      "[10582]\teval-rmse:3.87068\ttrain-rmse:2.01829\n",
      "[10583]\teval-rmse:3.86877\ttrain-rmse:2.01838\n",
      "[10584]\teval-rmse:3.87023\ttrain-rmse:2.01829\n",
      "[10585]\teval-rmse:3.86947\ttrain-rmse:2.01833\n",
      "[10586]\teval-rmse:3.87163\ttrain-rmse:2.01826\n",
      "[10587]\teval-rmse:3.8724\ttrain-rmse:2.01822\n",
      "[10588]\teval-rmse:3.87336\ttrain-rmse:2.01818\n",
      "[10589]\teval-rmse:3.8744\ttrain-rmse:2.01813\n",
      "[10590]\teval-rmse:3.87374\ttrain-rmse:2.01816\n",
      "[10591]\teval-rmse:3.8727\ttrain-rmse:2.01824\n",
      "[10592]\teval-rmse:3.87217\ttrain-rmse:2.01825\n",
      "[10593]\teval-rmse:3.87135\ttrain-rmse:2.0183\n",
      "[10594]\teval-rmse:3.87062\ttrain-rmse:2.01834\n",
      "[10595]\teval-rmse:3.87187\ttrain-rmse:2.01823\n",
      "[10596]\teval-rmse:3.87103\ttrain-rmse:2.01827\n",
      "[10597]\teval-rmse:3.86933\ttrain-rmse:2.01838\n",
      "[10598]\teval-rmse:3.86987\ttrain-rmse:2.01835\n",
      "[10599]\teval-rmse:3.87138\ttrain-rmse:2.01826\n",
      "[10600]\teval-rmse:3.87163\ttrain-rmse:2.01825\n",
      "[10601]\teval-rmse:3.87085\ttrain-rmse:2.01829\n",
      "[10602]\teval-rmse:3.87182\ttrain-rmse:2.01823\n",
      "[10603]\teval-rmse:3.87017\ttrain-rmse:2.01832\n",
      "[10604]\teval-rmse:3.87162\ttrain-rmse:2.01824\n",
      "[10605]\teval-rmse:3.87144\ttrain-rmse:2.01824\n",
      "[10606]\teval-rmse:3.87242\ttrain-rmse:2.01818\n",
      "[10607]\teval-rmse:3.87356\ttrain-rmse:2.01813\n",
      "[10608]\teval-rmse:3.87278\ttrain-rmse:2.01817\n",
      "[10609]\teval-rmse:3.87337\ttrain-rmse:2.01815\n",
      "[10610]\teval-rmse:3.87171\ttrain-rmse:2.01823\n",
      "[10611]\teval-rmse:3.87118\ttrain-rmse:2.01824\n",
      "[10612]\teval-rmse:3.87308\ttrain-rmse:2.01813\n",
      "[10613]\teval-rmse:3.87295\ttrain-rmse:2.01814\n",
      "[10614]\teval-rmse:3.87244\ttrain-rmse:2.01816\n",
      "[10615]\teval-rmse:3.87302\ttrain-rmse:2.01813\n",
      "[10616]\teval-rmse:3.87379\ttrain-rmse:2.01809\n",
      "[10617]\teval-rmse:3.87459\ttrain-rmse:2.01805\n",
      "[10618]\teval-rmse:3.87582\ttrain-rmse:2.018\n",
      "[10619]\teval-rmse:3.87655\ttrain-rmse:2.01796\n",
      "[10620]\teval-rmse:3.8751\ttrain-rmse:2.01803\n",
      "[10621]\teval-rmse:3.8736\ttrain-rmse:2.01811\n",
      "[10622]\teval-rmse:3.87506\ttrain-rmse:2.01803\n",
      "[10623]\teval-rmse:3.87604\ttrain-rmse:2.01798\n",
      "[10624]\teval-rmse:3.87503\ttrain-rmse:2.01803\n",
      "[10625]\teval-rmse:3.87683\ttrain-rmse:2.01796\n",
      "[10626]\teval-rmse:3.8783\ttrain-rmse:2.0179\n",
      "[10627]\teval-rmse:3.87999\ttrain-rmse:2.01785\n",
      "[10628]\teval-rmse:3.88195\ttrain-rmse:2.0178\n",
      "[10629]\teval-rmse:3.8817\ttrain-rmse:2.0178\n",
      "[10630]\teval-rmse:3.88249\ttrain-rmse:2.01778\n",
      "[10631]\teval-rmse:3.88323\ttrain-rmse:2.01776\n",
      "[10632]\teval-rmse:3.88503\ttrain-rmse:2.0177\n",
      "[10633]\teval-rmse:3.88414\ttrain-rmse:2.01772\n",
      "[10634]\teval-rmse:3.88627\ttrain-rmse:2.01768\n",
      "[10635]\teval-rmse:3.88579\ttrain-rmse:2.01769\n",
      "[10636]\teval-rmse:3.88452\ttrain-rmse:2.01771\n",
      "[10637]\teval-rmse:3.88586\ttrain-rmse:2.01768\n",
      "[10638]\teval-rmse:3.88709\ttrain-rmse:2.01766\n",
      "[10639]\teval-rmse:3.88602\ttrain-rmse:2.01766\n",
      "[10640]\teval-rmse:3.88448\ttrain-rmse:2.01774\n",
      "[10641]\teval-rmse:3.88364\ttrain-rmse:2.01776\n",
      "[10642]\teval-rmse:3.88299\ttrain-rmse:2.01778\n",
      "[10643]\teval-rmse:3.88358\ttrain-rmse:2.01776\n",
      "[10644]\teval-rmse:3.88284\ttrain-rmse:2.01777\n",
      "[10645]\teval-rmse:3.88178\ttrain-rmse:2.01778\n",
      "[10646]\teval-rmse:3.88119\ttrain-rmse:2.01755\n",
      "[10647]\teval-rmse:3.88032\ttrain-rmse:2.01757\n",
      "[10648]\teval-rmse:3.88136\ttrain-rmse:2.01754\n",
      "[10649]\teval-rmse:3.88093\ttrain-rmse:2.01755\n",
      "[10650]\teval-rmse:3.88232\ttrain-rmse:2.01752\n",
      "[10651]\teval-rmse:3.88158\ttrain-rmse:2.01753\n",
      "[10652]\teval-rmse:3.87927\ttrain-rmse:2.01758\n",
      "[10653]\teval-rmse:3.87916\ttrain-rmse:2.01758\n",
      "[10654]\teval-rmse:3.88131\ttrain-rmse:2.01755\n",
      "[10655]\teval-rmse:3.88233\ttrain-rmse:2.01752\n",
      "[10656]\teval-rmse:3.88326\ttrain-rmse:2.01751\n",
      "[10657]\teval-rmse:3.88155\ttrain-rmse:2.01753\n",
      "[10658]\teval-rmse:3.88268\ttrain-rmse:2.0175\n",
      "[10659]\teval-rmse:3.8808\ttrain-rmse:2.01756\n",
      "[10660]\teval-rmse:3.8814\ttrain-rmse:2.01755\n",
      "[10661]\teval-rmse:3.88196\ttrain-rmse:2.01753\n",
      "[10662]\teval-rmse:3.88298\ttrain-rmse:2.01751\n",
      "[10663]\teval-rmse:3.88083\ttrain-rmse:2.01757\n",
      "[10664]\teval-rmse:3.88069\ttrain-rmse:2.01757\n",
      "[10665]\teval-rmse:3.87938\ttrain-rmse:2.01762\n",
      "[10666]\teval-rmse:3.87949\ttrain-rmse:2.01761\n",
      "[10667]\teval-rmse:3.87843\ttrain-rmse:2.01764\n",
      "[10668]\teval-rmse:3.87861\ttrain-rmse:2.01763\n",
      "[10669]\teval-rmse:3.87957\ttrain-rmse:2.01759\n",
      "[10670]\teval-rmse:3.879\ttrain-rmse:2.01734\n",
      "[10671]\teval-rmse:3.87806\ttrain-rmse:2.01737\n",
      "[10672]\teval-rmse:3.87946\ttrain-rmse:2.01733\n",
      "[10673]\teval-rmse:3.87804\ttrain-rmse:2.01738\n",
      "[10674]\teval-rmse:3.87822\ttrain-rmse:2.01737\n",
      "[10675]\teval-rmse:3.87845\ttrain-rmse:2.01736\n",
      "[10676]\teval-rmse:3.88057\ttrain-rmse:2.01734\n",
      "[10677]\teval-rmse:3.88041\ttrain-rmse:2.01734\n",
      "[10678]\teval-rmse:3.88219\ttrain-rmse:2.01728\n",
      "[10679]\teval-rmse:3.8825\ttrain-rmse:2.01727\n",
      "[10680]\teval-rmse:3.88131\ttrain-rmse:2.01731\n",
      "[10681]\teval-rmse:3.88037\ttrain-rmse:2.01734\n",
      "[10682]\teval-rmse:3.88159\ttrain-rmse:2.0173\n",
      "[10683]\teval-rmse:3.88147\ttrain-rmse:2.0173\n",
      "[10684]\teval-rmse:3.87947\ttrain-rmse:2.01737\n",
      "[10685]\teval-rmse:3.8815\ttrain-rmse:2.01723\n",
      "[10686]\teval-rmse:3.88293\ttrain-rmse:2.0172\n",
      "[10687]\teval-rmse:3.88234\ttrain-rmse:2.01699\n",
      "[10688]\teval-rmse:3.88329\ttrain-rmse:2.01696\n",
      "[10689]\teval-rmse:3.88343\ttrain-rmse:2.01695\n",
      "[10690]\teval-rmse:3.88526\ttrain-rmse:2.01692\n",
      "[10691]\teval-rmse:3.8846\ttrain-rmse:2.01693\n",
      "[10692]\teval-rmse:3.88261\ttrain-rmse:2.01696\n",
      "[10693]\teval-rmse:3.88204\ttrain-rmse:2.01697\n",
      "[10694]\teval-rmse:3.88146\ttrain-rmse:2.01698\n",
      "[10695]\teval-rmse:3.88087\ttrain-rmse:2.017\n",
      "[10696]\teval-rmse:3.88214\ttrain-rmse:2.01698\n",
      "[10697]\teval-rmse:3.8843\ttrain-rmse:2.01696\n",
      "[10698]\teval-rmse:3.88289\ttrain-rmse:2.017\n",
      "[10699]\teval-rmse:3.88266\ttrain-rmse:2.017\n",
      "[10700]\teval-rmse:3.88322\ttrain-rmse:2.01698\n",
      "[10701]\teval-rmse:3.88448\ttrain-rmse:2.01696\n",
      "[10702]\teval-rmse:3.88223\ttrain-rmse:2.01701\n",
      "[10703]\teval-rmse:3.88165\ttrain-rmse:2.01701\n",
      "[10704]\teval-rmse:3.88226\ttrain-rmse:2.01699\n",
      "[10705]\teval-rmse:3.8843\ttrain-rmse:2.01695\n",
      "[10706]\teval-rmse:3.88503\ttrain-rmse:2.01694\n",
      "[10707]\teval-rmse:3.88686\ttrain-rmse:2.01691\n",
      "[10708]\teval-rmse:3.88447\ttrain-rmse:2.01695\n",
      "[10709]\teval-rmse:3.88341\ttrain-rmse:2.01696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10710]\teval-rmse:3.88361\ttrain-rmse:2.01695\n",
      "[10711]\teval-rmse:3.88303\ttrain-rmse:2.01697\n",
      "[10712]\teval-rmse:3.88244\ttrain-rmse:2.01699\n",
      "[10713]\teval-rmse:3.88279\ttrain-rmse:2.01698\n",
      "[10714]\teval-rmse:3.88312\ttrain-rmse:2.01697\n",
      "[10715]\teval-rmse:3.8846\ttrain-rmse:2.01695\n",
      "[10716]\teval-rmse:3.8825\ttrain-rmse:2.017\n",
      "[10717]\teval-rmse:3.88227\ttrain-rmse:2.017\n",
      "[10718]\teval-rmse:3.88238\ttrain-rmse:2.01699\n",
      "[10719]\teval-rmse:3.8823\ttrain-rmse:2.017\n",
      "[10720]\teval-rmse:3.88135\ttrain-rmse:2.01702\n",
      "[10721]\teval-rmse:3.88286\ttrain-rmse:2.01697\n",
      "[10722]\teval-rmse:3.88113\ttrain-rmse:2.01701\n",
      "[10723]\teval-rmse:3.88232\ttrain-rmse:2.01694\n",
      "[10724]\teval-rmse:3.88417\ttrain-rmse:2.0169\n",
      "[10725]\teval-rmse:3.88398\ttrain-rmse:2.0169\n",
      "[10726]\teval-rmse:3.88611\ttrain-rmse:2.01689\n",
      "[10727]\teval-rmse:3.88812\ttrain-rmse:2.01678\n",
      "[10728]\teval-rmse:3.89002\ttrain-rmse:2.01675\n",
      "[10729]\teval-rmse:3.88781\ttrain-rmse:2.0168\n",
      "[10730]\teval-rmse:3.88766\ttrain-rmse:2.0168\n",
      "[10731]\teval-rmse:3.88944\ttrain-rmse:2.01678\n",
      "[10732]\teval-rmse:3.88852\ttrain-rmse:2.0168\n",
      "[10733]\teval-rmse:3.88802\ttrain-rmse:2.0168\n",
      "[10734]\teval-rmse:3.88721\ttrain-rmse:2.01681\n",
      "[10735]\teval-rmse:3.88794\ttrain-rmse:2.0168\n",
      "[10736]\teval-rmse:3.88654\ttrain-rmse:2.01681\n",
      "[10737]\teval-rmse:3.88461\ttrain-rmse:2.01686\n",
      "[10738]\teval-rmse:3.88322\ttrain-rmse:2.01689\n",
      "[10739]\teval-rmse:3.88525\ttrain-rmse:2.01685\n",
      "[10740]\teval-rmse:3.88509\ttrain-rmse:2.01685\n",
      "[10741]\teval-rmse:3.88484\ttrain-rmse:2.01685\n",
      "[10742]\teval-rmse:3.88366\ttrain-rmse:2.01687\n",
      "[10743]\teval-rmse:3.88535\ttrain-rmse:2.01684\n",
      "[10744]\teval-rmse:3.88474\ttrain-rmse:2.01658\n",
      "[10745]\teval-rmse:3.88415\ttrain-rmse:2.01658\n",
      "[10746]\teval-rmse:3.8839\ttrain-rmse:2.01658\n",
      "[10747]\teval-rmse:3.88333\ttrain-rmse:2.0166\n",
      "[10748]\teval-rmse:3.88192\ttrain-rmse:2.01665\n",
      "[10749]\teval-rmse:3.88133\ttrain-rmse:2.01665\n",
      "[10750]\teval-rmse:3.88111\ttrain-rmse:2.01666\n",
      "[10751]\teval-rmse:3.88244\ttrain-rmse:2.01663\n",
      "[10752]\teval-rmse:3.8822\ttrain-rmse:2.01663\n",
      "[10753]\teval-rmse:3.88141\ttrain-rmse:2.01664\n",
      "[10754]\teval-rmse:3.88054\ttrain-rmse:2.01666\n",
      "[10755]\teval-rmse:3.88028\ttrain-rmse:2.01667\n",
      "[10756]\teval-rmse:3.87916\ttrain-rmse:2.0167\n",
      "[10757]\teval-rmse:3.87889\ttrain-rmse:2.0167\n",
      "[10758]\teval-rmse:3.88058\ttrain-rmse:2.01659\n",
      "[10759]\teval-rmse:3.88016\ttrain-rmse:2.01661\n",
      "[10760]\teval-rmse:3.87802\ttrain-rmse:2.01671\n",
      "[10761]\teval-rmse:3.87946\ttrain-rmse:2.01665\n",
      "[10762]\teval-rmse:3.87948\ttrain-rmse:2.01665\n",
      "[10763]\teval-rmse:3.88091\ttrain-rmse:2.0166\n",
      "[10764]\teval-rmse:3.87985\ttrain-rmse:2.01661\n",
      "[10765]\teval-rmse:3.88069\ttrain-rmse:2.01657\n",
      "[10766]\teval-rmse:3.88204\ttrain-rmse:2.01653\n",
      "[10767]\teval-rmse:3.88346\ttrain-rmse:2.01647\n",
      "[10768]\teval-rmse:3.8853\ttrain-rmse:2.01643\n",
      "[10769]\teval-rmse:3.88697\ttrain-rmse:2.01634\n",
      "[10770]\teval-rmse:3.88626\ttrain-rmse:2.01636\n",
      "[10771]\teval-rmse:3.88709\ttrain-rmse:2.01635\n",
      "[10772]\teval-rmse:3.88601\ttrain-rmse:2.01635\n",
      "[10773]\teval-rmse:3.88667\ttrain-rmse:2.01634\n",
      "[10774]\teval-rmse:3.88652\ttrain-rmse:2.01634\n",
      "[10775]\teval-rmse:3.88718\ttrain-rmse:2.01633\n",
      "[10776]\teval-rmse:3.88561\ttrain-rmse:2.01635\n",
      "[10777]\teval-rmse:3.88655\ttrain-rmse:2.01634\n",
      "[10778]\teval-rmse:3.88583\ttrain-rmse:2.01635\n",
      "[10779]\teval-rmse:3.88769\ttrain-rmse:2.01631\n",
      "[10780]\teval-rmse:3.88723\ttrain-rmse:2.01631\n",
      "[10781]\teval-rmse:3.88808\ttrain-rmse:2.01631\n",
      "[10782]\teval-rmse:3.88693\ttrain-rmse:2.01632\n",
      "[10783]\teval-rmse:3.8889\ttrain-rmse:2.01629\n",
      "[10784]\teval-rmse:3.888\ttrain-rmse:2.0163\n",
      "[10785]\teval-rmse:3.88829\ttrain-rmse:2.01629\n",
      "[10786]\teval-rmse:3.88735\ttrain-rmse:2.0163\n",
      "[10787]\teval-rmse:3.88677\ttrain-rmse:2.01631\n",
      "[10788]\teval-rmse:3.88878\ttrain-rmse:2.01621\n",
      "[10789]\teval-rmse:3.89021\ttrain-rmse:2.01619\n",
      "[10790]\teval-rmse:3.8891\ttrain-rmse:2.01619\n",
      "[10791]\teval-rmse:3.88987\ttrain-rmse:2.01618\n",
      "[10792]\teval-rmse:3.89004\ttrain-rmse:2.01618\n",
      "[10793]\teval-rmse:3.89102\ttrain-rmse:2.01618\n",
      "[10794]\teval-rmse:3.89106\ttrain-rmse:2.01618\n",
      "[10795]\teval-rmse:3.88897\ttrain-rmse:2.0162\n",
      "[10796]\teval-rmse:3.89028\ttrain-rmse:2.01618\n",
      "[10797]\teval-rmse:3.88916\ttrain-rmse:2.01618\n",
      "[10798]\teval-rmse:3.88804\ttrain-rmse:2.0162\n",
      "[10799]\teval-rmse:3.88694\ttrain-rmse:2.01622\n",
      "[10800]\teval-rmse:3.88786\ttrain-rmse:2.0162\n",
      "[10801]\teval-rmse:3.88668\ttrain-rmse:2.01622\n",
      "[10802]\teval-rmse:3.88791\ttrain-rmse:2.0162\n",
      "[10803]\teval-rmse:3.88982\ttrain-rmse:2.01618\n",
      "[10804]\teval-rmse:3.89183\ttrain-rmse:2.01616\n",
      "[10805]\teval-rmse:3.89025\ttrain-rmse:2.01616\n",
      "[10806]\teval-rmse:3.89186\ttrain-rmse:2.01615\n",
      "[10807]\teval-rmse:3.89326\ttrain-rmse:2.01614\n",
      "[10808]\teval-rmse:3.89264\ttrain-rmse:2.01614\n",
      "[10809]\teval-rmse:3.89068\ttrain-rmse:2.01615\n",
      "[10810]\teval-rmse:3.89231\ttrain-rmse:2.01616\n",
      "[10811]\teval-rmse:3.89304\ttrain-rmse:2.01616\n",
      "[10812]\teval-rmse:3.8948\ttrain-rmse:2.01616\n",
      "[10813]\teval-rmse:3.89369\ttrain-rmse:2.01614\n",
      "[10814]\teval-rmse:3.89397\ttrain-rmse:2.01615\n",
      "[10815]\teval-rmse:3.89374\ttrain-rmse:2.01614\n",
      "[10816]\teval-rmse:3.89531\ttrain-rmse:2.01615\n",
      "[10817]\teval-rmse:3.89582\ttrain-rmse:2.01616\n",
      "[10818]\teval-rmse:3.89458\ttrain-rmse:2.01616\n",
      "[10819]\teval-rmse:3.89473\ttrain-rmse:2.01616\n",
      "[10820]\teval-rmse:3.89565\ttrain-rmse:2.01617\n",
      "[10821]\teval-rmse:3.89643\ttrain-rmse:2.01617\n",
      "[10822]\teval-rmse:3.8981\ttrain-rmse:2.0162\n",
      "[10823]\teval-rmse:3.89696\ttrain-rmse:2.01618\n",
      "[10824]\teval-rmse:3.89581\ttrain-rmse:2.01616\n",
      "[10825]\teval-rmse:3.89394\ttrain-rmse:2.01614\n",
      "[10826]\teval-rmse:3.89534\ttrain-rmse:2.01614\n",
      "[10827]\teval-rmse:3.89349\ttrain-rmse:2.01613\n",
      "[10828]\teval-rmse:3.89379\ttrain-rmse:2.01613\n",
      "[10829]\teval-rmse:3.89195\ttrain-rmse:2.01611\n",
      "[10830]\teval-rmse:3.89081\ttrain-rmse:2.01616\n",
      "[10831]\teval-rmse:3.8929\ttrain-rmse:2.01607\n",
      "[10832]\teval-rmse:3.89382\ttrain-rmse:2.01608\n",
      "[10833]\teval-rmse:3.89304\ttrain-rmse:2.01607\n",
      "[10834]\teval-rmse:3.89331\ttrain-rmse:2.01607\n",
      "[10835]\teval-rmse:3.89193\ttrain-rmse:2.01608\n",
      "[10836]\teval-rmse:3.89284\ttrain-rmse:2.01608\n",
      "[10837]\teval-rmse:3.8917\ttrain-rmse:2.01607\n",
      "[10838]\teval-rmse:3.89336\ttrain-rmse:2.01608\n",
      "[10839]\teval-rmse:3.89236\ttrain-rmse:2.01608\n",
      "[10840]\teval-rmse:3.894\ttrain-rmse:2.01601\n",
      "[10841]\teval-rmse:3.89371\ttrain-rmse:2.01601\n",
      "[10842]\teval-rmse:3.89397\ttrain-rmse:2.01601\n",
      "[10843]\teval-rmse:3.8943\ttrain-rmse:2.01601\n",
      "[10844]\teval-rmse:3.89366\ttrain-rmse:2.01601\n",
      "[10845]\teval-rmse:3.89209\ttrain-rmse:2.01599\n",
      "[10846]\teval-rmse:3.89326\ttrain-rmse:2.01598\n",
      "[10847]\teval-rmse:3.8925\ttrain-rmse:2.01597\n",
      "[10848]\teval-rmse:3.89315\ttrain-rmse:2.01597\n",
      "[10849]\teval-rmse:3.89196\ttrain-rmse:2.01595\n",
      "[10850]\teval-rmse:3.89318\ttrain-rmse:2.01596\n",
      "[10851]\teval-rmse:3.89268\ttrain-rmse:2.01596\n",
      "[10852]\teval-rmse:3.89266\ttrain-rmse:2.01596\n",
      "[10853]\teval-rmse:3.89465\ttrain-rmse:2.01598\n",
      "[10854]\teval-rmse:3.89652\ttrain-rmse:2.016\n",
      "[10855]\teval-rmse:3.89834\ttrain-rmse:2.01603\n",
      "[10856]\teval-rmse:3.89844\ttrain-rmse:2.01603\n",
      "[10857]\teval-rmse:3.89865\ttrain-rmse:2.01603\n",
      "[10858]\teval-rmse:3.90076\ttrain-rmse:2.01607\n",
      "[10859]\teval-rmse:3.89982\ttrain-rmse:2.01604\n",
      "[10860]\teval-rmse:3.89866\ttrain-rmse:2.01602\n",
      "[10861]\teval-rmse:3.89848\ttrain-rmse:2.01601\n",
      "[10862]\teval-rmse:3.8961\ttrain-rmse:2.01599\n",
      "[10863]\teval-rmse:3.89625\ttrain-rmse:2.01599\n",
      "[10864]\teval-rmse:3.89606\ttrain-rmse:2.01598\n",
      "[10865]\teval-rmse:3.89393\ttrain-rmse:2.01597\n",
      "[10866]\teval-rmse:3.89388\ttrain-rmse:2.01597\n",
      "[10867]\teval-rmse:3.89601\ttrain-rmse:2.01599\n",
      "[10868]\teval-rmse:3.89624\ttrain-rmse:2.01599\n",
      "[10869]\teval-rmse:3.89436\ttrain-rmse:2.016\n",
      "[10870]\teval-rmse:3.89561\ttrain-rmse:2.016\n",
      "[10871]\teval-rmse:3.89595\ttrain-rmse:2.016\n",
      "[10872]\teval-rmse:3.89591\ttrain-rmse:2.016\n",
      "[10873]\teval-rmse:3.89401\ttrain-rmse:2.01598\n",
      "[10874]\teval-rmse:3.89601\ttrain-rmse:2.016\n",
      "[10875]\teval-rmse:3.89701\ttrain-rmse:2.01602\n",
      "[10876]\teval-rmse:3.8964\ttrain-rmse:2.01578\n",
      "[10877]\teval-rmse:3.89736\ttrain-rmse:2.0158\n",
      "[10878]\teval-rmse:3.8977\ttrain-rmse:2.0158\n",
      "[10879]\teval-rmse:3.89845\ttrain-rmse:2.01581\n",
      "[10880]\teval-rmse:3.89814\ttrain-rmse:2.01581\n",
      "[10881]\teval-rmse:3.896\ttrain-rmse:2.01578\n",
      "[10882]\teval-rmse:3.89593\ttrain-rmse:2.01578\n",
      "[10883]\teval-rmse:3.89529\ttrain-rmse:2.01577\n",
      "[10884]\teval-rmse:3.89608\ttrain-rmse:2.01578\n",
      "[10885]\teval-rmse:3.89683\ttrain-rmse:2.01579\n",
      "[10886]\teval-rmse:3.89798\ttrain-rmse:2.0158\n",
      "[10887]\teval-rmse:3.89906\ttrain-rmse:2.01581\n",
      "[10888]\teval-rmse:3.89929\ttrain-rmse:2.01582\n",
      "[10889]\teval-rmse:3.8994\ttrain-rmse:2.01582\n",
      "[10890]\teval-rmse:3.90149\ttrain-rmse:2.01588\n",
      "[10891]\teval-rmse:3.90155\ttrain-rmse:2.01588\n",
      "[10892]\teval-rmse:3.90039\ttrain-rmse:2.01586\n",
      "[10893]\teval-rmse:3.89916\ttrain-rmse:2.01582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10894]\teval-rmse:3.90031\ttrain-rmse:2.01585\n",
      "[10895]\teval-rmse:3.9024\ttrain-rmse:2.01591\n",
      "[10896]\teval-rmse:3.90171\ttrain-rmse:2.0159\n",
      "[10897]\teval-rmse:3.90211\ttrain-rmse:2.01591\n",
      "[10898]\teval-rmse:3.90128\ttrain-rmse:2.01587\n",
      "[10899]\teval-rmse:3.90291\ttrain-rmse:2.0159\n",
      "[10900]\teval-rmse:3.90137\ttrain-rmse:2.01585\n",
      "[10901]\teval-rmse:3.90296\ttrain-rmse:2.0159\n",
      "[10902]\teval-rmse:3.90209\ttrain-rmse:2.01587\n",
      "[10903]\teval-rmse:3.9009\ttrain-rmse:2.01584\n",
      "[10904]\teval-rmse:3.90152\ttrain-rmse:2.01587\n",
      "[10905]\teval-rmse:3.90315\ttrain-rmse:2.01583\n",
      "[10906]\teval-rmse:3.905\ttrain-rmse:2.01589\n",
      "[10907]\teval-rmse:3.90433\ttrain-rmse:2.01588\n",
      "[10908]\teval-rmse:3.90364\ttrain-rmse:2.01563\n",
      "[10909]\teval-rmse:3.90439\ttrain-rmse:2.01564\n",
      "[10910]\teval-rmse:3.90371\ttrain-rmse:2.01563\n",
      "[10911]\teval-rmse:3.90496\ttrain-rmse:2.01566\n",
      "[10912]\teval-rmse:3.90426\ttrain-rmse:2.01564\n",
      "[10913]\teval-rmse:3.9052\ttrain-rmse:2.01567\n",
      "[10914]\teval-rmse:3.90638\ttrain-rmse:2.01573\n",
      "[10915]\teval-rmse:3.90567\ttrain-rmse:2.01571\n",
      "[10916]\teval-rmse:3.90506\ttrain-rmse:2.01569\n",
      "[10917]\teval-rmse:3.90619\ttrain-rmse:2.01574\n",
      "[10918]\teval-rmse:3.90731\ttrain-rmse:2.01572\n",
      "[10919]\teval-rmse:3.90562\ttrain-rmse:2.01565\n",
      "[10920]\teval-rmse:3.90724\ttrain-rmse:2.01569\n",
      "[10921]\teval-rmse:3.90724\ttrain-rmse:2.01569\n",
      "[10922]\teval-rmse:3.90933\ttrain-rmse:2.01575\n",
      "[10923]\teval-rmse:3.9094\ttrain-rmse:2.01575\n",
      "[10924]\teval-rmse:3.91036\ttrain-rmse:2.0158\n",
      "[10925]\teval-rmse:3.91233\ttrain-rmse:2.01587\n",
      "[10926]\teval-rmse:3.91411\ttrain-rmse:2.01597\n",
      "[10927]\teval-rmse:3.91496\ttrain-rmse:2.01602\n",
      "[10928]\teval-rmse:3.91459\ttrain-rmse:2.01601\n",
      "[10929]\teval-rmse:3.91447\ttrain-rmse:2.016\n",
      "[10930]\teval-rmse:3.91297\ttrain-rmse:2.01594\n",
      "[10931]\teval-rmse:3.91383\ttrain-rmse:2.01597\n",
      "[10932]\teval-rmse:3.91484\ttrain-rmse:2.01603\n",
      "[10933]\teval-rmse:3.91354\ttrain-rmse:2.01595\n",
      "[10934]\teval-rmse:3.91439\ttrain-rmse:2.016\n",
      "[10935]\teval-rmse:3.91376\ttrain-rmse:2.01597\n",
      "[10936]\teval-rmse:3.91517\ttrain-rmse:2.01605\n",
      "[10937]\teval-rmse:3.91443\ttrain-rmse:2.01602\n",
      "[10938]\teval-rmse:3.91402\ttrain-rmse:2.016\n",
      "[10939]\teval-rmse:3.91277\ttrain-rmse:2.01592\n",
      "[10940]\teval-rmse:3.91281\ttrain-rmse:2.01593\n",
      "[10941]\teval-rmse:3.91325\ttrain-rmse:2.01595\n",
      "[10942]\teval-rmse:3.91452\ttrain-rmse:2.01603\n",
      "[10943]\teval-rmse:3.9161\ttrain-rmse:2.01613\n",
      "[10944]\teval-rmse:3.91727\ttrain-rmse:2.01621\n",
      "[10945]\teval-rmse:3.9182\ttrain-rmse:2.01627\n",
      "[10946]\teval-rmse:3.91791\ttrain-rmse:2.01626\n",
      "[10947]\teval-rmse:3.9175\ttrain-rmse:2.01623\n",
      "[10948]\teval-rmse:3.91598\ttrain-rmse:2.01613\n",
      "[10949]\teval-rmse:3.91682\ttrain-rmse:2.01617\n",
      "[10950]\teval-rmse:3.91603\ttrain-rmse:2.01613\n",
      "[10951]\teval-rmse:3.91525\ttrain-rmse:2.01609\n",
      "[10952]\teval-rmse:3.91734\ttrain-rmse:2.01619\n",
      "[10953]\teval-rmse:3.91805\ttrain-rmse:2.01622\n",
      "[10954]\teval-rmse:3.91646\ttrain-rmse:2.01612\n",
      "[10955]\teval-rmse:3.91605\ttrain-rmse:2.01609\n",
      "[10956]\teval-rmse:3.91527\ttrain-rmse:2.01605\n",
      "[10957]\teval-rmse:3.91402\ttrain-rmse:2.016\n",
      "[10958]\teval-rmse:3.91167\ttrain-rmse:2.01586\n",
      "[10959]\teval-rmse:3.91043\ttrain-rmse:2.01581\n",
      "[10960]\teval-rmse:3.90893\ttrain-rmse:2.01573\n",
      "[10961]\teval-rmse:3.90986\ttrain-rmse:2.01578\n",
      "[10962]\teval-rmse:3.90954\ttrain-rmse:2.01577\n",
      "[10963]\teval-rmse:3.90957\ttrain-rmse:2.01577\n",
      "[10964]\teval-rmse:3.90848\ttrain-rmse:2.01571\n",
      "[10965]\teval-rmse:3.90738\ttrain-rmse:2.01566\n",
      "[10966]\teval-rmse:3.90666\ttrain-rmse:2.0154\n",
      "[10967]\teval-rmse:3.90876\ttrain-rmse:2.01547\n",
      "[10968]\teval-rmse:3.90999\ttrain-rmse:2.01553\n",
      "[10969]\teval-rmse:3.90774\ttrain-rmse:2.01543\n",
      "[10970]\teval-rmse:3.90915\ttrain-rmse:2.0155\n",
      "[10971]\teval-rmse:3.90839\ttrain-rmse:2.01545\n",
      "[10972]\teval-rmse:3.9085\ttrain-rmse:2.01545\n",
      "[10973]\teval-rmse:3.90863\ttrain-rmse:2.01546\n",
      "[10974]\teval-rmse:3.90829\ttrain-rmse:2.01544\n",
      "[10975]\teval-rmse:3.90796\ttrain-rmse:2.01543\n",
      "[10976]\teval-rmse:3.90657\ttrain-rmse:2.01536\n",
      "[10977]\teval-rmse:3.90557\ttrain-rmse:2.01531\n",
      "[10978]\teval-rmse:3.90669\ttrain-rmse:2.01536\n",
      "[10979]\teval-rmse:3.90732\ttrain-rmse:2.01539\n",
      "[10980]\teval-rmse:3.90857\ttrain-rmse:2.01545\n",
      "[10981]\teval-rmse:3.90988\ttrain-rmse:2.01552\n",
      "[10982]\teval-rmse:3.90866\ttrain-rmse:2.01547\n",
      "[10983]\teval-rmse:3.91075\ttrain-rmse:2.01558\n",
      "[10984]\teval-rmse:3.9105\ttrain-rmse:2.01557\n",
      "[10985]\teval-rmse:3.91168\ttrain-rmse:2.01564\n",
      "[10986]\teval-rmse:3.91253\ttrain-rmse:2.01567\n",
      "[10987]\teval-rmse:3.91442\ttrain-rmse:2.0158\n",
      "[10988]\teval-rmse:3.91439\ttrain-rmse:2.0158\n",
      "[10989]\teval-rmse:3.91247\ttrain-rmse:2.01568\n",
      "[10990]\teval-rmse:3.91299\ttrain-rmse:2.01571\n",
      "[10991]\teval-rmse:3.91321\ttrain-rmse:2.01572\n",
      "[10992]\teval-rmse:3.91479\ttrain-rmse:2.01572\n",
      "[10993]\teval-rmse:3.91656\ttrain-rmse:2.01583\n",
      "[10994]\teval-rmse:3.91581\ttrain-rmse:2.0158\n",
      "[10995]\teval-rmse:3.91542\ttrain-rmse:2.01578\n",
      "[10996]\teval-rmse:3.91659\ttrain-rmse:2.01586\n",
      "[10997]\teval-rmse:3.91778\ttrain-rmse:2.01596\n",
      "[10998]\teval-rmse:3.91941\ttrain-rmse:2.0161\n",
      "[10999]\teval-rmse:3.9185\ttrain-rmse:2.01605\n",
      "[11000]\teval-rmse:3.91647\ttrain-rmse:2.0159\n",
      "[11001]\teval-rmse:3.91854\ttrain-rmse:2.01599\n",
      "[11002]\teval-rmse:3.91664\ttrain-rmse:2.01586\n",
      "[11003]\teval-rmse:3.91871\ttrain-rmse:2.01587\n",
      "[11004]\teval-rmse:3.91794\ttrain-rmse:2.01584\n",
      "[11005]\teval-rmse:3.91665\ttrain-rmse:2.01577\n",
      "[11006]\teval-rmse:3.91557\ttrain-rmse:2.0157\n",
      "[11007]\teval-rmse:3.91482\ttrain-rmse:2.01567\n",
      "[11008]\teval-rmse:3.91589\ttrain-rmse:2.01574\n",
      "[11009]\teval-rmse:3.91784\ttrain-rmse:2.01583\n",
      "[11010]\teval-rmse:3.91876\ttrain-rmse:2.0159\n",
      "[11011]\teval-rmse:3.92076\ttrain-rmse:2.01605\n",
      "[11012]\teval-rmse:3.92131\ttrain-rmse:2.01608\n",
      "[11013]\teval-rmse:3.92127\ttrain-rmse:2.01608\n",
      "[11014]\teval-rmse:3.9231\ttrain-rmse:2.01622\n",
      "[11015]\teval-rmse:3.92206\ttrain-rmse:2.01616\n",
      "[11016]\teval-rmse:3.92345\ttrain-rmse:2.01627\n",
      "[11017]\teval-rmse:3.92223\ttrain-rmse:2.01618\n",
      "[11018]\teval-rmse:3.92226\ttrain-rmse:2.01618\n",
      "[11019]\teval-rmse:3.92194\ttrain-rmse:2.01615\n",
      "[11020]\teval-rmse:3.92309\ttrain-rmse:2.01624\n",
      "[11021]\teval-rmse:3.9223\ttrain-rmse:2.0162\n",
      "[11022]\teval-rmse:3.92152\ttrain-rmse:2.01615\n",
      "[11023]\teval-rmse:3.91974\ttrain-rmse:2.01602\n",
      "[11024]\teval-rmse:3.91898\ttrain-rmse:2.01598\n",
      "[11025]\teval-rmse:3.91901\ttrain-rmse:2.01599\n",
      "[11026]\teval-rmse:3.92003\ttrain-rmse:2.01606\n",
      "[11027]\teval-rmse:3.91883\ttrain-rmse:2.01599\n",
      "[11028]\teval-rmse:3.91807\ttrain-rmse:2.01596\n",
      "[11029]\teval-rmse:3.92014\ttrain-rmse:2.01606\n",
      "[11030]\teval-rmse:3.92149\ttrain-rmse:2.01614\n",
      "[11031]\teval-rmse:3.92218\ttrain-rmse:2.01619\n",
      "[11032]\teval-rmse:3.92375\ttrain-rmse:2.01629\n",
      "[11033]\teval-rmse:3.92582\ttrain-rmse:2.0164\n",
      "[11034]\teval-rmse:3.92333\ttrain-rmse:2.0162\n",
      "[11035]\teval-rmse:3.92322\ttrain-rmse:2.01619\n",
      "[11036]\teval-rmse:3.92453\ttrain-rmse:2.01627\n",
      "[11037]\teval-rmse:3.92646\ttrain-rmse:2.01631\n",
      "[11038]\teval-rmse:3.92658\ttrain-rmse:2.01632\n",
      "[11039]\teval-rmse:3.92763\ttrain-rmse:2.01635\n",
      "[11040]\teval-rmse:3.92886\ttrain-rmse:2.01646\n",
      "[11041]\teval-rmse:3.92667\ttrain-rmse:2.01623\n",
      "[11042]\teval-rmse:3.92711\ttrain-rmse:2.01627\n",
      "[11043]\teval-rmse:3.92794\ttrain-rmse:2.01634\n",
      "[11044]\teval-rmse:3.92673\ttrain-rmse:2.01624\n",
      "[11045]\teval-rmse:3.9269\ttrain-rmse:2.01625\n",
      "[11046]\teval-rmse:3.92611\ttrain-rmse:2.01619\n",
      "[11047]\teval-rmse:3.92742\ttrain-rmse:2.01632\n",
      "[11048]\teval-rmse:3.92611\ttrain-rmse:2.0162\n",
      "[11049]\teval-rmse:3.92553\ttrain-rmse:2.01615\n",
      "[11050]\teval-rmse:3.9255\ttrain-rmse:2.01615\n",
      "[11051]\teval-rmse:3.92565\ttrain-rmse:2.01616\n",
      "[11052]\teval-rmse:3.92385\ttrain-rmse:2.01602\n",
      "[11053]\teval-rmse:3.92253\ttrain-rmse:2.01592\n",
      "[11054]\teval-rmse:3.92435\ttrain-rmse:2.01606\n",
      "[11055]\teval-rmse:3.92303\ttrain-rmse:2.01598\n",
      "[11056]\teval-rmse:3.9231\ttrain-rmse:2.01599\n",
      "[11057]\teval-rmse:3.92374\ttrain-rmse:2.01604\n",
      "[11058]\teval-rmse:3.92294\ttrain-rmse:2.01599\n",
      "[11059]\teval-rmse:3.92214\ttrain-rmse:2.01592\n",
      "[11060]\teval-rmse:3.92304\ttrain-rmse:2.01599\n",
      "[11061]\teval-rmse:3.92148\ttrain-rmse:2.01586\n",
      "[11062]\teval-rmse:3.92288\ttrain-rmse:2.01597\n",
      "[11063]\teval-rmse:3.92447\ttrain-rmse:2.016\n",
      "[11064]\teval-rmse:3.92338\ttrain-rmse:2.01592\n",
      "[11065]\teval-rmse:3.92295\ttrain-rmse:2.01589\n",
      "[11066]\teval-rmse:3.92352\ttrain-rmse:2.01594\n",
      "[11067]\teval-rmse:3.92221\ttrain-rmse:2.01587\n",
      "[11068]\teval-rmse:3.91987\ttrain-rmse:2.01569\n",
      "[11069]\teval-rmse:3.91993\ttrain-rmse:2.0157\n",
      "[11070]\teval-rmse:3.91926\ttrain-rmse:2.01565\n",
      "[11071]\teval-rmse:3.91934\ttrain-rmse:2.01565\n",
      "[11072]\teval-rmse:3.91819\ttrain-rmse:2.01557\n",
      "[11073]\teval-rmse:3.91743\ttrain-rmse:2.01552\n",
      "[11074]\teval-rmse:3.91811\ttrain-rmse:2.01557\n",
      "[11075]\teval-rmse:3.91771\ttrain-rmse:2.01554\n",
      "[11076]\teval-rmse:3.91778\ttrain-rmse:2.01555\n",
      "[11077]\teval-rmse:3.91862\ttrain-rmse:2.0156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11078]\teval-rmse:3.91968\ttrain-rmse:2.01562\n",
      "[11079]\teval-rmse:3.9189\ttrain-rmse:2.01558\n",
      "[11080]\teval-rmse:3.91726\ttrain-rmse:2.01547\n",
      "[11081]\teval-rmse:3.91802\ttrain-rmse:2.01553\n",
      "[11082]\teval-rmse:3.91802\ttrain-rmse:2.01552\n",
      "[11083]\teval-rmse:3.91974\ttrain-rmse:2.01565\n",
      "[11084]\teval-rmse:3.91968\ttrain-rmse:2.01564\n",
      "[11085]\teval-rmse:3.9179\ttrain-rmse:2.01552\n",
      "[11086]\teval-rmse:3.91882\ttrain-rmse:2.01558\n",
      "[11087]\teval-rmse:3.91769\ttrain-rmse:2.01552\n",
      "[11088]\teval-rmse:3.91737\ttrain-rmse:2.0155\n",
      "[11089]\teval-rmse:3.91821\ttrain-rmse:2.01555\n",
      "[11090]\teval-rmse:3.91742\ttrain-rmse:2.01551\n",
      "[11091]\teval-rmse:3.91778\ttrain-rmse:2.01553\n",
      "[11092]\teval-rmse:3.91694\ttrain-rmse:2.01549\n",
      "[11093]\teval-rmse:3.91771\ttrain-rmse:2.01554\n",
      "[11094]\teval-rmse:3.91979\ttrain-rmse:2.01564\n",
      "[11095]\teval-rmse:3.91837\ttrain-rmse:2.01561\n",
      "[11096]\teval-rmse:3.91894\ttrain-rmse:2.01565\n",
      "[11097]\teval-rmse:3.91892\ttrain-rmse:2.01565\n",
      "[11098]\teval-rmse:3.921\ttrain-rmse:2.01575\n",
      "[11099]\teval-rmse:3.91867\ttrain-rmse:2.01558\n",
      "[11100]\teval-rmse:3.91886\ttrain-rmse:2.0156\n",
      "[11101]\teval-rmse:3.91809\ttrain-rmse:2.01554\n",
      "[11102]\teval-rmse:3.91863\ttrain-rmse:2.01558\n",
      "[11103]\teval-rmse:3.91941\ttrain-rmse:2.01563\n",
      "[11104]\teval-rmse:3.91952\ttrain-rmse:2.01564\n",
      "[11105]\teval-rmse:3.91849\ttrain-rmse:2.01559\n",
      "[11106]\teval-rmse:3.91764\ttrain-rmse:2.01553\n",
      "[11107]\teval-rmse:3.91802\ttrain-rmse:2.01555\n",
      "[11108]\teval-rmse:3.91591\ttrain-rmse:2.01542\n",
      "[11109]\teval-rmse:3.91582\ttrain-rmse:2.01542\n",
      "[11110]\teval-rmse:3.91507\ttrain-rmse:2.01513\n",
      "[11111]\teval-rmse:3.91369\ttrain-rmse:2.01511\n",
      "[11112]\teval-rmse:3.91269\ttrain-rmse:2.01505\n",
      "[11113]\teval-rmse:3.91196\ttrain-rmse:2.01481\n",
      "[11114]\teval-rmse:3.91084\ttrain-rmse:2.01475\n",
      "[11115]\teval-rmse:3.91212\ttrain-rmse:2.01482\n",
      "[11116]\teval-rmse:3.91045\ttrain-rmse:2.01473\n",
      "[11117]\teval-rmse:3.90876\ttrain-rmse:2.01465\n",
      "[11118]\teval-rmse:3.90875\ttrain-rmse:2.01465\n",
      "[11119]\teval-rmse:3.90849\ttrain-rmse:2.01464\n",
      "[11120]\teval-rmse:3.90752\ttrain-rmse:2.0146\n",
      "[11121]\teval-rmse:3.90595\ttrain-rmse:2.01453\n",
      "[11122]\teval-rmse:3.90705\ttrain-rmse:2.01456\n",
      "[11123]\teval-rmse:3.90781\ttrain-rmse:2.01458\n",
      "[11124]\teval-rmse:3.90988\ttrain-rmse:2.01458\n",
      "[11125]\teval-rmse:3.91165\ttrain-rmse:2.01467\n",
      "[11126]\teval-rmse:3.91053\ttrain-rmse:2.01463\n",
      "[11127]\teval-rmse:3.91011\ttrain-rmse:2.01461\n",
      "[11128]\teval-rmse:3.90969\ttrain-rmse:2.01459\n",
      "[11129]\teval-rmse:3.90878\ttrain-rmse:2.01454\n",
      "[11130]\teval-rmse:3.90851\ttrain-rmse:2.01453\n",
      "[11131]\teval-rmse:3.90885\ttrain-rmse:2.01455\n",
      "[11132]\teval-rmse:3.91069\ttrain-rmse:2.01464\n",
      "[11133]\teval-rmse:3.90893\ttrain-rmse:2.01456\n",
      "[11134]\teval-rmse:3.90723\ttrain-rmse:2.01456\n",
      "[11135]\teval-rmse:3.90493\ttrain-rmse:2.01448\n",
      "[11136]\teval-rmse:3.90458\ttrain-rmse:2.01447\n",
      "[11137]\teval-rmse:3.90616\ttrain-rmse:2.01455\n",
      "[11138]\teval-rmse:3.9046\ttrain-rmse:2.01451\n",
      "[11139]\teval-rmse:3.90291\ttrain-rmse:2.01452\n",
      "[11140]\teval-rmse:3.90347\ttrain-rmse:2.01454\n",
      "[11141]\teval-rmse:3.90368\ttrain-rmse:2.01454\n",
      "[11142]\teval-rmse:3.90579\ttrain-rmse:2.0146\n",
      "[11143]\teval-rmse:3.90759\ttrain-rmse:2.0147\n",
      "[11144]\teval-rmse:3.90761\ttrain-rmse:2.0147\n",
      "[11145]\teval-rmse:3.90591\ttrain-rmse:2.01462\n",
      "[11146]\teval-rmse:3.90702\ttrain-rmse:2.01467\n",
      "[11147]\teval-rmse:3.90666\ttrain-rmse:2.01466\n",
      "[11148]\teval-rmse:3.90596\ttrain-rmse:2.01443\n",
      "[11149]\teval-rmse:3.90405\ttrain-rmse:2.01435\n",
      "[11150]\teval-rmse:3.90515\ttrain-rmse:2.01439\n",
      "[11151]\teval-rmse:3.90395\ttrain-rmse:2.01435\n",
      "[11152]\teval-rmse:3.90327\ttrain-rmse:2.01433\n",
      "[11153]\teval-rmse:3.90137\ttrain-rmse:2.01427\n",
      "[11154]\teval-rmse:3.9017\ttrain-rmse:2.01428\n",
      "[11155]\teval-rmse:3.90183\ttrain-rmse:2.01428\n",
      "[11156]\teval-rmse:3.8995\ttrain-rmse:2.01423\n",
      "[11157]\teval-rmse:3.9008\ttrain-rmse:2.01426\n",
      "[11158]\teval-rmse:3.89961\ttrain-rmse:2.01427\n",
      "[11159]\teval-rmse:3.901\ttrain-rmse:2.01431\n",
      "[11160]\teval-rmse:3.89933\ttrain-rmse:2.01425\n",
      "[11161]\teval-rmse:3.90104\ttrain-rmse:2.01428\n",
      "[11162]\teval-rmse:3.90289\ttrain-rmse:2.01432\n",
      "[11163]\teval-rmse:3.90391\ttrain-rmse:2.01436\n",
      "[11164]\teval-rmse:3.90235\ttrain-rmse:2.01432\n",
      "[11165]\teval-rmse:3.9042\ttrain-rmse:2.01439\n",
      "[11166]\teval-rmse:3.90189\ttrain-rmse:2.01433\n",
      "[11167]\teval-rmse:3.90117\ttrain-rmse:2.01431\n",
      "[11168]\teval-rmse:3.90277\ttrain-rmse:2.01429\n",
      "[11169]\teval-rmse:3.90238\ttrain-rmse:2.01427\n",
      "[11170]\teval-rmse:3.90156\ttrain-rmse:2.01424\n",
      "[11171]\teval-rmse:3.90302\ttrain-rmse:2.0143\n",
      "[11172]\teval-rmse:3.90425\ttrain-rmse:2.01433\n",
      "[11173]\teval-rmse:3.90257\ttrain-rmse:2.01427\n",
      "[11174]\teval-rmse:3.90134\ttrain-rmse:2.01422\n",
      "[11175]\teval-rmse:3.90158\ttrain-rmse:2.01423\n",
      "[11176]\teval-rmse:3.90237\ttrain-rmse:2.01426\n",
      "[11177]\teval-rmse:3.90235\ttrain-rmse:2.01426\n",
      "[11178]\teval-rmse:3.90057\ttrain-rmse:2.01418\n",
      "[11179]\teval-rmse:3.90243\ttrain-rmse:2.01424\n",
      "[11180]\teval-rmse:3.90035\ttrain-rmse:2.0142\n",
      "[11181]\teval-rmse:3.89966\ttrain-rmse:2.01395\n",
      "[11182]\teval-rmse:3.89977\ttrain-rmse:2.01396\n",
      "[11183]\teval-rmse:3.89856\ttrain-rmse:2.01396\n",
      "[11184]\teval-rmse:3.89791\ttrain-rmse:2.01395\n",
      "[11185]\teval-rmse:3.89581\ttrain-rmse:2.01391\n",
      "[11186]\teval-rmse:3.89742\ttrain-rmse:2.01387\n",
      "[11187]\teval-rmse:3.89676\ttrain-rmse:2.01386\n",
      "[11188]\teval-rmse:3.89646\ttrain-rmse:2.01385\n",
      "[11189]\teval-rmse:3.89493\ttrain-rmse:2.01383\n",
      "[11190]\teval-rmse:3.89504\ttrain-rmse:2.01383\n",
      "[11191]\teval-rmse:3.89485\ttrain-rmse:2.01383\n",
      "[11192]\teval-rmse:3.8942\ttrain-rmse:2.01382\n",
      "[11193]\teval-rmse:3.89543\ttrain-rmse:2.01384\n",
      "[11194]\teval-rmse:3.8967\ttrain-rmse:2.01385\n",
      "[11195]\teval-rmse:3.89746\ttrain-rmse:2.01387\n",
      "[11196]\teval-rmse:3.8953\ttrain-rmse:2.01383\n",
      "[11197]\teval-rmse:3.89537\ttrain-rmse:2.01383\n",
      "[11198]\teval-rmse:3.8937\ttrain-rmse:2.01379\n",
      "[11199]\teval-rmse:3.89154\ttrain-rmse:2.01375\n",
      "[11200]\teval-rmse:3.89219\ttrain-rmse:2.01375\n",
      "[11201]\teval-rmse:3.89147\ttrain-rmse:2.01374\n",
      "[11202]\teval-rmse:3.89358\ttrain-rmse:2.01376\n",
      "[11203]\teval-rmse:3.8954\ttrain-rmse:2.01378\n",
      "[11204]\teval-rmse:3.89351\ttrain-rmse:2.01374\n",
      "[11205]\teval-rmse:3.89481\ttrain-rmse:2.01375\n",
      "[11206]\teval-rmse:3.89524\ttrain-rmse:2.01376\n",
      "[11207]\teval-rmse:3.89614\ttrain-rmse:2.01377\n",
      "[11208]\teval-rmse:3.89707\ttrain-rmse:2.0138\n",
      "[11209]\teval-rmse:3.89675\ttrain-rmse:2.01379\n",
      "[11210]\teval-rmse:3.89653\ttrain-rmse:2.01379\n",
      "[11211]\teval-rmse:3.8984\ttrain-rmse:2.01381\n",
      "[11212]\teval-rmse:3.89885\ttrain-rmse:2.01382\n",
      "[11213]\teval-rmse:3.89767\ttrain-rmse:2.0138\n",
      "[11214]\teval-rmse:3.89897\ttrain-rmse:2.01383\n",
      "[11215]\teval-rmse:3.8991\ttrain-rmse:2.01383\n",
      "[11216]\teval-rmse:3.90003\ttrain-rmse:2.01386\n",
      "[11217]\teval-rmse:3.90114\ttrain-rmse:2.0139\n",
      "[11218]\teval-rmse:3.90186\ttrain-rmse:2.01392\n",
      "[11219]\teval-rmse:3.90271\ttrain-rmse:2.01394\n",
      "[11220]\teval-rmse:3.90339\ttrain-rmse:2.01397\n",
      "[11221]\teval-rmse:3.90219\ttrain-rmse:2.01394\n",
      "[11222]\teval-rmse:3.90097\ttrain-rmse:2.01395\n",
      "[11223]\teval-rmse:3.90065\ttrain-rmse:2.01394\n",
      "[11224]\teval-rmse:3.89917\ttrain-rmse:2.01389\n",
      "[11225]\teval-rmse:3.90125\ttrain-rmse:2.01396\n",
      "[11226]\teval-rmse:3.89968\ttrain-rmse:2.01391\n",
      "[11227]\teval-rmse:3.90117\ttrain-rmse:2.01396\n",
      "[11228]\teval-rmse:3.89999\ttrain-rmse:2.01393\n",
      "[11229]\teval-rmse:3.89878\ttrain-rmse:2.01389\n",
      "[11230]\teval-rmse:3.89855\ttrain-rmse:2.01388\n",
      "[11231]\teval-rmse:3.8995\ttrain-rmse:2.01391\n",
      "[11232]\teval-rmse:3.89849\ttrain-rmse:2.01388\n",
      "[11233]\teval-rmse:3.89674\ttrain-rmse:2.01383\n",
      "[11234]\teval-rmse:3.89639\ttrain-rmse:2.01383\n",
      "[11235]\teval-rmse:3.89825\ttrain-rmse:2.01385\n",
      "[11236]\teval-rmse:3.89795\ttrain-rmse:2.01385\n",
      "[11237]\teval-rmse:3.89728\ttrain-rmse:2.01383\n",
      "[11238]\teval-rmse:3.89587\ttrain-rmse:2.01379\n",
      "[11239]\teval-rmse:3.89527\ttrain-rmse:2.01353\n",
      "[11240]\teval-rmse:3.89616\ttrain-rmse:2.01355\n",
      "[11241]\teval-rmse:3.89788\ttrain-rmse:2.0136\n",
      "[11242]\teval-rmse:3.89924\ttrain-rmse:2.01365\n",
      "[11243]\teval-rmse:3.89717\ttrain-rmse:2.01359\n",
      "[11244]\teval-rmse:3.89748\ttrain-rmse:2.0136\n",
      "[11245]\teval-rmse:3.89523\ttrain-rmse:2.01354\n",
      "[11246]\teval-rmse:3.89374\ttrain-rmse:2.01351\n",
      "[11247]\teval-rmse:3.89316\ttrain-rmse:2.01324\n",
      "[11248]\teval-rmse:3.89451\ttrain-rmse:2.01327\n",
      "[11249]\teval-rmse:3.8925\ttrain-rmse:2.01324\n",
      "[11250]\teval-rmse:3.8945\ttrain-rmse:2.01329\n",
      "[11251]\teval-rmse:3.89228\ttrain-rmse:2.01325\n",
      "[11252]\teval-rmse:3.89039\ttrain-rmse:2.01323\n",
      "[11253]\teval-rmse:3.88975\ttrain-rmse:2.01302\n",
      "[11254]\teval-rmse:3.88987\ttrain-rmse:2.01302\n",
      "[11255]\teval-rmse:3.89043\ttrain-rmse:2.01303\n",
      "[11256]\teval-rmse:3.89011\ttrain-rmse:2.01303\n",
      "[11257]\teval-rmse:3.89209\ttrain-rmse:2.01307\n",
      "[11258]\teval-rmse:3.89418\ttrain-rmse:2.01309\n",
      "[11259]\teval-rmse:3.89316\ttrain-rmse:2.01306\n",
      "[11260]\teval-rmse:3.89223\ttrain-rmse:2.01305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11261]\teval-rmse:3.89364\ttrain-rmse:2.01308\n",
      "[11262]\teval-rmse:3.89244\ttrain-rmse:2.0131\n",
      "[11263]\teval-rmse:3.89104\ttrain-rmse:2.01309\n",
      "[11264]\teval-rmse:3.89105\ttrain-rmse:2.01309\n",
      "[11265]\teval-rmse:3.89218\ttrain-rmse:2.01306\n",
      "[11266]\teval-rmse:3.89056\ttrain-rmse:2.01302\n",
      "[11267]\teval-rmse:3.88908\ttrain-rmse:2.013\n",
      "[11268]\teval-rmse:3.88747\ttrain-rmse:2.013\n",
      "[11269]\teval-rmse:3.8872\ttrain-rmse:2.013\n",
      "[11270]\teval-rmse:3.88582\ttrain-rmse:2.013\n",
      "[11271]\teval-rmse:3.88779\ttrain-rmse:2.01293\n",
      "[11272]\teval-rmse:3.88863\ttrain-rmse:2.01294\n",
      "[11273]\teval-rmse:3.88818\ttrain-rmse:2.01293\n",
      "[11274]\teval-rmse:3.8865\ttrain-rmse:2.01291\n",
      "[11275]\teval-rmse:3.88487\ttrain-rmse:2.01289\n",
      "[11276]\teval-rmse:3.88652\ttrain-rmse:2.01288\n",
      "[11277]\teval-rmse:3.8868\ttrain-rmse:2.01288\n",
      "[11278]\teval-rmse:3.88763\ttrain-rmse:2.01288\n",
      "[11279]\teval-rmse:3.88854\ttrain-rmse:2.01288\n",
      "[11280]\teval-rmse:3.88931\ttrain-rmse:2.01288\n",
      "[11281]\teval-rmse:3.88765\ttrain-rmse:2.01285\n",
      "[11282]\teval-rmse:3.88791\ttrain-rmse:2.01285\n",
      "[11283]\teval-rmse:3.88901\ttrain-rmse:2.01285\n",
      "[11284]\teval-rmse:3.89054\ttrain-rmse:2.01286\n",
      "[11285]\teval-rmse:3.88991\ttrain-rmse:2.01286\n",
      "[11286]\teval-rmse:3.88812\ttrain-rmse:2.01285\n",
      "[11287]\teval-rmse:3.88916\ttrain-rmse:2.01285\n",
      "[11288]\teval-rmse:3.88977\ttrain-rmse:2.01286\n",
      "[11289]\teval-rmse:3.89091\ttrain-rmse:2.01288\n",
      "[11290]\teval-rmse:3.89118\ttrain-rmse:2.01288\n",
      "[11291]\teval-rmse:3.89232\ttrain-rmse:2.01291\n",
      "[11292]\teval-rmse:3.8914\ttrain-rmse:2.01289\n",
      "[11293]\teval-rmse:3.89215\ttrain-rmse:2.01291\n",
      "[11294]\teval-rmse:3.89001\ttrain-rmse:2.01287\n",
      "[11295]\teval-rmse:3.88863\ttrain-rmse:2.01286\n",
      "[11296]\teval-rmse:3.89003\ttrain-rmse:2.01287\n",
      "[11297]\teval-rmse:3.88795\ttrain-rmse:2.01287\n",
      "[11298]\teval-rmse:3.88694\ttrain-rmse:2.01287\n",
      "[11299]\teval-rmse:3.88677\ttrain-rmse:2.01286\n",
      "[11300]\teval-rmse:3.88854\ttrain-rmse:2.01286\n",
      "[11301]\teval-rmse:3.8876\ttrain-rmse:2.01285\n",
      "[11302]\teval-rmse:3.8861\ttrain-rmse:2.01286\n",
      "[11303]\teval-rmse:3.88549\ttrain-rmse:2.01262\n",
      "[11304]\teval-rmse:3.88676\ttrain-rmse:2.01263\n",
      "[11305]\teval-rmse:3.88565\ttrain-rmse:2.01263\n",
      "[11306]\teval-rmse:3.885\ttrain-rmse:2.01262\n",
      "[11307]\teval-rmse:3.88583\ttrain-rmse:2.01262\n",
      "[11308]\teval-rmse:3.8855\ttrain-rmse:2.01262\n",
      "[11309]\teval-rmse:3.88726\ttrain-rmse:2.01263\n",
      "[11310]\teval-rmse:3.88614\ttrain-rmse:2.01263\n",
      "[11311]\teval-rmse:3.88661\ttrain-rmse:2.01263\n",
      "[11312]\teval-rmse:3.88847\ttrain-rmse:2.01266\n",
      "[11313]\teval-rmse:3.88968\ttrain-rmse:2.01267\n",
      "[11314]\teval-rmse:3.88979\ttrain-rmse:2.01267\n",
      "[11315]\teval-rmse:3.88781\ttrain-rmse:2.01267\n",
      "[11316]\teval-rmse:3.88776\ttrain-rmse:2.01267\n",
      "[11317]\teval-rmse:3.88776\ttrain-rmse:2.01267\n",
      "[11318]\teval-rmse:3.88859\ttrain-rmse:2.01267\n",
      "[11319]\teval-rmse:3.88992\ttrain-rmse:2.01269\n",
      "[11320]\teval-rmse:3.89163\ttrain-rmse:2.01273\n",
      "[11321]\teval-rmse:3.89073\ttrain-rmse:2.01272\n",
      "[11322]\teval-rmse:3.89199\ttrain-rmse:2.01275\n",
      "[11323]\teval-rmse:3.89168\ttrain-rmse:2.01274\n",
      "[11324]\teval-rmse:3.89059\ttrain-rmse:2.01271\n",
      "[11325]\teval-rmse:3.89125\ttrain-rmse:2.01273\n",
      "[11326]\teval-rmse:3.88971\ttrain-rmse:2.0127\n",
      "[11327]\teval-rmse:3.88746\ttrain-rmse:2.01267\n",
      "[11328]\teval-rmse:3.88557\ttrain-rmse:2.01267\n",
      "[11329]\teval-rmse:3.88671\ttrain-rmse:2.01263\n",
      "[11330]\teval-rmse:3.88546\ttrain-rmse:2.01263\n",
      "[11331]\teval-rmse:3.88665\ttrain-rmse:2.01265\n",
      "[11332]\teval-rmse:3.88516\ttrain-rmse:2.01265\n",
      "[11333]\teval-rmse:3.88596\ttrain-rmse:2.01265\n",
      "[11334]\teval-rmse:3.88682\ttrain-rmse:2.01265\n",
      "[11335]\teval-rmse:3.88469\ttrain-rmse:2.01266\n",
      "[11336]\teval-rmse:3.88394\ttrain-rmse:2.01266\n",
      "[11337]\teval-rmse:3.8832\ttrain-rmse:2.01266\n",
      "[11338]\teval-rmse:3.88515\ttrain-rmse:2.01267\n",
      "[11339]\teval-rmse:3.88379\ttrain-rmse:2.01268\n",
      "[11340]\teval-rmse:3.88449\ttrain-rmse:2.01267\n",
      "[11341]\teval-rmse:3.88309\ttrain-rmse:2.01267\n",
      "[11342]\teval-rmse:3.88198\ttrain-rmse:2.01267\n",
      "[11343]\teval-rmse:3.88395\ttrain-rmse:2.01259\n",
      "[11344]\teval-rmse:3.8825\ttrain-rmse:2.01258\n",
      "[11345]\teval-rmse:3.88339\ttrain-rmse:2.01258\n",
      "[11346]\teval-rmse:3.88538\ttrain-rmse:2.01257\n",
      "[11347]\teval-rmse:3.88338\ttrain-rmse:2.01256\n",
      "[11348]\teval-rmse:3.88531\ttrain-rmse:2.01257\n",
      "[11349]\teval-rmse:3.88694\ttrain-rmse:2.01258\n",
      "[11350]\teval-rmse:3.88869\ttrain-rmse:2.01261\n",
      "[11351]\teval-rmse:3.89005\ttrain-rmse:2.01264\n",
      "[11352]\teval-rmse:3.89131\ttrain-rmse:2.01265\n",
      "[11353]\teval-rmse:3.89212\ttrain-rmse:2.01267\n",
      "[11354]\teval-rmse:3.89069\ttrain-rmse:2.01264\n",
      "[11355]\teval-rmse:3.89038\ttrain-rmse:2.01263\n",
      "[11356]\teval-rmse:3.88862\ttrain-rmse:2.0126\n",
      "[11357]\teval-rmse:3.89025\ttrain-rmse:2.01255\n",
      "[11358]\teval-rmse:3.89033\ttrain-rmse:2.01255\n",
      "[11359]\teval-rmse:3.89244\ttrain-rmse:2.01258\n",
      "[11360]\teval-rmse:3.89245\ttrain-rmse:2.01258\n",
      "[11361]\teval-rmse:3.89215\ttrain-rmse:2.01257\n",
      "[11362]\teval-rmse:3.89152\ttrain-rmse:2.01257\n",
      "[11363]\teval-rmse:3.8907\ttrain-rmse:2.01255\n",
      "[11364]\teval-rmse:3.88955\ttrain-rmse:2.01254\n",
      "[11365]\teval-rmse:3.88897\ttrain-rmse:2.0123\n",
      "[11366]\teval-rmse:3.88758\ttrain-rmse:2.01227\n",
      "[11367]\teval-rmse:3.88866\ttrain-rmse:2.01228\n",
      "[11368]\teval-rmse:3.88719\ttrain-rmse:2.01226\n",
      "[11369]\teval-rmse:3.88703\ttrain-rmse:2.01226\n",
      "[11370]\teval-rmse:3.88901\ttrain-rmse:2.01227\n",
      "[11371]\teval-rmse:3.88838\ttrain-rmse:2.01226\n",
      "[11372]\teval-rmse:3.88925\ttrain-rmse:2.01227\n",
      "[11373]\teval-rmse:3.89067\ttrain-rmse:2.0123\n",
      "[11374]\teval-rmse:3.89093\ttrain-rmse:2.0123\n",
      "[11375]\teval-rmse:3.89115\ttrain-rmse:2.01231\n",
      "[11376]\teval-rmse:3.89052\ttrain-rmse:2.01207\n",
      "[11377]\teval-rmse:3.89075\ttrain-rmse:2.01207\n",
      "[11378]\teval-rmse:3.88958\ttrain-rmse:2.01206\n",
      "[11379]\teval-rmse:3.88747\ttrain-rmse:2.01205\n",
      "[11380]\teval-rmse:3.88648\ttrain-rmse:2.01205\n",
      "[11381]\teval-rmse:3.88537\ttrain-rmse:2.01204\n",
      "[11382]\teval-rmse:3.88408\ttrain-rmse:2.01203\n",
      "[11383]\teval-rmse:3.88618\ttrain-rmse:2.01204\n",
      "[11384]\teval-rmse:3.8843\ttrain-rmse:2.01202\n",
      "[11385]\teval-rmse:3.88564\ttrain-rmse:2.01203\n",
      "[11386]\teval-rmse:3.88418\ttrain-rmse:2.01202\n",
      "[11387]\teval-rmse:3.88492\ttrain-rmse:2.01202\n",
      "[11388]\teval-rmse:3.88704\ttrain-rmse:2.01203\n",
      "[11389]\teval-rmse:3.88591\ttrain-rmse:2.01202\n",
      "[11390]\teval-rmse:3.88491\ttrain-rmse:2.01201\n",
      "[11391]\teval-rmse:3.88686\ttrain-rmse:2.01202\n",
      "[11392]\teval-rmse:3.88897\ttrain-rmse:2.01203\n",
      "[11393]\teval-rmse:3.88927\ttrain-rmse:2.01204\n",
      "[11394]\teval-rmse:3.89139\ttrain-rmse:2.01206\n",
      "[11395]\teval-rmse:3.8902\ttrain-rmse:2.01208\n",
      "[11396]\teval-rmse:3.89126\ttrain-rmse:2.0121\n",
      "[11397]\teval-rmse:3.89127\ttrain-rmse:2.0121\n",
      "[11398]\teval-rmse:3.891\ttrain-rmse:2.01209\n",
      "[11399]\teval-rmse:3.88953\ttrain-rmse:2.01207\n",
      "[11400]\teval-rmse:3.88891\ttrain-rmse:2.01206\n",
      "[11401]\teval-rmse:3.89102\ttrain-rmse:2.01209\n",
      "[11402]\teval-rmse:3.89082\ttrain-rmse:2.01209\n",
      "[11403]\teval-rmse:3.89017\ttrain-rmse:2.01209\n",
      "[11404]\teval-rmse:3.8882\ttrain-rmse:2.01208\n",
      "[11405]\teval-rmse:3.88845\ttrain-rmse:2.01208\n",
      "[11406]\teval-rmse:3.88693\ttrain-rmse:2.01206\n",
      "[11407]\teval-rmse:3.88577\ttrain-rmse:2.0121\n",
      "[11408]\teval-rmse:3.88437\ttrain-rmse:2.01209\n",
      "[11409]\teval-rmse:3.88421\ttrain-rmse:2.01209\n",
      "[11410]\teval-rmse:3.88605\ttrain-rmse:2.01212\n",
      "[11411]\teval-rmse:3.88644\ttrain-rmse:2.01212\n",
      "[11412]\teval-rmse:3.88715\ttrain-rmse:2.01213\n",
      "[11413]\teval-rmse:3.88683\ttrain-rmse:2.01213\n",
      "[11414]\teval-rmse:3.88828\ttrain-rmse:2.01215\n",
      "[11415]\teval-rmse:3.88767\ttrain-rmse:2.01214\n",
      "[11416]\teval-rmse:3.88641\ttrain-rmse:2.01218\n",
      "[11417]\teval-rmse:3.88595\ttrain-rmse:2.01216\n",
      "[11418]\teval-rmse:3.88436\ttrain-rmse:2.01217\n",
      "[11419]\teval-rmse:3.88649\ttrain-rmse:2.01218\n",
      "[11420]\teval-rmse:3.88588\ttrain-rmse:2.01217\n",
      "[11421]\teval-rmse:3.88571\ttrain-rmse:2.01217\n",
      "[11422]\teval-rmse:3.88511\ttrain-rmse:2.01217\n",
      "[11423]\teval-rmse:3.88291\ttrain-rmse:2.01216\n",
      "[11424]\teval-rmse:3.88325\ttrain-rmse:2.01216\n",
      "[11425]\teval-rmse:3.88142\ttrain-rmse:2.01217\n",
      "[11426]\teval-rmse:3.88165\ttrain-rmse:2.01217\n",
      "[11427]\teval-rmse:3.8819\ttrain-rmse:2.01216\n",
      "[11428]\teval-rmse:3.88332\ttrain-rmse:2.01217\n",
      "[11429]\teval-rmse:3.88299\ttrain-rmse:2.01216\n",
      "[11430]\teval-rmse:3.88506\ttrain-rmse:2.01208\n",
      "[11431]\teval-rmse:3.88398\ttrain-rmse:2.01206\n",
      "[11432]\teval-rmse:3.88351\ttrain-rmse:2.01206\n",
      "[11433]\teval-rmse:3.8849\ttrain-rmse:2.01207\n",
      "[11434]\teval-rmse:3.8855\ttrain-rmse:2.01207\n",
      "[11435]\teval-rmse:3.8839\ttrain-rmse:2.01207\n",
      "[11436]\teval-rmse:3.88427\ttrain-rmse:2.01207\n",
      "[11437]\teval-rmse:3.88474\ttrain-rmse:2.01208\n",
      "[11438]\teval-rmse:3.8838\ttrain-rmse:2.01207\n",
      "[11439]\teval-rmse:3.88501\ttrain-rmse:2.01209\n",
      "[11440]\teval-rmse:3.88336\ttrain-rmse:2.01208\n",
      "[11441]\teval-rmse:3.88319\ttrain-rmse:2.01208\n",
      "[11442]\teval-rmse:3.88444\ttrain-rmse:2.01208\n",
      "[11443]\teval-rmse:3.88384\ttrain-rmse:2.01208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11444]\teval-rmse:3.88271\ttrain-rmse:2.01213\n",
      "[11445]\teval-rmse:3.8835\ttrain-rmse:2.01213\n",
      "[11446]\teval-rmse:3.8832\ttrain-rmse:2.01213\n",
      "[11447]\teval-rmse:3.88211\ttrain-rmse:2.01213\n",
      "[11448]\teval-rmse:3.88082\ttrain-rmse:2.01213\n",
      "[11449]\teval-rmse:3.879\ttrain-rmse:2.01214\n",
      "[11450]\teval-rmse:3.88098\ttrain-rmse:2.01204\n",
      "[11451]\teval-rmse:3.88245\ttrain-rmse:2.01204\n",
      "[11452]\teval-rmse:3.88353\ttrain-rmse:2.01204\n",
      "[11453]\teval-rmse:3.88458\ttrain-rmse:2.01205\n",
      "[11454]\teval-rmse:3.88442\ttrain-rmse:2.01205\n",
      "[11455]\teval-rmse:3.88427\ttrain-rmse:2.01205\n",
      "[11456]\teval-rmse:3.88267\ttrain-rmse:2.0121\n",
      "[11457]\teval-rmse:3.8806\ttrain-rmse:2.01207\n",
      "[11458]\teval-rmse:3.88075\ttrain-rmse:2.01207\n",
      "[11459]\teval-rmse:3.88218\ttrain-rmse:2.01207\n",
      "[11460]\teval-rmse:3.88102\ttrain-rmse:2.01207\n",
      "[11461]\teval-rmse:3.87994\ttrain-rmse:2.01208\n",
      "[11462]\teval-rmse:3.87793\ttrain-rmse:2.01209\n",
      "[11463]\teval-rmse:3.87599\ttrain-rmse:2.01212\n",
      "[11464]\teval-rmse:3.87493\ttrain-rmse:2.01213\n",
      "[11465]\teval-rmse:3.87467\ttrain-rmse:2.01213\n",
      "[11466]\teval-rmse:3.87397\ttrain-rmse:2.01215\n",
      "[11467]\teval-rmse:3.8722\ttrain-rmse:2.01219\n",
      "[11468]\teval-rmse:3.87167\ttrain-rmse:2.0122\n",
      "[11469]\teval-rmse:3.87063\ttrain-rmse:2.01223\n",
      "[11470]\teval-rmse:3.87038\ttrain-rmse:2.01223\n",
      "[11471]\teval-rmse:3.87022\ttrain-rmse:2.01224\n",
      "[11472]\teval-rmse:3.87036\ttrain-rmse:2.01223\n",
      "[11473]\teval-rmse:3.87176\ttrain-rmse:2.0122\n",
      "[11474]\teval-rmse:3.86999\ttrain-rmse:2.01224\n",
      "[11475]\teval-rmse:3.86858\ttrain-rmse:2.01228\n",
      "[11476]\teval-rmse:3.8671\ttrain-rmse:2.01232\n",
      "[11477]\teval-rmse:3.86767\ttrain-rmse:2.0123\n",
      "[11478]\teval-rmse:3.86884\ttrain-rmse:2.01225\n",
      "[11479]\teval-rmse:3.86723\ttrain-rmse:2.01232\n",
      "[11480]\teval-rmse:3.86671\ttrain-rmse:2.01233\n",
      "[11481]\teval-rmse:3.86604\ttrain-rmse:2.01236\n",
      "[11482]\teval-rmse:3.86558\ttrain-rmse:2.01238\n",
      "[11483]\teval-rmse:3.86578\ttrain-rmse:2.01237\n",
      "[11484]\teval-rmse:3.86385\ttrain-rmse:2.01243\n",
      "[11485]\teval-rmse:3.86406\ttrain-rmse:2.01242\n",
      "[11486]\teval-rmse:3.86308\ttrain-rmse:2.01246\n",
      "[11487]\teval-rmse:3.8618\ttrain-rmse:2.01251\n",
      "[11488]\teval-rmse:3.86165\ttrain-rmse:2.01252\n",
      "[11489]\teval-rmse:3.86041\ttrain-rmse:2.01258\n",
      "[11490]\teval-rmse:3.85956\ttrain-rmse:2.01262\n",
      "[11491]\teval-rmse:3.861\ttrain-rmse:2.01254\n",
      "[11492]\teval-rmse:3.86239\ttrain-rmse:2.01247\n",
      "[11493]\teval-rmse:3.86195\ttrain-rmse:2.01249\n",
      "[11494]\teval-rmse:3.861\ttrain-rmse:2.01253\n",
      "[11495]\teval-rmse:3.85916\ttrain-rmse:2.01262\n",
      "[11496]\teval-rmse:3.85905\ttrain-rmse:2.01263\n",
      "[11497]\teval-rmse:3.85935\ttrain-rmse:2.01261\n",
      "[11498]\teval-rmse:3.85824\ttrain-rmse:2.01271\n",
      "[11499]\teval-rmse:3.8582\ttrain-rmse:2.01271\n",
      "[11500]\teval-rmse:3.86006\ttrain-rmse:2.01261\n",
      "[11501]\teval-rmse:3.86009\ttrain-rmse:2.01261\n",
      "[11502]\teval-rmse:3.86049\ttrain-rmse:2.01259\n",
      "[11503]\teval-rmse:3.86248\ttrain-rmse:2.01242\n",
      "[11504]\teval-rmse:3.86089\ttrain-rmse:2.01251\n",
      "[11505]\teval-rmse:3.86237\ttrain-rmse:2.01244\n",
      "[11506]\teval-rmse:3.86139\ttrain-rmse:2.01247\n",
      "[11507]\teval-rmse:3.86042\ttrain-rmse:2.01251\n",
      "[11508]\teval-rmse:3.86035\ttrain-rmse:2.01252\n",
      "[11509]\teval-rmse:3.85988\ttrain-rmse:2.01254\n",
      "[11510]\teval-rmse:3.85977\ttrain-rmse:2.01255\n",
      "[11511]\teval-rmse:3.8607\ttrain-rmse:2.0125\n",
      "[11512]\teval-rmse:3.86127\ttrain-rmse:2.01247\n",
      "[11513]\teval-rmse:3.86062\ttrain-rmse:2.0125\n",
      "[11514]\teval-rmse:3.85965\ttrain-rmse:2.01254\n",
      "[11515]\teval-rmse:3.8618\ttrain-rmse:2.01246\n",
      "[11516]\teval-rmse:3.86053\ttrain-rmse:2.01253\n",
      "[11517]\teval-rmse:3.86264\ttrain-rmse:2.01241\n",
      "[11518]\teval-rmse:3.86363\ttrain-rmse:2.01236\n",
      "[11519]\teval-rmse:3.86354\ttrain-rmse:2.01236\n",
      "[11520]\teval-rmse:3.86235\ttrain-rmse:2.01242\n",
      "[11521]\teval-rmse:3.86022\ttrain-rmse:2.01255\n",
      "[11522]\teval-rmse:3.86178\ttrain-rmse:2.01247\n",
      "[11523]\teval-rmse:3.86094\ttrain-rmse:2.01253\n",
      "[11524]\teval-rmse:3.8601\ttrain-rmse:2.01257\n",
      "[11525]\teval-rmse:3.85962\ttrain-rmse:2.0126\n",
      "[11526]\teval-rmse:3.8586\ttrain-rmse:2.01266\n",
      "[11527]\teval-rmse:3.85649\ttrain-rmse:2.01281\n",
      "[11528]\teval-rmse:3.85602\ttrain-rmse:2.01283\n",
      "[11529]\teval-rmse:3.85378\ttrain-rmse:2.01299\n",
      "[11530]\teval-rmse:3.85327\ttrain-rmse:2.01302\n",
      "[11531]\teval-rmse:3.85422\ttrain-rmse:2.01296\n",
      "[11532]\teval-rmse:3.85521\ttrain-rmse:2.01289\n",
      "[11533]\teval-rmse:3.85562\ttrain-rmse:2.01286\n",
      "[11534]\teval-rmse:3.85665\ttrain-rmse:2.01277\n",
      "[11535]\teval-rmse:3.85808\ttrain-rmse:2.01268\n",
      "[11536]\teval-rmse:3.85712\ttrain-rmse:2.01273\n",
      "[11537]\teval-rmse:3.85747\ttrain-rmse:2.0127\n",
      "[11538]\teval-rmse:3.85663\ttrain-rmse:2.01275\n",
      "[11539]\teval-rmse:3.85836\ttrain-rmse:2.01264\n",
      "[11540]\teval-rmse:3.85659\ttrain-rmse:2.01275\n",
      "[11541]\teval-rmse:3.85802\ttrain-rmse:2.01267\n",
      "[11542]\teval-rmse:3.85667\ttrain-rmse:2.01276\n",
      "[11543]\teval-rmse:3.85774\ttrain-rmse:2.01269\n",
      "[11544]\teval-rmse:3.85659\ttrain-rmse:2.01276\n",
      "[11545]\teval-rmse:3.85524\ttrain-rmse:2.01285\n",
      "[11546]\teval-rmse:3.856\ttrain-rmse:2.0128\n",
      "[11547]\teval-rmse:3.85814\ttrain-rmse:2.0127\n",
      "[11548]\teval-rmse:3.86024\ttrain-rmse:2.01251\n",
      "[11549]\teval-rmse:3.8588\ttrain-rmse:2.0126\n",
      "[11550]\teval-rmse:3.86079\ttrain-rmse:2.01242\n",
      "[11551]\teval-rmse:3.86054\ttrain-rmse:2.01244\n",
      "[11552]\teval-rmse:3.86084\ttrain-rmse:2.01242\n",
      "[11553]\teval-rmse:3.85885\ttrain-rmse:2.01254\n",
      "[11554]\teval-rmse:3.86046\ttrain-rmse:2.01243\n",
      "[11555]\teval-rmse:3.86053\ttrain-rmse:2.01243\n",
      "[11556]\teval-rmse:3.86238\ttrain-rmse:2.01232\n",
      "[11557]\teval-rmse:3.86065\ttrain-rmse:2.0124\n",
      "[11558]\teval-rmse:3.8628\ttrain-rmse:2.01231\n",
      "[11559]\teval-rmse:3.86144\ttrain-rmse:2.01238\n",
      "[11560]\teval-rmse:3.85957\ttrain-rmse:2.01251\n",
      "[11561]\teval-rmse:3.85838\ttrain-rmse:2.0126\n",
      "[11562]\teval-rmse:3.85868\ttrain-rmse:2.01257\n",
      "[11563]\teval-rmse:3.85962\ttrain-rmse:2.01252\n",
      "[11564]\teval-rmse:3.85793\ttrain-rmse:2.01263\n",
      "[11565]\teval-rmse:3.85758\ttrain-rmse:2.01265\n",
      "[11566]\teval-rmse:3.85878\ttrain-rmse:2.01257\n",
      "[11567]\teval-rmse:3.86064\ttrain-rmse:2.01246\n",
      "[11568]\teval-rmse:3.85871\ttrain-rmse:2.01257\n",
      "[11569]\teval-rmse:3.85684\ttrain-rmse:2.01268\n",
      "[11570]\teval-rmse:3.8563\ttrain-rmse:2.01273\n",
      "[11571]\teval-rmse:3.8559\ttrain-rmse:2.01247\n",
      "[11572]\teval-rmse:3.856\ttrain-rmse:2.01246\n",
      "[11573]\teval-rmse:3.85586\ttrain-rmse:2.01247\n",
      "[11574]\teval-rmse:3.85745\ttrain-rmse:2.01234\n",
      "[11575]\teval-rmse:3.8583\ttrain-rmse:2.01229\n",
      "[11576]\teval-rmse:3.8573\ttrain-rmse:2.01235\n",
      "[11577]\teval-rmse:3.85824\ttrain-rmse:2.0123\n",
      "[11578]\teval-rmse:3.85956\ttrain-rmse:2.01221\n",
      "[11579]\teval-rmse:3.86094\ttrain-rmse:2.01213\n",
      "[11580]\teval-rmse:3.85997\ttrain-rmse:2.01217\n",
      "[11581]\teval-rmse:3.85977\ttrain-rmse:2.01218\n",
      "[11582]\teval-rmse:3.85841\ttrain-rmse:2.01226\n",
      "[11583]\teval-rmse:3.85945\ttrain-rmse:2.0122\n",
      "[11584]\teval-rmse:3.86014\ttrain-rmse:2.01217\n",
      "[11585]\teval-rmse:3.8606\ttrain-rmse:2.01214\n",
      "[11586]\teval-rmse:3.86045\ttrain-rmse:2.01215\n",
      "[11587]\teval-rmse:3.86204\ttrain-rmse:2.01207\n",
      "[11588]\teval-rmse:3.86227\ttrain-rmse:2.01205\n",
      "[11589]\teval-rmse:3.86164\ttrain-rmse:2.01208\n",
      "[11590]\teval-rmse:3.8628\ttrain-rmse:2.01203\n",
      "[11591]\teval-rmse:3.86124\ttrain-rmse:2.01211\n",
      "[11592]\teval-rmse:3.86243\ttrain-rmse:2.01205\n",
      "[11593]\teval-rmse:3.86261\ttrain-rmse:2.01204\n",
      "[11594]\teval-rmse:3.86296\ttrain-rmse:2.01202\n",
      "[11595]\teval-rmse:3.86258\ttrain-rmse:2.01204\n",
      "[11596]\teval-rmse:3.86436\ttrain-rmse:2.01196\n",
      "[11597]\teval-rmse:3.86583\ttrain-rmse:2.01189\n",
      "[11598]\teval-rmse:3.86685\ttrain-rmse:2.01184\n",
      "[11599]\teval-rmse:3.86898\ttrain-rmse:2.01179\n",
      "[11600]\teval-rmse:3.86876\ttrain-rmse:2.01179\n",
      "[11601]\teval-rmse:3.8677\ttrain-rmse:2.01186\n",
      "[11602]\teval-rmse:3.86818\ttrain-rmse:2.01185\n",
      "[11603]\teval-rmse:3.86741\ttrain-rmse:2.01188\n",
      "[11604]\teval-rmse:3.86551\ttrain-rmse:2.01197\n",
      "[11605]\teval-rmse:3.86683\ttrain-rmse:2.01192\n",
      "[11606]\teval-rmse:3.86759\ttrain-rmse:2.01188\n",
      "[11607]\teval-rmse:3.86526\ttrain-rmse:2.01199\n",
      "[11608]\teval-rmse:3.86381\ttrain-rmse:2.01205\n",
      "[11609]\teval-rmse:3.86201\ttrain-rmse:2.01215\n",
      "[11610]\teval-rmse:3.86228\ttrain-rmse:2.01213\n",
      "[11611]\teval-rmse:3.86265\ttrain-rmse:2.01212\n",
      "[11612]\teval-rmse:3.86186\ttrain-rmse:2.01215\n",
      "[11613]\teval-rmse:3.86\ttrain-rmse:2.01227\n",
      "[11614]\teval-rmse:3.86142\ttrain-rmse:2.01219\n",
      "[11615]\teval-rmse:3.8603\ttrain-rmse:2.01228\n",
      "[11616]\teval-rmse:3.859\ttrain-rmse:2.01235\n",
      "[11617]\teval-rmse:3.85803\ttrain-rmse:2.0124\n",
      "[11618]\teval-rmse:3.85856\ttrain-rmse:2.01236\n",
      "[11619]\teval-rmse:3.85727\ttrain-rmse:2.01244\n",
      "[11620]\teval-rmse:3.85851\ttrain-rmse:2.01237\n",
      "[11621]\teval-rmse:3.85936\ttrain-rmse:2.01232\n",
      "[11622]\teval-rmse:3.85921\ttrain-rmse:2.01232\n",
      "[11623]\teval-rmse:3.85875\ttrain-rmse:2.01235\n",
      "[11624]\teval-rmse:3.85693\ttrain-rmse:2.01246\n",
      "[11625]\teval-rmse:3.85498\ttrain-rmse:2.01259\n",
      "[11626]\teval-rmse:3.85406\ttrain-rmse:2.01264\n",
      "[11627]\teval-rmse:3.85622\ttrain-rmse:2.01253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11628]\teval-rmse:3.85718\ttrain-rmse:2.01246\n",
      "[11629]\teval-rmse:3.8593\ttrain-rmse:2.01233\n",
      "[11630]\teval-rmse:3.86109\ttrain-rmse:2.01223\n",
      "[11631]\teval-rmse:3.86308\ttrain-rmse:2.01213\n",
      "[11632]\teval-rmse:3.86194\ttrain-rmse:2.01219\n",
      "[11633]\teval-rmse:3.86187\ttrain-rmse:2.01219\n",
      "[11634]\teval-rmse:3.86089\ttrain-rmse:2.01222\n",
      "[11635]\teval-rmse:3.8625\ttrain-rmse:2.01214\n",
      "[11636]\teval-rmse:3.86055\ttrain-rmse:2.01224\n",
      "[11637]\teval-rmse:3.85959\ttrain-rmse:2.01228\n",
      "[11638]\teval-rmse:3.86076\ttrain-rmse:2.01221\n",
      "[11639]\teval-rmse:3.86029\ttrain-rmse:2.01224\n",
      "[11640]\teval-rmse:3.85859\ttrain-rmse:2.01235\n",
      "[11641]\teval-rmse:3.85958\ttrain-rmse:2.01229\n",
      "[11642]\teval-rmse:3.85863\ttrain-rmse:2.01233\n",
      "[11643]\teval-rmse:3.85741\ttrain-rmse:2.0124\n",
      "[11644]\teval-rmse:3.85941\ttrain-rmse:2.01227\n",
      "[11645]\teval-rmse:3.85989\ttrain-rmse:2.01224\n",
      "[11646]\teval-rmse:3.86122\ttrain-rmse:2.01216\n",
      "[11647]\teval-rmse:3.86246\ttrain-rmse:2.01209\n",
      "[11648]\teval-rmse:3.86077\ttrain-rmse:2.01219\n",
      "[11649]\teval-rmse:3.8614\ttrain-rmse:2.01216\n",
      "[11650]\teval-rmse:3.86002\ttrain-rmse:2.01223\n",
      "[11651]\teval-rmse:3.85906\ttrain-rmse:2.01227\n",
      "[11652]\teval-rmse:3.86025\ttrain-rmse:2.01219\n",
      "[11653]\teval-rmse:3.86138\ttrain-rmse:2.01213\n",
      "[11654]\teval-rmse:3.86189\ttrain-rmse:2.0121\n",
      "[11655]\teval-rmse:3.86299\ttrain-rmse:2.01205\n",
      "[11656]\teval-rmse:3.8643\ttrain-rmse:2.01198\n",
      "[11657]\teval-rmse:3.86379\ttrain-rmse:2.012\n",
      "[11658]\teval-rmse:3.86568\ttrain-rmse:2.01192\n",
      "[11659]\teval-rmse:3.8665\ttrain-rmse:2.01189\n",
      "[11660]\teval-rmse:3.86693\ttrain-rmse:2.01188\n",
      "[11661]\teval-rmse:3.86754\ttrain-rmse:2.01185\n",
      "[11662]\teval-rmse:3.86791\ttrain-rmse:2.01184\n",
      "[11663]\teval-rmse:3.86664\ttrain-rmse:2.01188\n",
      "[11664]\teval-rmse:3.8667\ttrain-rmse:2.01188\n",
      "[11665]\teval-rmse:3.86539\ttrain-rmse:2.01192\n",
      "[11666]\teval-rmse:3.86588\ttrain-rmse:2.0119\n",
      "[11667]\teval-rmse:3.86795\ttrain-rmse:2.01174\n",
      "[11668]\teval-rmse:3.86803\ttrain-rmse:2.01174\n",
      "[11669]\teval-rmse:3.86865\ttrain-rmse:2.01172\n",
      "[11670]\teval-rmse:3.86677\ttrain-rmse:2.01178\n",
      "[11671]\teval-rmse:3.86664\ttrain-rmse:2.01179\n",
      "[11672]\teval-rmse:3.86587\ttrain-rmse:2.01181\n",
      "[11673]\teval-rmse:3.86697\ttrain-rmse:2.01177\n",
      "[11674]\teval-rmse:3.86635\ttrain-rmse:2.0118\n",
      "[11675]\teval-rmse:3.86737\ttrain-rmse:2.01176\n",
      "[11676]\teval-rmse:3.86529\ttrain-rmse:2.01184\n",
      "[11677]\teval-rmse:3.86723\ttrain-rmse:2.01176\n",
      "[11678]\teval-rmse:3.86666\ttrain-rmse:2.01178\n",
      "[11679]\teval-rmse:3.86579\ttrain-rmse:2.01181\n",
      "[11680]\teval-rmse:3.86492\ttrain-rmse:2.01184\n",
      "[11681]\teval-rmse:3.86484\ttrain-rmse:2.01185\n",
      "[11682]\teval-rmse:3.86547\ttrain-rmse:2.01182\n",
      "[11683]\teval-rmse:3.8654\ttrain-rmse:2.01182\n",
      "[11684]\teval-rmse:3.86572\ttrain-rmse:2.0118\n",
      "[11685]\teval-rmse:3.86648\ttrain-rmse:2.01178\n",
      "[11686]\teval-rmse:3.86479\ttrain-rmse:2.01184\n",
      "[11687]\teval-rmse:3.8643\ttrain-rmse:2.01185\n",
      "[11688]\teval-rmse:3.86617\ttrain-rmse:2.01178\n",
      "[11689]\teval-rmse:3.86519\ttrain-rmse:2.01181\n",
      "[11690]\teval-rmse:3.86659\ttrain-rmse:2.01175\n",
      "[11691]\teval-rmse:3.86554\ttrain-rmse:2.01179\n",
      "[11692]\teval-rmse:3.86635\ttrain-rmse:2.01176\n",
      "[11693]\teval-rmse:3.86786\ttrain-rmse:2.01171\n",
      "[11694]\teval-rmse:3.86714\ttrain-rmse:2.01173\n",
      "[11695]\teval-rmse:3.86843\ttrain-rmse:2.0117\n",
      "[11696]\teval-rmse:3.86938\ttrain-rmse:2.01167\n",
      "[11697]\teval-rmse:3.87068\ttrain-rmse:2.01164\n",
      "[11698]\teval-rmse:3.87265\ttrain-rmse:2.01158\n",
      "[11699]\teval-rmse:3.87432\ttrain-rmse:2.01155\n",
      "[11700]\teval-rmse:3.87377\ttrain-rmse:2.01133\n",
      "[11701]\teval-rmse:3.87303\ttrain-rmse:2.01133\n",
      "[11702]\teval-rmse:3.87386\ttrain-rmse:2.01132\n",
      "[11703]\teval-rmse:3.87406\ttrain-rmse:2.01132\n",
      "[11704]\teval-rmse:3.87232\ttrain-rmse:2.01134\n",
      "[11705]\teval-rmse:3.87173\ttrain-rmse:2.01136\n",
      "[11706]\teval-rmse:3.87381\ttrain-rmse:2.01133\n",
      "[11707]\teval-rmse:3.87596\ttrain-rmse:2.01129\n",
      "[11708]\teval-rmse:3.8746\ttrain-rmse:2.01131\n",
      "[11709]\teval-rmse:3.8748\ttrain-rmse:2.01131\n",
      "[11710]\teval-rmse:3.8761\ttrain-rmse:2.01128\n",
      "[11711]\teval-rmse:3.8771\ttrain-rmse:2.01127\n",
      "[11712]\teval-rmse:3.87771\ttrain-rmse:2.01127\n",
      "[11713]\teval-rmse:3.87959\ttrain-rmse:2.01127\n",
      "[11714]\teval-rmse:3.87859\ttrain-rmse:2.01128\n",
      "[11715]\teval-rmse:3.87752\ttrain-rmse:2.01129\n",
      "[11716]\teval-rmse:3.87915\ttrain-rmse:2.0112\n",
      "[11717]\teval-rmse:3.88059\ttrain-rmse:2.0112\n",
      "[11718]\teval-rmse:3.88075\ttrain-rmse:2.01121\n",
      "[11719]\teval-rmse:3.88205\ttrain-rmse:2.01123\n",
      "[11720]\teval-rmse:3.88132\ttrain-rmse:2.01123\n",
      "[11721]\teval-rmse:3.88117\ttrain-rmse:2.01123\n",
      "[11722]\teval-rmse:3.88009\ttrain-rmse:2.01124\n",
      "[11723]\teval-rmse:3.88014\ttrain-rmse:2.01124\n",
      "[11724]\teval-rmse:3.88173\ttrain-rmse:2.01126\n",
      "[11725]\teval-rmse:3.88348\ttrain-rmse:2.01128\n",
      "[11726]\teval-rmse:3.88169\ttrain-rmse:2.01124\n",
      "[11727]\teval-rmse:3.88289\ttrain-rmse:2.01125\n",
      "[11728]\teval-rmse:3.8813\ttrain-rmse:2.01131\n",
      "[11729]\teval-rmse:3.88212\ttrain-rmse:2.01132\n",
      "[11730]\teval-rmse:3.88142\ttrain-rmse:2.01132\n",
      "[11731]\teval-rmse:3.88084\ttrain-rmse:2.01132\n",
      "[11732]\teval-rmse:3.87945\ttrain-rmse:2.01132\n",
      "[11733]\teval-rmse:3.87893\ttrain-rmse:2.0111\n",
      "[11734]\teval-rmse:3.87965\ttrain-rmse:2.01111\n",
      "[11735]\teval-rmse:3.87815\ttrain-rmse:2.0111\n",
      "[11736]\teval-rmse:3.87607\ttrain-rmse:2.0111\n",
      "[11737]\teval-rmse:3.87642\ttrain-rmse:2.0111\n",
      "[11738]\teval-rmse:3.87433\ttrain-rmse:2.01111\n",
      "[11739]\teval-rmse:3.87378\ttrain-rmse:2.01089\n",
      "[11740]\teval-rmse:3.87591\ttrain-rmse:2.01086\n",
      "[11741]\teval-rmse:3.87668\ttrain-rmse:2.01086\n",
      "[11742]\teval-rmse:3.87644\ttrain-rmse:2.01086\n",
      "[11743]\teval-rmse:3.87523\ttrain-rmse:2.01091\n",
      "[11744]\teval-rmse:3.87617\ttrain-rmse:2.01092\n",
      "[11745]\teval-rmse:3.87419\ttrain-rmse:2.01093\n",
      "[11746]\teval-rmse:3.87445\ttrain-rmse:2.01093\n",
      "[11747]\teval-rmse:3.87389\ttrain-rmse:2.01071\n",
      "[11748]\teval-rmse:3.87236\ttrain-rmse:2.01075\n",
      "[11749]\teval-rmse:3.87278\ttrain-rmse:2.01074\n",
      "[11750]\teval-rmse:3.8723\ttrain-rmse:2.01075\n",
      "[11751]\teval-rmse:3.87177\ttrain-rmse:2.01076\n",
      "[11752]\teval-rmse:3.87265\ttrain-rmse:2.01075\n",
      "[11753]\teval-rmse:3.87253\ttrain-rmse:2.01075\n",
      "[11754]\teval-rmse:3.8746\ttrain-rmse:2.01073\n",
      "[11755]\teval-rmse:3.87341\ttrain-rmse:2.01079\n",
      "[11756]\teval-rmse:3.87338\ttrain-rmse:2.01079\n",
      "[11757]\teval-rmse:3.87515\ttrain-rmse:2.0108\n",
      "[11758]\teval-rmse:3.87559\ttrain-rmse:2.01079\n",
      "[11759]\teval-rmse:3.87347\ttrain-rmse:2.01079\n",
      "[11760]\teval-rmse:3.87194\ttrain-rmse:2.01082\n",
      "[11761]\teval-rmse:3.87134\ttrain-rmse:2.01083\n",
      "[11762]\teval-rmse:3.87\ttrain-rmse:2.01085\n",
      "[11763]\teval-rmse:3.86951\ttrain-rmse:2.01066\n",
      "[11764]\teval-rmse:3.86807\ttrain-rmse:2.01069\n",
      "[11765]\teval-rmse:3.86923\ttrain-rmse:2.01061\n",
      "[11766]\teval-rmse:3.86804\ttrain-rmse:2.01068\n",
      "[11767]\teval-rmse:3.86781\ttrain-rmse:2.01069\n",
      "[11768]\teval-rmse:3.86994\ttrain-rmse:2.01064\n",
      "[11769]\teval-rmse:3.87059\ttrain-rmse:2.01063\n",
      "[11770]\teval-rmse:3.86913\ttrain-rmse:2.01066\n",
      "[11771]\teval-rmse:3.86819\ttrain-rmse:2.01068\n",
      "[11772]\teval-rmse:3.86792\ttrain-rmse:2.01069\n",
      "[11773]\teval-rmse:3.86657\ttrain-rmse:2.0107\n",
      "[11774]\teval-rmse:3.86828\ttrain-rmse:2.01066\n",
      "[11775]\teval-rmse:3.86858\ttrain-rmse:2.01066\n",
      "[11776]\teval-rmse:3.86897\ttrain-rmse:2.01065\n",
      "[11777]\teval-rmse:3.86838\ttrain-rmse:2.01066\n",
      "[11778]\teval-rmse:3.87014\ttrain-rmse:2.0106\n",
      "[11779]\teval-rmse:3.86984\ttrain-rmse:2.01061\n",
      "[11780]\teval-rmse:3.87128\ttrain-rmse:2.01058\n",
      "[11781]\teval-rmse:3.87285\ttrain-rmse:2.01057\n",
      "[11782]\teval-rmse:3.87478\ttrain-rmse:2.01055\n",
      "[11783]\teval-rmse:3.87663\ttrain-rmse:2.01054\n",
      "[11784]\teval-rmse:3.87612\ttrain-rmse:2.01054\n",
      "[11785]\teval-rmse:3.87556\ttrain-rmse:2.01055\n",
      "[11786]\teval-rmse:3.8768\ttrain-rmse:2.01055\n",
      "[11787]\teval-rmse:3.87623\ttrain-rmse:2.01034\n",
      "[11788]\teval-rmse:3.87584\ttrain-rmse:2.01034\n",
      "[11789]\teval-rmse:3.8743\ttrain-rmse:2.01034\n",
      "[11790]\teval-rmse:3.87324\ttrain-rmse:2.01036\n",
      "[11791]\teval-rmse:3.87438\ttrain-rmse:2.01029\n",
      "[11792]\teval-rmse:3.87383\ttrain-rmse:2.0103\n",
      "[11793]\teval-rmse:3.87241\ttrain-rmse:2.01031\n",
      "[11794]\teval-rmse:3.87272\ttrain-rmse:2.01031\n",
      "[11795]\teval-rmse:3.87168\ttrain-rmse:2.01032\n",
      "[11796]\teval-rmse:3.87298\ttrain-rmse:2.01032\n",
      "[11797]\teval-rmse:3.87421\ttrain-rmse:2.01031\n",
      "[11798]\teval-rmse:3.87445\ttrain-rmse:2.01031\n",
      "[11799]\teval-rmse:3.87619\ttrain-rmse:2.01029\n",
      "[11800]\teval-rmse:3.87563\ttrain-rmse:2.01029\n",
      "[11801]\teval-rmse:3.87487\ttrain-rmse:2.01028\n",
      "[11802]\teval-rmse:3.87392\ttrain-rmse:2.01028\n",
      "[11803]\teval-rmse:3.87201\ttrain-rmse:2.01029\n",
      "[11804]\teval-rmse:3.86975\ttrain-rmse:2.01031\n",
      "[11805]\teval-rmse:3.87072\ttrain-rmse:2.0103\n",
      "[11806]\teval-rmse:3.87268\ttrain-rmse:2.01028\n",
      "[11807]\teval-rmse:3.87106\ttrain-rmse:2.01027\n",
      "[11808]\teval-rmse:3.87262\ttrain-rmse:2.01026\n",
      "[11809]\teval-rmse:3.87339\ttrain-rmse:2.01025\n",
      "[11810]\teval-rmse:3.87341\ttrain-rmse:2.01025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11811]\teval-rmse:3.87167\ttrain-rmse:2.01027\n",
      "[11812]\teval-rmse:3.87141\ttrain-rmse:2.01027\n",
      "[11813]\teval-rmse:3.86979\ttrain-rmse:2.01029\n",
      "[11814]\teval-rmse:3.86884\ttrain-rmse:2.01031\n",
      "[11815]\teval-rmse:3.87091\ttrain-rmse:2.01028\n",
      "[11816]\teval-rmse:3.87174\ttrain-rmse:2.01028\n",
      "[11817]\teval-rmse:3.87279\ttrain-rmse:2.01027\n",
      "[11818]\teval-rmse:3.87405\ttrain-rmse:2.01026\n",
      "[11819]\teval-rmse:3.87615\ttrain-rmse:2.01024\n",
      "[11820]\teval-rmse:3.87696\ttrain-rmse:2.01025\n",
      "[11821]\teval-rmse:3.87698\ttrain-rmse:2.01025\n",
      "[11822]\teval-rmse:3.8767\ttrain-rmse:2.01025\n",
      "[11823]\teval-rmse:3.87826\ttrain-rmse:2.01025\n",
      "[11824]\teval-rmse:3.87989\ttrain-rmse:2.01018\n",
      "[11825]\teval-rmse:3.88142\ttrain-rmse:2.0102\n",
      "[11826]\teval-rmse:3.88305\ttrain-rmse:2.0102\n",
      "[11827]\teval-rmse:3.88396\ttrain-rmse:2.01022\n",
      "[11828]\teval-rmse:3.88264\ttrain-rmse:2.0102\n",
      "[11829]\teval-rmse:3.88292\ttrain-rmse:2.01021\n",
      "[11830]\teval-rmse:3.88347\ttrain-rmse:2.01022\n",
      "[11831]\teval-rmse:3.88558\ttrain-rmse:2.01022\n",
      "[11832]\teval-rmse:3.88524\ttrain-rmse:2.01021\n",
      "[11833]\teval-rmse:3.88679\ttrain-rmse:2.01025\n",
      "[11834]\teval-rmse:3.88617\ttrain-rmse:2.01024\n",
      "[11835]\teval-rmse:3.88489\ttrain-rmse:2.01027\n",
      "[11836]\teval-rmse:3.88389\ttrain-rmse:2.01024\n",
      "[11837]\teval-rmse:3.88331\ttrain-rmse:2.01024\n",
      "[11838]\teval-rmse:3.88421\ttrain-rmse:2.01025\n",
      "[11839]\teval-rmse:3.88237\ttrain-rmse:2.01021\n",
      "[11840]\teval-rmse:3.88058\ttrain-rmse:2.01019\n",
      "[11841]\teval-rmse:3.87943\ttrain-rmse:2.01023\n",
      "[11842]\teval-rmse:3.88064\ttrain-rmse:2.01024\n",
      "[11843]\teval-rmse:3.88274\ttrain-rmse:2.01024\n",
      "[11844]\teval-rmse:3.88186\ttrain-rmse:2.01024\n",
      "[11845]\teval-rmse:3.88131\ttrain-rmse:2.01003\n",
      "[11846]\teval-rmse:3.88026\ttrain-rmse:2.01002\n",
      "[11847]\teval-rmse:3.87968\ttrain-rmse:2.01002\n",
      "[11848]\teval-rmse:3.88161\ttrain-rmse:2.01006\n",
      "[11849]\teval-rmse:3.88345\ttrain-rmse:2.01006\n",
      "[11850]\teval-rmse:3.88388\ttrain-rmse:2.01007\n",
      "[11851]\teval-rmse:3.88499\ttrain-rmse:2.01008\n",
      "[11852]\teval-rmse:3.88291\ttrain-rmse:2.01001\n",
      "[11853]\teval-rmse:3.88111\ttrain-rmse:2.00999\n",
      "[11854]\teval-rmse:3.88305\ttrain-rmse:2.01002\n",
      "[11855]\teval-rmse:3.88374\ttrain-rmse:2.01003\n",
      "[11856]\teval-rmse:3.88527\ttrain-rmse:2.01006\n",
      "[11857]\teval-rmse:3.88731\ttrain-rmse:2.01\n",
      "[11858]\teval-rmse:3.88619\ttrain-rmse:2.00999\n",
      "[11859]\teval-rmse:3.88389\ttrain-rmse:2.00995\n",
      "[11860]\teval-rmse:3.88408\ttrain-rmse:2.00995\n",
      "[11861]\teval-rmse:3.88349\ttrain-rmse:2.00995\n",
      "[11862]\teval-rmse:3.88312\ttrain-rmse:2.00994\n",
      "[11863]\teval-rmse:3.88101\ttrain-rmse:2.00991\n",
      "[11864]\teval-rmse:3.88123\ttrain-rmse:2.00991\n",
      "[11865]\teval-rmse:3.88066\ttrain-rmse:2.00991\n",
      "[11866]\teval-rmse:3.88278\ttrain-rmse:2.0099\n",
      "[11867]\teval-rmse:3.88488\ttrain-rmse:2.00991\n",
      "[11868]\teval-rmse:3.88698\ttrain-rmse:2.00992\n",
      "[11869]\teval-rmse:3.88909\ttrain-rmse:2.00994\n",
      "[11870]\teval-rmse:3.88685\ttrain-rmse:2.0099\n",
      "[11871]\teval-rmse:3.88474\ttrain-rmse:2.00988\n",
      "[11872]\teval-rmse:3.88489\ttrain-rmse:2.00989\n",
      "[11873]\teval-rmse:3.88373\ttrain-rmse:2.00988\n",
      "[11874]\teval-rmse:3.88351\ttrain-rmse:2.00987\n",
      "[11875]\teval-rmse:3.88167\ttrain-rmse:2.00986\n",
      "[11876]\teval-rmse:3.87979\ttrain-rmse:2.00984\n",
      "[11877]\teval-rmse:3.87801\ttrain-rmse:2.00986\n",
      "[11878]\teval-rmse:3.87865\ttrain-rmse:2.00985\n",
      "[11879]\teval-rmse:3.8803\ttrain-rmse:2.00984\n",
      "[11880]\teval-rmse:3.88219\ttrain-rmse:2.00984\n",
      "[11881]\teval-rmse:3.88275\ttrain-rmse:2.00985\n",
      "[11882]\teval-rmse:3.8823\ttrain-rmse:2.00984\n",
      "[11883]\teval-rmse:3.88105\ttrain-rmse:2.00989\n",
      "[11884]\teval-rmse:3.87918\ttrain-rmse:2.00986\n",
      "[11885]\teval-rmse:3.87956\ttrain-rmse:2.00986\n",
      "[11886]\teval-rmse:3.87896\ttrain-rmse:2.00987\n",
      "[11887]\teval-rmse:3.88107\ttrain-rmse:2.00986\n",
      "[11888]\teval-rmse:3.8795\ttrain-rmse:2.00992\n",
      "[11889]\teval-rmse:3.87867\ttrain-rmse:2.00993\n",
      "[11890]\teval-rmse:3.87841\ttrain-rmse:2.00993\n",
      "[11891]\teval-rmse:3.87821\ttrain-rmse:2.00993\n",
      "[11892]\teval-rmse:3.87834\ttrain-rmse:2.00993\n",
      "[11893]\teval-rmse:3.87624\ttrain-rmse:2.00994\n",
      "[11894]\teval-rmse:3.87622\ttrain-rmse:2.00994\n",
      "[11895]\teval-rmse:3.87563\ttrain-rmse:2.00995\n",
      "[11896]\teval-rmse:3.87775\ttrain-rmse:2.00993\n",
      "[11897]\teval-rmse:3.87988\ttrain-rmse:2.00992\n",
      "[11898]\teval-rmse:3.88015\ttrain-rmse:2.00992\n",
      "[11899]\teval-rmse:3.8818\ttrain-rmse:2.00991\n",
      "[11900]\teval-rmse:3.88302\ttrain-rmse:2.0099\n",
      "[11901]\teval-rmse:3.88268\ttrain-rmse:2.0099\n",
      "[11902]\teval-rmse:3.88438\ttrain-rmse:2.00991\n",
      "[11903]\teval-rmse:3.88619\ttrain-rmse:2.00992\n",
      "[11904]\teval-rmse:3.88831\ttrain-rmse:2.00994\n",
      "[11905]\teval-rmse:3.88797\ttrain-rmse:2.00994\n",
      "[11906]\teval-rmse:3.89008\ttrain-rmse:2.00996\n",
      "[11907]\teval-rmse:3.88919\ttrain-rmse:2.00995\n",
      "[11908]\teval-rmse:3.88809\ttrain-rmse:2.00994\n",
      "[11909]\teval-rmse:3.88997\ttrain-rmse:2.00997\n",
      "[11910]\teval-rmse:3.88968\ttrain-rmse:2.00997\n",
      "[11911]\teval-rmse:3.8881\ttrain-rmse:2.00992\n",
      "[11912]\teval-rmse:3.88874\ttrain-rmse:2.00993\n",
      "[11913]\teval-rmse:3.88736\ttrain-rmse:2.00991\n",
      "[11914]\teval-rmse:3.88929\ttrain-rmse:2.00994\n",
      "[11915]\teval-rmse:3.89085\ttrain-rmse:2.00997\n",
      "[11916]\teval-rmse:3.89196\ttrain-rmse:2.00994\n",
      "[11917]\teval-rmse:3.89175\ttrain-rmse:2.00994\n",
      "[11918]\teval-rmse:3.8938\ttrain-rmse:2.00989\n",
      "[11919]\teval-rmse:3.89491\ttrain-rmse:2.00987\n",
      "[11920]\teval-rmse:3.89633\ttrain-rmse:2.00991\n",
      "[11921]\teval-rmse:3.89721\ttrain-rmse:2.00993\n",
      "[11922]\teval-rmse:3.89926\ttrain-rmse:2.00998\n",
      "[11923]\teval-rmse:3.90042\ttrain-rmse:2.01002\n",
      "[11924]\teval-rmse:3.90151\ttrain-rmse:2.01001\n",
      "[11925]\teval-rmse:3.90125\ttrain-rmse:2.01\n",
      "[11926]\teval-rmse:3.90286\ttrain-rmse:2.01\n",
      "[11927]\teval-rmse:3.90346\ttrain-rmse:2.01002\n",
      "[11928]\teval-rmse:3.90124\ttrain-rmse:2.00993\n",
      "[11929]\teval-rmse:3.90101\ttrain-rmse:2.00992\n",
      "[11930]\teval-rmse:3.90182\ttrain-rmse:2.00996\n",
      "[11931]\teval-rmse:3.90142\ttrain-rmse:2.00994\n",
      "[11932]\teval-rmse:3.89949\ttrain-rmse:2.00986\n",
      "[11933]\teval-rmse:3.89873\ttrain-rmse:2.00983\n",
      "[11934]\teval-rmse:3.89666\ttrain-rmse:2.00978\n",
      "[11935]\teval-rmse:3.89605\ttrain-rmse:2.00953\n",
      "[11936]\teval-rmse:3.89717\ttrain-rmse:2.00956\n",
      "[11937]\teval-rmse:3.89829\ttrain-rmse:2.0096\n",
      "[11938]\teval-rmse:3.89622\ttrain-rmse:2.00954\n",
      "[11939]\teval-rmse:3.89582\ttrain-rmse:2.00953\n",
      "[11940]\teval-rmse:3.89516\ttrain-rmse:2.00951\n",
      "[11941]\teval-rmse:3.89726\ttrain-rmse:2.00956\n",
      "[11942]\teval-rmse:3.89608\ttrain-rmse:2.00953\n",
      "[11943]\teval-rmse:3.89391\ttrain-rmse:2.00945\n",
      "[11944]\teval-rmse:3.89598\ttrain-rmse:2.00951\n",
      "[11945]\teval-rmse:3.89609\ttrain-rmse:2.00951\n",
      "[11946]\teval-rmse:3.89612\ttrain-rmse:2.00951\n",
      "[11947]\teval-rmse:3.89532\ttrain-rmse:2.00949\n",
      "[11948]\teval-rmse:3.89664\ttrain-rmse:2.00954\n",
      "[11949]\teval-rmse:3.89718\ttrain-rmse:2.00956\n",
      "[11950]\teval-rmse:3.89924\ttrain-rmse:2.00963\n",
      "[11951]\teval-rmse:3.8973\ttrain-rmse:2.00957\n",
      "[11952]\teval-rmse:3.89867\ttrain-rmse:2.00961\n",
      "[11953]\teval-rmse:3.89748\ttrain-rmse:2.00958\n",
      "[11954]\teval-rmse:3.89656\ttrain-rmse:2.00955\n",
      "[11955]\teval-rmse:3.8944\ttrain-rmse:2.0095\n",
      "[11956]\teval-rmse:3.89567\ttrain-rmse:2.00952\n",
      "[11957]\teval-rmse:3.89381\ttrain-rmse:2.00947\n",
      "[11958]\teval-rmse:3.89316\ttrain-rmse:2.00946\n",
      "[11959]\teval-rmse:3.89333\ttrain-rmse:2.00946\n",
      "[11960]\teval-rmse:3.89374\ttrain-rmse:2.00947\n",
      "[11961]\teval-rmse:3.89174\ttrain-rmse:2.00942\n",
      "[11962]\teval-rmse:3.89366\ttrain-rmse:2.00947\n",
      "[11963]\teval-rmse:3.89265\ttrain-rmse:2.00944\n",
      "[11964]\teval-rmse:3.89197\ttrain-rmse:2.00943\n",
      "[11965]\teval-rmse:3.89211\ttrain-rmse:2.00943\n",
      "[11966]\teval-rmse:3.89364\ttrain-rmse:2.00945\n",
      "[11967]\teval-rmse:3.89164\ttrain-rmse:2.00941\n",
      "[11968]\teval-rmse:3.89309\ttrain-rmse:2.00943\n",
      "[11969]\teval-rmse:3.89402\ttrain-rmse:2.00945\n",
      "[11970]\teval-rmse:3.89238\ttrain-rmse:2.00941\n",
      "[11971]\teval-rmse:3.89304\ttrain-rmse:2.00942\n",
      "[11972]\teval-rmse:3.89455\ttrain-rmse:2.00945\n",
      "[11973]\teval-rmse:3.89391\ttrain-rmse:2.00924\n",
      "[11974]\teval-rmse:3.89418\ttrain-rmse:2.00925\n",
      "[11975]\teval-rmse:3.89229\ttrain-rmse:2.00922\n",
      "[11976]\teval-rmse:3.89314\ttrain-rmse:2.00923\n",
      "[11977]\teval-rmse:3.89284\ttrain-rmse:2.00922\n",
      "[11978]\teval-rmse:3.89263\ttrain-rmse:2.00922\n",
      "[11979]\teval-rmse:3.89293\ttrain-rmse:2.00923\n",
      "[11980]\teval-rmse:3.89112\ttrain-rmse:2.00919\n",
      "[11981]\teval-rmse:3.89233\ttrain-rmse:2.00923\n",
      "[11982]\teval-rmse:3.89438\ttrain-rmse:2.00919\n",
      "[11983]\teval-rmse:3.89622\ttrain-rmse:2.00925\n",
      "[11984]\teval-rmse:3.89745\ttrain-rmse:2.00928\n",
      "[11985]\teval-rmse:3.89776\ttrain-rmse:2.00929\n",
      "[11986]\teval-rmse:3.89838\ttrain-rmse:2.00932\n",
      "[11987]\teval-rmse:3.89995\ttrain-rmse:2.00938\n",
      "[11988]\teval-rmse:3.89988\ttrain-rmse:2.00937\n",
      "[11989]\teval-rmse:3.89946\ttrain-rmse:2.00936\n",
      "[11990]\teval-rmse:3.90156\ttrain-rmse:2.00942\n",
      "[11991]\teval-rmse:3.89962\ttrain-rmse:2.00934\n",
      "[11992]\teval-rmse:3.89837\ttrain-rmse:2.00934\n",
      "[11993]\teval-rmse:3.89893\ttrain-rmse:2.00936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11994]\teval-rmse:3.90054\ttrain-rmse:2.00942\n",
      "[11995]\teval-rmse:3.89848\ttrain-rmse:2.00934\n",
      "[11996]\teval-rmse:3.89904\ttrain-rmse:2.00936\n",
      "[11997]\teval-rmse:3.89756\ttrain-rmse:2.00931\n",
      "[11998]\teval-rmse:3.89859\ttrain-rmse:2.00935\n",
      "[11999]\teval-rmse:3.90038\ttrain-rmse:2.00942\n",
      "[12000]\teval-rmse:3.89795\ttrain-rmse:2.00932\n",
      "[12001]\teval-rmse:3.89772\ttrain-rmse:2.00932\n",
      "[12002]\teval-rmse:3.89627\ttrain-rmse:2.00927\n",
      "[12003]\teval-rmse:3.89494\ttrain-rmse:2.00928\n",
      "[12004]\teval-rmse:3.89429\ttrain-rmse:2.00905\n",
      "[12005]\teval-rmse:3.89465\ttrain-rmse:2.00906\n",
      "[12006]\teval-rmse:3.89407\ttrain-rmse:2.00904\n",
      "[12007]\teval-rmse:3.89356\ttrain-rmse:2.00903\n",
      "[12008]\teval-rmse:3.89451\ttrain-rmse:2.00905\n",
      "[12009]\teval-rmse:3.8943\ttrain-rmse:2.00905\n",
      "[12010]\teval-rmse:3.89264\ttrain-rmse:2.00907\n",
      "[12011]\teval-rmse:3.89411\ttrain-rmse:2.00911\n",
      "[12012]\teval-rmse:3.89474\ttrain-rmse:2.00913\n",
      "[12013]\teval-rmse:3.89442\ttrain-rmse:2.00912\n",
      "[12014]\teval-rmse:3.89285\ttrain-rmse:2.00908\n",
      "[12015]\teval-rmse:3.89105\ttrain-rmse:2.00902\n",
      "[12016]\teval-rmse:3.89123\ttrain-rmse:2.00902\n",
      "[12017]\teval-rmse:3.89173\ttrain-rmse:2.00903\n",
      "[12018]\teval-rmse:3.89271\ttrain-rmse:2.00906\n",
      "[12019]\teval-rmse:3.89223\ttrain-rmse:2.00904\n",
      "[12020]\teval-rmse:3.89345\ttrain-rmse:2.00907\n",
      "[12021]\teval-rmse:3.89201\ttrain-rmse:2.00902\n",
      "[12022]\teval-rmse:3.89338\ttrain-rmse:2.00904\n",
      "[12023]\teval-rmse:3.89305\ttrain-rmse:2.00904\n",
      "[12024]\teval-rmse:3.89071\ttrain-rmse:2.00899\n",
      "[12025]\teval-rmse:3.89276\ttrain-rmse:2.00902\n",
      "[12026]\teval-rmse:3.8947\ttrain-rmse:2.00899\n",
      "[12027]\teval-rmse:3.89347\ttrain-rmse:2.00897\n",
      "[12028]\teval-rmse:3.89168\ttrain-rmse:2.00893\n",
      "[12029]\teval-rmse:3.88996\ttrain-rmse:2.00892\n",
      "[12030]\teval-rmse:3.89035\ttrain-rmse:2.00892\n",
      "[12031]\teval-rmse:3.88972\ttrain-rmse:2.00868\n",
      "[12032]\teval-rmse:3.89134\ttrain-rmse:2.0087\n",
      "[12033]\teval-rmse:3.89261\ttrain-rmse:2.00873\n",
      "[12034]\teval-rmse:3.89387\ttrain-rmse:2.00875\n",
      "[12035]\teval-rmse:3.89269\ttrain-rmse:2.00873\n",
      "[12036]\teval-rmse:3.89248\ttrain-rmse:2.00873\n",
      "[12037]\teval-rmse:3.89059\ttrain-rmse:2.0087\n",
      "[12038]\teval-rmse:3.89268\ttrain-rmse:2.00873\n",
      "[12039]\teval-rmse:3.89152\ttrain-rmse:2.00872\n",
      "[12040]\teval-rmse:3.89074\ttrain-rmse:2.00871\n",
      "[12041]\teval-rmse:3.89236\ttrain-rmse:2.00873\n",
      "[12042]\teval-rmse:3.89445\ttrain-rmse:2.00877\n",
      "[12043]\teval-rmse:3.89292\ttrain-rmse:2.00875\n",
      "[12044]\teval-rmse:3.89227\ttrain-rmse:2.00851\n",
      "[12045]\teval-rmse:3.89312\ttrain-rmse:2.00853\n",
      "[12046]\teval-rmse:3.89126\ttrain-rmse:2.00851\n",
      "[12047]\teval-rmse:3.88986\ttrain-rmse:2.00848\n",
      "[12048]\teval-rmse:3.88887\ttrain-rmse:2.00848\n",
      "[12049]\teval-rmse:3.89025\ttrain-rmse:2.00848\n",
      "[12050]\teval-rmse:3.888\ttrain-rmse:2.00849\n",
      "[12051]\teval-rmse:3.88885\ttrain-rmse:2.00849\n",
      "[12052]\teval-rmse:3.88814\ttrain-rmse:2.00849\n",
      "[12053]\teval-rmse:3.89008\ttrain-rmse:2.00852\n",
      "[12054]\teval-rmse:3.88946\ttrain-rmse:2.00826\n",
      "[12055]\teval-rmse:3.88926\ttrain-rmse:2.00826\n",
      "[12056]\teval-rmse:3.88949\ttrain-rmse:2.00826\n",
      "[12057]\teval-rmse:3.89083\ttrain-rmse:2.00827\n",
      "[12058]\teval-rmse:3.88942\ttrain-rmse:2.00824\n",
      "[12059]\teval-rmse:3.88813\ttrain-rmse:2.00824\n",
      "[12060]\teval-rmse:3.88783\ttrain-rmse:2.00823\n",
      "[12061]\teval-rmse:3.88651\ttrain-rmse:2.00821\n",
      "[12062]\teval-rmse:3.88687\ttrain-rmse:2.00821\n",
      "[12063]\teval-rmse:3.88464\ttrain-rmse:2.00823\n",
      "[12064]\teval-rmse:3.88398\ttrain-rmse:2.00822\n",
      "[12065]\teval-rmse:3.88326\ttrain-rmse:2.00822\n",
      "[12066]\teval-rmse:3.88501\ttrain-rmse:2.00822\n",
      "[12067]\teval-rmse:3.88441\ttrain-rmse:2.00795\n",
      "[12068]\teval-rmse:3.8838\ttrain-rmse:2.00794\n",
      "[12069]\teval-rmse:3.88233\ttrain-rmse:2.00794\n",
      "[12070]\teval-rmse:3.8841\ttrain-rmse:2.00795\n",
      "[12071]\teval-rmse:3.88335\ttrain-rmse:2.00795\n",
      "[12072]\teval-rmse:3.8817\ttrain-rmse:2.00798\n",
      "[12073]\teval-rmse:3.88074\ttrain-rmse:2.008\n",
      "[12074]\teval-rmse:3.88015\ttrain-rmse:2.00774\n",
      "[12075]\teval-rmse:3.8821\ttrain-rmse:2.00771\n",
      "[12076]\teval-rmse:3.88218\ttrain-rmse:2.00771\n",
      "[12077]\teval-rmse:3.88106\ttrain-rmse:2.0077\n",
      "[12078]\teval-rmse:3.87889\ttrain-rmse:2.00774\n",
      "[12079]\teval-rmse:3.87863\ttrain-rmse:2.00774\n",
      "[12080]\teval-rmse:3.87678\ttrain-rmse:2.00779\n",
      "[12081]\teval-rmse:3.8789\ttrain-rmse:2.00778\n",
      "[12082]\teval-rmse:3.87934\ttrain-rmse:2.00777\n",
      "[12083]\teval-rmse:3.8773\ttrain-rmse:2.00778\n",
      "[12084]\teval-rmse:3.87866\ttrain-rmse:2.00775\n",
      "[12085]\teval-rmse:3.8774\ttrain-rmse:2.00776\n",
      "[12086]\teval-rmse:3.87655\ttrain-rmse:2.00777\n",
      "[12087]\teval-rmse:3.87552\ttrain-rmse:2.0078\n",
      "[12088]\teval-rmse:3.87523\ttrain-rmse:2.0078\n",
      "[12089]\teval-rmse:3.87372\ttrain-rmse:2.00783\n",
      "[12090]\teval-rmse:3.87568\ttrain-rmse:2.00779\n",
      "[12091]\teval-rmse:3.87631\ttrain-rmse:2.00778\n",
      "[12092]\teval-rmse:3.87611\ttrain-rmse:2.00778\n",
      "[12093]\teval-rmse:3.87764\ttrain-rmse:2.00774\n",
      "[12094]\teval-rmse:3.87749\ttrain-rmse:2.00773\n",
      "[12095]\teval-rmse:3.87687\ttrain-rmse:2.00774\n",
      "[12096]\teval-rmse:3.8763\ttrain-rmse:2.00752\n",
      "[12097]\teval-rmse:3.8776\ttrain-rmse:2.0075\n",
      "[12098]\teval-rmse:3.87968\ttrain-rmse:2.00741\n",
      "[12099]\teval-rmse:3.8791\ttrain-rmse:2.00715\n",
      "[12100]\teval-rmse:3.87983\ttrain-rmse:2.00713\n",
      "[12101]\teval-rmse:3.87798\ttrain-rmse:2.00717\n",
      "[12102]\teval-rmse:3.87774\ttrain-rmse:2.00717\n",
      "[12103]\teval-rmse:3.87819\ttrain-rmse:2.00716\n",
      "[12104]\teval-rmse:3.8767\ttrain-rmse:2.00718\n",
      "[12105]\teval-rmse:3.87782\ttrain-rmse:2.00717\n",
      "[12106]\teval-rmse:3.8764\ttrain-rmse:2.00719\n",
      "[12107]\teval-rmse:3.87705\ttrain-rmse:2.00718\n",
      "[12108]\teval-rmse:3.87852\ttrain-rmse:2.00717\n",
      "[12109]\teval-rmse:3.87914\ttrain-rmse:2.00716\n",
      "[12110]\teval-rmse:3.87886\ttrain-rmse:2.00716\n",
      "[12111]\teval-rmse:3.87828\ttrain-rmse:2.00695\n",
      "[12112]\teval-rmse:3.87808\ttrain-rmse:2.00695\n",
      "[12113]\teval-rmse:3.87809\ttrain-rmse:2.00695\n",
      "[12114]\teval-rmse:3.87629\ttrain-rmse:2.007\n",
      "[12115]\teval-rmse:3.87439\ttrain-rmse:2.00702\n",
      "[12116]\teval-rmse:3.8754\ttrain-rmse:2.007\n",
      "[12117]\teval-rmse:3.87634\ttrain-rmse:2.00699\n",
      "[12118]\teval-rmse:3.87608\ttrain-rmse:2.00699\n",
      "[12119]\teval-rmse:3.8765\ttrain-rmse:2.00698\n",
      "[12120]\teval-rmse:3.87825\ttrain-rmse:2.00696\n",
      "[12121]\teval-rmse:3.88018\ttrain-rmse:2.00692\n",
      "[12122]\teval-rmse:3.88108\ttrain-rmse:2.00691\n",
      "[12123]\teval-rmse:3.88164\ttrain-rmse:2.0069\n",
      "[12124]\teval-rmse:3.8832\ttrain-rmse:2.00691\n",
      "[12125]\teval-rmse:3.88403\ttrain-rmse:2.00692\n",
      "[12126]\teval-rmse:3.88344\ttrain-rmse:2.00691\n",
      "[12127]\teval-rmse:3.88517\ttrain-rmse:2.00691\n",
      "[12128]\teval-rmse:3.88357\ttrain-rmse:2.00695\n",
      "[12129]\teval-rmse:3.88161\ttrain-rmse:2.00696\n",
      "[12130]\teval-rmse:3.88161\ttrain-rmse:2.00696\n",
      "[12131]\teval-rmse:3.87978\ttrain-rmse:2.00695\n",
      "[12132]\teval-rmse:3.88116\ttrain-rmse:2.00695\n",
      "[12133]\teval-rmse:3.8798\ttrain-rmse:2.00695\n",
      "[12134]\teval-rmse:3.87874\ttrain-rmse:2.00697\n",
      "[12135]\teval-rmse:3.87897\ttrain-rmse:2.00696\n",
      "[12136]\teval-rmse:3.87871\ttrain-rmse:2.00696\n",
      "[12137]\teval-rmse:3.88034\ttrain-rmse:2.0069\n",
      "[12138]\teval-rmse:3.88053\ttrain-rmse:2.0069\n",
      "[12139]\teval-rmse:3.87868\ttrain-rmse:2.0069\n",
      "[12140]\teval-rmse:3.87812\ttrain-rmse:2.0069\n",
      "[12141]\teval-rmse:3.87745\ttrain-rmse:2.00691\n",
      "[12142]\teval-rmse:3.87561\ttrain-rmse:2.00696\n",
      "[12143]\teval-rmse:3.8776\ttrain-rmse:2.00691\n",
      "[12144]\teval-rmse:3.87833\ttrain-rmse:2.00691\n",
      "[12145]\teval-rmse:3.87915\ttrain-rmse:2.00691\n",
      "[12146]\teval-rmse:3.87948\ttrain-rmse:2.0069\n",
      "[12147]\teval-rmse:3.87968\ttrain-rmse:2.0069\n",
      "[12148]\teval-rmse:3.87884\ttrain-rmse:2.0069\n",
      "[12149]\teval-rmse:3.87693\ttrain-rmse:2.00691\n",
      "[12150]\teval-rmse:3.87672\ttrain-rmse:2.00692\n",
      "[12151]\teval-rmse:3.87848\ttrain-rmse:2.00691\n",
      "[12152]\teval-rmse:3.88014\ttrain-rmse:2.00688\n",
      "[12153]\teval-rmse:3.87956\ttrain-rmse:2.00668\n",
      "[12154]\teval-rmse:3.88083\ttrain-rmse:2.00668\n",
      "[12155]\teval-rmse:3.88178\ttrain-rmse:2.00667\n",
      "[12156]\teval-rmse:3.87973\ttrain-rmse:2.00666\n",
      "[12157]\teval-rmse:3.88084\ttrain-rmse:2.00667\n",
      "[12158]\teval-rmse:3.88277\ttrain-rmse:2.00661\n",
      "[12159]\teval-rmse:3.88331\ttrain-rmse:2.00661\n",
      "[12160]\teval-rmse:3.88216\ttrain-rmse:2.00662\n",
      "[12161]\teval-rmse:3.88088\ttrain-rmse:2.00666\n",
      "[12162]\teval-rmse:3.8828\ttrain-rmse:2.0066\n",
      "[12163]\teval-rmse:3.88307\ttrain-rmse:2.00659\n",
      "[12164]\teval-rmse:3.88434\ttrain-rmse:2.0066\n",
      "[12165]\teval-rmse:3.88436\ttrain-rmse:2.0066\n",
      "[12166]\teval-rmse:3.88377\ttrain-rmse:2.00659\n",
      "[12167]\teval-rmse:3.8854\ttrain-rmse:2.00661\n",
      "[12168]\teval-rmse:3.88679\ttrain-rmse:2.00661\n",
      "[12169]\teval-rmse:3.88872\ttrain-rmse:2.00657\n",
      "[12170]\teval-rmse:3.88949\ttrain-rmse:2.00658\n",
      "[12171]\teval-rmse:3.88834\ttrain-rmse:2.00656\n",
      "[12172]\teval-rmse:3.88996\ttrain-rmse:2.0066\n",
      "[12173]\teval-rmse:3.89041\ttrain-rmse:2.00661\n",
      "[12174]\teval-rmse:3.89149\ttrain-rmse:2.0066\n",
      "[12175]\teval-rmse:3.88985\ttrain-rmse:2.00657\n",
      "[12176]\teval-rmse:3.88923\ttrain-rmse:2.00634\n",
      "[12177]\teval-rmse:3.89056\ttrain-rmse:2.00637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12178]\teval-rmse:3.88924\ttrain-rmse:2.00635\n",
      "[12179]\teval-rmse:3.89108\ttrain-rmse:2.0064\n",
      "[12180]\teval-rmse:3.89299\ttrain-rmse:2.00646\n",
      "[12181]\teval-rmse:3.89166\ttrain-rmse:2.00641\n",
      "[12182]\teval-rmse:3.89218\ttrain-rmse:2.00643\n",
      "[12183]\teval-rmse:3.89119\ttrain-rmse:2.00641\n",
      "[12184]\teval-rmse:3.88955\ttrain-rmse:2.00642\n",
      "[12185]\teval-rmse:3.88861\ttrain-rmse:2.00641\n",
      "[12186]\teval-rmse:3.8888\ttrain-rmse:2.00641\n",
      "[12187]\teval-rmse:3.88818\ttrain-rmse:2.0064\n",
      "[12188]\teval-rmse:3.88704\ttrain-rmse:2.00638\n",
      "[12189]\teval-rmse:3.88513\ttrain-rmse:2.00637\n",
      "[12190]\teval-rmse:3.88723\ttrain-rmse:2.0064\n",
      "[12191]\teval-rmse:3.885\ttrain-rmse:2.00637\n",
      "[12192]\teval-rmse:3.88542\ttrain-rmse:2.00637\n",
      "[12193]\teval-rmse:3.88366\ttrain-rmse:2.00637\n",
      "[12194]\teval-rmse:3.88405\ttrain-rmse:2.00637\n",
      "[12195]\teval-rmse:3.88532\ttrain-rmse:2.00638\n",
      "[12196]\teval-rmse:3.88573\ttrain-rmse:2.00638\n",
      "[12197]\teval-rmse:3.88488\ttrain-rmse:2.00637\n",
      "[12198]\teval-rmse:3.88424\ttrain-rmse:2.00636\n",
      "[12199]\teval-rmse:3.88633\ttrain-rmse:2.00639\n",
      "[12200]\teval-rmse:3.88677\ttrain-rmse:2.00639\n",
      "[12201]\teval-rmse:3.88616\ttrain-rmse:2.00618\n",
      "[12202]\teval-rmse:3.8853\ttrain-rmse:2.00617\n",
      "[12203]\teval-rmse:3.88534\ttrain-rmse:2.00617\n",
      "[12204]\teval-rmse:3.88612\ttrain-rmse:2.00618\n",
      "[12205]\teval-rmse:3.88498\ttrain-rmse:2.00617\n",
      "[12206]\teval-rmse:3.88662\ttrain-rmse:2.00617\n",
      "[12207]\teval-rmse:3.88744\ttrain-rmse:2.00618\n",
      "[12208]\teval-rmse:3.88684\ttrain-rmse:2.00617\n",
      "[12209]\teval-rmse:3.88596\ttrain-rmse:2.00616\n",
      "[12210]\teval-rmse:3.88599\ttrain-rmse:2.00616\n",
      "[12211]\teval-rmse:3.8878\ttrain-rmse:2.0062\n",
      "[12212]\teval-rmse:3.88898\ttrain-rmse:2.00621\n",
      "[12213]\teval-rmse:3.89107\ttrain-rmse:2.00624\n",
      "[12214]\teval-rmse:3.89316\ttrain-rmse:2.00628\n",
      "[12215]\teval-rmse:3.89133\ttrain-rmse:2.00623\n",
      "[12216]\teval-rmse:3.89276\ttrain-rmse:2.00625\n",
      "[12217]\teval-rmse:3.89083\ttrain-rmse:2.00619\n",
      "[12218]\teval-rmse:3.89034\ttrain-rmse:2.00618\n",
      "[12219]\teval-rmse:3.89227\ttrain-rmse:2.00624\n",
      "[12220]\teval-rmse:3.89373\ttrain-rmse:2.00627\n",
      "[12221]\teval-rmse:3.89238\ttrain-rmse:2.00624\n",
      "[12222]\teval-rmse:3.89237\ttrain-rmse:2.00624\n",
      "[12223]\teval-rmse:3.89179\ttrain-rmse:2.00622\n",
      "[12224]\teval-rmse:3.89109\ttrain-rmse:2.0062\n",
      "[12225]\teval-rmse:3.89234\ttrain-rmse:2.00624\n",
      "[12226]\teval-rmse:3.89038\ttrain-rmse:2.00621\n",
      "[12227]\teval-rmse:3.89082\ttrain-rmse:2.00622\n",
      "[12228]\teval-rmse:3.89105\ttrain-rmse:2.00622\n",
      "[12229]\teval-rmse:3.89141\ttrain-rmse:2.00623\n",
      "[12230]\teval-rmse:3.89314\ttrain-rmse:2.00629\n",
      "[12231]\teval-rmse:3.8918\ttrain-rmse:2.00624\n",
      "[12232]\teval-rmse:3.8912\ttrain-rmse:2.00623\n",
      "[12233]\teval-rmse:3.89231\ttrain-rmse:2.00626\n",
      "[12234]\teval-rmse:3.89242\ttrain-rmse:2.00627\n",
      "[12235]\teval-rmse:3.89066\ttrain-rmse:2.00621\n",
      "[12236]\teval-rmse:3.88974\ttrain-rmse:2.00619\n",
      "[12237]\teval-rmse:3.89029\ttrain-rmse:2.0062\n",
      "[12238]\teval-rmse:3.89009\ttrain-rmse:2.00619\n",
      "[12239]\teval-rmse:3.88852\ttrain-rmse:2.00617\n",
      "[12240]\teval-rmse:3.88855\ttrain-rmse:2.00617\n",
      "[12241]\teval-rmse:3.89018\ttrain-rmse:2.00614\n",
      "[12242]\teval-rmse:3.89208\ttrain-rmse:2.00619\n",
      "[12243]\teval-rmse:3.89145\ttrain-rmse:2.00618\n",
      "[12244]\teval-rmse:3.8904\ttrain-rmse:2.00615\n",
      "[12245]\teval-rmse:3.88936\ttrain-rmse:2.00612\n",
      "[12246]\teval-rmse:3.88805\ttrain-rmse:2.0061\n",
      "[12247]\teval-rmse:3.88965\ttrain-rmse:2.00607\n",
      "[12248]\teval-rmse:3.89005\ttrain-rmse:2.00608\n",
      "[12249]\teval-rmse:3.89113\ttrain-rmse:2.00611\n",
      "[12250]\teval-rmse:3.88991\ttrain-rmse:2.00607\n",
      "[12251]\teval-rmse:3.89064\ttrain-rmse:2.00609\n",
      "[12252]\teval-rmse:3.89089\ttrain-rmse:2.0061\n",
      "[12253]\teval-rmse:3.88973\ttrain-rmse:2.00608\n",
      "[12254]\teval-rmse:3.88857\ttrain-rmse:2.00605\n",
      "[12255]\teval-rmse:3.88701\ttrain-rmse:2.00603\n",
      "[12256]\teval-rmse:3.88615\ttrain-rmse:2.00602\n",
      "[12257]\teval-rmse:3.88636\ttrain-rmse:2.00602\n",
      "[12258]\teval-rmse:3.8855\ttrain-rmse:2.00601\n",
      "[12259]\teval-rmse:3.88431\ttrain-rmse:2.00603\n",
      "[12260]\teval-rmse:3.88356\ttrain-rmse:2.00603\n",
      "[12261]\teval-rmse:3.88263\ttrain-rmse:2.00602\n",
      "[12262]\teval-rmse:3.88227\ttrain-rmse:2.00602\n",
      "[12263]\teval-rmse:3.88338\ttrain-rmse:2.00603\n",
      "[12264]\teval-rmse:3.88521\ttrain-rmse:2.00604\n",
      "[12265]\teval-rmse:3.8862\ttrain-rmse:2.00606\n",
      "[12266]\teval-rmse:3.88407\ttrain-rmse:2.00603\n",
      "[12267]\teval-rmse:3.88569\ttrain-rmse:2.00598\n",
      "[12268]\teval-rmse:3.88539\ttrain-rmse:2.00598\n",
      "[12269]\teval-rmse:3.8857\ttrain-rmse:2.00599\n",
      "[12270]\teval-rmse:3.88604\ttrain-rmse:2.00599\n",
      "[12271]\teval-rmse:3.88458\ttrain-rmse:2.00598\n",
      "[12272]\teval-rmse:3.88322\ttrain-rmse:2.00597\n",
      "[12273]\teval-rmse:3.88294\ttrain-rmse:2.00597\n",
      "[12274]\teval-rmse:3.88119\ttrain-rmse:2.00598\n",
      "[12275]\teval-rmse:3.88231\ttrain-rmse:2.00599\n",
      "[12276]\teval-rmse:3.88173\ttrain-rmse:2.00599\n",
      "[12277]\teval-rmse:3.88172\ttrain-rmse:2.00599\n",
      "[12278]\teval-rmse:3.8819\ttrain-rmse:2.00598\n",
      "[12279]\teval-rmse:3.88247\ttrain-rmse:2.00599\n",
      "[12280]\teval-rmse:3.88118\ttrain-rmse:2.00602\n",
      "[12281]\teval-rmse:3.88329\ttrain-rmse:2.00603\n",
      "[12282]\teval-rmse:3.88452\ttrain-rmse:2.00604\n",
      "[12283]\teval-rmse:3.8834\ttrain-rmse:2.00603\n",
      "[12284]\teval-rmse:3.88322\ttrain-rmse:2.00603\n",
      "[12285]\teval-rmse:3.88125\ttrain-rmse:2.00604\n",
      "[12286]\teval-rmse:3.88328\ttrain-rmse:2.00603\n",
      "[12287]\teval-rmse:3.88199\ttrain-rmse:2.00602\n",
      "[12288]\teval-rmse:3.88402\ttrain-rmse:2.00596\n",
      "[12289]\teval-rmse:3.88206\ttrain-rmse:2.00594\n",
      "[12290]\teval-rmse:3.88184\ttrain-rmse:2.00594\n",
      "[12291]\teval-rmse:3.88072\ttrain-rmse:2.00593\n",
      "[12292]\teval-rmse:3.88098\ttrain-rmse:2.00593\n",
      "[12293]\teval-rmse:3.88106\ttrain-rmse:2.00593\n",
      "[12294]\teval-rmse:3.88048\ttrain-rmse:2.00593\n",
      "[12295]\teval-rmse:3.88171\ttrain-rmse:2.00592\n",
      "[12296]\teval-rmse:3.88289\ttrain-rmse:2.00592\n",
      "[12297]\teval-rmse:3.88214\ttrain-rmse:2.00592\n",
      "[12298]\teval-rmse:3.88103\ttrain-rmse:2.00591\n",
      "[12299]\teval-rmse:3.88178\ttrain-rmse:2.00591\n",
      "[12300]\teval-rmse:3.88142\ttrain-rmse:2.00591\n",
      "[12301]\teval-rmse:3.87997\ttrain-rmse:2.00591\n",
      "[12302]\teval-rmse:3.88065\ttrain-rmse:2.00592\n",
      "[12303]\teval-rmse:3.88013\ttrain-rmse:2.00592\n",
      "[12304]\teval-rmse:3.88087\ttrain-rmse:2.00591\n",
      "[12305]\teval-rmse:3.88232\ttrain-rmse:2.00593\n",
      "[12306]\teval-rmse:3.88236\ttrain-rmse:2.00593\n",
      "[12307]\teval-rmse:3.88309\ttrain-rmse:2.00594\n",
      "[12308]\teval-rmse:3.88326\ttrain-rmse:2.00594\n",
      "[12309]\teval-rmse:3.88385\ttrain-rmse:2.00595\n",
      "[12310]\teval-rmse:3.88595\ttrain-rmse:2.00597\n",
      "[12311]\teval-rmse:3.88668\ttrain-rmse:2.00598\n",
      "[12312]\teval-rmse:3.88501\ttrain-rmse:2.00596\n",
      "[12313]\teval-rmse:3.88483\ttrain-rmse:2.00596\n",
      "[12314]\teval-rmse:3.88686\ttrain-rmse:2.00598\n",
      "[12315]\teval-rmse:3.88689\ttrain-rmse:2.00598\n",
      "[12316]\teval-rmse:3.88738\ttrain-rmse:2.00598\n",
      "[12317]\teval-rmse:3.88795\ttrain-rmse:2.006\n",
      "[12318]\teval-rmse:3.88819\ttrain-rmse:2.006\n",
      "[12319]\teval-rmse:3.88917\ttrain-rmse:2.00602\n",
      "[12320]\teval-rmse:3.88856\ttrain-rmse:2.00601\n",
      "[12321]\teval-rmse:3.88936\ttrain-rmse:2.00603\n",
      "[12322]\teval-rmse:3.8887\ttrain-rmse:2.00602\n",
      "[12323]\teval-rmse:3.88808\ttrain-rmse:2.00601\n",
      "[12324]\teval-rmse:3.88645\ttrain-rmse:2.00603\n",
      "[12325]\teval-rmse:3.88838\ttrain-rmse:2.00599\n",
      "[12326]\teval-rmse:3.88963\ttrain-rmse:2.00603\n",
      "[12327]\teval-rmse:3.88932\ttrain-rmse:2.00602\n",
      "[12328]\teval-rmse:3.88755\ttrain-rmse:2.00599\n",
      "[12329]\teval-rmse:3.88885\ttrain-rmse:2.00601\n",
      "[12330]\teval-rmse:3.8877\ttrain-rmse:2.00599\n",
      "[12331]\teval-rmse:3.88895\ttrain-rmse:2.00602\n",
      "[12332]\teval-rmse:3.88858\ttrain-rmse:2.00601\n",
      "[12333]\teval-rmse:3.88767\ttrain-rmse:2.00599\n",
      "[12334]\teval-rmse:3.88733\ttrain-rmse:2.00598\n",
      "[12335]\teval-rmse:3.88845\ttrain-rmse:2.00601\n",
      "[12336]\teval-rmse:3.88808\ttrain-rmse:2.00601\n",
      "[12337]\teval-rmse:3.88882\ttrain-rmse:2.00602\n",
      "[12338]\teval-rmse:3.8882\ttrain-rmse:2.0058\n",
      "[12339]\teval-rmse:3.88639\ttrain-rmse:2.00575\n",
      "[12340]\teval-rmse:3.88668\ttrain-rmse:2.00576\n",
      "[12341]\teval-rmse:3.88738\ttrain-rmse:2.00577\n",
      "[12342]\teval-rmse:3.8882\ttrain-rmse:2.0058\n",
      "[12343]\teval-rmse:3.88671\ttrain-rmse:2.00575\n",
      "[12344]\teval-rmse:3.8876\ttrain-rmse:2.00577\n",
      "[12345]\teval-rmse:3.88698\ttrain-rmse:2.00556\n",
      "[12346]\teval-rmse:3.88602\ttrain-rmse:2.00554\n",
      "[12347]\teval-rmse:3.88404\ttrain-rmse:2.0055\n",
      "[12348]\teval-rmse:3.88327\ttrain-rmse:2.00548\n",
      "[12349]\teval-rmse:3.88424\ttrain-rmse:2.00551\n",
      "[12350]\teval-rmse:3.88467\ttrain-rmse:2.00551\n",
      "[12351]\teval-rmse:3.88593\ttrain-rmse:2.00554\n",
      "[12352]\teval-rmse:3.88659\ttrain-rmse:2.00555\n",
      "[12353]\teval-rmse:3.88653\ttrain-rmse:2.00555\n",
      "[12354]\teval-rmse:3.8847\ttrain-rmse:2.00551\n",
      "[12355]\teval-rmse:3.88291\ttrain-rmse:2.00548\n",
      "[12356]\teval-rmse:3.88374\ttrain-rmse:2.00549\n",
      "[12357]\teval-rmse:3.88344\ttrain-rmse:2.00549\n",
      "[12358]\teval-rmse:3.88165\ttrain-rmse:2.00546\n",
      "[12359]\teval-rmse:3.88128\ttrain-rmse:2.00546\n",
      "[12360]\teval-rmse:3.88102\ttrain-rmse:2.00545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12361]\teval-rmse:3.88293\ttrain-rmse:2.0054\n",
      "[12362]\teval-rmse:3.88274\ttrain-rmse:2.0054\n",
      "[12363]\teval-rmse:3.88458\ttrain-rmse:2.00541\n",
      "[12364]\teval-rmse:3.88667\ttrain-rmse:2.00544\n",
      "[12365]\teval-rmse:3.88681\ttrain-rmse:2.00544\n",
      "[12366]\teval-rmse:3.88882\ttrain-rmse:2.00541\n",
      "[12367]\teval-rmse:3.88868\ttrain-rmse:2.0054\n",
      "[12368]\teval-rmse:3.88807\ttrain-rmse:2.0054\n",
      "[12369]\teval-rmse:3.8874\ttrain-rmse:2.00538\n",
      "[12370]\teval-rmse:3.88709\ttrain-rmse:2.00538\n",
      "[12371]\teval-rmse:3.88741\ttrain-rmse:2.00539\n",
      "[12372]\teval-rmse:3.88753\ttrain-rmse:2.00539\n",
      "[12373]\teval-rmse:3.88732\ttrain-rmse:2.00538\n",
      "[12374]\teval-rmse:3.88729\ttrain-rmse:2.00538\n",
      "[12375]\teval-rmse:3.8878\ttrain-rmse:2.00539\n",
      "[12376]\teval-rmse:3.88793\ttrain-rmse:2.0054\n",
      "[12377]\teval-rmse:3.88965\ttrain-rmse:2.00544\n",
      "[12378]\teval-rmse:3.89006\ttrain-rmse:2.00545\n",
      "[12379]\teval-rmse:3.89031\ttrain-rmse:2.00546\n",
      "[12380]\teval-rmse:3.89101\ttrain-rmse:2.00548\n",
      "[12381]\teval-rmse:3.89292\ttrain-rmse:2.00553\n",
      "[12382]\teval-rmse:3.89269\ttrain-rmse:2.00553\n",
      "[12383]\teval-rmse:3.89152\ttrain-rmse:2.0055\n",
      "[12384]\teval-rmse:3.89227\ttrain-rmse:2.00553\n",
      "[12385]\teval-rmse:3.893\ttrain-rmse:2.00556\n",
      "[12386]\teval-rmse:3.89447\ttrain-rmse:2.00562\n",
      "[12387]\teval-rmse:3.89582\ttrain-rmse:2.00567\n",
      "[12388]\teval-rmse:3.89692\ttrain-rmse:2.00573\n",
      "[12389]\teval-rmse:3.89811\ttrain-rmse:2.00579\n",
      "[12390]\teval-rmse:3.89926\ttrain-rmse:2.00585\n",
      "[12391]\teval-rmse:3.90083\ttrain-rmse:2.00586\n",
      "[12392]\teval-rmse:3.90171\ttrain-rmse:2.00592\n",
      "[12393]\teval-rmse:3.90005\ttrain-rmse:2.00582\n",
      "[12394]\teval-rmse:3.90014\ttrain-rmse:2.00582\n",
      "[12395]\teval-rmse:3.90023\ttrain-rmse:2.00583\n",
      "[12396]\teval-rmse:3.8983\ttrain-rmse:2.00571\n",
      "[12397]\teval-rmse:3.89915\ttrain-rmse:2.00576\n",
      "[12398]\teval-rmse:3.89729\ttrain-rmse:2.00565\n",
      "[12399]\teval-rmse:3.89663\ttrain-rmse:2.00542\n",
      "[12400]\teval-rmse:3.89662\ttrain-rmse:2.00542\n",
      "[12401]\teval-rmse:3.89659\ttrain-rmse:2.00542\n",
      "[12402]\teval-rmse:3.89726\ttrain-rmse:2.00546\n",
      "[12403]\teval-rmse:3.89675\ttrain-rmse:2.00543\n",
      "[12404]\teval-rmse:3.89866\ttrain-rmse:2.00554\n",
      "[12405]\teval-rmse:3.90038\ttrain-rmse:2.00564\n",
      "[12406]\teval-rmse:3.90227\ttrain-rmse:2.00565\n",
      "[12407]\teval-rmse:3.90262\ttrain-rmse:2.00567\n",
      "[12408]\teval-rmse:3.90384\ttrain-rmse:2.00575\n",
      "[12409]\teval-rmse:3.90541\ttrain-rmse:2.00584\n",
      "[12410]\teval-rmse:3.90576\ttrain-rmse:2.00586\n",
      "[12411]\teval-rmse:3.90529\ttrain-rmse:2.00583\n",
      "[12412]\teval-rmse:3.9035\ttrain-rmse:2.00571\n",
      "[12413]\teval-rmse:3.90507\ttrain-rmse:2.00574\n",
      "[12414]\teval-rmse:3.90365\ttrain-rmse:2.00563\n",
      "[12415]\teval-rmse:3.90138\ttrain-rmse:2.00549\n",
      "[12416]\teval-rmse:3.90102\ttrain-rmse:2.00548\n",
      "[12417]\teval-rmse:3.90077\ttrain-rmse:2.00547\n",
      "[12418]\teval-rmse:3.90092\ttrain-rmse:2.00547\n",
      "[12419]\teval-rmse:3.89922\ttrain-rmse:2.0054\n",
      "[12420]\teval-rmse:3.90086\ttrain-rmse:2.00549\n",
      "[12421]\teval-rmse:3.89919\ttrain-rmse:2.00538\n",
      "[12422]\teval-rmse:3.89799\ttrain-rmse:2.00535\n",
      "[12423]\teval-rmse:3.89774\ttrain-rmse:2.00534\n",
      "[12424]\teval-rmse:3.89652\ttrain-rmse:2.0053\n",
      "[12425]\teval-rmse:3.89859\ttrain-rmse:2.00536\n",
      "[12426]\teval-rmse:3.89999\ttrain-rmse:2.00544\n",
      "[12427]\teval-rmse:3.89876\ttrain-rmse:2.00537\n",
      "[12428]\teval-rmse:3.89796\ttrain-rmse:2.00515\n",
      "[12429]\teval-rmse:3.89744\ttrain-rmse:2.00512\n",
      "[12430]\teval-rmse:3.89625\ttrain-rmse:2.00508\n",
      "[12431]\teval-rmse:3.896\ttrain-rmse:2.00507\n",
      "[12432]\teval-rmse:3.89614\ttrain-rmse:2.00508\n",
      "[12433]\teval-rmse:3.89702\ttrain-rmse:2.00513\n",
      "[12434]\teval-rmse:3.89711\ttrain-rmse:2.00514\n",
      "[12435]\teval-rmse:3.89774\ttrain-rmse:2.00517\n",
      "[12436]\teval-rmse:3.89928\ttrain-rmse:2.00526\n",
      "[12437]\teval-rmse:3.90049\ttrain-rmse:2.00534\n",
      "[12438]\teval-rmse:3.90013\ttrain-rmse:2.00532\n",
      "[12439]\teval-rmse:3.90176\ttrain-rmse:2.00542\n",
      "[12440]\teval-rmse:3.90054\ttrain-rmse:2.00537\n",
      "[12441]\teval-rmse:3.89974\ttrain-rmse:2.00533\n",
      "[12442]\teval-rmse:3.90008\ttrain-rmse:2.00535\n",
      "[12443]\teval-rmse:3.90024\ttrain-rmse:2.00536\n",
      "[12444]\teval-rmse:3.89986\ttrain-rmse:2.00534\n",
      "[12445]\teval-rmse:3.89953\ttrain-rmse:2.00532\n",
      "[12446]\teval-rmse:3.89782\ttrain-rmse:2.00522\n",
      "[12447]\teval-rmse:3.8972\ttrain-rmse:2.00519\n",
      "[12448]\teval-rmse:3.89799\ttrain-rmse:2.00523\n",
      "[12449]\teval-rmse:3.89956\ttrain-rmse:2.00524\n",
      "[12450]\teval-rmse:3.89962\ttrain-rmse:2.00524\n",
      "[12451]\teval-rmse:3.89927\ttrain-rmse:2.00523\n",
      "[12452]\teval-rmse:3.8986\ttrain-rmse:2.00521\n",
      "[12453]\teval-rmse:3.89774\ttrain-rmse:2.00516\n",
      "[12454]\teval-rmse:3.89644\ttrain-rmse:2.00509\n",
      "[12455]\teval-rmse:3.89694\ttrain-rmse:2.00511\n",
      "[12456]\teval-rmse:3.89593\ttrain-rmse:2.00505\n",
      "[12457]\teval-rmse:3.89561\ttrain-rmse:2.00503\n",
      "[12458]\teval-rmse:3.89497\ttrain-rmse:2.00482\n",
      "[12459]\teval-rmse:3.89682\ttrain-rmse:2.00492\n",
      "[12460]\teval-rmse:3.89642\ttrain-rmse:2.0049\n",
      "[12461]\teval-rmse:3.89457\ttrain-rmse:2.0048\n",
      "[12462]\teval-rmse:3.89294\ttrain-rmse:2.00471\n",
      "[12463]\teval-rmse:3.89263\ttrain-rmse:2.0047\n",
      "[12464]\teval-rmse:3.89033\ttrain-rmse:2.0046\n",
      "[12465]\teval-rmse:3.89156\ttrain-rmse:2.00465\n",
      "[12466]\teval-rmse:3.89261\ttrain-rmse:2.00469\n",
      "[12467]\teval-rmse:3.89284\ttrain-rmse:2.0047\n",
      "[12468]\teval-rmse:3.89088\ttrain-rmse:2.00462\n",
      "[12469]\teval-rmse:3.88886\ttrain-rmse:2.00454\n",
      "[12470]\teval-rmse:3.8877\ttrain-rmse:2.00452\n",
      "[12471]\teval-rmse:3.88971\ttrain-rmse:2.00459\n",
      "[12472]\teval-rmse:3.88749\ttrain-rmse:2.00451\n",
      "[12473]\teval-rmse:3.88634\ttrain-rmse:2.00449\n",
      "[12474]\teval-rmse:3.88823\ttrain-rmse:2.00456\n",
      "[12475]\teval-rmse:3.8891\ttrain-rmse:2.00459\n",
      "[12476]\teval-rmse:3.89032\ttrain-rmse:2.00463\n",
      "[12477]\teval-rmse:3.88971\ttrain-rmse:2.00462\n",
      "[12478]\teval-rmse:3.89135\ttrain-rmse:2.00468\n",
      "[12479]\teval-rmse:3.89018\ttrain-rmse:2.00462\n",
      "[12480]\teval-rmse:3.88996\ttrain-rmse:2.00462\n",
      "[12481]\teval-rmse:3.88799\ttrain-rmse:2.00455\n",
      "[12482]\teval-rmse:3.88618\ttrain-rmse:2.00448\n",
      "[12483]\teval-rmse:3.88458\ttrain-rmse:2.00444\n",
      "[12484]\teval-rmse:3.8862\ttrain-rmse:2.00441\n",
      "[12485]\teval-rmse:3.88694\ttrain-rmse:2.00443\n",
      "[12486]\teval-rmse:3.88554\ttrain-rmse:2.00439\n",
      "[12487]\teval-rmse:3.88704\ttrain-rmse:2.00443\n",
      "[12488]\teval-rmse:3.8881\ttrain-rmse:2.00446\n",
      "[12489]\teval-rmse:3.88751\ttrain-rmse:2.00444\n",
      "[12490]\teval-rmse:3.8857\ttrain-rmse:2.0044\n",
      "[12491]\teval-rmse:3.8851\ttrain-rmse:2.0044\n",
      "[12492]\teval-rmse:3.88436\ttrain-rmse:2.00438\n",
      "[12493]\teval-rmse:3.88628\ttrain-rmse:2.00435\n",
      "[12494]\teval-rmse:3.88692\ttrain-rmse:2.00437\n",
      "[12495]\teval-rmse:3.88798\ttrain-rmse:2.00441\n",
      "[12496]\teval-rmse:3.88829\ttrain-rmse:2.00441\n",
      "[12497]\teval-rmse:3.88789\ttrain-rmse:2.0044\n",
      "[12498]\teval-rmse:3.88714\ttrain-rmse:2.00438\n",
      "[12499]\teval-rmse:3.88599\ttrain-rmse:2.00437\n",
      "[12500]\teval-rmse:3.88681\ttrain-rmse:2.00438\n",
      "[12501]\teval-rmse:3.8865\ttrain-rmse:2.00438\n",
      "[12502]\teval-rmse:3.88658\ttrain-rmse:2.00438\n",
      "[12503]\teval-rmse:3.88589\ttrain-rmse:2.00436\n",
      "[12504]\teval-rmse:3.88618\ttrain-rmse:2.00437\n",
      "[12505]\teval-rmse:3.8841\ttrain-rmse:2.00431\n",
      "[12506]\teval-rmse:3.88367\ttrain-rmse:2.0043\n",
      "[12507]\teval-rmse:3.88206\ttrain-rmse:2.00428\n",
      "[12508]\teval-rmse:3.88121\ttrain-rmse:2.00427\n",
      "[12509]\teval-rmse:3.88265\ttrain-rmse:2.0043\n",
      "[12510]\teval-rmse:3.88314\ttrain-rmse:2.00431\n",
      "[12511]\teval-rmse:3.88118\ttrain-rmse:2.00429\n",
      "[12512]\teval-rmse:3.88047\ttrain-rmse:2.00428\n",
      "[12513]\teval-rmse:3.87901\ttrain-rmse:2.00427\n",
      "[12514]\teval-rmse:3.8809\ttrain-rmse:2.00422\n",
      "[12515]\teval-rmse:3.88299\ttrain-rmse:2.00424\n",
      "[12516]\teval-rmse:3.88379\ttrain-rmse:2.00425\n",
      "[12517]\teval-rmse:3.88431\ttrain-rmse:2.00426\n",
      "[12518]\teval-rmse:3.88596\ttrain-rmse:2.0043\n",
      "[12519]\teval-rmse:3.88464\ttrain-rmse:2.00432\n",
      "[12520]\teval-rmse:3.88378\ttrain-rmse:2.00431\n",
      "[12521]\teval-rmse:3.88562\ttrain-rmse:2.00435\n",
      "[12522]\teval-rmse:3.88476\ttrain-rmse:2.00433\n",
      "[12523]\teval-rmse:3.88296\ttrain-rmse:2.00431\n",
      "[12524]\teval-rmse:3.88141\ttrain-rmse:2.00429\n",
      "[12525]\teval-rmse:3.88046\ttrain-rmse:2.00429\n",
      "[12526]\teval-rmse:3.87936\ttrain-rmse:2.00428\n",
      "[12527]\teval-rmse:3.87978\ttrain-rmse:2.00429\n",
      "[12528]\teval-rmse:3.87962\ttrain-rmse:2.00429\n",
      "[12529]\teval-rmse:3.87885\ttrain-rmse:2.00428\n",
      "[12530]\teval-rmse:3.87702\ttrain-rmse:2.00428\n",
      "[12531]\teval-rmse:3.87499\ttrain-rmse:2.00427\n",
      "[12532]\teval-rmse:3.87465\ttrain-rmse:2.00427\n",
      "[12533]\teval-rmse:3.87555\ttrain-rmse:2.00427\n",
      "[12534]\teval-rmse:3.87699\ttrain-rmse:2.00428\n",
      "[12535]\teval-rmse:3.87472\ttrain-rmse:2.00428\n",
      "[12536]\teval-rmse:3.87493\ttrain-rmse:2.00428\n",
      "[12537]\teval-rmse:3.87438\ttrain-rmse:2.00406\n",
      "[12538]\teval-rmse:3.87582\ttrain-rmse:2.00407\n",
      "[12539]\teval-rmse:3.87396\ttrain-rmse:2.00405\n",
      "[12540]\teval-rmse:3.87345\ttrain-rmse:2.00405\n",
      "[12541]\teval-rmse:3.87236\ttrain-rmse:2.00405\n",
      "[12542]\teval-rmse:3.87183\ttrain-rmse:2.00384\n",
      "[12543]\teval-rmse:3.8717\ttrain-rmse:2.00384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12544]\teval-rmse:3.87195\ttrain-rmse:2.00384\n",
      "[12545]\teval-rmse:3.87227\ttrain-rmse:2.00384\n",
      "[12546]\teval-rmse:3.87067\ttrain-rmse:2.00387\n",
      "[12547]\teval-rmse:3.87042\ttrain-rmse:2.00387\n",
      "[12548]\teval-rmse:3.86981\ttrain-rmse:2.00388\n",
      "[12549]\teval-rmse:3.87113\ttrain-rmse:2.00388\n",
      "[12550]\teval-rmse:3.87259\ttrain-rmse:2.00387\n",
      "[12551]\teval-rmse:3.87332\ttrain-rmse:2.00386\n",
      "[12552]\teval-rmse:3.87393\ttrain-rmse:2.00387\n",
      "[12553]\teval-rmse:3.87367\ttrain-rmse:2.00387\n",
      "[12554]\teval-rmse:3.87313\ttrain-rmse:2.00387\n",
      "[12555]\teval-rmse:3.87279\ttrain-rmse:2.00388\n",
      "[12556]\teval-rmse:3.87147\ttrain-rmse:2.00388\n",
      "[12557]\teval-rmse:3.8734\ttrain-rmse:2.00389\n",
      "[12558]\teval-rmse:3.87469\ttrain-rmse:2.0039\n",
      "[12559]\teval-rmse:3.87394\ttrain-rmse:2.0039\n",
      "[12560]\teval-rmse:3.87367\ttrain-rmse:2.0039\n",
      "[12561]\teval-rmse:3.87406\ttrain-rmse:2.0039\n",
      "[12562]\teval-rmse:3.87401\ttrain-rmse:2.0039\n",
      "[12563]\teval-rmse:3.87427\ttrain-rmse:2.0039\n",
      "[12564]\teval-rmse:3.8732\ttrain-rmse:2.00391\n",
      "[12565]\teval-rmse:3.87339\ttrain-rmse:2.00391\n",
      "[12566]\teval-rmse:3.87517\ttrain-rmse:2.00392\n",
      "[12567]\teval-rmse:3.87462\ttrain-rmse:2.00376\n",
      "[12568]\teval-rmse:3.87437\ttrain-rmse:2.00376\n",
      "[12569]\teval-rmse:3.87587\ttrain-rmse:2.00377\n",
      "[12570]\teval-rmse:3.87695\ttrain-rmse:2.00374\n",
      "[12571]\teval-rmse:3.87566\ttrain-rmse:2.00371\n",
      "[12572]\teval-rmse:3.87539\ttrain-rmse:2.00371\n",
      "[12573]\teval-rmse:3.87651\ttrain-rmse:2.00372\n",
      "[12574]\teval-rmse:3.87524\ttrain-rmse:2.00371\n",
      "[12575]\teval-rmse:3.87377\ttrain-rmse:2.0037\n",
      "[12576]\teval-rmse:3.87321\ttrain-rmse:2.0037\n",
      "[12577]\teval-rmse:3.87327\ttrain-rmse:2.0037\n",
      "[12578]\teval-rmse:3.87426\ttrain-rmse:2.00371\n",
      "[12579]\teval-rmse:3.87637\ttrain-rmse:2.0037\n",
      "[12580]\teval-rmse:3.87581\ttrain-rmse:2.00353\n",
      "[12581]\teval-rmse:3.87733\ttrain-rmse:2.00356\n",
      "[12582]\teval-rmse:3.87681\ttrain-rmse:2.00355\n",
      "[12583]\teval-rmse:3.87706\ttrain-rmse:2.00355\n",
      "[12584]\teval-rmse:3.87878\ttrain-rmse:2.00356\n",
      "[12585]\teval-rmse:3.877\ttrain-rmse:2.00353\n",
      "[12586]\teval-rmse:3.87564\ttrain-rmse:2.00353\n",
      "[12587]\teval-rmse:3.87483\ttrain-rmse:2.00353\n",
      "[12588]\teval-rmse:3.87509\ttrain-rmse:2.00353\n",
      "[12589]\teval-rmse:3.874\ttrain-rmse:2.00354\n",
      "[12590]\teval-rmse:3.87549\ttrain-rmse:2.00356\n",
      "[12591]\teval-rmse:3.87675\ttrain-rmse:2.00358\n",
      "[12592]\teval-rmse:3.87565\ttrain-rmse:2.00358\n",
      "[12593]\teval-rmse:3.87533\ttrain-rmse:2.00358\n",
      "[12594]\teval-rmse:3.87472\ttrain-rmse:2.00357\n",
      "[12595]\teval-rmse:3.87606\ttrain-rmse:2.00359\n",
      "[12596]\teval-rmse:3.87789\ttrain-rmse:2.00362\n",
      "[12597]\teval-rmse:3.87681\ttrain-rmse:2.00362\n",
      "[12598]\teval-rmse:3.87654\ttrain-rmse:2.00362\n",
      "[12599]\teval-rmse:3.87495\ttrain-rmse:2.00366\n",
      "[12600]\teval-rmse:3.8736\ttrain-rmse:2.00364\n",
      "[12601]\teval-rmse:3.87305\ttrain-rmse:2.00365\n",
      "[12602]\teval-rmse:3.87251\ttrain-rmse:2.00365\n",
      "[12603]\teval-rmse:3.87415\ttrain-rmse:2.00364\n",
      "[12604]\teval-rmse:3.87401\ttrain-rmse:2.00365\n",
      "[12605]\teval-rmse:3.87496\ttrain-rmse:2.00367\n",
      "[12606]\teval-rmse:3.87615\ttrain-rmse:2.0037\n",
      "[12607]\teval-rmse:3.87795\ttrain-rmse:2.00375\n",
      "[12608]\teval-rmse:3.87742\ttrain-rmse:2.00373\n",
      "[12609]\teval-rmse:3.87923\ttrain-rmse:2.00375\n",
      "[12610]\teval-rmse:3.88046\ttrain-rmse:2.00376\n",
      "[12611]\teval-rmse:3.87926\ttrain-rmse:2.00373\n",
      "[12612]\teval-rmse:3.88094\ttrain-rmse:2.00377\n",
      "[12613]\teval-rmse:3.88191\ttrain-rmse:2.00381\n",
      "[12614]\teval-rmse:3.88216\ttrain-rmse:2.00382\n",
      "[12615]\teval-rmse:3.88401\ttrain-rmse:2.0039\n",
      "[12616]\teval-rmse:3.88445\ttrain-rmse:2.00392\n",
      "[12617]\teval-rmse:3.88386\ttrain-rmse:2.00376\n",
      "[12618]\teval-rmse:3.88328\ttrain-rmse:2.00374\n",
      "[12619]\teval-rmse:3.88233\ttrain-rmse:2.0037\n",
      "[12620]\teval-rmse:3.88101\ttrain-rmse:2.00366\n",
      "[12621]\teval-rmse:3.8827\ttrain-rmse:2.00372\n",
      "[12622]\teval-rmse:3.8808\ttrain-rmse:2.00364\n",
      "[12623]\teval-rmse:3.8804\ttrain-rmse:2.00362\n",
      "[12624]\teval-rmse:3.8817\ttrain-rmse:2.00368\n",
      "[12625]\teval-rmse:3.88057\ttrain-rmse:2.00367\n",
      "[12626]\teval-rmse:3.87935\ttrain-rmse:2.00368\n",
      "[12627]\teval-rmse:3.87824\ttrain-rmse:2.00367\n",
      "[12628]\teval-rmse:3.87931\ttrain-rmse:2.00372\n",
      "[12629]\teval-rmse:3.87987\ttrain-rmse:2.00374\n",
      "[12630]\teval-rmse:3.88099\ttrain-rmse:2.00379\n",
      "[12631]\teval-rmse:3.88041\ttrain-rmse:2.00362\n",
      "[12632]\teval-rmse:3.87991\ttrain-rmse:2.0036\n",
      "[12633]\teval-rmse:3.87789\ttrain-rmse:2.00352\n",
      "[12634]\teval-rmse:3.87786\ttrain-rmse:2.00352\n",
      "[12635]\teval-rmse:3.8777\ttrain-rmse:2.00351\n",
      "[12636]\teval-rmse:3.87611\ttrain-rmse:2.0035\n",
      "[12637]\teval-rmse:3.87705\ttrain-rmse:2.00353\n",
      "[12638]\teval-rmse:3.87574\ttrain-rmse:2.00351\n",
      "[12639]\teval-rmse:3.87736\ttrain-rmse:2.00352\n",
      "[12640]\teval-rmse:3.87661\ttrain-rmse:2.00351\n",
      "[12641]\teval-rmse:3.8767\ttrain-rmse:2.00351\n",
      "[12642]\teval-rmse:3.87778\ttrain-rmse:2.00354\n",
      "[12643]\teval-rmse:3.87589\ttrain-rmse:2.00349\n",
      "[12644]\teval-rmse:3.87533\ttrain-rmse:2.00349\n",
      "[12645]\teval-rmse:3.87623\ttrain-rmse:2.00353\n",
      "[12646]\teval-rmse:3.87664\ttrain-rmse:2.00354\n",
      "[12647]\teval-rmse:3.87674\ttrain-rmse:2.00354\n",
      "[12648]\teval-rmse:3.87571\ttrain-rmse:2.00352\n",
      "[12649]\teval-rmse:3.87759\ttrain-rmse:2.00353\n",
      "[12650]\teval-rmse:3.87705\ttrain-rmse:2.00353\n",
      "[12651]\teval-rmse:3.8752\ttrain-rmse:2.00349\n",
      "[12652]\teval-rmse:3.87401\ttrain-rmse:2.00352\n",
      "[12653]\teval-rmse:3.87349\ttrain-rmse:2.00351\n",
      "[12654]\teval-rmse:3.87431\ttrain-rmse:2.00352\n",
      "[12655]\teval-rmse:3.87582\ttrain-rmse:2.00355\n",
      "[12656]\teval-rmse:3.87424\ttrain-rmse:2.00359\n",
      "[12657]\teval-rmse:3.87257\ttrain-rmse:2.00356\n",
      "[12658]\teval-rmse:3.87149\ttrain-rmse:2.00357\n",
      "[12659]\teval-rmse:3.8721\ttrain-rmse:2.00358\n",
      "[12660]\teval-rmse:3.87056\ttrain-rmse:2.00359\n",
      "[12661]\teval-rmse:3.86951\ttrain-rmse:2.00357\n",
      "[12662]\teval-rmse:3.8688\ttrain-rmse:2.00357\n",
      "[12663]\teval-rmse:3.87005\ttrain-rmse:2.00359\n",
      "[12664]\teval-rmse:3.8695\ttrain-rmse:2.0036\n",
      "[12665]\teval-rmse:3.87084\ttrain-rmse:2.00359\n",
      "[12666]\teval-rmse:3.87109\ttrain-rmse:2.00359\n",
      "[12667]\teval-rmse:3.87319\ttrain-rmse:2.00358\n",
      "[12668]\teval-rmse:3.87436\ttrain-rmse:2.00361\n",
      "[12669]\teval-rmse:3.87528\ttrain-rmse:2.00364\n",
      "[12670]\teval-rmse:3.87549\ttrain-rmse:2.00365\n",
      "[12671]\teval-rmse:3.87441\ttrain-rmse:2.00361\n",
      "[12672]\teval-rmse:3.87284\ttrain-rmse:2.0036\n",
      "[12673]\teval-rmse:3.87294\ttrain-rmse:2.00361\n",
      "[12674]\teval-rmse:3.87329\ttrain-rmse:2.00362\n",
      "[12675]\teval-rmse:3.87194\ttrain-rmse:2.00362\n",
      "[12676]\teval-rmse:3.87255\ttrain-rmse:2.00363\n",
      "[12677]\teval-rmse:3.87359\ttrain-rmse:2.00367\n",
      "[12678]\teval-rmse:3.87311\ttrain-rmse:2.00349\n",
      "[12679]\teval-rmse:3.87261\ttrain-rmse:2.00331\n",
      "[12680]\teval-rmse:3.87044\ttrain-rmse:2.00324\n",
      "[12681]\teval-rmse:3.87123\ttrain-rmse:2.00326\n",
      "[12682]\teval-rmse:3.8696\ttrain-rmse:2.00325\n",
      "[12683]\teval-rmse:3.8687\ttrain-rmse:2.00322\n",
      "[12684]\teval-rmse:3.8686\ttrain-rmse:2.00322\n",
      "[12685]\teval-rmse:3.86847\ttrain-rmse:2.00321\n",
      "[12686]\teval-rmse:3.86831\ttrain-rmse:2.00321\n",
      "[12687]\teval-rmse:3.86929\ttrain-rmse:2.00324\n",
      "[12688]\teval-rmse:3.87037\ttrain-rmse:2.00324\n",
      "[12689]\teval-rmse:3.87246\ttrain-rmse:2.00322\n",
      "[12690]\teval-rmse:3.87191\ttrain-rmse:2.00307\n",
      "[12691]\teval-rmse:3.87119\ttrain-rmse:2.00306\n",
      "[12692]\teval-rmse:3.87207\ttrain-rmse:2.00308\n",
      "[12693]\teval-rmse:3.87273\ttrain-rmse:2.00311\n",
      "[12694]\teval-rmse:3.8724\ttrain-rmse:2.0031\n",
      "[12695]\teval-rmse:3.87021\ttrain-rmse:2.00302\n",
      "[12696]\teval-rmse:3.87164\ttrain-rmse:2.00301\n",
      "[12697]\teval-rmse:3.87287\ttrain-rmse:2.00303\n",
      "[12698]\teval-rmse:3.87423\ttrain-rmse:2.00308\n",
      "[12699]\teval-rmse:3.87368\ttrain-rmse:2.00291\n",
      "[12700]\teval-rmse:3.87212\ttrain-rmse:2.00295\n",
      "[12701]\teval-rmse:3.87401\ttrain-rmse:2.00299\n",
      "[12702]\teval-rmse:3.87272\ttrain-rmse:2.00296\n",
      "[12703]\teval-rmse:3.87373\ttrain-rmse:2.003\n",
      "[12704]\teval-rmse:3.8739\ttrain-rmse:2.003\n",
      "[12705]\teval-rmse:3.87539\ttrain-rmse:2.00306\n",
      "[12706]\teval-rmse:3.87515\ttrain-rmse:2.00305\n",
      "[12707]\teval-rmse:3.87369\ttrain-rmse:2.00304\n",
      "[12708]\teval-rmse:3.87277\ttrain-rmse:2.00304\n",
      "[12709]\teval-rmse:3.8719\ttrain-rmse:2.00302\n",
      "[12710]\teval-rmse:3.87119\ttrain-rmse:2.00302\n",
      "[12711]\teval-rmse:3.87253\ttrain-rmse:2.00306\n",
      "[12712]\teval-rmse:3.87452\ttrain-rmse:2.00307\n",
      "[12713]\teval-rmse:3.87566\ttrain-rmse:2.00312\n",
      "[12714]\teval-rmse:3.87647\ttrain-rmse:2.00316\n",
      "[12715]\teval-rmse:3.87715\ttrain-rmse:2.00317\n",
      "[12716]\teval-rmse:3.87781\ttrain-rmse:2.0032\n",
      "[12717]\teval-rmse:3.87849\ttrain-rmse:2.00321\n",
      "[12718]\teval-rmse:3.87894\ttrain-rmse:2.00322\n",
      "[12719]\teval-rmse:3.87706\ttrain-rmse:2.00319\n",
      "[12720]\teval-rmse:3.87764\ttrain-rmse:2.00322\n",
      "[12721]\teval-rmse:3.87877\ttrain-rmse:2.00329\n",
      "[12722]\teval-rmse:3.87825\ttrain-rmse:2.00313\n",
      "[12723]\teval-rmse:3.8772\ttrain-rmse:2.00311\n",
      "[12724]\teval-rmse:3.87528\ttrain-rmse:2.00301\n",
      "[12725]\teval-rmse:3.87313\ttrain-rmse:2.00291\n",
      "[12726]\teval-rmse:3.87414\ttrain-rmse:2.00293\n",
      "[12727]\teval-rmse:3.87423\ttrain-rmse:2.00294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12728]\teval-rmse:3.87564\ttrain-rmse:2.00294\n",
      "[12729]\teval-rmse:3.87704\ttrain-rmse:2.00301\n",
      "[12730]\teval-rmse:3.8788\ttrain-rmse:2.00307\n",
      "[12731]\teval-rmse:3.87891\ttrain-rmse:2.00307\n",
      "[12732]\teval-rmse:3.88026\ttrain-rmse:2.00315\n",
      "[12733]\teval-rmse:3.87894\ttrain-rmse:2.00316\n",
      "[12734]\teval-rmse:3.87837\ttrain-rmse:2.00314\n",
      "[12735]\teval-rmse:3.87742\ttrain-rmse:2.0031\n",
      "[12736]\teval-rmse:3.87807\ttrain-rmse:2.00312\n",
      "[12737]\teval-rmse:3.87676\ttrain-rmse:2.00313\n",
      "[12738]\teval-rmse:3.87712\ttrain-rmse:2.00316\n",
      "[12739]\teval-rmse:3.87835\ttrain-rmse:2.00317\n",
      "[12740]\teval-rmse:3.87852\ttrain-rmse:2.00318\n",
      "[12741]\teval-rmse:3.87757\ttrain-rmse:2.00314\n",
      "[12742]\teval-rmse:3.8769\ttrain-rmse:2.00312\n",
      "[12743]\teval-rmse:3.87832\ttrain-rmse:2.00314\n",
      "[12744]\teval-rmse:3.87963\ttrain-rmse:2.00319\n",
      "[12745]\teval-rmse:3.88069\ttrain-rmse:2.00316\n",
      "[12746]\teval-rmse:3.8788\ttrain-rmse:2.00311\n",
      "[12747]\teval-rmse:3.87855\ttrain-rmse:2.0031\n",
      "[12748]\teval-rmse:3.87829\ttrain-rmse:2.00309\n",
      "[12749]\teval-rmse:3.87967\ttrain-rmse:2.00313\n",
      "[12750]\teval-rmse:3.87849\ttrain-rmse:2.00309\n",
      "[12751]\teval-rmse:3.87897\ttrain-rmse:2.00312\n",
      "[12752]\teval-rmse:3.8783\ttrain-rmse:2.00308\n",
      "[12753]\teval-rmse:3.87611\ttrain-rmse:2.00301\n",
      "[12754]\teval-rmse:3.87699\ttrain-rmse:2.00305\n",
      "[12755]\teval-rmse:3.87813\ttrain-rmse:2.00312\n",
      "[12756]\teval-rmse:3.87994\ttrain-rmse:2.00318\n",
      "[12757]\teval-rmse:3.8818\ttrain-rmse:2.00325\n",
      "[12758]\teval-rmse:3.88361\ttrain-rmse:2.00338\n",
      "[12759]\teval-rmse:3.88228\ttrain-rmse:2.00329\n",
      "[12760]\teval-rmse:3.88332\ttrain-rmse:2.00325\n",
      "[12761]\teval-rmse:3.88265\ttrain-rmse:2.00323\n",
      "[12762]\teval-rmse:3.88249\ttrain-rmse:2.00322\n",
      "[12763]\teval-rmse:3.88419\ttrain-rmse:2.0033\n",
      "[12764]\teval-rmse:3.88285\ttrain-rmse:2.00325\n",
      "[12765]\teval-rmse:3.88491\ttrain-rmse:2.00327\n",
      "[12766]\teval-rmse:3.88563\ttrain-rmse:2.00332\n",
      "[12767]\teval-rmse:3.88407\ttrain-rmse:2.00325\n",
      "[12768]\teval-rmse:3.88415\ttrain-rmse:2.00325\n",
      "[12769]\teval-rmse:3.88553\ttrain-rmse:2.00332\n",
      "[12770]\teval-rmse:3.88604\ttrain-rmse:2.00336\n",
      "[12771]\teval-rmse:3.88607\ttrain-rmse:2.00336\n",
      "[12772]\teval-rmse:3.88416\ttrain-rmse:2.0033\n",
      "[12773]\teval-rmse:3.88458\ttrain-rmse:2.00333\n",
      "[12774]\teval-rmse:3.8839\ttrain-rmse:2.00329\n",
      "[12775]\teval-rmse:3.88426\ttrain-rmse:2.0033\n",
      "[12776]\teval-rmse:3.8849\ttrain-rmse:2.00332\n",
      "[12777]\teval-rmse:3.88621\ttrain-rmse:2.00339\n",
      "[12778]\teval-rmse:3.88688\ttrain-rmse:2.00344\n",
      "[12779]\teval-rmse:3.88828\ttrain-rmse:2.00352\n",
      "[12780]\teval-rmse:3.88955\ttrain-rmse:2.00362\n",
      "[12781]\teval-rmse:3.89051\ttrain-rmse:2.00371\n",
      "[12782]\teval-rmse:3.89039\ttrain-rmse:2.0037\n",
      "[12783]\teval-rmse:3.88828\ttrain-rmse:2.00352\n",
      "[12784]\teval-rmse:3.88973\ttrain-rmse:2.00361\n",
      "[12785]\teval-rmse:3.88847\ttrain-rmse:2.00355\n",
      "[12786]\teval-rmse:3.88967\ttrain-rmse:2.00366\n",
      "[12787]\teval-rmse:3.89154\ttrain-rmse:2.00377\n",
      "[12788]\teval-rmse:3.89216\ttrain-rmse:2.00381\n",
      "[12789]\teval-rmse:3.89337\ttrain-rmse:2.00393\n",
      "[12790]\teval-rmse:3.89489\ttrain-rmse:2.00408\n",
      "[12791]\teval-rmse:3.89464\ttrain-rmse:2.00405\n",
      "[12792]\teval-rmse:3.89263\ttrain-rmse:2.00386\n",
      "[12793]\teval-rmse:3.89336\ttrain-rmse:2.0039\n",
      "[12794]\teval-rmse:3.8911\ttrain-rmse:2.0037\n",
      "[12795]\teval-rmse:3.88936\ttrain-rmse:2.00355\n",
      "[12796]\teval-rmse:3.89104\ttrain-rmse:2.00365\n",
      "[12797]\teval-rmse:3.89081\ttrain-rmse:2.00365\n",
      "[12798]\teval-rmse:3.89151\ttrain-rmse:2.00369\n",
      "[12799]\teval-rmse:3.89059\ttrain-rmse:2.00363\n",
      "[12800]\teval-rmse:3.89267\ttrain-rmse:2.00367\n",
      "[12801]\teval-rmse:3.89072\ttrain-rmse:2.00358\n",
      "[12802]\teval-rmse:3.89134\ttrain-rmse:2.0036\n",
      "[12803]\teval-rmse:3.88998\ttrain-rmse:2.00348\n",
      "[12804]\teval-rmse:3.89195\ttrain-rmse:2.00347\n",
      "[12805]\teval-rmse:3.89295\ttrain-rmse:2.00346\n",
      "[12806]\teval-rmse:3.89165\ttrain-rmse:2.00344\n",
      "[12807]\teval-rmse:3.89283\ttrain-rmse:2.00348\n",
      "[12808]\teval-rmse:3.89276\ttrain-rmse:2.00348\n",
      "[12809]\teval-rmse:3.89222\ttrain-rmse:2.00343\n",
      "[12810]\teval-rmse:3.89084\ttrain-rmse:2.00335\n",
      "[12811]\teval-rmse:3.8902\ttrain-rmse:2.00316\n",
      "[12812]\teval-rmse:3.88843\ttrain-rmse:2.00306\n",
      "[12813]\teval-rmse:3.88989\ttrain-rmse:2.00317\n",
      "[12814]\teval-rmse:3.89073\ttrain-rmse:2.00324\n",
      "[12815]\teval-rmse:3.88989\ttrain-rmse:2.0032\n",
      "[12816]\teval-rmse:3.89155\ttrain-rmse:2.00334\n",
      "[12817]\teval-rmse:3.89351\ttrain-rmse:2.00334\n",
      "[12818]\teval-rmse:3.89479\ttrain-rmse:2.0034\n",
      "[12819]\teval-rmse:3.89548\ttrain-rmse:2.00345\n",
      "[12820]\teval-rmse:3.89662\ttrain-rmse:2.00355\n",
      "[12821]\teval-rmse:3.89663\ttrain-rmse:2.00355\n",
      "[12822]\teval-rmse:3.89848\ttrain-rmse:2.0037\n",
      "[12823]\teval-rmse:3.89726\ttrain-rmse:2.00365\n",
      "[12824]\teval-rmse:3.8966\ttrain-rmse:2.00348\n",
      "[12825]\teval-rmse:3.89698\ttrain-rmse:2.00351\n",
      "[12826]\teval-rmse:3.89786\ttrain-rmse:2.00358\n",
      "[12827]\teval-rmse:3.89694\ttrain-rmse:2.00349\n",
      "[12828]\teval-rmse:3.89675\ttrain-rmse:2.00347\n",
      "[12829]\teval-rmse:3.89781\ttrain-rmse:2.00358\n",
      "[12830]\teval-rmse:3.89809\ttrain-rmse:2.00361\n",
      "[12831]\teval-rmse:3.89832\ttrain-rmse:2.00363\n",
      "[12832]\teval-rmse:3.89947\ttrain-rmse:2.00373\n",
      "[12833]\teval-rmse:3.89909\ttrain-rmse:2.00371\n",
      "[12834]\teval-rmse:3.89907\ttrain-rmse:2.00371\n",
      "[12835]\teval-rmse:3.89841\ttrain-rmse:2.00365\n",
      "[12836]\teval-rmse:3.89642\ttrain-rmse:2.00349\n",
      "[12837]\teval-rmse:3.89717\ttrain-rmse:2.00356\n",
      "[12838]\teval-rmse:3.89803\ttrain-rmse:2.00366\n",
      "[12839]\teval-rmse:3.89575\ttrain-rmse:2.00342\n",
      "[12840]\teval-rmse:3.8951\ttrain-rmse:2.00339\n",
      "[12841]\teval-rmse:3.8955\ttrain-rmse:2.00343\n",
      "[12842]\teval-rmse:3.8965\ttrain-rmse:2.00347\n",
      "[12843]\teval-rmse:3.89584\ttrain-rmse:2.00345\n",
      "[12844]\teval-rmse:3.89603\ttrain-rmse:2.00347\n",
      "[12845]\teval-rmse:3.89512\ttrain-rmse:2.00341\n",
      "[12846]\teval-rmse:3.89372\ttrain-rmse:2.00333\n",
      "[12847]\teval-rmse:3.892\ttrain-rmse:2.0033\n",
      "[12848]\teval-rmse:3.89053\ttrain-rmse:2.00323\n",
      "[12849]\teval-rmse:3.89249\ttrain-rmse:2.00331\n",
      "[12850]\teval-rmse:3.89138\ttrain-rmse:2.00325\n",
      "[12851]\teval-rmse:3.89134\ttrain-rmse:2.00324\n",
      "[12852]\teval-rmse:3.88938\ttrain-rmse:2.00307\n",
      "[12853]\teval-rmse:3.89044\ttrain-rmse:2.00316\n",
      "[12854]\teval-rmse:3.88905\ttrain-rmse:2.00314\n",
      "[12855]\teval-rmse:3.8899\ttrain-rmse:2.0032\n",
      "[12856]\teval-rmse:3.88873\ttrain-rmse:2.00312\n",
      "[12857]\teval-rmse:3.88718\ttrain-rmse:2.00306\n",
      "[12858]\teval-rmse:3.88721\ttrain-rmse:2.00306\n",
      "[12859]\teval-rmse:3.88693\ttrain-rmse:2.00304\n",
      "[12860]\teval-rmse:3.88758\ttrain-rmse:2.00306\n",
      "[12861]\teval-rmse:3.88944\ttrain-rmse:2.00313\n",
      "[12862]\teval-rmse:3.88766\ttrain-rmse:2.00302\n",
      "[12863]\teval-rmse:3.88914\ttrain-rmse:2.00314\n",
      "[12864]\teval-rmse:3.89082\ttrain-rmse:2.0032\n",
      "[12865]\teval-rmse:3.8925\ttrain-rmse:2.00328\n",
      "[12866]\teval-rmse:3.89158\ttrain-rmse:2.00323\n",
      "[12867]\teval-rmse:3.89311\ttrain-rmse:2.00337\n",
      "[12868]\teval-rmse:3.89376\ttrain-rmse:2.00343\n",
      "[12869]\teval-rmse:3.89216\ttrain-rmse:2.00335\n",
      "[12870]\teval-rmse:3.89323\ttrain-rmse:2.00342\n",
      "[12871]\teval-rmse:3.89211\ttrain-rmse:2.00332\n",
      "[12872]\teval-rmse:3.89406\ttrain-rmse:2.00332\n",
      "[12873]\teval-rmse:3.89569\ttrain-rmse:2.00344\n",
      "[12874]\teval-rmse:3.89723\ttrain-rmse:2.00345\n",
      "[12875]\teval-rmse:3.89658\ttrain-rmse:2.00341\n",
      "[12876]\teval-rmse:3.89458\ttrain-rmse:2.00321\n",
      "[12877]\teval-rmse:3.89305\ttrain-rmse:2.00311\n",
      "[12878]\teval-rmse:3.89294\ttrain-rmse:2.0031\n",
      "[12879]\teval-rmse:3.89229\ttrain-rmse:2.00307\n",
      "[12880]\teval-rmse:3.89191\ttrain-rmse:2.00305\n",
      "[12881]\teval-rmse:3.8937\ttrain-rmse:2.00313\n",
      "[12882]\teval-rmse:3.89548\ttrain-rmse:2.00322\n",
      "[12883]\teval-rmse:3.8964\ttrain-rmse:2.00331\n",
      "[12884]\teval-rmse:3.89607\ttrain-rmse:2.00328\n",
      "[12885]\teval-rmse:3.89448\ttrain-rmse:2.00316\n",
      "[12886]\teval-rmse:3.89241\ttrain-rmse:2.00301\n",
      "[12887]\teval-rmse:3.89425\ttrain-rmse:2.00302\n",
      "[12888]\teval-rmse:3.89403\ttrain-rmse:2.003\n",
      "[12889]\teval-rmse:3.8941\ttrain-rmse:2.00301\n",
      "[12890]\teval-rmse:3.89214\ttrain-rmse:2.0029\n",
      "[12891]\teval-rmse:3.89277\ttrain-rmse:2.00296\n",
      "[12892]\teval-rmse:3.89066\ttrain-rmse:2.00278\n",
      "[12893]\teval-rmse:3.89221\ttrain-rmse:2.00284\n",
      "[12894]\teval-rmse:3.89034\ttrain-rmse:2.00272\n",
      "[12895]\teval-rmse:3.88955\ttrain-rmse:2.00266\n",
      "[12896]\teval-rmse:3.89151\ttrain-rmse:2.00266\n",
      "[12897]\teval-rmse:3.89087\ttrain-rmse:2.00249\n",
      "[12898]\teval-rmse:3.88904\ttrain-rmse:2.00235\n",
      "[12899]\teval-rmse:3.89012\ttrain-rmse:2.00243\n",
      "[12900]\teval-rmse:3.88948\ttrain-rmse:2.0024\n",
      "[12901]\teval-rmse:3.88708\ttrain-rmse:2.00223\n",
      "[12902]\teval-rmse:3.88915\ttrain-rmse:2.00227\n",
      "[12903]\teval-rmse:3.88714\ttrain-rmse:2.00213\n",
      "[12904]\teval-rmse:3.88779\ttrain-rmse:2.00218\n",
      "[12905]\teval-rmse:3.88985\ttrain-rmse:2.00222\n",
      "[12906]\teval-rmse:3.89021\ttrain-rmse:2.00224\n",
      "[12907]\teval-rmse:3.8914\ttrain-rmse:2.00232\n",
      "[12908]\teval-rmse:3.89309\ttrain-rmse:2.00243\n",
      "[12909]\teval-rmse:3.89162\ttrain-rmse:2.00236\n",
      "[12910]\teval-rmse:3.89186\ttrain-rmse:2.00238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12911]\teval-rmse:3.89307\ttrain-rmse:2.00247\n",
      "[12912]\teval-rmse:3.89284\ttrain-rmse:2.00245\n",
      "[12913]\teval-rmse:3.89095\ttrain-rmse:2.00234\n",
      "[12914]\teval-rmse:3.88931\ttrain-rmse:2.00224\n",
      "[12915]\teval-rmse:3.8876\ttrain-rmse:2.00213\n",
      "[12916]\teval-rmse:3.88799\ttrain-rmse:2.00215\n",
      "[12917]\teval-rmse:3.89005\ttrain-rmse:2.00219\n",
      "[12918]\teval-rmse:3.88905\ttrain-rmse:2.00213\n",
      "[12919]\teval-rmse:3.88852\ttrain-rmse:2.00211\n",
      "[12920]\teval-rmse:3.88834\ttrain-rmse:2.00209\n",
      "[12921]\teval-rmse:3.89013\ttrain-rmse:2.00219\n",
      "[12922]\teval-rmse:3.88904\ttrain-rmse:2.00213\n",
      "[12923]\teval-rmse:3.8903\ttrain-rmse:2.00222\n",
      "[12924]\teval-rmse:3.88985\ttrain-rmse:2.00219\n",
      "[12925]\teval-rmse:3.88902\ttrain-rmse:2.00215\n",
      "[12926]\teval-rmse:3.89108\ttrain-rmse:2.00219\n",
      "[12927]\teval-rmse:3.89187\ttrain-rmse:2.00225\n",
      "[12928]\teval-rmse:3.89124\ttrain-rmse:2.00207\n",
      "[12929]\teval-rmse:3.89061\ttrain-rmse:2.00187\n",
      "[12930]\teval-rmse:3.89247\ttrain-rmse:2.00188\n",
      "[12931]\teval-rmse:3.89128\ttrain-rmse:2.00183\n",
      "[12932]\teval-rmse:3.89104\ttrain-rmse:2.00183\n",
      "[12933]\teval-rmse:3.89147\ttrain-rmse:2.00186\n",
      "[12934]\teval-rmse:3.89127\ttrain-rmse:2.00185\n",
      "[12935]\teval-rmse:3.89229\ttrain-rmse:2.00189\n",
      "[12936]\teval-rmse:3.89062\ttrain-rmse:2.00179\n",
      "[12937]\teval-rmse:3.89099\ttrain-rmse:2.00181\n",
      "[12938]\teval-rmse:3.89213\ttrain-rmse:2.0019\n",
      "[12939]\teval-rmse:3.89224\ttrain-rmse:2.0019\n",
      "[12940]\teval-rmse:3.89269\ttrain-rmse:2.00193\n",
      "[12941]\teval-rmse:3.89198\ttrain-rmse:2.0019\n",
      "[12942]\teval-rmse:3.89328\ttrain-rmse:2.002\n",
      "[12943]\teval-rmse:3.89146\ttrain-rmse:2.00186\n",
      "[12944]\teval-rmse:3.89076\ttrain-rmse:2.00182\n",
      "[12945]\teval-rmse:3.88931\ttrain-rmse:2.00176\n",
      "[12946]\teval-rmse:3.89118\ttrain-rmse:2.00187\n",
      "[12947]\teval-rmse:3.89182\ttrain-rmse:2.00192\n",
      "[12948]\teval-rmse:3.89388\ttrain-rmse:2.00198\n",
      "[12949]\teval-rmse:3.89452\ttrain-rmse:2.002\n",
      "[12950]\teval-rmse:3.89572\ttrain-rmse:2.00208\n",
      "[12951]\teval-rmse:3.89415\ttrain-rmse:2.00198\n",
      "[12952]\teval-rmse:3.89296\ttrain-rmse:2.00194\n",
      "[12953]\teval-rmse:3.89177\ttrain-rmse:2.0019\n",
      "[12954]\teval-rmse:3.89113\ttrain-rmse:2.00188\n",
      "[12955]\teval-rmse:3.89236\ttrain-rmse:2.00198\n",
      "[12956]\teval-rmse:3.89013\ttrain-rmse:2.00182\n",
      "[12957]\teval-rmse:3.89131\ttrain-rmse:2.0019\n",
      "[12958]\teval-rmse:3.89067\ttrain-rmse:2.00189\n",
      "[12959]\teval-rmse:3.89158\ttrain-rmse:2.00196\n",
      "[12960]\teval-rmse:3.89088\ttrain-rmse:2.0019\n",
      "[12961]\teval-rmse:3.89093\ttrain-rmse:2.00191\n",
      "[12962]\teval-rmse:3.8921\ttrain-rmse:2.00199\n",
      "[12963]\teval-rmse:3.8913\ttrain-rmse:2.00194\n",
      "[12964]\teval-rmse:3.88991\ttrain-rmse:2.00192\n",
      "[12965]\teval-rmse:3.89111\ttrain-rmse:2.00199\n",
      "[12966]\teval-rmse:3.89289\ttrain-rmse:2.00207\n",
      "[12967]\teval-rmse:3.89409\ttrain-rmse:2.00215\n",
      "[12968]\teval-rmse:3.89546\ttrain-rmse:2.00227\n",
      "[12969]\teval-rmse:3.89444\ttrain-rmse:2.0022\n",
      "[12970]\teval-rmse:3.89373\ttrain-rmse:2.00216\n",
      "[12971]\teval-rmse:3.89424\ttrain-rmse:2.0022\n",
      "[12972]\teval-rmse:3.89217\ttrain-rmse:2.00207\n",
      "[12973]\teval-rmse:3.89061\ttrain-rmse:2.002\n",
      "[12974]\teval-rmse:3.8918\ttrain-rmse:2.00205\n",
      "[12975]\teval-rmse:3.89337\ttrain-rmse:2.00218\n",
      "[12976]\teval-rmse:3.89224\ttrain-rmse:2.00208\n",
      "[12977]\teval-rmse:3.89308\ttrain-rmse:2.00215\n",
      "[12978]\teval-rmse:3.89195\ttrain-rmse:2.0021\n",
      "[12979]\teval-rmse:3.89149\ttrain-rmse:2.00207\n",
      "[12980]\teval-rmse:3.89068\ttrain-rmse:2.002\n",
      "[12981]\teval-rmse:3.89015\ttrain-rmse:2.00196\n",
      "[12982]\teval-rmse:3.88982\ttrain-rmse:2.00195\n",
      "[12983]\teval-rmse:3.89047\ttrain-rmse:2.00197\n",
      "[12984]\teval-rmse:3.89202\ttrain-rmse:2.00197\n",
      "[12985]\teval-rmse:3.89317\ttrain-rmse:2.00206\n",
      "[12986]\teval-rmse:3.89305\ttrain-rmse:2.00205\n",
      "[12987]\teval-rmse:3.89267\ttrain-rmse:2.00202\n",
      "[12988]\teval-rmse:3.89052\ttrain-rmse:2.00185\n",
      "[12989]\teval-rmse:3.89018\ttrain-rmse:2.00184\n",
      "[12990]\teval-rmse:3.88901\ttrain-rmse:2.00176\n",
      "[12991]\teval-rmse:3.89107\ttrain-rmse:2.00181\n",
      "[12992]\teval-rmse:3.88885\ttrain-rmse:2.00166\n",
      "[12993]\teval-rmse:3.88759\ttrain-rmse:2.00165\n",
      "[12994]\teval-rmse:3.88917\ttrain-rmse:2.00176\n",
      "[12995]\teval-rmse:3.88898\ttrain-rmse:2.00175\n",
      "[12996]\teval-rmse:3.89022\ttrain-rmse:2.00183\n",
      "[12997]\teval-rmse:3.89086\ttrain-rmse:2.00185\n",
      "[12998]\teval-rmse:3.89022\ttrain-rmse:2.00183\n",
      "[12999]\teval-rmse:3.89137\ttrain-rmse:2.0019\n",
      "[13000]\teval-rmse:3.89109\ttrain-rmse:2.00188\n",
      "[13001]\teval-rmse:3.89048\ttrain-rmse:2.00185\n",
      "[13002]\teval-rmse:3.89124\ttrain-rmse:2.00189\n",
      "[13003]\teval-rmse:3.89014\ttrain-rmse:2.00184\n",
      "[13004]\teval-rmse:3.89089\ttrain-rmse:2.00189\n",
      "[13005]\teval-rmse:3.88918\ttrain-rmse:2.00176\n",
      "[13006]\teval-rmse:3.88856\ttrain-rmse:2.00174\n",
      "[13007]\teval-rmse:3.88748\ttrain-rmse:2.00169\n",
      "[13008]\teval-rmse:3.88918\ttrain-rmse:2.00175\n",
      "[13009]\teval-rmse:3.89039\ttrain-rmse:2.00183\n",
      "[13010]\teval-rmse:3.89113\ttrain-rmse:2.00189\n",
      "[13011]\teval-rmse:3.88993\ttrain-rmse:2.00182\n",
      "[13012]\teval-rmse:3.88969\ttrain-rmse:2.00181\n",
      "[13013]\teval-rmse:3.89115\ttrain-rmse:2.0019\n",
      "[13014]\teval-rmse:3.89124\ttrain-rmse:2.0019\n",
      "[13015]\teval-rmse:3.89034\ttrain-rmse:2.00186\n",
      "[13016]\teval-rmse:3.88876\ttrain-rmse:2.00177\n",
      "[13017]\teval-rmse:3.89022\ttrain-rmse:2.00186\n",
      "[13018]\teval-rmse:3.88925\ttrain-rmse:2.00178\n",
      "[13019]\teval-rmse:3.88732\ttrain-rmse:2.00171\n",
      "[13020]\teval-rmse:3.88746\ttrain-rmse:2.00172\n",
      "[13021]\teval-rmse:3.88512\ttrain-rmse:2.00159\n",
      "[13022]\teval-rmse:3.88501\ttrain-rmse:2.00158\n",
      "[13023]\teval-rmse:3.88439\ttrain-rmse:2.00157\n",
      "[13024]\teval-rmse:3.88386\ttrain-rmse:2.00154\n",
      "[13025]\teval-rmse:3.88412\ttrain-rmse:2.00156\n",
      "[13026]\teval-rmse:3.8827\ttrain-rmse:2.0015\n",
      "[13027]\teval-rmse:3.88477\ttrain-rmse:2.00153\n",
      "[13028]\teval-rmse:3.88545\ttrain-rmse:2.00156\n",
      "[13029]\teval-rmse:3.88428\ttrain-rmse:2.00153\n",
      "[13030]\teval-rmse:3.88444\ttrain-rmse:2.00154\n",
      "[13031]\teval-rmse:3.88545\ttrain-rmse:2.00158\n",
      "[13032]\teval-rmse:3.88627\ttrain-rmse:2.00162\n",
      "[13033]\teval-rmse:3.88683\ttrain-rmse:2.00166\n",
      "[13034]\teval-rmse:3.88687\ttrain-rmse:2.00166\n",
      "[13035]\teval-rmse:3.88709\ttrain-rmse:2.00168\n",
      "[13036]\teval-rmse:3.88593\ttrain-rmse:2.00166\n",
      "[13037]\teval-rmse:3.8858\ttrain-rmse:2.00165\n",
      "[13038]\teval-rmse:3.88501\ttrain-rmse:2.00161\n",
      "[13039]\teval-rmse:3.88469\ttrain-rmse:2.00159\n",
      "[13040]\teval-rmse:3.88535\ttrain-rmse:2.00162\n",
      "[13041]\teval-rmse:3.8851\ttrain-rmse:2.00161\n",
      "[13042]\teval-rmse:3.88498\ttrain-rmse:2.0016\n",
      "[13043]\teval-rmse:3.88685\ttrain-rmse:2.00169\n",
      "[13044]\teval-rmse:3.88871\ttrain-rmse:2.00179\n",
      "[13045]\teval-rmse:3.88799\ttrain-rmse:2.00174\n",
      "[13046]\teval-rmse:3.88958\ttrain-rmse:2.00183\n",
      "[13047]\teval-rmse:3.89115\ttrain-rmse:2.00195\n",
      "[13048]\teval-rmse:3.89028\ttrain-rmse:2.00189\n",
      "[13049]\teval-rmse:3.89105\ttrain-rmse:2.00194\n",
      "[13050]\teval-rmse:3.88918\ttrain-rmse:2.00183\n",
      "[13051]\teval-rmse:3.88857\ttrain-rmse:2.00182\n",
      "[13052]\teval-rmse:3.88623\ttrain-rmse:2.00167\n",
      "[13053]\teval-rmse:3.88648\ttrain-rmse:2.00168\n",
      "[13054]\teval-rmse:3.88817\ttrain-rmse:2.00174\n",
      "[13055]\teval-rmse:3.88617\ttrain-rmse:2.00162\n",
      "[13056]\teval-rmse:3.88453\ttrain-rmse:2.00154\n",
      "[13057]\teval-rmse:3.88622\ttrain-rmse:2.00159\n",
      "[13058]\teval-rmse:3.88802\ttrain-rmse:2.00166\n",
      "[13059]\teval-rmse:3.88916\ttrain-rmse:2.00172\n",
      "[13060]\teval-rmse:3.88906\ttrain-rmse:2.00171\n",
      "[13061]\teval-rmse:3.88758\ttrain-rmse:2.00162\n",
      "[13062]\teval-rmse:3.88562\ttrain-rmse:2.00152\n",
      "[13063]\teval-rmse:3.88502\ttrain-rmse:2.00134\n",
      "[13064]\teval-rmse:3.88441\ttrain-rmse:2.00115\n",
      "[13065]\teval-rmse:3.88582\ttrain-rmse:2.00119\n",
      "[13066]\teval-rmse:3.88512\ttrain-rmse:2.00116\n",
      "[13067]\teval-rmse:3.88578\ttrain-rmse:2.0012\n",
      "[13068]\teval-rmse:3.88737\ttrain-rmse:2.00128\n",
      "[13069]\teval-rmse:3.88714\ttrain-rmse:2.00127\n",
      "[13070]\teval-rmse:3.88759\ttrain-rmse:2.00129\n",
      "[13071]\teval-rmse:3.88585\ttrain-rmse:2.0012\n",
      "[13072]\teval-rmse:3.88791\ttrain-rmse:2.00123\n",
      "[13073]\teval-rmse:3.88835\ttrain-rmse:2.00127\n",
      "[13074]\teval-rmse:3.88707\ttrain-rmse:2.00125\n",
      "[13075]\teval-rmse:3.88795\ttrain-rmse:2.0013\n",
      "[13076]\teval-rmse:3.88795\ttrain-rmse:2.0013\n",
      "[13077]\teval-rmse:3.88678\ttrain-rmse:2.00123\n",
      "[13078]\teval-rmse:3.88771\ttrain-rmse:2.00129\n",
      "[13079]\teval-rmse:3.88738\ttrain-rmse:2.00128\n",
      "[13080]\teval-rmse:3.88821\ttrain-rmse:2.00134\n",
      "[13081]\teval-rmse:3.88596\ttrain-rmse:2.0012\n",
      "[13082]\teval-rmse:3.88713\ttrain-rmse:2.00126\n",
      "[13083]\teval-rmse:3.88524\ttrain-rmse:2.00116\n",
      "[13084]\teval-rmse:3.88377\ttrain-rmse:2.00109\n",
      "[13085]\teval-rmse:3.88301\ttrain-rmse:2.00107\n",
      "[13086]\teval-rmse:3.88378\ttrain-rmse:2.0011\n",
      "[13087]\teval-rmse:3.88319\ttrain-rmse:2.00089\n",
      "[13088]\teval-rmse:3.88341\ttrain-rmse:2.0009\n",
      "[13089]\teval-rmse:3.88377\ttrain-rmse:2.00091\n",
      "[13090]\teval-rmse:3.88547\ttrain-rmse:2.00099\n",
      "[13091]\teval-rmse:3.88466\ttrain-rmse:2.00095\n",
      "[13092]\teval-rmse:3.88567\ttrain-rmse:2.00102\n",
      "[13093]\teval-rmse:3.8834\ttrain-rmse:2.00089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13094]\teval-rmse:3.88249\ttrain-rmse:2.00085\n",
      "[13095]\teval-rmse:3.88291\ttrain-rmse:2.00087\n",
      "[13096]\teval-rmse:3.88477\ttrain-rmse:2.00095\n",
      "[13097]\teval-rmse:3.88353\ttrain-rmse:2.0009\n",
      "[13098]\teval-rmse:3.88456\ttrain-rmse:2.00088\n",
      "[13099]\teval-rmse:3.88341\ttrain-rmse:2.00086\n",
      "[13100]\teval-rmse:3.88314\ttrain-rmse:2.00085\n",
      "[13101]\teval-rmse:3.88391\ttrain-rmse:2.00088\n",
      "[13102]\teval-rmse:3.88173\ttrain-rmse:2.00078\n",
      "[13103]\teval-rmse:3.88294\ttrain-rmse:2.00083\n",
      "[13104]\teval-rmse:3.8843\ttrain-rmse:2.0009\n",
      "[13105]\teval-rmse:3.88369\ttrain-rmse:2.00089\n",
      "[13106]\teval-rmse:3.88309\ttrain-rmse:2.00088\n",
      "[13107]\teval-rmse:3.88486\ttrain-rmse:2.00097\n",
      "[13108]\teval-rmse:3.88343\ttrain-rmse:2.0009\n",
      "[13109]\teval-rmse:3.88471\ttrain-rmse:2.00098\n",
      "[13110]\teval-rmse:3.88571\ttrain-rmse:2.00104\n",
      "[13111]\teval-rmse:3.88543\ttrain-rmse:2.00102\n",
      "[13112]\teval-rmse:3.88748\ttrain-rmse:2.00106\n",
      "[13113]\teval-rmse:3.88754\ttrain-rmse:2.00106\n",
      "[13114]\teval-rmse:3.8877\ttrain-rmse:2.00107\n",
      "[13115]\teval-rmse:3.88708\ttrain-rmse:2.00106\n",
      "[13116]\teval-rmse:3.88752\ttrain-rmse:2.00108\n",
      "[13117]\teval-rmse:3.88636\ttrain-rmse:2.00106\n",
      "[13118]\teval-rmse:3.88803\ttrain-rmse:2.00118\n",
      "[13119]\teval-rmse:3.88811\ttrain-rmse:2.00118\n",
      "[13120]\teval-rmse:3.8875\ttrain-rmse:2.00101\n",
      "[13121]\teval-rmse:3.88931\ttrain-rmse:2.00109\n",
      "[13122]\teval-rmse:3.88961\ttrain-rmse:2.00111\n",
      "[13123]\teval-rmse:3.89075\ttrain-rmse:2.00119\n",
      "[13124]\teval-rmse:3.8911\ttrain-rmse:2.00121\n",
      "[13125]\teval-rmse:3.89239\ttrain-rmse:2.00127\n",
      "[13126]\teval-rmse:3.89272\ttrain-rmse:2.0013\n",
      "[13127]\teval-rmse:3.89238\ttrain-rmse:2.00128\n",
      "[13128]\teval-rmse:3.89256\ttrain-rmse:2.00129\n",
      "[13129]\teval-rmse:3.89356\ttrain-rmse:2.00134\n",
      "[13130]\teval-rmse:3.89308\ttrain-rmse:2.0013\n",
      "[13131]\teval-rmse:3.89197\ttrain-rmse:2.00122\n",
      "[13132]\teval-rmse:3.89312\ttrain-rmse:2.00132\n",
      "[13133]\teval-rmse:3.89412\ttrain-rmse:2.00132\n",
      "[13134]\teval-rmse:3.89615\ttrain-rmse:2.00138\n",
      "[13135]\teval-rmse:3.8963\ttrain-rmse:2.00139\n",
      "[13136]\teval-rmse:3.89442\ttrain-rmse:2.00129\n",
      "[13137]\teval-rmse:3.89331\ttrain-rmse:2.00122\n",
      "[13138]\teval-rmse:3.89527\ttrain-rmse:2.00133\n",
      "[13139]\teval-rmse:3.89462\ttrain-rmse:2.00129\n",
      "[13140]\teval-rmse:3.89421\ttrain-rmse:2.00126\n",
      "[13141]\teval-rmse:3.89391\ttrain-rmse:2.00124\n",
      "[13142]\teval-rmse:3.89166\ttrain-rmse:2.00107\n",
      "[13143]\teval-rmse:3.89216\ttrain-rmse:2.0011\n",
      "[13144]\teval-rmse:3.89143\ttrain-rmse:2.00106\n",
      "[13145]\teval-rmse:3.89243\ttrain-rmse:2.00106\n",
      "[13146]\teval-rmse:3.89208\ttrain-rmse:2.00105\n",
      "[13147]\teval-rmse:3.89355\ttrain-rmse:2.00115\n",
      "[13148]\teval-rmse:3.89332\ttrain-rmse:2.00113\n",
      "[13149]\teval-rmse:3.89457\ttrain-rmse:2.00122\n",
      "[13150]\teval-rmse:3.8957\ttrain-rmse:2.00131\n",
      "[13151]\teval-rmse:3.89338\ttrain-rmse:2.00115\n",
      "[13152]\teval-rmse:3.89316\ttrain-rmse:2.00113\n",
      "[13153]\teval-rmse:3.89252\ttrain-rmse:2.00111\n",
      "[13154]\teval-rmse:3.89343\ttrain-rmse:2.00118\n",
      "[13155]\teval-rmse:3.89367\ttrain-rmse:2.0012\n",
      "[13156]\teval-rmse:3.89143\ttrain-rmse:2.00103\n",
      "[13157]\teval-rmse:3.89081\ttrain-rmse:2.00099\n",
      "[13158]\teval-rmse:3.89266\ttrain-rmse:2.00111\n",
      "[13159]\teval-rmse:3.8907\ttrain-rmse:2.00101\n",
      "[13160]\teval-rmse:3.88834\ttrain-rmse:2.00087\n",
      "[13161]\teval-rmse:3.88799\ttrain-rmse:2.00086\n",
      "[13162]\teval-rmse:3.88843\ttrain-rmse:2.00089\n",
      "[13163]\teval-rmse:3.88903\ttrain-rmse:2.00093\n",
      "[13164]\teval-rmse:3.88794\ttrain-rmse:2.00086\n",
      "[13165]\teval-rmse:3.88649\ttrain-rmse:2.00078\n",
      "[13166]\teval-rmse:3.88815\ttrain-rmse:2.00087\n",
      "[13167]\teval-rmse:3.88813\ttrain-rmse:2.00087\n",
      "[13168]\teval-rmse:3.88973\ttrain-rmse:2.00097\n",
      "[13169]\teval-rmse:3.89047\ttrain-rmse:2.00102\n",
      "[13170]\teval-rmse:3.88881\ttrain-rmse:2.00092\n",
      "[13171]\teval-rmse:3.88817\ttrain-rmse:2.0009\n",
      "[13172]\teval-rmse:3.88944\ttrain-rmse:2.00098\n",
      "[13173]\teval-rmse:3.89008\ttrain-rmse:2.00102\n",
      "[13174]\teval-rmse:3.89021\ttrain-rmse:2.00102\n",
      "[13175]\teval-rmse:3.88976\ttrain-rmse:2.001\n",
      "[13176]\teval-rmse:3.88933\ttrain-rmse:2.00097\n",
      "[13177]\teval-rmse:3.89054\ttrain-rmse:2.00107\n",
      "[13178]\teval-rmse:3.88894\ttrain-rmse:2.00097\n",
      "[13179]\teval-rmse:3.88798\ttrain-rmse:2.00091\n",
      "[13180]\teval-rmse:3.88584\ttrain-rmse:2.00079\n",
      "[13181]\teval-rmse:3.88666\ttrain-rmse:2.00084\n",
      "[13182]\teval-rmse:3.887\ttrain-rmse:2.00085\n",
      "[13183]\teval-rmse:3.88718\ttrain-rmse:2.00087\n",
      "[13184]\teval-rmse:3.88754\ttrain-rmse:2.00089\n",
      "[13185]\teval-rmse:3.88933\ttrain-rmse:2.00101\n",
      "[13186]\teval-rmse:3.89024\ttrain-rmse:2.00107\n",
      "[13187]\teval-rmse:3.88847\ttrain-rmse:2.00096\n",
      "[13188]\teval-rmse:3.8889\ttrain-rmse:2.00099\n",
      "[13189]\teval-rmse:3.88808\ttrain-rmse:2.00094\n",
      "[13190]\teval-rmse:3.88882\ttrain-rmse:2.00098\n",
      "[13191]\teval-rmse:3.89066\ttrain-rmse:2.001\n",
      "[13192]\teval-rmse:3.89003\ttrain-rmse:2.00081\n",
      "[13193]\teval-rmse:3.89169\ttrain-rmse:2.00094\n",
      "[13194]\teval-rmse:3.88964\ttrain-rmse:2.00081\n",
      "[13195]\teval-rmse:3.89075\ttrain-rmse:2.0009\n",
      "[13196]\teval-rmse:3.8927\ttrain-rmse:2.001\n",
      "[13197]\teval-rmse:3.89122\ttrain-rmse:2.00092\n",
      "[13198]\teval-rmse:3.88966\ttrain-rmse:2.0008\n",
      "[13199]\teval-rmse:3.88876\ttrain-rmse:2.00074\n",
      "[13200]\teval-rmse:3.88891\ttrain-rmse:2.00075\n",
      "[13201]\teval-rmse:3.89047\ttrain-rmse:2.00076\n",
      "[13202]\teval-rmse:3.88966\ttrain-rmse:2.00072\n",
      "[13203]\teval-rmse:3.88873\ttrain-rmse:2.00066\n",
      "[13204]\teval-rmse:3.88957\ttrain-rmse:2.0007\n",
      "[13205]\teval-rmse:3.88952\ttrain-rmse:2.0007\n",
      "[13206]\teval-rmse:3.89052\ttrain-rmse:2.0007\n",
      "[13207]\teval-rmse:3.88989\ttrain-rmse:2.00053\n",
      "[13208]\teval-rmse:3.89156\ttrain-rmse:2.00065\n",
      "[13209]\teval-rmse:3.89118\ttrain-rmse:2.00063\n",
      "[13210]\teval-rmse:3.89078\ttrain-rmse:2.0006\n",
      "[13211]\teval-rmse:3.89284\ttrain-rmse:2.00067\n",
      "[13212]\teval-rmse:3.89374\ttrain-rmse:2.00074\n",
      "[13213]\teval-rmse:3.89427\ttrain-rmse:2.00078\n",
      "[13214]\teval-rmse:3.89525\ttrain-rmse:2.00079\n",
      "[13215]\teval-rmse:3.89461\ttrain-rmse:2.00077\n",
      "[13216]\teval-rmse:3.89399\ttrain-rmse:2.00059\n",
      "[13217]\teval-rmse:3.89199\ttrain-rmse:2.00045\n",
      "[13218]\teval-rmse:3.892\ttrain-rmse:2.00045\n",
      "[13219]\teval-rmse:3.88974\ttrain-rmse:2.00031\n",
      "[13220]\teval-rmse:3.88954\ttrain-rmse:2.00029\n",
      "[13221]\teval-rmse:3.89132\ttrain-rmse:2.00038\n",
      "[13222]\teval-rmse:3.89203\ttrain-rmse:2.00044\n",
      "[13223]\teval-rmse:3.89044\ttrain-rmse:2.00034\n",
      "[13224]\teval-rmse:3.88837\ttrain-rmse:2.00019\n",
      "[13225]\teval-rmse:3.89021\ttrain-rmse:2.00027\n",
      "[13226]\teval-rmse:3.88852\ttrain-rmse:2.00019\n",
      "[13227]\teval-rmse:3.8865\ttrain-rmse:2.00008\n",
      "[13228]\teval-rmse:3.88617\ttrain-rmse:2.00007\n",
      "[13229]\teval-rmse:3.88745\ttrain-rmse:2.00016\n",
      "[13230]\teval-rmse:3.88941\ttrain-rmse:2.00027\n",
      "[13231]\teval-rmse:3.88708\ttrain-rmse:2.00014\n",
      "[13232]\teval-rmse:3.88572\ttrain-rmse:2.00006\n",
      "[13233]\teval-rmse:3.88551\ttrain-rmse:2.00005\n",
      "[13234]\teval-rmse:3.88508\ttrain-rmse:2.00003\n",
      "[13235]\teval-rmse:3.88448\ttrain-rmse:2.00002\n",
      "[13236]\teval-rmse:3.88302\ttrain-rmse:1.99995\n",
      "[13237]\teval-rmse:3.88279\ttrain-rmse:1.99994\n",
      "[13238]\teval-rmse:3.88322\ttrain-rmse:1.99996\n",
      "[13239]\teval-rmse:3.88516\ttrain-rmse:1.99996\n",
      "[13240]\teval-rmse:3.88526\ttrain-rmse:1.99996\n",
      "[13241]\teval-rmse:3.88465\ttrain-rmse:1.99994\n",
      "[13242]\teval-rmse:3.88298\ttrain-rmse:1.99985\n",
      "[13243]\teval-rmse:3.88336\ttrain-rmse:1.99986\n",
      "[13244]\teval-rmse:3.88392\ttrain-rmse:1.99989\n",
      "[13245]\teval-rmse:3.88332\ttrain-rmse:1.9997\n",
      "[13246]\teval-rmse:3.88405\ttrain-rmse:1.99974\n",
      "[13247]\teval-rmse:3.88585\ttrain-rmse:1.9998\n",
      "[13248]\teval-rmse:3.88389\ttrain-rmse:1.99971\n",
      "[13249]\teval-rmse:3.88464\ttrain-rmse:1.99974\n",
      "[13250]\teval-rmse:3.88566\ttrain-rmse:1.99979\n",
      "[13251]\teval-rmse:3.88542\ttrain-rmse:1.99978\n",
      "[13252]\teval-rmse:3.88748\ttrain-rmse:1.99983\n",
      "[13253]\teval-rmse:3.88917\ttrain-rmse:1.9999\n",
      "[13254]\teval-rmse:3.88937\ttrain-rmse:1.99991\n",
      "[13255]\teval-rmse:3.89075\ttrain-rmse:2.00001\n",
      "[13256]\teval-rmse:3.8927\ttrain-rmse:2.00011\n",
      "[13257]\teval-rmse:3.891\ttrain-rmse:2.00007\n",
      "[13258]\teval-rmse:3.89255\ttrain-rmse:2.00009\n",
      "[13259]\teval-rmse:3.89183\ttrain-rmse:2.00006\n",
      "[13260]\teval-rmse:3.89097\ttrain-rmse:2\n",
      "[13261]\teval-rmse:3.89171\ttrain-rmse:2.00006\n",
      "[13262]\teval-rmse:3.89053\ttrain-rmse:1.99996\n",
      "[13263]\teval-rmse:3.8926\ttrain-rmse:2.00003\n",
      "[13264]\teval-rmse:3.8936\ttrain-rmse:2.00011\n",
      "[13265]\teval-rmse:3.89491\ttrain-rmse:2.00021\n",
      "[13266]\teval-rmse:3.89378\ttrain-rmse:2.00013\n",
      "[13267]\teval-rmse:3.89256\ttrain-rmse:2.00009\n",
      "[13268]\teval-rmse:3.8911\ttrain-rmse:2\n",
      "[13269]\teval-rmse:3.89062\ttrain-rmse:1.99997\n",
      "[13270]\teval-rmse:3.89151\ttrain-rmse:2.00004\n",
      "[13271]\teval-rmse:3.89233\ttrain-rmse:2.0001\n",
      "[13272]\teval-rmse:3.89101\ttrain-rmse:2.00002\n",
      "[13273]\teval-rmse:3.88972\ttrain-rmse:1.99995\n",
      "[13274]\teval-rmse:3.88961\ttrain-rmse:1.99994\n",
      "[13275]\teval-rmse:3.89005\ttrain-rmse:1.99997\n",
      "[13276]\teval-rmse:3.89108\ttrain-rmse:2.00004\n",
      "[13277]\teval-rmse:3.89209\ttrain-rmse:2.00013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13278]\teval-rmse:3.89402\ttrain-rmse:2.00015\n",
      "[13279]\teval-rmse:3.89353\ttrain-rmse:2.00011\n",
      "[13280]\teval-rmse:3.89437\ttrain-rmse:2.00017\n",
      "[13281]\teval-rmse:3.89195\ttrain-rmse:1.99999\n",
      "[13282]\teval-rmse:3.89182\ttrain-rmse:1.99998\n",
      "[13283]\teval-rmse:3.89006\ttrain-rmse:1.99985\n",
      "[13284]\teval-rmse:3.88847\ttrain-rmse:1.99976\n",
      "[13285]\teval-rmse:3.8887\ttrain-rmse:1.99977\n",
      "[13286]\teval-rmse:3.88922\ttrain-rmse:1.99981\n",
      "[13287]\teval-rmse:3.88852\ttrain-rmse:1.99976\n",
      "[13288]\teval-rmse:3.88781\ttrain-rmse:1.99972\n",
      "[13289]\teval-rmse:3.88916\ttrain-rmse:1.99981\n",
      "[13290]\teval-rmse:3.89075\ttrain-rmse:1.9999\n",
      "[13291]\teval-rmse:3.89089\ttrain-rmse:1.99991\n",
      "[13292]\teval-rmse:3.89173\ttrain-rmse:1.99995\n",
      "[13293]\teval-rmse:3.89321\ttrain-rmse:2.00006\n",
      "[13294]\teval-rmse:3.89383\ttrain-rmse:2.0001\n",
      "[13295]\teval-rmse:3.89317\ttrain-rmse:2.00007\n",
      "[13296]\teval-rmse:3.89253\ttrain-rmse:1.99986\n",
      "[13297]\teval-rmse:3.89054\ttrain-rmse:1.99971\n",
      "[13298]\teval-rmse:3.88836\ttrain-rmse:1.99957\n",
      "[13299]\teval-rmse:3.88757\ttrain-rmse:1.99953\n",
      "[13300]\teval-rmse:3.88793\ttrain-rmse:1.99955\n",
      "[13301]\teval-rmse:3.88988\ttrain-rmse:1.99957\n",
      "[13302]\teval-rmse:3.89147\ttrain-rmse:1.99967\n",
      "[13303]\teval-rmse:3.89352\ttrain-rmse:1.99975\n",
      "[13304]\teval-rmse:3.89164\ttrain-rmse:1.9996\n",
      "[13305]\teval-rmse:3.89054\ttrain-rmse:1.99952\n",
      "[13306]\teval-rmse:3.88829\ttrain-rmse:1.99938\n",
      "[13307]\teval-rmse:3.88843\ttrain-rmse:1.99939\n",
      "[13308]\teval-rmse:3.8878\ttrain-rmse:1.9992\n",
      "[13309]\teval-rmse:3.88976\ttrain-rmse:1.99929\n",
      "[13310]\teval-rmse:3.8894\ttrain-rmse:1.99926\n",
      "[13311]\teval-rmse:3.88823\ttrain-rmse:1.99918\n",
      "[13312]\teval-rmse:3.88631\ttrain-rmse:1.99908\n",
      "[13313]\teval-rmse:3.88724\ttrain-rmse:1.99913\n",
      "[13314]\teval-rmse:3.88541\ttrain-rmse:1.99901\n",
      "[13315]\teval-rmse:3.88598\ttrain-rmse:1.99904\n",
      "[13316]\teval-rmse:3.88454\ttrain-rmse:1.99898\n",
      "[13317]\teval-rmse:3.88558\ttrain-rmse:1.99902\n",
      "[13318]\teval-rmse:3.8847\ttrain-rmse:1.99898\n",
      "[13319]\teval-rmse:3.88343\ttrain-rmse:1.99897\n",
      "[13320]\teval-rmse:3.88436\ttrain-rmse:1.99901\n",
      "[13321]\teval-rmse:3.884\ttrain-rmse:1.999\n",
      "[13322]\teval-rmse:3.8819\ttrain-rmse:1.99889\n",
      "[13323]\teval-rmse:3.88255\ttrain-rmse:1.99892\n",
      "[13324]\teval-rmse:3.88461\ttrain-rmse:1.99896\n",
      "[13325]\teval-rmse:3.88645\ttrain-rmse:1.99896\n",
      "[13326]\teval-rmse:3.88804\ttrain-rmse:1.99903\n",
      "[13327]\teval-rmse:3.88898\ttrain-rmse:1.99907\n",
      "[13328]\teval-rmse:3.88879\ttrain-rmse:1.99907\n",
      "[13329]\teval-rmse:3.88889\ttrain-rmse:1.99907\n",
      "[13330]\teval-rmse:3.88668\ttrain-rmse:1.99896\n",
      "[13331]\teval-rmse:3.88849\ttrain-rmse:1.99905\n",
      "[13332]\teval-rmse:3.88741\ttrain-rmse:1.999\n",
      "[13333]\teval-rmse:3.88557\ttrain-rmse:1.99891\n",
      "[13334]\teval-rmse:3.88563\ttrain-rmse:1.99891\n",
      "[13335]\teval-rmse:3.88759\ttrain-rmse:1.999\n",
      "[13336]\teval-rmse:3.88881\ttrain-rmse:1.99905\n",
      "[13337]\teval-rmse:3.88763\ttrain-rmse:1.99902\n",
      "[13338]\teval-rmse:3.88945\ttrain-rmse:1.99911\n",
      "[13339]\teval-rmse:3.89079\ttrain-rmse:1.99919\n",
      "[13340]\teval-rmse:3.89056\ttrain-rmse:1.99918\n",
      "[13341]\teval-rmse:3.89012\ttrain-rmse:1.99916\n",
      "[13342]\teval-rmse:3.88887\ttrain-rmse:1.99908\n",
      "[13343]\teval-rmse:3.88961\ttrain-rmse:1.99912\n",
      "[13344]\teval-rmse:3.89064\ttrain-rmse:1.99917\n",
      "[13345]\teval-rmse:3.89001\ttrain-rmse:1.99914\n",
      "[13346]\teval-rmse:3.89114\ttrain-rmse:1.9992\n",
      "[13347]\teval-rmse:3.89066\ttrain-rmse:1.99918\n",
      "[13348]\teval-rmse:3.89189\ttrain-rmse:1.99926\n",
      "[13349]\teval-rmse:3.89321\ttrain-rmse:1.99934\n",
      "[13350]\teval-rmse:3.89284\ttrain-rmse:1.99933\n",
      "[13351]\teval-rmse:3.89282\ttrain-rmse:1.99933\n",
      "[13352]\teval-rmse:3.89355\ttrain-rmse:1.99937\n",
      "[13353]\teval-rmse:3.89244\ttrain-rmse:1.99931\n",
      "[13354]\teval-rmse:3.8918\ttrain-rmse:1.99928\n",
      "[13355]\teval-rmse:3.89116\ttrain-rmse:1.99926\n",
      "[13356]\teval-rmse:3.8909\ttrain-rmse:1.99925\n",
      "[13357]\teval-rmse:3.89126\ttrain-rmse:1.99927\n",
      "[13358]\teval-rmse:3.89265\ttrain-rmse:1.99935\n",
      "[13359]\teval-rmse:3.89393\ttrain-rmse:1.99943\n",
      "[13360]\teval-rmse:3.8923\ttrain-rmse:1.99933\n",
      "[13361]\teval-rmse:3.89435\ttrain-rmse:1.9994\n",
      "[13362]\teval-rmse:3.8947\ttrain-rmse:1.99942\n",
      "[13363]\teval-rmse:3.89299\ttrain-rmse:1.99933\n",
      "[13364]\teval-rmse:3.89503\ttrain-rmse:1.9994\n",
      "[13365]\teval-rmse:3.8968\ttrain-rmse:1.99953\n",
      "[13366]\teval-rmse:3.89702\ttrain-rmse:1.99954\n",
      "[13367]\teval-rmse:3.89744\ttrain-rmse:1.99957\n",
      "[13368]\teval-rmse:3.89899\ttrain-rmse:1.99968\n",
      "[13369]\teval-rmse:3.8983\ttrain-rmse:1.99965\n",
      "[13370]\teval-rmse:3.89603\ttrain-rmse:1.99951\n",
      "[13371]\teval-rmse:3.89405\ttrain-rmse:1.99937\n",
      "[13372]\teval-rmse:3.89536\ttrain-rmse:1.99946\n",
      "[13373]\teval-rmse:3.89496\ttrain-rmse:1.99944\n",
      "[13374]\teval-rmse:3.89646\ttrain-rmse:1.99955\n",
      "[13375]\teval-rmse:3.89613\ttrain-rmse:1.99953\n",
      "[13376]\teval-rmse:3.89745\ttrain-rmse:1.99963\n",
      "[13377]\teval-rmse:3.89678\ttrain-rmse:1.99959\n",
      "[13378]\teval-rmse:3.89639\ttrain-rmse:1.99957\n",
      "[13379]\teval-rmse:3.89566\ttrain-rmse:1.99952\n",
      "[13380]\teval-rmse:3.896\ttrain-rmse:1.99955\n",
      "[13381]\teval-rmse:3.89533\ttrain-rmse:1.99935\n",
      "[13382]\teval-rmse:3.89655\ttrain-rmse:1.99944\n",
      "[13383]\teval-rmse:3.8944\ttrain-rmse:1.99929\n",
      "[13384]\teval-rmse:3.89226\ttrain-rmse:1.99914\n",
      "[13385]\teval-rmse:3.89225\ttrain-rmse:1.99914\n",
      "[13386]\teval-rmse:3.8916\ttrain-rmse:1.99895\n",
      "[13387]\teval-rmse:3.89029\ttrain-rmse:1.99892\n",
      "[13388]\teval-rmse:3.88889\ttrain-rmse:1.99884\n",
      "[13389]\teval-rmse:3.88889\ttrain-rmse:1.99884\n",
      "[13390]\teval-rmse:3.88827\ttrain-rmse:1.99881\n",
      "[13391]\teval-rmse:3.88937\ttrain-rmse:1.99887\n",
      "[13392]\teval-rmse:3.88874\ttrain-rmse:1.99867\n",
      "[13393]\teval-rmse:3.8867\ttrain-rmse:1.99856\n",
      "[13394]\teval-rmse:3.88474\ttrain-rmse:1.99846\n",
      "[13395]\teval-rmse:3.88398\ttrain-rmse:1.99843\n",
      "[13396]\teval-rmse:3.88235\ttrain-rmse:1.99834\n",
      "[13397]\teval-rmse:3.88395\ttrain-rmse:1.99839\n",
      "[13398]\teval-rmse:3.88309\ttrain-rmse:1.99836\n",
      "[13399]\teval-rmse:3.88411\ttrain-rmse:1.99842\n",
      "[13400]\teval-rmse:3.88351\ttrain-rmse:1.99841\n",
      "[13401]\teval-rmse:3.88308\ttrain-rmse:1.99839\n",
      "[13402]\teval-rmse:3.88193\ttrain-rmse:1.99837\n",
      "[13403]\teval-rmse:3.87983\ttrain-rmse:1.99828\n",
      "[13404]\teval-rmse:3.88006\ttrain-rmse:1.99829\n",
      "[13405]\teval-rmse:3.88045\ttrain-rmse:1.9983\n",
      "[13406]\teval-rmse:3.88145\ttrain-rmse:1.9983\n",
      "[13407]\teval-rmse:3.8811\ttrain-rmse:1.99828\n",
      "[13408]\teval-rmse:3.88147\ttrain-rmse:1.99829\n",
      "[13409]\teval-rmse:3.88063\ttrain-rmse:1.99826\n",
      "[13410]\teval-rmse:3.87922\ttrain-rmse:1.99821\n",
      "[13411]\teval-rmse:3.87808\ttrain-rmse:1.99819\n",
      "[13412]\teval-rmse:3.87819\ttrain-rmse:1.99819\n",
      "[13413]\teval-rmse:3.87658\ttrain-rmse:1.99821\n",
      "[13414]\teval-rmse:3.87519\ttrain-rmse:1.99818\n",
      "[13415]\teval-rmse:3.87381\ttrain-rmse:1.99815\n",
      "[13416]\teval-rmse:3.87425\ttrain-rmse:1.99816\n",
      "[13417]\teval-rmse:3.87369\ttrain-rmse:1.99798\n",
      "[13418]\teval-rmse:3.87288\ttrain-rmse:1.99796\n",
      "[13419]\teval-rmse:3.87292\ttrain-rmse:1.99796\n",
      "[13420]\teval-rmse:3.87458\ttrain-rmse:1.998\n",
      "[13421]\teval-rmse:3.87591\ttrain-rmse:1.99804\n",
      "[13422]\teval-rmse:3.87424\ttrain-rmse:1.99797\n",
      "[13423]\teval-rmse:3.87457\ttrain-rmse:1.99798\n",
      "[13424]\teval-rmse:3.87601\ttrain-rmse:1.99802\n",
      "[13425]\teval-rmse:3.87686\ttrain-rmse:1.99805\n",
      "[13426]\teval-rmse:3.87827\ttrain-rmse:1.99809\n",
      "[13427]\teval-rmse:3.87693\ttrain-rmse:1.99805\n",
      "[13428]\teval-rmse:3.87796\ttrain-rmse:1.99803\n",
      "[13429]\teval-rmse:3.87723\ttrain-rmse:1.99801\n",
      "[13430]\teval-rmse:3.87716\ttrain-rmse:1.998\n",
      "[13431]\teval-rmse:3.87812\ttrain-rmse:1.99804\n",
      "[13432]\teval-rmse:3.87651\ttrain-rmse:1.998\n",
      "[13433]\teval-rmse:3.87593\ttrain-rmse:1.99799\n",
      "[13434]\teval-rmse:3.87407\ttrain-rmse:1.99792\n",
      "[13435]\teval-rmse:3.87246\ttrain-rmse:1.99788\n",
      "[13436]\teval-rmse:3.8735\ttrain-rmse:1.9979\n",
      "[13437]\teval-rmse:3.87446\ttrain-rmse:1.99793\n",
      "[13438]\teval-rmse:3.87625\ttrain-rmse:1.99798\n",
      "[13439]\teval-rmse:3.8772\ttrain-rmse:1.99802\n",
      "[13440]\teval-rmse:3.87905\ttrain-rmse:1.998\n",
      "[13441]\teval-rmse:3.88027\ttrain-rmse:1.99804\n",
      "[13442]\teval-rmse:3.87859\ttrain-rmse:1.99798\n",
      "[13443]\teval-rmse:3.8787\ttrain-rmse:1.99799\n",
      "[13444]\teval-rmse:3.87994\ttrain-rmse:1.99803\n",
      "[13445]\teval-rmse:3.88116\ttrain-rmse:1.99808\n",
      "[13446]\teval-rmse:3.88191\ttrain-rmse:1.99811\n",
      "[13447]\teval-rmse:3.88186\ttrain-rmse:1.99811\n",
      "[13448]\teval-rmse:3.88206\ttrain-rmse:1.99812\n",
      "[13449]\teval-rmse:3.88021\ttrain-rmse:1.99804\n",
      "[13450]\teval-rmse:3.879\ttrain-rmse:1.99798\n",
      "[13451]\teval-rmse:3.88106\ttrain-rmse:1.99801\n",
      "[13452]\teval-rmse:3.88179\ttrain-rmse:1.99804\n",
      "[13453]\teval-rmse:3.88121\ttrain-rmse:1.99784\n",
      "[13454]\teval-rmse:3.88205\ttrain-rmse:1.99788\n",
      "[13455]\teval-rmse:3.88383\ttrain-rmse:1.99796\n",
      "[13456]\teval-rmse:3.88459\ttrain-rmse:1.998\n",
      "[13457]\teval-rmse:3.88296\ttrain-rmse:1.99792\n",
      "[13458]\teval-rmse:3.88302\ttrain-rmse:1.99792\n",
      "[13459]\teval-rmse:3.88109\ttrain-rmse:1.99784\n",
      "[13460]\teval-rmse:3.88315\ttrain-rmse:1.99788\n",
      "[13461]\teval-rmse:3.88361\ttrain-rmse:1.9979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13462]\teval-rmse:3.88418\ttrain-rmse:1.99793\n",
      "[13463]\teval-rmse:3.88573\ttrain-rmse:1.99801\n",
      "[13464]\teval-rmse:3.88527\ttrain-rmse:1.99798\n",
      "[13465]\teval-rmse:3.88733\ttrain-rmse:1.99809\n",
      "[13466]\teval-rmse:3.88566\ttrain-rmse:1.99802\n",
      "[13467]\teval-rmse:3.88771\ttrain-rmse:1.99807\n",
      "[13468]\teval-rmse:3.88811\ttrain-rmse:1.99809\n",
      "[13469]\teval-rmse:3.8875\ttrain-rmse:1.99807\n",
      "[13470]\teval-rmse:3.88863\ttrain-rmse:1.99813\n",
      "[13471]\teval-rmse:3.88919\ttrain-rmse:1.99816\n",
      "[13472]\teval-rmse:3.8899\ttrain-rmse:1.99821\n",
      "[13473]\teval-rmse:3.89173\ttrain-rmse:1.9983\n",
      "[13474]\teval-rmse:3.89366\ttrain-rmse:1.99834\n",
      "[13475]\teval-rmse:3.89159\ttrain-rmse:1.99822\n",
      "[13476]\teval-rmse:3.89059\ttrain-rmse:1.99816\n",
      "[13477]\teval-rmse:3.88939\ttrain-rmse:1.99812\n",
      "[13478]\teval-rmse:3.8901\ttrain-rmse:1.99816\n",
      "[13479]\teval-rmse:3.89214\ttrain-rmse:1.99823\n",
      "[13480]\teval-rmse:3.89329\ttrain-rmse:1.99831\n",
      "[13481]\teval-rmse:3.89247\ttrain-rmse:1.99825\n",
      "[13482]\teval-rmse:3.89183\ttrain-rmse:1.99822\n",
      "[13483]\teval-rmse:3.89098\ttrain-rmse:1.99818\n",
      "[13484]\teval-rmse:3.89036\ttrain-rmse:1.99815\n",
      "[13485]\teval-rmse:3.89112\ttrain-rmse:1.9982\n",
      "[13486]\teval-rmse:3.89065\ttrain-rmse:1.99818\n",
      "[13487]\teval-rmse:3.89103\ttrain-rmse:1.99821\n",
      "[13488]\teval-rmse:3.89214\ttrain-rmse:1.99829\n",
      "[13489]\teval-rmse:3.89377\ttrain-rmse:1.99841\n",
      "[13490]\teval-rmse:3.89188\ttrain-rmse:1.99829\n",
      "[13491]\teval-rmse:3.89003\ttrain-rmse:1.99819\n",
      "[13492]\teval-rmse:3.88894\ttrain-rmse:1.99811\n",
      "[13493]\teval-rmse:3.88796\ttrain-rmse:1.99806\n",
      "[13494]\teval-rmse:3.88656\ttrain-rmse:1.998\n",
      "[13495]\teval-rmse:3.88731\ttrain-rmse:1.99804\n",
      "[13496]\teval-rmse:3.88823\ttrain-rmse:1.99809\n",
      "[13497]\teval-rmse:3.88754\ttrain-rmse:1.99805\n",
      "[13498]\teval-rmse:3.88691\ttrain-rmse:1.99803\n",
      "[13499]\teval-rmse:3.88525\ttrain-rmse:1.99795\n",
      "[13500]\teval-rmse:3.88668\ttrain-rmse:1.998\n",
      "[13501]\teval-rmse:3.88804\ttrain-rmse:1.99809\n",
      "[13502]\teval-rmse:3.88766\ttrain-rmse:1.99807\n",
      "[13503]\teval-rmse:3.88745\ttrain-rmse:1.99805\n",
      "[13504]\teval-rmse:3.88567\ttrain-rmse:1.99795\n",
      "[13505]\teval-rmse:3.88561\ttrain-rmse:1.99795\n",
      "[13506]\teval-rmse:3.88526\ttrain-rmse:1.99794\n",
      "[13507]\teval-rmse:3.88357\ttrain-rmse:1.99785\n",
      "[13508]\teval-rmse:3.88477\ttrain-rmse:1.99791\n",
      "[13509]\teval-rmse:3.88359\ttrain-rmse:1.99788\n",
      "[13510]\teval-rmse:3.88314\ttrain-rmse:1.99786\n",
      "[13511]\teval-rmse:3.8814\ttrain-rmse:1.99777\n",
      "[13512]\teval-rmse:3.88062\ttrain-rmse:1.99774\n",
      "[13513]\teval-rmse:3.88055\ttrain-rmse:1.99774\n",
      "[13514]\teval-rmse:3.88043\ttrain-rmse:1.99774\n",
      "[13515]\teval-rmse:3.87984\ttrain-rmse:1.99756\n",
      "[13516]\teval-rmse:3.88191\ttrain-rmse:1.9976\n",
      "[13517]\teval-rmse:3.88366\ttrain-rmse:1.99767\n",
      "[13518]\teval-rmse:3.88343\ttrain-rmse:1.99767\n",
      "[13519]\teval-rmse:3.88331\ttrain-rmse:1.99766\n",
      "[13520]\teval-rmse:3.88362\ttrain-rmse:1.99767\n",
      "[13521]\teval-rmse:3.88437\ttrain-rmse:1.99772\n",
      "[13522]\teval-rmse:3.88246\ttrain-rmse:1.99765\n",
      "[13523]\teval-rmse:3.88433\ttrain-rmse:1.99773\n",
      "[13524]\teval-rmse:3.88295\ttrain-rmse:1.99767\n",
      "[13525]\teval-rmse:3.88105\ttrain-rmse:1.99758\n",
      "[13526]\teval-rmse:3.8799\ttrain-rmse:1.99756\n",
      "[13527]\teval-rmse:3.88156\ttrain-rmse:1.99762\n",
      "[13528]\teval-rmse:3.88362\ttrain-rmse:1.99766\n",
      "[13529]\teval-rmse:3.88165\ttrain-rmse:1.99758\n",
      "[13530]\teval-rmse:3.88106\ttrain-rmse:1.9974\n",
      "[13531]\teval-rmse:3.88089\ttrain-rmse:1.99739\n",
      "[13532]\teval-rmse:3.87852\ttrain-rmse:1.99732\n",
      "[13533]\teval-rmse:3.87676\ttrain-rmse:1.99727\n",
      "[13534]\teval-rmse:3.87644\ttrain-rmse:1.99726\n",
      "[13535]\teval-rmse:3.87839\ttrain-rmse:1.9973\n",
      "[13536]\teval-rmse:3.87862\ttrain-rmse:1.99731\n",
      "[13537]\teval-rmse:3.87702\ttrain-rmse:1.99727\n",
      "[13538]\teval-rmse:3.87543\ttrain-rmse:1.99723\n",
      "[13539]\teval-rmse:3.87702\ttrain-rmse:1.99727\n",
      "[13540]\teval-rmse:3.87717\ttrain-rmse:1.99727\n",
      "[13541]\teval-rmse:3.87904\ttrain-rmse:1.99733\n",
      "[13542]\teval-rmse:3.87963\ttrain-rmse:1.99735\n",
      "[13543]\teval-rmse:3.87905\ttrain-rmse:1.99715\n",
      "[13544]\teval-rmse:3.87821\ttrain-rmse:1.99712\n",
      "[13545]\teval-rmse:3.87802\ttrain-rmse:1.99711\n",
      "[13546]\teval-rmse:3.87771\ttrain-rmse:1.99711\n",
      "[13547]\teval-rmse:3.87815\ttrain-rmse:1.99712\n",
      "[13548]\teval-rmse:3.87975\ttrain-rmse:1.99718\n",
      "[13549]\teval-rmse:3.8786\ttrain-rmse:1.99714\n",
      "[13550]\teval-rmse:3.88066\ttrain-rmse:1.99717\n",
      "[13551]\teval-rmse:3.87903\ttrain-rmse:1.99717\n",
      "[13552]\teval-rmse:3.87821\ttrain-rmse:1.99714\n",
      "[13553]\teval-rmse:3.8771\ttrain-rmse:1.99711\n",
      "[13554]\teval-rmse:3.87551\ttrain-rmse:1.99706\n",
      "[13555]\teval-rmse:3.876\ttrain-rmse:1.99708\n",
      "[13556]\teval-rmse:3.87761\ttrain-rmse:1.99712\n",
      "[13557]\teval-rmse:3.87681\ttrain-rmse:1.9971\n",
      "[13558]\teval-rmse:3.8757\ttrain-rmse:1.99707\n",
      "[13559]\teval-rmse:3.87423\ttrain-rmse:1.99704\n",
      "[13560]\teval-rmse:3.87264\ttrain-rmse:1.99701\n",
      "[13561]\teval-rmse:3.87335\ttrain-rmse:1.99702\n",
      "[13562]\teval-rmse:3.8717\ttrain-rmse:1.99698\n",
      "[13563]\teval-rmse:3.8722\ttrain-rmse:1.99699\n",
      "[13564]\teval-rmse:3.8711\ttrain-rmse:1.99698\n",
      "[13565]\teval-rmse:3.86939\ttrain-rmse:1.99697\n",
      "[13566]\teval-rmse:3.87057\ttrain-rmse:1.99697\n",
      "[13567]\teval-rmse:3.87127\ttrain-rmse:1.99698\n",
      "[13568]\teval-rmse:3.86907\ttrain-rmse:1.99696\n",
      "[13569]\teval-rmse:3.87084\ttrain-rmse:1.99698\n",
      "[13570]\teval-rmse:3.87031\ttrain-rmse:1.99698\n",
      "[13571]\teval-rmse:3.87142\ttrain-rmse:1.99699\n",
      "[13572]\teval-rmse:3.87209\ttrain-rmse:1.99701\n",
      "[13573]\teval-rmse:3.87192\ttrain-rmse:1.99701\n",
      "[13574]\teval-rmse:3.87303\ttrain-rmse:1.99704\n",
      "[13575]\teval-rmse:3.87427\ttrain-rmse:1.99706\n",
      "[13576]\teval-rmse:3.87404\ttrain-rmse:1.99705\n",
      "[13577]\teval-rmse:3.87203\ttrain-rmse:1.99701\n",
      "[13578]\teval-rmse:3.87409\ttrain-rmse:1.99703\n",
      "[13579]\teval-rmse:3.87484\ttrain-rmse:1.99704\n",
      "[13580]\teval-rmse:3.87351\ttrain-rmse:1.99701\n",
      "[13581]\teval-rmse:3.87295\ttrain-rmse:1.99701\n",
      "[13582]\teval-rmse:3.87173\ttrain-rmse:1.99702\n",
      "[13583]\teval-rmse:3.8738\ttrain-rmse:1.99706\n",
      "[13584]\teval-rmse:3.87309\ttrain-rmse:1.99705\n",
      "[13585]\teval-rmse:3.87486\ttrain-rmse:1.9971\n",
      "[13586]\teval-rmse:3.8743\ttrain-rmse:1.9971\n",
      "[13587]\teval-rmse:3.87283\ttrain-rmse:1.99706\n",
      "[13588]\teval-rmse:3.87286\ttrain-rmse:1.99706\n",
      "[13589]\teval-rmse:3.87121\ttrain-rmse:1.99703\n",
      "[13590]\teval-rmse:3.86971\ttrain-rmse:1.99701\n",
      "[13591]\teval-rmse:3.87179\ttrain-rmse:1.99702\n",
      "[13592]\teval-rmse:3.8731\ttrain-rmse:1.99704\n",
      "[13593]\teval-rmse:3.87255\ttrain-rmse:1.99687\n",
      "[13594]\teval-rmse:3.87063\ttrain-rmse:1.99685\n",
      "[13595]\teval-rmse:3.87224\ttrain-rmse:1.99688\n",
      "[13596]\teval-rmse:3.8717\ttrain-rmse:1.99669\n",
      "[13597]\teval-rmse:3.87195\ttrain-rmse:1.9967\n",
      "[13598]\teval-rmse:3.87094\ttrain-rmse:1.99669\n",
      "[13599]\teval-rmse:3.8711\ttrain-rmse:1.99669\n",
      "[13600]\teval-rmse:3.87315\ttrain-rmse:1.9967\n",
      "[13601]\teval-rmse:3.87138\ttrain-rmse:1.99666\n",
      "[13602]\teval-rmse:3.87325\ttrain-rmse:1.99672\n",
      "[13603]\teval-rmse:3.87133\ttrain-rmse:1.99669\n",
      "[13604]\teval-rmse:3.87319\ttrain-rmse:1.99671\n",
      "[13605]\teval-rmse:3.87186\ttrain-rmse:1.99669\n",
      "[13606]\teval-rmse:3.87319\ttrain-rmse:1.99672\n",
      "[13607]\teval-rmse:3.87228\ttrain-rmse:1.99671\n",
      "[13608]\teval-rmse:3.87233\ttrain-rmse:1.99671\n",
      "[13609]\teval-rmse:3.87439\ttrain-rmse:1.99672\n",
      "[13610]\teval-rmse:3.87574\ttrain-rmse:1.99676\n",
      "[13611]\teval-rmse:3.87554\ttrain-rmse:1.99675\n",
      "[13612]\teval-rmse:3.87624\ttrain-rmse:1.99677\n",
      "[13613]\teval-rmse:3.87571\ttrain-rmse:1.99659\n",
      "[13614]\teval-rmse:3.8765\ttrain-rmse:1.99662\n",
      "[13615]\teval-rmse:3.87768\ttrain-rmse:1.99665\n",
      "[13616]\teval-rmse:3.87711\ttrain-rmse:1.99647\n",
      "[13617]\teval-rmse:3.87516\ttrain-rmse:1.99641\n",
      "[13618]\teval-rmse:3.87393\ttrain-rmse:1.99642\n",
      "[13619]\teval-rmse:3.87462\ttrain-rmse:1.99645\n",
      "[13620]\teval-rmse:3.87235\ttrain-rmse:1.99639\n",
      "[13621]\teval-rmse:3.87379\ttrain-rmse:1.99642\n",
      "[13622]\teval-rmse:3.87501\ttrain-rmse:1.99646\n",
      "[13623]\teval-rmse:3.87681\ttrain-rmse:1.99652\n",
      "[13624]\teval-rmse:3.87675\ttrain-rmse:1.99651\n",
      "[13625]\teval-rmse:3.87618\ttrain-rmse:1.99633\n",
      "[13626]\teval-rmse:3.87626\ttrain-rmse:1.99633\n",
      "[13627]\teval-rmse:3.87714\ttrain-rmse:1.99635\n",
      "[13628]\teval-rmse:3.87761\ttrain-rmse:1.99637\n",
      "[13629]\teval-rmse:3.87684\ttrain-rmse:1.99635\n",
      "[13630]\teval-rmse:3.87634\ttrain-rmse:1.99632\n",
      "[13631]\teval-rmse:3.8757\ttrain-rmse:1.99631\n",
      "[13632]\teval-rmse:3.87403\ttrain-rmse:1.99625\n",
      "[13633]\teval-rmse:3.87543\ttrain-rmse:1.99629\n",
      "[13634]\teval-rmse:3.87479\ttrain-rmse:1.99627\n",
      "[13635]\teval-rmse:3.87368\ttrain-rmse:1.99624\n",
      "[13636]\teval-rmse:3.87389\ttrain-rmse:1.99624\n",
      "[13637]\teval-rmse:3.8736\ttrain-rmse:1.99624\n",
      "[13638]\teval-rmse:3.87495\ttrain-rmse:1.99627\n",
      "[13639]\teval-rmse:3.87515\ttrain-rmse:1.99627\n",
      "[13640]\teval-rmse:3.8756\ttrain-rmse:1.99629\n",
      "[13641]\teval-rmse:3.87457\ttrain-rmse:1.99625\n",
      "[13642]\teval-rmse:3.8745\ttrain-rmse:1.99625\n",
      "[13643]\teval-rmse:3.87409\ttrain-rmse:1.99624\n",
      "[13644]\teval-rmse:3.87389\ttrain-rmse:1.99624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13645]\teval-rmse:3.87326\ttrain-rmse:1.99621\n",
      "[13646]\teval-rmse:3.87532\ttrain-rmse:1.99623\n",
      "[13647]\teval-rmse:3.87692\ttrain-rmse:1.99622\n",
      "[13648]\teval-rmse:3.87709\ttrain-rmse:1.99622\n",
      "[13649]\teval-rmse:3.87786\ttrain-rmse:1.99625\n",
      "[13650]\teval-rmse:3.87981\ttrain-rmse:1.9963\n",
      "[13651]\teval-rmse:3.88096\ttrain-rmse:1.99634\n",
      "[13652]\teval-rmse:3.88064\ttrain-rmse:1.99634\n",
      "[13653]\teval-rmse:3.87869\ttrain-rmse:1.99624\n",
      "[13654]\teval-rmse:3.87837\ttrain-rmse:1.99623\n",
      "[13655]\teval-rmse:3.87779\ttrain-rmse:1.99621\n",
      "[13656]\teval-rmse:3.876\ttrain-rmse:1.99613\n",
      "[13657]\teval-rmse:3.87528\ttrain-rmse:1.99612\n",
      "[13658]\teval-rmse:3.87637\ttrain-rmse:1.99615\n",
      "[13659]\teval-rmse:3.87564\ttrain-rmse:1.99613\n",
      "[13660]\teval-rmse:3.87741\ttrain-rmse:1.99619\n",
      "[13661]\teval-rmse:3.87581\ttrain-rmse:1.99616\n",
      "[13662]\teval-rmse:3.87712\ttrain-rmse:1.99621\n",
      "[13663]\teval-rmse:3.87842\ttrain-rmse:1.99627\n",
      "[13664]\teval-rmse:3.87632\ttrain-rmse:1.99618\n",
      "[13665]\teval-rmse:3.87576\ttrain-rmse:1.99617\n",
      "[13666]\teval-rmse:3.87662\ttrain-rmse:1.9962\n",
      "[13667]\teval-rmse:3.87703\ttrain-rmse:1.99621\n",
      "[13668]\teval-rmse:3.87487\ttrain-rmse:1.99612\n",
      "[13669]\teval-rmse:3.87446\ttrain-rmse:1.99611\n",
      "[13670]\teval-rmse:3.8759\ttrain-rmse:1.99615\n",
      "[13671]\teval-rmse:3.87639\ttrain-rmse:1.99616\n",
      "[13672]\teval-rmse:3.87642\ttrain-rmse:1.99616\n",
      "[13673]\teval-rmse:3.87819\ttrain-rmse:1.99622\n",
      "[13674]\teval-rmse:3.87821\ttrain-rmse:1.99622\n",
      "[13675]\teval-rmse:3.87679\ttrain-rmse:1.99616\n",
      "[13676]\teval-rmse:3.87526\ttrain-rmse:1.99611\n",
      "[13677]\teval-rmse:3.87711\ttrain-rmse:1.99615\n",
      "[13678]\teval-rmse:3.87571\ttrain-rmse:1.99611\n",
      "[13679]\teval-rmse:3.87372\ttrain-rmse:1.99606\n",
      "[13680]\teval-rmse:3.87352\ttrain-rmse:1.99605\n",
      "[13681]\teval-rmse:3.87538\ttrain-rmse:1.99603\n",
      "[13682]\teval-rmse:3.87611\ttrain-rmse:1.99605\n",
      "[13683]\teval-rmse:3.87555\ttrain-rmse:1.99587\n",
      "[13684]\teval-rmse:3.87514\ttrain-rmse:1.99586\n",
      "[13685]\teval-rmse:3.87472\ttrain-rmse:1.99585\n",
      "[13686]\teval-rmse:3.87324\ttrain-rmse:1.99581\n",
      "[13687]\teval-rmse:3.87269\ttrain-rmse:1.99581\n",
      "[13688]\teval-rmse:3.87075\ttrain-rmse:1.99575\n",
      "[13689]\teval-rmse:3.87122\ttrain-rmse:1.99576\n",
      "[13690]\teval-rmse:3.87254\ttrain-rmse:1.9958\n",
      "[13691]\teval-rmse:3.87124\ttrain-rmse:1.99577\n",
      "[13692]\teval-rmse:3.87106\ttrain-rmse:1.99577\n",
      "[13693]\teval-rmse:3.87124\ttrain-rmse:1.99577\n",
      "[13694]\teval-rmse:3.87312\ttrain-rmse:1.99583\n",
      "[13695]\teval-rmse:3.87272\ttrain-rmse:1.99582\n",
      "[13696]\teval-rmse:3.87195\ttrain-rmse:1.99581\n",
      "[13697]\teval-rmse:3.87003\ttrain-rmse:1.99579\n",
      "[13698]\teval-rmse:3.86901\ttrain-rmse:1.99577\n",
      "[13699]\teval-rmse:3.86924\ttrain-rmse:1.99578\n",
      "[13700]\teval-rmse:3.8703\ttrain-rmse:1.99579\n",
      "[13701]\teval-rmse:3.87158\ttrain-rmse:1.99582\n",
      "[13702]\teval-rmse:3.87089\ttrain-rmse:1.99581\n",
      "[13703]\teval-rmse:3.86913\ttrain-rmse:1.99578\n",
      "[13704]\teval-rmse:3.87025\ttrain-rmse:1.99581\n",
      "[13705]\teval-rmse:3.87039\ttrain-rmse:1.99581\n",
      "[13706]\teval-rmse:3.87088\ttrain-rmse:1.99582\n",
      "[13707]\teval-rmse:3.87215\ttrain-rmse:1.99585\n",
      "[13708]\teval-rmse:3.87274\ttrain-rmse:1.99586\n",
      "[13709]\teval-rmse:3.87298\ttrain-rmse:1.99586\n",
      "[13710]\teval-rmse:3.87111\ttrain-rmse:1.9958\n",
      "[13711]\teval-rmse:3.87138\ttrain-rmse:1.99581\n",
      "[13712]\teval-rmse:3.86944\ttrain-rmse:1.99578\n",
      "[13713]\teval-rmse:3.86969\ttrain-rmse:1.99578\n",
      "[13714]\teval-rmse:3.86739\ttrain-rmse:1.99575\n",
      "[13715]\teval-rmse:3.86925\ttrain-rmse:1.99571\n",
      "[13716]\teval-rmse:3.87096\ttrain-rmse:1.99573\n",
      "[13717]\teval-rmse:3.87255\ttrain-rmse:1.9957\n",
      "[13718]\teval-rmse:3.87107\ttrain-rmse:1.99566\n",
      "[13719]\teval-rmse:3.86935\ttrain-rmse:1.99565\n",
      "[13720]\teval-rmse:3.8714\ttrain-rmse:1.99566\n",
      "[13721]\teval-rmse:3.87065\ttrain-rmse:1.99565\n",
      "[13722]\teval-rmse:3.87192\ttrain-rmse:1.99566\n",
      "[13723]\teval-rmse:3.8706\ttrain-rmse:1.99565\n",
      "[13724]\teval-rmse:3.87141\ttrain-rmse:1.99566\n",
      "[13725]\teval-rmse:3.86934\ttrain-rmse:1.99564\n",
      "[13726]\teval-rmse:3.86977\ttrain-rmse:1.99564\n",
      "[13727]\teval-rmse:3.87136\ttrain-rmse:1.99561\n",
      "[13728]\teval-rmse:3.87282\ttrain-rmse:1.99562\n",
      "[13729]\teval-rmse:3.87413\ttrain-rmse:1.99564\n",
      "[13730]\teval-rmse:3.87447\ttrain-rmse:1.99565\n",
      "[13731]\teval-rmse:3.87564\ttrain-rmse:1.99568\n",
      "[13732]\teval-rmse:3.87508\ttrain-rmse:1.99567\n",
      "[13733]\teval-rmse:3.87395\ttrain-rmse:1.99566\n",
      "[13734]\teval-rmse:3.87419\ttrain-rmse:1.99566\n",
      "[13735]\teval-rmse:3.87399\ttrain-rmse:1.99566\n",
      "[13736]\teval-rmse:3.87458\ttrain-rmse:1.99567\n",
      "[13737]\teval-rmse:3.87458\ttrain-rmse:1.99567\n",
      "[13738]\teval-rmse:3.87493\ttrain-rmse:1.99568\n",
      "[13739]\teval-rmse:3.8732\ttrain-rmse:1.99564\n",
      "[13740]\teval-rmse:3.87526\ttrain-rmse:1.99567\n",
      "[13741]\teval-rmse:3.87516\ttrain-rmse:1.99566\n",
      "[13742]\teval-rmse:3.8732\ttrain-rmse:1.99561\n",
      "[13743]\teval-rmse:3.87389\ttrain-rmse:1.99562\n",
      "[13744]\teval-rmse:3.87566\ttrain-rmse:1.99566\n",
      "[13745]\teval-rmse:3.87399\ttrain-rmse:1.99561\n",
      "[13746]\teval-rmse:3.87419\ttrain-rmse:1.99561\n",
      "[13747]\teval-rmse:3.87521\ttrain-rmse:1.99563\n",
      "[13748]\teval-rmse:3.87562\ttrain-rmse:1.99564\n",
      "[13749]\teval-rmse:3.8764\ttrain-rmse:1.99565\n",
      "[13750]\teval-rmse:3.87445\ttrain-rmse:1.99561\n",
      "[13751]\teval-rmse:3.87422\ttrain-rmse:1.99561\n",
      "[13752]\teval-rmse:3.87393\ttrain-rmse:1.9956\n",
      "[13753]\teval-rmse:3.87598\ttrain-rmse:1.99563\n",
      "[13754]\teval-rmse:3.87474\ttrain-rmse:1.99564\n",
      "[13755]\teval-rmse:3.8752\ttrain-rmse:1.99564\n",
      "[13756]\teval-rmse:3.87662\ttrain-rmse:1.99568\n",
      "[13757]\teval-rmse:3.87607\ttrain-rmse:1.99567\n",
      "[13758]\teval-rmse:3.87663\ttrain-rmse:1.99568\n",
      "[13759]\teval-rmse:3.87485\ttrain-rmse:1.99564\n",
      "[13760]\teval-rmse:3.87309\ttrain-rmse:1.99561\n",
      "[13761]\teval-rmse:3.87163\ttrain-rmse:1.99559\n",
      "[13762]\teval-rmse:3.87243\ttrain-rmse:1.9956\n",
      "[13763]\teval-rmse:3.87069\ttrain-rmse:1.99558\n",
      "[13764]\teval-rmse:3.87019\ttrain-rmse:1.99538\n",
      "[13765]\teval-rmse:3.86961\ttrain-rmse:1.99538\n",
      "[13766]\teval-rmse:3.8694\ttrain-rmse:1.99538\n",
      "[13767]\teval-rmse:3.86887\ttrain-rmse:1.99537\n",
      "[13768]\teval-rmse:3.86778\ttrain-rmse:1.99537\n",
      "[13769]\teval-rmse:3.86788\ttrain-rmse:1.99537\n",
      "[13770]\teval-rmse:3.86886\ttrain-rmse:1.99538\n",
      "[13771]\teval-rmse:3.8691\ttrain-rmse:1.99539\n",
      "[13772]\teval-rmse:3.87013\ttrain-rmse:1.9954\n",
      "[13773]\teval-rmse:3.86929\ttrain-rmse:1.99539\n",
      "[13774]\teval-rmse:3.86999\ttrain-rmse:1.99539\n",
      "[13775]\teval-rmse:3.86836\ttrain-rmse:1.99538\n",
      "[13776]\teval-rmse:3.86862\ttrain-rmse:1.99538\n",
      "[13777]\teval-rmse:3.86678\ttrain-rmse:1.99538\n",
      "[13778]\teval-rmse:3.86867\ttrain-rmse:1.99539\n",
      "[13779]\teval-rmse:3.8674\ttrain-rmse:1.99537\n",
      "[13780]\teval-rmse:3.86907\ttrain-rmse:1.99539\n",
      "[13781]\teval-rmse:3.86998\ttrain-rmse:1.9954\n",
      "[13782]\teval-rmse:3.86835\ttrain-rmse:1.99538\n",
      "[13783]\teval-rmse:3.86964\ttrain-rmse:1.99538\n",
      "[13784]\teval-rmse:3.87053\ttrain-rmse:1.99539\n",
      "[13785]\teval-rmse:3.86944\ttrain-rmse:1.99538\n",
      "[13786]\teval-rmse:3.86873\ttrain-rmse:1.99537\n",
      "[13787]\teval-rmse:3.86709\ttrain-rmse:1.99537\n",
      "[13788]\teval-rmse:3.86682\ttrain-rmse:1.99537\n",
      "[13789]\teval-rmse:3.86552\ttrain-rmse:1.99537\n",
      "[13790]\teval-rmse:3.86623\ttrain-rmse:1.99537\n",
      "[13791]\teval-rmse:3.86495\ttrain-rmse:1.99538\n",
      "[13792]\teval-rmse:3.86692\ttrain-rmse:1.99537\n",
      "[13793]\teval-rmse:3.86538\ttrain-rmse:1.99537\n",
      "[13794]\teval-rmse:3.86328\ttrain-rmse:1.99539\n",
      "[13795]\teval-rmse:3.86137\ttrain-rmse:1.99543\n",
      "[13796]\teval-rmse:3.86299\ttrain-rmse:1.99541\n",
      "[13797]\teval-rmse:3.86376\ttrain-rmse:1.9954\n",
      "[13798]\teval-rmse:3.86447\ttrain-rmse:1.9954\n",
      "[13799]\teval-rmse:3.86497\ttrain-rmse:1.99539\n",
      "[13800]\teval-rmse:3.86517\ttrain-rmse:1.99539\n",
      "[13801]\teval-rmse:3.86724\ttrain-rmse:1.99539\n",
      "[13802]\teval-rmse:3.86741\ttrain-rmse:1.99539\n",
      "[13803]\teval-rmse:3.86556\ttrain-rmse:1.99541\n",
      "[13804]\teval-rmse:3.86504\ttrain-rmse:1.9952\n",
      "[13805]\teval-rmse:3.86457\ttrain-rmse:1.99501\n",
      "[13806]\teval-rmse:3.86431\ttrain-rmse:1.99501\n",
      "[13807]\teval-rmse:3.86296\ttrain-rmse:1.99502\n",
      "[13808]\teval-rmse:3.86398\ttrain-rmse:1.995\n",
      "[13809]\teval-rmse:3.86605\ttrain-rmse:1.99499\n",
      "[13810]\teval-rmse:3.86487\ttrain-rmse:1.995\n",
      "[13811]\teval-rmse:3.86564\ttrain-rmse:1.995\n",
      "[13812]\teval-rmse:3.86601\ttrain-rmse:1.99499\n",
      "[13813]\teval-rmse:3.86645\ttrain-rmse:1.99499\n",
      "[13814]\teval-rmse:3.86833\ttrain-rmse:1.99499\n",
      "[13815]\teval-rmse:3.86796\ttrain-rmse:1.99498\n",
      "[13816]\teval-rmse:3.86748\ttrain-rmse:1.99479\n",
      "[13817]\teval-rmse:3.86624\ttrain-rmse:1.99479\n",
      "[13818]\teval-rmse:3.86768\ttrain-rmse:1.99479\n",
      "[13819]\teval-rmse:3.86648\ttrain-rmse:1.99479\n",
      "[13820]\teval-rmse:3.86824\ttrain-rmse:1.99479\n",
      "[13821]\teval-rmse:3.86787\ttrain-rmse:1.99479\n",
      "[13822]\teval-rmse:3.86883\ttrain-rmse:1.9948\n",
      "[13823]\teval-rmse:3.86831\ttrain-rmse:1.9948\n",
      "[13824]\teval-rmse:3.86992\ttrain-rmse:1.9948\n",
      "[13825]\teval-rmse:3.87134\ttrain-rmse:1.99482\n",
      "[13826]\teval-rmse:3.87294\ttrain-rmse:1.99486\n",
      "[13827]\teval-rmse:3.87498\ttrain-rmse:1.99488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13828]\teval-rmse:3.87443\ttrain-rmse:1.99487\n",
      "[13829]\teval-rmse:3.87285\ttrain-rmse:1.99485\n",
      "[13830]\teval-rmse:3.87471\ttrain-rmse:1.99483\n",
      "[13831]\teval-rmse:3.87348\ttrain-rmse:1.9948\n",
      "[13832]\teval-rmse:3.87295\ttrain-rmse:1.99479\n",
      "[13833]\teval-rmse:3.8722\ttrain-rmse:1.99479\n",
      "[13834]\teval-rmse:3.87084\ttrain-rmse:1.99477\n",
      "[13835]\teval-rmse:3.87086\ttrain-rmse:1.99477\n",
      "[13836]\teval-rmse:3.87137\ttrain-rmse:1.99477\n",
      "[13837]\teval-rmse:3.87107\ttrain-rmse:1.99477\n",
      "[13838]\teval-rmse:3.87289\ttrain-rmse:1.99479\n",
      "[13839]\teval-rmse:3.87258\ttrain-rmse:1.99479\n",
      "[13840]\teval-rmse:3.87464\ttrain-rmse:1.99481\n",
      "[13841]\teval-rmse:3.87592\ttrain-rmse:1.99484\n",
      "[13842]\teval-rmse:3.87694\ttrain-rmse:1.99483\n",
      "[13843]\teval-rmse:3.87898\ttrain-rmse:1.99487\n",
      "[13844]\teval-rmse:3.87925\ttrain-rmse:1.99488\n",
      "[13845]\teval-rmse:3.8792\ttrain-rmse:1.99488\n",
      "[13846]\teval-rmse:3.88046\ttrain-rmse:1.99491\n",
      "[13847]\teval-rmse:3.88206\ttrain-rmse:1.99496\n",
      "[13848]\teval-rmse:3.88254\ttrain-rmse:1.99498\n",
      "[13849]\teval-rmse:3.88026\ttrain-rmse:1.99491\n",
      "[13850]\teval-rmse:3.88056\ttrain-rmse:1.99492\n",
      "[13851]\teval-rmse:3.88236\ttrain-rmse:1.99497\n",
      "[13852]\teval-rmse:3.88015\ttrain-rmse:1.9949\n",
      "[13853]\teval-rmse:3.88063\ttrain-rmse:1.99492\n",
      "[13854]\teval-rmse:3.88136\ttrain-rmse:1.99494\n",
      "[13855]\teval-rmse:3.88201\ttrain-rmse:1.99496\n",
      "[13856]\teval-rmse:3.88328\ttrain-rmse:1.99501\n",
      "[13857]\teval-rmse:3.88349\ttrain-rmse:1.99502\n",
      "[13858]\teval-rmse:3.88465\ttrain-rmse:1.99507\n",
      "[13859]\teval-rmse:3.88326\ttrain-rmse:1.99505\n",
      "[13860]\teval-rmse:3.88531\ttrain-rmse:1.99511\n",
      "[13861]\teval-rmse:3.88307\ttrain-rmse:1.995\n",
      "[13862]\teval-rmse:3.88334\ttrain-rmse:1.99501\n",
      "[13863]\teval-rmse:3.88255\ttrain-rmse:1.99499\n",
      "[13864]\teval-rmse:3.88194\ttrain-rmse:1.99497\n",
      "[13865]\teval-rmse:3.88377\ttrain-rmse:1.99498\n",
      "[13866]\teval-rmse:3.88215\ttrain-rmse:1.99491\n",
      "[13867]\teval-rmse:3.8836\ttrain-rmse:1.99496\n",
      "[13868]\teval-rmse:3.88132\ttrain-rmse:1.9949\n",
      "[13869]\teval-rmse:3.88276\ttrain-rmse:1.99494\n",
      "[13870]\teval-rmse:3.88219\ttrain-rmse:1.99475\n",
      "[13871]\teval-rmse:3.88424\ttrain-rmse:1.99481\n",
      "[13872]\teval-rmse:3.88346\ttrain-rmse:1.99478\n",
      "[13873]\teval-rmse:3.88295\ttrain-rmse:1.99476\n",
      "[13874]\teval-rmse:3.88239\ttrain-rmse:1.99475\n",
      "[13875]\teval-rmse:3.8841\ttrain-rmse:1.99481\n",
      "[13876]\teval-rmse:3.88315\ttrain-rmse:1.99478\n",
      "[13877]\teval-rmse:3.88439\ttrain-rmse:1.99483\n",
      "[13878]\teval-rmse:3.88598\ttrain-rmse:1.99484\n",
      "[13879]\teval-rmse:3.88455\ttrain-rmse:1.99479\n",
      "[13880]\teval-rmse:3.88327\ttrain-rmse:1.99475\n",
      "[13881]\teval-rmse:3.88376\ttrain-rmse:1.99477\n",
      "[13882]\teval-rmse:3.88389\ttrain-rmse:1.99477\n",
      "[13883]\teval-rmse:3.88236\ttrain-rmse:1.99473\n",
      "[13884]\teval-rmse:3.88084\ttrain-rmse:1.99469\n",
      "[13885]\teval-rmse:3.88256\ttrain-rmse:1.99473\n",
      "[13886]\teval-rmse:3.88382\ttrain-rmse:1.99477\n",
      "[13887]\teval-rmse:3.88543\ttrain-rmse:1.99484\n",
      "[13888]\teval-rmse:3.88344\ttrain-rmse:1.99476\n",
      "[13889]\teval-rmse:3.8841\ttrain-rmse:1.99478\n",
      "[13890]\teval-rmse:3.88308\ttrain-rmse:1.99475\n",
      "[13891]\teval-rmse:3.88214\ttrain-rmse:1.99472\n",
      "[13892]\teval-rmse:3.8834\ttrain-rmse:1.99476\n",
      "[13893]\teval-rmse:3.88312\ttrain-rmse:1.99475\n",
      "[13894]\teval-rmse:3.88506\ttrain-rmse:1.99476\n",
      "[13895]\teval-rmse:3.8865\ttrain-rmse:1.99481\n",
      "[13896]\teval-rmse:3.88471\ttrain-rmse:1.99475\n",
      "[13897]\teval-rmse:3.88411\ttrain-rmse:1.99456\n",
      "[13898]\teval-rmse:3.88351\ttrain-rmse:1.99455\n",
      "[13899]\teval-rmse:3.88346\ttrain-rmse:1.99454\n",
      "[13900]\teval-rmse:3.88487\ttrain-rmse:1.9946\n",
      "[13901]\teval-rmse:3.88271\ttrain-rmse:1.99452\n",
      "[13902]\teval-rmse:3.88407\ttrain-rmse:1.99456\n",
      "[13903]\teval-rmse:3.88347\ttrain-rmse:1.99436\n",
      "[13904]\teval-rmse:3.88117\ttrain-rmse:1.9943\n",
      "[13905]\teval-rmse:3.88122\ttrain-rmse:1.9943\n",
      "[13906]\teval-rmse:3.87995\ttrain-rmse:1.9943\n",
      "[13907]\teval-rmse:3.88172\ttrain-rmse:1.99436\n",
      "[13908]\teval-rmse:3.88331\ttrain-rmse:1.99436\n",
      "[13909]\teval-rmse:3.88251\ttrain-rmse:1.99433\n",
      "[13910]\teval-rmse:3.88274\ttrain-rmse:1.99434\n",
      "[13911]\teval-rmse:3.88191\ttrain-rmse:1.99432\n",
      "[13912]\teval-rmse:3.88028\ttrain-rmse:1.99431\n",
      "[13913]\teval-rmse:3.87868\ttrain-rmse:1.99426\n",
      "[13914]\teval-rmse:3.87811\ttrain-rmse:1.99424\n",
      "[13915]\teval-rmse:3.87673\ttrain-rmse:1.99421\n",
      "[13916]\teval-rmse:3.87705\ttrain-rmse:1.99421\n",
      "[13917]\teval-rmse:3.87547\ttrain-rmse:1.99418\n",
      "[13918]\teval-rmse:3.87392\ttrain-rmse:1.99414\n",
      "[13919]\teval-rmse:3.87407\ttrain-rmse:1.99414\n",
      "[13920]\teval-rmse:3.87475\ttrain-rmse:1.99416\n",
      "[13921]\teval-rmse:3.87443\ttrain-rmse:1.99415\n",
      "[13922]\teval-rmse:3.87605\ttrain-rmse:1.99418\n",
      "[13923]\teval-rmse:3.87679\ttrain-rmse:1.9942\n",
      "[13924]\teval-rmse:3.87839\ttrain-rmse:1.99423\n",
      "[13925]\teval-rmse:3.88009\ttrain-rmse:1.99427\n",
      "[13926]\teval-rmse:3.88005\ttrain-rmse:1.99427\n",
      "[13927]\teval-rmse:3.87972\ttrain-rmse:1.99426\n",
      "[13928]\teval-rmse:3.87892\ttrain-rmse:1.99425\n",
      "[13929]\teval-rmse:3.88069\ttrain-rmse:1.99429\n",
      "[13930]\teval-rmse:3.88145\ttrain-rmse:1.99432\n",
      "[13931]\teval-rmse:3.88328\ttrain-rmse:1.99433\n",
      "[13932]\teval-rmse:3.88293\ttrain-rmse:1.99432\n",
      "[13933]\teval-rmse:3.88233\ttrain-rmse:1.9943\n",
      "[13934]\teval-rmse:3.88251\ttrain-rmse:1.9943\n",
      "[13935]\teval-rmse:3.88432\ttrain-rmse:1.99437\n",
      "[13936]\teval-rmse:3.88373\ttrain-rmse:1.99435\n",
      "[13937]\teval-rmse:3.88439\ttrain-rmse:1.99438\n",
      "[13938]\teval-rmse:3.88643\ttrain-rmse:1.99445\n",
      "[13939]\teval-rmse:3.88661\ttrain-rmse:1.99445\n",
      "[13940]\teval-rmse:3.88472\ttrain-rmse:1.99437\n",
      "[13941]\teval-rmse:3.88316\ttrain-rmse:1.99431\n",
      "[13942]\teval-rmse:3.88319\ttrain-rmse:1.99431\n",
      "[13943]\teval-rmse:3.88259\ttrain-rmse:1.99429\n",
      "[13944]\teval-rmse:3.8832\ttrain-rmse:1.99432\n",
      "[13945]\teval-rmse:3.88217\ttrain-rmse:1.99428\n",
      "[13946]\teval-rmse:3.883\ttrain-rmse:1.99431\n",
      "[13947]\teval-rmse:3.88353\ttrain-rmse:1.99433\n",
      "[13948]\teval-rmse:3.88155\ttrain-rmse:1.99426\n",
      "[13949]\teval-rmse:3.87947\ttrain-rmse:1.9942\n",
      "[13950]\teval-rmse:3.88074\ttrain-rmse:1.99424\n",
      "[13951]\teval-rmse:3.88015\ttrain-rmse:1.99422\n",
      "[13952]\teval-rmse:3.87952\ttrain-rmse:1.99421\n",
      "[13953]\teval-rmse:3.8786\ttrain-rmse:1.99419\n",
      "[13954]\teval-rmse:3.88019\ttrain-rmse:1.99423\n",
      "[13955]\teval-rmse:3.88087\ttrain-rmse:1.99426\n",
      "[13956]\teval-rmse:3.88254\ttrain-rmse:1.99433\n",
      "[13957]\teval-rmse:3.8838\ttrain-rmse:1.99437\n",
      "[13958]\teval-rmse:3.88192\ttrain-rmse:1.99431\n",
      "[13959]\teval-rmse:3.87988\ttrain-rmse:1.99424\n",
      "[13960]\teval-rmse:3.87799\ttrain-rmse:1.99419\n",
      "[13961]\teval-rmse:3.87926\ttrain-rmse:1.99423\n",
      "[13962]\teval-rmse:3.88013\ttrain-rmse:1.99426\n",
      "[13963]\teval-rmse:3.87873\ttrain-rmse:1.99422\n",
      "[13964]\teval-rmse:3.87973\ttrain-rmse:1.99422\n",
      "[13965]\teval-rmse:3.87921\ttrain-rmse:1.9942\n",
      "[13966]\teval-rmse:3.88009\ttrain-rmse:1.99423\n",
      "[13967]\teval-rmse:3.88015\ttrain-rmse:1.99423\n",
      "[13968]\teval-rmse:3.87983\ttrain-rmse:1.99422\n",
      "[13969]\teval-rmse:3.87915\ttrain-rmse:1.9942\n",
      "[13970]\teval-rmse:3.87933\ttrain-rmse:1.99421\n",
      "[13971]\teval-rmse:3.87911\ttrain-rmse:1.9942\n",
      "[13972]\teval-rmse:3.87832\ttrain-rmse:1.99418\n",
      "[13973]\teval-rmse:3.87757\ttrain-rmse:1.99416\n",
      "[13974]\teval-rmse:3.87563\ttrain-rmse:1.99412\n",
      "[13975]\teval-rmse:3.87717\ttrain-rmse:1.99416\n",
      "[13976]\teval-rmse:3.87912\ttrain-rmse:1.9942\n",
      "[13977]\teval-rmse:3.8787\ttrain-rmse:1.99419\n",
      "[13978]\teval-rmse:3.87837\ttrain-rmse:1.99418\n",
      "[13979]\teval-rmse:3.87745\ttrain-rmse:1.99415\n",
      "[13980]\teval-rmse:3.87829\ttrain-rmse:1.99418\n",
      "[13981]\teval-rmse:3.87766\ttrain-rmse:1.99416\n",
      "[13982]\teval-rmse:3.8778\ttrain-rmse:1.99416\n",
      "[13983]\teval-rmse:3.8783\ttrain-rmse:1.99418\n",
      "[13984]\teval-rmse:3.87983\ttrain-rmse:1.99422\n",
      "[13985]\teval-rmse:3.8796\ttrain-rmse:1.99421\n",
      "[13986]\teval-rmse:3.87908\ttrain-rmse:1.9942\n",
      "[13987]\teval-rmse:3.87986\ttrain-rmse:1.99422\n",
      "[13988]\teval-rmse:3.87868\ttrain-rmse:1.99419\n",
      "[13989]\teval-rmse:3.87786\ttrain-rmse:1.99417\n",
      "[13990]\teval-rmse:3.87808\ttrain-rmse:1.99418\n",
      "[13991]\teval-rmse:3.88013\ttrain-rmse:1.99422\n",
      "[13992]\teval-rmse:3.87934\ttrain-rmse:1.9942\n",
      "[13993]\teval-rmse:3.87775\ttrain-rmse:1.99417\n",
      "[13994]\teval-rmse:3.87547\ttrain-rmse:1.99412\n",
      "[13995]\teval-rmse:3.87388\ttrain-rmse:1.9941\n",
      "[13996]\teval-rmse:3.87535\ttrain-rmse:1.99411\n",
      "[13997]\teval-rmse:3.87428\ttrain-rmse:1.9941\n",
      "[13998]\teval-rmse:3.87633\ttrain-rmse:1.99413\n",
      "[13999]\teval-rmse:3.87766\ttrain-rmse:1.99416\n",
      "[14000]\teval-rmse:3.87733\ttrain-rmse:1.99415\n",
      "[14001]\teval-rmse:3.87573\ttrain-rmse:1.99412\n",
      "[14002]\teval-rmse:3.874\ttrain-rmse:1.9941\n",
      "[14003]\teval-rmse:3.87311\ttrain-rmse:1.99409\n",
      "[14004]\teval-rmse:3.87335\ttrain-rmse:1.99409\n",
      "[14005]\teval-rmse:3.87284\ttrain-rmse:1.9939\n",
      "[14006]\teval-rmse:3.87282\ttrain-rmse:1.9939\n",
      "[14007]\teval-rmse:3.87295\ttrain-rmse:1.9939\n",
      "[14008]\teval-rmse:3.8724\ttrain-rmse:1.99389\n",
      "[14009]\teval-rmse:3.87301\ttrain-rmse:1.9939\n",
      "[14010]\teval-rmse:3.87139\ttrain-rmse:1.99389\n",
      "[14011]\teval-rmse:3.87343\ttrain-rmse:1.99391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14012]\teval-rmse:3.87408\ttrain-rmse:1.99392\n",
      "[14013]\teval-rmse:3.87546\ttrain-rmse:1.99394\n",
      "[14014]\teval-rmse:3.87335\ttrain-rmse:1.99393\n",
      "[14015]\teval-rmse:3.87412\ttrain-rmse:1.99394\n",
      "[14016]\teval-rmse:3.87412\ttrain-rmse:1.99394\n",
      "[14017]\teval-rmse:3.87305\ttrain-rmse:1.99394\n",
      "[14018]\teval-rmse:3.87323\ttrain-rmse:1.99394\n",
      "[14019]\teval-rmse:3.87119\ttrain-rmse:1.99393\n",
      "[14020]\teval-rmse:3.87067\ttrain-rmse:1.99392\n",
      "[14021]\teval-rmse:3.87099\ttrain-rmse:1.99393\n",
      "[14022]\teval-rmse:3.8713\ttrain-rmse:1.99393\n",
      "[14023]\teval-rmse:3.871\ttrain-rmse:1.99392\n",
      "[14024]\teval-rmse:3.87182\ttrain-rmse:1.99394\n",
      "[14025]\teval-rmse:3.87377\ttrain-rmse:1.99395\n",
      "[14026]\teval-rmse:3.87385\ttrain-rmse:1.99395\n",
      "[14027]\teval-rmse:3.87272\ttrain-rmse:1.99393\n",
      "[14028]\teval-rmse:3.87323\ttrain-rmse:1.99394\n",
      "[14029]\teval-rmse:3.87267\ttrain-rmse:1.99393\n",
      "[14030]\teval-rmse:3.87181\ttrain-rmse:1.99392\n",
      "[14031]\teval-rmse:3.87162\ttrain-rmse:1.99392\n",
      "[14032]\teval-rmse:3.86977\ttrain-rmse:1.99392\n",
      "[14033]\teval-rmse:3.86857\ttrain-rmse:1.99394\n",
      "[14034]\teval-rmse:3.86726\ttrain-rmse:1.99397\n",
      "[14035]\teval-rmse:3.86698\ttrain-rmse:1.99396\n",
      "[14036]\teval-rmse:3.86861\ttrain-rmse:1.99396\n",
      "[14037]\teval-rmse:3.86803\ttrain-rmse:1.99396\n",
      "[14038]\teval-rmse:3.86592\ttrain-rmse:1.994\n",
      "[14039]\teval-rmse:3.86788\ttrain-rmse:1.99395\n",
      "[14040]\teval-rmse:3.86717\ttrain-rmse:1.99396\n",
      "[14041]\teval-rmse:3.86566\ttrain-rmse:1.99398\n",
      "[14042]\teval-rmse:3.8652\ttrain-rmse:1.99399\n",
      "[14043]\teval-rmse:3.86411\ttrain-rmse:1.99399\n",
      "[14044]\teval-rmse:3.86618\ttrain-rmse:1.99398\n",
      "[14045]\teval-rmse:3.86746\ttrain-rmse:1.99398\n",
      "[14046]\teval-rmse:3.86728\ttrain-rmse:1.99398\n",
      "[14047]\teval-rmse:3.86674\ttrain-rmse:1.99378\n",
      "[14048]\teval-rmse:3.86738\ttrain-rmse:1.99378\n",
      "[14049]\teval-rmse:3.86739\ttrain-rmse:1.99378\n",
      "[14050]\teval-rmse:3.86686\ttrain-rmse:1.99359\n",
      "[14051]\teval-rmse:3.86515\ttrain-rmse:1.99359\n",
      "[14052]\teval-rmse:3.86463\ttrain-rmse:1.99338\n",
      "[14053]\teval-rmse:3.86581\ttrain-rmse:1.99336\n",
      "[14054]\teval-rmse:3.86405\ttrain-rmse:1.99337\n",
      "[14055]\teval-rmse:3.86329\ttrain-rmse:1.99338\n",
      "[14056]\teval-rmse:3.86434\ttrain-rmse:1.99337\n",
      "[14057]\teval-rmse:3.8625\ttrain-rmse:1.99339\n",
      "[14058]\teval-rmse:3.86234\ttrain-rmse:1.99339\n",
      "[14059]\teval-rmse:3.8615\ttrain-rmse:1.9934\n",
      "[14060]\teval-rmse:3.86104\ttrain-rmse:1.99341\n",
      "[14061]\teval-rmse:3.86045\ttrain-rmse:1.99341\n",
      "[14062]\teval-rmse:3.85996\ttrain-rmse:1.99342\n",
      "[14063]\teval-rmse:3.8607\ttrain-rmse:1.99341\n",
      "[14064]\teval-rmse:3.86128\ttrain-rmse:1.9934\n",
      "[14065]\teval-rmse:3.86325\ttrain-rmse:1.99338\n",
      "[14066]\teval-rmse:3.86252\ttrain-rmse:1.99339\n",
      "[14067]\teval-rmse:3.86316\ttrain-rmse:1.99338\n",
      "[14068]\teval-rmse:3.86164\ttrain-rmse:1.99343\n",
      "[14069]\teval-rmse:3.86047\ttrain-rmse:1.99347\n",
      "[14070]\teval-rmse:3.86168\ttrain-rmse:1.99345\n",
      "[14071]\teval-rmse:3.8624\ttrain-rmse:1.99344\n",
      "[14072]\teval-rmse:3.86212\ttrain-rmse:1.99344\n",
      "[14073]\teval-rmse:3.8601\ttrain-rmse:1.99345\n",
      "[14074]\teval-rmse:3.86069\ttrain-rmse:1.99344\n",
      "[14075]\teval-rmse:3.85919\ttrain-rmse:1.99347\n",
      "[14076]\teval-rmse:3.85946\ttrain-rmse:1.99346\n",
      "[14077]\teval-rmse:3.86049\ttrain-rmse:1.99344\n",
      "[14078]\teval-rmse:3.86212\ttrain-rmse:1.99342\n",
      "[14079]\teval-rmse:3.86231\ttrain-rmse:1.99341\n",
      "[14080]\teval-rmse:3.86114\ttrain-rmse:1.99343\n",
      "[14081]\teval-rmse:3.85955\ttrain-rmse:1.99345\n",
      "[14082]\teval-rmse:3.85994\ttrain-rmse:1.99344\n",
      "[14083]\teval-rmse:3.85887\ttrain-rmse:1.99345\n",
      "[14084]\teval-rmse:3.8574\ttrain-rmse:1.99349\n",
      "[14085]\teval-rmse:3.85568\ttrain-rmse:1.99353\n",
      "[14086]\teval-rmse:3.85512\ttrain-rmse:1.99355\n",
      "[14087]\teval-rmse:3.85637\ttrain-rmse:1.99351\n",
      "[14088]\teval-rmse:3.85456\ttrain-rmse:1.99355\n",
      "[14089]\teval-rmse:3.85443\ttrain-rmse:1.99355\n",
      "[14090]\teval-rmse:3.85575\ttrain-rmse:1.99352\n",
      "[14091]\teval-rmse:3.85542\ttrain-rmse:1.99353\n",
      "[14092]\teval-rmse:3.85597\ttrain-rmse:1.99351\n",
      "[14093]\teval-rmse:3.85553\ttrain-rmse:1.99352\n",
      "[14094]\teval-rmse:3.85651\ttrain-rmse:1.9935\n",
      "[14095]\teval-rmse:3.85619\ttrain-rmse:1.9935\n",
      "[14096]\teval-rmse:3.85792\ttrain-rmse:1.99346\n",
      "[14097]\teval-rmse:3.85874\ttrain-rmse:1.99344\n",
      "[14098]\teval-rmse:3.85826\ttrain-rmse:1.99326\n",
      "[14099]\teval-rmse:3.85958\ttrain-rmse:1.99323\n",
      "[14100]\teval-rmse:3.85756\ttrain-rmse:1.99328\n",
      "[14101]\teval-rmse:3.85688\ttrain-rmse:1.9933\n",
      "[14102]\teval-rmse:3.85802\ttrain-rmse:1.99326\n",
      "[14103]\teval-rmse:3.85778\ttrain-rmse:1.99327\n",
      "[14104]\teval-rmse:3.85984\ttrain-rmse:1.99324\n",
      "[14105]\teval-rmse:3.85994\ttrain-rmse:1.99324\n",
      "[14106]\teval-rmse:3.86102\ttrain-rmse:1.99322\n",
      "[14107]\teval-rmse:3.86087\ttrain-rmse:1.99322\n",
      "[14108]\teval-rmse:3.86293\ttrain-rmse:1.99321\n",
      "[14109]\teval-rmse:3.86498\ttrain-rmse:1.99321\n",
      "[14110]\teval-rmse:3.865\ttrain-rmse:1.99321\n",
      "[14111]\teval-rmse:3.8651\ttrain-rmse:1.99321\n",
      "[14112]\teval-rmse:3.86483\ttrain-rmse:1.99321\n",
      "[14113]\teval-rmse:3.86431\ttrain-rmse:1.99303\n",
      "[14114]\teval-rmse:3.86487\ttrain-rmse:1.99302\n",
      "[14115]\teval-rmse:3.86378\ttrain-rmse:1.99303\n",
      "[14116]\teval-rmse:3.86446\ttrain-rmse:1.99302\n",
      "[14117]\teval-rmse:3.86375\ttrain-rmse:1.99303\n",
      "[14118]\teval-rmse:3.86537\ttrain-rmse:1.99302\n",
      "[14119]\teval-rmse:3.86575\ttrain-rmse:1.99302\n",
      "[14120]\teval-rmse:3.8678\ttrain-rmse:1.99303\n",
      "[14121]\teval-rmse:3.86618\ttrain-rmse:1.99303\n",
      "[14122]\teval-rmse:3.86748\ttrain-rmse:1.99303\n",
      "[14123]\teval-rmse:3.86884\ttrain-rmse:1.99303\n",
      "[14124]\teval-rmse:3.8672\ttrain-rmse:1.99303\n",
      "[14125]\teval-rmse:3.86582\ttrain-rmse:1.99303\n",
      "[14126]\teval-rmse:3.86415\ttrain-rmse:1.99305\n",
      "[14127]\teval-rmse:3.86611\ttrain-rmse:1.99304\n",
      "[14128]\teval-rmse:3.86682\ttrain-rmse:1.99303\n",
      "[14129]\teval-rmse:3.86843\ttrain-rmse:1.993\n",
      "[14130]\teval-rmse:3.86677\ttrain-rmse:1.99299\n",
      "[14131]\teval-rmse:3.86567\ttrain-rmse:1.99298\n",
      "[14132]\teval-rmse:3.86406\ttrain-rmse:1.99299\n",
      "[14133]\teval-rmse:3.86612\ttrain-rmse:1.99299\n",
      "[14134]\teval-rmse:3.86542\ttrain-rmse:1.993\n",
      "[14135]\teval-rmse:3.86434\ttrain-rmse:1.993\n",
      "[14136]\teval-rmse:3.8663\ttrain-rmse:1.99298\n",
      "[14137]\teval-rmse:3.86612\ttrain-rmse:1.99298\n",
      "[14138]\teval-rmse:3.86762\ttrain-rmse:1.99296\n",
      "[14139]\teval-rmse:3.86691\ttrain-rmse:1.99298\n",
      "[14140]\teval-rmse:3.86639\ttrain-rmse:1.9928\n",
      "[14141]\teval-rmse:3.86609\ttrain-rmse:1.9928\n",
      "[14142]\teval-rmse:3.86705\ttrain-rmse:1.9928\n",
      "[14143]\teval-rmse:3.8681\ttrain-rmse:1.9928\n",
      "[14144]\teval-rmse:3.87005\ttrain-rmse:1.99281\n",
      "[14145]\teval-rmse:3.86914\ttrain-rmse:1.9928\n",
      "[14146]\teval-rmse:3.86762\ttrain-rmse:1.9928\n",
      "[14147]\teval-rmse:3.86944\ttrain-rmse:1.99281\n",
      "[14148]\teval-rmse:3.86755\ttrain-rmse:1.9928\n",
      "[14149]\teval-rmse:3.86898\ttrain-rmse:1.9928\n",
      "[14150]\teval-rmse:3.87104\ttrain-rmse:1.99282\n",
      "[14151]\teval-rmse:3.86925\ttrain-rmse:1.99281\n",
      "[14152]\teval-rmse:3.86747\ttrain-rmse:1.99281\n",
      "[14153]\teval-rmse:3.86576\ttrain-rmse:1.99282\n",
      "[14154]\teval-rmse:3.86623\ttrain-rmse:1.99281\n",
      "[14155]\teval-rmse:3.86677\ttrain-rmse:1.99281\n",
      "[14156]\teval-rmse:3.8678\ttrain-rmse:1.99278\n",
      "[14157]\teval-rmse:3.86924\ttrain-rmse:1.99278\n",
      "[14158]\teval-rmse:3.87053\ttrain-rmse:1.99279\n",
      "[14159]\teval-rmse:3.87073\ttrain-rmse:1.99279\n",
      "[14160]\teval-rmse:3.86969\ttrain-rmse:1.99278\n",
      "[14161]\teval-rmse:3.86993\ttrain-rmse:1.99278\n",
      "[14162]\teval-rmse:3.86859\ttrain-rmse:1.99278\n",
      "[14163]\teval-rmse:3.87064\ttrain-rmse:1.9928\n",
      "[14164]\teval-rmse:3.87088\ttrain-rmse:1.9928\n",
      "[14165]\teval-rmse:3.8705\ttrain-rmse:1.9928\n",
      "[14166]\teval-rmse:3.8702\ttrain-rmse:1.99279\n",
      "[14167]\teval-rmse:3.87\ttrain-rmse:1.99279\n",
      "[14168]\teval-rmse:3.87058\ttrain-rmse:1.9928\n",
      "[14169]\teval-rmse:3.87003\ttrain-rmse:1.9926\n",
      "[14170]\teval-rmse:3.86806\ttrain-rmse:1.99259\n",
      "[14171]\teval-rmse:3.86649\ttrain-rmse:1.99259\n",
      "[14172]\teval-rmse:3.86774\ttrain-rmse:1.99258\n",
      "[14173]\teval-rmse:3.86712\ttrain-rmse:1.99259\n",
      "[14174]\teval-rmse:3.86832\ttrain-rmse:1.99259\n",
      "[14175]\teval-rmse:3.86679\ttrain-rmse:1.99259\n",
      "[14176]\teval-rmse:3.86884\ttrain-rmse:1.9926\n",
      "[14177]\teval-rmse:3.86687\ttrain-rmse:1.99259\n",
      "[14178]\teval-rmse:3.86763\ttrain-rmse:1.9926\n",
      "[14179]\teval-rmse:3.86741\ttrain-rmse:1.9926\n",
      "[14180]\teval-rmse:3.86768\ttrain-rmse:1.9926\n",
      "[14181]\teval-rmse:3.86871\ttrain-rmse:1.99257\n",
      "[14182]\teval-rmse:3.86796\ttrain-rmse:1.99257\n",
      "[14183]\teval-rmse:3.86978\ttrain-rmse:1.99257\n",
      "[14184]\teval-rmse:3.87173\ttrain-rmse:1.99259\n",
      "[14185]\teval-rmse:3.87017\ttrain-rmse:1.99261\n",
      "[14186]\teval-rmse:3.86882\ttrain-rmse:1.99261\n",
      "[14187]\teval-rmse:3.86675\ttrain-rmse:1.99262\n",
      "[14188]\teval-rmse:3.86804\ttrain-rmse:1.99261\n",
      "[14189]\teval-rmse:3.86776\ttrain-rmse:1.99261\n",
      "[14190]\teval-rmse:3.86757\ttrain-rmse:1.99261\n",
      "[14191]\teval-rmse:3.8657\ttrain-rmse:1.99263\n",
      "[14192]\teval-rmse:3.86756\ttrain-rmse:1.99263\n",
      "[14193]\teval-rmse:3.86704\ttrain-rmse:1.99263\n",
      "[14194]\teval-rmse:3.86765\ttrain-rmse:1.99262\n",
      "[14195]\teval-rmse:3.86613\ttrain-rmse:1.99263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14196]\teval-rmse:3.86693\ttrain-rmse:1.99262\n",
      "[14197]\teval-rmse:3.86655\ttrain-rmse:1.99262\n",
      "[14198]\teval-rmse:3.86818\ttrain-rmse:1.99262\n",
      "[14199]\teval-rmse:3.86929\ttrain-rmse:1.99262\n",
      "[14200]\teval-rmse:3.86976\ttrain-rmse:1.99262\n",
      "[14201]\teval-rmse:3.87148\ttrain-rmse:1.99263\n",
      "[14202]\teval-rmse:3.87043\ttrain-rmse:1.99262\n",
      "[14203]\teval-rmse:3.8697\ttrain-rmse:1.99263\n",
      "[14204]\teval-rmse:3.87091\ttrain-rmse:1.99263\n",
      "[14205]\teval-rmse:3.87038\ttrain-rmse:1.99263\n",
      "[14206]\teval-rmse:3.86998\ttrain-rmse:1.99263\n",
      "[14207]\teval-rmse:3.86944\ttrain-rmse:1.99244\n",
      "[14208]\teval-rmse:3.86923\ttrain-rmse:1.99244\n",
      "[14209]\teval-rmse:3.87013\ttrain-rmse:1.99244\n",
      "[14210]\teval-rmse:3.87171\ttrain-rmse:1.99246\n",
      "[14211]\teval-rmse:3.87332\ttrain-rmse:1.99244\n",
      "[14212]\teval-rmse:3.87208\ttrain-rmse:1.99245\n",
      "[14213]\teval-rmse:3.87229\ttrain-rmse:1.99246\n",
      "[14214]\teval-rmse:3.87395\ttrain-rmse:1.99249\n",
      "[14215]\teval-rmse:3.87435\ttrain-rmse:1.9925\n",
      "[14216]\teval-rmse:3.87301\ttrain-rmse:1.9925\n",
      "[14217]\teval-rmse:3.87417\ttrain-rmse:1.99253\n",
      "[14218]\teval-rmse:3.87293\ttrain-rmse:1.99254\n",
      "[14219]\teval-rmse:3.87156\ttrain-rmse:1.99252\n",
      "[14220]\teval-rmse:3.87229\ttrain-rmse:1.99253\n",
      "[14221]\teval-rmse:3.87083\ttrain-rmse:1.99251\n",
      "[14222]\teval-rmse:3.86848\ttrain-rmse:1.99248\n",
      "[14223]\teval-rmse:3.86728\ttrain-rmse:1.9925\n",
      "[14224]\teval-rmse:3.86896\ttrain-rmse:1.99251\n",
      "[14225]\teval-rmse:3.86913\ttrain-rmse:1.99251\n",
      "[14226]\teval-rmse:3.87024\ttrain-rmse:1.99252\n",
      "[14227]\teval-rmse:3.86994\ttrain-rmse:1.99252\n",
      "[14228]\teval-rmse:3.87126\ttrain-rmse:1.99253\n",
      "[14229]\teval-rmse:3.87004\ttrain-rmse:1.99252\n",
      "[14230]\teval-rmse:3.86984\ttrain-rmse:1.99252\n",
      "[14231]\teval-rmse:3.86945\ttrain-rmse:1.99252\n",
      "[14232]\teval-rmse:3.86799\ttrain-rmse:1.99251\n",
      "[14233]\teval-rmse:3.86932\ttrain-rmse:1.99252\n",
      "[14234]\teval-rmse:3.87069\ttrain-rmse:1.99254\n",
      "[14235]\teval-rmse:3.87106\ttrain-rmse:1.99255\n",
      "[14236]\teval-rmse:3.87267\ttrain-rmse:1.99257\n",
      "[14237]\teval-rmse:3.87213\ttrain-rmse:1.9924\n",
      "[14238]\teval-rmse:3.87158\ttrain-rmse:1.99223\n",
      "[14239]\teval-rmse:3.86972\ttrain-rmse:1.9922\n",
      "[14240]\teval-rmse:3.87156\ttrain-rmse:1.99222\n",
      "[14241]\teval-rmse:3.87009\ttrain-rmse:1.9922\n",
      "[14242]\teval-rmse:3.87195\ttrain-rmse:1.99223\n",
      "[14243]\teval-rmse:3.87321\ttrain-rmse:1.99226\n",
      "[14244]\teval-rmse:3.87183\ttrain-rmse:1.99224\n",
      "[14245]\teval-rmse:3.87173\ttrain-rmse:1.99224\n",
      "[14246]\teval-rmse:3.86964\ttrain-rmse:1.9922\n",
      "[14247]\teval-rmse:3.86804\ttrain-rmse:1.99217\n",
      "[14248]\teval-rmse:3.8693\ttrain-rmse:1.99219\n",
      "[14249]\teval-rmse:3.86818\ttrain-rmse:1.99218\n",
      "[14250]\teval-rmse:3.86721\ttrain-rmse:1.99218\n",
      "[14251]\teval-rmse:3.86744\ttrain-rmse:1.99218\n",
      "[14252]\teval-rmse:3.86929\ttrain-rmse:1.9922\n",
      "[14253]\teval-rmse:3.87133\ttrain-rmse:1.99223\n",
      "[14254]\teval-rmse:3.87073\ttrain-rmse:1.99222\n",
      "[14255]\teval-rmse:3.87052\ttrain-rmse:1.99222\n",
      "[14256]\teval-rmse:3.86844\ttrain-rmse:1.99219\n",
      "[14257]\teval-rmse:3.86646\ttrain-rmse:1.99218\n",
      "[14258]\teval-rmse:3.86664\ttrain-rmse:1.99218\n",
      "[14259]\teval-rmse:3.86681\ttrain-rmse:1.99218\n",
      "[14260]\teval-rmse:3.86698\ttrain-rmse:1.99218\n",
      "[14261]\teval-rmse:3.86636\ttrain-rmse:1.99218\n",
      "[14262]\teval-rmse:3.86653\ttrain-rmse:1.99218\n",
      "[14263]\teval-rmse:3.86523\ttrain-rmse:1.99221\n",
      "[14264]\teval-rmse:3.86473\ttrain-rmse:1.99203\n",
      "[14265]\teval-rmse:3.86307\ttrain-rmse:1.99203\n",
      "[14266]\teval-rmse:3.86223\ttrain-rmse:1.99203\n",
      "[14267]\teval-rmse:3.8636\ttrain-rmse:1.99203\n",
      "[14268]\teval-rmse:3.86523\ttrain-rmse:1.99198\n",
      "[14269]\teval-rmse:3.86707\ttrain-rmse:1.99194\n",
      "[14270]\teval-rmse:3.86719\ttrain-rmse:1.99194\n",
      "[14271]\teval-rmse:3.86608\ttrain-rmse:1.99194\n",
      "[14272]\teval-rmse:3.86659\ttrain-rmse:1.99194\n",
      "[14273]\teval-rmse:3.86711\ttrain-rmse:1.99194\n",
      "[14274]\teval-rmse:3.86703\ttrain-rmse:1.99194\n",
      "[14275]\teval-rmse:3.86908\ttrain-rmse:1.99196\n",
      "[14276]\teval-rmse:3.86977\ttrain-rmse:1.99197\n",
      "[14277]\teval-rmse:3.87123\ttrain-rmse:1.99199\n",
      "[14278]\teval-rmse:3.86981\ttrain-rmse:1.99197\n",
      "[14279]\teval-rmse:3.87008\ttrain-rmse:1.99197\n",
      "[14280]\teval-rmse:3.87157\ttrain-rmse:1.992\n",
      "[14281]\teval-rmse:3.87063\ttrain-rmse:1.99197\n",
      "[14282]\teval-rmse:3.86952\ttrain-rmse:1.99196\n",
      "[14283]\teval-rmse:3.87123\ttrain-rmse:1.99198\n",
      "[14284]\teval-rmse:3.86992\ttrain-rmse:1.99196\n",
      "[14285]\teval-rmse:3.87048\ttrain-rmse:1.99198\n",
      "[14286]\teval-rmse:3.86994\ttrain-rmse:1.99197\n",
      "[14287]\teval-rmse:3.86838\ttrain-rmse:1.99199\n",
      "[14288]\teval-rmse:3.86764\ttrain-rmse:1.992\n",
      "[14289]\teval-rmse:3.86711\ttrain-rmse:1.99183\n",
      "[14290]\teval-rmse:3.86781\ttrain-rmse:1.99184\n",
      "[14291]\teval-rmse:3.86961\ttrain-rmse:1.99186\n",
      "[14292]\teval-rmse:3.86806\ttrain-rmse:1.99185\n",
      "[14293]\teval-rmse:3.8667\ttrain-rmse:1.99184\n",
      "[14294]\teval-rmse:3.86502\ttrain-rmse:1.99184\n",
      "[14295]\teval-rmse:3.86373\ttrain-rmse:1.99187\n",
      "[14296]\teval-rmse:3.86265\ttrain-rmse:1.99186\n",
      "[14297]\teval-rmse:3.86278\ttrain-rmse:1.99186\n",
      "[14298]\teval-rmse:3.86218\ttrain-rmse:1.99186\n",
      "[14299]\teval-rmse:3.86249\ttrain-rmse:1.99186\n",
      "[14300]\teval-rmse:3.86251\ttrain-rmse:1.99186\n",
      "[14301]\teval-rmse:3.8637\ttrain-rmse:1.99187\n",
      "[14302]\teval-rmse:3.86487\ttrain-rmse:1.99187\n",
      "[14303]\teval-rmse:3.86539\ttrain-rmse:1.99188\n",
      "[14304]\teval-rmse:3.86545\ttrain-rmse:1.99188\n",
      "[14305]\teval-rmse:3.8672\ttrain-rmse:1.99189\n",
      "[14306]\teval-rmse:3.86838\ttrain-rmse:1.99191\n",
      "[14307]\teval-rmse:3.87033\ttrain-rmse:1.99192\n",
      "[14308]\teval-rmse:3.87237\ttrain-rmse:1.99195\n",
      "[14309]\teval-rmse:3.8708\ttrain-rmse:1.99197\n",
      "[14310]\teval-rmse:3.87139\ttrain-rmse:1.99198\n",
      "[14311]\teval-rmse:3.87231\ttrain-rmse:1.992\n",
      "[14312]\teval-rmse:3.87285\ttrain-rmse:1.99202\n",
      "[14313]\teval-rmse:3.87372\ttrain-rmse:1.99203\n",
      "[14314]\teval-rmse:3.87558\ttrain-rmse:1.99202\n",
      "[14315]\teval-rmse:3.87355\ttrain-rmse:1.99196\n",
      "[14316]\teval-rmse:3.87549\ttrain-rmse:1.992\n",
      "[14317]\teval-rmse:3.87699\ttrain-rmse:1.99204\n",
      "[14318]\teval-rmse:3.87549\ttrain-rmse:1.99199\n",
      "[14319]\teval-rmse:3.8745\ttrain-rmse:1.99197\n",
      "[14320]\teval-rmse:3.87317\ttrain-rmse:1.99192\n",
      "[14321]\teval-rmse:3.87454\ttrain-rmse:1.99195\n",
      "[14322]\teval-rmse:3.87292\ttrain-rmse:1.9919\n",
      "[14323]\teval-rmse:3.8724\ttrain-rmse:1.99174\n",
      "[14324]\teval-rmse:3.87117\ttrain-rmse:1.99171\n",
      "[14325]\teval-rmse:3.87218\ttrain-rmse:1.99172\n",
      "[14326]\teval-rmse:3.87258\ttrain-rmse:1.99173\n",
      "[14327]\teval-rmse:3.87462\ttrain-rmse:1.99177\n",
      "[14328]\teval-rmse:3.87638\ttrain-rmse:1.99182\n",
      "[14329]\teval-rmse:3.87558\ttrain-rmse:1.99179\n",
      "[14330]\teval-rmse:3.87752\ttrain-rmse:1.99178\n",
      "[14331]\teval-rmse:3.87541\ttrain-rmse:1.99171\n",
      "[14332]\teval-rmse:3.87347\ttrain-rmse:1.99165\n",
      "[14333]\teval-rmse:3.87147\ttrain-rmse:1.99161\n",
      "[14334]\teval-rmse:3.87164\ttrain-rmse:1.99161\n",
      "[14335]\teval-rmse:3.87007\ttrain-rmse:1.9916\n",
      "[14336]\teval-rmse:3.8705\ttrain-rmse:1.9916\n",
      "[14337]\teval-rmse:3.87211\ttrain-rmse:1.99163\n",
      "[14338]\teval-rmse:3.87155\ttrain-rmse:1.99162\n",
      "[14339]\teval-rmse:3.87124\ttrain-rmse:1.99162\n",
      "[14340]\teval-rmse:3.87032\ttrain-rmse:1.9916\n",
      "[14341]\teval-rmse:3.87141\ttrain-rmse:1.99162\n",
      "[14342]\teval-rmse:3.87326\ttrain-rmse:1.99165\n",
      "[14343]\teval-rmse:3.87428\ttrain-rmse:1.99164\n",
      "[14344]\teval-rmse:3.87293\ttrain-rmse:1.99165\n",
      "[14345]\teval-rmse:3.87292\ttrain-rmse:1.99165\n",
      "[14346]\teval-rmse:3.87075\ttrain-rmse:1.99161\n",
      "[14347]\teval-rmse:3.86939\ttrain-rmse:1.9916\n",
      "[14348]\teval-rmse:3.87133\ttrain-rmse:1.99157\n",
      "[14349]\teval-rmse:3.86992\ttrain-rmse:1.99155\n",
      "[14350]\teval-rmse:3.86823\ttrain-rmse:1.99154\n",
      "[14351]\teval-rmse:3.86774\ttrain-rmse:1.99154\n",
      "[14352]\teval-rmse:3.86721\ttrain-rmse:1.99154\n",
      "[14353]\teval-rmse:3.86535\ttrain-rmse:1.99154\n",
      "[14354]\teval-rmse:3.86738\ttrain-rmse:1.99155\n",
      "[14355]\teval-rmse:3.86719\ttrain-rmse:1.99154\n",
      "[14356]\teval-rmse:3.86669\ttrain-rmse:1.99154\n",
      "[14357]\teval-rmse:3.86698\ttrain-rmse:1.99154\n",
      "[14358]\teval-rmse:3.8668\ttrain-rmse:1.99154\n",
      "[14359]\teval-rmse:3.86607\ttrain-rmse:1.99156\n",
      "[14360]\teval-rmse:3.86723\ttrain-rmse:1.99156\n",
      "[14361]\teval-rmse:3.86715\ttrain-rmse:1.99156\n",
      "[14362]\teval-rmse:3.86576\ttrain-rmse:1.99156\n",
      "[14363]\teval-rmse:3.86438\ttrain-rmse:1.99156\n",
      "[14364]\teval-rmse:3.86577\ttrain-rmse:1.99155\n",
      "[14365]\teval-rmse:3.8664\ttrain-rmse:1.99156\n",
      "[14366]\teval-rmse:3.86569\ttrain-rmse:1.99156\n",
      "[14367]\teval-rmse:3.86764\ttrain-rmse:1.99157\n",
      "[14368]\teval-rmse:3.86712\ttrain-rmse:1.99156\n",
      "[14369]\teval-rmse:3.86649\ttrain-rmse:1.99156\n",
      "[14370]\teval-rmse:3.86678\ttrain-rmse:1.99156\n",
      "[14371]\teval-rmse:3.86808\ttrain-rmse:1.99157\n",
      "[14372]\teval-rmse:3.86856\ttrain-rmse:1.99157\n",
      "[14373]\teval-rmse:3.8706\ttrain-rmse:1.99159\n",
      "[14374]\teval-rmse:3.86924\ttrain-rmse:1.99159\n",
      "[14375]\teval-rmse:3.87109\ttrain-rmse:1.99156\n",
      "[14376]\teval-rmse:3.8721\ttrain-rmse:1.99157\n",
      "[14377]\teval-rmse:3.87227\ttrain-rmse:1.99157\n",
      "[14378]\teval-rmse:3.87121\ttrain-rmse:1.99157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14379]\teval-rmse:3.87091\ttrain-rmse:1.99156\n",
      "[14380]\teval-rmse:3.87171\ttrain-rmse:1.99157\n",
      "[14381]\teval-rmse:3.86992\ttrain-rmse:1.99156\n",
      "[14382]\teval-rmse:3.8708\ttrain-rmse:1.99157\n",
      "[14383]\teval-rmse:3.87049\ttrain-rmse:1.99156\n",
      "[14384]\teval-rmse:3.87254\ttrain-rmse:1.99159\n",
      "[14385]\teval-rmse:3.872\ttrain-rmse:1.99158\n",
      "[14386]\teval-rmse:3.87011\ttrain-rmse:1.99157\n",
      "[14387]\teval-rmse:3.86972\ttrain-rmse:1.99157\n",
      "[14388]\teval-rmse:3.87176\ttrain-rmse:1.99159\n",
      "[14389]\teval-rmse:3.87338\ttrain-rmse:1.99158\n",
      "[14390]\teval-rmse:3.87262\ttrain-rmse:1.99158\n",
      "[14391]\teval-rmse:3.87106\ttrain-rmse:1.9916\n",
      "[14392]\teval-rmse:3.8729\ttrain-rmse:1.99161\n",
      "[14393]\teval-rmse:3.87268\ttrain-rmse:1.99161\n",
      "[14394]\teval-rmse:3.87328\ttrain-rmse:1.99162\n",
      "[14395]\teval-rmse:3.87324\ttrain-rmse:1.99162\n",
      "[14396]\teval-rmse:3.87176\ttrain-rmse:1.9916\n",
      "[14397]\teval-rmse:3.87123\ttrain-rmse:1.99159\n",
      "[14398]\teval-rmse:3.87001\ttrain-rmse:1.99161\n",
      "[14399]\teval-rmse:3.87185\ttrain-rmse:1.99163\n",
      "[14400]\teval-rmse:3.87154\ttrain-rmse:1.99162\n",
      "[14401]\teval-rmse:3.87163\ttrain-rmse:1.99162\n",
      "[14402]\teval-rmse:3.87059\ttrain-rmse:1.99161\n",
      "[14403]\teval-rmse:3.8722\ttrain-rmse:1.99163\n",
      "[14404]\teval-rmse:3.87234\ttrain-rmse:1.99163\n",
      "[14405]\teval-rmse:3.87236\ttrain-rmse:1.99163\n",
      "[14406]\teval-rmse:3.87348\ttrain-rmse:1.99165\n",
      "[14407]\teval-rmse:3.87431\ttrain-rmse:1.99167\n",
      "[14408]\teval-rmse:3.87358\ttrain-rmse:1.99165\n",
      "[14409]\teval-rmse:3.87399\ttrain-rmse:1.99166\n",
      "[14410]\teval-rmse:3.87242\ttrain-rmse:1.99163\n",
      "[14411]\teval-rmse:3.87127\ttrain-rmse:1.99161\n",
      "[14412]\teval-rmse:3.87145\ttrain-rmse:1.99162\n",
      "[14413]\teval-rmse:3.87057\ttrain-rmse:1.99161\n",
      "[14414]\teval-rmse:3.86885\ttrain-rmse:1.9916\n",
      "[14415]\teval-rmse:3.86731\ttrain-rmse:1.9916\n",
      "[14416]\teval-rmse:3.86847\ttrain-rmse:1.9916\n",
      "[14417]\teval-rmse:3.86907\ttrain-rmse:1.9916\n",
      "[14418]\teval-rmse:3.86888\ttrain-rmse:1.9916\n",
      "[14419]\teval-rmse:3.86935\ttrain-rmse:1.99161\n",
      "[14420]\teval-rmse:3.87063\ttrain-rmse:1.99161\n",
      "[14421]\teval-rmse:3.87147\ttrain-rmse:1.99162\n",
      "[14422]\teval-rmse:3.87\ttrain-rmse:1.99161\n",
      "[14423]\teval-rmse:3.87149\ttrain-rmse:1.99163\n",
      "[14424]\teval-rmse:3.87218\ttrain-rmse:1.99164\n",
      "[14425]\teval-rmse:3.8713\ttrain-rmse:1.99163\n",
      "[14426]\teval-rmse:3.8713\ttrain-rmse:1.99163\n",
      "[14427]\teval-rmse:3.87196\ttrain-rmse:1.99164\n",
      "[14428]\teval-rmse:3.87072\ttrain-rmse:1.99165\n",
      "[14429]\teval-rmse:3.87203\ttrain-rmse:1.99167\n",
      "[14430]\teval-rmse:3.87322\ttrain-rmse:1.99169\n",
      "[14431]\teval-rmse:3.87373\ttrain-rmse:1.99169\n",
      "[14432]\teval-rmse:3.87318\ttrain-rmse:1.99168\n",
      "[14433]\teval-rmse:3.87297\ttrain-rmse:1.99168\n",
      "[14434]\teval-rmse:3.87295\ttrain-rmse:1.99168\n",
      "[14435]\teval-rmse:3.8722\ttrain-rmse:1.99167\n",
      "[14436]\teval-rmse:3.87355\ttrain-rmse:1.9917\n",
      "[14437]\teval-rmse:3.87299\ttrain-rmse:1.99169\n",
      "[14438]\teval-rmse:3.87401\ttrain-rmse:1.99168\n",
      "[14439]\teval-rmse:3.87369\ttrain-rmse:1.99168\n",
      "[14440]\teval-rmse:3.87337\ttrain-rmse:1.99167\n",
      "[14441]\teval-rmse:3.87465\ttrain-rmse:1.9917\n",
      "[14442]\teval-rmse:3.87626\ttrain-rmse:1.99174\n",
      "[14443]\teval-rmse:3.87406\ttrain-rmse:1.99167\n",
      "[14444]\teval-rmse:3.87557\ttrain-rmse:1.99171\n",
      "[14445]\teval-rmse:3.87687\ttrain-rmse:1.99174\n",
      "[14446]\teval-rmse:3.87517\ttrain-rmse:1.99169\n",
      "[14447]\teval-rmse:3.87437\ttrain-rmse:1.99168\n",
      "[14448]\teval-rmse:3.87511\ttrain-rmse:1.9917\n",
      "[14449]\teval-rmse:3.87715\ttrain-rmse:1.99175\n",
      "[14450]\teval-rmse:3.87505\ttrain-rmse:1.99168\n",
      "[14451]\teval-rmse:3.87338\ttrain-rmse:1.99164\n",
      "[14452]\teval-rmse:3.87263\ttrain-rmse:1.99163\n",
      "[14453]\teval-rmse:3.8729\ttrain-rmse:1.99164\n",
      "[14454]\teval-rmse:3.87268\ttrain-rmse:1.99163\n",
      "[14455]\teval-rmse:3.87088\ttrain-rmse:1.99161\n",
      "[14456]\teval-rmse:3.87065\ttrain-rmse:1.9916\n",
      "[14457]\teval-rmse:3.87126\ttrain-rmse:1.99161\n",
      "[14458]\teval-rmse:3.87072\ttrain-rmse:1.9916\n",
      "[14459]\teval-rmse:3.8707\ttrain-rmse:1.9916\n",
      "[14460]\teval-rmse:3.86919\ttrain-rmse:1.99159\n",
      "[14461]\teval-rmse:3.86756\ttrain-rmse:1.99158\n",
      "[14462]\teval-rmse:3.8657\ttrain-rmse:1.99158\n",
      "[14463]\teval-rmse:3.86718\ttrain-rmse:1.99158\n",
      "[14464]\teval-rmse:3.86858\ttrain-rmse:1.99159\n",
      "[14465]\teval-rmse:3.86746\ttrain-rmse:1.99158\n",
      "[14466]\teval-rmse:3.86796\ttrain-rmse:1.99158\n",
      "[14467]\teval-rmse:3.86779\ttrain-rmse:1.99158\n",
      "[14468]\teval-rmse:3.86838\ttrain-rmse:1.99158\n",
      "[14469]\teval-rmse:3.87043\ttrain-rmse:1.99161\n",
      "[14470]\teval-rmse:3.86922\ttrain-rmse:1.99159\n",
      "[14471]\teval-rmse:3.87116\ttrain-rmse:1.99156\n",
      "[14472]\teval-rmse:3.86995\ttrain-rmse:1.99158\n",
      "[14473]\teval-rmse:3.86942\ttrain-rmse:1.99157\n",
      "[14474]\teval-rmse:3.87146\ttrain-rmse:1.99158\n",
      "[14475]\teval-rmse:3.87264\ttrain-rmse:1.9916\n",
      "[14476]\teval-rmse:3.87127\ttrain-rmse:1.99158\n",
      "[14477]\teval-rmse:3.87169\ttrain-rmse:1.99159\n",
      "[14478]\teval-rmse:3.87374\ttrain-rmse:1.99162\n",
      "[14479]\teval-rmse:3.87457\ttrain-rmse:1.99164\n",
      "[14480]\teval-rmse:3.87558\ttrain-rmse:1.99163\n",
      "[14481]\teval-rmse:3.87737\ttrain-rmse:1.99167\n",
      "[14482]\teval-rmse:3.87696\ttrain-rmse:1.99166\n",
      "[14483]\teval-rmse:3.87571\ttrain-rmse:1.99163\n",
      "[14484]\teval-rmse:3.87587\ttrain-rmse:1.99163\n",
      "[14485]\teval-rmse:3.87391\ttrain-rmse:1.99159\n",
      "[14486]\teval-rmse:3.87202\ttrain-rmse:1.99155\n",
      "[14487]\teval-rmse:3.87038\ttrain-rmse:1.99153\n",
      "[14488]\teval-rmse:3.87141\ttrain-rmse:1.99151\n",
      "[14489]\teval-rmse:3.86926\ttrain-rmse:1.99149\n",
      "[14490]\teval-rmse:3.8673\ttrain-rmse:1.99149\n",
      "[14491]\teval-rmse:3.86555\ttrain-rmse:1.99149\n",
      "[14492]\teval-rmse:3.86759\ttrain-rmse:1.9915\n",
      "[14493]\teval-rmse:3.86899\ttrain-rmse:1.9915\n",
      "[14494]\teval-rmse:3.87043\ttrain-rmse:1.9915\n",
      "[14495]\teval-rmse:3.87062\ttrain-rmse:1.9915\n",
      "[14496]\teval-rmse:3.87014\ttrain-rmse:1.9915\n",
      "[14497]\teval-rmse:3.86945\ttrain-rmse:1.9915\n",
      "[14498]\teval-rmse:3.87141\ttrain-rmse:1.99146\n",
      "[14499]\teval-rmse:3.87328\ttrain-rmse:1.99147\n",
      "[14500]\teval-rmse:3.87494\ttrain-rmse:1.99149\n",
      "[14501]\teval-rmse:3.87359\ttrain-rmse:1.99147\n",
      "[14502]\teval-rmse:3.87563\ttrain-rmse:1.99151\n",
      "[14503]\teval-rmse:3.87623\ttrain-rmse:1.99152\n",
      "[14504]\teval-rmse:3.87728\ttrain-rmse:1.99153\n",
      "[14505]\teval-rmse:3.87796\ttrain-rmse:1.99154\n",
      "[14506]\teval-rmse:3.87935\ttrain-rmse:1.99158\n",
      "[14507]\teval-rmse:3.87877\ttrain-rmse:1.99156\n",
      "[14508]\teval-rmse:3.87738\ttrain-rmse:1.99154\n",
      "[14509]\teval-rmse:3.87681\ttrain-rmse:1.99134\n",
      "[14510]\teval-rmse:3.87801\ttrain-rmse:1.99137\n",
      "[14511]\teval-rmse:3.87601\ttrain-rmse:1.99134\n",
      "[14512]\teval-rmse:3.87463\ttrain-rmse:1.99131\n",
      "[14513]\teval-rmse:3.87294\ttrain-rmse:1.9913\n",
      "[14514]\teval-rmse:3.87348\ttrain-rmse:1.9913\n",
      "[14515]\teval-rmse:3.87274\ttrain-rmse:1.99131\n",
      "[14516]\teval-rmse:3.87218\ttrain-rmse:1.9913\n",
      "[14517]\teval-rmse:3.87093\ttrain-rmse:1.99129\n",
      "[14518]\teval-rmse:3.87111\ttrain-rmse:1.99129\n",
      "[14519]\teval-rmse:3.87163\ttrain-rmse:1.99129\n",
      "[14520]\teval-rmse:3.87325\ttrain-rmse:1.9913\n",
      "[14521]\teval-rmse:3.87169\ttrain-rmse:1.99128\n",
      "[14522]\teval-rmse:3.87092\ttrain-rmse:1.99128\n",
      "[14523]\teval-rmse:3.86992\ttrain-rmse:1.99128\n",
      "[14524]\teval-rmse:3.87113\ttrain-rmse:1.99128\n",
      "[14525]\teval-rmse:3.87023\ttrain-rmse:1.99128\n",
      "[14526]\teval-rmse:3.87016\ttrain-rmse:1.99128\n",
      "[14527]\teval-rmse:3.86962\ttrain-rmse:1.99109\n",
      "[14528]\teval-rmse:3.86941\ttrain-rmse:1.99109\n",
      "[14529]\teval-rmse:3.871\ttrain-rmse:1.9911\n",
      "[14530]\teval-rmse:3.87147\ttrain-rmse:1.9911\n",
      "[14531]\teval-rmse:3.87329\ttrain-rmse:1.99112\n",
      "[14532]\teval-rmse:3.87274\ttrain-rmse:1.99111\n",
      "[14533]\teval-rmse:3.87138\ttrain-rmse:1.9911\n",
      "[14534]\teval-rmse:3.87341\ttrain-rmse:1.99114\n",
      "[14535]\teval-rmse:3.87348\ttrain-rmse:1.99114\n",
      "[14536]\teval-rmse:3.87177\ttrain-rmse:1.99113\n",
      "[14537]\teval-rmse:3.87122\ttrain-rmse:1.99095\n",
      "[14538]\teval-rmse:3.8699\ttrain-rmse:1.99094\n",
      "[14539]\teval-rmse:3.86936\ttrain-rmse:1.99094\n",
      "[14540]\teval-rmse:3.86929\ttrain-rmse:1.99094\n",
      "[14541]\teval-rmse:3.87124\ttrain-rmse:1.99095\n",
      "[14542]\teval-rmse:3.87152\ttrain-rmse:1.99095\n",
      "[14543]\teval-rmse:3.87248\ttrain-rmse:1.99096\n",
      "[14544]\teval-rmse:3.87325\ttrain-rmse:1.99097\n",
      "[14545]\teval-rmse:3.87456\ttrain-rmse:1.99099\n",
      "[14546]\teval-rmse:3.87418\ttrain-rmse:1.99099\n",
      "[14547]\teval-rmse:3.87203\ttrain-rmse:1.99097\n",
      "[14548]\teval-rmse:3.87315\ttrain-rmse:1.99098\n",
      "[14549]\teval-rmse:3.871\ttrain-rmse:1.99096\n",
      "[14550]\teval-rmse:3.87069\ttrain-rmse:1.99096\n",
      "[14551]\teval-rmse:3.86868\ttrain-rmse:1.99097\n",
      "[14552]\teval-rmse:3.86888\ttrain-rmse:1.99097\n",
      "[14553]\teval-rmse:3.86707\ttrain-rmse:1.99099\n",
      "[14554]\teval-rmse:3.86861\ttrain-rmse:1.99098\n",
      "[14555]\teval-rmse:3.87025\ttrain-rmse:1.99098\n",
      "[14556]\teval-rmse:3.87168\ttrain-rmse:1.99099\n",
      "[14557]\teval-rmse:3.87115\ttrain-rmse:1.99099\n",
      "[14558]\teval-rmse:3.87078\ttrain-rmse:1.99099\n",
      "[14559]\teval-rmse:3.87029\ttrain-rmse:1.99098\n",
      "[14560]\teval-rmse:3.86975\ttrain-rmse:1.99079\n",
      "[14561]\teval-rmse:3.8716\ttrain-rmse:1.99081\n",
      "[14562]\teval-rmse:3.87138\ttrain-rmse:1.9908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14563]\teval-rmse:3.87239\ttrain-rmse:1.99081\n",
      "[14564]\teval-rmse:3.87326\ttrain-rmse:1.99082\n",
      "[14565]\teval-rmse:3.87252\ttrain-rmse:1.99081\n",
      "[14566]\teval-rmse:3.87396\ttrain-rmse:1.99082\n",
      "[14567]\teval-rmse:3.87535\ttrain-rmse:1.99084\n",
      "[14568]\teval-rmse:3.87645\ttrain-rmse:1.99087\n",
      "[14569]\teval-rmse:3.87816\ttrain-rmse:1.99092\n",
      "[14570]\teval-rmse:3.87661\ttrain-rmse:1.99087\n",
      "[14571]\teval-rmse:3.87743\ttrain-rmse:1.9909\n",
      "[14572]\teval-rmse:3.87708\ttrain-rmse:1.99089\n",
      "[14573]\teval-rmse:3.87826\ttrain-rmse:1.99092\n",
      "[14574]\teval-rmse:3.88029\ttrain-rmse:1.99098\n",
      "[14575]\teval-rmse:3.88199\ttrain-rmse:1.99102\n",
      "[14576]\teval-rmse:3.88278\ttrain-rmse:1.99105\n",
      "[14577]\teval-rmse:3.88219\ttrain-rmse:1.99103\n",
      "[14578]\teval-rmse:3.88325\ttrain-rmse:1.99107\n",
      "[14579]\teval-rmse:3.88281\ttrain-rmse:1.99105\n",
      "[14580]\teval-rmse:3.88125\ttrain-rmse:1.99099\n",
      "[14581]\teval-rmse:3.88155\ttrain-rmse:1.991\n",
      "[14582]\teval-rmse:3.88017\ttrain-rmse:1.99095\n",
      "[14583]\teval-rmse:3.87958\ttrain-rmse:1.99093\n",
      "[14584]\teval-rmse:3.87932\ttrain-rmse:1.99093\n",
      "[14585]\teval-rmse:3.87981\ttrain-rmse:1.99094\n",
      "[14586]\teval-rmse:3.88007\ttrain-rmse:1.99095\n",
      "[14587]\teval-rmse:3.87982\ttrain-rmse:1.99094\n",
      "[14588]\teval-rmse:3.88152\ttrain-rmse:1.99099\n",
      "[14589]\teval-rmse:3.8831\ttrain-rmse:1.991\n",
      "[14590]\teval-rmse:3.88199\ttrain-rmse:1.99096\n",
      "[14591]\teval-rmse:3.88285\ttrain-rmse:1.99099\n",
      "[14592]\teval-rmse:3.88146\ttrain-rmse:1.99094\n",
      "[14593]\teval-rmse:3.88315\ttrain-rmse:1.991\n",
      "[14594]\teval-rmse:3.88508\ttrain-rmse:1.99102\n",
      "[14595]\teval-rmse:3.88366\ttrain-rmse:1.99096\n",
      "[14596]\teval-rmse:3.88257\ttrain-rmse:1.99091\n",
      "[14597]\teval-rmse:3.88118\ttrain-rmse:1.9909\n",
      "[14598]\teval-rmse:3.88299\ttrain-rmse:1.99096\n",
      "[14599]\teval-rmse:3.88468\ttrain-rmse:1.99102\n",
      "[14600]\teval-rmse:3.88337\ttrain-rmse:1.991\n",
      "[14601]\teval-rmse:3.88167\ttrain-rmse:1.99093\n",
      "[14602]\teval-rmse:3.88341\ttrain-rmse:1.991\n",
      "[14603]\teval-rmse:3.8851\ttrain-rmse:1.99106\n",
      "[14604]\teval-rmse:3.8844\ttrain-rmse:1.99103\n",
      "[14605]\teval-rmse:3.88483\ttrain-rmse:1.99105\n",
      "[14606]\teval-rmse:3.8848\ttrain-rmse:1.99105\n",
      "[14607]\teval-rmse:3.88658\ttrain-rmse:1.99112\n",
      "[14608]\teval-rmse:3.88706\ttrain-rmse:1.99114\n",
      "[14609]\teval-rmse:3.88489\ttrain-rmse:1.99106\n",
      "[14610]\teval-rmse:3.88558\ttrain-rmse:1.99109\n",
      "[14611]\teval-rmse:3.88677\ttrain-rmse:1.99113\n",
      "[14612]\teval-rmse:3.88671\ttrain-rmse:1.99113\n",
      "[14613]\teval-rmse:3.8853\ttrain-rmse:1.99108\n",
      "[14614]\teval-rmse:3.88449\ttrain-rmse:1.99106\n",
      "[14615]\teval-rmse:3.88609\ttrain-rmse:1.99112\n",
      "[14616]\teval-rmse:3.88707\ttrain-rmse:1.99114\n",
      "[14617]\teval-rmse:3.88668\ttrain-rmse:1.99112\n",
      "[14618]\teval-rmse:3.88475\ttrain-rmse:1.99105\n",
      "[14619]\teval-rmse:3.88556\ttrain-rmse:1.99109\n",
      "[14620]\teval-rmse:3.88583\ttrain-rmse:1.9911\n",
      "[14621]\teval-rmse:3.88383\ttrain-rmse:1.99103\n",
      "[14622]\teval-rmse:3.88322\ttrain-rmse:1.99101\n",
      "[14623]\teval-rmse:3.88262\ttrain-rmse:1.99081\n",
      "[14624]\teval-rmse:3.88235\ttrain-rmse:1.9908\n",
      "[14625]\teval-rmse:3.88072\ttrain-rmse:1.99079\n",
      "[14626]\teval-rmse:3.88209\ttrain-rmse:1.99083\n",
      "[14627]\teval-rmse:3.87995\ttrain-rmse:1.99077\n",
      "[14628]\teval-rmse:3.87877\ttrain-rmse:1.99074\n",
      "[14629]\teval-rmse:3.87977\ttrain-rmse:1.99076\n",
      "[14630]\teval-rmse:3.87858\ttrain-rmse:1.99073\n",
      "[14631]\teval-rmse:3.87669\ttrain-rmse:1.99067\n",
      "[14632]\teval-rmse:3.87484\ttrain-rmse:1.99065\n",
      "[14633]\teval-rmse:3.87504\ttrain-rmse:1.99066\n",
      "[14634]\teval-rmse:3.87554\ttrain-rmse:1.99067\n",
      "[14635]\teval-rmse:3.87498\ttrain-rmse:1.99065\n",
      "[14636]\teval-rmse:3.87362\ttrain-rmse:1.99063\n",
      "[14637]\teval-rmse:3.87129\ttrain-rmse:1.99062\n",
      "[14638]\teval-rmse:3.86938\ttrain-rmse:1.99061\n",
      "[14639]\teval-rmse:3.87143\ttrain-rmse:1.99064\n",
      "[14640]\teval-rmse:3.87183\ttrain-rmse:1.99064\n",
      "[14641]\teval-rmse:3.87256\ttrain-rmse:1.99064\n",
      "[14642]\teval-rmse:3.87367\ttrain-rmse:1.99065\n",
      "[14643]\teval-rmse:3.87544\ttrain-rmse:1.99066\n",
      "[14644]\teval-rmse:3.87565\ttrain-rmse:1.99066\n",
      "[14645]\teval-rmse:3.87683\ttrain-rmse:1.99068\n",
      "[14646]\teval-rmse:3.87625\ttrain-rmse:1.99046\n",
      "[14647]\teval-rmse:3.87635\ttrain-rmse:1.99046\n",
      "[14648]\teval-rmse:3.87702\ttrain-rmse:1.99048\n",
      "[14649]\teval-rmse:3.87881\ttrain-rmse:1.99053\n",
      "[14650]\teval-rmse:3.87948\ttrain-rmse:1.99055\n",
      "[14651]\teval-rmse:3.88078\ttrain-rmse:1.99059\n",
      "[14652]\teval-rmse:3.8828\ttrain-rmse:1.99066\n",
      "[14653]\teval-rmse:3.88408\ttrain-rmse:1.99071\n",
      "[14654]\teval-rmse:3.88218\ttrain-rmse:1.99065\n",
      "[14655]\teval-rmse:3.88355\ttrain-rmse:1.9907\n",
      "[14656]\teval-rmse:3.88441\ttrain-rmse:1.99073\n",
      "[14657]\teval-rmse:3.88509\ttrain-rmse:1.99076\n",
      "[14658]\teval-rmse:3.88536\ttrain-rmse:1.99076\n",
      "[14659]\teval-rmse:3.88539\ttrain-rmse:1.99077\n",
      "[14660]\teval-rmse:3.88502\ttrain-rmse:1.99075\n",
      "[14661]\teval-rmse:3.88544\ttrain-rmse:1.99077\n",
      "[14662]\teval-rmse:3.88571\ttrain-rmse:1.99078\n",
      "[14663]\teval-rmse:3.8851\ttrain-rmse:1.99076\n",
      "[14664]\teval-rmse:3.88351\ttrain-rmse:1.99068\n",
      "[14665]\teval-rmse:3.88221\ttrain-rmse:1.99064\n",
      "[14666]\teval-rmse:3.88045\ttrain-rmse:1.99057\n",
      "[14667]\teval-rmse:3.88019\ttrain-rmse:1.99056\n",
      "[14668]\teval-rmse:3.87873\ttrain-rmse:1.99052\n",
      "[14669]\teval-rmse:3.87839\ttrain-rmse:1.99051\n",
      "[14670]\teval-rmse:3.87931\ttrain-rmse:1.99054\n",
      "[14671]\teval-rmse:3.87954\ttrain-rmse:1.99055\n",
      "[14672]\teval-rmse:3.87863\ttrain-rmse:1.99053\n",
      "[14673]\teval-rmse:3.88065\ttrain-rmse:1.99059\n",
      "[14674]\teval-rmse:3.87835\ttrain-rmse:1.99054\n",
      "[14675]\teval-rmse:3.87885\ttrain-rmse:1.99055\n",
      "[14676]\teval-rmse:3.87997\ttrain-rmse:1.99058\n",
      "[14677]\teval-rmse:3.87777\ttrain-rmse:1.99054\n",
      "[14678]\teval-rmse:3.87677\ttrain-rmse:1.99052\n",
      "[14679]\teval-rmse:3.87446\ttrain-rmse:1.9905\n",
      "[14680]\teval-rmse:3.8737\ttrain-rmse:1.9905\n",
      "[14681]\teval-rmse:3.87315\ttrain-rmse:1.99049\n",
      "[14682]\teval-rmse:3.87509\ttrain-rmse:1.99052\n",
      "[14683]\teval-rmse:3.87711\ttrain-rmse:1.99057\n",
      "[14684]\teval-rmse:3.87594\ttrain-rmse:1.99054\n",
      "[14685]\teval-rmse:3.87385\ttrain-rmse:1.9905\n",
      "[14686]\teval-rmse:3.87404\ttrain-rmse:1.99051\n",
      "[14687]\teval-rmse:3.87338\ttrain-rmse:1.99051\n",
      "[14688]\teval-rmse:3.87316\ttrain-rmse:1.9905\n",
      "[14689]\teval-rmse:3.87252\ttrain-rmse:1.99049\n",
      "[14690]\teval-rmse:3.87168\ttrain-rmse:1.99048\n",
      "[14691]\teval-rmse:3.87253\ttrain-rmse:1.99049\n",
      "[14692]\teval-rmse:3.87396\ttrain-rmse:1.99052\n",
      "[14693]\teval-rmse:3.8753\ttrain-rmse:1.99053\n",
      "[14694]\teval-rmse:3.87373\ttrain-rmse:1.9905\n",
      "[14695]\teval-rmse:3.87452\ttrain-rmse:1.99051\n",
      "[14696]\teval-rmse:3.8749\ttrain-rmse:1.99052\n",
      "[14697]\teval-rmse:3.8756\ttrain-rmse:1.99053\n",
      "[14698]\teval-rmse:3.87721\ttrain-rmse:1.99053\n",
      "[14699]\teval-rmse:3.87813\ttrain-rmse:1.99056\n",
      "[14700]\teval-rmse:3.87878\ttrain-rmse:1.99057\n",
      "[14701]\teval-rmse:3.87737\ttrain-rmse:1.99053\n",
      "[14702]\teval-rmse:3.87702\ttrain-rmse:1.99052\n",
      "[14703]\teval-rmse:3.87613\ttrain-rmse:1.9905\n",
      "[14704]\teval-rmse:3.87412\ttrain-rmse:1.99046\n",
      "[14705]\teval-rmse:3.87417\ttrain-rmse:1.99046\n",
      "[14706]\teval-rmse:3.87469\ttrain-rmse:1.99047\n",
      "[14707]\teval-rmse:3.87569\ttrain-rmse:1.99046\n",
      "[14708]\teval-rmse:3.87616\ttrain-rmse:1.99047\n",
      "[14709]\teval-rmse:3.87744\ttrain-rmse:1.99048\n",
      "[14710]\teval-rmse:3.87788\ttrain-rmse:1.99049\n",
      "[14711]\teval-rmse:3.87754\ttrain-rmse:1.99048\n",
      "[14712]\teval-rmse:3.87729\ttrain-rmse:1.99048\n",
      "[14713]\teval-rmse:3.87592\ttrain-rmse:1.99045\n",
      "[14714]\teval-rmse:3.87762\ttrain-rmse:1.99047\n",
      "[14715]\teval-rmse:3.87909\ttrain-rmse:1.9905\n",
      "[14716]\teval-rmse:3.87868\ttrain-rmse:1.99049\n",
      "[14717]\teval-rmse:3.8781\ttrain-rmse:1.99047\n",
      "[14718]\teval-rmse:3.87784\ttrain-rmse:1.99046\n",
      "[14719]\teval-rmse:3.87726\ttrain-rmse:1.99045\n",
      "[14720]\teval-rmse:3.87567\ttrain-rmse:1.99041\n",
      "[14721]\teval-rmse:3.87408\ttrain-rmse:1.99038\n",
      "[14722]\teval-rmse:3.87376\ttrain-rmse:1.99037\n",
      "[14723]\teval-rmse:3.87287\ttrain-rmse:1.99037\n",
      "[14724]\teval-rmse:3.87154\ttrain-rmse:1.99035\n",
      "[14725]\teval-rmse:3.871\ttrain-rmse:1.99034\n",
      "[14726]\teval-rmse:3.87035\ttrain-rmse:1.99034\n",
      "[14727]\teval-rmse:3.869\ttrain-rmse:1.99034\n",
      "[14728]\teval-rmse:3.86727\ttrain-rmse:1.99033\n",
      "[14729]\teval-rmse:3.86738\ttrain-rmse:1.99033\n",
      "[14730]\teval-rmse:3.86632\ttrain-rmse:1.99034\n",
      "[14731]\teval-rmse:3.86696\ttrain-rmse:1.99033\n",
      "[14732]\teval-rmse:3.86634\ttrain-rmse:1.99034\n",
      "[14733]\teval-rmse:3.86586\ttrain-rmse:1.99016\n",
      "[14734]\teval-rmse:3.86666\ttrain-rmse:1.99016\n",
      "[14735]\teval-rmse:3.86713\ttrain-rmse:1.99016\n",
      "[14736]\teval-rmse:3.86526\ttrain-rmse:1.99018\n",
      "[14737]\teval-rmse:3.86479\ttrain-rmse:1.98997\n",
      "[14738]\teval-rmse:3.86392\ttrain-rmse:1.98998\n",
      "[14739]\teval-rmse:3.86322\ttrain-rmse:1.99\n",
      "[14740]\teval-rmse:3.86403\ttrain-rmse:1.99\n",
      "[14741]\teval-rmse:3.86297\ttrain-rmse:1.99001\n",
      "[14742]\teval-rmse:3.86246\ttrain-rmse:1.98981\n",
      "[14743]\teval-rmse:3.86326\ttrain-rmse:1.9898\n",
      "[14744]\teval-rmse:3.86379\ttrain-rmse:1.9898\n",
      "[14745]\teval-rmse:3.86328\ttrain-rmse:1.9898\n",
      "[14746]\teval-rmse:3.8649\ttrain-rmse:1.98976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14747]\teval-rmse:3.86557\ttrain-rmse:1.98975\n",
      "[14748]\teval-rmse:3.86446\ttrain-rmse:1.98975\n",
      "[14749]\teval-rmse:3.86498\ttrain-rmse:1.98975\n",
      "[14750]\teval-rmse:3.8666\ttrain-rmse:1.98972\n",
      "[14751]\teval-rmse:3.8652\ttrain-rmse:1.98971\n",
      "[14752]\teval-rmse:3.86419\ttrain-rmse:1.98973\n",
      "[14753]\teval-rmse:3.86521\ttrain-rmse:1.9897\n",
      "[14754]\teval-rmse:3.86368\ttrain-rmse:1.98971\n",
      "[14755]\teval-rmse:3.86377\ttrain-rmse:1.98971\n",
      "[14756]\teval-rmse:3.86499\ttrain-rmse:1.98969\n",
      "[14757]\teval-rmse:3.86561\ttrain-rmse:1.98969\n",
      "[14758]\teval-rmse:3.86623\ttrain-rmse:1.98969\n",
      "[14759]\teval-rmse:3.8657\ttrain-rmse:1.9895\n",
      "[14760]\teval-rmse:3.86617\ttrain-rmse:1.9895\n",
      "[14761]\teval-rmse:3.86718\ttrain-rmse:1.98948\n",
      "[14762]\teval-rmse:3.86902\ttrain-rmse:1.98949\n",
      "[14763]\teval-rmse:3.87074\ttrain-rmse:1.9895\n",
      "[14764]\teval-rmse:3.87235\ttrain-rmse:1.98952\n",
      "[14765]\teval-rmse:3.871\ttrain-rmse:1.98952\n",
      "[14766]\teval-rmse:3.86995\ttrain-rmse:1.98951\n",
      "[14767]\teval-rmse:3.86843\ttrain-rmse:1.98949\n",
      "[14768]\teval-rmse:3.8671\ttrain-rmse:1.98951\n",
      "[14769]\teval-rmse:3.86528\ttrain-rmse:1.98952\n",
      "[14770]\teval-rmse:3.86367\ttrain-rmse:1.98952\n",
      "[14771]\teval-rmse:3.86235\ttrain-rmse:1.98953\n",
      "[14772]\teval-rmse:3.86106\ttrain-rmse:1.98956\n",
      "[14773]\teval-rmse:3.85997\ttrain-rmse:1.98956\n",
      "[14774]\teval-rmse:3.86126\ttrain-rmse:1.98954\n",
      "[14775]\teval-rmse:3.85917\ttrain-rmse:1.98958\n",
      "[14776]\teval-rmse:3.85958\ttrain-rmse:1.98957\n",
      "[14777]\teval-rmse:3.86007\ttrain-rmse:1.98956\n",
      "[14778]\teval-rmse:3.86118\ttrain-rmse:1.98955\n",
      "[14779]\teval-rmse:3.86113\ttrain-rmse:1.98955\n",
      "[14780]\teval-rmse:3.86175\ttrain-rmse:1.98955\n",
      "[14781]\teval-rmse:3.86212\ttrain-rmse:1.98955\n",
      "[14782]\teval-rmse:3.86365\ttrain-rmse:1.98954\n",
      "[14783]\teval-rmse:3.86532\ttrain-rmse:1.98954\n",
      "[14784]\teval-rmse:3.86699\ttrain-rmse:1.98954\n",
      "[14785]\teval-rmse:3.86804\ttrain-rmse:1.98955\n",
      "[14786]\teval-rmse:3.86604\ttrain-rmse:1.98954\n",
      "[14787]\teval-rmse:3.86418\ttrain-rmse:1.98954\n",
      "[14788]\teval-rmse:3.8658\ttrain-rmse:1.98954\n",
      "[14789]\teval-rmse:3.86573\ttrain-rmse:1.98954\n",
      "[14790]\teval-rmse:3.86441\ttrain-rmse:1.98957\n",
      "[14791]\teval-rmse:3.86479\ttrain-rmse:1.98956\n",
      "[14792]\teval-rmse:3.86431\ttrain-rmse:1.98957\n",
      "[14793]\teval-rmse:3.86635\ttrain-rmse:1.98958\n",
      "[14794]\teval-rmse:3.867\ttrain-rmse:1.98959\n",
      "[14795]\teval-rmse:3.86583\ttrain-rmse:1.98959\n",
      "[14796]\teval-rmse:3.86489\ttrain-rmse:1.98958\n",
      "[14797]\teval-rmse:3.86523\ttrain-rmse:1.98959\n",
      "[14798]\teval-rmse:3.86569\ttrain-rmse:1.98958\n",
      "[14799]\teval-rmse:3.86679\ttrain-rmse:1.98958\n",
      "[14800]\teval-rmse:3.86873\ttrain-rmse:1.98955\n",
      "[14801]\teval-rmse:3.86843\ttrain-rmse:1.98955\n",
      "[14802]\teval-rmse:3.86688\ttrain-rmse:1.98954\n",
      "[14803]\teval-rmse:3.86827\ttrain-rmse:1.98955\n",
      "[14804]\teval-rmse:3.87021\ttrain-rmse:1.98952\n",
      "[14805]\teval-rmse:3.86972\ttrain-rmse:1.98952\n",
      "[14806]\teval-rmse:3.87049\ttrain-rmse:1.98952\n",
      "[14807]\teval-rmse:3.86923\ttrain-rmse:1.98951\n",
      "[14808]\teval-rmse:3.86874\ttrain-rmse:1.98951\n",
      "[14809]\teval-rmse:3.86925\ttrain-rmse:1.98951\n",
      "[14810]\teval-rmse:3.87129\ttrain-rmse:1.98954\n",
      "[14811]\teval-rmse:3.87079\ttrain-rmse:1.98935\n",
      "[14812]\teval-rmse:3.87181\ttrain-rmse:1.98937\n",
      "[14813]\teval-rmse:3.87068\ttrain-rmse:1.98935\n",
      "[14814]\teval-rmse:3.87251\ttrain-rmse:1.98938\n",
      "[14815]\teval-rmse:3.87303\ttrain-rmse:1.98939\n",
      "[14816]\teval-rmse:3.87137\ttrain-rmse:1.98937\n",
      "[14817]\teval-rmse:3.86953\ttrain-rmse:1.98934\n",
      "[14818]\teval-rmse:3.87054\ttrain-rmse:1.98933\n",
      "[14819]\teval-rmse:3.87173\ttrain-rmse:1.98935\n",
      "[14820]\teval-rmse:3.87367\ttrain-rmse:1.98934\n",
      "[14821]\teval-rmse:3.87509\ttrain-rmse:1.98937\n",
      "[14822]\teval-rmse:3.8758\ttrain-rmse:1.98938\n",
      "[14823]\teval-rmse:3.87625\ttrain-rmse:1.98939\n",
      "[14824]\teval-rmse:3.87459\ttrain-rmse:1.98936\n",
      "[14825]\teval-rmse:3.87274\ttrain-rmse:1.98933\n",
      "[14826]\teval-rmse:3.87302\ttrain-rmse:1.98933\n",
      "[14827]\teval-rmse:3.87401\ttrain-rmse:1.98934\n",
      "[14828]\teval-rmse:3.87236\ttrain-rmse:1.98931\n",
      "[14829]\teval-rmse:3.87254\ttrain-rmse:1.98931\n",
      "[14830]\teval-rmse:3.87324\ttrain-rmse:1.98933\n",
      "[14831]\teval-rmse:3.87259\ttrain-rmse:1.98932\n",
      "[14832]\teval-rmse:3.87094\ttrain-rmse:1.98931\n",
      "[14833]\teval-rmse:3.87297\ttrain-rmse:1.98934\n",
      "[14834]\teval-rmse:3.8714\ttrain-rmse:1.98932\n",
      "[14835]\teval-rmse:3.87268\ttrain-rmse:1.98933\n",
      "[14836]\teval-rmse:3.8711\ttrain-rmse:1.98934\n",
      "[14837]\teval-rmse:3.87184\ttrain-rmse:1.98935\n",
      "[14838]\teval-rmse:3.87161\ttrain-rmse:1.98934\n",
      "[14839]\teval-rmse:3.87096\ttrain-rmse:1.98935\n",
      "[14840]\teval-rmse:3.87261\ttrain-rmse:1.98937\n",
      "[14841]\teval-rmse:3.87054\ttrain-rmse:1.98935\n",
      "[14842]\teval-rmse:3.87022\ttrain-rmse:1.98935\n",
      "[14843]\teval-rmse:3.87183\ttrain-rmse:1.98937\n",
      "[14844]\teval-rmse:3.86972\ttrain-rmse:1.98936\n",
      "[14845]\teval-rmse:3.86951\ttrain-rmse:1.98936\n",
      "[14846]\teval-rmse:3.86978\ttrain-rmse:1.98936\n",
      "[14847]\teval-rmse:3.86788\ttrain-rmse:1.98934\n",
      "[14848]\teval-rmse:3.86734\ttrain-rmse:1.98934\n",
      "[14849]\teval-rmse:3.86672\ttrain-rmse:1.98935\n",
      "[14850]\teval-rmse:3.86846\ttrain-rmse:1.98933\n",
      "[14851]\teval-rmse:3.86957\ttrain-rmse:1.98933\n",
      "[14852]\teval-rmse:3.86834\ttrain-rmse:1.98935\n",
      "[14853]\teval-rmse:3.86786\ttrain-rmse:1.98915\n",
      "[14854]\teval-rmse:3.86734\ttrain-rmse:1.98896\n",
      "[14855]\teval-rmse:3.86598\ttrain-rmse:1.98896\n",
      "[14856]\teval-rmse:3.8655\ttrain-rmse:1.98895\n",
      "[14857]\teval-rmse:3.86601\ttrain-rmse:1.98896\n",
      "[14858]\teval-rmse:3.86406\ttrain-rmse:1.98895\n",
      "[14859]\teval-rmse:3.866\ttrain-rmse:1.98891\n",
      "[14860]\teval-rmse:3.86569\ttrain-rmse:1.98891\n",
      "[14861]\teval-rmse:3.86416\ttrain-rmse:1.98891\n",
      "[14862]\teval-rmse:3.86214\ttrain-rmse:1.98892\n",
      "[14863]\teval-rmse:3.86178\ttrain-rmse:1.98893\n",
      "[14864]\teval-rmse:3.86004\ttrain-rmse:1.98896\n",
      "[14865]\teval-rmse:3.85878\ttrain-rmse:1.98899\n",
      "[14866]\teval-rmse:3.85729\ttrain-rmse:1.98902\n",
      "[14867]\teval-rmse:3.85751\ttrain-rmse:1.98901\n",
      "[14868]\teval-rmse:3.85725\ttrain-rmse:1.98901\n",
      "[14869]\teval-rmse:3.85887\ttrain-rmse:1.98899\n",
      "[14870]\teval-rmse:3.85758\ttrain-rmse:1.98903\n",
      "[14871]\teval-rmse:3.85602\ttrain-rmse:1.98908\n",
      "[14872]\teval-rmse:3.85641\ttrain-rmse:1.98906\n",
      "[14873]\teval-rmse:3.85547\ttrain-rmse:1.9891\n",
      "[14874]\teval-rmse:3.8572\ttrain-rmse:1.98906\n",
      "[14875]\teval-rmse:3.85594\ttrain-rmse:1.98911\n",
      "[14876]\teval-rmse:3.85578\ttrain-rmse:1.9891\n",
      "[14877]\teval-rmse:3.85782\ttrain-rmse:1.98909\n",
      "[14878]\teval-rmse:3.85656\ttrain-rmse:1.98914\n",
      "[14879]\teval-rmse:3.85679\ttrain-rmse:1.98913\n",
      "[14880]\teval-rmse:3.85611\ttrain-rmse:1.98914\n",
      "[14881]\teval-rmse:3.85446\ttrain-rmse:1.98921\n",
      "[14882]\teval-rmse:3.85466\ttrain-rmse:1.9892\n",
      "[14883]\teval-rmse:3.85315\ttrain-rmse:1.98925\n",
      "[14884]\teval-rmse:3.85436\ttrain-rmse:1.9892\n",
      "[14885]\teval-rmse:3.85268\ttrain-rmse:1.98925\n",
      "[14886]\teval-rmse:3.85301\ttrain-rmse:1.98924\n",
      "[14887]\teval-rmse:3.85374\ttrain-rmse:1.98922\n",
      "[14888]\teval-rmse:3.8536\ttrain-rmse:1.98922\n",
      "[14889]\teval-rmse:3.85268\ttrain-rmse:1.98925\n",
      "[14890]\teval-rmse:3.85214\ttrain-rmse:1.98927\n",
      "[14891]\teval-rmse:3.85028\ttrain-rmse:1.98936\n",
      "[14892]\teval-rmse:3.84925\ttrain-rmse:1.98937\n",
      "[14893]\teval-rmse:3.8475\ttrain-rmse:1.98945\n",
      "[14894]\teval-rmse:3.84819\ttrain-rmse:1.98941\n",
      "[14895]\teval-rmse:3.84884\ttrain-rmse:1.98937\n",
      "[14896]\teval-rmse:3.85055\ttrain-rmse:1.98928\n",
      "[14897]\teval-rmse:3.85182\ttrain-rmse:1.98922\n",
      "[14898]\teval-rmse:3.85287\ttrain-rmse:1.98917\n",
      "[14899]\teval-rmse:3.8516\ttrain-rmse:1.98921\n",
      "[14900]\teval-rmse:3.85056\ttrain-rmse:1.98923\n",
      "[14901]\teval-rmse:3.85177\ttrain-rmse:1.98918\n",
      "[14902]\teval-rmse:3.85359\ttrain-rmse:1.9891\n",
      "[14903]\teval-rmse:3.85563\ttrain-rmse:1.98908\n",
      "[14904]\teval-rmse:3.85517\ttrain-rmse:1.98908\n",
      "[14905]\teval-rmse:3.8547\ttrain-rmse:1.98908\n",
      "[14906]\teval-rmse:3.85365\ttrain-rmse:1.9891\n",
      "[14907]\teval-rmse:3.85541\ttrain-rmse:1.98905\n",
      "[14908]\teval-rmse:3.85394\ttrain-rmse:1.98911\n",
      "[14909]\teval-rmse:3.8526\ttrain-rmse:1.98915\n",
      "[14910]\teval-rmse:3.85236\ttrain-rmse:1.98915\n",
      "[14911]\teval-rmse:3.85201\ttrain-rmse:1.98917\n",
      "[14912]\teval-rmse:3.85364\ttrain-rmse:1.98909\n",
      "[14913]\teval-rmse:3.85526\ttrain-rmse:1.98905\n",
      "[14914]\teval-rmse:3.85555\ttrain-rmse:1.98904\n",
      "[14915]\teval-rmse:3.85439\ttrain-rmse:1.98907\n",
      "[14916]\teval-rmse:3.85441\ttrain-rmse:1.98907\n",
      "[14917]\teval-rmse:3.85375\ttrain-rmse:1.9891\n",
      "[14918]\teval-rmse:3.85291\ttrain-rmse:1.98912\n",
      "[14919]\teval-rmse:3.85363\ttrain-rmse:1.9891\n",
      "[14920]\teval-rmse:3.85526\ttrain-rmse:1.98906\n",
      "[14921]\teval-rmse:3.85732\ttrain-rmse:1.98904\n",
      "[14922]\teval-rmse:3.85716\ttrain-rmse:1.98904\n",
      "[14923]\teval-rmse:3.85577\ttrain-rmse:1.98907\n",
      "[14924]\teval-rmse:3.85646\ttrain-rmse:1.98905\n",
      "[14925]\teval-rmse:3.8554\ttrain-rmse:1.98906\n",
      "[14926]\teval-rmse:3.85695\ttrain-rmse:1.98901\n",
      "[14927]\teval-rmse:3.85715\ttrain-rmse:1.98901\n",
      "[14928]\teval-rmse:3.85733\ttrain-rmse:1.989\n",
      "[14929]\teval-rmse:3.85685\ttrain-rmse:1.98881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14930]\teval-rmse:3.85692\ttrain-rmse:1.98881\n",
      "[14931]\teval-rmse:3.85733\ttrain-rmse:1.9888\n",
      "[14932]\teval-rmse:3.85837\ttrain-rmse:1.98877\n",
      "[14933]\teval-rmse:3.86003\ttrain-rmse:1.98875\n",
      "[14934]\teval-rmse:3.85894\ttrain-rmse:1.98875\n",
      "[14935]\teval-rmse:3.85975\ttrain-rmse:1.98874\n",
      "[14936]\teval-rmse:3.86178\ttrain-rmse:1.98874\n",
      "[14937]\teval-rmse:3.8625\ttrain-rmse:1.98874\n",
      "[14938]\teval-rmse:3.86435\ttrain-rmse:1.98873\n",
      "[14939]\teval-rmse:3.86241\ttrain-rmse:1.98874\n",
      "[14940]\teval-rmse:3.86354\ttrain-rmse:1.98874\n",
      "[14941]\teval-rmse:3.86429\ttrain-rmse:1.98874\n",
      "[14942]\teval-rmse:3.86358\ttrain-rmse:1.98876\n",
      "[14943]\teval-rmse:3.86199\ttrain-rmse:1.98876\n",
      "[14944]\teval-rmse:3.86243\ttrain-rmse:1.98876\n",
      "[14945]\teval-rmse:3.86414\ttrain-rmse:1.98875\n",
      "[14946]\teval-rmse:3.86304\ttrain-rmse:1.98874\n",
      "[14947]\teval-rmse:3.86194\ttrain-rmse:1.98874\n",
      "[14948]\teval-rmse:3.86064\ttrain-rmse:1.98877\n",
      "[14949]\teval-rmse:3.86078\ttrain-rmse:1.98877\n",
      "[14950]\teval-rmse:3.8604\ttrain-rmse:1.98877\n",
      "[14951]\teval-rmse:3.85967\ttrain-rmse:1.98878\n",
      "[14952]\teval-rmse:3.8584\ttrain-rmse:1.98879\n",
      "[14953]\teval-rmse:3.85803\ttrain-rmse:1.9888\n",
      "[14954]\teval-rmse:3.85855\ttrain-rmse:1.98879\n",
      "[14955]\teval-rmse:3.8583\ttrain-rmse:1.98879\n",
      "[14956]\teval-rmse:3.85753\ttrain-rmse:1.9888\n",
      "[14957]\teval-rmse:3.85719\ttrain-rmse:1.98881\n",
      "[14958]\teval-rmse:3.85692\ttrain-rmse:1.98881\n",
      "[14959]\teval-rmse:3.85876\ttrain-rmse:1.98875\n",
      "[14960]\teval-rmse:3.86042\ttrain-rmse:1.98873\n",
      "[14961]\teval-rmse:3.86212\ttrain-rmse:1.98872\n",
      "[14962]\teval-rmse:3.86165\ttrain-rmse:1.98872\n",
      "[14963]\teval-rmse:3.86206\ttrain-rmse:1.98872\n",
      "[14964]\teval-rmse:3.86334\ttrain-rmse:1.98871\n",
      "[14965]\teval-rmse:3.86141\ttrain-rmse:1.98872\n",
      "[14966]\teval-rmse:3.86221\ttrain-rmse:1.98872\n",
      "[14967]\teval-rmse:3.86106\ttrain-rmse:1.98872\n",
      "[14968]\teval-rmse:3.8622\ttrain-rmse:1.98871\n",
      "[14969]\teval-rmse:3.86068\ttrain-rmse:1.98872\n",
      "[14970]\teval-rmse:3.86162\ttrain-rmse:1.98872\n",
      "[14971]\teval-rmse:3.86347\ttrain-rmse:1.98871\n",
      "[14972]\teval-rmse:3.86226\ttrain-rmse:1.98873\n",
      "[14973]\teval-rmse:3.86342\ttrain-rmse:1.98874\n",
      "[14974]\teval-rmse:3.86291\ttrain-rmse:1.98856\n",
      "[14975]\teval-rmse:3.86181\ttrain-rmse:1.98855\n",
      "[14976]\teval-rmse:3.8634\ttrain-rmse:1.98855\n",
      "[14977]\teval-rmse:3.86478\ttrain-rmse:1.98855\n",
      "[14978]\teval-rmse:3.8663\ttrain-rmse:1.98856\n",
      "[14979]\teval-rmse:3.86766\ttrain-rmse:1.98857\n",
      "[14980]\teval-rmse:3.86736\ttrain-rmse:1.98857\n",
      "[14981]\teval-rmse:3.86512\ttrain-rmse:1.98855\n",
      "[14982]\teval-rmse:3.86401\ttrain-rmse:1.98854\n",
      "[14983]\teval-rmse:3.86434\ttrain-rmse:1.98854\n",
      "[14984]\teval-rmse:3.86552\ttrain-rmse:1.98856\n",
      "[14985]\teval-rmse:3.8648\ttrain-rmse:1.98855\n",
      "[14986]\teval-rmse:3.86664\ttrain-rmse:1.98857\n",
      "[14987]\teval-rmse:3.86644\ttrain-rmse:1.98857\n",
      "[14988]\teval-rmse:3.86531\ttrain-rmse:1.98856\n",
      "[14989]\teval-rmse:3.86734\ttrain-rmse:1.98858\n",
      "[14990]\teval-rmse:3.86916\ttrain-rmse:1.98856\n",
      "[14991]\teval-rmse:3.86931\ttrain-rmse:1.98856\n",
      "[14992]\teval-rmse:3.86878\ttrain-rmse:1.98856\n",
      "[14993]\teval-rmse:3.86773\ttrain-rmse:1.98854\n",
      "[14994]\teval-rmse:3.86909\ttrain-rmse:1.98856\n",
      "[14995]\teval-rmse:3.86877\ttrain-rmse:1.98855\n",
      "[14996]\teval-rmse:3.87037\ttrain-rmse:1.98858\n",
      "[14997]\teval-rmse:3.86844\ttrain-rmse:1.98854\n",
      "[14998]\teval-rmse:3.8698\ttrain-rmse:1.98856\n",
      "[14999]\teval-rmse:3.87182\ttrain-rmse:1.9886\n",
      "[15000]\teval-rmse:3.87107\ttrain-rmse:1.98858\n",
      "[15001]\teval-rmse:3.8725\ttrain-rmse:1.98861\n",
      "[15002]\teval-rmse:3.87217\ttrain-rmse:1.9886\n",
      "[15003]\teval-rmse:3.87195\ttrain-rmse:1.9886\n",
      "[15004]\teval-rmse:3.8708\ttrain-rmse:1.98858\n",
      "[15005]\teval-rmse:3.87149\ttrain-rmse:1.98859\n",
      "[15006]\teval-rmse:3.87034\ttrain-rmse:1.98857\n",
      "[15007]\teval-rmse:3.86898\ttrain-rmse:1.98858\n",
      "[15008]\teval-rmse:3.87026\ttrain-rmse:1.9886\n",
      "[15009]\teval-rmse:3.86862\ttrain-rmse:1.98857\n",
      "[15010]\teval-rmse:3.86635\ttrain-rmse:1.98853\n",
      "[15011]\teval-rmse:3.86736\ttrain-rmse:1.98855\n",
      "[15012]\teval-rmse:3.86785\ttrain-rmse:1.98856\n",
      "[15013]\teval-rmse:3.86917\ttrain-rmse:1.98858\n",
      "[15014]\teval-rmse:3.86935\ttrain-rmse:1.98858\n",
      "[15015]\teval-rmse:3.86886\ttrain-rmse:1.98841\n",
      "[15016]\teval-rmse:3.86854\ttrain-rmse:1.9884\n",
      "[15017]\teval-rmse:3.86923\ttrain-rmse:1.98842\n",
      "[15018]\teval-rmse:3.86743\ttrain-rmse:1.98839\n",
      "[15019]\teval-rmse:3.86748\ttrain-rmse:1.98839\n",
      "[15020]\teval-rmse:3.86938\ttrain-rmse:1.98843\n",
      "[15021]\teval-rmse:3.87023\ttrain-rmse:1.98844\n",
      "[15022]\teval-rmse:3.86969\ttrain-rmse:1.98843\n",
      "[15023]\teval-rmse:3.86891\ttrain-rmse:1.98842\n",
      "[15024]\teval-rmse:3.86823\ttrain-rmse:1.9884\n",
      "[15025]\teval-rmse:3.86933\ttrain-rmse:1.98842\n",
      "[15026]\teval-rmse:3.86724\ttrain-rmse:1.98838\n",
      "[15027]\teval-rmse:3.86762\ttrain-rmse:1.98839\n",
      "[15028]\teval-rmse:3.86889\ttrain-rmse:1.98842\n",
      "[15029]\teval-rmse:3.87055\ttrain-rmse:1.98846\n",
      "[15030]\teval-rmse:3.87068\ttrain-rmse:1.98846\n",
      "[15031]\teval-rmse:3.87154\ttrain-rmse:1.98848\n",
      "[15032]\teval-rmse:3.87121\ttrain-rmse:1.98847\n",
      "[15033]\teval-rmse:3.87168\ttrain-rmse:1.98849\n",
      "[15034]\teval-rmse:3.87054\ttrain-rmse:1.98847\n",
      "[15035]\teval-rmse:3.86928\ttrain-rmse:1.98847\n",
      "[15036]\teval-rmse:3.86813\ttrain-rmse:1.98845\n",
      "[15037]\teval-rmse:3.8665\ttrain-rmse:1.98841\n",
      "[15038]\teval-rmse:3.86527\ttrain-rmse:1.98839\n",
      "[15039]\teval-rmse:3.86497\ttrain-rmse:1.98839\n",
      "[15040]\teval-rmse:3.86589\ttrain-rmse:1.9884\n",
      "[15041]\teval-rmse:3.86689\ttrain-rmse:1.98842\n",
      "[15042]\teval-rmse:3.867\ttrain-rmse:1.98842\n",
      "[15043]\teval-rmse:3.86857\ttrain-rmse:1.98845\n",
      "[15044]\teval-rmse:3.86669\ttrain-rmse:1.98842\n",
      "[15045]\teval-rmse:3.86528\ttrain-rmse:1.98839\n",
      "[15046]\teval-rmse:3.86525\ttrain-rmse:1.98839\n",
      "[15047]\teval-rmse:3.86577\ttrain-rmse:1.9884\n",
      "[15048]\teval-rmse:3.86511\ttrain-rmse:1.98823\n",
      "[15049]\teval-rmse:3.8647\ttrain-rmse:1.98823\n",
      "[15050]\teval-rmse:3.86309\ttrain-rmse:1.9882\n",
      "[15051]\teval-rmse:3.86364\ttrain-rmse:1.98821\n",
      "[15052]\teval-rmse:3.86219\ttrain-rmse:1.9882\n",
      "[15053]\teval-rmse:3.86246\ttrain-rmse:1.9882\n",
      "[15054]\teval-rmse:3.8619\ttrain-rmse:1.9882\n",
      "[15055]\teval-rmse:3.86013\ttrain-rmse:1.9882\n",
      "[15056]\teval-rmse:3.85857\ttrain-rmse:1.9882\n",
      "[15057]\teval-rmse:3.85811\ttrain-rmse:1.9882\n",
      "[15058]\teval-rmse:3.8576\ttrain-rmse:1.9882\n",
      "[15059]\teval-rmse:3.85631\ttrain-rmse:1.98821\n",
      "[15060]\teval-rmse:3.85605\ttrain-rmse:1.98821\n",
      "[15061]\teval-rmse:3.85767\ttrain-rmse:1.98819\n",
      "[15062]\teval-rmse:3.85701\ttrain-rmse:1.9882\n",
      "[15063]\teval-rmse:3.85582\ttrain-rmse:1.98823\n",
      "[15064]\teval-rmse:3.85651\ttrain-rmse:1.98822\n",
      "[15065]\teval-rmse:3.85494\ttrain-rmse:1.98824\n",
      "[15066]\teval-rmse:3.85496\ttrain-rmse:1.98824\n",
      "[15067]\teval-rmse:3.85657\ttrain-rmse:1.98819\n",
      "[15068]\teval-rmse:3.85725\ttrain-rmse:1.98818\n",
      "[15069]\teval-rmse:3.85835\ttrain-rmse:1.98818\n",
      "[15070]\teval-rmse:3.85787\ttrain-rmse:1.98818\n",
      "[15071]\teval-rmse:3.85595\ttrain-rmse:1.9882\n",
      "[15072]\teval-rmse:3.85395\ttrain-rmse:1.98823\n",
      "[15073]\teval-rmse:3.85224\ttrain-rmse:1.98826\n",
      "[15074]\teval-rmse:3.85404\ttrain-rmse:1.98822\n",
      "[15075]\teval-rmse:3.85609\ttrain-rmse:1.9882\n",
      "[15076]\teval-rmse:3.85791\ttrain-rmse:1.98815\n",
      "[15077]\teval-rmse:3.85742\ttrain-rmse:1.98815\n",
      "[15078]\teval-rmse:3.85946\ttrain-rmse:1.98814\n",
      "[15079]\teval-rmse:3.85983\ttrain-rmse:1.98814\n",
      "[15080]\teval-rmse:3.85934\ttrain-rmse:1.98796\n",
      "[15081]\teval-rmse:3.85751\ttrain-rmse:1.98797\n",
      "[15082]\teval-rmse:3.85682\ttrain-rmse:1.98799\n",
      "[15083]\teval-rmse:3.85665\ttrain-rmse:1.98799\n",
      "[15084]\teval-rmse:3.85718\ttrain-rmse:1.98799\n",
      "[15085]\teval-rmse:3.85671\ttrain-rmse:1.98799\n",
      "[15086]\teval-rmse:3.85523\ttrain-rmse:1.98801\n",
      "[15087]\teval-rmse:3.85393\ttrain-rmse:1.98803\n",
      "[15088]\teval-rmse:3.85472\ttrain-rmse:1.98802\n",
      "[15089]\teval-rmse:3.85456\ttrain-rmse:1.98802\n",
      "[15090]\teval-rmse:3.8562\ttrain-rmse:1.988\n",
      "[15091]\teval-rmse:3.85459\ttrain-rmse:1.98802\n",
      "[15092]\teval-rmse:3.85309\ttrain-rmse:1.98804\n",
      "[15093]\teval-rmse:3.85224\ttrain-rmse:1.98806\n",
      "[15094]\teval-rmse:3.85077\ttrain-rmse:1.98812\n",
      "[15095]\teval-rmse:3.84963\ttrain-rmse:1.98815\n",
      "[15096]\teval-rmse:3.84879\ttrain-rmse:1.98817\n",
      "[15097]\teval-rmse:3.84866\ttrain-rmse:1.98817\n",
      "[15098]\teval-rmse:3.84953\ttrain-rmse:1.98815\n",
      "[15099]\teval-rmse:3.85087\ttrain-rmse:1.98812\n",
      "[15100]\teval-rmse:3.85292\ttrain-rmse:1.98809\n",
      "[15101]\teval-rmse:3.85348\ttrain-rmse:1.98808\n",
      "[15102]\teval-rmse:3.85403\ttrain-rmse:1.98807\n",
      "[15103]\teval-rmse:3.85465\ttrain-rmse:1.98807\n",
      "[15104]\teval-rmse:3.85515\ttrain-rmse:1.98806\n",
      "[15105]\teval-rmse:3.85708\ttrain-rmse:1.988\n",
      "[15106]\teval-rmse:3.85692\ttrain-rmse:1.988\n",
      "[15107]\teval-rmse:3.85644\ttrain-rmse:1.988\n",
      "[15108]\teval-rmse:3.85495\ttrain-rmse:1.98805\n",
      "[15109]\teval-rmse:3.85678\ttrain-rmse:1.98798\n",
      "[15110]\teval-rmse:3.85779\ttrain-rmse:1.98798\n",
      "[15111]\teval-rmse:3.85971\ttrain-rmse:1.98792\n",
      "[15112]\teval-rmse:3.86049\ttrain-rmse:1.98792\n",
      "[15113]\teval-rmse:3.86047\ttrain-rmse:1.98792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15114]\teval-rmse:3.85966\ttrain-rmse:1.98792\n",
      "[15115]\teval-rmse:3.86119\ttrain-rmse:1.98792\n",
      "[15116]\teval-rmse:3.86165\ttrain-rmse:1.98792\n",
      "[15117]\teval-rmse:3.85959\ttrain-rmse:1.98791\n",
      "[15118]\teval-rmse:3.85993\ttrain-rmse:1.98791\n",
      "[15119]\teval-rmse:3.86171\ttrain-rmse:1.98792\n",
      "[15120]\teval-rmse:3.8629\ttrain-rmse:1.98792\n",
      "[15121]\teval-rmse:3.86217\ttrain-rmse:1.98792\n",
      "[15122]\teval-rmse:3.861\ttrain-rmse:1.98792\n",
      "[15123]\teval-rmse:3.86249\ttrain-rmse:1.98793\n",
      "[15124]\teval-rmse:3.8626\ttrain-rmse:1.98793\n",
      "[15125]\teval-rmse:3.86241\ttrain-rmse:1.98793\n",
      "[15126]\teval-rmse:3.86191\ttrain-rmse:1.98793\n",
      "[15127]\teval-rmse:3.86028\ttrain-rmse:1.98791\n",
      "[15128]\teval-rmse:3.85819\ttrain-rmse:1.98791\n",
      "[15129]\teval-rmse:3.85745\ttrain-rmse:1.98791\n",
      "[15130]\teval-rmse:3.85896\ttrain-rmse:1.98791\n",
      "[15131]\teval-rmse:3.85776\ttrain-rmse:1.98794\n",
      "[15132]\teval-rmse:3.85938\ttrain-rmse:1.98794\n",
      "[15133]\teval-rmse:3.86006\ttrain-rmse:1.98794\n",
      "[15134]\teval-rmse:3.86191\ttrain-rmse:1.98795\n",
      "[15135]\teval-rmse:3.86231\ttrain-rmse:1.98795\n",
      "[15136]\teval-rmse:3.86023\ttrain-rmse:1.98793\n",
      "[15137]\teval-rmse:3.86143\ttrain-rmse:1.98794\n",
      "[15138]\teval-rmse:3.86124\ttrain-rmse:1.98794\n",
      "[15139]\teval-rmse:3.86167\ttrain-rmse:1.98794\n",
      "[15140]\teval-rmse:3.86199\ttrain-rmse:1.98795\n",
      "[15141]\teval-rmse:3.86349\ttrain-rmse:1.98797\n",
      "[15142]\teval-rmse:3.86264\ttrain-rmse:1.98796\n",
      "[15143]\teval-rmse:3.86214\ttrain-rmse:1.98796\n",
      "[15144]\teval-rmse:3.86267\ttrain-rmse:1.98796\n",
      "[15145]\teval-rmse:3.86279\ttrain-rmse:1.98797\n",
      "[15146]\teval-rmse:3.86459\ttrain-rmse:1.98799\n",
      "[15147]\teval-rmse:3.86464\ttrain-rmse:1.98799\n",
      "[15148]\teval-rmse:3.8632\ttrain-rmse:1.98798\n",
      "[15149]\teval-rmse:3.86451\ttrain-rmse:1.988\n",
      "[15150]\teval-rmse:3.86403\ttrain-rmse:1.98785\n",
      "[15151]\teval-rmse:3.86546\ttrain-rmse:1.98788\n",
      "[15152]\teval-rmse:3.86515\ttrain-rmse:1.98788\n",
      "[15153]\teval-rmse:3.86717\ttrain-rmse:1.9879\n",
      "[15154]\teval-rmse:3.86802\ttrain-rmse:1.98792\n",
      "[15155]\teval-rmse:3.8672\ttrain-rmse:1.9879\n",
      "[15156]\teval-rmse:3.86786\ttrain-rmse:1.98792\n",
      "[15157]\teval-rmse:3.86754\ttrain-rmse:1.98791\n",
      "[15158]\teval-rmse:3.86574\ttrain-rmse:1.98789\n",
      "[15159]\teval-rmse:3.86582\ttrain-rmse:1.98789\n",
      "[15160]\teval-rmse:3.86535\ttrain-rmse:1.98773\n",
      "[15161]\teval-rmse:3.8643\ttrain-rmse:1.98771\n",
      "[15162]\teval-rmse:3.864\ttrain-rmse:1.98771\n",
      "[15163]\teval-rmse:3.86352\ttrain-rmse:1.9877\n",
      "[15164]\teval-rmse:3.86463\ttrain-rmse:1.98773\n",
      "[15165]\teval-rmse:3.86479\ttrain-rmse:1.98773\n",
      "[15166]\teval-rmse:3.86465\ttrain-rmse:1.98773\n",
      "[15167]\teval-rmse:3.865\ttrain-rmse:1.98774\n",
      "[15168]\teval-rmse:3.86308\ttrain-rmse:1.98769\n",
      "[15169]\teval-rmse:3.86441\ttrain-rmse:1.98772\n",
      "[15170]\teval-rmse:3.86337\ttrain-rmse:1.9877\n",
      "[15171]\teval-rmse:3.86164\ttrain-rmse:1.98768\n",
      "[15172]\teval-rmse:3.86033\ttrain-rmse:1.9877\n",
      "[15173]\teval-rmse:3.85828\ttrain-rmse:1.9877\n",
      "[15174]\teval-rmse:3.86011\ttrain-rmse:1.98772\n",
      "[15175]\teval-rmse:3.86112\ttrain-rmse:1.98774\n",
      "[15176]\teval-rmse:3.8621\ttrain-rmse:1.98776\n",
      "[15177]\teval-rmse:3.86148\ttrain-rmse:1.98775\n",
      "[15178]\teval-rmse:3.86004\ttrain-rmse:1.98775\n",
      "[15179]\teval-rmse:3.85955\ttrain-rmse:1.98759\n",
      "[15180]\teval-rmse:3.85804\ttrain-rmse:1.98757\n",
      "[15181]\teval-rmse:3.85776\ttrain-rmse:1.98757\n",
      "[15182]\teval-rmse:3.85759\ttrain-rmse:1.98757\n",
      "[15183]\teval-rmse:3.8572\ttrain-rmse:1.98757\n",
      "[15184]\teval-rmse:3.85666\ttrain-rmse:1.98757\n",
      "[15185]\teval-rmse:3.85464\ttrain-rmse:1.98757\n",
      "[15186]\teval-rmse:3.85296\ttrain-rmse:1.98757\n",
      "[15187]\teval-rmse:3.85271\ttrain-rmse:1.98757\n",
      "[15188]\teval-rmse:3.85441\ttrain-rmse:1.98754\n",
      "[15189]\teval-rmse:3.85215\ttrain-rmse:1.98756\n",
      "[15190]\teval-rmse:3.85091\ttrain-rmse:1.98757\n",
      "[15191]\teval-rmse:3.85207\ttrain-rmse:1.98755\n",
      "[15192]\teval-rmse:3.85102\ttrain-rmse:1.98757\n",
      "[15193]\teval-rmse:3.85088\ttrain-rmse:1.98757\n",
      "[15194]\teval-rmse:3.84972\ttrain-rmse:1.98762\n",
      "[15195]\teval-rmse:3.84958\ttrain-rmse:1.98762\n",
      "[15196]\teval-rmse:3.84893\ttrain-rmse:1.98764\n",
      "[15197]\teval-rmse:3.84848\ttrain-rmse:1.98749\n",
      "[15198]\teval-rmse:3.84703\ttrain-rmse:1.98755\n",
      "[15199]\teval-rmse:3.8464\ttrain-rmse:1.98757\n",
      "[15200]\teval-rmse:3.84743\ttrain-rmse:1.98752\n",
      "[15201]\teval-rmse:3.84927\ttrain-rmse:1.98748\n",
      "[15202]\teval-rmse:3.84804\ttrain-rmse:1.9875\n",
      "[15203]\teval-rmse:3.84853\ttrain-rmse:1.98749\n",
      "[15204]\teval-rmse:3.84877\ttrain-rmse:1.98748\n",
      "[15205]\teval-rmse:3.84842\ttrain-rmse:1.98749\n",
      "[15206]\teval-rmse:3.84739\ttrain-rmse:1.98751\n",
      "[15207]\teval-rmse:3.8459\ttrain-rmse:1.98754\n",
      "[15208]\teval-rmse:3.84489\ttrain-rmse:1.98756\n",
      "[15209]\teval-rmse:3.84427\ttrain-rmse:1.98758\n",
      "[15210]\teval-rmse:3.8457\ttrain-rmse:1.98754\n",
      "[15211]\teval-rmse:3.84624\ttrain-rmse:1.98753\n",
      "[15212]\teval-rmse:3.84774\ttrain-rmse:1.98749\n",
      "[15213]\teval-rmse:3.84596\ttrain-rmse:1.98754\n",
      "[15214]\teval-rmse:3.84484\ttrain-rmse:1.98757\n",
      "[15215]\teval-rmse:3.84442\ttrain-rmse:1.98741\n",
      "[15216]\teval-rmse:3.84271\ttrain-rmse:1.98746\n",
      "[15217]\teval-rmse:3.84464\ttrain-rmse:1.98736\n",
      "[15218]\teval-rmse:3.84428\ttrain-rmse:1.98719\n",
      "[15219]\teval-rmse:3.84327\ttrain-rmse:1.98723\n",
      "[15220]\teval-rmse:3.84174\ttrain-rmse:1.98728\n",
      "[15221]\teval-rmse:3.84111\ttrain-rmse:1.98731\n",
      "[15222]\teval-rmse:3.84118\ttrain-rmse:1.98731\n",
      "[15223]\teval-rmse:3.84078\ttrain-rmse:1.98716\n",
      "[15224]\teval-rmse:3.83885\ttrain-rmse:1.98724\n",
      "[15225]\teval-rmse:3.83845\ttrain-rmse:1.98726\n",
      "[15226]\teval-rmse:3.83815\ttrain-rmse:1.98727\n",
      "[15227]\teval-rmse:3.83998\ttrain-rmse:1.98715\n",
      "[15228]\teval-rmse:3.83888\ttrain-rmse:1.9872\n",
      "[15229]\teval-rmse:3.84059\ttrain-rmse:1.98712\n",
      "[15230]\teval-rmse:3.8402\ttrain-rmse:1.98713\n",
      "[15231]\teval-rmse:3.83927\ttrain-rmse:1.98717\n",
      "[15232]\teval-rmse:3.83875\ttrain-rmse:1.98721\n",
      "[15233]\teval-rmse:3.84003\ttrain-rmse:1.98715\n",
      "[15234]\teval-rmse:3.84187\ttrain-rmse:1.98708\n",
      "[15235]\teval-rmse:3.84124\ttrain-rmse:1.98711\n",
      "[15236]\teval-rmse:3.84228\ttrain-rmse:1.98705\n",
      "[15237]\teval-rmse:3.84176\ttrain-rmse:1.98708\n",
      "[15238]\teval-rmse:3.84246\ttrain-rmse:1.98705\n",
      "[15239]\teval-rmse:3.84277\ttrain-rmse:1.98704\n",
      "[15240]\teval-rmse:3.84176\ttrain-rmse:1.98707\n",
      "[15241]\teval-rmse:3.84036\ttrain-rmse:1.98713\n",
      "[15242]\teval-rmse:3.8411\ttrain-rmse:1.9871\n",
      "[15243]\teval-rmse:3.84135\ttrain-rmse:1.98709\n",
      "[15244]\teval-rmse:3.84318\ttrain-rmse:1.98699\n",
      "[15245]\teval-rmse:3.84252\ttrain-rmse:1.98701\n",
      "[15246]\teval-rmse:3.84093\ttrain-rmse:1.98706\n",
      "[15247]\teval-rmse:3.84144\ttrain-rmse:1.98704\n",
      "[15248]\teval-rmse:3.83932\ttrain-rmse:1.98711\n",
      "[15249]\teval-rmse:3.84017\ttrain-rmse:1.98708\n",
      "[15250]\teval-rmse:3.83857\ttrain-rmse:1.98715\n",
      "[15251]\teval-rmse:3.83938\ttrain-rmse:1.98711\n",
      "[15252]\teval-rmse:3.83994\ttrain-rmse:1.98709\n",
      "[15253]\teval-rmse:3.8403\ttrain-rmse:1.98707\n",
      "[15254]\teval-rmse:3.84058\ttrain-rmse:1.98706\n",
      "[15255]\teval-rmse:3.84109\ttrain-rmse:1.98704\n",
      "[15256]\teval-rmse:3.83988\ttrain-rmse:1.9871\n",
      "[15257]\teval-rmse:3.84093\ttrain-rmse:1.98706\n",
      "[15258]\teval-rmse:3.84145\ttrain-rmse:1.98704\n",
      "[15259]\teval-rmse:3.84229\ttrain-rmse:1.98701\n",
      "[15260]\teval-rmse:3.84279\ttrain-rmse:1.98699\n",
      "[15261]\teval-rmse:3.84409\ttrain-rmse:1.98694\n",
      "[15262]\teval-rmse:3.84306\ttrain-rmse:1.98697\n",
      "[15263]\teval-rmse:3.84152\ttrain-rmse:1.98702\n",
      "[15264]\teval-rmse:3.84132\ttrain-rmse:1.98703\n",
      "[15265]\teval-rmse:3.84271\ttrain-rmse:1.98697\n",
      "[15266]\teval-rmse:3.84297\ttrain-rmse:1.98697\n",
      "[15267]\teval-rmse:3.84185\ttrain-rmse:1.98701\n",
      "[15268]\teval-rmse:3.84056\ttrain-rmse:1.98706\n",
      "[15269]\teval-rmse:3.84261\ttrain-rmse:1.987\n",
      "[15270]\teval-rmse:3.84162\ttrain-rmse:1.98703\n",
      "[15271]\teval-rmse:3.84188\ttrain-rmse:1.98702\n",
      "[15272]\teval-rmse:3.84175\ttrain-rmse:1.98702\n",
      "[15273]\teval-rmse:3.84154\ttrain-rmse:1.98703\n",
      "[15274]\teval-rmse:3.84337\ttrain-rmse:1.98693\n",
      "[15275]\teval-rmse:3.84214\ttrain-rmse:1.98699\n",
      "[15276]\teval-rmse:3.84353\ttrain-rmse:1.98694\n",
      "[15277]\teval-rmse:3.84231\ttrain-rmse:1.98698\n",
      "[15278]\teval-rmse:3.84414\ttrain-rmse:1.98688\n",
      "[15279]\teval-rmse:3.84498\ttrain-rmse:1.98686\n",
      "[15280]\teval-rmse:3.84397\ttrain-rmse:1.98689\n",
      "[15281]\teval-rmse:3.84332\ttrain-rmse:1.98692\n",
      "[15282]\teval-rmse:3.84349\ttrain-rmse:1.98691\n",
      "[15283]\teval-rmse:3.84454\ttrain-rmse:1.98688\n",
      "[15284]\teval-rmse:3.84333\ttrain-rmse:1.98692\n",
      "[15285]\teval-rmse:3.8418\ttrain-rmse:1.98698\n",
      "[15286]\teval-rmse:3.84231\ttrain-rmse:1.98696\n",
      "[15287]\teval-rmse:3.8422\ttrain-rmse:1.98697\n",
      "[15288]\teval-rmse:3.8424\ttrain-rmse:1.98696\n",
      "[15289]\teval-rmse:3.84343\ttrain-rmse:1.9869\n",
      "[15290]\teval-rmse:3.8417\ttrain-rmse:1.98697\n",
      "[15291]\teval-rmse:3.84038\ttrain-rmse:1.98703\n",
      "[15292]\teval-rmse:3.83998\ttrain-rmse:1.98704\n",
      "[15293]\teval-rmse:3.8386\ttrain-rmse:1.98713\n",
      "[15294]\teval-rmse:3.83708\ttrain-rmse:1.98719\n",
      "[15295]\teval-rmse:3.8362\ttrain-rmse:1.98723\n",
      "[15296]\teval-rmse:3.8348\ttrain-rmse:1.98731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15297]\teval-rmse:3.83335\ttrain-rmse:1.9874\n",
      "[15298]\teval-rmse:3.83539\ttrain-rmse:1.98731\n",
      "[15299]\teval-rmse:3.83704\ttrain-rmse:1.98721\n",
      "[15300]\teval-rmse:3.83685\ttrain-rmse:1.98722\n",
      "[15301]\teval-rmse:3.83516\ttrain-rmse:1.98731\n",
      "[15302]\teval-rmse:3.83602\ttrain-rmse:1.98727\n",
      "[15303]\teval-rmse:3.83657\ttrain-rmse:1.98724\n",
      "[15304]\teval-rmse:3.83638\ttrain-rmse:1.98725\n",
      "[15305]\teval-rmse:3.83447\ttrain-rmse:1.98736\n",
      "[15306]\teval-rmse:3.83474\ttrain-rmse:1.98734\n",
      "[15307]\teval-rmse:3.83297\ttrain-rmse:1.98745\n",
      "[15308]\teval-rmse:3.83153\ttrain-rmse:1.98755\n",
      "[15309]\teval-rmse:3.8315\ttrain-rmse:1.98755\n",
      "[15310]\teval-rmse:3.83224\ttrain-rmse:1.9875\n",
      "[15311]\teval-rmse:3.83158\ttrain-rmse:1.98754\n",
      "[15312]\teval-rmse:3.83122\ttrain-rmse:1.98756\n",
      "[15313]\teval-rmse:3.83218\ttrain-rmse:1.98749\n",
      "[15314]\teval-rmse:3.83061\ttrain-rmse:1.9876\n",
      "[15315]\teval-rmse:3.83218\ttrain-rmse:1.98748\n",
      "[15316]\teval-rmse:3.83383\ttrain-rmse:1.98736\n",
      "[15317]\teval-rmse:3.8344\ttrain-rmse:1.98732\n",
      "[15318]\teval-rmse:3.83468\ttrain-rmse:1.9873\n",
      "[15319]\teval-rmse:3.83632\ttrain-rmse:1.98721\n",
      "[15320]\teval-rmse:3.83738\ttrain-rmse:1.98716\n",
      "[15321]\teval-rmse:3.83581\ttrain-rmse:1.98724\n",
      "[15322]\teval-rmse:3.83573\ttrain-rmse:1.98724\n",
      "[15323]\teval-rmse:3.83697\ttrain-rmse:1.98717\n",
      "[15324]\teval-rmse:3.83677\ttrain-rmse:1.98717\n",
      "[15325]\teval-rmse:3.83536\ttrain-rmse:1.98725\n",
      "[15326]\teval-rmse:3.83528\ttrain-rmse:1.98726\n",
      "[15327]\teval-rmse:3.8349\ttrain-rmse:1.98727\n",
      "[15328]\teval-rmse:3.83666\ttrain-rmse:1.98717\n",
      "[15329]\teval-rmse:3.8354\ttrain-rmse:1.98724\n",
      "[15330]\teval-rmse:3.83716\ttrain-rmse:1.98714\n",
      "[15331]\teval-rmse:3.83607\ttrain-rmse:1.98722\n",
      "[15332]\teval-rmse:3.83719\ttrain-rmse:1.98716\n",
      "[15333]\teval-rmse:3.83813\ttrain-rmse:1.98711\n",
      "[15334]\teval-rmse:3.83925\ttrain-rmse:1.98706\n",
      "[15335]\teval-rmse:3.83865\ttrain-rmse:1.98709\n",
      "[15336]\teval-rmse:3.83768\ttrain-rmse:1.98713\n",
      "[15337]\teval-rmse:3.837\ttrain-rmse:1.98717\n",
      "[15338]\teval-rmse:3.83848\ttrain-rmse:1.9871\n",
      "[15339]\teval-rmse:3.83844\ttrain-rmse:1.9871\n",
      "[15340]\teval-rmse:3.83693\ttrain-rmse:1.98718\n",
      "[15341]\teval-rmse:3.83846\ttrain-rmse:1.9871\n",
      "[15342]\teval-rmse:3.83658\ttrain-rmse:1.9872\n",
      "[15343]\teval-rmse:3.83597\ttrain-rmse:1.98723\n",
      "[15344]\teval-rmse:3.83559\ttrain-rmse:1.98725\n",
      "[15345]\teval-rmse:3.83674\ttrain-rmse:1.98718\n",
      "[15346]\teval-rmse:3.83833\ttrain-rmse:1.98711\n",
      "[15347]\teval-rmse:3.84038\ttrain-rmse:1.98704\n",
      "[15348]\teval-rmse:3.84114\ttrain-rmse:1.987\n",
      "[15349]\teval-rmse:3.84014\ttrain-rmse:1.98704\n",
      "[15350]\teval-rmse:3.84218\ttrain-rmse:1.98697\n",
      "[15351]\teval-rmse:3.84197\ttrain-rmse:1.98698\n",
      "[15352]\teval-rmse:3.84228\ttrain-rmse:1.98697\n",
      "[15353]\teval-rmse:3.84067\ttrain-rmse:1.98703\n",
      "[15354]\teval-rmse:3.84231\ttrain-rmse:1.98697\n",
      "[15355]\teval-rmse:3.84436\ttrain-rmse:1.98691\n",
      "[15356]\teval-rmse:3.84424\ttrain-rmse:1.98691\n",
      "[15357]\teval-rmse:3.84454\ttrain-rmse:1.9869\n",
      "[15358]\teval-rmse:3.84379\ttrain-rmse:1.98693\n",
      "[15359]\teval-rmse:3.84348\ttrain-rmse:1.98694\n",
      "[15360]\teval-rmse:3.84248\ttrain-rmse:1.98697\n",
      "[15361]\teval-rmse:3.84207\ttrain-rmse:1.98698\n",
      "[15362]\teval-rmse:3.84038\ttrain-rmse:1.98705\n",
      "[15363]\teval-rmse:3.8396\ttrain-rmse:1.98709\n",
      "[15364]\teval-rmse:3.84153\ttrain-rmse:1.987\n",
      "[15365]\teval-rmse:3.84359\ttrain-rmse:1.98694\n",
      "[15366]\teval-rmse:3.84381\ttrain-rmse:1.98694\n",
      "[15367]\teval-rmse:3.84428\ttrain-rmse:1.98692\n",
      "[15368]\teval-rmse:3.84633\ttrain-rmse:1.98687\n",
      "[15369]\teval-rmse:3.84813\ttrain-rmse:1.98681\n",
      "[15370]\teval-rmse:3.84598\ttrain-rmse:1.98688\n",
      "[15371]\teval-rmse:3.84728\ttrain-rmse:1.98684\n",
      "[15372]\teval-rmse:3.84831\ttrain-rmse:1.98681\n",
      "[15373]\teval-rmse:3.84982\ttrain-rmse:1.98678\n",
      "[15374]\teval-rmse:3.84966\ttrain-rmse:1.98678\n",
      "[15375]\teval-rmse:3.84793\ttrain-rmse:1.98682\n",
      "[15376]\teval-rmse:3.84922\ttrain-rmse:1.98679\n",
      "[15377]\teval-rmse:3.85077\ttrain-rmse:1.98677\n",
      "[15378]\teval-rmse:3.85179\ttrain-rmse:1.98672\n",
      "[15379]\teval-rmse:3.85182\ttrain-rmse:1.98672\n",
      "[15380]\teval-rmse:3.85136\ttrain-rmse:1.98656\n",
      "[15381]\teval-rmse:3.85162\ttrain-rmse:1.98656\n",
      "[15382]\teval-rmse:3.85057\ttrain-rmse:1.98657\n",
      "[15383]\teval-rmse:3.84983\ttrain-rmse:1.98658\n",
      "[15384]\teval-rmse:3.85063\ttrain-rmse:1.98656\n",
      "[15385]\teval-rmse:3.8493\ttrain-rmse:1.98659\n",
      "[15386]\teval-rmse:3.84804\ttrain-rmse:1.98664\n",
      "[15387]\teval-rmse:3.84727\ttrain-rmse:1.98666\n",
      "[15388]\teval-rmse:3.84776\ttrain-rmse:1.98665\n",
      "[15389]\teval-rmse:3.84871\ttrain-rmse:1.98663\n",
      "[15390]\teval-rmse:3.84779\ttrain-rmse:1.98665\n",
      "[15391]\teval-rmse:3.84852\ttrain-rmse:1.98663\n",
      "[15392]\teval-rmse:3.84924\ttrain-rmse:1.98662\n",
      "[15393]\teval-rmse:3.84782\ttrain-rmse:1.98664\n",
      "[15394]\teval-rmse:3.84965\ttrain-rmse:1.98661\n",
      "[15395]\teval-rmse:3.84892\ttrain-rmse:1.98662\n",
      "[15396]\teval-rmse:3.85054\ttrain-rmse:1.98656\n",
      "[15397]\teval-rmse:3.85188\ttrain-rmse:1.98654\n",
      "[15398]\teval-rmse:3.85279\ttrain-rmse:1.98653\n",
      "[15399]\teval-rmse:3.85209\ttrain-rmse:1.98654\n",
      "[15400]\teval-rmse:3.85412\ttrain-rmse:1.98652\n",
      "[15401]\teval-rmse:3.85615\ttrain-rmse:1.98651\n",
      "[15402]\teval-rmse:3.858\ttrain-rmse:1.9865\n",
      "[15403]\teval-rmse:3.85867\ttrain-rmse:1.98651\n",
      "[15404]\teval-rmse:3.85924\ttrain-rmse:1.98651\n",
      "[15405]\teval-rmse:3.86066\ttrain-rmse:1.98652\n",
      "[15406]\teval-rmse:3.86257\ttrain-rmse:1.98648\n",
      "[15407]\teval-rmse:3.86154\ttrain-rmse:1.98647\n",
      "[15408]\teval-rmse:3.86231\ttrain-rmse:1.98648\n",
      "[15409]\teval-rmse:3.86294\ttrain-rmse:1.98649\n",
      "[15410]\teval-rmse:3.86163\ttrain-rmse:1.98648\n",
      "[15411]\teval-rmse:3.86001\ttrain-rmse:1.98646\n",
      "[15412]\teval-rmse:3.86044\ttrain-rmse:1.98646\n",
      "[15413]\teval-rmse:3.85996\ttrain-rmse:1.98646\n",
      "[15414]\teval-rmse:3.85874\ttrain-rmse:1.98648\n",
      "[15415]\teval-rmse:3.86065\ttrain-rmse:1.98645\n",
      "[15416]\teval-rmse:3.85861\ttrain-rmse:1.98643\n",
      "[15417]\teval-rmse:3.85681\ttrain-rmse:1.98643\n",
      "[15418]\teval-rmse:3.85794\ttrain-rmse:1.98644\n",
      "[15419]\teval-rmse:3.85819\ttrain-rmse:1.98644\n",
      "[15420]\teval-rmse:3.85887\ttrain-rmse:1.98643\n",
      "[15421]\teval-rmse:3.85734\ttrain-rmse:1.98643\n",
      "[15422]\teval-rmse:3.85687\ttrain-rmse:1.98643\n",
      "[15423]\teval-rmse:3.85846\ttrain-rmse:1.98642\n",
      "[15424]\teval-rmse:3.85852\ttrain-rmse:1.98642\n",
      "[15425]\teval-rmse:3.8594\ttrain-rmse:1.98642\n",
      "[15426]\teval-rmse:3.85933\ttrain-rmse:1.98642\n",
      "[15427]\teval-rmse:3.8578\ttrain-rmse:1.98643\n",
      "[15428]\teval-rmse:3.85911\ttrain-rmse:1.98642\n",
      "[15429]\teval-rmse:3.86024\ttrain-rmse:1.98643\n",
      "[15430]\teval-rmse:3.8608\ttrain-rmse:1.98643\n",
      "[15431]\teval-rmse:3.86086\ttrain-rmse:1.98643\n",
      "[15432]\teval-rmse:3.86038\ttrain-rmse:1.98643\n",
      "[15433]\teval-rmse:3.86148\ttrain-rmse:1.98644\n",
      "[15434]\teval-rmse:3.86047\ttrain-rmse:1.98643\n",
      "[15435]\teval-rmse:3.86227\ttrain-rmse:1.9864\n",
      "[15436]\teval-rmse:3.86238\ttrain-rmse:1.9864\n",
      "[15437]\teval-rmse:3.86242\ttrain-rmse:1.9864\n",
      "[15438]\teval-rmse:3.86306\ttrain-rmse:1.98641\n",
      "[15439]\teval-rmse:3.86418\ttrain-rmse:1.98643\n",
      "[15440]\teval-rmse:3.86387\ttrain-rmse:1.98643\n",
      "[15441]\teval-rmse:3.86296\ttrain-rmse:1.98642\n",
      "[15442]\teval-rmse:3.86137\ttrain-rmse:1.9864\n",
      "[15443]\teval-rmse:3.86327\ttrain-rmse:1.98637\n",
      "[15444]\teval-rmse:3.86247\ttrain-rmse:1.98636\n",
      "[15445]\teval-rmse:3.86227\ttrain-rmse:1.98635\n",
      "[15446]\teval-rmse:3.86074\ttrain-rmse:1.98635\n",
      "[15447]\teval-rmse:3.8594\ttrain-rmse:1.98634\n",
      "[15448]\teval-rmse:3.85891\ttrain-rmse:1.98616\n",
      "[15449]\teval-rmse:3.85961\ttrain-rmse:1.98616\n",
      "[15450]\teval-rmse:3.86089\ttrain-rmse:1.98617\n",
      "[15451]\teval-rmse:3.8617\ttrain-rmse:1.98618\n",
      "[15452]\teval-rmse:3.86007\ttrain-rmse:1.98616\n",
      "[15453]\teval-rmse:3.8617\ttrain-rmse:1.98617\n",
      "[15454]\teval-rmse:3.86187\ttrain-rmse:1.98617\n",
      "[15455]\teval-rmse:3.86043\ttrain-rmse:1.98616\n",
      "[15456]\teval-rmse:3.86205\ttrain-rmse:1.98614\n",
      "[15457]\teval-rmse:3.86155\ttrain-rmse:1.98597\n",
      "[15458]\teval-rmse:3.86323\ttrain-rmse:1.98599\n",
      "[15459]\teval-rmse:3.86358\ttrain-rmse:1.98599\n",
      "[15460]\teval-rmse:3.86157\ttrain-rmse:1.98597\n",
      "[15461]\teval-rmse:3.86028\ttrain-rmse:1.98596\n",
      "[15462]\teval-rmse:3.85918\ttrain-rmse:1.98596\n",
      "[15463]\teval-rmse:3.85731\ttrain-rmse:1.98596\n",
      "[15464]\teval-rmse:3.85684\ttrain-rmse:1.98596\n",
      "[15465]\teval-rmse:3.85645\ttrain-rmse:1.98596\n",
      "[15466]\teval-rmse:3.85689\ttrain-rmse:1.98596\n",
      "[15467]\teval-rmse:3.85689\ttrain-rmse:1.98596\n",
      "[15468]\teval-rmse:3.85534\ttrain-rmse:1.98596\n",
      "[15469]\teval-rmse:3.85518\ttrain-rmse:1.98596\n",
      "[15470]\teval-rmse:3.85541\ttrain-rmse:1.98596\n",
      "[15471]\teval-rmse:3.85743\ttrain-rmse:1.98596\n",
      "[15472]\teval-rmse:3.85811\ttrain-rmse:1.98595\n",
      "[15473]\teval-rmse:3.85604\ttrain-rmse:1.98596\n",
      "[15474]\teval-rmse:3.85743\ttrain-rmse:1.98595\n",
      "[15475]\teval-rmse:3.85547\ttrain-rmse:1.98597\n",
      "[15476]\teval-rmse:3.85505\ttrain-rmse:1.9858\n",
      "[15477]\teval-rmse:3.85338\ttrain-rmse:1.98582\n",
      "[15478]\teval-rmse:3.85155\ttrain-rmse:1.98586\n",
      "[15479]\teval-rmse:3.85012\ttrain-rmse:1.98591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15480]\teval-rmse:3.85151\ttrain-rmse:1.98587\n",
      "[15481]\teval-rmse:3.85045\ttrain-rmse:1.98588\n",
      "[15482]\teval-rmse:3.84854\ttrain-rmse:1.98595\n",
      "[15483]\teval-rmse:3.8482\ttrain-rmse:1.98596\n",
      "[15484]\teval-rmse:3.84975\ttrain-rmse:1.98591\n",
      "[15485]\teval-rmse:3.8496\ttrain-rmse:1.98592\n",
      "[15486]\teval-rmse:3.84911\ttrain-rmse:1.98593\n",
      "[15487]\teval-rmse:3.84827\ttrain-rmse:1.98596\n",
      "[15488]\teval-rmse:3.84651\ttrain-rmse:1.98602\n",
      "[15489]\teval-rmse:3.84784\ttrain-rmse:1.98596\n",
      "[15490]\teval-rmse:3.84901\ttrain-rmse:1.98593\n",
      "[15491]\teval-rmse:3.84824\ttrain-rmse:1.98595\n",
      "[15492]\teval-rmse:3.84625\ttrain-rmse:1.98602\n",
      "[15493]\teval-rmse:3.84461\ttrain-rmse:1.98608\n",
      "[15494]\teval-rmse:3.84407\ttrain-rmse:1.98611\n",
      "[15495]\teval-rmse:3.84571\ttrain-rmse:1.98604\n",
      "[15496]\teval-rmse:3.84441\ttrain-rmse:1.9861\n",
      "[15497]\teval-rmse:3.84399\ttrain-rmse:1.98611\n",
      "[15498]\teval-rmse:3.84357\ttrain-rmse:1.98594\n",
      "[15499]\teval-rmse:3.84238\ttrain-rmse:1.98599\n",
      "[15500]\teval-rmse:3.84185\ttrain-rmse:1.98602\n",
      "[15501]\teval-rmse:3.84323\ttrain-rmse:1.98595\n",
      "[15502]\teval-rmse:3.84505\ttrain-rmse:1.98585\n",
      "[15503]\teval-rmse:3.84344\ttrain-rmse:1.98592\n",
      "[15504]\teval-rmse:3.84222\ttrain-rmse:1.98597\n",
      "[15505]\teval-rmse:3.84338\ttrain-rmse:1.98591\n",
      "[15506]\teval-rmse:3.8439\ttrain-rmse:1.98589\n",
      "[15507]\teval-rmse:3.84379\ttrain-rmse:1.98589\n",
      "[15508]\teval-rmse:3.84325\ttrain-rmse:1.98592\n",
      "[15509]\teval-rmse:3.8446\ttrain-rmse:1.98586\n",
      "[15510]\teval-rmse:3.84623\ttrain-rmse:1.98581\n",
      "[15511]\teval-rmse:3.84827\ttrain-rmse:1.98577\n",
      "[15512]\teval-rmse:3.84676\ttrain-rmse:1.98582\n",
      "[15513]\teval-rmse:3.84858\ttrain-rmse:1.98576\n",
      "[15514]\teval-rmse:3.85033\ttrain-rmse:1.9857\n",
      "[15515]\teval-rmse:3.85009\ttrain-rmse:1.98571\n",
      "[15516]\teval-rmse:3.84914\ttrain-rmse:1.98573\n",
      "[15517]\teval-rmse:3.84734\ttrain-rmse:1.98579\n",
      "[15518]\teval-rmse:3.84729\ttrain-rmse:1.98579\n",
      "[15519]\teval-rmse:3.84933\ttrain-rmse:1.98576\n",
      "[15520]\teval-rmse:3.84981\ttrain-rmse:1.98575\n",
      "[15521]\teval-rmse:3.85058\ttrain-rmse:1.98572\n",
      "[15522]\teval-rmse:3.85034\ttrain-rmse:1.98573\n",
      "[15523]\teval-rmse:3.84846\ttrain-rmse:1.98579\n",
      "[15524]\teval-rmse:3.85017\ttrain-rmse:1.98574\n",
      "[15525]\teval-rmse:3.84872\ttrain-rmse:1.98578\n",
      "[15526]\teval-rmse:3.84706\ttrain-rmse:1.98584\n",
      "[15527]\teval-rmse:3.84835\ttrain-rmse:1.98579\n",
      "[15528]\teval-rmse:3.85039\ttrain-rmse:1.98576\n",
      "[15529]\teval-rmse:3.85083\ttrain-rmse:1.98575\n",
      "[15530]\teval-rmse:3.85178\ttrain-rmse:1.98572\n",
      "[15531]\teval-rmse:3.85234\ttrain-rmse:1.98571\n",
      "[15532]\teval-rmse:3.85269\ttrain-rmse:1.9857\n",
      "[15533]\teval-rmse:3.85472\ttrain-rmse:1.98569\n",
      "[15534]\teval-rmse:3.85424\ttrain-rmse:1.9857\n",
      "[15535]\teval-rmse:3.85316\ttrain-rmse:1.98571\n",
      "[15536]\teval-rmse:3.85467\ttrain-rmse:1.98568\n",
      "[15537]\teval-rmse:3.85298\ttrain-rmse:1.98571\n",
      "[15538]\teval-rmse:3.85415\ttrain-rmse:1.98569\n",
      "[15539]\teval-rmse:3.8527\ttrain-rmse:1.98572\n",
      "[15540]\teval-rmse:3.85048\ttrain-rmse:1.98577\n",
      "[15541]\teval-rmse:3.85003\ttrain-rmse:1.98577\n",
      "[15542]\teval-rmse:3.85156\ttrain-rmse:1.98573\n",
      "[15543]\teval-rmse:3.8505\ttrain-rmse:1.98574\n",
      "[15544]\teval-rmse:3.84854\ttrain-rmse:1.9858\n",
      "[15545]\teval-rmse:3.84905\ttrain-rmse:1.98578\n",
      "[15546]\teval-rmse:3.8471\ttrain-rmse:1.98585\n",
      "[15547]\teval-rmse:3.84734\ttrain-rmse:1.98584\n",
      "[15548]\teval-rmse:3.84692\ttrain-rmse:1.98584\n",
      "[15549]\teval-rmse:3.84589\ttrain-rmse:1.98586\n",
      "[15550]\teval-rmse:3.84576\ttrain-rmse:1.98587\n",
      "[15551]\teval-rmse:3.84728\ttrain-rmse:1.98581\n",
      "[15552]\teval-rmse:3.84882\ttrain-rmse:1.98576\n",
      "[15553]\teval-rmse:3.84921\ttrain-rmse:1.98575\n",
      "[15554]\teval-rmse:3.85033\ttrain-rmse:1.98572\n",
      "[15555]\teval-rmse:3.84928\ttrain-rmse:1.98574\n",
      "[15556]\teval-rmse:3.85012\ttrain-rmse:1.98571\n",
      "[15557]\teval-rmse:3.84956\ttrain-rmse:1.98574\n",
      "[15558]\teval-rmse:3.84941\ttrain-rmse:1.98574\n",
      "[15559]\teval-rmse:3.84806\ttrain-rmse:1.98577\n",
      "[15560]\teval-rmse:3.84662\ttrain-rmse:1.98582\n",
      "[15561]\teval-rmse:3.84471\ttrain-rmse:1.98589\n",
      "[15562]\teval-rmse:3.84553\ttrain-rmse:1.98586\n",
      "[15563]\teval-rmse:3.84757\ttrain-rmse:1.98582\n",
      "[15564]\teval-rmse:3.84758\ttrain-rmse:1.98582\n",
      "[15565]\teval-rmse:3.84829\ttrain-rmse:1.9858\n",
      "[15566]\teval-rmse:3.84774\ttrain-rmse:1.98582\n",
      "[15567]\teval-rmse:3.84978\ttrain-rmse:1.98579\n",
      "[15568]\teval-rmse:3.84794\ttrain-rmse:1.98585\n",
      "[15569]\teval-rmse:3.84669\ttrain-rmse:1.98591\n",
      "[15570]\teval-rmse:3.84646\ttrain-rmse:1.98591\n",
      "[15571]\teval-rmse:3.84778\ttrain-rmse:1.98586\n",
      "[15572]\teval-rmse:3.84675\ttrain-rmse:1.98588\n",
      "[15573]\teval-rmse:3.84816\ttrain-rmse:1.98583\n",
      "[15574]\teval-rmse:3.84802\ttrain-rmse:1.98584\n",
      "[15575]\teval-rmse:3.84778\ttrain-rmse:1.98584\n",
      "[15576]\teval-rmse:3.84856\ttrain-rmse:1.98581\n",
      "[15577]\teval-rmse:3.85031\ttrain-rmse:1.98576\n",
      "[15578]\teval-rmse:3.85234\ttrain-rmse:1.98574\n",
      "[15579]\teval-rmse:3.85208\ttrain-rmse:1.98574\n",
      "[15580]\teval-rmse:3.85182\ttrain-rmse:1.98574\n",
      "[15581]\teval-rmse:3.85275\ttrain-rmse:1.98572\n",
      "[15582]\teval-rmse:3.85179\ttrain-rmse:1.98574\n",
      "[15583]\teval-rmse:3.85019\ttrain-rmse:1.98578\n",
      "[15584]\teval-rmse:3.8509\ttrain-rmse:1.98576\n",
      "[15585]\teval-rmse:3.8514\ttrain-rmse:1.98575\n",
      "[15586]\teval-rmse:3.85186\ttrain-rmse:1.98574\n",
      "[15587]\teval-rmse:3.85379\ttrain-rmse:1.9857\n",
      "[15588]\teval-rmse:3.85543\ttrain-rmse:1.98567\n",
      "[15589]\teval-rmse:3.85408\ttrain-rmse:1.98569\n",
      "[15590]\teval-rmse:3.85362\ttrain-rmse:1.98552\n",
      "[15591]\teval-rmse:3.8529\ttrain-rmse:1.98554\n",
      "[15592]\teval-rmse:3.85252\ttrain-rmse:1.98555\n",
      "[15593]\teval-rmse:3.85125\ttrain-rmse:1.98559\n",
      "[15594]\teval-rmse:3.85167\ttrain-rmse:1.98558\n",
      "[15595]\teval-rmse:3.84981\ttrain-rmse:1.98563\n",
      "[15596]\teval-rmse:3.84814\ttrain-rmse:1.98568\n",
      "[15597]\teval-rmse:3.84667\ttrain-rmse:1.98574\n",
      "[15598]\teval-rmse:3.84495\ttrain-rmse:1.9858\n",
      "[15599]\teval-rmse:3.84566\ttrain-rmse:1.98578\n",
      "[15600]\teval-rmse:3.84496\ttrain-rmse:1.98581\n",
      "[15601]\teval-rmse:3.84442\ttrain-rmse:1.98583\n",
      "[15602]\teval-rmse:3.84459\ttrain-rmse:1.98582\n",
      "[15603]\teval-rmse:3.84289\ttrain-rmse:1.9859\n",
      "[15604]\teval-rmse:3.841\ttrain-rmse:1.986\n",
      "[15605]\teval-rmse:3.84241\ttrain-rmse:1.98592\n",
      "[15606]\teval-rmse:3.842\ttrain-rmse:1.98593\n",
      "[15607]\teval-rmse:3.84028\ttrain-rmse:1.98601\n",
      "[15608]\teval-rmse:3.8419\ttrain-rmse:1.98594\n",
      "[15609]\teval-rmse:3.83993\ttrain-rmse:1.98605\n",
      "[15610]\teval-rmse:3.84175\ttrain-rmse:1.98596\n",
      "[15611]\teval-rmse:3.84134\ttrain-rmse:1.98597\n",
      "[15612]\teval-rmse:3.84317\ttrain-rmse:1.98587\n",
      "[15613]\teval-rmse:3.84294\ttrain-rmse:1.98587\n",
      "[15614]\teval-rmse:3.8437\ttrain-rmse:1.98583\n",
      "[15615]\teval-rmse:3.84512\ttrain-rmse:1.98578\n",
      "[15616]\teval-rmse:3.84519\ttrain-rmse:1.98577\n",
      "[15617]\teval-rmse:3.84665\ttrain-rmse:1.98571\n",
      "[15618]\teval-rmse:3.8451\ttrain-rmse:1.98579\n",
      "[15619]\teval-rmse:3.84714\ttrain-rmse:1.98575\n",
      "[15620]\teval-rmse:3.84795\ttrain-rmse:1.98572\n",
      "[15621]\teval-rmse:3.84619\ttrain-rmse:1.98578\n",
      "[15622]\teval-rmse:3.84597\ttrain-rmse:1.98579\n",
      "[15623]\teval-rmse:3.84563\ttrain-rmse:1.9858\n",
      "[15624]\teval-rmse:3.8444\ttrain-rmse:1.98586\n",
      "[15625]\teval-rmse:3.84573\ttrain-rmse:1.98581\n",
      "[15626]\teval-rmse:3.84732\ttrain-rmse:1.98573\n",
      "[15627]\teval-rmse:3.84892\ttrain-rmse:1.98568\n",
      "[15628]\teval-rmse:3.84942\ttrain-rmse:1.98566\n",
      "[15629]\teval-rmse:3.85019\ttrain-rmse:1.98563\n",
      "[15630]\teval-rmse:3.85114\ttrain-rmse:1.98561\n",
      "[15631]\teval-rmse:3.84977\ttrain-rmse:1.98565\n",
      "[15632]\teval-rmse:3.85107\ttrain-rmse:1.98562\n",
      "[15633]\teval-rmse:3.85135\ttrain-rmse:1.98561\n",
      "[15634]\teval-rmse:3.8509\ttrain-rmse:1.98561\n",
      "[15635]\teval-rmse:3.84941\ttrain-rmse:1.98565\n",
      "[15636]\teval-rmse:3.84787\ttrain-rmse:1.9857\n",
      "[15637]\teval-rmse:3.84932\ttrain-rmse:1.98565\n",
      "[15638]\teval-rmse:3.84909\ttrain-rmse:1.98565\n",
      "[15639]\teval-rmse:3.85039\ttrain-rmse:1.98561\n",
      "[15640]\teval-rmse:3.85119\ttrain-rmse:1.98559\n",
      "[15641]\teval-rmse:3.84931\ttrain-rmse:1.98564\n",
      "[15642]\teval-rmse:3.84876\ttrain-rmse:1.98567\n",
      "[15643]\teval-rmse:3.84891\ttrain-rmse:1.98566\n",
      "[15644]\teval-rmse:3.85094\ttrain-rmse:1.98564\n",
      "[15645]\teval-rmse:3.84966\ttrain-rmse:1.98567\n",
      "[15646]\teval-rmse:3.84883\ttrain-rmse:1.9857\n",
      "[15647]\teval-rmse:3.84789\ttrain-rmse:1.98573\n",
      "[15648]\teval-rmse:3.84635\ttrain-rmse:1.98578\n",
      "[15649]\teval-rmse:3.84783\ttrain-rmse:1.98573\n",
      "[15650]\teval-rmse:3.84668\ttrain-rmse:1.98577\n",
      "[15651]\teval-rmse:3.84566\ttrain-rmse:1.98578\n",
      "[15652]\teval-rmse:3.84677\ttrain-rmse:1.98574\n",
      "[15653]\teval-rmse:3.84505\ttrain-rmse:1.9858\n",
      "[15654]\teval-rmse:3.84646\ttrain-rmse:1.98575\n",
      "[15655]\teval-rmse:3.84801\ttrain-rmse:1.9857\n",
      "[15656]\teval-rmse:3.8482\ttrain-rmse:1.98569\n",
      "[15657]\teval-rmse:3.84984\ttrain-rmse:1.98564\n",
      "[15658]\teval-rmse:3.85101\ttrain-rmse:1.98562\n",
      "[15659]\teval-rmse:3.85107\ttrain-rmse:1.98562\n",
      "[15660]\teval-rmse:3.85278\ttrain-rmse:1.98558\n",
      "[15661]\teval-rmse:3.85333\ttrain-rmse:1.98557\n",
      "[15662]\teval-rmse:3.85525\ttrain-rmse:1.98554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15663]\teval-rmse:3.85417\ttrain-rmse:1.98554\n",
      "[15664]\teval-rmse:3.853\ttrain-rmse:1.98556\n",
      "[15665]\teval-rmse:3.85112\ttrain-rmse:1.98559\n",
      "[15666]\teval-rmse:3.85075\ttrain-rmse:1.9856\n",
      "[15667]\teval-rmse:3.85145\ttrain-rmse:1.98559\n",
      "[15668]\teval-rmse:3.85079\ttrain-rmse:1.9856\n",
      "[15669]\teval-rmse:3.84953\ttrain-rmse:1.98564\n",
      "[15670]\teval-rmse:3.84759\ttrain-rmse:1.9857\n",
      "[15671]\teval-rmse:3.84582\ttrain-rmse:1.98577\n",
      "[15672]\teval-rmse:3.84786\ttrain-rmse:1.98573\n",
      "[15673]\teval-rmse:3.84638\ttrain-rmse:1.98579\n",
      "[15674]\teval-rmse:3.84595\ttrain-rmse:1.98561\n",
      "[15675]\teval-rmse:3.84494\ttrain-rmse:1.98566\n",
      "[15676]\teval-rmse:3.84518\ttrain-rmse:1.98565\n",
      "[15677]\teval-rmse:3.84684\ttrain-rmse:1.98559\n",
      "[15678]\teval-rmse:3.8471\ttrain-rmse:1.98557\n",
      "[15679]\teval-rmse:3.84739\ttrain-rmse:1.98556\n",
      "[15680]\teval-rmse:3.84932\ttrain-rmse:1.98548\n",
      "[15681]\teval-rmse:3.8488\ttrain-rmse:1.9855\n",
      "[15682]\teval-rmse:3.84975\ttrain-rmse:1.98547\n",
      "[15683]\teval-rmse:3.8487\ttrain-rmse:1.98548\n",
      "[15684]\teval-rmse:3.84804\ttrain-rmse:1.98551\n",
      "[15685]\teval-rmse:3.84975\ttrain-rmse:1.98546\n",
      "[15686]\teval-rmse:3.8495\ttrain-rmse:1.98546\n",
      "[15687]\teval-rmse:3.84863\ttrain-rmse:1.98549\n",
      "[15688]\teval-rmse:3.84769\ttrain-rmse:1.98552\n",
      "[15689]\teval-rmse:3.84926\ttrain-rmse:1.98546\n",
      "[15690]\teval-rmse:3.84994\ttrain-rmse:1.98544\n",
      "[15691]\teval-rmse:3.84992\ttrain-rmse:1.98544\n",
      "[15692]\teval-rmse:3.85008\ttrain-rmse:1.98543\n",
      "[15693]\teval-rmse:3.85058\ttrain-rmse:1.98542\n",
      "[15694]\teval-rmse:3.85068\ttrain-rmse:1.98542\n",
      "[15695]\teval-rmse:3.8492\ttrain-rmse:1.98545\n",
      "[15696]\teval-rmse:3.84718\ttrain-rmse:1.98553\n",
      "[15697]\teval-rmse:3.84789\ttrain-rmse:1.98551\n",
      "[15698]\teval-rmse:3.84788\ttrain-rmse:1.98551\n",
      "[15699]\teval-rmse:3.84991\ttrain-rmse:1.98548\n",
      "[15700]\teval-rmse:3.85183\ttrain-rmse:1.98541\n",
      "[15701]\teval-rmse:3.85256\ttrain-rmse:1.9854\n",
      "[15702]\teval-rmse:3.8521\ttrain-rmse:1.98521\n",
      "[15703]\teval-rmse:3.85148\ttrain-rmse:1.98523\n",
      "[15704]\teval-rmse:3.84972\ttrain-rmse:1.98528\n",
      "[15705]\teval-rmse:3.84821\ttrain-rmse:1.98533\n",
      "[15706]\teval-rmse:3.85025\ttrain-rmse:1.98531\n",
      "[15707]\teval-rmse:3.85064\ttrain-rmse:1.98529\n",
      "[15708]\teval-rmse:3.85019\ttrain-rmse:1.98513\n",
      "[15709]\teval-rmse:3.85072\ttrain-rmse:1.98511\n",
      "[15710]\teval-rmse:3.85258\ttrain-rmse:1.98506\n",
      "[15711]\teval-rmse:3.85183\ttrain-rmse:1.98509\n",
      "[15712]\teval-rmse:3.85347\ttrain-rmse:1.98505\n",
      "[15713]\teval-rmse:3.85273\ttrain-rmse:1.98507\n",
      "[15714]\teval-rmse:3.85301\ttrain-rmse:1.98506\n",
      "[15715]\teval-rmse:3.85275\ttrain-rmse:1.98506\n",
      "[15716]\teval-rmse:3.8524\ttrain-rmse:1.98507\n",
      "[15717]\teval-rmse:3.85196\ttrain-rmse:1.98507\n",
      "[15718]\teval-rmse:3.85016\ttrain-rmse:1.98512\n",
      "[15719]\teval-rmse:3.84854\ttrain-rmse:1.98517\n",
      "[15720]\teval-rmse:3.85\ttrain-rmse:1.98512\n",
      "[15721]\teval-rmse:3.84924\ttrain-rmse:1.98514\n",
      "[15722]\teval-rmse:3.84867\ttrain-rmse:1.98498\n",
      "[15723]\teval-rmse:3.84803\ttrain-rmse:1.985\n",
      "[15724]\teval-rmse:3.84742\ttrain-rmse:1.98503\n",
      "[15725]\teval-rmse:3.84905\ttrain-rmse:1.98498\n",
      "[15726]\teval-rmse:3.84686\ttrain-rmse:1.98506\n",
      "[15727]\teval-rmse:3.84554\ttrain-rmse:1.98512\n",
      "[15728]\teval-rmse:3.84628\ttrain-rmse:1.98508\n",
      "[15729]\teval-rmse:3.84791\ttrain-rmse:1.98501\n",
      "[15730]\teval-rmse:3.84825\ttrain-rmse:1.985\n",
      "[15731]\teval-rmse:3.8491\ttrain-rmse:1.98497\n",
      "[15732]\teval-rmse:3.84866\ttrain-rmse:1.98478\n",
      "[15733]\teval-rmse:3.84672\ttrain-rmse:1.98486\n",
      "[15734]\teval-rmse:3.84506\ttrain-rmse:1.98493\n",
      "[15735]\teval-rmse:3.846\ttrain-rmse:1.98489\n",
      "[15736]\teval-rmse:3.84624\ttrain-rmse:1.98488\n",
      "[15737]\teval-rmse:3.84443\ttrain-rmse:1.98497\n",
      "[15738]\teval-rmse:3.84647\ttrain-rmse:1.98493\n",
      "[15739]\teval-rmse:3.84704\ttrain-rmse:1.9849\n",
      "[15740]\teval-rmse:3.84544\ttrain-rmse:1.98497\n",
      "[15741]\teval-rmse:3.84553\ttrain-rmse:1.98497\n",
      "[15742]\teval-rmse:3.84592\ttrain-rmse:1.98494\n",
      "[15743]\teval-rmse:3.84505\ttrain-rmse:1.98499\n",
      "[15744]\teval-rmse:3.84708\ttrain-rmse:1.98495\n",
      "[15745]\teval-rmse:3.84872\ttrain-rmse:1.98489\n",
      "[15746]\teval-rmse:3.84848\ttrain-rmse:1.98489\n",
      "[15747]\teval-rmse:3.84648\ttrain-rmse:1.98499\n",
      "[15748]\teval-rmse:3.84724\ttrain-rmse:1.98496\n",
      "[15749]\teval-rmse:3.84859\ttrain-rmse:1.98489\n",
      "[15750]\teval-rmse:3.8488\ttrain-rmse:1.98488\n",
      "[15751]\teval-rmse:3.84845\ttrain-rmse:1.98489\n",
      "[15752]\teval-rmse:3.84873\ttrain-rmse:1.98488\n",
      "[15753]\teval-rmse:3.85049\ttrain-rmse:1.9848\n",
      "[15754]\teval-rmse:3.85024\ttrain-rmse:1.9848\n",
      "[15755]\teval-rmse:3.85209\ttrain-rmse:1.98474\n",
      "[15756]\teval-rmse:3.85261\ttrain-rmse:1.98472\n",
      "[15757]\teval-rmse:3.85443\ttrain-rmse:1.98469\n",
      "[15758]\teval-rmse:3.85583\ttrain-rmse:1.98466\n",
      "[15759]\teval-rmse:3.8561\ttrain-rmse:1.98466\n",
      "[15760]\teval-rmse:3.85642\ttrain-rmse:1.98465\n",
      "[15761]\teval-rmse:3.85678\ttrain-rmse:1.98464\n",
      "[15762]\teval-rmse:3.857\ttrain-rmse:1.98464\n",
      "[15763]\teval-rmse:3.85736\ttrain-rmse:1.98464\n",
      "[15764]\teval-rmse:3.85891\ttrain-rmse:1.98461\n",
      "[15765]\teval-rmse:3.85709\ttrain-rmse:1.98462\n",
      "[15766]\teval-rmse:3.85781\ttrain-rmse:1.98462\n",
      "[15767]\teval-rmse:3.85604\ttrain-rmse:1.98464\n",
      "[15768]\teval-rmse:3.85648\ttrain-rmse:1.98463\n",
      "[15769]\teval-rmse:3.85518\ttrain-rmse:1.98464\n",
      "[15770]\teval-rmse:3.85338\ttrain-rmse:1.98467\n",
      "[15771]\teval-rmse:3.85191\ttrain-rmse:1.9847\n",
      "[15772]\teval-rmse:3.85073\ttrain-rmse:1.98474\n",
      "[15773]\teval-rmse:3.84898\ttrain-rmse:1.98479\n",
      "[15774]\teval-rmse:3.84855\ttrain-rmse:1.98462\n",
      "[15775]\teval-rmse:3.85031\ttrain-rmse:1.98457\n",
      "[15776]\teval-rmse:3.84905\ttrain-rmse:1.98462\n",
      "[15777]\teval-rmse:3.85069\ttrain-rmse:1.98457\n",
      "[15778]\teval-rmse:3.85024\ttrain-rmse:1.98457\n",
      "[15779]\teval-rmse:3.85154\ttrain-rmse:1.98454\n",
      "[15780]\teval-rmse:3.85203\ttrain-rmse:1.98453\n",
      "[15781]\teval-rmse:3.85166\ttrain-rmse:1.98454\n",
      "[15782]\teval-rmse:3.85367\ttrain-rmse:1.98453\n",
      "[15783]\teval-rmse:3.8531\ttrain-rmse:1.98454\n",
      "[15784]\teval-rmse:3.85182\ttrain-rmse:1.98458\n",
      "[15785]\teval-rmse:3.8523\ttrain-rmse:1.98457\n",
      "[15786]\teval-rmse:3.8536\ttrain-rmse:1.98454\n",
      "[15787]\teval-rmse:3.85436\ttrain-rmse:1.98453\n",
      "[15788]\teval-rmse:3.85507\ttrain-rmse:1.98452\n",
      "[15789]\teval-rmse:3.85503\ttrain-rmse:1.98452\n",
      "[15790]\teval-rmse:3.85434\ttrain-rmse:1.98453\n",
      "[15791]\teval-rmse:3.85399\ttrain-rmse:1.98454\n",
      "[15792]\teval-rmse:3.85353\ttrain-rmse:1.98455\n",
      "[15793]\teval-rmse:3.85493\ttrain-rmse:1.98453\n",
      "[15794]\teval-rmse:3.85695\ttrain-rmse:1.98453\n",
      "[15795]\teval-rmse:3.85647\ttrain-rmse:1.98435\n",
      "[15796]\teval-rmse:3.85701\ttrain-rmse:1.98434\n",
      "[15797]\teval-rmse:3.85772\ttrain-rmse:1.98434\n",
      "[15798]\teval-rmse:3.85691\ttrain-rmse:1.98434\n",
      "[15799]\teval-rmse:3.85604\ttrain-rmse:1.98435\n",
      "[15800]\teval-rmse:3.85449\ttrain-rmse:1.98437\n",
      "[15801]\teval-rmse:3.85283\ttrain-rmse:1.9844\n",
      "[15802]\teval-rmse:3.8535\ttrain-rmse:1.98439\n",
      "[15803]\teval-rmse:3.85513\ttrain-rmse:1.98436\n",
      "[15804]\teval-rmse:3.85586\ttrain-rmse:1.98435\n",
      "[15805]\teval-rmse:3.85539\ttrain-rmse:1.98435\n",
      "[15806]\teval-rmse:3.85326\ttrain-rmse:1.98438\n",
      "[15807]\teval-rmse:3.85259\ttrain-rmse:1.9844\n",
      "[15808]\teval-rmse:3.85292\ttrain-rmse:1.98439\n",
      "[15809]\teval-rmse:3.85245\ttrain-rmse:1.98439\n",
      "[15810]\teval-rmse:3.85167\ttrain-rmse:1.98441\n",
      "[15811]\teval-rmse:3.85122\ttrain-rmse:1.98441\n",
      "[15812]\teval-rmse:3.85283\ttrain-rmse:1.98436\n",
      "[15813]\teval-rmse:3.85355\ttrain-rmse:1.98435\n",
      "[15814]\teval-rmse:3.85558\ttrain-rmse:1.98434\n",
      "[15815]\teval-rmse:3.85659\ttrain-rmse:1.98433\n",
      "[15816]\teval-rmse:3.85702\ttrain-rmse:1.98433\n",
      "[15817]\teval-rmse:3.8578\ttrain-rmse:1.98432\n",
      "[15818]\teval-rmse:3.85804\ttrain-rmse:1.98432\n",
      "[15819]\teval-rmse:3.85634\ttrain-rmse:1.98433\n",
      "[15820]\teval-rmse:3.85767\ttrain-rmse:1.98431\n",
      "[15821]\teval-rmse:3.85719\ttrain-rmse:1.98417\n",
      "[15822]\teval-rmse:3.85738\ttrain-rmse:1.98416\n",
      "[15823]\teval-rmse:3.85689\ttrain-rmse:1.98416\n",
      "[15824]\teval-rmse:3.85626\ttrain-rmse:1.98417\n",
      "[15825]\teval-rmse:3.85743\ttrain-rmse:1.98416\n",
      "[15826]\teval-rmse:3.85613\ttrain-rmse:1.98417\n",
      "[15827]\teval-rmse:3.85543\ttrain-rmse:1.98418\n",
      "[15828]\teval-rmse:3.85341\ttrain-rmse:1.98421\n",
      "[15829]\teval-rmse:3.85214\ttrain-rmse:1.98424\n",
      "[15830]\teval-rmse:3.85028\ttrain-rmse:1.98428\n",
      "[15831]\teval-rmse:3.85056\ttrain-rmse:1.98428\n",
      "[15832]\teval-rmse:3.8504\ttrain-rmse:1.98428\n",
      "[15833]\teval-rmse:3.85014\ttrain-rmse:1.98428\n",
      "[15834]\teval-rmse:3.85169\ttrain-rmse:1.98425\n",
      "[15835]\teval-rmse:3.85243\ttrain-rmse:1.98423\n",
      "[15836]\teval-rmse:3.85093\ttrain-rmse:1.98426\n",
      "[15837]\teval-rmse:3.84987\ttrain-rmse:1.98427\n",
      "[15838]\teval-rmse:3.85057\ttrain-rmse:1.98425\n",
      "[15839]\teval-rmse:3.84901\ttrain-rmse:1.98429\n",
      "[15840]\teval-rmse:3.84864\ttrain-rmse:1.98431\n",
      "[15841]\teval-rmse:3.8471\ttrain-rmse:1.98436\n",
      "[15842]\teval-rmse:3.84912\ttrain-rmse:1.9843\n",
      "[15843]\teval-rmse:3.84807\ttrain-rmse:1.98431\n",
      "[15844]\teval-rmse:3.84634\ttrain-rmse:1.98437\n",
      "[15845]\teval-rmse:3.84591\ttrain-rmse:1.98422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15846]\teval-rmse:3.84575\ttrain-rmse:1.98422\n",
      "[15847]\teval-rmse:3.84553\ttrain-rmse:1.98423\n",
      "[15848]\teval-rmse:3.84734\ttrain-rmse:1.98417\n",
      "[15849]\teval-rmse:3.84868\ttrain-rmse:1.98413\n",
      "[15850]\teval-rmse:3.84957\ttrain-rmse:1.98411\n",
      "[15851]\teval-rmse:3.84913\ttrain-rmse:1.98411\n",
      "[15852]\teval-rmse:3.84949\ttrain-rmse:1.9841\n",
      "[15853]\teval-rmse:3.85054\ttrain-rmse:1.98408\n",
      "[15854]\teval-rmse:3.85009\ttrain-rmse:1.98393\n",
      "[15855]\teval-rmse:3.84835\ttrain-rmse:1.98397\n",
      "[15856]\teval-rmse:3.84759\ttrain-rmse:1.98399\n",
      "[15857]\teval-rmse:3.84961\ttrain-rmse:1.98396\n",
      "[15858]\teval-rmse:3.84936\ttrain-rmse:1.98397\n",
      "[15859]\teval-rmse:3.85006\ttrain-rmse:1.98395\n",
      "[15860]\teval-rmse:3.85121\ttrain-rmse:1.98393\n",
      "[15861]\teval-rmse:3.85086\ttrain-rmse:1.98394\n",
      "[15862]\teval-rmse:3.85244\ttrain-rmse:1.98393\n",
      "[15863]\teval-rmse:3.85198\ttrain-rmse:1.98379\n",
      "[15864]\teval-rmse:3.85371\ttrain-rmse:1.98377\n",
      "[15865]\teval-rmse:3.85214\ttrain-rmse:1.98378\n",
      "[15866]\teval-rmse:3.85213\ttrain-rmse:1.98378\n",
      "[15867]\teval-rmse:3.85252\ttrain-rmse:1.98378\n",
      "[15868]\teval-rmse:3.85235\ttrain-rmse:1.98378\n",
      "[15869]\teval-rmse:3.85008\ttrain-rmse:1.9838\n",
      "[15870]\teval-rmse:3.84875\ttrain-rmse:1.98383\n",
      "[15871]\teval-rmse:3.84884\ttrain-rmse:1.98383\n",
      "[15872]\teval-rmse:3.84904\ttrain-rmse:1.98383\n",
      "[15873]\teval-rmse:3.84926\ttrain-rmse:1.98382\n",
      "[15874]\teval-rmse:3.85118\ttrain-rmse:1.98378\n",
      "[15875]\teval-rmse:3.85119\ttrain-rmse:1.98378\n",
      "[15876]\teval-rmse:3.85188\ttrain-rmse:1.98377\n",
      "[15877]\teval-rmse:3.8526\ttrain-rmse:1.98376\n",
      "[15878]\teval-rmse:3.85038\ttrain-rmse:1.98379\n",
      "[15879]\teval-rmse:3.84887\ttrain-rmse:1.98382\n",
      "[15880]\teval-rmse:3.85078\ttrain-rmse:1.98376\n",
      "[15881]\teval-rmse:3.85053\ttrain-rmse:1.98376\n",
      "[15882]\teval-rmse:3.84935\ttrain-rmse:1.98378\n",
      "[15883]\teval-rmse:3.84892\ttrain-rmse:1.98378\n",
      "[15884]\teval-rmse:3.84729\ttrain-rmse:1.98383\n",
      "[15885]\teval-rmse:3.84714\ttrain-rmse:1.98383\n",
      "[15886]\teval-rmse:3.84611\ttrain-rmse:1.98385\n",
      "[15887]\teval-rmse:3.84597\ttrain-rmse:1.98385\n",
      "[15888]\teval-rmse:3.84768\ttrain-rmse:1.98379\n",
      "[15889]\teval-rmse:3.8479\ttrain-rmse:1.98379\n",
      "[15890]\teval-rmse:3.84695\ttrain-rmse:1.98382\n",
      "[15891]\teval-rmse:3.84523\ttrain-rmse:1.98387\n",
      "[15892]\teval-rmse:3.84437\ttrain-rmse:1.9839\n",
      "[15893]\teval-rmse:3.84376\ttrain-rmse:1.98393\n",
      "[15894]\teval-rmse:3.84212\ttrain-rmse:1.98399\n",
      "[15895]\teval-rmse:3.84315\ttrain-rmse:1.98395\n",
      "[15896]\teval-rmse:3.84332\ttrain-rmse:1.98394\n",
      "[15897]\teval-rmse:3.84264\ttrain-rmse:1.98397\n",
      "[15898]\teval-rmse:3.84301\ttrain-rmse:1.98395\n",
      "[15899]\teval-rmse:3.8426\ttrain-rmse:1.98397\n",
      "[15900]\teval-rmse:3.84307\ttrain-rmse:1.98395\n",
      "[15901]\teval-rmse:3.84283\ttrain-rmse:1.98396\n",
      "[15902]\teval-rmse:3.84241\ttrain-rmse:1.98396\n",
      "[15903]\teval-rmse:3.84322\ttrain-rmse:1.98393\n",
      "[15904]\teval-rmse:3.84322\ttrain-rmse:1.98393\n",
      "[15905]\teval-rmse:3.84241\ttrain-rmse:1.98397\n",
      "[15906]\teval-rmse:3.84074\ttrain-rmse:1.98405\n",
      "[15907]\teval-rmse:3.83942\ttrain-rmse:1.98411\n",
      "[15908]\teval-rmse:3.84125\ttrain-rmse:1.98403\n",
      "[15909]\teval-rmse:3.83927\ttrain-rmse:1.98414\n",
      "[15910]\teval-rmse:3.84091\ttrain-rmse:1.98406\n",
      "[15911]\teval-rmse:3.84184\ttrain-rmse:1.98402\n",
      "[15912]\teval-rmse:3.8404\ttrain-rmse:1.98408\n",
      "[15913]\teval-rmse:3.84092\ttrain-rmse:1.98406\n",
      "[15914]\teval-rmse:3.84059\ttrain-rmse:1.98407\n",
      "[15915]\teval-rmse:3.84155\ttrain-rmse:1.98403\n",
      "[15916]\teval-rmse:3.84004\ttrain-rmse:1.9841\n",
      "[15917]\teval-rmse:3.83904\ttrain-rmse:1.98413\n",
      "[15918]\teval-rmse:3.83808\ttrain-rmse:1.98417\n",
      "[15919]\teval-rmse:3.83641\ttrain-rmse:1.98428\n",
      "[15920]\teval-rmse:3.8363\ttrain-rmse:1.98428\n",
      "[15921]\teval-rmse:3.83769\ttrain-rmse:1.98419\n",
      "[15922]\teval-rmse:3.83852\ttrain-rmse:1.98415\n",
      "[15923]\teval-rmse:3.83813\ttrain-rmse:1.98397\n",
      "[15924]\teval-rmse:3.8386\ttrain-rmse:1.98395\n",
      "[15925]\teval-rmse:3.83859\ttrain-rmse:1.98395\n",
      "[15926]\teval-rmse:3.83916\ttrain-rmse:1.98392\n",
      "[15927]\teval-rmse:3.84076\ttrain-rmse:1.98385\n",
      "[15928]\teval-rmse:3.8386\ttrain-rmse:1.98394\n",
      "[15929]\teval-rmse:3.84025\ttrain-rmse:1.98386\n",
      "[15930]\teval-rmse:3.8384\ttrain-rmse:1.98395\n",
      "[15931]\teval-rmse:3.83801\ttrain-rmse:1.98396\n",
      "[15932]\teval-rmse:3.83604\ttrain-rmse:1.98408\n",
      "[15933]\teval-rmse:3.83594\ttrain-rmse:1.98408\n",
      "[15934]\teval-rmse:3.83474\ttrain-rmse:1.98416\n",
      "[15935]\teval-rmse:3.83639\ttrain-rmse:1.98406\n",
      "[15936]\teval-rmse:3.83678\ttrain-rmse:1.98404\n",
      "[15937]\teval-rmse:3.83639\ttrain-rmse:1.98387\n",
      "[15938]\teval-rmse:3.83497\ttrain-rmse:1.98395\n",
      "[15939]\teval-rmse:3.83623\ttrain-rmse:1.98388\n",
      "[15940]\teval-rmse:3.8348\ttrain-rmse:1.98397\n",
      "[15941]\teval-rmse:3.83469\ttrain-rmse:1.98398\n",
      "[15942]\teval-rmse:3.83626\ttrain-rmse:1.98388\n",
      "[15943]\teval-rmse:3.83414\ttrain-rmse:1.984\n",
      "[15944]\teval-rmse:3.83489\ttrain-rmse:1.98395\n",
      "[15945]\teval-rmse:3.83548\ttrain-rmse:1.98392\n",
      "[15946]\teval-rmse:3.83664\ttrain-rmse:1.98385\n",
      "[15947]\teval-rmse:3.83525\ttrain-rmse:1.98393\n",
      "[15948]\teval-rmse:3.83597\ttrain-rmse:1.98389\n",
      "[15949]\teval-rmse:3.83559\ttrain-rmse:1.9839\n",
      "[15950]\teval-rmse:3.83539\ttrain-rmse:1.9839\n",
      "[15951]\teval-rmse:3.83528\ttrain-rmse:1.98391\n",
      "[15952]\teval-rmse:3.83613\ttrain-rmse:1.98385\n",
      "[15953]\teval-rmse:3.83629\ttrain-rmse:1.98384\n",
      "[15954]\teval-rmse:3.83502\ttrain-rmse:1.98391\n",
      "[15955]\teval-rmse:3.83492\ttrain-rmse:1.98392\n",
      "[15956]\teval-rmse:3.83449\ttrain-rmse:1.98394\n",
      "[15957]\teval-rmse:3.83614\ttrain-rmse:1.98385\n",
      "[15958]\teval-rmse:3.83732\ttrain-rmse:1.98379\n",
      "[15959]\teval-rmse:3.83763\ttrain-rmse:1.98378\n",
      "[15960]\teval-rmse:3.83855\ttrain-rmse:1.98373\n",
      "[15961]\teval-rmse:3.83979\ttrain-rmse:1.98367\n",
      "[15962]\teval-rmse:3.84026\ttrain-rmse:1.98365\n",
      "[15963]\teval-rmse:3.84057\ttrain-rmse:1.98364\n",
      "[15964]\teval-rmse:3.84141\ttrain-rmse:1.9836\n",
      "[15965]\teval-rmse:3.84028\ttrain-rmse:1.98365\n",
      "[15966]\teval-rmse:3.83969\ttrain-rmse:1.98367\n",
      "[15967]\teval-rmse:3.84014\ttrain-rmse:1.98365\n",
      "[15968]\teval-rmse:3.83816\ttrain-rmse:1.98375\n",
      "[15969]\teval-rmse:3.83705\ttrain-rmse:1.98381\n",
      "[15970]\teval-rmse:3.83491\ttrain-rmse:1.98392\n",
      "[15971]\teval-rmse:3.83584\ttrain-rmse:1.98386\n",
      "[15972]\teval-rmse:3.83397\ttrain-rmse:1.98397\n",
      "[15973]\teval-rmse:3.83299\ttrain-rmse:1.98401\n",
      "[15974]\teval-rmse:3.83174\ttrain-rmse:1.9841\n",
      "[15975]\teval-rmse:3.83175\ttrain-rmse:1.9841\n",
      "[15976]\teval-rmse:3.83038\ttrain-rmse:1.9842\n",
      "[15977]\teval-rmse:3.829\ttrain-rmse:1.9843\n",
      "[15978]\teval-rmse:3.82842\ttrain-rmse:1.98435\n",
      "[15979]\teval-rmse:3.82957\ttrain-rmse:1.98426\n",
      "[15980]\teval-rmse:3.82959\ttrain-rmse:1.98426\n",
      "[15981]\teval-rmse:3.82994\ttrain-rmse:1.98424\n",
      "[15982]\teval-rmse:3.83113\ttrain-rmse:1.98415\n",
      "[15983]\teval-rmse:3.82997\ttrain-rmse:1.98425\n",
      "[15984]\teval-rmse:3.8288\ttrain-rmse:1.98433\n",
      "[15985]\teval-rmse:3.82974\ttrain-rmse:1.98426\n",
      "[15986]\teval-rmse:3.82918\ttrain-rmse:1.9843\n",
      "[15987]\teval-rmse:3.82883\ttrain-rmse:1.98432\n",
      "[15988]\teval-rmse:3.82741\ttrain-rmse:1.98444\n",
      "[15989]\teval-rmse:3.82742\ttrain-rmse:1.98444\n",
      "[15990]\teval-rmse:3.82847\ttrain-rmse:1.98435\n",
      "[15991]\teval-rmse:3.8304\ttrain-rmse:1.98419\n",
      "[15992]\teval-rmse:3.83244\ttrain-rmse:1.9841\n",
      "[15993]\teval-rmse:3.83208\ttrain-rmse:1.98412\n",
      "[15994]\teval-rmse:3.83053\ttrain-rmse:1.98424\n",
      "[15995]\teval-rmse:3.83036\ttrain-rmse:1.98424\n",
      "[15996]\teval-rmse:3.83154\ttrain-rmse:1.98416\n",
      "[15997]\teval-rmse:3.83325\ttrain-rmse:1.98405\n",
      "[15998]\teval-rmse:3.83217\ttrain-rmse:1.98413\n",
      "[15999]\teval-rmse:3.83247\ttrain-rmse:1.98411\n",
      "[16000]\teval-rmse:3.83324\ttrain-rmse:1.98406\n",
      "[16001]\teval-rmse:3.83227\ttrain-rmse:1.9841\n",
      "[16002]\teval-rmse:3.8306\ttrain-rmse:1.9842\n",
      "[16003]\teval-rmse:3.83043\ttrain-rmse:1.98422\n",
      "[16004]\teval-rmse:3.83103\ttrain-rmse:1.98418\n",
      "[16005]\teval-rmse:3.82911\ttrain-rmse:1.98433\n",
      "[16006]\teval-rmse:3.82854\ttrain-rmse:1.98438\n",
      "[16007]\teval-rmse:3.83008\ttrain-rmse:1.98427\n",
      "[16008]\teval-rmse:3.82874\ttrain-rmse:1.98437\n",
      "[16009]\teval-rmse:3.82915\ttrain-rmse:1.98434\n",
      "[16010]\teval-rmse:3.82898\ttrain-rmse:1.98435\n",
      "[16011]\teval-rmse:3.83081\ttrain-rmse:1.9842\n",
      "[16012]\teval-rmse:3.82985\ttrain-rmse:1.98424\n",
      "[16013]\teval-rmse:3.82841\ttrain-rmse:1.98436\n",
      "[16014]\teval-rmse:3.82735\ttrain-rmse:1.98445\n",
      "[16015]\teval-rmse:3.82804\ttrain-rmse:1.98439\n",
      "[16016]\teval-rmse:3.82771\ttrain-rmse:1.98441\n",
      "[16017]\teval-rmse:3.8285\ttrain-rmse:1.98434\n",
      "[16018]\teval-rmse:3.82793\ttrain-rmse:1.98439\n",
      "[16019]\teval-rmse:3.82692\ttrain-rmse:1.98447\n",
      "[16020]\teval-rmse:3.82587\ttrain-rmse:1.98456\n",
      "[16021]\teval-rmse:3.8272\ttrain-rmse:1.98446\n",
      "[16022]\teval-rmse:3.82856\ttrain-rmse:1.98434\n",
      "[16023]\teval-rmse:3.82763\ttrain-rmse:1.98441\n",
      "[16024]\teval-rmse:3.82797\ttrain-rmse:1.98439\n",
      "[16025]\teval-rmse:3.82741\ttrain-rmse:1.98443\n",
      "[16026]\teval-rmse:3.82906\ttrain-rmse:1.9843\n",
      "[16027]\teval-rmse:3.82852\ttrain-rmse:1.98435\n",
      "[16028]\teval-rmse:3.83035\ttrain-rmse:1.9842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16029]\teval-rmse:3.8314\ttrain-rmse:1.98413\n",
      "[16030]\teval-rmse:3.83188\ttrain-rmse:1.98411\n",
      "[16031]\teval-rmse:3.83152\ttrain-rmse:1.98412\n",
      "[16032]\teval-rmse:3.83279\ttrain-rmse:1.98403\n",
      "[16033]\teval-rmse:3.83231\ttrain-rmse:1.98406\n",
      "[16034]\teval-rmse:3.83302\ttrain-rmse:1.98402\n",
      "[16035]\teval-rmse:3.8314\ttrain-rmse:1.98413\n",
      "[16036]\teval-rmse:3.83311\ttrain-rmse:1.98402\n",
      "[16037]\teval-rmse:3.83173\ttrain-rmse:1.98411\n",
      "[16038]\teval-rmse:3.8301\ttrain-rmse:1.98423\n",
      "[16039]\teval-rmse:3.83012\ttrain-rmse:1.98423\n",
      "[16040]\teval-rmse:3.83183\ttrain-rmse:1.9841\n",
      "[16041]\teval-rmse:3.83019\ttrain-rmse:1.98421\n",
      "[16042]\teval-rmse:3.82962\ttrain-rmse:1.98425\n",
      "[16043]\teval-rmse:3.83127\ttrain-rmse:1.98415\n",
      "[16044]\teval-rmse:3.83261\ttrain-rmse:1.98406\n",
      "[16045]\teval-rmse:3.83097\ttrain-rmse:1.98418\n",
      "[16046]\teval-rmse:3.83301\ttrain-rmse:1.98409\n",
      "[16047]\teval-rmse:3.83168\ttrain-rmse:1.98419\n",
      "[16048]\teval-rmse:3.8315\ttrain-rmse:1.9842\n",
      "[16049]\teval-rmse:3.83132\ttrain-rmse:1.98421\n",
      "[16050]\teval-rmse:3.83114\ttrain-rmse:1.98422\n",
      "[16051]\teval-rmse:3.83221\ttrain-rmse:1.98413\n",
      "[16052]\teval-rmse:3.83185\ttrain-rmse:1.98415\n",
      "[16053]\teval-rmse:3.83389\ttrain-rmse:1.98407\n",
      "[16054]\teval-rmse:3.83592\ttrain-rmse:1.98399\n",
      "[16055]\teval-rmse:3.8356\ttrain-rmse:1.98401\n",
      "[16056]\teval-rmse:3.83423\ttrain-rmse:1.9841\n",
      "[16057]\teval-rmse:3.83229\ttrain-rmse:1.98424\n",
      "[16058]\teval-rmse:3.83175\ttrain-rmse:1.98429\n",
      "[16059]\teval-rmse:3.83166\ttrain-rmse:1.98429\n",
      "[16060]\teval-rmse:3.83213\ttrain-rmse:1.98426\n",
      "[16061]\teval-rmse:3.83247\ttrain-rmse:1.98423\n",
      "[16062]\teval-rmse:3.83113\ttrain-rmse:1.98432\n",
      "[16063]\teval-rmse:3.83072\ttrain-rmse:1.98435\n",
      "[16064]\teval-rmse:3.82873\ttrain-rmse:1.9845\n",
      "[16065]\teval-rmse:3.82819\ttrain-rmse:1.98455\n",
      "[16066]\teval-rmse:3.82813\ttrain-rmse:1.98455\n",
      "[16067]\teval-rmse:3.82774\ttrain-rmse:1.98457\n",
      "[16068]\teval-rmse:3.82693\ttrain-rmse:1.98465\n",
      "[16069]\teval-rmse:3.82896\ttrain-rmse:1.98455\n",
      "[16070]\teval-rmse:3.8298\ttrain-rmse:1.98448\n",
      "[16071]\teval-rmse:3.82817\ttrain-rmse:1.98463\n",
      "[16072]\teval-rmse:3.82788\ttrain-rmse:1.98465\n",
      "[16073]\teval-rmse:3.82655\ttrain-rmse:1.98478\n",
      "[16074]\teval-rmse:3.82534\ttrain-rmse:1.9849\n",
      "[16075]\teval-rmse:3.82354\ttrain-rmse:1.9851\n",
      "[16076]\teval-rmse:3.82317\ttrain-rmse:1.98514\n",
      "[16077]\teval-rmse:3.82341\ttrain-rmse:1.98511\n",
      "[16078]\teval-rmse:3.82416\ttrain-rmse:1.98505\n",
      "[16079]\teval-rmse:3.82304\ttrain-rmse:1.98514\n",
      "[16080]\teval-rmse:3.82194\ttrain-rmse:1.98527\n",
      "[16081]\teval-rmse:3.82353\ttrain-rmse:1.98508\n",
      "[16082]\teval-rmse:3.82213\ttrain-rmse:1.98521\n",
      "[16083]\teval-rmse:3.82086\ttrain-rmse:1.98536\n",
      "[16084]\teval-rmse:3.81927\ttrain-rmse:1.98552\n",
      "[16085]\teval-rmse:3.82006\ttrain-rmse:1.98543\n",
      "[16086]\teval-rmse:3.822\ttrain-rmse:1.98523\n",
      "[16087]\teval-rmse:3.82261\ttrain-rmse:1.98516\n",
      "[16088]\teval-rmse:3.82201\ttrain-rmse:1.98522\n",
      "[16089]\teval-rmse:3.82061\ttrain-rmse:1.98536\n",
      "[16090]\teval-rmse:3.82223\ttrain-rmse:1.9852\n",
      "[16091]\teval-rmse:3.82273\ttrain-rmse:1.98515\n",
      "[16092]\teval-rmse:3.82439\ttrain-rmse:1.985\n",
      "[16093]\teval-rmse:3.82573\ttrain-rmse:1.98486\n",
      "[16094]\teval-rmse:3.82757\ttrain-rmse:1.9847\n",
      "[16095]\teval-rmse:3.82778\ttrain-rmse:1.98468\n",
      "[16096]\teval-rmse:3.82597\ttrain-rmse:1.98486\n",
      "[16097]\teval-rmse:3.82525\ttrain-rmse:1.98492\n",
      "[16098]\teval-rmse:3.82491\ttrain-rmse:1.98478\n",
      "[16099]\teval-rmse:3.82625\ttrain-rmse:1.98466\n",
      "[16100]\teval-rmse:3.82808\ttrain-rmse:1.98451\n",
      "[16101]\teval-rmse:3.82763\ttrain-rmse:1.98454\n",
      "[16102]\teval-rmse:3.82729\ttrain-rmse:1.98438\n",
      "[16103]\teval-rmse:3.82695\ttrain-rmse:1.9842\n",
      "[16104]\teval-rmse:3.82535\ttrain-rmse:1.98434\n",
      "[16105]\teval-rmse:3.82423\ttrain-rmse:1.98443\n",
      "[16106]\teval-rmse:3.82332\ttrain-rmse:1.98448\n",
      "[16107]\teval-rmse:3.82202\ttrain-rmse:1.98459\n",
      "[16108]\teval-rmse:3.82089\ttrain-rmse:1.9847\n",
      "[16109]\teval-rmse:3.82097\ttrain-rmse:1.9847\n",
      "[16110]\teval-rmse:3.8214\ttrain-rmse:1.98465\n",
      "[16111]\teval-rmse:3.81986\ttrain-rmse:1.98483\n",
      "[16112]\teval-rmse:3.82179\ttrain-rmse:1.98464\n",
      "[16113]\teval-rmse:3.82147\ttrain-rmse:1.98467\n",
      "[16114]\teval-rmse:3.82188\ttrain-rmse:1.98463\n",
      "[16115]\teval-rmse:3.82368\ttrain-rmse:1.98446\n",
      "[16116]\teval-rmse:3.82362\ttrain-rmse:1.98445\n",
      "[16117]\teval-rmse:3.82204\ttrain-rmse:1.9846\n",
      "[16118]\teval-rmse:3.82256\ttrain-rmse:1.98454\n",
      "[16119]\teval-rmse:3.82166\ttrain-rmse:1.9846\n",
      "[16120]\teval-rmse:3.82235\ttrain-rmse:1.98452\n",
      "[16121]\teval-rmse:3.82079\ttrain-rmse:1.98467\n",
      "[16122]\teval-rmse:3.8212\ttrain-rmse:1.98463\n",
      "[16123]\teval-rmse:3.82217\ttrain-rmse:1.98454\n",
      "[16124]\teval-rmse:3.82313\ttrain-rmse:1.98445\n",
      "[16125]\teval-rmse:3.82269\ttrain-rmse:1.98449\n",
      "[16126]\teval-rmse:3.8213\ttrain-rmse:1.98461\n",
      "[16127]\teval-rmse:3.8214\ttrain-rmse:1.9846\n",
      "[16128]\teval-rmse:3.82322\ttrain-rmse:1.98444\n",
      "[16129]\teval-rmse:3.82324\ttrain-rmse:1.98444\n",
      "[16130]\teval-rmse:3.82463\ttrain-rmse:1.98429\n",
      "[16131]\teval-rmse:3.8236\ttrain-rmse:1.98438\n",
      "[16132]\teval-rmse:3.82466\ttrain-rmse:1.98427\n",
      "[16133]\teval-rmse:3.82671\ttrain-rmse:1.98416\n",
      "[16134]\teval-rmse:3.82769\ttrain-rmse:1.98408\n",
      "[16135]\teval-rmse:3.82904\ttrain-rmse:1.98396\n",
      "[16136]\teval-rmse:3.82871\ttrain-rmse:1.98397\n",
      "[16137]\teval-rmse:3.82863\ttrain-rmse:1.98398\n",
      "[16138]\teval-rmse:3.82701\ttrain-rmse:1.98411\n",
      "[16139]\teval-rmse:3.82562\ttrain-rmse:1.98422\n",
      "[16140]\teval-rmse:3.82442\ttrain-rmse:1.98433\n",
      "[16141]\teval-rmse:3.82491\ttrain-rmse:1.98428\n",
      "[16142]\teval-rmse:3.82586\ttrain-rmse:1.9842\n",
      "[16143]\teval-rmse:3.82582\ttrain-rmse:1.9842\n",
      "[16144]\teval-rmse:3.82548\ttrain-rmse:1.98421\n",
      "[16145]\teval-rmse:3.82397\ttrain-rmse:1.98436\n",
      "[16146]\teval-rmse:3.82511\ttrain-rmse:1.98425\n",
      "[16147]\teval-rmse:3.82588\ttrain-rmse:1.98418\n",
      "[16148]\teval-rmse:3.82731\ttrain-rmse:1.98407\n",
      "[16149]\teval-rmse:3.82768\ttrain-rmse:1.98404\n",
      "[16150]\teval-rmse:3.82656\ttrain-rmse:1.98414\n",
      "[16151]\teval-rmse:3.82573\ttrain-rmse:1.98421\n",
      "[16152]\teval-rmse:3.82604\ttrain-rmse:1.98419\n",
      "[16153]\teval-rmse:3.8255\ttrain-rmse:1.98424\n",
      "[16154]\teval-rmse:3.82581\ttrain-rmse:1.98421\n",
      "[16155]\teval-rmse:3.8247\ttrain-rmse:1.98431\n",
      "[16156]\teval-rmse:3.8234\ttrain-rmse:1.98443\n",
      "[16157]\teval-rmse:3.82484\ttrain-rmse:1.98431\n",
      "[16158]\teval-rmse:3.82309\ttrain-rmse:1.98446\n",
      "[16159]\teval-rmse:3.82371\ttrain-rmse:1.9844\n",
      "[16160]\teval-rmse:3.82498\ttrain-rmse:1.98429\n",
      "[16161]\teval-rmse:3.82436\ttrain-rmse:1.98435\n",
      "[16162]\teval-rmse:3.82469\ttrain-rmse:1.98432\n",
      "[16163]\teval-rmse:3.82662\ttrain-rmse:1.98417\n",
      "[16164]\teval-rmse:3.82824\ttrain-rmse:1.98402\n",
      "[16165]\teval-rmse:3.83007\ttrain-rmse:1.98387\n",
      "[16166]\teval-rmse:3.82973\ttrain-rmse:1.98389\n",
      "[16167]\teval-rmse:3.83154\ttrain-rmse:1.98377\n",
      "[16168]\teval-rmse:3.83117\ttrain-rmse:1.98361\n",
      "[16169]\teval-rmse:3.8296\ttrain-rmse:1.98372\n",
      "[16170]\teval-rmse:3.83163\ttrain-rmse:1.98363\n",
      "[16171]\teval-rmse:3.83214\ttrain-rmse:1.98359\n",
      "[16172]\teval-rmse:3.83166\ttrain-rmse:1.98362\n",
      "[16173]\teval-rmse:3.83188\ttrain-rmse:1.98361\n",
      "[16174]\teval-rmse:3.83346\ttrain-rmse:1.9835\n",
      "[16175]\teval-rmse:3.834\ttrain-rmse:1.98347\n",
      "[16176]\teval-rmse:3.83264\ttrain-rmse:1.98357\n",
      "[16177]\teval-rmse:3.83196\ttrain-rmse:1.98361\n",
      "[16178]\teval-rmse:3.83305\ttrain-rmse:1.98354\n",
      "[16179]\teval-rmse:3.83509\ttrain-rmse:1.98346\n",
      "[16180]\teval-rmse:3.83488\ttrain-rmse:1.98347\n",
      "[16181]\teval-rmse:3.83543\ttrain-rmse:1.98344\n",
      "[16182]\teval-rmse:3.83494\ttrain-rmse:1.98347\n",
      "[16183]\teval-rmse:3.83526\ttrain-rmse:1.98345\n",
      "[16184]\teval-rmse:3.83729\ttrain-rmse:1.98338\n",
      "[16185]\teval-rmse:3.83644\ttrain-rmse:1.98344\n",
      "[16186]\teval-rmse:3.83539\ttrain-rmse:1.98351\n",
      "[16187]\teval-rmse:3.83743\ttrain-rmse:1.98344\n",
      "[16188]\teval-rmse:3.83741\ttrain-rmse:1.98344\n",
      "[16189]\teval-rmse:3.83912\ttrain-rmse:1.98335\n",
      "[16190]\teval-rmse:3.84015\ttrain-rmse:1.9833\n",
      "[16191]\teval-rmse:3.83865\ttrain-rmse:1.98337\n",
      "[16192]\teval-rmse:3.83833\ttrain-rmse:1.98338\n",
      "[16193]\teval-rmse:3.84015\ttrain-rmse:1.98328\n",
      "[16194]\teval-rmse:3.83933\ttrain-rmse:1.98332\n",
      "[16195]\teval-rmse:3.83982\ttrain-rmse:1.98329\n",
      "[16196]\teval-rmse:3.8385\ttrain-rmse:1.98335\n",
      "[16197]\teval-rmse:3.83828\ttrain-rmse:1.98336\n",
      "[16198]\teval-rmse:3.84031\ttrain-rmse:1.9833\n",
      "[16199]\teval-rmse:3.84093\ttrain-rmse:1.98327\n",
      "[16200]\teval-rmse:3.84196\ttrain-rmse:1.98322\n",
      "[16201]\teval-rmse:3.84196\ttrain-rmse:1.98322\n",
      "[16202]\teval-rmse:3.84215\ttrain-rmse:1.98321\n",
      "[16203]\teval-rmse:3.84071\ttrain-rmse:1.98328\n",
      "[16204]\teval-rmse:3.84252\ttrain-rmse:1.98319\n",
      "[16205]\teval-rmse:3.84333\ttrain-rmse:1.98316\n",
      "[16206]\teval-rmse:3.84513\ttrain-rmse:1.98309\n",
      "[16207]\teval-rmse:3.84561\ttrain-rmse:1.98307\n",
      "[16208]\teval-rmse:3.8475\ttrain-rmse:1.98302\n",
      "[16209]\teval-rmse:3.84774\ttrain-rmse:1.98301\n",
      "[16210]\teval-rmse:3.8473\ttrain-rmse:1.98301\n",
      "[16211]\teval-rmse:3.84763\ttrain-rmse:1.983\n",
      "[16212]\teval-rmse:3.8472\ttrain-rmse:1.98301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16213]\teval-rmse:3.848\ttrain-rmse:1.98299\n",
      "[16214]\teval-rmse:3.84894\ttrain-rmse:1.98296\n",
      "[16215]\teval-rmse:3.84811\ttrain-rmse:1.98298\n",
      "[16216]\teval-rmse:3.84796\ttrain-rmse:1.98299\n",
      "[16217]\teval-rmse:3.8478\ttrain-rmse:1.98299\n",
      "[16218]\teval-rmse:3.84609\ttrain-rmse:1.98305\n",
      "[16219]\teval-rmse:3.84566\ttrain-rmse:1.98306\n",
      "[16220]\teval-rmse:3.84529\ttrain-rmse:1.98291\n",
      "[16221]\teval-rmse:3.84405\ttrain-rmse:1.98296\n",
      "[16222]\teval-rmse:3.84496\ttrain-rmse:1.98293\n",
      "[16223]\teval-rmse:3.84461\ttrain-rmse:1.98294\n",
      "[16224]\teval-rmse:3.8451\ttrain-rmse:1.98293\n",
      "[16225]\teval-rmse:3.84318\ttrain-rmse:1.98299\n",
      "[16226]\teval-rmse:3.84177\ttrain-rmse:1.98305\n",
      "[16227]\teval-rmse:3.84166\ttrain-rmse:1.98305\n",
      "[16228]\teval-rmse:3.84009\ttrain-rmse:1.98314\n",
      "[16229]\teval-rmse:3.84142\ttrain-rmse:1.98308\n",
      "[16230]\teval-rmse:3.84171\ttrain-rmse:1.98307\n",
      "[16231]\teval-rmse:3.84084\ttrain-rmse:1.98311\n",
      "[16232]\teval-rmse:3.84049\ttrain-rmse:1.98297\n",
      "[16233]\teval-rmse:3.84251\ttrain-rmse:1.98293\n",
      "[16234]\teval-rmse:3.84268\ttrain-rmse:1.98292\n",
      "[16235]\teval-rmse:3.84353\ttrain-rmse:1.98288\n",
      "[16236]\teval-rmse:3.84291\ttrain-rmse:1.98291\n",
      "[16237]\teval-rmse:3.84494\ttrain-rmse:1.98287\n",
      "[16238]\teval-rmse:3.84307\ttrain-rmse:1.98297\n",
      "[16239]\teval-rmse:3.84254\ttrain-rmse:1.983\n",
      "[16240]\teval-rmse:3.84121\ttrain-rmse:1.98305\n",
      "[16241]\teval-rmse:3.84233\ttrain-rmse:1.98301\n",
      "[16242]\teval-rmse:3.84242\ttrain-rmse:1.983\n",
      "[16243]\teval-rmse:3.84444\ttrain-rmse:1.98296\n",
      "[16244]\teval-rmse:3.84473\ttrain-rmse:1.98295\n",
      "[16245]\teval-rmse:3.8461\ttrain-rmse:1.9829\n",
      "[16246]\teval-rmse:3.84547\ttrain-rmse:1.98292\n",
      "[16247]\teval-rmse:3.84657\ttrain-rmse:1.98287\n",
      "[16248]\teval-rmse:3.84479\ttrain-rmse:1.98295\n",
      "[16249]\teval-rmse:3.84307\ttrain-rmse:1.98302\n",
      "[16250]\teval-rmse:3.84184\ttrain-rmse:1.98308\n",
      "[16251]\teval-rmse:3.84256\ttrain-rmse:1.98305\n",
      "[16252]\teval-rmse:3.84105\ttrain-rmse:1.98314\n",
      "[16253]\teval-rmse:3.84276\ttrain-rmse:1.98306\n",
      "[16254]\teval-rmse:3.84305\ttrain-rmse:1.98304\n",
      "[16255]\teval-rmse:3.84416\ttrain-rmse:1.98298\n",
      "[16256]\teval-rmse:3.84579\ttrain-rmse:1.98292\n",
      "[16257]\teval-rmse:3.84681\ttrain-rmse:1.98288\n",
      "[16258]\teval-rmse:3.84826\ttrain-rmse:1.98283\n",
      "[16259]\teval-rmse:3.84899\ttrain-rmse:1.98281\n",
      "[16260]\teval-rmse:3.84884\ttrain-rmse:1.98281\n",
      "[16261]\teval-rmse:3.84684\ttrain-rmse:1.98289\n",
      "[16262]\teval-rmse:3.84847\ttrain-rmse:1.98282\n",
      "[16263]\teval-rmse:3.84766\ttrain-rmse:1.98286\n",
      "[16264]\teval-rmse:3.84762\ttrain-rmse:1.98286\n",
      "[16265]\teval-rmse:3.84621\ttrain-rmse:1.98292\n",
      "[16266]\teval-rmse:3.84597\ttrain-rmse:1.98292\n",
      "[16267]\teval-rmse:3.84493\ttrain-rmse:1.98294\n",
      "[16268]\teval-rmse:3.84452\ttrain-rmse:1.98294\n",
      "[16269]\teval-rmse:3.84615\ttrain-rmse:1.98289\n",
      "[16270]\teval-rmse:3.84779\ttrain-rmse:1.98283\n",
      "[16271]\teval-rmse:3.84903\ttrain-rmse:1.9828\n",
      "[16272]\teval-rmse:3.84838\ttrain-rmse:1.98282\n",
      "[16273]\teval-rmse:3.84796\ttrain-rmse:1.98266\n",
      "[16274]\teval-rmse:3.84771\ttrain-rmse:1.98266\n",
      "[16275]\teval-rmse:3.84689\ttrain-rmse:1.98268\n",
      "[16276]\teval-rmse:3.84584\ttrain-rmse:1.9827\n",
      "[16277]\teval-rmse:3.84715\ttrain-rmse:1.98265\n",
      "[16278]\teval-rmse:3.84721\ttrain-rmse:1.98265\n",
      "[16279]\teval-rmse:3.8488\ttrain-rmse:1.98261\n",
      "[16280]\teval-rmse:3.84819\ttrain-rmse:1.98263\n",
      "[16281]\teval-rmse:3.84625\ttrain-rmse:1.98272\n",
      "[16282]\teval-rmse:3.84827\ttrain-rmse:1.98269\n",
      "[16283]\teval-rmse:3.84677\ttrain-rmse:1.98276\n",
      "[16284]\teval-rmse:3.84572\ttrain-rmse:1.98277\n",
      "[16285]\teval-rmse:3.84596\ttrain-rmse:1.98276\n",
      "[16286]\teval-rmse:3.84571\ttrain-rmse:1.98276\n",
      "[16287]\teval-rmse:3.84392\ttrain-rmse:1.98286\n",
      "[16288]\teval-rmse:3.84529\ttrain-rmse:1.9828\n",
      "[16289]\teval-rmse:3.84455\ttrain-rmse:1.98283\n",
      "[16290]\teval-rmse:3.84432\ttrain-rmse:1.98283\n",
      "[16291]\teval-rmse:3.84229\ttrain-rmse:1.98293\n",
      "[16292]\teval-rmse:3.8441\ttrain-rmse:1.98286\n",
      "[16293]\teval-rmse:3.84523\ttrain-rmse:1.98281\n",
      "[16294]\teval-rmse:3.84687\ttrain-rmse:1.98273\n",
      "[16295]\teval-rmse:3.84532\ttrain-rmse:1.98281\n",
      "[16296]\teval-rmse:3.84459\ttrain-rmse:1.98284\n",
      "[16297]\teval-rmse:3.84306\ttrain-rmse:1.9829\n",
      "[16298]\teval-rmse:3.84336\ttrain-rmse:1.98288\n",
      "[16299]\teval-rmse:3.84448\ttrain-rmse:1.98281\n",
      "[16300]\teval-rmse:3.84406\ttrain-rmse:1.98282\n",
      "[16301]\teval-rmse:3.84436\ttrain-rmse:1.98281\n",
      "[16302]\teval-rmse:3.84394\ttrain-rmse:1.98265\n",
      "[16303]\teval-rmse:3.84575\ttrain-rmse:1.98259\n",
      "[16304]\teval-rmse:3.84644\ttrain-rmse:1.98257\n",
      "[16305]\teval-rmse:3.84724\ttrain-rmse:1.98254\n",
      "[16306]\teval-rmse:3.84698\ttrain-rmse:1.98254\n",
      "[16307]\teval-rmse:3.84665\ttrain-rmse:1.98255\n",
      "[16308]\teval-rmse:3.84747\ttrain-rmse:1.98252\n",
      "[16309]\teval-rmse:3.84605\ttrain-rmse:1.98256\n",
      "[16310]\teval-rmse:3.84611\ttrain-rmse:1.98256\n",
      "[16311]\teval-rmse:3.84673\ttrain-rmse:1.98254\n",
      "[16312]\teval-rmse:3.84768\ttrain-rmse:1.9825\n",
      "[16313]\teval-rmse:3.84729\ttrain-rmse:1.98236\n",
      "[16314]\teval-rmse:3.84593\ttrain-rmse:1.98239\n",
      "[16315]\teval-rmse:3.84447\ttrain-rmse:1.98246\n",
      "[16316]\teval-rmse:3.8462\ttrain-rmse:1.98238\n",
      "[16317]\teval-rmse:3.84587\ttrain-rmse:1.98239\n",
      "[16318]\teval-rmse:3.84525\ttrain-rmse:1.98241\n",
      "[16319]\teval-rmse:3.84633\ttrain-rmse:1.98238\n",
      "[16320]\teval-rmse:3.84656\ttrain-rmse:1.98237\n",
      "[16321]\teval-rmse:3.84541\ttrain-rmse:1.98242\n",
      "[16322]\teval-rmse:3.84417\ttrain-rmse:1.98246\n",
      "[16323]\teval-rmse:3.84296\ttrain-rmse:1.9825\n",
      "[16324]\teval-rmse:3.84459\ttrain-rmse:1.98245\n",
      "[16325]\teval-rmse:3.84396\ttrain-rmse:1.98247\n",
      "[16326]\teval-rmse:3.8452\ttrain-rmse:1.98244\n",
      "[16327]\teval-rmse:3.84339\ttrain-rmse:1.98251\n",
      "[16328]\teval-rmse:3.84343\ttrain-rmse:1.9825\n",
      "[16329]\teval-rmse:3.84302\ttrain-rmse:1.98251\n",
      "[16330]\teval-rmse:3.84217\ttrain-rmse:1.98254\n",
      "[16331]\teval-rmse:3.84339\ttrain-rmse:1.9825\n",
      "[16332]\teval-rmse:3.84275\ttrain-rmse:1.98252\n",
      "[16333]\teval-rmse:3.84319\ttrain-rmse:1.98251\n",
      "[16334]\teval-rmse:3.84522\ttrain-rmse:1.98247\n",
      "[16335]\teval-rmse:3.84507\ttrain-rmse:1.98247\n",
      "[16336]\teval-rmse:3.84681\ttrain-rmse:1.9824\n",
      "[16337]\teval-rmse:3.8475\ttrain-rmse:1.98238\n",
      "[16338]\teval-rmse:3.84675\ttrain-rmse:1.9824\n",
      "[16339]\teval-rmse:3.84478\ttrain-rmse:1.98245\n",
      "[16340]\teval-rmse:3.84669\ttrain-rmse:1.9824\n",
      "[16341]\teval-rmse:3.84825\ttrain-rmse:1.98236\n",
      "[16342]\teval-rmse:3.84914\ttrain-rmse:1.98233\n",
      "[16343]\teval-rmse:3.84731\ttrain-rmse:1.98238\n",
      "[16344]\teval-rmse:3.84848\ttrain-rmse:1.98234\n",
      "[16345]\teval-rmse:3.85031\ttrain-rmse:1.9823\n",
      "[16346]\teval-rmse:3.85215\ttrain-rmse:1.98227\n",
      "[16347]\teval-rmse:3.85221\ttrain-rmse:1.98227\n",
      "[16348]\teval-rmse:3.85175\ttrain-rmse:1.98211\n",
      "[16349]\teval-rmse:3.8513\ttrain-rmse:1.98194\n",
      "[16350]\teval-rmse:3.85241\ttrain-rmse:1.98192\n",
      "[16351]\teval-rmse:3.85111\ttrain-rmse:1.98195\n",
      "[16352]\teval-rmse:3.85159\ttrain-rmse:1.98195\n",
      "[16353]\teval-rmse:3.84958\ttrain-rmse:1.98197\n",
      "[16354]\teval-rmse:3.85159\ttrain-rmse:1.98196\n",
      "[16355]\teval-rmse:3.8536\ttrain-rmse:1.98196\n",
      "[16356]\teval-rmse:3.85392\ttrain-rmse:1.98195\n",
      "[16357]\teval-rmse:3.85335\ttrain-rmse:1.98196\n",
      "[16358]\teval-rmse:3.85317\ttrain-rmse:1.98196\n",
      "[16359]\teval-rmse:3.85394\ttrain-rmse:1.98195\n",
      "[16360]\teval-rmse:3.85437\ttrain-rmse:1.98194\n",
      "[16361]\teval-rmse:3.85536\ttrain-rmse:1.98193\n",
      "[16362]\teval-rmse:3.85439\ttrain-rmse:1.98194\n",
      "[16363]\teval-rmse:3.85469\ttrain-rmse:1.98193\n",
      "[16364]\teval-rmse:3.8531\ttrain-rmse:1.98197\n",
      "[16365]\teval-rmse:3.85282\ttrain-rmse:1.98197\n",
      "[16366]\teval-rmse:3.85444\ttrain-rmse:1.98193\n",
      "[16367]\teval-rmse:3.85294\ttrain-rmse:1.98196\n",
      "[16368]\teval-rmse:3.85266\ttrain-rmse:1.98196\n",
      "[16369]\teval-rmse:3.85226\ttrain-rmse:1.98197\n",
      "[16370]\teval-rmse:3.85427\ttrain-rmse:1.98196\n",
      "[16371]\teval-rmse:3.85319\ttrain-rmse:1.98196\n",
      "[16372]\teval-rmse:3.85376\ttrain-rmse:1.98196\n",
      "[16373]\teval-rmse:3.85346\ttrain-rmse:1.98196\n",
      "[16374]\teval-rmse:3.85407\ttrain-rmse:1.98194\n",
      "[16375]\teval-rmse:3.85495\ttrain-rmse:1.98194\n",
      "[16376]\teval-rmse:3.85404\ttrain-rmse:1.98194\n",
      "[16377]\teval-rmse:3.85519\ttrain-rmse:1.98192\n",
      "[16378]\teval-rmse:3.8541\ttrain-rmse:1.98192\n",
      "[16379]\teval-rmse:3.85212\ttrain-rmse:1.98194\n",
      "[16380]\teval-rmse:3.85255\ttrain-rmse:1.98193\n",
      "[16381]\teval-rmse:3.85159\ttrain-rmse:1.98194\n",
      "[16382]\teval-rmse:3.85108\ttrain-rmse:1.98195\n",
      "[16383]\teval-rmse:3.85121\ttrain-rmse:1.98195\n",
      "[16384]\teval-rmse:3.84975\ttrain-rmse:1.98199\n",
      "[16385]\teval-rmse:3.85046\ttrain-rmse:1.98198\n",
      "[16386]\teval-rmse:3.84901\ttrain-rmse:1.98203\n",
      "[16387]\teval-rmse:3.85067\ttrain-rmse:1.98201\n",
      "[16388]\teval-rmse:3.8511\ttrain-rmse:1.982\n",
      "[16389]\teval-rmse:3.85044\ttrain-rmse:1.98201\n",
      "[16390]\teval-rmse:3.84977\ttrain-rmse:1.98202\n",
      "[16391]\teval-rmse:3.85092\ttrain-rmse:1.98199\n",
      "[16392]\teval-rmse:3.85239\ttrain-rmse:1.98197\n",
      "[16393]\teval-rmse:3.85285\ttrain-rmse:1.98196\n",
      "[16394]\teval-rmse:3.85311\ttrain-rmse:1.98195\n",
      "[16395]\teval-rmse:3.85119\ttrain-rmse:1.98196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16396]\teval-rmse:3.85121\ttrain-rmse:1.98196\n",
      "[16397]\teval-rmse:3.85214\ttrain-rmse:1.98195\n",
      "[16398]\teval-rmse:3.85045\ttrain-rmse:1.98198\n",
      "[16399]\teval-rmse:3.85092\ttrain-rmse:1.98197\n",
      "[16400]\teval-rmse:3.85222\ttrain-rmse:1.98195\n",
      "[16401]\teval-rmse:3.85272\ttrain-rmse:1.98195\n",
      "[16402]\teval-rmse:3.85226\ttrain-rmse:1.98195\n",
      "[16403]\teval-rmse:3.85182\ttrain-rmse:1.98195\n",
      "[16404]\teval-rmse:3.85382\ttrain-rmse:1.98194\n",
      "[16405]\teval-rmse:3.85494\ttrain-rmse:1.98193\n",
      "[16406]\teval-rmse:3.85475\ttrain-rmse:1.98193\n",
      "[16407]\teval-rmse:3.85428\ttrain-rmse:1.98193\n",
      "[16408]\teval-rmse:3.8547\ttrain-rmse:1.98192\n",
      "[16409]\teval-rmse:3.85339\ttrain-rmse:1.98193\n",
      "[16410]\teval-rmse:3.85517\ttrain-rmse:1.98192\n",
      "[16411]\teval-rmse:3.85364\ttrain-rmse:1.98193\n",
      "[16412]\teval-rmse:3.85206\ttrain-rmse:1.98195\n",
      "[16413]\teval-rmse:3.8516\ttrain-rmse:1.98195\n",
      "[16414]\teval-rmse:3.8535\ttrain-rmse:1.9819\n",
      "[16415]\teval-rmse:3.85332\ttrain-rmse:1.9819\n",
      "[16416]\teval-rmse:3.85155\ttrain-rmse:1.98192\n",
      "[16417]\teval-rmse:3.8493\ttrain-rmse:1.98194\n",
      "[16418]\teval-rmse:3.85008\ttrain-rmse:1.98193\n",
      "[16419]\teval-rmse:3.84901\ttrain-rmse:1.98193\n",
      "[16420]\teval-rmse:3.84746\ttrain-rmse:1.98197\n",
      "[16421]\teval-rmse:3.84601\ttrain-rmse:1.98202\n",
      "[16422]\teval-rmse:3.8473\ttrain-rmse:1.98199\n",
      "[16423]\teval-rmse:3.8483\ttrain-rmse:1.98197\n",
      "[16424]\teval-rmse:3.84861\ttrain-rmse:1.98197\n",
      "[16425]\teval-rmse:3.85001\ttrain-rmse:1.98194\n",
      "[16426]\teval-rmse:3.85055\ttrain-rmse:1.98193\n",
      "[16427]\teval-rmse:3.8502\ttrain-rmse:1.98194\n",
      "[16428]\teval-rmse:3.85056\ttrain-rmse:1.98193\n",
      "[16429]\teval-rmse:3.85257\ttrain-rmse:1.98192\n",
      "[16430]\teval-rmse:3.85388\ttrain-rmse:1.9819\n",
      "[16431]\teval-rmse:3.8528\ttrain-rmse:1.9819\n",
      "[16432]\teval-rmse:3.85234\ttrain-rmse:1.9819\n",
      "[16433]\teval-rmse:3.85167\ttrain-rmse:1.98192\n",
      "[16434]\teval-rmse:3.84991\ttrain-rmse:1.98195\n",
      "[16435]\teval-rmse:3.85033\ttrain-rmse:1.98195\n",
      "[16436]\teval-rmse:3.85028\ttrain-rmse:1.98195\n",
      "[16437]\teval-rmse:3.84983\ttrain-rmse:1.98195\n",
      "[16438]\teval-rmse:3.84821\ttrain-rmse:1.98199\n",
      "[16439]\teval-rmse:3.8489\ttrain-rmse:1.98198\n",
      "[16440]\teval-rmse:3.84717\ttrain-rmse:1.98203\n",
      "[16441]\teval-rmse:3.847\ttrain-rmse:1.98203\n",
      "[16442]\teval-rmse:3.84525\ttrain-rmse:1.98208\n",
      "[16443]\teval-rmse:3.84455\ttrain-rmse:1.9821\n",
      "[16444]\teval-rmse:3.84313\ttrain-rmse:1.98214\n",
      "[16445]\teval-rmse:3.84155\ttrain-rmse:1.98222\n",
      "[16446]\teval-rmse:3.84312\ttrain-rmse:1.98214\n",
      "[16447]\teval-rmse:3.84154\ttrain-rmse:1.9822\n",
      "[16448]\teval-rmse:3.84113\ttrain-rmse:1.98221\n",
      "[16449]\teval-rmse:3.84114\ttrain-rmse:1.9822\n",
      "[16450]\teval-rmse:3.84261\ttrain-rmse:1.98215\n",
      "[16451]\teval-rmse:3.844\ttrain-rmse:1.98211\n",
      "[16452]\teval-rmse:3.84242\ttrain-rmse:1.98218\n",
      "[16453]\teval-rmse:3.84299\ttrain-rmse:1.98215\n",
      "[16454]\teval-rmse:3.84246\ttrain-rmse:1.98218\n",
      "[16455]\teval-rmse:3.84437\ttrain-rmse:1.98212\n",
      "[16456]\teval-rmse:3.8424\ttrain-rmse:1.98218\n",
      "[16457]\teval-rmse:3.84293\ttrain-rmse:1.98216\n",
      "[16458]\teval-rmse:3.84495\ttrain-rmse:1.98212\n",
      "[16459]\teval-rmse:3.84557\ttrain-rmse:1.98211\n",
      "[16460]\teval-rmse:3.84515\ttrain-rmse:1.98195\n",
      "[16461]\teval-rmse:3.84444\ttrain-rmse:1.98198\n",
      "[16462]\teval-rmse:3.84407\ttrain-rmse:1.98183\n",
      "[16463]\teval-rmse:3.84248\ttrain-rmse:1.9819\n",
      "[16464]\teval-rmse:3.84117\ttrain-rmse:1.98195\n",
      "[16465]\teval-rmse:3.83972\ttrain-rmse:1.98201\n",
      "[16466]\teval-rmse:3.83991\ttrain-rmse:1.982\n",
      "[16467]\teval-rmse:3.84038\ttrain-rmse:1.98198\n",
      "[16468]\teval-rmse:3.83958\ttrain-rmse:1.98201\n",
      "[16469]\teval-rmse:3.83908\ttrain-rmse:1.98203\n",
      "[16470]\teval-rmse:3.83857\ttrain-rmse:1.98205\n",
      "[16471]\teval-rmse:3.83735\ttrain-rmse:1.98211\n",
      "[16472]\teval-rmse:3.83885\ttrain-rmse:1.98205\n",
      "[16473]\teval-rmse:3.83862\ttrain-rmse:1.98205\n",
      "[16474]\teval-rmse:3.83643\ttrain-rmse:1.98215\n",
      "[16475]\teval-rmse:3.83622\ttrain-rmse:1.98216\n",
      "[16476]\teval-rmse:3.83509\ttrain-rmse:1.98223\n",
      "[16477]\teval-rmse:3.83489\ttrain-rmse:1.98224\n",
      "[16478]\teval-rmse:3.83602\ttrain-rmse:1.98216\n",
      "[16479]\teval-rmse:3.8348\ttrain-rmse:1.98225\n",
      "[16480]\teval-rmse:3.83572\ttrain-rmse:1.98219\n",
      "[16481]\teval-rmse:3.83699\ttrain-rmse:1.98211\n",
      "[16482]\teval-rmse:3.83774\ttrain-rmse:1.98208\n",
      "[16483]\teval-rmse:3.83828\ttrain-rmse:1.98205\n",
      "[16484]\teval-rmse:3.8403\ttrain-rmse:1.982\n",
      "[16485]\teval-rmse:3.8394\ttrain-rmse:1.98205\n",
      "[16486]\teval-rmse:3.83839\ttrain-rmse:1.98207\n",
      "[16487]\teval-rmse:3.83849\ttrain-rmse:1.98207\n",
      "[16488]\teval-rmse:3.83967\ttrain-rmse:1.982\n",
      "[16489]\teval-rmse:3.83866\ttrain-rmse:1.98202\n",
      "[16490]\teval-rmse:3.83808\ttrain-rmse:1.98206\n",
      "[16491]\teval-rmse:3.83774\ttrain-rmse:1.98191\n",
      "[16492]\teval-rmse:3.83865\ttrain-rmse:1.98186\n",
      "[16493]\teval-rmse:3.83827\ttrain-rmse:1.98187\n",
      "[16494]\teval-rmse:3.83806\ttrain-rmse:1.98188\n",
      "[16495]\teval-rmse:3.8384\ttrain-rmse:1.98186\n",
      "[16496]\teval-rmse:3.83632\ttrain-rmse:1.98196\n",
      "[16497]\teval-rmse:3.83656\ttrain-rmse:1.98194\n",
      "[16498]\teval-rmse:3.83781\ttrain-rmse:1.98188\n",
      "[16499]\teval-rmse:3.83942\ttrain-rmse:1.98181\n",
      "[16500]\teval-rmse:3.83803\ttrain-rmse:1.98189\n",
      "[16501]\teval-rmse:3.83588\ttrain-rmse:1.98199\n",
      "[16502]\teval-rmse:3.83477\ttrain-rmse:1.98206\n",
      "[16503]\teval-rmse:3.83617\ttrain-rmse:1.98197\n",
      "[16504]\teval-rmse:3.83819\ttrain-rmse:1.98191\n",
      "[16505]\teval-rmse:3.83635\ttrain-rmse:1.982\n",
      "[16506]\teval-rmse:3.83762\ttrain-rmse:1.98194\n",
      "[16507]\teval-rmse:3.83964\ttrain-rmse:1.98189\n",
      "[16508]\teval-rmse:3.83966\ttrain-rmse:1.98189\n",
      "[16509]\teval-rmse:3.84024\ttrain-rmse:1.98186\n",
      "[16510]\teval-rmse:3.84\ttrain-rmse:1.98187\n",
      "[16511]\teval-rmse:3.8396\ttrain-rmse:1.98187\n",
      "[16512]\teval-rmse:3.83947\ttrain-rmse:1.98188\n",
      "[16513]\teval-rmse:3.83934\ttrain-rmse:1.98188\n",
      "[16514]\teval-rmse:3.83833\ttrain-rmse:1.9819\n",
      "[16515]\teval-rmse:3.837\ttrain-rmse:1.98196\n",
      "[16516]\teval-rmse:3.8389\ttrain-rmse:1.98185\n",
      "[16517]\teval-rmse:3.83732\ttrain-rmse:1.98192\n",
      "[16518]\teval-rmse:3.8374\ttrain-rmse:1.98192\n",
      "[16519]\teval-rmse:3.83763\ttrain-rmse:1.98191\n",
      "[16520]\teval-rmse:3.8388\ttrain-rmse:1.98184\n",
      "[16521]\teval-rmse:3.84039\ttrain-rmse:1.98178\n",
      "[16522]\teval-rmse:3.8424\ttrain-rmse:1.98173\n",
      "[16523]\teval-rmse:3.84404\ttrain-rmse:1.98166\n",
      "[16524]\teval-rmse:3.84278\ttrain-rmse:1.98171\n",
      "[16525]\teval-rmse:3.8439\ttrain-rmse:1.98168\n",
      "[16526]\teval-rmse:3.84469\ttrain-rmse:1.98166\n",
      "[16527]\teval-rmse:3.84619\ttrain-rmse:1.98162\n",
      "[16528]\teval-rmse:3.84635\ttrain-rmse:1.98162\n",
      "[16529]\teval-rmse:3.84756\ttrain-rmse:1.98159\n",
      "[16530]\teval-rmse:3.84628\ttrain-rmse:1.98162\n",
      "[16531]\teval-rmse:3.84566\ttrain-rmse:1.98164\n",
      "[16532]\teval-rmse:3.84621\ttrain-rmse:1.98162\n",
      "[16533]\teval-rmse:3.8467\ttrain-rmse:1.98161\n",
      "[16534]\teval-rmse:3.84553\ttrain-rmse:1.98164\n",
      "[16535]\teval-rmse:3.84406\ttrain-rmse:1.98168\n",
      "[16536]\teval-rmse:3.84303\ttrain-rmse:1.98169\n",
      "[16537]\teval-rmse:3.84346\ttrain-rmse:1.98168\n",
      "[16538]\teval-rmse:3.84278\ttrain-rmse:1.98171\n",
      "[16539]\teval-rmse:3.84263\ttrain-rmse:1.98171\n",
      "[16540]\teval-rmse:3.84432\ttrain-rmse:1.98166\n",
      "[16541]\teval-rmse:3.84437\ttrain-rmse:1.98166\n",
      "[16542]\teval-rmse:3.84538\ttrain-rmse:1.98163\n",
      "[16543]\teval-rmse:3.84614\ttrain-rmse:1.98161\n",
      "[16544]\teval-rmse:3.84599\ttrain-rmse:1.98161\n",
      "[16545]\teval-rmse:3.84778\ttrain-rmse:1.98154\n",
      "[16546]\teval-rmse:3.84843\ttrain-rmse:1.98153\n",
      "[16547]\teval-rmse:3.84699\ttrain-rmse:1.98157\n",
      "[16548]\teval-rmse:3.84799\ttrain-rmse:1.98153\n",
      "[16549]\teval-rmse:3.84693\ttrain-rmse:1.98154\n",
      "[16550]\teval-rmse:3.84867\ttrain-rmse:1.9815\n",
      "[16551]\teval-rmse:3.847\ttrain-rmse:1.98153\n",
      "[16552]\teval-rmse:3.84684\ttrain-rmse:1.98153\n",
      "[16553]\teval-rmse:3.84668\ttrain-rmse:1.98153\n",
      "[16554]\teval-rmse:3.84813\ttrain-rmse:1.9815\n",
      "[16555]\teval-rmse:3.84786\ttrain-rmse:1.9815\n",
      "[16556]\teval-rmse:3.84916\ttrain-rmse:1.98148\n",
      "[16557]\teval-rmse:3.84748\ttrain-rmse:1.98151\n",
      "[16558]\teval-rmse:3.84911\ttrain-rmse:1.98148\n",
      "[16559]\teval-rmse:3.84743\ttrain-rmse:1.98151\n",
      "[16560]\teval-rmse:3.84923\ttrain-rmse:1.98145\n",
      "[16561]\teval-rmse:3.84767\ttrain-rmse:1.98149\n",
      "[16562]\teval-rmse:3.84816\ttrain-rmse:1.98148\n",
      "[16563]\teval-rmse:3.84905\ttrain-rmse:1.98147\n",
      "[16564]\teval-rmse:3.84732\ttrain-rmse:1.98149\n",
      "[16565]\teval-rmse:3.84626\ttrain-rmse:1.9815\n",
      "[16566]\teval-rmse:3.84589\ttrain-rmse:1.98151\n",
      "[16567]\teval-rmse:3.84437\ttrain-rmse:1.98156\n",
      "[16568]\teval-rmse:3.84345\ttrain-rmse:1.98158\n",
      "[16569]\teval-rmse:3.84525\ttrain-rmse:1.98151\n",
      "[16570]\teval-rmse:3.84571\ttrain-rmse:1.9815\n",
      "[16571]\teval-rmse:3.84772\ttrain-rmse:1.98148\n",
      "[16572]\teval-rmse:3.84671\ttrain-rmse:1.98151\n",
      "[16573]\teval-rmse:3.84633\ttrain-rmse:1.98135\n",
      "[16574]\teval-rmse:3.84802\ttrain-rmse:1.98132\n",
      "[16575]\teval-rmse:3.84873\ttrain-rmse:1.98131\n",
      "[16576]\teval-rmse:3.84837\ttrain-rmse:1.98131\n",
      "[16577]\teval-rmse:3.84662\ttrain-rmse:1.98134\n",
      "[16578]\teval-rmse:3.84731\ttrain-rmse:1.98133\n",
      "[16579]\teval-rmse:3.84586\ttrain-rmse:1.98138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16580]\teval-rmse:3.84561\ttrain-rmse:1.98138\n",
      "[16581]\teval-rmse:3.84699\ttrain-rmse:1.98133\n",
      "[16582]\teval-rmse:3.84706\ttrain-rmse:1.98133\n",
      "[16583]\teval-rmse:3.84716\ttrain-rmse:1.98133\n",
      "[16584]\teval-rmse:3.84673\ttrain-rmse:1.98133\n",
      "[16585]\teval-rmse:3.84634\ttrain-rmse:1.98118\n",
      "[16586]\teval-rmse:3.84597\ttrain-rmse:1.98119\n",
      "[16587]\teval-rmse:3.84768\ttrain-rmse:1.98116\n",
      "[16588]\teval-rmse:3.84743\ttrain-rmse:1.98116\n",
      "[16589]\teval-rmse:3.84872\ttrain-rmse:1.98114\n",
      "[16590]\teval-rmse:3.84837\ttrain-rmse:1.98115\n",
      "[16591]\teval-rmse:3.84836\ttrain-rmse:1.98115\n",
      "[16592]\teval-rmse:3.84653\ttrain-rmse:1.98118\n",
      "[16593]\teval-rmse:3.84703\ttrain-rmse:1.98117\n",
      "[16594]\teval-rmse:3.84814\ttrain-rmse:1.98116\n",
      "[16595]\teval-rmse:3.84772\ttrain-rmse:1.98116\n",
      "[16596]\teval-rmse:3.84562\ttrain-rmse:1.9812\n",
      "[16597]\teval-rmse:3.84424\ttrain-rmse:1.98124\n",
      "[16598]\teval-rmse:3.84274\ttrain-rmse:1.9813\n",
      "[16599]\teval-rmse:3.84171\ttrain-rmse:1.98131\n",
      "[16600]\teval-rmse:3.84298\ttrain-rmse:1.98127\n",
      "[16601]\teval-rmse:3.84325\ttrain-rmse:1.98126\n",
      "[16602]\teval-rmse:3.84497\ttrain-rmse:1.98121\n",
      "[16603]\teval-rmse:3.84546\ttrain-rmse:1.9812\n",
      "[16604]\teval-rmse:3.84676\ttrain-rmse:1.98117\n",
      "[16605]\teval-rmse:3.84572\ttrain-rmse:1.98118\n",
      "[16606]\teval-rmse:3.8475\ttrain-rmse:1.98112\n",
      "[16607]\teval-rmse:3.84724\ttrain-rmse:1.98112\n",
      "[16608]\teval-rmse:3.84635\ttrain-rmse:1.98114\n",
      "[16609]\teval-rmse:3.84571\ttrain-rmse:1.98115\n",
      "[16610]\teval-rmse:3.84514\ttrain-rmse:1.98117\n",
      "[16611]\teval-rmse:3.84576\ttrain-rmse:1.98115\n",
      "[16612]\teval-rmse:3.84387\ttrain-rmse:1.98121\n",
      "[16613]\teval-rmse:3.84328\ttrain-rmse:1.98124\n",
      "[16614]\teval-rmse:3.84458\ttrain-rmse:1.98121\n",
      "[16615]\teval-rmse:3.84557\ttrain-rmse:1.98117\n",
      "[16616]\teval-rmse:3.84663\ttrain-rmse:1.98115\n",
      "[16617]\teval-rmse:3.84717\ttrain-rmse:1.98113\n",
      "[16618]\teval-rmse:3.84847\ttrain-rmse:1.98111\n",
      "[16619]\teval-rmse:3.84628\ttrain-rmse:1.98115\n",
      "[16620]\teval-rmse:3.84679\ttrain-rmse:1.98114\n",
      "[16621]\teval-rmse:3.84555\ttrain-rmse:1.98116\n",
      "[16622]\teval-rmse:3.84484\ttrain-rmse:1.98117\n",
      "[16623]\teval-rmse:3.8442\ttrain-rmse:1.9812\n",
      "[16624]\teval-rmse:3.84288\ttrain-rmse:1.98125\n",
      "[16625]\teval-rmse:3.84247\ttrain-rmse:1.98126\n",
      "[16626]\teval-rmse:3.84348\ttrain-rmse:1.98123\n",
      "[16627]\teval-rmse:3.84222\ttrain-rmse:1.98127\n",
      "[16628]\teval-rmse:3.84351\ttrain-rmse:1.98121\n",
      "[16629]\teval-rmse:3.84504\ttrain-rmse:1.98117\n",
      "[16630]\teval-rmse:3.8466\ttrain-rmse:1.98114\n",
      "[16631]\teval-rmse:3.84554\ttrain-rmse:1.98115\n",
      "[16632]\teval-rmse:3.84485\ttrain-rmse:1.98118\n",
      "[16633]\teval-rmse:3.84657\ttrain-rmse:1.98114\n",
      "[16634]\teval-rmse:3.84746\ttrain-rmse:1.98113\n",
      "[16635]\teval-rmse:3.84729\ttrain-rmse:1.98113\n",
      "[16636]\teval-rmse:3.8478\ttrain-rmse:1.98112\n",
      "[16637]\teval-rmse:3.84635\ttrain-rmse:1.98117\n",
      "[16638]\teval-rmse:3.84593\ttrain-rmse:1.98117\n",
      "[16639]\teval-rmse:3.84555\ttrain-rmse:1.98118\n",
      "[16640]\teval-rmse:3.84678\ttrain-rmse:1.98116\n",
      "[16641]\teval-rmse:3.847\ttrain-rmse:1.98115\n",
      "[16642]\teval-rmse:3.84573\ttrain-rmse:1.98117\n",
      "[16643]\teval-rmse:3.8453\ttrain-rmse:1.98101\n",
      "[16644]\teval-rmse:3.84732\ttrain-rmse:1.981\n",
      "[16645]\teval-rmse:3.84676\ttrain-rmse:1.981\n",
      "[16646]\teval-rmse:3.84786\ttrain-rmse:1.98099\n",
      "[16647]\teval-rmse:3.84859\ttrain-rmse:1.98097\n",
      "[16648]\teval-rmse:3.84895\ttrain-rmse:1.98096\n",
      "[16649]\teval-rmse:3.84766\ttrain-rmse:1.98097\n",
      "[16650]\teval-rmse:3.84835\ttrain-rmse:1.98097\n",
      "[16651]\teval-rmse:3.84809\ttrain-rmse:1.98097\n",
      "[16652]\teval-rmse:3.84782\ttrain-rmse:1.98097\n",
      "[16653]\teval-rmse:3.84739\ttrain-rmse:1.98098\n",
      "[16654]\teval-rmse:3.84787\ttrain-rmse:1.98097\n",
      "[16655]\teval-rmse:3.84659\ttrain-rmse:1.981\n",
      "[16656]\teval-rmse:3.84837\ttrain-rmse:1.98095\n",
      "[16657]\teval-rmse:3.85015\ttrain-rmse:1.98094\n",
      "[16658]\teval-rmse:3.85025\ttrain-rmse:1.98093\n",
      "[16659]\teval-rmse:3.85044\ttrain-rmse:1.98093\n",
      "[16660]\teval-rmse:3.85006\ttrain-rmse:1.98094\n",
      "[16661]\teval-rmse:3.85151\ttrain-rmse:1.98091\n",
      "[16662]\teval-rmse:3.85003\ttrain-rmse:1.98095\n",
      "[16663]\teval-rmse:3.84959\ttrain-rmse:1.98095\n",
      "[16664]\teval-rmse:3.84932\ttrain-rmse:1.98095\n",
      "[16665]\teval-rmse:3.84825\ttrain-rmse:1.98095\n",
      "[16666]\teval-rmse:3.84718\ttrain-rmse:1.98096\n",
      "[16667]\teval-rmse:3.84566\ttrain-rmse:1.981\n",
      "[16668]\teval-rmse:3.84717\ttrain-rmse:1.98097\n",
      "[16669]\teval-rmse:3.84549\ttrain-rmse:1.981\n",
      "[16670]\teval-rmse:3.84726\ttrain-rmse:1.98096\n",
      "[16671]\teval-rmse:3.84882\ttrain-rmse:1.98094\n",
      "[16672]\teval-rmse:3.84855\ttrain-rmse:1.98095\n",
      "[16673]\teval-rmse:3.84778\ttrain-rmse:1.98095\n",
      "[16674]\teval-rmse:3.84823\ttrain-rmse:1.98095\n",
      "[16675]\teval-rmse:3.84693\ttrain-rmse:1.98097\n",
      "[16676]\teval-rmse:3.8451\ttrain-rmse:1.98102\n",
      "[16677]\teval-rmse:3.84393\ttrain-rmse:1.98104\n",
      "[16678]\teval-rmse:3.84423\ttrain-rmse:1.98103\n",
      "[16679]\teval-rmse:3.8438\ttrain-rmse:1.98087\n",
      "[16680]\teval-rmse:3.8418\ttrain-rmse:1.98093\n",
      "[16681]\teval-rmse:3.84028\ttrain-rmse:1.98098\n",
      "[16682]\teval-rmse:3.84206\ttrain-rmse:1.98093\n",
      "[16683]\teval-rmse:3.84169\ttrain-rmse:1.98094\n",
      "[16684]\teval-rmse:3.84021\ttrain-rmse:1.98098\n",
      "[16685]\teval-rmse:3.84071\ttrain-rmse:1.98096\n",
      "[16686]\teval-rmse:3.83911\ttrain-rmse:1.98101\n",
      "[16687]\teval-rmse:3.84066\ttrain-rmse:1.98095\n",
      "[16688]\teval-rmse:3.84254\ttrain-rmse:1.98087\n",
      "[16689]\teval-rmse:3.84239\ttrain-rmse:1.98087\n",
      "[16690]\teval-rmse:3.84083\ttrain-rmse:1.98091\n",
      "[16691]\teval-rmse:3.84236\ttrain-rmse:1.98087\n",
      "[16692]\teval-rmse:3.84197\ttrain-rmse:1.98073\n",
      "[16693]\teval-rmse:3.84081\ttrain-rmse:1.98077\n",
      "[16694]\teval-rmse:3.8395\ttrain-rmse:1.9808\n",
      "[16695]\teval-rmse:3.83911\ttrain-rmse:1.98081\n",
      "[16696]\teval-rmse:3.83809\ttrain-rmse:1.98083\n",
      "[16697]\teval-rmse:3.8392\ttrain-rmse:1.9808\n",
      "[16698]\teval-rmse:3.83751\ttrain-rmse:1.98085\n",
      "[16699]\teval-rmse:3.83953\ttrain-rmse:1.98081\n",
      "[16700]\teval-rmse:3.84116\ttrain-rmse:1.98076\n",
      "[16701]\teval-rmse:3.84268\ttrain-rmse:1.9807\n",
      "[16702]\teval-rmse:3.84214\ttrain-rmse:1.98073\n",
      "[16703]\teval-rmse:3.84191\ttrain-rmse:1.98073\n",
      "[16704]\teval-rmse:3.84076\ttrain-rmse:1.98078\n",
      "[16705]\teval-rmse:3.84061\ttrain-rmse:1.98078\n",
      "[16706]\teval-rmse:3.83898\ttrain-rmse:1.98083\n",
      "[16707]\teval-rmse:3.83836\ttrain-rmse:1.98086\n",
      "[16708]\teval-rmse:3.83979\ttrain-rmse:1.98081\n",
      "[16709]\teval-rmse:3.83926\ttrain-rmse:1.98083\n",
      "[16710]\teval-rmse:3.83947\ttrain-rmse:1.98082\n",
      "[16711]\teval-rmse:3.84149\ttrain-rmse:1.98078\n",
      "[16712]\teval-rmse:3.84086\ttrain-rmse:1.98081\n",
      "[16713]\teval-rmse:3.84162\ttrain-rmse:1.98079\n",
      "[16714]\teval-rmse:3.84014\ttrain-rmse:1.98083\n",
      "[16715]\teval-rmse:3.84088\ttrain-rmse:1.9808\n",
      "[16716]\teval-rmse:3.8414\ttrain-rmse:1.98079\n",
      "[16717]\teval-rmse:3.84279\ttrain-rmse:1.98075\n",
      "[16718]\teval-rmse:3.84309\ttrain-rmse:1.98075\n",
      "[16719]\teval-rmse:3.84378\ttrain-rmse:1.98073\n",
      "[16720]\teval-rmse:3.84184\ttrain-rmse:1.98079\n",
      "[16721]\teval-rmse:3.84057\ttrain-rmse:1.98083\n",
      "[16722]\teval-rmse:3.83942\ttrain-rmse:1.98088\n",
      "[16723]\teval-rmse:3.83942\ttrain-rmse:1.98088\n",
      "[16724]\teval-rmse:3.83818\ttrain-rmse:1.98094\n",
      "[16725]\teval-rmse:3.83868\ttrain-rmse:1.98092\n",
      "[16726]\teval-rmse:3.83698\ttrain-rmse:1.981\n",
      "[16727]\teval-rmse:3.8366\ttrain-rmse:1.98084\n",
      "[16728]\teval-rmse:3.83622\ttrain-rmse:1.98085\n",
      "[16729]\teval-rmse:3.83464\ttrain-rmse:1.98091\n",
      "[16730]\teval-rmse:3.83365\ttrain-rmse:1.98094\n",
      "[16731]\teval-rmse:3.83369\ttrain-rmse:1.98094\n",
      "[16732]\teval-rmse:3.83177\ttrain-rmse:1.98103\n",
      "[16733]\teval-rmse:3.83334\ttrain-rmse:1.98096\n",
      "[16734]\teval-rmse:3.83297\ttrain-rmse:1.98081\n",
      "[16735]\teval-rmse:3.8335\ttrain-rmse:1.98079\n",
      "[16736]\teval-rmse:3.83253\ttrain-rmse:1.98083\n",
      "[16737]\teval-rmse:3.83456\ttrain-rmse:1.98077\n",
      "[16738]\teval-rmse:3.83436\ttrain-rmse:1.98077\n",
      "[16739]\teval-rmse:3.83404\ttrain-rmse:1.98062\n",
      "[16740]\teval-rmse:3.83436\ttrain-rmse:1.9806\n",
      "[16741]\teval-rmse:3.83589\ttrain-rmse:1.98054\n",
      "[16742]\teval-rmse:3.83505\ttrain-rmse:1.98057\n",
      "[16743]\teval-rmse:3.83706\ttrain-rmse:1.98052\n",
      "[16744]\teval-rmse:3.83566\ttrain-rmse:1.98059\n",
      "[16745]\teval-rmse:3.83428\ttrain-rmse:1.98067\n",
      "[16746]\teval-rmse:3.83369\ttrain-rmse:1.9807\n",
      "[16747]\teval-rmse:3.83202\ttrain-rmse:1.98077\n",
      "[16748]\teval-rmse:3.83169\ttrain-rmse:1.98079\n",
      "[16749]\teval-rmse:3.83249\ttrain-rmse:1.98075\n",
      "[16750]\teval-rmse:3.8317\ttrain-rmse:1.98079\n",
      "[16751]\teval-rmse:3.83101\ttrain-rmse:1.98083\n",
      "[16752]\teval-rmse:3.83006\ttrain-rmse:1.98089\n",
      "[16753]\teval-rmse:3.83037\ttrain-rmse:1.98087\n",
      "[16754]\teval-rmse:3.8306\ttrain-rmse:1.98086\n",
      "[16755]\teval-rmse:3.8304\ttrain-rmse:1.98086\n",
      "[16756]\teval-rmse:3.83089\ttrain-rmse:1.98084\n",
      "[16757]\teval-rmse:3.83141\ttrain-rmse:1.9808\n",
      "[16758]\teval-rmse:3.83006\ttrain-rmse:1.98088\n",
      "[16759]\teval-rmse:3.83115\ttrain-rmse:1.9808\n",
      "[16760]\teval-rmse:3.8327\ttrain-rmse:1.9807\n",
      "[16761]\teval-rmse:3.83211\ttrain-rmse:1.98073\n",
      "[16762]\teval-rmse:3.83353\ttrain-rmse:1.98067\n",
      "[16763]\teval-rmse:3.83241\ttrain-rmse:1.98073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16764]\teval-rmse:3.83444\ttrain-rmse:1.98066\n",
      "[16765]\teval-rmse:3.83423\ttrain-rmse:1.98067\n",
      "[16766]\teval-rmse:3.83231\ttrain-rmse:1.98077\n",
      "[16767]\teval-rmse:3.83308\ttrain-rmse:1.98072\n",
      "[16768]\teval-rmse:3.83259\ttrain-rmse:1.98074\n",
      "[16769]\teval-rmse:3.83383\ttrain-rmse:1.98068\n",
      "[16770]\teval-rmse:3.83389\ttrain-rmse:1.98068\n",
      "[16771]\teval-rmse:3.83519\ttrain-rmse:1.98061\n",
      "[16772]\teval-rmse:3.83506\ttrain-rmse:1.98061\n",
      "[16773]\teval-rmse:3.83549\ttrain-rmse:1.98059\n",
      "[16774]\teval-rmse:3.83602\ttrain-rmse:1.98057\n",
      "[16775]\teval-rmse:3.83739\ttrain-rmse:1.9805\n",
      "[16776]\teval-rmse:3.8394\ttrain-rmse:1.98045\n",
      "[16777]\teval-rmse:3.8381\ttrain-rmse:1.9805\n",
      "[16778]\teval-rmse:3.8391\ttrain-rmse:1.98046\n",
      "[16779]\teval-rmse:3.83838\ttrain-rmse:1.98049\n",
      "[16780]\teval-rmse:3.83886\ttrain-rmse:1.98047\n",
      "[16781]\teval-rmse:3.83844\ttrain-rmse:1.98048\n",
      "[16782]\teval-rmse:3.83731\ttrain-rmse:1.98052\n",
      "[16783]\teval-rmse:3.83825\ttrain-rmse:1.98049\n",
      "[16784]\teval-rmse:3.83702\ttrain-rmse:1.98055\n",
      "[16785]\teval-rmse:3.83504\ttrain-rmse:1.98065\n",
      "[16786]\teval-rmse:3.83293\ttrain-rmse:1.98075\n",
      "[16787]\teval-rmse:3.83257\ttrain-rmse:1.9806\n",
      "[16788]\teval-rmse:3.83446\ttrain-rmse:1.98048\n",
      "[16789]\teval-rmse:3.83525\ttrain-rmse:1.98045\n",
      "[16790]\teval-rmse:3.83726\ttrain-rmse:1.9804\n",
      "[16791]\teval-rmse:3.83765\ttrain-rmse:1.98038\n",
      "[16792]\teval-rmse:3.83732\ttrain-rmse:1.98039\n",
      "[16793]\teval-rmse:3.83776\ttrain-rmse:1.98037\n",
      "[16794]\teval-rmse:3.83637\ttrain-rmse:1.98044\n",
      "[16795]\teval-rmse:3.83577\ttrain-rmse:1.98047\n",
      "[16796]\teval-rmse:3.83459\ttrain-rmse:1.98053\n",
      "[16797]\teval-rmse:3.83515\ttrain-rmse:1.9805\n",
      "[16798]\teval-rmse:3.83698\ttrain-rmse:1.9804\n",
      "[16799]\teval-rmse:3.83523\ttrain-rmse:1.9805\n",
      "[16800]\teval-rmse:3.83606\ttrain-rmse:1.98046\n",
      "[16801]\teval-rmse:3.83678\ttrain-rmse:1.98043\n",
      "[16802]\teval-rmse:3.83577\ttrain-rmse:1.98046\n",
      "[16803]\teval-rmse:3.83628\ttrain-rmse:1.98043\n",
      "[16804]\teval-rmse:3.83577\ttrain-rmse:1.98046\n",
      "[16805]\teval-rmse:3.83706\ttrain-rmse:1.98039\n",
      "[16806]\teval-rmse:3.83762\ttrain-rmse:1.98037\n",
      "[16807]\teval-rmse:3.83963\ttrain-rmse:1.98032\n",
      "[16808]\teval-rmse:3.8394\ttrain-rmse:1.98033\n",
      "[16809]\teval-rmse:3.8402\ttrain-rmse:1.98029\n",
      "[16810]\teval-rmse:3.84024\ttrain-rmse:1.98029\n",
      "[16811]\teval-rmse:3.84203\ttrain-rmse:1.98021\n",
      "[16812]\teval-rmse:3.8427\ttrain-rmse:1.9802\n",
      "[16813]\teval-rmse:3.84254\ttrain-rmse:1.9802\n",
      "[16814]\teval-rmse:3.84104\ttrain-rmse:1.98025\n",
      "[16815]\teval-rmse:3.84306\ttrain-rmse:1.98022\n",
      "[16816]\teval-rmse:3.84444\ttrain-rmse:1.98018\n",
      "[16817]\teval-rmse:3.84516\ttrain-rmse:1.98016\n",
      "[16818]\teval-rmse:3.84694\ttrain-rmse:1.98014\n",
      "[16819]\teval-rmse:3.8465\ttrain-rmse:1.98014\n",
      "[16820]\teval-rmse:3.84607\ttrain-rmse:1.98014\n",
      "[16821]\teval-rmse:3.84423\ttrain-rmse:1.98017\n",
      "[16822]\teval-rmse:3.84235\ttrain-rmse:1.98023\n",
      "[16823]\teval-rmse:3.84383\ttrain-rmse:1.9802\n",
      "[16824]\teval-rmse:3.84267\ttrain-rmse:1.98024\n",
      "[16825]\teval-rmse:3.84373\ttrain-rmse:1.98021\n",
      "[16826]\teval-rmse:3.84201\ttrain-rmse:1.98025\n",
      "[16827]\teval-rmse:3.84382\ttrain-rmse:1.98021\n",
      "[16828]\teval-rmse:3.84344\ttrain-rmse:1.98008\n",
      "[16829]\teval-rmse:3.84417\ttrain-rmse:1.98005\n",
      "[16830]\teval-rmse:3.84445\ttrain-rmse:1.98005\n",
      "[16831]\teval-rmse:3.84561\ttrain-rmse:1.98002\n",
      "[16832]\teval-rmse:3.84721\ttrain-rmse:1.97999\n",
      "[16833]\teval-rmse:3.84659\ttrain-rmse:1.98\n",
      "[16834]\teval-rmse:3.84735\ttrain-rmse:1.97999\n",
      "[16835]\teval-rmse:3.84513\ttrain-rmse:1.98001\n",
      "[16836]\teval-rmse:3.84341\ttrain-rmse:1.98004\n",
      "[16837]\teval-rmse:3.84498\ttrain-rmse:1.98001\n",
      "[16838]\teval-rmse:3.84648\ttrain-rmse:1.97999\n",
      "[16839]\teval-rmse:3.84796\ttrain-rmse:1.97998\n",
      "[16840]\teval-rmse:3.84707\ttrain-rmse:1.97999\n",
      "[16841]\teval-rmse:3.84494\ttrain-rmse:1.98002\n",
      "[16842]\teval-rmse:3.84369\ttrain-rmse:1.98004\n",
      "[16843]\teval-rmse:3.84327\ttrain-rmse:1.9799\n",
      "[16844]\teval-rmse:3.84283\ttrain-rmse:1.97991\n",
      "[16845]\teval-rmse:3.84241\ttrain-rmse:1.97976\n",
      "[16846]\teval-rmse:3.84291\ttrain-rmse:1.97975\n",
      "[16847]\teval-rmse:3.84142\ttrain-rmse:1.97978\n",
      "[16848]\teval-rmse:3.84166\ttrain-rmse:1.97978\n",
      "[16849]\teval-rmse:3.84188\ttrain-rmse:1.97977\n",
      "[16850]\teval-rmse:3.84035\ttrain-rmse:1.97981\n",
      "[16851]\teval-rmse:3.83914\ttrain-rmse:1.97985\n",
      "[16852]\teval-rmse:3.83948\ttrain-rmse:1.97984\n",
      "[16853]\teval-rmse:3.83886\ttrain-rmse:1.97987\n",
      "[16854]\teval-rmse:3.83731\ttrain-rmse:1.97993\n",
      "[16855]\teval-rmse:3.83854\ttrain-rmse:1.97989\n",
      "[16856]\teval-rmse:3.8383\ttrain-rmse:1.9799\n",
      "[16857]\teval-rmse:3.83864\ttrain-rmse:1.97988\n",
      "[16858]\teval-rmse:3.83682\ttrain-rmse:1.97995\n",
      "[16859]\teval-rmse:3.83693\ttrain-rmse:1.97994\n",
      "[16860]\teval-rmse:3.83772\ttrain-rmse:1.97992\n",
      "[16861]\teval-rmse:3.83824\ttrain-rmse:1.97989\n",
      "[16862]\teval-rmse:3.83861\ttrain-rmse:1.97988\n",
      "[16863]\teval-rmse:3.83814\ttrain-rmse:1.9799\n",
      "[16864]\teval-rmse:3.83752\ttrain-rmse:1.97992\n",
      "[16865]\teval-rmse:3.83797\ttrain-rmse:1.97991\n",
      "[16866]\teval-rmse:3.8375\ttrain-rmse:1.97992\n",
      "[16867]\teval-rmse:3.8378\ttrain-rmse:1.97991\n",
      "[16868]\teval-rmse:3.83858\ttrain-rmse:1.97988\n",
      "[16869]\teval-rmse:3.84026\ttrain-rmse:1.97984\n",
      "[16870]\teval-rmse:3.83854\ttrain-rmse:1.97989\n",
      "[16871]\teval-rmse:3.83906\ttrain-rmse:1.97987\n",
      "[16872]\teval-rmse:3.83891\ttrain-rmse:1.97987\n",
      "[16873]\teval-rmse:3.84047\ttrain-rmse:1.97983\n",
      "[16874]\teval-rmse:3.83965\ttrain-rmse:1.97985\n",
      "[16875]\teval-rmse:3.83827\ttrain-rmse:1.97991\n",
      "[16876]\teval-rmse:3.83995\ttrain-rmse:1.97985\n",
      "[16877]\teval-rmse:3.83891\ttrain-rmse:1.97987\n",
      "[16878]\teval-rmse:3.83935\ttrain-rmse:1.97986\n",
      "[16879]\teval-rmse:3.83795\ttrain-rmse:1.97992\n",
      "[16880]\teval-rmse:3.83792\ttrain-rmse:1.97992\n",
      "[16881]\teval-rmse:3.83994\ttrain-rmse:1.97988\n",
      "[16882]\teval-rmse:3.84131\ttrain-rmse:1.97985\n",
      "[16883]\teval-rmse:3.8413\ttrain-rmse:1.97985\n",
      "[16884]\teval-rmse:3.84069\ttrain-rmse:1.97987\n",
      "[16885]\teval-rmse:3.84021\ttrain-rmse:1.97988\n",
      "[16886]\teval-rmse:3.83985\ttrain-rmse:1.97975\n",
      "[16887]\teval-rmse:3.84163\ttrain-rmse:1.97971\n",
      "[16888]\teval-rmse:3.84239\ttrain-rmse:1.97968\n",
      "[16889]\teval-rmse:3.8441\ttrain-rmse:1.97966\n",
      "[16890]\teval-rmse:3.84572\ttrain-rmse:1.9796\n",
      "[16891]\teval-rmse:3.84637\ttrain-rmse:1.97959\n",
      "[16892]\teval-rmse:3.84618\ttrain-rmse:1.9796\n",
      "[16893]\teval-rmse:3.84575\ttrain-rmse:1.97947\n",
      "[16894]\teval-rmse:3.84377\ttrain-rmse:1.97951\n",
      "[16895]\teval-rmse:3.84217\ttrain-rmse:1.97955\n",
      "[16896]\teval-rmse:3.84356\ttrain-rmse:1.97953\n",
      "[16897]\teval-rmse:3.84213\ttrain-rmse:1.97958\n",
      "[16898]\teval-rmse:3.84352\ttrain-rmse:1.97954\n",
      "[16899]\teval-rmse:3.84288\ttrain-rmse:1.97956\n",
      "[16900]\teval-rmse:3.84397\ttrain-rmse:1.97954\n",
      "[16901]\teval-rmse:3.84597\ttrain-rmse:1.97952\n",
      "[16902]\teval-rmse:3.84785\ttrain-rmse:1.9795\n",
      "[16903]\teval-rmse:3.84865\ttrain-rmse:1.97949\n",
      "[16904]\teval-rmse:3.85011\ttrain-rmse:1.9795\n",
      "[16905]\teval-rmse:3.85108\ttrain-rmse:1.97947\n",
      "[16906]\teval-rmse:3.84931\ttrain-rmse:1.97947\n",
      "[16907]\teval-rmse:3.85069\ttrain-rmse:1.97946\n",
      "[16908]\teval-rmse:3.85226\ttrain-rmse:1.97947\n",
      "[16909]\teval-rmse:3.85092\ttrain-rmse:1.97947\n",
      "[16910]\teval-rmse:3.84872\ttrain-rmse:1.97947\n",
      "[16911]\teval-rmse:3.84706\ttrain-rmse:1.97947\n",
      "[16912]\teval-rmse:3.84651\ttrain-rmse:1.97949\n",
      "[16913]\teval-rmse:3.84554\ttrain-rmse:1.97949\n",
      "[16914]\teval-rmse:3.8441\ttrain-rmse:1.97954\n",
      "[16915]\teval-rmse:3.84609\ttrain-rmse:1.97953\n",
      "[16916]\teval-rmse:3.84713\ttrain-rmse:1.97951\n",
      "[16917]\teval-rmse:3.84517\ttrain-rmse:1.97955\n",
      "[16918]\teval-rmse:3.84679\ttrain-rmse:1.97949\n",
      "[16919]\teval-rmse:3.84785\ttrain-rmse:1.97948\n",
      "[16920]\teval-rmse:3.84794\ttrain-rmse:1.97948\n",
      "[16921]\teval-rmse:3.84976\ttrain-rmse:1.97946\n",
      "[16922]\teval-rmse:3.84844\ttrain-rmse:1.97946\n",
      "[16923]\teval-rmse:3.84703\ttrain-rmse:1.97947\n",
      "[16924]\teval-rmse:3.84813\ttrain-rmse:1.97946\n",
      "[16925]\teval-rmse:3.84853\ttrain-rmse:1.97946\n",
      "[16926]\teval-rmse:3.84775\ttrain-rmse:1.97946\n",
      "[16927]\teval-rmse:3.84667\ttrain-rmse:1.97946\n",
      "[16928]\teval-rmse:3.84754\ttrain-rmse:1.97945\n",
      "[16929]\teval-rmse:3.84916\ttrain-rmse:1.97941\n",
      "[16930]\teval-rmse:3.84746\ttrain-rmse:1.97943\n",
      "[16931]\teval-rmse:3.8488\ttrain-rmse:1.97941\n",
      "[16932]\teval-rmse:3.84828\ttrain-rmse:1.97941\n",
      "[16933]\teval-rmse:3.84881\ttrain-rmse:1.97941\n",
      "[16934]\teval-rmse:3.84761\ttrain-rmse:1.97942\n",
      "[16935]\teval-rmse:3.8479\ttrain-rmse:1.97941\n",
      "[16936]\teval-rmse:3.84751\ttrain-rmse:1.97927\n",
      "[16937]\teval-rmse:3.84796\ttrain-rmse:1.97927\n",
      "[16938]\teval-rmse:3.84904\ttrain-rmse:1.97927\n",
      "[16939]\teval-rmse:3.84978\ttrain-rmse:1.97927\n",
      "[16940]\teval-rmse:3.85044\ttrain-rmse:1.97927\n",
      "[16941]\teval-rmse:3.84864\ttrain-rmse:1.97927\n",
      "[16942]\teval-rmse:3.84716\ttrain-rmse:1.97928\n",
      "[16943]\teval-rmse:3.84648\ttrain-rmse:1.97929\n",
      "[16944]\teval-rmse:3.84541\ttrain-rmse:1.97929\n",
      "[16945]\teval-rmse:3.84399\ttrain-rmse:1.97932\n",
      "[16946]\teval-rmse:3.84335\ttrain-rmse:1.97934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16947]\teval-rmse:3.84507\ttrain-rmse:1.97932\n",
      "[16948]\teval-rmse:3.84313\ttrain-rmse:1.97936\n",
      "[16949]\teval-rmse:3.84388\ttrain-rmse:1.97935\n",
      "[16950]\teval-rmse:3.84334\ttrain-rmse:1.97936\n",
      "[16951]\teval-rmse:3.84455\ttrain-rmse:1.97935\n",
      "[16952]\teval-rmse:3.84638\ttrain-rmse:1.97932\n",
      "[16953]\teval-rmse:3.84758\ttrain-rmse:1.97931\n",
      "[16954]\teval-rmse:3.84739\ttrain-rmse:1.97931\n",
      "[16955]\teval-rmse:3.84938\ttrain-rmse:1.97931\n",
      "[16956]\teval-rmse:3.85082\ttrain-rmse:1.9793\n",
      "[16957]\teval-rmse:3.84935\ttrain-rmse:1.9793\n",
      "[16958]\teval-rmse:3.84805\ttrain-rmse:1.9793\n",
      "[16959]\teval-rmse:3.85004\ttrain-rmse:1.9793\n",
      "[16960]\teval-rmse:3.85143\ttrain-rmse:1.97931\n",
      "[16961]\teval-rmse:3.85305\ttrain-rmse:1.97931\n",
      "[16962]\teval-rmse:3.85099\ttrain-rmse:1.97932\n",
      "[16963]\teval-rmse:3.85096\ttrain-rmse:1.97932\n",
      "[16964]\teval-rmse:3.85284\ttrain-rmse:1.97934\n",
      "[16965]\teval-rmse:3.85084\ttrain-rmse:1.97934\n",
      "[16966]\teval-rmse:3.84975\ttrain-rmse:1.97933\n",
      "[16967]\teval-rmse:3.84855\ttrain-rmse:1.97934\n",
      "[16968]\teval-rmse:3.85016\ttrain-rmse:1.97934\n",
      "[16969]\teval-rmse:3.85034\ttrain-rmse:1.97934\n",
      "[16970]\teval-rmse:3.84872\ttrain-rmse:1.97934\n",
      "[16971]\teval-rmse:3.85004\ttrain-rmse:1.97934\n",
      "[16972]\teval-rmse:3.85142\ttrain-rmse:1.97934\n",
      "[16973]\teval-rmse:3.85219\ttrain-rmse:1.97934\n",
      "[16974]\teval-rmse:3.85297\ttrain-rmse:1.97934\n",
      "[16975]\teval-rmse:3.85183\ttrain-rmse:1.97934\n",
      "[16976]\teval-rmse:3.85003\ttrain-rmse:1.97933\n",
      "[16977]\teval-rmse:3.85077\ttrain-rmse:1.97933\n",
      "[16978]\teval-rmse:3.8512\ttrain-rmse:1.97934\n",
      "[16979]\teval-rmse:3.85308\ttrain-rmse:1.97934\n",
      "[16980]\teval-rmse:3.85278\ttrain-rmse:1.97934\n",
      "[16981]\teval-rmse:3.85439\ttrain-rmse:1.97935\n",
      "[16982]\teval-rmse:3.85486\ttrain-rmse:1.97936\n",
      "[16983]\teval-rmse:3.85544\ttrain-rmse:1.97936\n",
      "[16984]\teval-rmse:3.85637\ttrain-rmse:1.97937\n",
      "[16985]\teval-rmse:3.85491\ttrain-rmse:1.97935\n",
      "[16986]\teval-rmse:3.85519\ttrain-rmse:1.97935\n",
      "[16987]\teval-rmse:3.8564\ttrain-rmse:1.97937\n",
      "[16988]\teval-rmse:3.85665\ttrain-rmse:1.97937\n",
      "[16989]\teval-rmse:3.85762\ttrain-rmse:1.97939\n",
      "[16990]\teval-rmse:3.85738\ttrain-rmse:1.97939\n",
      "[16991]\teval-rmse:3.85923\ttrain-rmse:1.97938\n",
      "[16992]\teval-rmse:3.86001\ttrain-rmse:1.9794\n",
      "[16993]\teval-rmse:3.86161\ttrain-rmse:1.9794\n",
      "[16994]\teval-rmse:3.86171\ttrain-rmse:1.97941\n",
      "[16995]\teval-rmse:3.86274\ttrain-rmse:1.97944\n",
      "[16996]\teval-rmse:3.86294\ttrain-rmse:1.97945\n",
      "[16997]\teval-rmse:3.86492\ttrain-rmse:1.9795\n",
      "[16998]\teval-rmse:3.86605\ttrain-rmse:1.97954\n",
      "[16999]\teval-rmse:3.86465\ttrain-rmse:1.9795\n",
      "[17000]\teval-rmse:3.86257\ttrain-rmse:1.97942\n",
      "[17001]\teval-rmse:3.86291\ttrain-rmse:1.97943\n",
      "[17002]\teval-rmse:3.8624\ttrain-rmse:1.97942\n",
      "[17003]\teval-rmse:3.86075\ttrain-rmse:1.97937\n",
      "[17004]\teval-rmse:3.85941\ttrain-rmse:1.97934\n",
      "[17005]\teval-rmse:3.85731\ttrain-rmse:1.97929\n",
      "[17006]\teval-rmse:3.85802\ttrain-rmse:1.97931\n",
      "[17007]\teval-rmse:3.85618\ttrain-rmse:1.97929\n",
      "[17008]\teval-rmse:3.85412\ttrain-rmse:1.97927\n",
      "[17009]\teval-rmse:3.85488\ttrain-rmse:1.97928\n",
      "[17010]\teval-rmse:3.85494\ttrain-rmse:1.97928\n",
      "[17011]\teval-rmse:3.85447\ttrain-rmse:1.97914\n",
      "[17012]\teval-rmse:3.85624\ttrain-rmse:1.97915\n",
      "[17013]\teval-rmse:3.85646\ttrain-rmse:1.97916\n",
      "[17014]\teval-rmse:3.85495\ttrain-rmse:1.97914\n",
      "[17015]\teval-rmse:3.85425\ttrain-rmse:1.97915\n",
      "[17016]\teval-rmse:3.85325\ttrain-rmse:1.97914\n",
      "[17017]\teval-rmse:3.85367\ttrain-rmse:1.97914\n",
      "[17018]\teval-rmse:3.85256\ttrain-rmse:1.97914\n",
      "[17019]\teval-rmse:3.85226\ttrain-rmse:1.97913\n",
      "[17020]\teval-rmse:3.85251\ttrain-rmse:1.97914\n",
      "[17021]\teval-rmse:3.85032\ttrain-rmse:1.97913\n",
      "[17022]\teval-rmse:3.85002\ttrain-rmse:1.97913\n",
      "[17023]\teval-rmse:3.85111\ttrain-rmse:1.97912\n",
      "[17024]\teval-rmse:3.8507\ttrain-rmse:1.97912\n",
      "[17025]\teval-rmse:3.85195\ttrain-rmse:1.97912\n",
      "[17026]\teval-rmse:3.85074\ttrain-rmse:1.97914\n",
      "[17027]\teval-rmse:3.85147\ttrain-rmse:1.97914\n",
      "[17028]\teval-rmse:3.85117\ttrain-rmse:1.97914\n",
      "[17029]\teval-rmse:3.85072\ttrain-rmse:1.97899\n",
      "[17030]\teval-rmse:3.84935\ttrain-rmse:1.979\n",
      "[17031]\teval-rmse:3.8472\ttrain-rmse:1.979\n",
      "[17032]\teval-rmse:3.84703\ttrain-rmse:1.979\n",
      "[17033]\teval-rmse:3.84658\ttrain-rmse:1.979\n",
      "[17034]\teval-rmse:3.84736\ttrain-rmse:1.97899\n",
      "[17035]\teval-rmse:3.84671\ttrain-rmse:1.979\n",
      "[17036]\teval-rmse:3.84492\ttrain-rmse:1.97902\n",
      "[17037]\teval-rmse:3.84428\ttrain-rmse:1.97903\n",
      "[17038]\teval-rmse:3.84531\ttrain-rmse:1.97901\n",
      "[17039]\teval-rmse:3.84675\ttrain-rmse:1.97899\n",
      "[17040]\teval-rmse:3.84657\ttrain-rmse:1.97899\n",
      "[17041]\teval-rmse:3.84807\ttrain-rmse:1.97898\n",
      "[17042]\teval-rmse:3.84629\ttrain-rmse:1.979\n",
      "[17043]\teval-rmse:3.8461\ttrain-rmse:1.979\n",
      "[17044]\teval-rmse:3.84641\ttrain-rmse:1.97899\n",
      "[17045]\teval-rmse:3.84623\ttrain-rmse:1.97899\n",
      "[17046]\teval-rmse:3.84688\ttrain-rmse:1.97899\n",
      "[17047]\teval-rmse:3.8485\ttrain-rmse:1.97898\n",
      "[17048]\teval-rmse:3.84821\ttrain-rmse:1.97898\n",
      "[17049]\teval-rmse:3.84997\ttrain-rmse:1.97899\n",
      "[17050]\teval-rmse:3.85155\ttrain-rmse:1.979\n",
      "[17051]\teval-rmse:3.85315\ttrain-rmse:1.97897\n",
      "[17052]\teval-rmse:3.8524\ttrain-rmse:1.97897\n",
      "[17053]\teval-rmse:3.85171\ttrain-rmse:1.97898\n",
      "[17054]\teval-rmse:3.85142\ttrain-rmse:1.97898\n",
      "[17055]\teval-rmse:3.85095\ttrain-rmse:1.97897\n",
      "[17056]\teval-rmse:3.85114\ttrain-rmse:1.97897\n",
      "[17057]\teval-rmse:3.85229\ttrain-rmse:1.97898\n",
      "[17058]\teval-rmse:3.85186\ttrain-rmse:1.97884\n",
      "[17059]\teval-rmse:3.85324\ttrain-rmse:1.97886\n",
      "[17060]\teval-rmse:3.8523\ttrain-rmse:1.97885\n",
      "[17061]\teval-rmse:3.85059\ttrain-rmse:1.97883\n",
      "[17062]\teval-rmse:3.85016\ttrain-rmse:1.97883\n",
      "[17063]\teval-rmse:3.85038\ttrain-rmse:1.97883\n",
      "[17064]\teval-rmse:3.84891\ttrain-rmse:1.97883\n",
      "[17065]\teval-rmse:3.85068\ttrain-rmse:1.97884\n",
      "[17066]\teval-rmse:3.84886\ttrain-rmse:1.97884\n",
      "[17067]\teval-rmse:3.84842\ttrain-rmse:1.97871\n",
      "[17068]\teval-rmse:3.8487\ttrain-rmse:1.97871\n",
      "[17069]\teval-rmse:3.84932\ttrain-rmse:1.97871\n",
      "[17070]\teval-rmse:3.84913\ttrain-rmse:1.97871\n",
      "[17071]\teval-rmse:3.85072\ttrain-rmse:1.97871\n",
      "[17072]\teval-rmse:3.84929\ttrain-rmse:1.9787\n",
      "[17073]\teval-rmse:3.8498\ttrain-rmse:1.9787\n",
      "[17074]\teval-rmse:3.8518\ttrain-rmse:1.97872\n",
      "[17075]\teval-rmse:3.85288\ttrain-rmse:1.97873\n",
      "[17076]\teval-rmse:3.85098\ttrain-rmse:1.97871\n",
      "[17077]\teval-rmse:3.85028\ttrain-rmse:1.9787\n",
      "[17078]\teval-rmse:3.85184\ttrain-rmse:1.97871\n",
      "[17079]\teval-rmse:3.85298\ttrain-rmse:1.97873\n",
      "[17080]\teval-rmse:3.85249\ttrain-rmse:1.97872\n",
      "[17081]\teval-rmse:3.85088\ttrain-rmse:1.9787\n",
      "[17082]\teval-rmse:3.85045\ttrain-rmse:1.9787\n",
      "[17083]\teval-rmse:3.84898\ttrain-rmse:1.97871\n",
      "[17084]\teval-rmse:3.84879\ttrain-rmse:1.97871\n",
      "[17085]\teval-rmse:3.84747\ttrain-rmse:1.97871\n",
      "[17086]\teval-rmse:3.84728\ttrain-rmse:1.97871\n",
      "[17087]\teval-rmse:3.84759\ttrain-rmse:1.97871\n",
      "[17088]\teval-rmse:3.84622\ttrain-rmse:1.97872\n",
      "[17089]\teval-rmse:3.8443\ttrain-rmse:1.97873\n",
      "[17090]\teval-rmse:3.84573\ttrain-rmse:1.97873\n",
      "[17091]\teval-rmse:3.84748\ttrain-rmse:1.97871\n",
      "[17092]\teval-rmse:3.84828\ttrain-rmse:1.97871\n",
      "[17093]\teval-rmse:3.84651\ttrain-rmse:1.97871\n",
      "[17094]\teval-rmse:3.84608\ttrain-rmse:1.97871\n",
      "[17095]\teval-rmse:3.84665\ttrain-rmse:1.97871\n",
      "[17096]\teval-rmse:3.84786\ttrain-rmse:1.9787\n",
      "[17097]\teval-rmse:3.84922\ttrain-rmse:1.9787\n",
      "[17098]\teval-rmse:3.84977\ttrain-rmse:1.9787\n",
      "[17099]\teval-rmse:3.84947\ttrain-rmse:1.9787\n",
      "[17100]\teval-rmse:3.84963\ttrain-rmse:1.9787\n",
      "[17101]\teval-rmse:3.85049\ttrain-rmse:1.97871\n",
      "[17102]\teval-rmse:3.84939\ttrain-rmse:1.97871\n",
      "[17103]\teval-rmse:3.84992\ttrain-rmse:1.97871\n",
      "[17104]\teval-rmse:3.84951\ttrain-rmse:1.97871\n",
      "[17105]\teval-rmse:3.8482\ttrain-rmse:1.97871\n",
      "[17106]\teval-rmse:3.84603\ttrain-rmse:1.97871\n",
      "[17107]\teval-rmse:3.84664\ttrain-rmse:1.97871\n",
      "[17108]\teval-rmse:3.84842\ttrain-rmse:1.97871\n",
      "[17109]\teval-rmse:3.84916\ttrain-rmse:1.97872\n",
      "[17110]\teval-rmse:3.85035\ttrain-rmse:1.97873\n",
      "[17111]\teval-rmse:3.85071\ttrain-rmse:1.97873\n",
      "[17112]\teval-rmse:3.85004\ttrain-rmse:1.97874\n",
      "[17113]\teval-rmse:3.8487\ttrain-rmse:1.97874\n",
      "[17114]\teval-rmse:3.84947\ttrain-rmse:1.97875\n",
      "[17115]\teval-rmse:3.84928\ttrain-rmse:1.97875\n",
      "[17116]\teval-rmse:3.8499\ttrain-rmse:1.97876\n",
      "[17117]\teval-rmse:3.85124\ttrain-rmse:1.97878\n",
      "[17118]\teval-rmse:3.84922\ttrain-rmse:1.97875\n",
      "[17119]\teval-rmse:3.85019\ttrain-rmse:1.97877\n",
      "[17120]\teval-rmse:3.85161\ttrain-rmse:1.97879\n",
      "[17121]\teval-rmse:3.85121\ttrain-rmse:1.97878\n",
      "[17122]\teval-rmse:3.84937\ttrain-rmse:1.97876\n",
      "[17123]\teval-rmse:3.84858\ttrain-rmse:1.97876\n",
      "[17124]\teval-rmse:3.8495\ttrain-rmse:1.97876\n",
      "[17125]\teval-rmse:3.84794\ttrain-rmse:1.97875\n",
      "[17126]\teval-rmse:3.84617\ttrain-rmse:1.97875\n",
      "[17127]\teval-rmse:3.84423\ttrain-rmse:1.97875\n",
      "[17128]\teval-rmse:3.84384\ttrain-rmse:1.97875\n",
      "[17129]\teval-rmse:3.84356\ttrain-rmse:1.97876\n",
      "[17130]\teval-rmse:3.84383\ttrain-rmse:1.97875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17131]\teval-rmse:3.84481\ttrain-rmse:1.97874\n",
      "[17132]\teval-rmse:3.84521\ttrain-rmse:1.97874\n",
      "[17133]\teval-rmse:3.84369\ttrain-rmse:1.97876\n",
      "[17134]\teval-rmse:3.84387\ttrain-rmse:1.97876\n",
      "[17135]\teval-rmse:3.84412\ttrain-rmse:1.97876\n",
      "[17136]\teval-rmse:3.84218\ttrain-rmse:1.97877\n",
      "[17137]\teval-rmse:3.8438\ttrain-rmse:1.97874\n",
      "[17138]\teval-rmse:3.84338\ttrain-rmse:1.97875\n",
      "[17139]\teval-rmse:3.84515\ttrain-rmse:1.97869\n",
      "[17140]\teval-rmse:3.84551\ttrain-rmse:1.97869\n",
      "[17141]\teval-rmse:3.84397\ttrain-rmse:1.97871\n",
      "[17142]\teval-rmse:3.84222\ttrain-rmse:1.97872\n",
      "[17143]\teval-rmse:3.84147\ttrain-rmse:1.97873\n",
      "[17144]\teval-rmse:3.84214\ttrain-rmse:1.97872\n",
      "[17145]\teval-rmse:3.84071\ttrain-rmse:1.97877\n",
      "[17146]\teval-rmse:3.84031\ttrain-rmse:1.97878\n",
      "[17147]\teval-rmse:3.84123\ttrain-rmse:1.97876\n",
      "[17148]\teval-rmse:3.84152\ttrain-rmse:1.97876\n",
      "[17149]\teval-rmse:3.8418\ttrain-rmse:1.97876\n",
      "[17150]\teval-rmse:3.84306\ttrain-rmse:1.97874\n",
      "[17151]\teval-rmse:3.84329\ttrain-rmse:1.97874\n",
      "[17152]\teval-rmse:3.84377\ttrain-rmse:1.97874\n",
      "[17153]\teval-rmse:3.84441\ttrain-rmse:1.97873\n",
      "[17154]\teval-rmse:3.8461\ttrain-rmse:1.97872\n",
      "[17155]\teval-rmse:3.84787\ttrain-rmse:1.97873\n",
      "[17156]\teval-rmse:3.84818\ttrain-rmse:1.97873\n",
      "[17157]\teval-rmse:3.84649\ttrain-rmse:1.97873\n",
      "[17158]\teval-rmse:3.84542\ttrain-rmse:1.97873\n",
      "[17159]\teval-rmse:3.84559\ttrain-rmse:1.97873\n",
      "[17160]\teval-rmse:3.84712\ttrain-rmse:1.97874\n",
      "[17161]\teval-rmse:3.84663\ttrain-rmse:1.97874\n",
      "[17162]\teval-rmse:3.84555\ttrain-rmse:1.97874\n",
      "[17163]\teval-rmse:3.84645\ttrain-rmse:1.97875\n",
      "[17164]\teval-rmse:3.84798\ttrain-rmse:1.97877\n",
      "[17165]\teval-rmse:3.8478\ttrain-rmse:1.97877\n",
      "[17166]\teval-rmse:3.84868\ttrain-rmse:1.97877\n",
      "[17167]\teval-rmse:3.8476\ttrain-rmse:1.97877\n",
      "[17168]\teval-rmse:3.84716\ttrain-rmse:1.97863\n",
      "[17169]\teval-rmse:3.84641\ttrain-rmse:1.97862\n",
      "[17170]\teval-rmse:3.84584\ttrain-rmse:1.97862\n",
      "[17171]\teval-rmse:3.84429\ttrain-rmse:1.97862\n",
      "[17172]\teval-rmse:3.84387\ttrain-rmse:1.97862\n",
      "[17173]\teval-rmse:3.84531\ttrain-rmse:1.97863\n",
      "[17174]\teval-rmse:3.84374\ttrain-rmse:1.97863\n",
      "[17175]\teval-rmse:3.84221\ttrain-rmse:1.97863\n",
      "[17176]\teval-rmse:3.84389\ttrain-rmse:1.97863\n",
      "[17177]\teval-rmse:3.8427\ttrain-rmse:1.97866\n",
      "[17178]\teval-rmse:3.84232\ttrain-rmse:1.97867\n",
      "[17179]\teval-rmse:3.84061\ttrain-rmse:1.97867\n",
      "[17180]\teval-rmse:3.8391\ttrain-rmse:1.9787\n",
      "[17181]\teval-rmse:3.83737\ttrain-rmse:1.97873\n",
      "[17182]\teval-rmse:3.83824\ttrain-rmse:1.97871\n",
      "[17183]\teval-rmse:3.83687\ttrain-rmse:1.97874\n",
      "[17184]\teval-rmse:3.83709\ttrain-rmse:1.97874\n",
      "[17185]\teval-rmse:3.83696\ttrain-rmse:1.97874\n",
      "[17186]\teval-rmse:3.83715\ttrain-rmse:1.97874\n",
      "[17187]\teval-rmse:3.83645\ttrain-rmse:1.97875\n",
      "[17188]\teval-rmse:3.83607\ttrain-rmse:1.97876\n",
      "[17189]\teval-rmse:3.83748\ttrain-rmse:1.97874\n",
      "[17190]\teval-rmse:3.83792\ttrain-rmse:1.97874\n",
      "[17191]\teval-rmse:3.8393\ttrain-rmse:1.97872\n",
      "[17192]\teval-rmse:3.84062\ttrain-rmse:1.97873\n",
      "[17193]\teval-rmse:3.83865\ttrain-rmse:1.97872\n",
      "[17194]\teval-rmse:3.83728\ttrain-rmse:1.97875\n",
      "[17195]\teval-rmse:3.83568\ttrain-rmse:1.97877\n",
      "[17196]\teval-rmse:3.83744\ttrain-rmse:1.97874\n",
      "[17197]\teval-rmse:3.83842\ttrain-rmse:1.97871\n",
      "[17198]\teval-rmse:3.83827\ttrain-rmse:1.97872\n",
      "[17199]\teval-rmse:3.83754\ttrain-rmse:1.97873\n",
      "[17200]\teval-rmse:3.83638\ttrain-rmse:1.97875\n",
      "[17201]\teval-rmse:3.83682\ttrain-rmse:1.97874\n",
      "[17202]\teval-rmse:3.83868\ttrain-rmse:1.97871\n",
      "[17203]\teval-rmse:3.83673\ttrain-rmse:1.97873\n",
      "[17204]\teval-rmse:3.83823\ttrain-rmse:1.97871\n",
      "[17205]\teval-rmse:3.8386\ttrain-rmse:1.97871\n",
      "[17206]\teval-rmse:3.83966\ttrain-rmse:1.9787\n",
      "[17207]\teval-rmse:3.83993\ttrain-rmse:1.9787\n",
      "[17208]\teval-rmse:3.83929\ttrain-rmse:1.97871\n",
      "[17209]\teval-rmse:3.83903\ttrain-rmse:1.97871\n",
      "[17210]\teval-rmse:3.83941\ttrain-rmse:1.97871\n",
      "[17211]\teval-rmse:3.83894\ttrain-rmse:1.97872\n",
      "[17212]\teval-rmse:3.84051\ttrain-rmse:1.97871\n",
      "[17213]\teval-rmse:3.84119\ttrain-rmse:1.9787\n",
      "[17214]\teval-rmse:3.8408\ttrain-rmse:1.97871\n",
      "[17215]\teval-rmse:3.84212\ttrain-rmse:1.97871\n",
      "[17216]\teval-rmse:3.84411\ttrain-rmse:1.97869\n",
      "[17217]\teval-rmse:3.84278\ttrain-rmse:1.97868\n",
      "[17218]\teval-rmse:3.84239\ttrain-rmse:1.97868\n",
      "[17219]\teval-rmse:3.84063\ttrain-rmse:1.97868\n",
      "[17220]\teval-rmse:3.8421\ttrain-rmse:1.97869\n",
      "[17221]\teval-rmse:3.84073\ttrain-rmse:1.97869\n",
      "[17222]\teval-rmse:3.84175\ttrain-rmse:1.97869\n",
      "[17223]\teval-rmse:3.83961\ttrain-rmse:1.97869\n",
      "[17224]\teval-rmse:3.83758\ttrain-rmse:1.97871\n",
      "[17225]\teval-rmse:3.83672\ttrain-rmse:1.97874\n",
      "[17226]\teval-rmse:3.83541\ttrain-rmse:1.97876\n",
      "[17227]\teval-rmse:3.83377\ttrain-rmse:1.97882\n",
      "[17228]\teval-rmse:3.83411\ttrain-rmse:1.97881\n",
      "[17229]\teval-rmse:3.83364\ttrain-rmse:1.97883\n",
      "[17230]\teval-rmse:3.83527\ttrain-rmse:1.97878\n",
      "[17231]\teval-rmse:3.83598\ttrain-rmse:1.97877\n",
      "[17232]\teval-rmse:3.83621\ttrain-rmse:1.97876\n",
      "[17233]\teval-rmse:3.83519\ttrain-rmse:1.97879\n",
      "[17234]\teval-rmse:3.83574\ttrain-rmse:1.97877\n",
      "[17235]\teval-rmse:3.83774\ttrain-rmse:1.97873\n",
      "[17236]\teval-rmse:3.83633\ttrain-rmse:1.97876\n",
      "[17237]\teval-rmse:3.83531\ttrain-rmse:1.97878\n",
      "[17238]\teval-rmse:3.8368\ttrain-rmse:1.97876\n",
      "[17239]\teval-rmse:3.83656\ttrain-rmse:1.97876\n",
      "[17240]\teval-rmse:3.83748\ttrain-rmse:1.97874\n",
      "[17241]\teval-rmse:3.83852\ttrain-rmse:1.97874\n",
      "[17242]\teval-rmse:3.83724\ttrain-rmse:1.97876\n",
      "[17243]\teval-rmse:3.83801\ttrain-rmse:1.97875\n",
      "[17244]\teval-rmse:3.8382\ttrain-rmse:1.97874\n",
      "[17245]\teval-rmse:3.83923\ttrain-rmse:1.97874\n",
      "[17246]\teval-rmse:3.83973\ttrain-rmse:1.97873\n",
      "[17247]\teval-rmse:3.84071\ttrain-rmse:1.97871\n",
      "[17248]\teval-rmse:3.84271\ttrain-rmse:1.9787\n",
      "[17249]\teval-rmse:3.84369\ttrain-rmse:1.97869\n",
      "[17250]\teval-rmse:3.84216\ttrain-rmse:1.97869\n",
      "[17251]\teval-rmse:3.84325\ttrain-rmse:1.97869\n",
      "[17252]\teval-rmse:3.843\ttrain-rmse:1.97869\n",
      "[17253]\teval-rmse:3.84169\ttrain-rmse:1.97869\n",
      "[17254]\teval-rmse:3.8426\ttrain-rmse:1.97869\n",
      "[17255]\teval-rmse:3.84244\ttrain-rmse:1.97869\n",
      "[17256]\teval-rmse:3.84246\ttrain-rmse:1.97869\n",
      "[17257]\teval-rmse:3.84242\ttrain-rmse:1.97869\n",
      "[17258]\teval-rmse:3.84177\ttrain-rmse:1.9787\n",
      "[17259]\teval-rmse:3.84006\ttrain-rmse:1.9787\n",
      "[17260]\teval-rmse:3.84136\ttrain-rmse:1.97869\n",
      "[17261]\teval-rmse:3.84245\ttrain-rmse:1.97869\n",
      "[17262]\teval-rmse:3.84219\ttrain-rmse:1.97869\n",
      "[17263]\teval-rmse:3.8427\ttrain-rmse:1.97869\n",
      "[17264]\teval-rmse:3.84348\ttrain-rmse:1.9787\n",
      "[17265]\teval-rmse:3.84309\ttrain-rmse:1.9787\n",
      "[17266]\teval-rmse:3.84309\ttrain-rmse:1.9787\n",
      "[17267]\teval-rmse:3.84234\ttrain-rmse:1.9787\n",
      "[17268]\teval-rmse:3.84218\ttrain-rmse:1.9787\n",
      "[17269]\teval-rmse:3.84245\ttrain-rmse:1.9787\n",
      "[17270]\teval-rmse:3.84308\ttrain-rmse:1.9787\n",
      "[17271]\teval-rmse:3.84395\ttrain-rmse:1.9787\n",
      "[17272]\teval-rmse:3.84457\ttrain-rmse:1.9787\n",
      "[17273]\teval-rmse:3.84584\ttrain-rmse:1.97871\n",
      "[17274]\teval-rmse:3.84634\ttrain-rmse:1.97871\n",
      "[17275]\teval-rmse:3.84832\ttrain-rmse:1.97871\n",
      "[17276]\teval-rmse:3.84993\ttrain-rmse:1.97868\n",
      "[17277]\teval-rmse:3.85041\ttrain-rmse:1.97869\n",
      "[17278]\teval-rmse:3.85\ttrain-rmse:1.97869\n",
      "[17279]\teval-rmse:3.85129\ttrain-rmse:1.97871\n",
      "[17280]\teval-rmse:3.84959\ttrain-rmse:1.97868\n",
      "[17281]\teval-rmse:3.84789\ttrain-rmse:1.97865\n",
      "[17282]\teval-rmse:3.84851\ttrain-rmse:1.97867\n",
      "[17283]\teval-rmse:3.84856\ttrain-rmse:1.97867\n",
      "[17284]\teval-rmse:3.84829\ttrain-rmse:1.97866\n",
      "[17285]\teval-rmse:3.84801\ttrain-rmse:1.97866\n",
      "[17286]\teval-rmse:3.84887\ttrain-rmse:1.97867\n",
      "[17287]\teval-rmse:3.85004\ttrain-rmse:1.9787\n",
      "[17288]\teval-rmse:3.85074\ttrain-rmse:1.97871\n",
      "[17289]\teval-rmse:3.85005\ttrain-rmse:1.97872\n",
      "[17290]\teval-rmse:3.84789\ttrain-rmse:1.97868\n",
      "[17291]\teval-rmse:3.84938\ttrain-rmse:1.9787\n",
      "[17292]\teval-rmse:3.85049\ttrain-rmse:1.97873\n",
      "[17293]\teval-rmse:3.84938\ttrain-rmse:1.97872\n",
      "[17294]\teval-rmse:3.85041\ttrain-rmse:1.97875\n",
      "[17295]\teval-rmse:3.84897\ttrain-rmse:1.97874\n",
      "[17296]\teval-rmse:3.84749\ttrain-rmse:1.97873\n",
      "[17297]\teval-rmse:3.84683\ttrain-rmse:1.97873\n",
      "[17298]\teval-rmse:3.84464\ttrain-rmse:1.9787\n",
      "[17299]\teval-rmse:3.845\ttrain-rmse:1.97871\n",
      "[17300]\teval-rmse:3.84461\ttrain-rmse:1.97857\n",
      "[17301]\teval-rmse:3.84355\ttrain-rmse:1.97858\n",
      "[17302]\teval-rmse:3.8433\ttrain-rmse:1.97857\n",
      "[17303]\teval-rmse:3.84372\ttrain-rmse:1.97858\n",
      "[17304]\teval-rmse:3.84221\ttrain-rmse:1.97857\n",
      "[17305]\teval-rmse:3.84093\ttrain-rmse:1.97861\n",
      "[17306]\teval-rmse:3.83936\ttrain-rmse:1.97862\n",
      "[17307]\teval-rmse:3.83779\ttrain-rmse:1.97863\n",
      "[17308]\teval-rmse:3.83765\ttrain-rmse:1.97863\n",
      "[17309]\teval-rmse:3.836\ttrain-rmse:1.97866\n",
      "[17310]\teval-rmse:3.83425\ttrain-rmse:1.9787\n",
      "[17311]\teval-rmse:3.8345\ttrain-rmse:1.97869\n",
      "[17312]\teval-rmse:3.83539\ttrain-rmse:1.97866\n",
      "[17313]\teval-rmse:3.83453\ttrain-rmse:1.97868\n",
      "[17314]\teval-rmse:3.8344\ttrain-rmse:1.97869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17315]\teval-rmse:3.83484\ttrain-rmse:1.97868\n",
      "[17316]\teval-rmse:3.83437\ttrain-rmse:1.97869\n",
      "[17317]\teval-rmse:3.8327\ttrain-rmse:1.97873\n",
      "[17318]\teval-rmse:3.8322\ttrain-rmse:1.97876\n",
      "[17319]\teval-rmse:3.83087\ttrain-rmse:1.9788\n",
      "[17320]\teval-rmse:3.83216\ttrain-rmse:1.97875\n",
      "[17321]\teval-rmse:3.83054\ttrain-rmse:1.97881\n",
      "[17322]\teval-rmse:3.83191\ttrain-rmse:1.97876\n",
      "[17323]\teval-rmse:3.83235\ttrain-rmse:1.97875\n",
      "[17324]\teval-rmse:3.83088\ttrain-rmse:1.97879\n",
      "[17325]\teval-rmse:3.83189\ttrain-rmse:1.97876\n",
      "[17326]\teval-rmse:3.83241\ttrain-rmse:1.97874\n",
      "[17327]\teval-rmse:3.83184\ttrain-rmse:1.97876\n",
      "[17328]\teval-rmse:3.83061\ttrain-rmse:1.97881\n",
      "[17329]\teval-rmse:3.83099\ttrain-rmse:1.97879\n",
      "[17330]\teval-rmse:3.83033\ttrain-rmse:1.97882\n",
      "[17331]\teval-rmse:3.83028\ttrain-rmse:1.97882\n",
      "[17332]\teval-rmse:3.83207\ttrain-rmse:1.97876\n",
      "[17333]\teval-rmse:3.83171\ttrain-rmse:1.97877\n",
      "[17334]\teval-rmse:3.83093\ttrain-rmse:1.9788\n",
      "[17335]\teval-rmse:3.83062\ttrain-rmse:1.97865\n",
      "[17336]\teval-rmse:3.83019\ttrain-rmse:1.97867\n",
      "[17337]\teval-rmse:3.82982\ttrain-rmse:1.97868\n",
      "[17338]\teval-rmse:3.83183\ttrain-rmse:1.97862\n",
      "[17339]\teval-rmse:3.83123\ttrain-rmse:1.97864\n",
      "[17340]\teval-rmse:3.83011\ttrain-rmse:1.9787\n",
      "[17341]\teval-rmse:3.83174\ttrain-rmse:1.97861\n",
      "[17342]\teval-rmse:3.83153\ttrain-rmse:1.97862\n",
      "[17343]\teval-rmse:3.83116\ttrain-rmse:1.97848\n",
      "[17344]\teval-rmse:3.8308\ttrain-rmse:1.97835\n",
      "[17345]\teval-rmse:3.8313\ttrain-rmse:1.97833\n",
      "[17346]\teval-rmse:3.83282\ttrain-rmse:1.97827\n",
      "[17347]\teval-rmse:3.83415\ttrain-rmse:1.97823\n",
      "[17348]\teval-rmse:3.83315\ttrain-rmse:1.97826\n",
      "[17349]\teval-rmse:3.83466\ttrain-rmse:1.97822\n",
      "[17350]\teval-rmse:3.83452\ttrain-rmse:1.97823\n",
      "[17351]\teval-rmse:3.83274\ttrain-rmse:1.97827\n",
      "[17352]\teval-rmse:3.83202\ttrain-rmse:1.97829\n",
      "[17353]\teval-rmse:3.83403\ttrain-rmse:1.97824\n",
      "[17354]\teval-rmse:3.83395\ttrain-rmse:1.97825\n",
      "[17355]\teval-rmse:3.83177\ttrain-rmse:1.97829\n",
      "[17356]\teval-rmse:3.83173\ttrain-rmse:1.97829\n",
      "[17357]\teval-rmse:3.83075\ttrain-rmse:1.97833\n",
      "[17358]\teval-rmse:3.83175\ttrain-rmse:1.9783\n",
      "[17359]\teval-rmse:3.83217\ttrain-rmse:1.97829\n",
      "[17360]\teval-rmse:3.83369\ttrain-rmse:1.97823\n",
      "[17361]\teval-rmse:3.83476\ttrain-rmse:1.97821\n",
      "[17362]\teval-rmse:3.83343\ttrain-rmse:1.97824\n",
      "[17363]\teval-rmse:3.83209\ttrain-rmse:1.97828\n",
      "[17364]\teval-rmse:3.83298\ttrain-rmse:1.97825\n",
      "[17365]\teval-rmse:3.83152\ttrain-rmse:1.97829\n",
      "[17366]\teval-rmse:3.83102\ttrain-rmse:1.97831\n",
      "[17367]\teval-rmse:3.83202\ttrain-rmse:1.97827\n",
      "[17368]\teval-rmse:3.8333\ttrain-rmse:1.97823\n",
      "[17369]\teval-rmse:3.83464\ttrain-rmse:1.9782\n",
      "[17370]\teval-rmse:3.83642\ttrain-rmse:1.97816\n",
      "[17371]\teval-rmse:3.83794\ttrain-rmse:1.97813\n",
      "[17372]\teval-rmse:3.83755\ttrain-rmse:1.97813\n",
      "[17373]\teval-rmse:3.83941\ttrain-rmse:1.97806\n",
      "[17374]\teval-rmse:3.83758\ttrain-rmse:1.97808\n",
      "[17375]\teval-rmse:3.83867\ttrain-rmse:1.97807\n",
      "[17376]\teval-rmse:3.83917\ttrain-rmse:1.97806\n",
      "[17377]\teval-rmse:3.83785\ttrain-rmse:1.97808\n",
      "[17378]\teval-rmse:3.83936\ttrain-rmse:1.97805\n",
      "[17379]\teval-rmse:3.83896\ttrain-rmse:1.97791\n",
      "[17380]\teval-rmse:3.83974\ttrain-rmse:1.97791\n",
      "[17381]\teval-rmse:3.8382\ttrain-rmse:1.97792\n",
      "[17382]\teval-rmse:3.83739\ttrain-rmse:1.97794\n",
      "[17383]\teval-rmse:3.83588\ttrain-rmse:1.97796\n",
      "[17384]\teval-rmse:3.83788\ttrain-rmse:1.97792\n",
      "[17385]\teval-rmse:3.83852\ttrain-rmse:1.97791\n",
      "[17386]\teval-rmse:3.83813\ttrain-rmse:1.97778\n",
      "[17387]\teval-rmse:3.83928\ttrain-rmse:1.97777\n",
      "[17388]\teval-rmse:3.84128\ttrain-rmse:1.97775\n",
      "[17389]\teval-rmse:3.83937\ttrain-rmse:1.97777\n",
      "[17390]\teval-rmse:3.83874\ttrain-rmse:1.97779\n",
      "[17391]\teval-rmse:3.83737\ttrain-rmse:1.97781\n",
      "[17392]\teval-rmse:3.83525\ttrain-rmse:1.97785\n",
      "[17393]\teval-rmse:3.83576\ttrain-rmse:1.97784\n",
      "[17394]\teval-rmse:3.83696\ttrain-rmse:1.97781\n",
      "[17395]\teval-rmse:3.83897\ttrain-rmse:1.97778\n",
      "[17396]\teval-rmse:3.84026\ttrain-rmse:1.97776\n",
      "[17397]\teval-rmse:3.83908\ttrain-rmse:1.9778\n",
      "[17398]\teval-rmse:3.84011\ttrain-rmse:1.97778\n",
      "[17399]\teval-rmse:3.83985\ttrain-rmse:1.97779\n",
      "[17400]\teval-rmse:3.84166\ttrain-rmse:1.97776\n",
      "[17401]\teval-rmse:3.84149\ttrain-rmse:1.97777\n",
      "[17402]\teval-rmse:3.8398\ttrain-rmse:1.97778\n",
      "[17403]\teval-rmse:3.83893\ttrain-rmse:1.97779\n",
      "[17404]\teval-rmse:3.84093\ttrain-rmse:1.97777\n",
      "[17405]\teval-rmse:3.84141\ttrain-rmse:1.97777\n",
      "[17406]\teval-rmse:3.84077\ttrain-rmse:1.97779\n",
      "[17407]\teval-rmse:3.83943\ttrain-rmse:1.97781\n",
      "[17408]\teval-rmse:3.83993\ttrain-rmse:1.9778\n",
      "[17409]\teval-rmse:3.84009\ttrain-rmse:1.97779\n",
      "[17410]\teval-rmse:3.84015\ttrain-rmse:1.97779\n",
      "[17411]\teval-rmse:3.83898\ttrain-rmse:1.97782\n",
      "[17412]\teval-rmse:3.83942\ttrain-rmse:1.97781\n",
      "[17413]\teval-rmse:3.83748\ttrain-rmse:1.97784\n",
      "[17414]\teval-rmse:3.83608\ttrain-rmse:1.9779\n",
      "[17415]\teval-rmse:3.83674\ttrain-rmse:1.97789\n",
      "[17416]\teval-rmse:3.8372\ttrain-rmse:1.97788\n",
      "[17417]\teval-rmse:3.83565\ttrain-rmse:1.97792\n",
      "[17418]\teval-rmse:3.83542\ttrain-rmse:1.97792\n",
      "[17419]\teval-rmse:3.83571\ttrain-rmse:1.97792\n",
      "[17420]\teval-rmse:3.8342\ttrain-rmse:1.97796\n",
      "[17421]\teval-rmse:3.83565\ttrain-rmse:1.97792\n",
      "[17422]\teval-rmse:3.8345\ttrain-rmse:1.97796\n",
      "[17423]\teval-rmse:3.83569\ttrain-rmse:1.97792\n",
      "[17424]\teval-rmse:3.83555\ttrain-rmse:1.97793\n",
      "[17425]\teval-rmse:3.83374\ttrain-rmse:1.97797\n",
      "[17426]\teval-rmse:3.83351\ttrain-rmse:1.97797\n",
      "[17427]\teval-rmse:3.83503\ttrain-rmse:1.97792\n",
      "[17428]\teval-rmse:3.83365\ttrain-rmse:1.97799\n",
      "[17429]\teval-rmse:3.83486\ttrain-rmse:1.97796\n",
      "[17430]\teval-rmse:3.8362\ttrain-rmse:1.97792\n",
      "[17431]\teval-rmse:3.83759\ttrain-rmse:1.9779\n",
      "[17432]\teval-rmse:3.83722\ttrain-rmse:1.97791\n",
      "[17433]\teval-rmse:3.83638\ttrain-rmse:1.97792\n",
      "[17434]\teval-rmse:3.83512\ttrain-rmse:1.97796\n",
      "[17435]\teval-rmse:3.83409\ttrain-rmse:1.97798\n",
      "[17436]\teval-rmse:3.8327\ttrain-rmse:1.97805\n",
      "[17437]\teval-rmse:3.83221\ttrain-rmse:1.97807\n",
      "[17438]\teval-rmse:3.83066\ttrain-rmse:1.97812\n",
      "[17439]\teval-rmse:3.83029\ttrain-rmse:1.97813\n",
      "[17440]\teval-rmse:3.82945\ttrain-rmse:1.97817\n",
      "[17441]\teval-rmse:3.82976\ttrain-rmse:1.97815\n",
      "[17442]\teval-rmse:3.82941\ttrain-rmse:1.97802\n",
      "[17443]\teval-rmse:3.8292\ttrain-rmse:1.97803\n",
      "[17444]\teval-rmse:3.82995\ttrain-rmse:1.97799\n",
      "[17445]\teval-rmse:3.83152\ttrain-rmse:1.97793\n",
      "[17446]\teval-rmse:3.83175\ttrain-rmse:1.97793\n",
      "[17447]\teval-rmse:3.83224\ttrain-rmse:1.97791\n",
      "[17448]\teval-rmse:3.83174\ttrain-rmse:1.97793\n",
      "[17449]\teval-rmse:3.83356\ttrain-rmse:1.97788\n",
      "[17450]\teval-rmse:3.83294\ttrain-rmse:1.9779\n",
      "[17451]\teval-rmse:3.83457\ttrain-rmse:1.97782\n",
      "[17452]\teval-rmse:3.8361\ttrain-rmse:1.97777\n",
      "[17453]\teval-rmse:3.83774\ttrain-rmse:1.97776\n",
      "[17454]\teval-rmse:3.83735\ttrain-rmse:1.97776\n",
      "[17455]\teval-rmse:3.83539\ttrain-rmse:1.9778\n",
      "[17456]\teval-rmse:3.83514\ttrain-rmse:1.9778\n",
      "[17457]\teval-rmse:3.8348\ttrain-rmse:1.97781\n",
      "[17458]\teval-rmse:3.83622\ttrain-rmse:1.97778\n",
      "[17459]\teval-rmse:3.83746\ttrain-rmse:1.97776\n",
      "[17460]\teval-rmse:3.83642\ttrain-rmse:1.97778\n",
      "[17461]\teval-rmse:3.8362\ttrain-rmse:1.97778\n",
      "[17462]\teval-rmse:3.83442\ttrain-rmse:1.97781\n",
      "[17463]\teval-rmse:3.83341\ttrain-rmse:1.97784\n",
      "[17464]\teval-rmse:3.8328\ttrain-rmse:1.97785\n",
      "[17465]\teval-rmse:3.83429\ttrain-rmse:1.97782\n",
      "[17466]\teval-rmse:3.83584\ttrain-rmse:1.97779\n",
      "[17467]\teval-rmse:3.83678\ttrain-rmse:1.97778\n",
      "[17468]\teval-rmse:3.83744\ttrain-rmse:1.97777\n",
      "[17469]\teval-rmse:3.83682\ttrain-rmse:1.97779\n",
      "[17470]\teval-rmse:3.83825\ttrain-rmse:1.97778\n",
      "[17471]\teval-rmse:3.83987\ttrain-rmse:1.97778\n",
      "[17472]\teval-rmse:3.84163\ttrain-rmse:1.97772\n",
      "[17473]\teval-rmse:3.83958\ttrain-rmse:1.97772\n",
      "[17474]\teval-rmse:3.83785\ttrain-rmse:1.97773\n",
      "[17475]\teval-rmse:3.839\ttrain-rmse:1.97772\n",
      "[17476]\teval-rmse:3.83708\ttrain-rmse:1.97774\n",
      "[17477]\teval-rmse:3.83637\ttrain-rmse:1.97775\n",
      "[17478]\teval-rmse:3.83693\ttrain-rmse:1.97774\n",
      "[17479]\teval-rmse:3.83544\ttrain-rmse:1.97777\n",
      "[17480]\teval-rmse:3.836\ttrain-rmse:1.97776\n",
      "[17481]\teval-rmse:3.83647\ttrain-rmse:1.97775\n",
      "[17482]\teval-rmse:3.83598\ttrain-rmse:1.97776\n",
      "[17483]\teval-rmse:3.8355\ttrain-rmse:1.97777\n",
      "[17484]\teval-rmse:3.83594\ttrain-rmse:1.97777\n",
      "[17485]\teval-rmse:3.83511\ttrain-rmse:1.97778\n",
      "[17486]\teval-rmse:3.83673\ttrain-rmse:1.97771\n",
      "[17487]\teval-rmse:3.83495\ttrain-rmse:1.97773\n",
      "[17488]\teval-rmse:3.83672\ttrain-rmse:1.97765\n",
      "[17489]\teval-rmse:3.83693\ttrain-rmse:1.97765\n",
      "[17490]\teval-rmse:3.83868\ttrain-rmse:1.97761\n",
      "[17491]\teval-rmse:3.84033\ttrain-rmse:1.97759\n",
      "[17492]\teval-rmse:3.84202\ttrain-rmse:1.97759\n",
      "[17493]\teval-rmse:3.84222\ttrain-rmse:1.97759\n",
      "[17494]\teval-rmse:3.84195\ttrain-rmse:1.97759\n",
      "[17495]\teval-rmse:3.84314\ttrain-rmse:1.97759\n",
      "[17496]\teval-rmse:3.8438\ttrain-rmse:1.97759\n",
      "[17497]\teval-rmse:3.84457\ttrain-rmse:1.97759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17498]\teval-rmse:3.8461\ttrain-rmse:1.97761\n",
      "[17499]\teval-rmse:3.84807\ttrain-rmse:1.97761\n",
      "[17500]\teval-rmse:3.84844\ttrain-rmse:1.97761\n",
      "[17501]\teval-rmse:3.84996\ttrain-rmse:1.97764\n",
      "[17502]\teval-rmse:3.84903\ttrain-rmse:1.97764\n",
      "[17503]\teval-rmse:3.84926\ttrain-rmse:1.97764\n",
      "[17504]\teval-rmse:3.8511\ttrain-rmse:1.97761\n",
      "[17505]\teval-rmse:3.85\ttrain-rmse:1.97761\n",
      "[17506]\teval-rmse:3.84877\ttrain-rmse:1.97762\n",
      "[17507]\teval-rmse:3.84687\ttrain-rmse:1.97759\n",
      "[17508]\teval-rmse:3.84661\ttrain-rmse:1.97759\n",
      "[17509]\teval-rmse:3.84677\ttrain-rmse:1.97759\n",
      "[17510]\teval-rmse:3.84675\ttrain-rmse:1.97759\n",
      "[17511]\teval-rmse:3.84633\ttrain-rmse:1.97759\n",
      "[17512]\teval-rmse:3.84592\ttrain-rmse:1.97759\n",
      "[17513]\teval-rmse:3.84629\ttrain-rmse:1.97759\n",
      "[17514]\teval-rmse:3.84714\ttrain-rmse:1.9776\n",
      "[17515]\teval-rmse:3.84574\ttrain-rmse:1.97759\n",
      "[17516]\teval-rmse:3.8462\ttrain-rmse:1.97759\n",
      "[17517]\teval-rmse:3.8445\ttrain-rmse:1.97758\n",
      "[17518]\teval-rmse:3.84384\ttrain-rmse:1.97759\n",
      "[17519]\teval-rmse:3.84332\ttrain-rmse:1.97759\n",
      "[17520]\teval-rmse:3.84447\ttrain-rmse:1.9776\n",
      "[17521]\teval-rmse:3.84514\ttrain-rmse:1.9776\n",
      "[17522]\teval-rmse:3.84578\ttrain-rmse:1.97761\n",
      "[17523]\teval-rmse:3.84386\ttrain-rmse:1.97758\n",
      "[17524]\teval-rmse:3.84585\ttrain-rmse:1.9776\n",
      "[17525]\teval-rmse:3.8451\ttrain-rmse:1.97759\n",
      "[17526]\teval-rmse:3.84685\ttrain-rmse:1.97761\n",
      "[17527]\teval-rmse:3.84634\ttrain-rmse:1.9776\n",
      "[17528]\teval-rmse:3.84462\ttrain-rmse:1.97759\n",
      "[17529]\teval-rmse:3.8431\ttrain-rmse:1.97758\n",
      "[17530]\teval-rmse:3.84245\ttrain-rmse:1.97758\n",
      "[17531]\teval-rmse:3.84392\ttrain-rmse:1.97758\n",
      "[17532]\teval-rmse:3.84497\ttrain-rmse:1.97759\n",
      "[17533]\teval-rmse:3.84524\ttrain-rmse:1.97759\n",
      "[17534]\teval-rmse:3.84609\ttrain-rmse:1.97759\n",
      "[17535]\teval-rmse:3.84537\ttrain-rmse:1.97758\n",
      "[17536]\teval-rmse:3.84689\ttrain-rmse:1.9776\n",
      "[17537]\teval-rmse:3.84802\ttrain-rmse:1.97762\n",
      "[17538]\teval-rmse:3.84955\ttrain-rmse:1.97765\n",
      "[17539]\teval-rmse:3.84914\ttrain-rmse:1.97753\n",
      "[17540]\teval-rmse:3.84758\ttrain-rmse:1.9775\n",
      "[17541]\teval-rmse:3.84807\ttrain-rmse:1.97751\n",
      "[17542]\teval-rmse:3.84853\ttrain-rmse:1.97752\n",
      "[17543]\teval-rmse:3.84982\ttrain-rmse:1.97754\n",
      "[17544]\teval-rmse:3.84979\ttrain-rmse:1.97754\n",
      "[17545]\teval-rmse:3.84778\ttrain-rmse:1.9775\n",
      "[17546]\teval-rmse:3.84953\ttrain-rmse:1.97753\n",
      "[17547]\teval-rmse:3.84943\ttrain-rmse:1.97753\n",
      "[17548]\teval-rmse:3.84756\ttrain-rmse:1.9775\n",
      "[17549]\teval-rmse:3.84885\ttrain-rmse:1.97752\n",
      "[17550]\teval-rmse:3.84841\ttrain-rmse:1.97751\n",
      "[17551]\teval-rmse:3.84924\ttrain-rmse:1.97752\n",
      "[17552]\teval-rmse:3.84998\ttrain-rmse:1.97753\n",
      "[17553]\teval-rmse:3.84968\ttrain-rmse:1.97752\n",
      "[17554]\teval-rmse:3.85014\ttrain-rmse:1.97754\n",
      "[17555]\teval-rmse:3.84913\ttrain-rmse:1.97751\n",
      "[17556]\teval-rmse:3.84758\ttrain-rmse:1.97749\n",
      "[17557]\teval-rmse:3.84731\ttrain-rmse:1.97748\n",
      "[17558]\teval-rmse:3.84664\ttrain-rmse:1.97748\n",
      "[17559]\teval-rmse:3.84571\ttrain-rmse:1.97747\n",
      "[17560]\teval-rmse:3.84594\ttrain-rmse:1.97747\n",
      "[17561]\teval-rmse:3.8464\ttrain-rmse:1.97747\n",
      "[17562]\teval-rmse:3.84444\ttrain-rmse:1.97746\n",
      "[17563]\teval-rmse:3.84377\ttrain-rmse:1.97746\n",
      "[17564]\teval-rmse:3.84338\ttrain-rmse:1.97746\n",
      "[17565]\teval-rmse:3.8449\ttrain-rmse:1.97745\n",
      "[17566]\teval-rmse:3.84462\ttrain-rmse:1.97745\n",
      "[17567]\teval-rmse:3.84574\ttrain-rmse:1.97745\n",
      "[17568]\teval-rmse:3.84433\ttrain-rmse:1.97744\n",
      "[17569]\teval-rmse:3.84391\ttrain-rmse:1.97745\n",
      "[17570]\teval-rmse:3.84438\ttrain-rmse:1.97745\n",
      "[17571]\teval-rmse:3.84575\ttrain-rmse:1.97744\n",
      "[17572]\teval-rmse:3.8476\ttrain-rmse:1.97741\n",
      "[17573]\teval-rmse:3.84659\ttrain-rmse:1.97739\n",
      "[17574]\teval-rmse:3.84476\ttrain-rmse:1.97738\n",
      "[17575]\teval-rmse:3.84373\ttrain-rmse:1.97738\n",
      "[17576]\teval-rmse:3.84355\ttrain-rmse:1.97738\n",
      "[17577]\teval-rmse:3.8421\ttrain-rmse:1.97742\n",
      "[17578]\teval-rmse:3.84039\ttrain-rmse:1.97744\n",
      "[17579]\teval-rmse:3.84224\ttrain-rmse:1.97738\n",
      "[17580]\teval-rmse:3.84354\ttrain-rmse:1.97738\n",
      "[17581]\teval-rmse:3.84198\ttrain-rmse:1.97739\n",
      "[17582]\teval-rmse:3.84072\ttrain-rmse:1.97741\n",
      "[17583]\teval-rmse:3.84271\ttrain-rmse:1.9774\n",
      "[17584]\teval-rmse:3.84232\ttrain-rmse:1.9774\n",
      "[17585]\teval-rmse:3.84125\ttrain-rmse:1.97741\n",
      "[17586]\teval-rmse:3.83971\ttrain-rmse:1.97744\n",
      "[17587]\teval-rmse:3.83945\ttrain-rmse:1.97744\n",
      "[17588]\teval-rmse:3.83813\ttrain-rmse:1.97747\n",
      "[17589]\teval-rmse:3.83652\ttrain-rmse:1.9775\n",
      "[17590]\teval-rmse:3.83805\ttrain-rmse:1.97747\n",
      "[17591]\teval-rmse:3.83657\ttrain-rmse:1.9775\n",
      "[17592]\teval-rmse:3.83504\ttrain-rmse:1.97755\n",
      "[17593]\teval-rmse:3.83379\ttrain-rmse:1.97761\n",
      "[17594]\teval-rmse:3.83485\ttrain-rmse:1.97757\n",
      "[17595]\teval-rmse:3.83315\ttrain-rmse:1.97764\n",
      "[17596]\teval-rmse:3.83145\ttrain-rmse:1.97769\n",
      "[17597]\teval-rmse:3.8328\ttrain-rmse:1.97763\n",
      "[17598]\teval-rmse:3.83439\ttrain-rmse:1.97757\n",
      "[17599]\teval-rmse:3.83401\ttrain-rmse:1.97744\n",
      "[17600]\teval-rmse:3.8323\ttrain-rmse:1.97751\n",
      "[17601]\teval-rmse:3.83107\ttrain-rmse:1.97757\n",
      "[17602]\teval-rmse:3.82966\ttrain-rmse:1.97764\n",
      "[17603]\teval-rmse:3.82935\ttrain-rmse:1.97751\n",
      "[17604]\teval-rmse:3.82804\ttrain-rmse:1.97756\n",
      "[17605]\teval-rmse:3.82746\ttrain-rmse:1.97758\n",
      "[17606]\teval-rmse:3.82611\ttrain-rmse:1.97767\n",
      "[17607]\teval-rmse:3.82763\ttrain-rmse:1.97759\n",
      "[17608]\teval-rmse:3.82595\ttrain-rmse:1.97769\n",
      "[17609]\teval-rmse:3.82617\ttrain-rmse:1.97767\n",
      "[17610]\teval-rmse:3.82732\ttrain-rmse:1.9776\n",
      "[17611]\teval-rmse:3.82912\ttrain-rmse:1.97753\n",
      "[17612]\teval-rmse:3.82948\ttrain-rmse:1.97751\n",
      "[17613]\teval-rmse:3.83084\ttrain-rmse:1.97745\n",
      "[17614]\teval-rmse:3.83271\ttrain-rmse:1.97738\n",
      "[17615]\teval-rmse:3.83447\ttrain-rmse:1.97733\n",
      "[17616]\teval-rmse:3.83362\ttrain-rmse:1.97735\n",
      "[17617]\teval-rmse:3.8353\ttrain-rmse:1.97731\n",
      "[17618]\teval-rmse:3.83574\ttrain-rmse:1.9773\n",
      "[17619]\teval-rmse:3.83697\ttrain-rmse:1.97727\n",
      "[17620]\teval-rmse:3.83549\ttrain-rmse:1.97729\n",
      "[17621]\teval-rmse:3.83428\ttrain-rmse:1.97733\n",
      "[17622]\teval-rmse:3.83493\ttrain-rmse:1.97731\n",
      "[17623]\teval-rmse:3.8335\ttrain-rmse:1.97736\n",
      "[17624]\teval-rmse:3.83395\ttrain-rmse:1.97735\n",
      "[17625]\teval-rmse:3.83207\ttrain-rmse:1.9774\n",
      "[17626]\teval-rmse:3.83406\ttrain-rmse:1.97735\n",
      "[17627]\teval-rmse:3.83458\ttrain-rmse:1.97733\n",
      "[17628]\teval-rmse:3.83366\ttrain-rmse:1.97736\n",
      "[17629]\teval-rmse:3.83392\ttrain-rmse:1.97735\n",
      "[17630]\teval-rmse:3.83521\ttrain-rmse:1.97732\n",
      "[17631]\teval-rmse:3.83707\ttrain-rmse:1.97724\n",
      "[17632]\teval-rmse:3.83693\ttrain-rmse:1.97724\n",
      "[17633]\teval-rmse:3.83607\ttrain-rmse:1.97726\n",
      "[17634]\teval-rmse:3.83676\ttrain-rmse:1.97724\n",
      "[17635]\teval-rmse:3.83623\ttrain-rmse:1.97725\n",
      "[17636]\teval-rmse:3.83473\ttrain-rmse:1.9773\n",
      "[17637]\teval-rmse:3.83672\ttrain-rmse:1.97726\n",
      "[17638]\teval-rmse:3.83716\ttrain-rmse:1.97724\n",
      "[17639]\teval-rmse:3.83516\ttrain-rmse:1.97732\n",
      "[17640]\teval-rmse:3.83686\ttrain-rmse:1.97728\n",
      "[17641]\teval-rmse:3.83751\ttrain-rmse:1.97726\n",
      "[17642]\teval-rmse:3.83736\ttrain-rmse:1.97727\n",
      "[17643]\teval-rmse:3.83722\ttrain-rmse:1.97727\n",
      "[17644]\teval-rmse:3.83754\ttrain-rmse:1.97726\n",
      "[17645]\teval-rmse:3.83883\ttrain-rmse:1.97723\n",
      "[17646]\teval-rmse:3.83743\ttrain-rmse:1.97725\n",
      "[17647]\teval-rmse:3.83768\ttrain-rmse:1.97725\n",
      "[17648]\teval-rmse:3.83821\ttrain-rmse:1.97724\n",
      "[17649]\teval-rmse:3.83748\ttrain-rmse:1.97725\n",
      "[17650]\teval-rmse:3.83905\ttrain-rmse:1.97723\n",
      "[17651]\teval-rmse:3.84104\ttrain-rmse:1.97721\n",
      "[17652]\teval-rmse:3.84152\ttrain-rmse:1.9772\n",
      "[17653]\teval-rmse:3.84194\ttrain-rmse:1.97719\n",
      "[17654]\teval-rmse:3.84065\ttrain-rmse:1.97723\n",
      "[17655]\teval-rmse:3.83984\ttrain-rmse:1.97725\n",
      "[17656]\teval-rmse:3.83968\ttrain-rmse:1.97725\n",
      "[17657]\teval-rmse:3.84168\ttrain-rmse:1.97723\n",
      "[17658]\teval-rmse:3.83978\ttrain-rmse:1.97727\n",
      "[17659]\teval-rmse:3.84133\ttrain-rmse:1.97725\n",
      "[17660]\teval-rmse:3.83988\ttrain-rmse:1.97729\n",
      "[17661]\teval-rmse:3.83841\ttrain-rmse:1.97733\n",
      "[17662]\teval-rmse:3.84004\ttrain-rmse:1.97727\n",
      "[17663]\teval-rmse:3.83965\ttrain-rmse:1.97727\n",
      "[17664]\teval-rmse:3.84025\ttrain-rmse:1.97725\n",
      "[17665]\teval-rmse:3.84203\ttrain-rmse:1.9772\n",
      "[17666]\teval-rmse:3.84166\ttrain-rmse:1.9772\n",
      "[17667]\teval-rmse:3.84148\ttrain-rmse:1.9772\n",
      "[17668]\teval-rmse:3.84131\ttrain-rmse:1.9772\n",
      "[17669]\teval-rmse:3.83936\ttrain-rmse:1.97723\n",
      "[17670]\teval-rmse:3.84098\ttrain-rmse:1.97718\n",
      "[17671]\teval-rmse:3.84058\ttrain-rmse:1.97718\n",
      "[17672]\teval-rmse:3.84011\ttrain-rmse:1.97719\n",
      "[17673]\teval-rmse:3.84151\ttrain-rmse:1.97717\n",
      "[17674]\teval-rmse:3.83984\ttrain-rmse:1.97722\n",
      "[17675]\teval-rmse:3.84032\ttrain-rmse:1.97721\n",
      "[17676]\teval-rmse:3.8389\ttrain-rmse:1.97725\n",
      "[17677]\teval-rmse:3.83954\ttrain-rmse:1.97723\n",
      "[17678]\teval-rmse:3.84007\ttrain-rmse:1.97722\n",
      "[17679]\teval-rmse:3.8401\ttrain-rmse:1.97722\n",
      "[17680]\teval-rmse:3.83974\ttrain-rmse:1.97722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17681]\teval-rmse:3.83759\ttrain-rmse:1.9773\n",
      "[17682]\teval-rmse:3.83723\ttrain-rmse:1.9773\n",
      "[17683]\teval-rmse:3.83707\ttrain-rmse:1.97731\n",
      "[17684]\teval-rmse:3.8377\ttrain-rmse:1.97728\n",
      "[17685]\teval-rmse:3.83788\ttrain-rmse:1.97728\n",
      "[17686]\teval-rmse:3.83662\ttrain-rmse:1.97733\n",
      "[17687]\teval-rmse:3.83493\ttrain-rmse:1.97737\n",
      "[17688]\teval-rmse:3.83355\ttrain-rmse:1.97744\n",
      "[17689]\teval-rmse:3.83317\ttrain-rmse:1.97745\n",
      "[17690]\teval-rmse:3.83466\ttrain-rmse:1.97738\n",
      "[17691]\teval-rmse:3.83406\ttrain-rmse:1.97741\n",
      "[17692]\teval-rmse:3.83328\ttrain-rmse:1.97744\n",
      "[17693]\teval-rmse:3.83527\ttrain-rmse:1.9774\n",
      "[17694]\teval-rmse:3.83354\ttrain-rmse:1.97748\n",
      "[17695]\teval-rmse:3.8314\ttrain-rmse:1.9776\n",
      "[17696]\teval-rmse:3.8304\ttrain-rmse:1.97762\n",
      "[17697]\teval-rmse:3.8314\ttrain-rmse:1.97758\n",
      "[17698]\teval-rmse:3.83217\ttrain-rmse:1.97755\n",
      "[17699]\teval-rmse:3.83033\ttrain-rmse:1.97766\n",
      "[17700]\teval-rmse:3.83151\ttrain-rmse:1.97758\n",
      "[17701]\teval-rmse:3.83004\ttrain-rmse:1.97768\n",
      "[17702]\teval-rmse:3.82871\ttrain-rmse:1.97774\n",
      "[17703]\teval-rmse:3.82906\ttrain-rmse:1.97771\n",
      "[17704]\teval-rmse:3.82972\ttrain-rmse:1.97767\n",
      "[17705]\teval-rmse:3.8294\ttrain-rmse:1.97753\n",
      "[17706]\teval-rmse:3.82734\ttrain-rmse:1.97767\n",
      "[17707]\teval-rmse:3.82577\ttrain-rmse:1.97775\n",
      "[17708]\teval-rmse:3.82764\ttrain-rmse:1.97763\n",
      "[17709]\teval-rmse:3.82965\ttrain-rmse:1.97756\n",
      "[17710]\teval-rmse:3.82953\ttrain-rmse:1.97756\n",
      "[17711]\teval-rmse:3.82959\ttrain-rmse:1.97756\n",
      "[17712]\teval-rmse:3.82879\ttrain-rmse:1.97759\n",
      "[17713]\teval-rmse:3.8271\ttrain-rmse:1.97772\n",
      "[17714]\teval-rmse:3.82548\ttrain-rmse:1.97781\n",
      "[17715]\teval-rmse:3.82712\ttrain-rmse:1.9777\n",
      "[17716]\teval-rmse:3.82602\ttrain-rmse:1.97778\n",
      "[17717]\teval-rmse:3.8264\ttrain-rmse:1.97775\n",
      "[17718]\teval-rmse:3.82512\ttrain-rmse:1.97785\n",
      "[17719]\teval-rmse:3.82457\ttrain-rmse:1.97789\n",
      "[17720]\teval-rmse:3.82447\ttrain-rmse:1.9779\n",
      "[17721]\teval-rmse:3.82283\ttrain-rmse:1.978\n",
      "[17722]\teval-rmse:3.82448\ttrain-rmse:1.97788\n",
      "[17723]\teval-rmse:3.82439\ttrain-rmse:1.97788\n",
      "[17724]\teval-rmse:3.823\ttrain-rmse:1.97801\n",
      "[17725]\teval-rmse:3.82349\ttrain-rmse:1.97798\n",
      "[17726]\teval-rmse:3.82466\ttrain-rmse:1.97787\n",
      "[17727]\teval-rmse:3.82516\ttrain-rmse:1.97782\n",
      "[17728]\teval-rmse:3.82525\ttrain-rmse:1.97782\n",
      "[17729]\teval-rmse:3.82507\ttrain-rmse:1.97783\n",
      "[17730]\teval-rmse:3.82624\ttrain-rmse:1.97774\n",
      "[17731]\teval-rmse:3.82492\ttrain-rmse:1.97781\n",
      "[17732]\teval-rmse:3.82439\ttrain-rmse:1.97785\n",
      "[17733]\teval-rmse:3.82257\ttrain-rmse:1.97801\n",
      "[17734]\teval-rmse:3.82335\ttrain-rmse:1.97794\n",
      "[17735]\teval-rmse:3.8217\ttrain-rmse:1.97809\n",
      "[17736]\teval-rmse:3.82138\ttrain-rmse:1.97795\n",
      "[17737]\teval-rmse:3.82044\ttrain-rmse:1.97798\n",
      "[17738]\teval-rmse:3.81968\ttrain-rmse:1.97804\n",
      "[17739]\teval-rmse:3.81853\ttrain-rmse:1.97813\n",
      "[17740]\teval-rmse:3.82022\ttrain-rmse:1.97799\n",
      "[17741]\teval-rmse:3.81906\ttrain-rmse:1.97808\n",
      "[17742]\teval-rmse:3.81918\ttrain-rmse:1.97807\n",
      "[17743]\teval-rmse:3.81923\ttrain-rmse:1.97806\n",
      "[17744]\teval-rmse:3.82006\ttrain-rmse:1.978\n",
      "[17745]\teval-rmse:3.82075\ttrain-rmse:1.97793\n",
      "[17746]\teval-rmse:3.82035\ttrain-rmse:1.97796\n",
      "[17747]\teval-rmse:3.82237\ttrain-rmse:1.97786\n",
      "[17748]\teval-rmse:3.82067\ttrain-rmse:1.97798\n",
      "[17749]\teval-rmse:3.82095\ttrain-rmse:1.97795\n",
      "[17750]\teval-rmse:3.81958\ttrain-rmse:1.9781\n",
      "[17751]\teval-rmse:3.81807\ttrain-rmse:1.97822\n",
      "[17752]\teval-rmse:3.81703\ttrain-rmse:1.97831\n",
      "[17753]\teval-rmse:3.81664\ttrain-rmse:1.97835\n",
      "[17754]\teval-rmse:3.81572\ttrain-rmse:1.9784\n",
      "[17755]\teval-rmse:3.81536\ttrain-rmse:1.97844\n",
      "[17756]\teval-rmse:3.81572\ttrain-rmse:1.9784\n",
      "[17757]\teval-rmse:3.8158\ttrain-rmse:1.97839\n",
      "[17758]\teval-rmse:3.81488\ttrain-rmse:1.97845\n",
      "[17759]\teval-rmse:3.81328\ttrain-rmse:1.97864\n",
      "[17760]\teval-rmse:3.81485\ttrain-rmse:1.9785\n",
      "[17761]\teval-rmse:3.81322\ttrain-rmse:1.97868\n",
      "[17762]\teval-rmse:3.81212\ttrain-rmse:1.97879\n",
      "[17763]\teval-rmse:3.81081\ttrain-rmse:1.97896\n",
      "[17764]\teval-rmse:3.81013\ttrain-rmse:1.97903\n",
      "[17765]\teval-rmse:3.80878\ttrain-rmse:1.97922\n",
      "[17766]\teval-rmse:3.80756\ttrain-rmse:1.97936\n",
      "[17767]\teval-rmse:3.8061\ttrain-rmse:1.97959\n",
      "[17768]\teval-rmse:3.80777\ttrain-rmse:1.97939\n",
      "[17769]\teval-rmse:3.80854\ttrain-rmse:1.9793\n",
      "[17770]\teval-rmse:3.80745\ttrain-rmse:1.97942\n",
      "[17771]\teval-rmse:3.80831\ttrain-rmse:1.97932\n",
      "[17772]\teval-rmse:3.80806\ttrain-rmse:1.97933\n",
      "[17773]\teval-rmse:3.80688\ttrain-rmse:1.97947\n",
      "[17774]\teval-rmse:3.80641\ttrain-rmse:1.97952\n",
      "[17775]\teval-rmse:3.80617\ttrain-rmse:1.97953\n",
      "[17776]\teval-rmse:3.8042\ttrain-rmse:1.97983\n",
      "[17777]\teval-rmse:3.80254\ttrain-rmse:1.98008\n",
      "[17778]\teval-rmse:3.80376\ttrain-rmse:1.97987\n",
      "[17779]\teval-rmse:3.80308\ttrain-rmse:1.97995\n",
      "[17780]\teval-rmse:3.80414\ttrain-rmse:1.97982\n",
      "[17781]\teval-rmse:3.80499\ttrain-rmse:1.97971\n",
      "[17782]\teval-rmse:3.80701\ttrain-rmse:1.97955\n",
      "[17783]\teval-rmse:3.80677\ttrain-rmse:1.97958\n",
      "[17784]\teval-rmse:3.80734\ttrain-rmse:1.97949\n",
      "[17785]\teval-rmse:3.80589\ttrain-rmse:1.97967\n",
      "[17786]\teval-rmse:3.80752\ttrain-rmse:1.97947\n",
      "[17787]\teval-rmse:3.80789\ttrain-rmse:1.97941\n",
      "[17788]\teval-rmse:3.80906\ttrain-rmse:1.97925\n",
      "[17789]\teval-rmse:3.81035\ttrain-rmse:1.9791\n",
      "[17790]\teval-rmse:3.80977\ttrain-rmse:1.97916\n",
      "[17791]\teval-rmse:3.81009\ttrain-rmse:1.97909\n",
      "[17792]\teval-rmse:3.81024\ttrain-rmse:1.97907\n",
      "[17793]\teval-rmse:3.80866\ttrain-rmse:1.97929\n",
      "[17794]\teval-rmse:3.80839\ttrain-rmse:1.97931\n",
      "[17795]\teval-rmse:3.80974\ttrain-rmse:1.97916\n",
      "[17796]\teval-rmse:3.81058\ttrain-rmse:1.97907\n",
      "[17797]\teval-rmse:3.81025\ttrain-rmse:1.9791\n",
      "[17798]\teval-rmse:3.81186\ttrain-rmse:1.97887\n",
      "[17799]\teval-rmse:3.81321\ttrain-rmse:1.97874\n",
      "[17800]\teval-rmse:3.81209\ttrain-rmse:1.97885\n",
      "[17801]\teval-rmse:3.81048\ttrain-rmse:1.97907\n",
      "[17802]\teval-rmse:3.81033\ttrain-rmse:1.97907\n",
      "[17803]\teval-rmse:3.80957\ttrain-rmse:1.97918\n",
      "[17804]\teval-rmse:3.80992\ttrain-rmse:1.97912\n",
      "[17805]\teval-rmse:3.80832\ttrain-rmse:1.97935\n",
      "[17806]\teval-rmse:3.80723\ttrain-rmse:1.97947\n",
      "[17807]\teval-rmse:3.80912\ttrain-rmse:1.97926\n",
      "[17808]\teval-rmse:3.80803\ttrain-rmse:1.97938\n",
      "[17809]\teval-rmse:3.80672\ttrain-rmse:1.97951\n",
      "[17810]\teval-rmse:3.80601\ttrain-rmse:1.97962\n",
      "[17811]\teval-rmse:3.8045\ttrain-rmse:1.97981\n",
      "[17812]\teval-rmse:3.8053\ttrain-rmse:1.97968\n",
      "[17813]\teval-rmse:3.8071\ttrain-rmse:1.97947\n",
      "[17814]\teval-rmse:3.80635\ttrain-rmse:1.97958\n",
      "[17815]\teval-rmse:3.80803\ttrain-rmse:1.97939\n",
      "[17816]\teval-rmse:3.80779\ttrain-rmse:1.97942\n",
      "[17817]\teval-rmse:3.80784\ttrain-rmse:1.97941\n",
      "[17818]\teval-rmse:3.80666\ttrain-rmse:1.97955\n",
      "[17819]\teval-rmse:3.80856\ttrain-rmse:1.97934\n",
      "[17820]\teval-rmse:3.8074\ttrain-rmse:1.97948\n",
      "[17821]\teval-rmse:3.80703\ttrain-rmse:1.97951\n",
      "[17822]\teval-rmse:3.80778\ttrain-rmse:1.97942\n",
      "[17823]\teval-rmse:3.8098\ttrain-rmse:1.97927\n",
      "[17824]\teval-rmse:3.8083\ttrain-rmse:1.97951\n",
      "[17825]\teval-rmse:3.80951\ttrain-rmse:1.97933\n",
      "[17826]\teval-rmse:3.80906\ttrain-rmse:1.97938\n",
      "[17827]\teval-rmse:3.80762\ttrain-rmse:1.97955\n",
      "[17828]\teval-rmse:3.80768\ttrain-rmse:1.97954\n",
      "[17829]\teval-rmse:3.80731\ttrain-rmse:1.97958\n",
      "[17830]\teval-rmse:3.80664\ttrain-rmse:1.97966\n",
      "[17831]\teval-rmse:3.80821\ttrain-rmse:1.97948\n",
      "[17832]\teval-rmse:3.80694\ttrain-rmse:1.97968\n",
      "[17833]\teval-rmse:3.80861\ttrain-rmse:1.97949\n",
      "[17834]\teval-rmse:3.80836\ttrain-rmse:1.9795\n",
      "[17835]\teval-rmse:3.80989\ttrain-rmse:1.97928\n",
      "[17836]\teval-rmse:3.80827\ttrain-rmse:1.97951\n",
      "[17837]\teval-rmse:3.80832\ttrain-rmse:1.9795\n",
      "[17838]\teval-rmse:3.80936\ttrain-rmse:1.97938\n",
      "[17839]\teval-rmse:3.80735\ttrain-rmse:1.97968\n",
      "[17840]\teval-rmse:3.80723\ttrain-rmse:1.97969\n",
      "[17841]\teval-rmse:3.80805\ttrain-rmse:1.97956\n",
      "[17842]\teval-rmse:3.80767\ttrain-rmse:1.9796\n",
      "[17843]\teval-rmse:3.80829\ttrain-rmse:1.97952\n",
      "[17844]\teval-rmse:3.80805\ttrain-rmse:1.97955\n",
      "[17845]\teval-rmse:3.80963\ttrain-rmse:1.97933\n",
      "[17846]\teval-rmse:3.81\ttrain-rmse:1.97927\n",
      "[17847]\teval-rmse:3.81172\ttrain-rmse:1.97908\n",
      "[17848]\teval-rmse:3.81002\ttrain-rmse:1.97931\n",
      "[17849]\teval-rmse:3.8098\ttrain-rmse:1.97916\n",
      "[17850]\teval-rmse:3.81182\ttrain-rmse:1.97902\n",
      "[17851]\teval-rmse:3.81315\ttrain-rmse:1.97883\n",
      "[17852]\teval-rmse:3.8139\ttrain-rmse:1.97872\n",
      "[17853]\teval-rmse:3.81276\ttrain-rmse:1.97888\n",
      "[17854]\teval-rmse:3.81375\ttrain-rmse:1.97875\n",
      "[17855]\teval-rmse:3.8146\ttrain-rmse:1.97863\n",
      "[17856]\teval-rmse:3.8137\ttrain-rmse:1.97869\n",
      "[17857]\teval-rmse:3.81536\ttrain-rmse:1.97852\n",
      "[17858]\teval-rmse:3.81393\ttrain-rmse:1.9787\n",
      "[17859]\teval-rmse:3.81364\ttrain-rmse:1.97853\n",
      "[17860]\teval-rmse:3.81544\ttrain-rmse:1.97836\n",
      "[17861]\teval-rmse:3.81441\ttrain-rmse:1.97846\n",
      "[17862]\teval-rmse:3.81621\ttrain-rmse:1.97829\n",
      "[17863]\teval-rmse:3.81821\ttrain-rmse:1.97817\n",
      "[17864]\teval-rmse:3.81813\ttrain-rmse:1.97817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17865]\teval-rmse:3.81916\ttrain-rmse:1.97808\n",
      "[17866]\teval-rmse:3.81997\ttrain-rmse:1.97799\n",
      "[17867]\teval-rmse:3.81989\ttrain-rmse:1.97799\n",
      "[17868]\teval-rmse:3.82133\ttrain-rmse:1.97787\n",
      "[17869]\teval-rmse:3.82103\ttrain-rmse:1.9779\n",
      "[17870]\teval-rmse:3.8194\ttrain-rmse:1.97809\n",
      "[17871]\teval-rmse:3.81897\ttrain-rmse:1.97813\n",
      "[17872]\teval-rmse:3.81881\ttrain-rmse:1.97813\n",
      "[17873]\teval-rmse:3.81975\ttrain-rmse:1.97805\n",
      "[17874]\teval-rmse:3.82119\ttrain-rmse:1.97794\n",
      "[17875]\teval-rmse:3.82024\ttrain-rmse:1.97798\n",
      "[17876]\teval-rmse:3.81992\ttrain-rmse:1.9778\n",
      "[17877]\teval-rmse:3.81984\ttrain-rmse:1.9778\n",
      "[17878]\teval-rmse:3.82015\ttrain-rmse:1.97776\n",
      "[17879]\teval-rmse:3.81876\ttrain-rmse:1.97787\n",
      "[17880]\teval-rmse:3.82006\ttrain-rmse:1.97773\n",
      "[17881]\teval-rmse:3.81849\ttrain-rmse:1.97785\n",
      "[17882]\teval-rmse:3.81813\ttrain-rmse:1.97788\n",
      "[17883]\teval-rmse:3.81761\ttrain-rmse:1.97793\n",
      "[17884]\teval-rmse:3.81606\ttrain-rmse:1.97811\n",
      "[17885]\teval-rmse:3.81678\ttrain-rmse:1.97804\n",
      "[17886]\teval-rmse:3.81648\ttrain-rmse:1.97805\n",
      "[17887]\teval-rmse:3.81557\ttrain-rmse:1.97809\n",
      "[17888]\teval-rmse:3.81736\ttrain-rmse:1.97793\n",
      "[17889]\teval-rmse:3.81815\ttrain-rmse:1.97784\n",
      "[17890]\teval-rmse:3.81753\ttrain-rmse:1.97789\n",
      "[17891]\teval-rmse:3.81829\ttrain-rmse:1.9778\n",
      "[17892]\teval-rmse:3.81821\ttrain-rmse:1.97781\n",
      "[17893]\teval-rmse:3.81814\ttrain-rmse:1.97781\n",
      "[17894]\teval-rmse:3.81657\ttrain-rmse:1.97795\n",
      "[17895]\teval-rmse:3.81543\ttrain-rmse:1.97809\n",
      "[17896]\teval-rmse:3.81704\ttrain-rmse:1.97789\n",
      "[17897]\teval-rmse:3.81656\ttrain-rmse:1.97793\n",
      "[17898]\teval-rmse:3.81517\ttrain-rmse:1.9781\n",
      "[17899]\teval-rmse:3.81719\ttrain-rmse:1.97798\n",
      "[17900]\teval-rmse:3.8192\ttrain-rmse:1.97788\n",
      "[17901]\teval-rmse:3.81782\ttrain-rmse:1.97799\n",
      "[17902]\teval-rmse:3.81838\ttrain-rmse:1.97792\n",
      "[17903]\teval-rmse:3.81875\ttrain-rmse:1.97788\n",
      "[17904]\teval-rmse:3.81794\ttrain-rmse:1.97798\n",
      "[17905]\teval-rmse:3.81994\ttrain-rmse:1.97787\n",
      "[17906]\teval-rmse:3.82138\ttrain-rmse:1.97776\n",
      "[17907]\teval-rmse:3.82173\ttrain-rmse:1.97773\n",
      "[17908]\teval-rmse:3.82135\ttrain-rmse:1.97775\n",
      "[17909]\teval-rmse:3.82192\ttrain-rmse:1.97769\n",
      "[17910]\teval-rmse:3.82164\ttrain-rmse:1.97754\n",
      "[17911]\teval-rmse:3.82236\ttrain-rmse:1.97747\n",
      "[17912]\teval-rmse:3.82204\ttrain-rmse:1.97748\n",
      "[17913]\teval-rmse:3.82307\ttrain-rmse:1.97741\n",
      "[17914]\teval-rmse:3.82193\ttrain-rmse:1.97749\n",
      "[17915]\teval-rmse:3.82349\ttrain-rmse:1.97738\n",
      "[17916]\teval-rmse:3.82289\ttrain-rmse:1.97745\n",
      "[17917]\teval-rmse:3.82458\ttrain-rmse:1.97733\n",
      "[17918]\teval-rmse:3.82646\ttrain-rmse:1.97721\n",
      "[17919]\teval-rmse:3.82527\ttrain-rmse:1.97727\n",
      "[17920]\teval-rmse:3.82494\ttrain-rmse:1.97728\n",
      "[17921]\teval-rmse:3.82545\ttrain-rmse:1.97724\n",
      "[17922]\teval-rmse:3.82513\ttrain-rmse:1.97726\n",
      "[17923]\teval-rmse:3.82353\ttrain-rmse:1.97737\n",
      "[17924]\teval-rmse:3.82319\ttrain-rmse:1.97738\n",
      "[17925]\teval-rmse:3.82211\ttrain-rmse:1.97746\n",
      "[17926]\teval-rmse:3.82044\ttrain-rmse:1.97765\n",
      "[17927]\teval-rmse:3.81918\ttrain-rmse:1.97774\n",
      "[17928]\teval-rmse:3.82039\ttrain-rmse:1.97761\n",
      "[17929]\teval-rmse:3.81933\ttrain-rmse:1.97769\n",
      "[17930]\teval-rmse:3.81945\ttrain-rmse:1.97767\n",
      "[17931]\teval-rmse:3.82055\ttrain-rmse:1.97756\n",
      "[17932]\teval-rmse:3.8211\ttrain-rmse:1.9775\n",
      "[17933]\teval-rmse:3.81937\ttrain-rmse:1.97767\n",
      "[17934]\teval-rmse:3.82116\ttrain-rmse:1.97754\n",
      "[17935]\teval-rmse:3.81943\ttrain-rmse:1.97772\n",
      "[17936]\teval-rmse:3.82094\ttrain-rmse:1.97759\n",
      "[17937]\teval-rmse:3.82093\ttrain-rmse:1.97759\n",
      "[17938]\teval-rmse:3.82084\ttrain-rmse:1.97759\n",
      "[17939]\teval-rmse:3.81948\ttrain-rmse:1.97775\n",
      "[17940]\teval-rmse:3.82051\ttrain-rmse:1.97766\n",
      "[17941]\teval-rmse:3.82109\ttrain-rmse:1.97761\n",
      "[17942]\teval-rmse:3.82077\ttrain-rmse:1.97761\n",
      "[17943]\teval-rmse:3.82122\ttrain-rmse:1.97757\n",
      "[17944]\teval-rmse:3.82005\ttrain-rmse:1.97766\n",
      "[17945]\teval-rmse:3.82039\ttrain-rmse:1.97762\n",
      "[17946]\teval-rmse:3.82239\ttrain-rmse:1.97752\n",
      "[17947]\teval-rmse:3.82158\ttrain-rmse:1.97762\n",
      "[17948]\teval-rmse:3.82305\ttrain-rmse:1.9775\n",
      "[17949]\teval-rmse:3.82273\ttrain-rmse:1.97751\n",
      "[17950]\teval-rmse:3.82241\ttrain-rmse:1.97751\n",
      "[17951]\teval-rmse:3.82264\ttrain-rmse:1.97749\n",
      "[17952]\teval-rmse:3.82465\ttrain-rmse:1.9774\n",
      "[17953]\teval-rmse:3.82432\ttrain-rmse:1.97741\n",
      "[17954]\teval-rmse:3.8249\ttrain-rmse:1.97736\n",
      "[17955]\teval-rmse:3.8255\ttrain-rmse:1.9773\n",
      "[17956]\teval-rmse:3.82687\ttrain-rmse:1.97717\n",
      "[17957]\teval-rmse:3.82538\ttrain-rmse:1.9773\n",
      "[17958]\teval-rmse:3.82529\ttrain-rmse:1.97729\n",
      "[17959]\teval-rmse:3.82694\ttrain-rmse:1.9772\n",
      "[17960]\teval-rmse:3.82674\ttrain-rmse:1.9772\n",
      "[17961]\teval-rmse:3.82863\ttrain-rmse:1.97709\n",
      "[17962]\teval-rmse:3.82996\ttrain-rmse:1.97702\n",
      "[17963]\teval-rmse:3.83018\ttrain-rmse:1.977\n",
      "[17964]\teval-rmse:3.83149\ttrain-rmse:1.9769\n",
      "[17965]\teval-rmse:3.83296\ttrain-rmse:1.97679\n",
      "[17966]\teval-rmse:3.83259\ttrain-rmse:1.9768\n",
      "[17967]\teval-rmse:3.831\ttrain-rmse:1.97687\n",
      "[17968]\teval-rmse:3.83171\ttrain-rmse:1.97682\n",
      "[17969]\teval-rmse:3.83112\ttrain-rmse:1.97685\n",
      "[17970]\teval-rmse:3.83293\ttrain-rmse:1.97671\n",
      "[17971]\teval-rmse:3.8328\ttrain-rmse:1.97671\n",
      "[17972]\teval-rmse:3.8331\ttrain-rmse:1.9767\n",
      "[17973]\teval-rmse:3.83269\ttrain-rmse:1.97671\n",
      "[17974]\teval-rmse:3.83346\ttrain-rmse:1.97668\n",
      "[17975]\teval-rmse:3.83546\ttrain-rmse:1.97664\n",
      "[17976]\teval-rmse:3.83507\ttrain-rmse:1.97649\n",
      "[17977]\teval-rmse:3.83437\ttrain-rmse:1.97652\n",
      "[17978]\teval-rmse:3.8353\ttrain-rmse:1.97646\n",
      "[17979]\teval-rmse:3.83649\ttrain-rmse:1.9764\n",
      "[17980]\teval-rmse:3.83634\ttrain-rmse:1.97639\n",
      "[17981]\teval-rmse:3.83748\ttrain-rmse:1.97634\n",
      "[17982]\teval-rmse:3.83558\ttrain-rmse:1.97645\n",
      "[17983]\teval-rmse:3.83521\ttrain-rmse:1.97645\n",
      "[17984]\teval-rmse:3.83692\ttrain-rmse:1.97639\n",
      "[17985]\teval-rmse:3.83695\ttrain-rmse:1.97639\n",
      "[17986]\teval-rmse:3.83679\ttrain-rmse:1.97639\n",
      "[17987]\teval-rmse:3.83833\ttrain-rmse:1.97631\n",
      "[17988]\teval-rmse:3.83621\ttrain-rmse:1.97641\n",
      "[17989]\teval-rmse:3.83757\ttrain-rmse:1.97636\n",
      "[17990]\teval-rmse:3.83934\ttrain-rmse:1.9763\n",
      "[17991]\teval-rmse:3.84111\ttrain-rmse:1.97625\n",
      "[17992]\teval-rmse:3.84071\ttrain-rmse:1.97627\n",
      "[17993]\teval-rmse:3.84271\ttrain-rmse:1.97626\n",
      "[17994]\teval-rmse:3.84206\ttrain-rmse:1.97628\n",
      "[17995]\teval-rmse:3.84082\ttrain-rmse:1.97633\n",
      "[17996]\teval-rmse:3.84194\ttrain-rmse:1.97628\n",
      "[17997]\teval-rmse:3.84332\ttrain-rmse:1.97624\n",
      "[17998]\teval-rmse:3.84531\ttrain-rmse:1.97624\n",
      "[17999]\teval-rmse:3.8456\ttrain-rmse:1.97623\n",
      "[18000]\teval-rmse:3.84517\ttrain-rmse:1.97623\n",
      "[18001]\teval-rmse:3.84498\ttrain-rmse:1.97622\n",
      "[18002]\teval-rmse:3.84661\ttrain-rmse:1.9762\n",
      "[18003]\teval-rmse:3.84727\ttrain-rmse:1.97619\n",
      "[18004]\teval-rmse:3.84771\ttrain-rmse:1.97618\n",
      "[18005]\teval-rmse:3.84729\ttrain-rmse:1.97619\n",
      "[18006]\teval-rmse:3.84645\ttrain-rmse:1.97619\n",
      "[18007]\teval-rmse:3.84826\ttrain-rmse:1.97615\n",
      "[18008]\teval-rmse:3.84855\ttrain-rmse:1.97614\n",
      "[18009]\teval-rmse:3.84727\ttrain-rmse:1.97615\n",
      "[18010]\teval-rmse:3.84903\ttrain-rmse:1.97614\n",
      "[18011]\teval-rmse:3.84959\ttrain-rmse:1.97614\n",
      "[18012]\teval-rmse:3.84929\ttrain-rmse:1.97613\n",
      "[18013]\teval-rmse:3.85087\ttrain-rmse:1.97614\n",
      "[18014]\teval-rmse:3.85285\ttrain-rmse:1.97616\n",
      "[18015]\teval-rmse:3.8542\ttrain-rmse:1.97616\n",
      "[18016]\teval-rmse:3.85605\ttrain-rmse:1.97616\n",
      "[18017]\teval-rmse:3.85571\ttrain-rmse:1.97615\n",
      "[18018]\teval-rmse:3.85502\ttrain-rmse:1.97614\n",
      "[18019]\teval-rmse:3.85573\ttrain-rmse:1.97614\n",
      "[18020]\teval-rmse:3.85503\ttrain-rmse:1.97614\n",
      "[18021]\teval-rmse:3.85328\ttrain-rmse:1.97613\n",
      "[18022]\teval-rmse:3.85502\ttrain-rmse:1.97616\n",
      "[18023]\teval-rmse:3.85324\ttrain-rmse:1.97613\n",
      "[18024]\teval-rmse:3.85277\ttrain-rmse:1.97612\n",
      "[18025]\teval-rmse:3.85096\ttrain-rmse:1.97611\n",
      "[18026]\teval-rmse:3.85169\ttrain-rmse:1.97612\n",
      "[18027]\teval-rmse:3.85123\ttrain-rmse:1.97597\n",
      "[18028]\teval-rmse:3.84991\ttrain-rmse:1.97599\n",
      "[18029]\teval-rmse:3.84917\ttrain-rmse:1.97598\n",
      "[18030]\teval-rmse:3.8505\ttrain-rmse:1.97599\n",
      "[18031]\teval-rmse:3.84881\ttrain-rmse:1.97601\n",
      "[18032]\teval-rmse:3.84725\ttrain-rmse:1.97602\n",
      "[18033]\teval-rmse:3.84887\ttrain-rmse:1.97599\n",
      "[18034]\teval-rmse:3.8504\ttrain-rmse:1.97599\n",
      "[18035]\teval-rmse:3.85193\ttrain-rmse:1.976\n",
      "[18036]\teval-rmse:3.85213\ttrain-rmse:1.976\n",
      "[18037]\teval-rmse:3.85342\ttrain-rmse:1.97599\n",
      "[18038]\teval-rmse:3.85267\ttrain-rmse:1.97599\n",
      "[18039]\teval-rmse:3.85298\ttrain-rmse:1.97599\n",
      "[18040]\teval-rmse:3.85185\ttrain-rmse:1.97598\n",
      "[18041]\teval-rmse:3.85203\ttrain-rmse:1.97597\n",
      "[18042]\teval-rmse:3.85125\ttrain-rmse:1.97597\n",
      "[18043]\teval-rmse:3.85061\ttrain-rmse:1.97596\n",
      "[18044]\teval-rmse:3.84887\ttrain-rmse:1.97599\n",
      "[18045]\teval-rmse:3.84704\ttrain-rmse:1.97603\n",
      "[18046]\teval-rmse:3.84674\ttrain-rmse:1.97603\n",
      "[18047]\teval-rmse:3.84702\ttrain-rmse:1.97602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18048]\teval-rmse:3.84822\ttrain-rmse:1.976\n",
      "[18049]\teval-rmse:3.8478\ttrain-rmse:1.976\n",
      "[18050]\teval-rmse:3.8487\ttrain-rmse:1.97598\n",
      "[18051]\teval-rmse:3.8476\ttrain-rmse:1.97598\n",
      "[18052]\teval-rmse:3.84786\ttrain-rmse:1.97597\n",
      "[18053]\teval-rmse:3.84742\ttrain-rmse:1.97596\n",
      "[18054]\teval-rmse:3.84698\ttrain-rmse:1.97596\n",
      "[18055]\teval-rmse:3.84668\ttrain-rmse:1.97596\n",
      "[18056]\teval-rmse:3.84797\ttrain-rmse:1.97594\n",
      "[18057]\teval-rmse:3.84825\ttrain-rmse:1.97594\n",
      "[18058]\teval-rmse:3.84758\ttrain-rmse:1.97594\n",
      "[18059]\teval-rmse:3.84738\ttrain-rmse:1.97593\n",
      "[18060]\teval-rmse:3.849\ttrain-rmse:1.97592\n",
      "[18061]\teval-rmse:3.84777\ttrain-rmse:1.97592\n",
      "[18062]\teval-rmse:3.8482\ttrain-rmse:1.97592\n",
      "[18063]\teval-rmse:3.8485\ttrain-rmse:1.97592\n",
      "[18064]\teval-rmse:3.84787\ttrain-rmse:1.97592\n",
      "[18065]\teval-rmse:3.84831\ttrain-rmse:1.97591\n",
      "[18066]\teval-rmse:3.84681\ttrain-rmse:1.97593\n",
      "[18067]\teval-rmse:3.84731\ttrain-rmse:1.97593\n",
      "[18068]\teval-rmse:3.84605\ttrain-rmse:1.97596\n",
      "[18069]\teval-rmse:3.84539\ttrain-rmse:1.97596\n",
      "[18070]\teval-rmse:3.84431\ttrain-rmse:1.97596\n",
      "[18071]\teval-rmse:3.8456\ttrain-rmse:1.97593\n",
      "[18072]\teval-rmse:3.84424\ttrain-rmse:1.97596\n",
      "[18073]\teval-rmse:3.84252\ttrain-rmse:1.97599\n",
      "[18074]\teval-rmse:3.84438\ttrain-rmse:1.97596\n",
      "[18075]\teval-rmse:3.84345\ttrain-rmse:1.97599\n",
      "[18076]\teval-rmse:3.84303\ttrain-rmse:1.97599\n",
      "[18077]\teval-rmse:3.8425\ttrain-rmse:1.976\n",
      "[18078]\teval-rmse:3.84348\ttrain-rmse:1.97597\n",
      "[18079]\teval-rmse:3.84524\ttrain-rmse:1.97595\n",
      "[18080]\teval-rmse:3.84397\ttrain-rmse:1.97596\n",
      "[18081]\teval-rmse:3.84332\ttrain-rmse:1.97597\n",
      "[18082]\teval-rmse:3.84389\ttrain-rmse:1.97595\n",
      "[18083]\teval-rmse:3.84453\ttrain-rmse:1.97595\n",
      "[18084]\teval-rmse:3.84309\ttrain-rmse:1.97596\n",
      "[18085]\teval-rmse:3.8418\ttrain-rmse:1.97598\n",
      "[18086]\teval-rmse:3.84163\ttrain-rmse:1.97598\n",
      "[18087]\teval-rmse:3.84137\ttrain-rmse:1.97598\n",
      "[18088]\teval-rmse:3.84009\ttrain-rmse:1.97602\n",
      "[18089]\teval-rmse:3.84185\ttrain-rmse:1.97596\n",
      "[18090]\teval-rmse:3.84016\ttrain-rmse:1.976\n",
      "[18091]\teval-rmse:3.83875\ttrain-rmse:1.97603\n",
      "[18092]\teval-rmse:3.8385\ttrain-rmse:1.97604\n",
      "[18093]\teval-rmse:3.83699\ttrain-rmse:1.9761\n",
      "[18094]\teval-rmse:3.83661\ttrain-rmse:1.97596\n",
      "[18095]\teval-rmse:3.83707\ttrain-rmse:1.97594\n",
      "[18096]\teval-rmse:3.83568\ttrain-rmse:1.97598\n",
      "[18097]\teval-rmse:3.83502\ttrain-rmse:1.97601\n",
      "[18098]\teval-rmse:3.83498\ttrain-rmse:1.97602\n",
      "[18099]\teval-rmse:3.83523\ttrain-rmse:1.976\n",
      "[18100]\teval-rmse:3.83401\ttrain-rmse:1.97605\n",
      "[18101]\teval-rmse:3.835\ttrain-rmse:1.97599\n",
      "[18102]\teval-rmse:3.83352\ttrain-rmse:1.97607\n",
      "[18103]\teval-rmse:3.83428\ttrain-rmse:1.97604\n",
      "[18104]\teval-rmse:3.83569\ttrain-rmse:1.97597\n",
      "[18105]\teval-rmse:3.83634\ttrain-rmse:1.97595\n",
      "[18106]\teval-rmse:3.83644\ttrain-rmse:1.97594\n",
      "[18107]\teval-rmse:3.8371\ttrain-rmse:1.97592\n",
      "[18108]\teval-rmse:3.83736\ttrain-rmse:1.97591\n",
      "[18109]\teval-rmse:3.8376\ttrain-rmse:1.97591\n",
      "[18110]\teval-rmse:3.83633\ttrain-rmse:1.97594\n",
      "[18111]\teval-rmse:3.83664\ttrain-rmse:1.97593\n",
      "[18112]\teval-rmse:3.83637\ttrain-rmse:1.97593\n",
      "[18113]\teval-rmse:3.83817\ttrain-rmse:1.97588\n",
      "[18114]\teval-rmse:3.83676\ttrain-rmse:1.97593\n",
      "[18115]\teval-rmse:3.83829\ttrain-rmse:1.9759\n",
      "[18116]\teval-rmse:3.83744\ttrain-rmse:1.97592\n",
      "[18117]\teval-rmse:3.83682\ttrain-rmse:1.97594\n",
      "[18118]\teval-rmse:3.83751\ttrain-rmse:1.97592\n",
      "[18119]\teval-rmse:3.83702\ttrain-rmse:1.97594\n",
      "[18120]\teval-rmse:3.8377\ttrain-rmse:1.97592\n",
      "[18121]\teval-rmse:3.83833\ttrain-rmse:1.97589\n",
      "[18122]\teval-rmse:3.84003\ttrain-rmse:1.97586\n",
      "[18123]\teval-rmse:3.83851\ttrain-rmse:1.97592\n",
      "[18124]\teval-rmse:3.83711\ttrain-rmse:1.97597\n",
      "[18125]\teval-rmse:3.83644\ttrain-rmse:1.97598\n",
      "[18126]\teval-rmse:3.83517\ttrain-rmse:1.97604\n",
      "[18127]\teval-rmse:3.8361\ttrain-rmse:1.97599\n",
      "[18128]\teval-rmse:3.83494\ttrain-rmse:1.97603\n",
      "[18129]\teval-rmse:3.8333\ttrain-rmse:1.97609\n",
      "[18130]\teval-rmse:3.83352\ttrain-rmse:1.97608\n",
      "[18131]\teval-rmse:3.83538\ttrain-rmse:1.976\n",
      "[18132]\teval-rmse:3.83663\ttrain-rmse:1.97595\n",
      "[18133]\teval-rmse:3.83602\ttrain-rmse:1.97597\n",
      "[18134]\teval-rmse:3.83766\ttrain-rmse:1.97593\n",
      "[18135]\teval-rmse:3.83727\ttrain-rmse:1.97594\n",
      "[18136]\teval-rmse:3.83903\ttrain-rmse:1.97588\n",
      "[18137]\teval-rmse:3.84042\ttrain-rmse:1.97584\n",
      "[18138]\teval-rmse:3.84194\ttrain-rmse:1.9758\n",
      "[18139]\teval-rmse:3.84379\ttrain-rmse:1.97579\n",
      "[18140]\teval-rmse:3.84352\ttrain-rmse:1.97579\n",
      "[18141]\teval-rmse:3.84473\ttrain-rmse:1.97578\n",
      "[18142]\teval-rmse:3.84483\ttrain-rmse:1.97578\n",
      "[18143]\teval-rmse:3.84532\ttrain-rmse:1.97578\n",
      "[18144]\teval-rmse:3.84693\ttrain-rmse:1.97576\n",
      "[18145]\teval-rmse:3.84543\ttrain-rmse:1.97577\n",
      "[18146]\teval-rmse:3.84523\ttrain-rmse:1.97577\n",
      "[18147]\teval-rmse:3.84677\ttrain-rmse:1.97577\n",
      "[18148]\teval-rmse:3.84481\ttrain-rmse:1.9758\n",
      "[18149]\teval-rmse:3.84666\ttrain-rmse:1.97579\n",
      "[18150]\teval-rmse:3.8461\ttrain-rmse:1.97579\n",
      "[18151]\teval-rmse:3.84426\ttrain-rmse:1.97582\n",
      "[18152]\teval-rmse:3.84429\ttrain-rmse:1.97582\n",
      "[18153]\teval-rmse:3.84541\ttrain-rmse:1.97581\n",
      "[18154]\teval-rmse:3.84603\ttrain-rmse:1.9758\n",
      "[18155]\teval-rmse:3.84453\ttrain-rmse:1.97581\n",
      "[18156]\teval-rmse:3.84295\ttrain-rmse:1.97584\n",
      "[18157]\teval-rmse:3.84493\ttrain-rmse:1.97584\n",
      "[18158]\teval-rmse:3.84322\ttrain-rmse:1.97588\n",
      "[18159]\teval-rmse:3.84203\ttrain-rmse:1.97591\n",
      "[18160]\teval-rmse:3.8424\ttrain-rmse:1.9759\n",
      "[18161]\teval-rmse:3.84091\ttrain-rmse:1.97594\n",
      "[18162]\teval-rmse:3.84134\ttrain-rmse:1.97592\n",
      "[18163]\teval-rmse:3.84116\ttrain-rmse:1.97593\n",
      "[18164]\teval-rmse:3.8398\ttrain-rmse:1.97597\n",
      "[18165]\teval-rmse:3.84026\ttrain-rmse:1.97595\n",
      "[18166]\teval-rmse:3.84009\ttrain-rmse:1.97595\n",
      "[18167]\teval-rmse:3.84124\ttrain-rmse:1.97592\n",
      "[18168]\teval-rmse:3.84038\ttrain-rmse:1.97593\n",
      "[18169]\teval-rmse:3.84172\ttrain-rmse:1.97591\n",
      "[18170]\teval-rmse:3.84036\ttrain-rmse:1.97593\n",
      "[18171]\teval-rmse:3.8402\ttrain-rmse:1.97593\n",
      "[18172]\teval-rmse:3.8404\ttrain-rmse:1.97593\n",
      "[18173]\teval-rmse:3.84169\ttrain-rmse:1.97591\n",
      "[18174]\teval-rmse:3.84128\ttrain-rmse:1.97591\n",
      "[18175]\teval-rmse:3.84252\ttrain-rmse:1.97588\n",
      "[18176]\teval-rmse:3.8421\ttrain-rmse:1.97588\n",
      "[18177]\teval-rmse:3.8404\ttrain-rmse:1.97593\n",
      "[18178]\teval-rmse:3.84046\ttrain-rmse:1.97593\n",
      "[18179]\teval-rmse:3.84221\ttrain-rmse:1.97591\n",
      "[18180]\teval-rmse:3.84276\ttrain-rmse:1.9759\n",
      "[18181]\teval-rmse:3.84157\ttrain-rmse:1.97591\n",
      "[18182]\teval-rmse:3.84162\ttrain-rmse:1.97591\n",
      "[18183]\teval-rmse:3.84125\ttrain-rmse:1.97577\n",
      "[18184]\teval-rmse:3.84088\ttrain-rmse:1.97578\n",
      "[18185]\teval-rmse:3.84174\ttrain-rmse:1.97577\n",
      "[18186]\teval-rmse:3.83976\ttrain-rmse:1.97583\n",
      "[18187]\teval-rmse:3.83848\ttrain-rmse:1.97585\n",
      "[18188]\teval-rmse:3.83703\ttrain-rmse:1.97591\n",
      "[18189]\teval-rmse:3.83668\ttrain-rmse:1.97578\n",
      "[18190]\teval-rmse:3.83666\ttrain-rmse:1.97578\n",
      "[18191]\teval-rmse:3.83805\ttrain-rmse:1.97575\n",
      "[18192]\teval-rmse:3.83673\ttrain-rmse:1.97577\n",
      "[18193]\teval-rmse:3.8378\ttrain-rmse:1.97573\n",
      "[18194]\teval-rmse:3.83718\ttrain-rmse:1.97575\n",
      "[18195]\teval-rmse:3.83526\ttrain-rmse:1.97584\n",
      "[18196]\teval-rmse:3.83492\ttrain-rmse:1.97569\n",
      "[18197]\teval-rmse:3.83591\ttrain-rmse:1.97565\n",
      "[18198]\teval-rmse:3.83475\ttrain-rmse:1.9757\n",
      "[18199]\teval-rmse:3.83307\ttrain-rmse:1.97575\n",
      "[18200]\teval-rmse:3.83151\ttrain-rmse:1.97581\n",
      "[18201]\teval-rmse:3.83092\ttrain-rmse:1.97584\n",
      "[18202]\teval-rmse:3.83087\ttrain-rmse:1.97584\n",
      "[18203]\teval-rmse:3.83051\ttrain-rmse:1.97584\n",
      "[18204]\teval-rmse:3.82892\ttrain-rmse:1.97591\n",
      "[18205]\teval-rmse:3.82751\ttrain-rmse:1.97598\n",
      "[18206]\teval-rmse:3.82786\ttrain-rmse:1.97596\n",
      "[18207]\teval-rmse:3.82633\ttrain-rmse:1.97603\n",
      "[18208]\teval-rmse:3.82598\ttrain-rmse:1.97588\n",
      "[18209]\teval-rmse:3.82657\ttrain-rmse:1.97584\n",
      "[18210]\teval-rmse:3.82571\ttrain-rmse:1.97589\n",
      "[18211]\teval-rmse:3.82735\ttrain-rmse:1.97579\n",
      "[18212]\teval-rmse:3.82706\ttrain-rmse:1.97565\n",
      "[18213]\teval-rmse:3.82853\ttrain-rmse:1.97559\n",
      "[18214]\teval-rmse:3.82964\ttrain-rmse:1.97554\n",
      "[18215]\teval-rmse:3.82837\ttrain-rmse:1.97562\n",
      "[18216]\teval-rmse:3.82871\ttrain-rmse:1.9756\n",
      "[18217]\teval-rmse:3.82918\ttrain-rmse:1.97557\n",
      "[18218]\teval-rmse:3.83116\ttrain-rmse:1.97552\n",
      "[18219]\teval-rmse:3.83315\ttrain-rmse:1.97547\n",
      "[18220]\teval-rmse:3.83214\ttrain-rmse:1.97549\n",
      "[18221]\teval-rmse:3.83247\ttrain-rmse:1.97547\n",
      "[18222]\teval-rmse:3.83054\ttrain-rmse:1.97559\n",
      "[18223]\teval-rmse:3.83252\ttrain-rmse:1.97554\n",
      "[18224]\teval-rmse:3.83164\ttrain-rmse:1.97558\n",
      "[18225]\teval-rmse:3.83362\ttrain-rmse:1.97554\n",
      "[18226]\teval-rmse:3.83392\ttrain-rmse:1.97552\n",
      "[18227]\teval-rmse:3.83327\ttrain-rmse:1.97556\n",
      "[18228]\teval-rmse:3.83226\ttrain-rmse:1.97558\n",
      "[18229]\teval-rmse:3.83038\ttrain-rmse:1.9757\n",
      "[18230]\teval-rmse:3.82864\ttrain-rmse:1.97578\n",
      "[18231]\teval-rmse:3.82874\ttrain-rmse:1.97578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18232]\teval-rmse:3.82915\ttrain-rmse:1.97575\n",
      "[18233]\teval-rmse:3.82829\ttrain-rmse:1.97579\n",
      "[18234]\teval-rmse:3.82782\ttrain-rmse:1.97582\n",
      "[18235]\teval-rmse:3.82937\ttrain-rmse:1.97575\n",
      "[18236]\teval-rmse:3.8278\ttrain-rmse:1.97582\n",
      "[18237]\teval-rmse:3.82782\ttrain-rmse:1.97582\n",
      "[18238]\teval-rmse:3.82981\ttrain-rmse:1.97576\n",
      "[18239]\teval-rmse:3.82846\ttrain-rmse:1.97584\n",
      "[18240]\teval-rmse:3.82848\ttrain-rmse:1.97584\n",
      "[18241]\teval-rmse:3.82903\ttrain-rmse:1.97581\n",
      "[18242]\teval-rmse:3.82908\ttrain-rmse:1.9758\n",
      "[18243]\teval-rmse:3.82809\ttrain-rmse:1.97583\n",
      "[18244]\teval-rmse:3.82648\ttrain-rmse:1.97596\n",
      "[18245]\teval-rmse:3.82836\ttrain-rmse:1.97585\n",
      "[18246]\teval-rmse:3.83023\ttrain-rmse:1.97576\n",
      "[18247]\teval-rmse:3.82987\ttrain-rmse:1.97576\n",
      "[18248]\teval-rmse:3.82952\ttrain-rmse:1.97577\n",
      "[18249]\teval-rmse:3.83045\ttrain-rmse:1.97572\n",
      "[18250]\teval-rmse:3.83186\ttrain-rmse:1.97567\n",
      "[18251]\teval-rmse:3.83098\ttrain-rmse:1.97571\n",
      "[18252]\teval-rmse:3.83147\ttrain-rmse:1.97568\n",
      "[18253]\teval-rmse:3.83051\ttrain-rmse:1.97573\n",
      "[18254]\teval-rmse:3.83015\ttrain-rmse:1.97575\n",
      "[18255]\teval-rmse:3.83192\ttrain-rmse:1.97565\n",
      "[18256]\teval-rmse:3.83218\ttrain-rmse:1.97564\n",
      "[18257]\teval-rmse:3.83272\ttrain-rmse:1.97561\n",
      "[18258]\teval-rmse:3.83425\ttrain-rmse:1.97556\n",
      "[18259]\teval-rmse:3.83534\ttrain-rmse:1.9755\n",
      "[18260]\teval-rmse:3.83496\ttrain-rmse:1.97534\n",
      "[18261]\teval-rmse:3.8363\ttrain-rmse:1.9753\n",
      "[18262]\teval-rmse:3.83699\ttrain-rmse:1.97526\n",
      "[18263]\teval-rmse:3.83783\ttrain-rmse:1.97523\n",
      "[18264]\teval-rmse:3.83807\ttrain-rmse:1.97522\n",
      "[18265]\teval-rmse:3.83702\ttrain-rmse:1.97523\n",
      "[18266]\teval-rmse:3.83719\ttrain-rmse:1.97523\n",
      "[18267]\teval-rmse:3.83765\ttrain-rmse:1.97521\n",
      "[18268]\teval-rmse:3.83791\ttrain-rmse:1.9752\n",
      "[18269]\teval-rmse:3.83723\ttrain-rmse:1.97522\n",
      "[18270]\teval-rmse:3.83633\ttrain-rmse:1.97526\n",
      "[18271]\teval-rmse:3.83529\ttrain-rmse:1.97528\n",
      "[18272]\teval-rmse:3.83335\ttrain-rmse:1.97539\n",
      "[18273]\teval-rmse:3.83248\ttrain-rmse:1.97542\n",
      "[18274]\teval-rmse:3.83165\ttrain-rmse:1.97545\n",
      "[18275]\teval-rmse:3.83312\ttrain-rmse:1.97539\n",
      "[18276]\teval-rmse:3.83369\ttrain-rmse:1.97537\n",
      "[18277]\teval-rmse:3.83434\ttrain-rmse:1.97533\n",
      "[18278]\teval-rmse:3.83584\ttrain-rmse:1.97527\n",
      "[18279]\teval-rmse:3.83706\ttrain-rmse:1.97523\n",
      "[18280]\teval-rmse:3.83534\ttrain-rmse:1.97527\n",
      "[18281]\teval-rmse:3.83434\ttrain-rmse:1.97532\n",
      "[18282]\teval-rmse:3.83614\ttrain-rmse:1.97527\n",
      "[18283]\teval-rmse:3.83684\ttrain-rmse:1.97524\n",
      "[18284]\teval-rmse:3.83702\ttrain-rmse:1.97523\n",
      "[18285]\teval-rmse:3.83854\ttrain-rmse:1.97517\n",
      "[18286]\teval-rmse:3.84006\ttrain-rmse:1.97511\n",
      "[18287]\teval-rmse:3.83978\ttrain-rmse:1.97511\n",
      "[18288]\teval-rmse:3.83813\ttrain-rmse:1.97517\n",
      "[18289]\teval-rmse:3.83954\ttrain-rmse:1.97512\n",
      "[18290]\teval-rmse:3.83972\ttrain-rmse:1.97512\n",
      "[18291]\teval-rmse:3.83954\ttrain-rmse:1.97512\n",
      "[18292]\teval-rmse:3.83982\ttrain-rmse:1.97511\n",
      "[18293]\teval-rmse:3.8412\ttrain-rmse:1.97509\n",
      "[18294]\teval-rmse:3.84206\ttrain-rmse:1.97508\n",
      "[18295]\teval-rmse:3.84381\ttrain-rmse:1.97504\n",
      "[18296]\teval-rmse:3.84522\ttrain-rmse:1.97504\n",
      "[18297]\teval-rmse:3.84415\ttrain-rmse:1.97503\n",
      "[18298]\teval-rmse:3.84232\ttrain-rmse:1.97504\n",
      "[18299]\teval-rmse:3.84257\ttrain-rmse:1.97504\n",
      "[18300]\teval-rmse:3.84272\ttrain-rmse:1.97504\n",
      "[18301]\teval-rmse:3.84084\ttrain-rmse:1.97508\n",
      "[18302]\teval-rmse:3.84067\ttrain-rmse:1.97508\n",
      "[18303]\teval-rmse:3.84265\ttrain-rmse:1.97507\n",
      "[18304]\teval-rmse:3.8445\ttrain-rmse:1.97503\n",
      "[18305]\teval-rmse:3.84274\ttrain-rmse:1.97508\n",
      "[18306]\teval-rmse:3.84168\ttrain-rmse:1.97508\n",
      "[18307]\teval-rmse:3.8415\ttrain-rmse:1.97508\n",
      "[18308]\teval-rmse:3.84122\ttrain-rmse:1.97508\n",
      "[18309]\teval-rmse:3.8432\ttrain-rmse:1.97507\n",
      "[18310]\teval-rmse:3.84278\ttrain-rmse:1.97508\n",
      "[18311]\teval-rmse:3.84463\ttrain-rmse:1.97506\n",
      "[18312]\teval-rmse:3.84318\ttrain-rmse:1.9751\n",
      "[18313]\teval-rmse:3.84376\ttrain-rmse:1.9751\n",
      "[18314]\teval-rmse:3.84544\ttrain-rmse:1.97509\n",
      "[18315]\teval-rmse:3.84492\ttrain-rmse:1.97509\n",
      "[18316]\teval-rmse:3.84316\ttrain-rmse:1.97513\n",
      "[18317]\teval-rmse:3.84256\ttrain-rmse:1.97514\n",
      "[18318]\teval-rmse:3.84389\ttrain-rmse:1.97512\n",
      "[18319]\teval-rmse:3.84428\ttrain-rmse:1.97511\n",
      "[18320]\teval-rmse:3.84626\ttrain-rmse:1.97512\n",
      "[18321]\teval-rmse:3.84505\ttrain-rmse:1.97515\n",
      "[18322]\teval-rmse:3.84558\ttrain-rmse:1.97515\n",
      "[18323]\teval-rmse:3.84437\ttrain-rmse:1.97517\n",
      "[18324]\teval-rmse:3.84395\ttrain-rmse:1.97518\n",
      "[18325]\teval-rmse:3.84271\ttrain-rmse:1.97522\n",
      "[18326]\teval-rmse:3.84225\ttrain-rmse:1.97523\n",
      "[18327]\teval-rmse:3.84155\ttrain-rmse:1.97524\n",
      "[18328]\teval-rmse:3.84312\ttrain-rmse:1.97522\n",
      "[18329]\teval-rmse:3.84356\ttrain-rmse:1.9752\n",
      "[18330]\teval-rmse:3.84314\ttrain-rmse:1.97505\n",
      "[18331]\teval-rmse:3.84161\ttrain-rmse:1.97507\n",
      "[18332]\teval-rmse:3.8412\ttrain-rmse:1.97507\n",
      "[18333]\teval-rmse:3.84079\ttrain-rmse:1.97507\n",
      "[18334]\teval-rmse:3.84219\ttrain-rmse:1.97506\n",
      "[18335]\teval-rmse:3.84112\ttrain-rmse:1.97506\n",
      "[18336]\teval-rmse:3.84141\ttrain-rmse:1.97505\n",
      "[18337]\teval-rmse:3.84084\ttrain-rmse:1.97507\n",
      "[18338]\teval-rmse:3.83977\ttrain-rmse:1.97508\n",
      "[18339]\teval-rmse:3.84096\ttrain-rmse:1.97504\n",
      "[18340]\teval-rmse:3.84115\ttrain-rmse:1.97503\n",
      "[18341]\teval-rmse:3.8412\ttrain-rmse:1.97503\n",
      "[18342]\teval-rmse:3.84038\ttrain-rmse:1.97504\n",
      "[18343]\teval-rmse:3.84191\ttrain-rmse:1.97502\n",
      "[18344]\teval-rmse:3.84059\ttrain-rmse:1.97506\n",
      "[18345]\teval-rmse:3.84058\ttrain-rmse:1.97506\n",
      "[18346]\teval-rmse:3.83873\ttrain-rmse:1.97514\n",
      "[18347]\teval-rmse:3.8398\ttrain-rmse:1.9751\n",
      "[18348]\teval-rmse:3.8403\ttrain-rmse:1.97509\n",
      "[18349]\teval-rmse:3.84035\ttrain-rmse:1.97509\n",
      "[18350]\teval-rmse:3.83962\ttrain-rmse:1.9751\n",
      "[18351]\teval-rmse:3.83909\ttrain-rmse:1.97511\n",
      "[18352]\teval-rmse:3.84062\ttrain-rmse:1.97505\n",
      "[18353]\teval-rmse:3.84045\ttrain-rmse:1.97505\n",
      "[18354]\teval-rmse:3.8385\ttrain-rmse:1.97512\n",
      "[18355]\teval-rmse:3.84025\ttrain-rmse:1.97504\n",
      "[18356]\teval-rmse:3.84007\ttrain-rmse:1.97505\n",
      "[18357]\teval-rmse:3.83873\ttrain-rmse:1.9751\n",
      "[18358]\teval-rmse:3.83787\ttrain-rmse:1.97511\n",
      "[18359]\teval-rmse:3.83851\ttrain-rmse:1.9751\n",
      "[18360]\teval-rmse:3.83884\ttrain-rmse:1.97509\n",
      "[18361]\teval-rmse:3.83927\ttrain-rmse:1.97507\n",
      "[18362]\teval-rmse:3.84111\ttrain-rmse:1.97502\n",
      "[18363]\teval-rmse:3.83939\ttrain-rmse:1.97509\n",
      "[18364]\teval-rmse:3.83899\ttrain-rmse:1.97509\n",
      "[18365]\teval-rmse:3.83905\ttrain-rmse:1.97509\n",
      "[18366]\teval-rmse:3.8395\ttrain-rmse:1.97508\n",
      "[18367]\teval-rmse:3.83758\ttrain-rmse:1.97512\n",
      "[18368]\teval-rmse:3.83743\ttrain-rmse:1.97512\n",
      "[18369]\teval-rmse:3.83727\ttrain-rmse:1.97513\n",
      "[18370]\teval-rmse:3.83591\ttrain-rmse:1.97519\n",
      "[18371]\teval-rmse:3.83547\ttrain-rmse:1.9752\n",
      "[18372]\teval-rmse:3.83421\ttrain-rmse:1.97524\n",
      "[18373]\teval-rmse:3.83283\ttrain-rmse:1.9753\n",
      "[18374]\teval-rmse:3.83304\ttrain-rmse:1.97529\n",
      "[18375]\teval-rmse:3.8318\ttrain-rmse:1.97535\n",
      "[18376]\teval-rmse:3.83111\ttrain-rmse:1.97538\n",
      "[18377]\teval-rmse:3.83147\ttrain-rmse:1.97535\n",
      "[18378]\teval-rmse:3.83154\ttrain-rmse:1.97535\n",
      "[18379]\teval-rmse:3.83183\ttrain-rmse:1.97533\n",
      "[18380]\teval-rmse:3.83281\ttrain-rmse:1.97529\n",
      "[18381]\teval-rmse:3.83199\ttrain-rmse:1.97532\n",
      "[18382]\teval-rmse:3.83203\ttrain-rmse:1.97532\n",
      "[18383]\teval-rmse:3.83139\ttrain-rmse:1.97535\n",
      "[18384]\teval-rmse:3.83117\ttrain-rmse:1.97536\n",
      "[18385]\teval-rmse:3.82935\ttrain-rmse:1.97548\n",
      "[18386]\teval-rmse:3.83134\ttrain-rmse:1.97543\n",
      "[18387]\teval-rmse:3.83298\ttrain-rmse:1.97537\n",
      "[18388]\teval-rmse:3.83239\ttrain-rmse:1.97539\n",
      "[18389]\teval-rmse:3.83203\ttrain-rmse:1.97524\n",
      "[18390]\teval-rmse:3.83338\ttrain-rmse:1.97515\n",
      "[18391]\teval-rmse:3.83344\ttrain-rmse:1.97515\n",
      "[18392]\teval-rmse:3.83455\ttrain-rmse:1.97509\n",
      "[18393]\teval-rmse:3.83417\ttrain-rmse:1.97509\n",
      "[18394]\teval-rmse:3.83381\ttrain-rmse:1.9751\n",
      "[18395]\teval-rmse:3.83437\ttrain-rmse:1.97507\n",
      "[18396]\teval-rmse:3.83534\ttrain-rmse:1.97505\n",
      "[18397]\teval-rmse:3.83678\ttrain-rmse:1.97497\n",
      "[18398]\teval-rmse:3.83743\ttrain-rmse:1.97495\n",
      "[18399]\teval-rmse:3.83558\ttrain-rmse:1.97504\n",
      "[18400]\teval-rmse:3.83491\ttrain-rmse:1.97507\n",
      "[18401]\teval-rmse:3.83443\ttrain-rmse:1.97508\n",
      "[18402]\teval-rmse:3.83596\ttrain-rmse:1.97504\n",
      "[18403]\teval-rmse:3.83637\ttrain-rmse:1.97502\n",
      "[18404]\teval-rmse:3.83613\ttrain-rmse:1.97503\n",
      "[18405]\teval-rmse:3.83509\ttrain-rmse:1.97504\n",
      "[18406]\teval-rmse:3.83471\ttrain-rmse:1.97491\n",
      "[18407]\teval-rmse:3.83645\ttrain-rmse:1.97484\n",
      "[18408]\teval-rmse:3.83507\ttrain-rmse:1.97488\n",
      "[18409]\teval-rmse:3.83469\ttrain-rmse:1.97473\n",
      "[18410]\teval-rmse:3.83275\ttrain-rmse:1.97484\n",
      "[18411]\teval-rmse:3.83147\ttrain-rmse:1.97492\n",
      "[18412]\teval-rmse:3.83133\ttrain-rmse:1.97492\n",
      "[18413]\teval-rmse:3.83045\ttrain-rmse:1.97497\n",
      "[18414]\teval-rmse:3.83075\ttrain-rmse:1.97495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18415]\teval-rmse:3.8307\ttrain-rmse:1.97495\n",
      "[18416]\teval-rmse:3.8313\ttrain-rmse:1.97493\n",
      "[18417]\teval-rmse:3.83271\ttrain-rmse:1.97487\n",
      "[18418]\teval-rmse:3.83133\ttrain-rmse:1.97494\n",
      "[18419]\teval-rmse:3.83136\ttrain-rmse:1.97494\n",
      "[18420]\teval-rmse:3.831\ttrain-rmse:1.97495\n",
      "[18421]\teval-rmse:3.83243\ttrain-rmse:1.97488\n",
      "[18422]\teval-rmse:3.83377\ttrain-rmse:1.97482\n",
      "[18423]\teval-rmse:3.83353\ttrain-rmse:1.97482\n",
      "[18424]\teval-rmse:3.8333\ttrain-rmse:1.97483\n",
      "[18425]\teval-rmse:3.83163\ttrain-rmse:1.97488\n",
      "[18426]\teval-rmse:3.83121\ttrain-rmse:1.97491\n",
      "[18427]\teval-rmse:3.82935\ttrain-rmse:1.975\n",
      "[18428]\teval-rmse:3.82812\ttrain-rmse:1.97508\n",
      "[18429]\teval-rmse:3.82878\ttrain-rmse:1.97504\n",
      "[18430]\teval-rmse:3.82848\ttrain-rmse:1.97492\n",
      "[18431]\teval-rmse:3.83047\ttrain-rmse:1.97486\n",
      "[18432]\teval-rmse:3.8316\ttrain-rmse:1.97479\n",
      "[18433]\teval-rmse:3.83036\ttrain-rmse:1.97483\n",
      "[18434]\teval-rmse:3.83171\ttrain-rmse:1.97478\n",
      "[18435]\teval-rmse:3.83268\ttrain-rmse:1.97472\n",
      "[18436]\teval-rmse:3.83296\ttrain-rmse:1.97471\n",
      "[18437]\teval-rmse:3.83136\ttrain-rmse:1.97476\n",
      "[18438]\teval-rmse:3.8295\ttrain-rmse:1.97487\n",
      "[18439]\teval-rmse:3.82869\ttrain-rmse:1.97493\n",
      "[18440]\teval-rmse:3.82899\ttrain-rmse:1.9749\n",
      "[18441]\teval-rmse:3.82944\ttrain-rmse:1.97488\n",
      "[18442]\teval-rmse:3.82804\ttrain-rmse:1.97497\n",
      "[18443]\teval-rmse:3.82879\ttrain-rmse:1.97492\n",
      "[18444]\teval-rmse:3.83056\ttrain-rmse:1.97483\n",
      "[18445]\teval-rmse:3.83227\ttrain-rmse:1.97475\n",
      "[18446]\teval-rmse:3.83045\ttrain-rmse:1.97486\n",
      "[18447]\teval-rmse:3.829\ttrain-rmse:1.97492\n",
      "[18448]\teval-rmse:3.83042\ttrain-rmse:1.97484\n",
      "[18449]\teval-rmse:3.83007\ttrain-rmse:1.97485\n",
      "[18450]\teval-rmse:3.82984\ttrain-rmse:1.97486\n",
      "[18451]\teval-rmse:3.82971\ttrain-rmse:1.97485\n",
      "[18452]\teval-rmse:3.83032\ttrain-rmse:1.97482\n",
      "[18453]\teval-rmse:3.83078\ttrain-rmse:1.97479\n",
      "[18454]\teval-rmse:3.83253\ttrain-rmse:1.9747\n",
      "[18455]\teval-rmse:3.83314\ttrain-rmse:1.97467\n",
      "[18456]\teval-rmse:3.83447\ttrain-rmse:1.97463\n",
      "[18457]\teval-rmse:3.83286\ttrain-rmse:1.97469\n",
      "[18458]\teval-rmse:3.83397\ttrain-rmse:1.97463\n",
      "[18459]\teval-rmse:3.83328\ttrain-rmse:1.97465\n",
      "[18460]\teval-rmse:3.83527\ttrain-rmse:1.97461\n",
      "[18461]\teval-rmse:3.83586\ttrain-rmse:1.97458\n",
      "[18462]\teval-rmse:3.8356\ttrain-rmse:1.97459\n",
      "[18463]\teval-rmse:3.83412\ttrain-rmse:1.97463\n",
      "[18464]\teval-rmse:3.83508\ttrain-rmse:1.97459\n",
      "[18465]\teval-rmse:3.83483\ttrain-rmse:1.97459\n",
      "[18466]\teval-rmse:3.83682\ttrain-rmse:1.97456\n",
      "[18467]\teval-rmse:3.83879\ttrain-rmse:1.97454\n",
      "[18468]\teval-rmse:3.8384\ttrain-rmse:1.97454\n",
      "[18469]\teval-rmse:3.83971\ttrain-rmse:1.97452\n",
      "[18470]\teval-rmse:3.84045\ttrain-rmse:1.9745\n",
      "[18471]\teval-rmse:3.84169\ttrain-rmse:1.97448\n",
      "[18472]\teval-rmse:3.83953\ttrain-rmse:1.97454\n",
      "[18473]\teval-rmse:3.8407\ttrain-rmse:1.97449\n",
      "[18474]\teval-rmse:3.83896\ttrain-rmse:1.97452\n",
      "[18475]\teval-rmse:3.83869\ttrain-rmse:1.97453\n",
      "[18476]\teval-rmse:3.83939\ttrain-rmse:1.9745\n",
      "[18477]\teval-rmse:3.84058\ttrain-rmse:1.97447\n",
      "[18478]\teval-rmse:3.84137\ttrain-rmse:1.97444\n",
      "[18479]\teval-rmse:3.8399\ttrain-rmse:1.97449\n",
      "[18480]\teval-rmse:3.84016\ttrain-rmse:1.97448\n",
      "[18481]\teval-rmse:3.83846\ttrain-rmse:1.97452\n",
      "[18482]\teval-rmse:3.83687\ttrain-rmse:1.97456\n",
      "[18483]\teval-rmse:3.83653\ttrain-rmse:1.97442\n",
      "[18484]\teval-rmse:3.83685\ttrain-rmse:1.9744\n",
      "[18485]\teval-rmse:3.83628\ttrain-rmse:1.97443\n",
      "[18486]\teval-rmse:3.83603\ttrain-rmse:1.97443\n",
      "[18487]\teval-rmse:3.83666\ttrain-rmse:1.97442\n",
      "[18488]\teval-rmse:3.83632\ttrain-rmse:1.97428\n",
      "[18489]\teval-rmse:3.83456\ttrain-rmse:1.97434\n",
      "[18490]\teval-rmse:3.83618\ttrain-rmse:1.97427\n",
      "[18491]\teval-rmse:3.83755\ttrain-rmse:1.97423\n",
      "[18492]\teval-rmse:3.83606\ttrain-rmse:1.97428\n",
      "[18493]\teval-rmse:3.83464\ttrain-rmse:1.97435\n",
      "[18494]\teval-rmse:3.83622\ttrain-rmse:1.97427\n",
      "[18495]\teval-rmse:3.83767\ttrain-rmse:1.97421\n",
      "[18496]\teval-rmse:3.83599\ttrain-rmse:1.97425\n",
      "[18497]\teval-rmse:3.8346\ttrain-rmse:1.97431\n",
      "[18498]\teval-rmse:3.83512\ttrain-rmse:1.97428\n",
      "[18499]\teval-rmse:3.83552\ttrain-rmse:1.97426\n",
      "[18500]\teval-rmse:3.83708\ttrain-rmse:1.9742\n",
      "[18501]\teval-rmse:3.83682\ttrain-rmse:1.9742\n",
      "[18502]\teval-rmse:3.83597\ttrain-rmse:1.97423\n",
      "[18503]\teval-rmse:3.83628\ttrain-rmse:1.97422\n",
      "[18504]\teval-rmse:3.83742\ttrain-rmse:1.97418\n",
      "[18505]\teval-rmse:3.83705\ttrain-rmse:1.97418\n",
      "[18506]\teval-rmse:3.83838\ttrain-rmse:1.97415\n",
      "[18507]\teval-rmse:3.83786\ttrain-rmse:1.97416\n",
      "[18508]\teval-rmse:3.83718\ttrain-rmse:1.97418\n",
      "[18509]\teval-rmse:3.83832\ttrain-rmse:1.97414\n",
      "[18510]\teval-rmse:3.83887\ttrain-rmse:1.97413\n",
      "[18511]\teval-rmse:3.8402\ttrain-rmse:1.97411\n",
      "[18512]\teval-rmse:3.83891\ttrain-rmse:1.97415\n",
      "[18513]\teval-rmse:3.83851\ttrain-rmse:1.97415\n",
      "[18514]\teval-rmse:3.83878\ttrain-rmse:1.97414\n",
      "[18515]\teval-rmse:3.83732\ttrain-rmse:1.97417\n",
      "[18516]\teval-rmse:3.83664\ttrain-rmse:1.97419\n",
      "[18517]\teval-rmse:3.83451\ttrain-rmse:1.97424\n",
      "[18518]\teval-rmse:3.83575\ttrain-rmse:1.97421\n",
      "[18519]\teval-rmse:3.83439\ttrain-rmse:1.97427\n",
      "[18520]\teval-rmse:3.83356\ttrain-rmse:1.97429\n",
      "[18521]\teval-rmse:3.83423\ttrain-rmse:1.97426\n",
      "[18522]\teval-rmse:3.83444\ttrain-rmse:1.97426\n",
      "[18523]\teval-rmse:3.83365\ttrain-rmse:1.97428\n",
      "[18524]\teval-rmse:3.83417\ttrain-rmse:1.97426\n",
      "[18525]\teval-rmse:3.83281\ttrain-rmse:1.97433\n",
      "[18526]\teval-rmse:3.83327\ttrain-rmse:1.97431\n",
      "[18527]\teval-rmse:3.83524\ttrain-rmse:1.97425\n",
      "[18528]\teval-rmse:3.83486\ttrain-rmse:1.97411\n",
      "[18529]\teval-rmse:3.83471\ttrain-rmse:1.97411\n",
      "[18530]\teval-rmse:3.83558\ttrain-rmse:1.97409\n",
      "[18531]\teval-rmse:3.83488\ttrain-rmse:1.97411\n",
      "[18532]\teval-rmse:3.83405\ttrain-rmse:1.97413\n",
      "[18533]\teval-rmse:3.83603\ttrain-rmse:1.9741\n",
      "[18534]\teval-rmse:3.83646\ttrain-rmse:1.97408\n",
      "[18535]\teval-rmse:3.83709\ttrain-rmse:1.97406\n",
      "[18536]\teval-rmse:3.83706\ttrain-rmse:1.97406\n",
      "[18537]\teval-rmse:3.83578\ttrain-rmse:1.9741\n",
      "[18538]\teval-rmse:3.83553\ttrain-rmse:1.97411\n",
      "[18539]\teval-rmse:3.83414\ttrain-rmse:1.97416\n",
      "[18540]\teval-rmse:3.83599\ttrain-rmse:1.97411\n",
      "[18541]\teval-rmse:3.83655\ttrain-rmse:1.97409\n",
      "[18542]\teval-rmse:3.83551\ttrain-rmse:1.97411\n",
      "[18543]\teval-rmse:3.835\ttrain-rmse:1.97412\n",
      "[18544]\teval-rmse:3.83698\ttrain-rmse:1.9741\n",
      "[18545]\teval-rmse:3.83659\ttrain-rmse:1.97411\n",
      "[18546]\teval-rmse:3.83821\ttrain-rmse:1.97407\n",
      "[18547]\teval-rmse:3.83982\ttrain-rmse:1.97405\n",
      "[18548]\teval-rmse:3.84029\ttrain-rmse:1.97405\n",
      "[18549]\teval-rmse:3.84055\ttrain-rmse:1.97404\n",
      "[18550]\teval-rmse:3.84076\ttrain-rmse:1.97404\n",
      "[18551]\teval-rmse:3.84126\ttrain-rmse:1.97403\n",
      "[18552]\teval-rmse:3.83952\ttrain-rmse:1.97405\n",
      "[18553]\teval-rmse:3.84125\ttrain-rmse:1.97403\n",
      "[18554]\teval-rmse:3.84089\ttrain-rmse:1.97391\n",
      "[18555]\teval-rmse:3.84\ttrain-rmse:1.97392\n",
      "[18556]\teval-rmse:3.83982\ttrain-rmse:1.97392\n",
      "[18557]\teval-rmse:3.84179\ttrain-rmse:1.97392\n",
      "[18558]\teval-rmse:3.84264\ttrain-rmse:1.97391\n",
      "[18559]\teval-rmse:3.84103\ttrain-rmse:1.97393\n",
      "[18560]\teval-rmse:3.83952\ttrain-rmse:1.97397\n",
      "[18561]\teval-rmse:3.84062\ttrain-rmse:1.97395\n",
      "[18562]\teval-rmse:3.83897\ttrain-rmse:1.974\n",
      "[18563]\teval-rmse:3.83757\ttrain-rmse:1.97403\n",
      "[18564]\teval-rmse:3.83571\ttrain-rmse:1.97411\n",
      "[18565]\teval-rmse:3.83532\ttrain-rmse:1.97412\n",
      "[18566]\teval-rmse:3.83494\ttrain-rmse:1.97412\n",
      "[18567]\teval-rmse:3.8361\ttrain-rmse:1.97407\n",
      "[18568]\teval-rmse:3.83478\ttrain-rmse:1.97411\n",
      "[18569]\teval-rmse:3.83509\ttrain-rmse:1.9741\n",
      "[18570]\teval-rmse:3.83561\ttrain-rmse:1.97408\n",
      "[18571]\teval-rmse:3.8351\ttrain-rmse:1.9741\n",
      "[18572]\teval-rmse:3.83584\ttrain-rmse:1.97406\n",
      "[18573]\teval-rmse:3.8348\ttrain-rmse:1.97408\n",
      "[18574]\teval-rmse:3.83477\ttrain-rmse:1.97408\n",
      "[18575]\teval-rmse:3.83652\ttrain-rmse:1.97401\n",
      "[18576]\teval-rmse:3.83635\ttrain-rmse:1.97402\n",
      "[18577]\teval-rmse:3.83791\ttrain-rmse:1.97398\n",
      "[18578]\teval-rmse:3.83969\ttrain-rmse:1.97395\n",
      "[18579]\teval-rmse:3.83811\ttrain-rmse:1.97398\n",
      "[18580]\teval-rmse:3.83878\ttrain-rmse:1.97395\n",
      "[18581]\teval-rmse:3.83902\ttrain-rmse:1.97394\n",
      "[18582]\teval-rmse:3.84054\ttrain-rmse:1.97392\n",
      "[18583]\teval-rmse:3.84149\ttrain-rmse:1.97389\n",
      "[18584]\teval-rmse:3.84109\ttrain-rmse:1.97389\n",
      "[18585]\teval-rmse:3.83957\ttrain-rmse:1.97392\n",
      "[18586]\teval-rmse:3.84131\ttrain-rmse:1.97387\n",
      "[18587]\teval-rmse:3.83987\ttrain-rmse:1.97391\n",
      "[18588]\teval-rmse:3.83946\ttrain-rmse:1.97392\n",
      "[18589]\teval-rmse:3.84042\ttrain-rmse:1.9739\n",
      "[18590]\teval-rmse:3.83935\ttrain-rmse:1.97391\n",
      "[18591]\teval-rmse:3.83829\ttrain-rmse:1.97392\n",
      "[18592]\teval-rmse:3.83767\ttrain-rmse:1.97394\n",
      "[18593]\teval-rmse:3.83964\ttrain-rmse:1.97392\n",
      "[18594]\teval-rmse:3.83898\ttrain-rmse:1.97395\n",
      "[18595]\teval-rmse:3.83747\ttrain-rmse:1.97398\n",
      "[18596]\teval-rmse:3.8387\ttrain-rmse:1.97395\n",
      "[18597]\teval-rmse:3.83742\ttrain-rmse:1.97399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18598]\teval-rmse:3.83921\ttrain-rmse:1.97395\n",
      "[18599]\teval-rmse:3.83904\ttrain-rmse:1.97395\n",
      "[18600]\teval-rmse:3.83982\ttrain-rmse:1.97393\n",
      "[18601]\teval-rmse:3.83912\ttrain-rmse:1.97396\n",
      "[18602]\teval-rmse:3.83999\ttrain-rmse:1.97394\n",
      "[18603]\teval-rmse:3.83847\ttrain-rmse:1.97397\n",
      "[18604]\teval-rmse:3.837\ttrain-rmse:1.97401\n",
      "[18605]\teval-rmse:3.83751\ttrain-rmse:1.97399\n",
      "[18606]\teval-rmse:3.83847\ttrain-rmse:1.97396\n",
      "[18607]\teval-rmse:3.83656\ttrain-rmse:1.97401\n",
      "[18608]\teval-rmse:3.83652\ttrain-rmse:1.97401\n",
      "[18609]\teval-rmse:3.83822\ttrain-rmse:1.97394\n",
      "[18610]\teval-rmse:3.83666\ttrain-rmse:1.97398\n",
      "[18611]\teval-rmse:3.83715\ttrain-rmse:1.97395\n",
      "[18612]\teval-rmse:3.83767\ttrain-rmse:1.97394\n",
      "[18613]\teval-rmse:3.83595\ttrain-rmse:1.97399\n",
      "[18614]\teval-rmse:3.83468\ttrain-rmse:1.97402\n",
      "[18615]\teval-rmse:3.83386\ttrain-rmse:1.97405\n",
      "[18616]\teval-rmse:3.83538\ttrain-rmse:1.974\n",
      "[18617]\teval-rmse:3.83717\ttrain-rmse:1.97395\n",
      "[18618]\teval-rmse:3.83692\ttrain-rmse:1.97396\n",
      "[18619]\teval-rmse:3.83654\ttrain-rmse:1.97396\n",
      "[18620]\teval-rmse:3.83629\ttrain-rmse:1.97396\n",
      "[18621]\teval-rmse:3.83803\ttrain-rmse:1.9739\n",
      "[18622]\teval-rmse:3.83927\ttrain-rmse:1.97385\n",
      "[18623]\teval-rmse:3.8411\ttrain-rmse:1.9738\n",
      "[18624]\teval-rmse:3.84177\ttrain-rmse:1.97379\n",
      "[18625]\teval-rmse:3.84227\ttrain-rmse:1.97378\n",
      "[18626]\teval-rmse:3.84144\ttrain-rmse:1.9738\n",
      "[18627]\teval-rmse:3.83974\ttrain-rmse:1.97383\n",
      "[18628]\teval-rmse:3.84042\ttrain-rmse:1.97381\n",
      "[18629]\teval-rmse:3.83989\ttrain-rmse:1.97383\n",
      "[18630]\teval-rmse:3.8382\ttrain-rmse:1.97386\n",
      "[18631]\teval-rmse:3.83758\ttrain-rmse:1.97388\n",
      "[18632]\teval-rmse:3.83582\ttrain-rmse:1.97395\n",
      "[18633]\teval-rmse:3.83516\ttrain-rmse:1.97398\n",
      "[18634]\teval-rmse:3.83675\ttrain-rmse:1.97391\n",
      "[18635]\teval-rmse:3.83837\ttrain-rmse:1.97385\n",
      "[18636]\teval-rmse:3.83905\ttrain-rmse:1.97383\n",
      "[18637]\teval-rmse:3.83969\ttrain-rmse:1.97381\n",
      "[18638]\teval-rmse:3.83819\ttrain-rmse:1.97385\n",
      "[18639]\teval-rmse:3.83673\ttrain-rmse:1.97391\n",
      "[18640]\teval-rmse:3.83751\ttrain-rmse:1.97387\n",
      "[18641]\teval-rmse:3.83566\ttrain-rmse:1.97396\n",
      "[18642]\teval-rmse:3.83596\ttrain-rmse:1.97395\n",
      "[18643]\teval-rmse:3.83616\ttrain-rmse:1.97394\n",
      "[18644]\teval-rmse:3.83776\ttrain-rmse:1.97389\n",
      "[18645]\teval-rmse:3.83892\ttrain-rmse:1.97385\n",
      "[18646]\teval-rmse:3.84057\ttrain-rmse:1.97381\n",
      "[18647]\teval-rmse:3.83937\ttrain-rmse:1.97385\n",
      "[18648]\teval-rmse:3.83988\ttrain-rmse:1.97383\n",
      "[18649]\teval-rmse:3.84137\ttrain-rmse:1.9738\n",
      "[18650]\teval-rmse:3.84134\ttrain-rmse:1.9738\n",
      "[18651]\teval-rmse:3.83964\ttrain-rmse:1.97383\n",
      "[18652]\teval-rmse:3.84115\ttrain-rmse:1.9738\n",
      "[18653]\teval-rmse:3.84182\ttrain-rmse:1.97379\n",
      "[18654]\teval-rmse:3.84043\ttrain-rmse:1.97382\n",
      "[18655]\teval-rmse:3.84117\ttrain-rmse:1.9738\n",
      "[18656]\teval-rmse:3.84278\ttrain-rmse:1.97378\n",
      "[18657]\teval-rmse:3.8425\ttrain-rmse:1.97378\n",
      "[18658]\teval-rmse:3.84447\ttrain-rmse:1.97378\n",
      "[18659]\teval-rmse:3.84454\ttrain-rmse:1.97378\n",
      "[18660]\teval-rmse:3.84651\ttrain-rmse:1.97379\n",
      "[18661]\teval-rmse:3.84745\ttrain-rmse:1.97378\n",
      "[18662]\teval-rmse:3.84701\ttrain-rmse:1.97379\n",
      "[18663]\teval-rmse:3.84528\ttrain-rmse:1.9738\n",
      "[18664]\teval-rmse:3.84384\ttrain-rmse:1.97383\n",
      "[18665]\teval-rmse:3.84355\ttrain-rmse:1.97383\n",
      "[18666]\teval-rmse:3.84551\ttrain-rmse:1.97383\n",
      "[18667]\teval-rmse:3.84443\ttrain-rmse:1.97383\n",
      "[18668]\teval-rmse:3.84516\ttrain-rmse:1.97382\n",
      "[18669]\teval-rmse:3.84536\ttrain-rmse:1.97382\n",
      "[18670]\teval-rmse:3.84665\ttrain-rmse:1.97381\n",
      "[18671]\teval-rmse:3.84527\ttrain-rmse:1.97384\n",
      "[18672]\teval-rmse:3.84549\ttrain-rmse:1.97383\n",
      "[18673]\teval-rmse:3.8448\ttrain-rmse:1.97383\n",
      "[18674]\teval-rmse:3.84537\ttrain-rmse:1.97383\n",
      "[18675]\teval-rmse:3.84622\ttrain-rmse:1.97382\n",
      "[18676]\teval-rmse:3.84755\ttrain-rmse:1.97382\n",
      "[18677]\teval-rmse:3.84901\ttrain-rmse:1.9738\n",
      "[18678]\teval-rmse:3.84857\ttrain-rmse:1.9738\n",
      "[18679]\teval-rmse:3.84733\ttrain-rmse:1.97381\n",
      "[18680]\teval-rmse:3.84894\ttrain-rmse:1.97381\n",
      "[18681]\teval-rmse:3.84862\ttrain-rmse:1.97381\n",
      "[18682]\teval-rmse:3.84898\ttrain-rmse:1.97381\n",
      "[18683]\teval-rmse:3.84725\ttrain-rmse:1.97382\n",
      "[18684]\teval-rmse:3.84898\ttrain-rmse:1.97382\n",
      "[18685]\teval-rmse:3.84855\ttrain-rmse:1.97382\n",
      "[18686]\teval-rmse:3.84731\ttrain-rmse:1.97383\n",
      "[18687]\teval-rmse:3.84859\ttrain-rmse:1.97382\n",
      "[18688]\teval-rmse:3.84748\ttrain-rmse:1.97381\n",
      "[18689]\teval-rmse:3.8491\ttrain-rmse:1.97382\n",
      "[18690]\teval-rmse:3.85106\ttrain-rmse:1.97385\n",
      "[18691]\teval-rmse:3.8501\ttrain-rmse:1.97384\n",
      "[18692]\teval-rmse:3.85033\ttrain-rmse:1.97384\n",
      "[18693]\teval-rmse:3.8504\ttrain-rmse:1.97384\n",
      "[18694]\teval-rmse:3.85019\ttrain-rmse:1.97384\n",
      "[18695]\teval-rmse:3.85068\ttrain-rmse:1.97384\n",
      "[18696]\teval-rmse:3.85217\ttrain-rmse:1.97386\n",
      "[18697]\teval-rmse:3.85155\ttrain-rmse:1.97385\n",
      "[18698]\teval-rmse:3.85025\ttrain-rmse:1.97386\n",
      "[18699]\teval-rmse:3.85073\ttrain-rmse:1.97386\n",
      "[18700]\teval-rmse:3.8504\ttrain-rmse:1.97385\n",
      "[18701]\teval-rmse:3.84929\ttrain-rmse:1.97384\n",
      "[18702]\teval-rmse:3.84861\ttrain-rmse:1.97385\n",
      "[18703]\teval-rmse:3.84709\ttrain-rmse:1.97385\n",
      "[18704]\teval-rmse:3.84541\ttrain-rmse:1.97385\n",
      "[18705]\teval-rmse:3.84347\ttrain-rmse:1.97388\n",
      "[18706]\teval-rmse:3.84505\ttrain-rmse:1.97385\n",
      "[18707]\teval-rmse:3.84464\ttrain-rmse:1.97385\n",
      "[18708]\teval-rmse:3.84531\ttrain-rmse:1.97384\n",
      "[18709]\teval-rmse:3.84705\ttrain-rmse:1.97384\n",
      "[18710]\teval-rmse:3.84648\ttrain-rmse:1.97384\n",
      "[18711]\teval-rmse:3.84755\ttrain-rmse:1.97383\n",
      "[18712]\teval-rmse:3.84831\ttrain-rmse:1.97384\n",
      "[18713]\teval-rmse:3.84702\ttrain-rmse:1.97384\n",
      "[18714]\teval-rmse:3.84632\ttrain-rmse:1.97384\n",
      "[18715]\teval-rmse:3.84592\ttrain-rmse:1.97371\n",
      "[18716]\teval-rmse:3.84621\ttrain-rmse:1.97371\n",
      "[18717]\teval-rmse:3.846\ttrain-rmse:1.97371\n",
      "[18718]\teval-rmse:3.84544\ttrain-rmse:1.97372\n",
      "[18719]\teval-rmse:3.84583\ttrain-rmse:1.97372\n",
      "[18720]\teval-rmse:3.84541\ttrain-rmse:1.97372\n",
      "[18721]\teval-rmse:3.84382\ttrain-rmse:1.97374\n",
      "[18722]\teval-rmse:3.8422\ttrain-rmse:1.97375\n",
      "[18723]\teval-rmse:3.84277\ttrain-rmse:1.97375\n",
      "[18724]\teval-rmse:3.84236\ttrain-rmse:1.97361\n",
      "[18725]\teval-rmse:3.84016\ttrain-rmse:1.97363\n",
      "[18726]\teval-rmse:3.84021\ttrain-rmse:1.97363\n",
      "[18727]\teval-rmse:3.84116\ttrain-rmse:1.9736\n",
      "[18728]\teval-rmse:3.84052\ttrain-rmse:1.97362\n",
      "[18729]\teval-rmse:3.83989\ttrain-rmse:1.97364\n",
      "[18730]\teval-rmse:3.83917\ttrain-rmse:1.97365\n",
      "[18731]\teval-rmse:3.83792\ttrain-rmse:1.97369\n",
      "[18732]\teval-rmse:3.83831\ttrain-rmse:1.97368\n",
      "[18733]\teval-rmse:3.83703\ttrain-rmse:1.97371\n",
      "[18734]\teval-rmse:3.83518\ttrain-rmse:1.97375\n",
      "[18735]\teval-rmse:3.83473\ttrain-rmse:1.97376\n",
      "[18736]\teval-rmse:3.83532\ttrain-rmse:1.97374\n",
      "[18737]\teval-rmse:3.83575\ttrain-rmse:1.97372\n",
      "[18738]\teval-rmse:3.83434\ttrain-rmse:1.97379\n",
      "[18739]\teval-rmse:3.83374\ttrain-rmse:1.97381\n",
      "[18740]\teval-rmse:3.83324\ttrain-rmse:1.97383\n",
      "[18741]\teval-rmse:3.83309\ttrain-rmse:1.97383\n",
      "[18742]\teval-rmse:3.83173\ttrain-rmse:1.97388\n",
      "[18743]\teval-rmse:3.83262\ttrain-rmse:1.97385\n",
      "[18744]\teval-rmse:3.83225\ttrain-rmse:1.97372\n",
      "[18745]\teval-rmse:3.83304\ttrain-rmse:1.97369\n",
      "[18746]\teval-rmse:3.83288\ttrain-rmse:1.97369\n",
      "[18747]\teval-rmse:3.83306\ttrain-rmse:1.97368\n",
      "[18748]\teval-rmse:3.83503\ttrain-rmse:1.97365\n",
      "[18749]\teval-rmse:3.83343\ttrain-rmse:1.97373\n",
      "[18750]\teval-rmse:3.83306\ttrain-rmse:1.97375\n",
      "[18751]\teval-rmse:3.83414\ttrain-rmse:1.97369\n",
      "[18752]\teval-rmse:3.83298\ttrain-rmse:1.97373\n",
      "[18753]\teval-rmse:3.83169\ttrain-rmse:1.9738\n",
      "[18754]\teval-rmse:3.83028\ttrain-rmse:1.97389\n",
      "[18755]\teval-rmse:3.82991\ttrain-rmse:1.97391\n",
      "[18756]\teval-rmse:3.83039\ttrain-rmse:1.97388\n",
      "[18757]\teval-rmse:3.83179\ttrain-rmse:1.9738\n",
      "[18758]\teval-rmse:3.83293\ttrain-rmse:1.97373\n",
      "[18759]\teval-rmse:3.83268\ttrain-rmse:1.97373\n",
      "[18760]\teval-rmse:3.83279\ttrain-rmse:1.97373\n",
      "[18761]\teval-rmse:3.83304\ttrain-rmse:1.97371\n",
      "[18762]\teval-rmse:3.83415\ttrain-rmse:1.97367\n",
      "[18763]\teval-rmse:3.83254\ttrain-rmse:1.97376\n",
      "[18764]\teval-rmse:3.83453\ttrain-rmse:1.97372\n",
      "[18765]\teval-rmse:3.83623\ttrain-rmse:1.97364\n",
      "[18766]\teval-rmse:3.83607\ttrain-rmse:1.97364\n",
      "[18767]\teval-rmse:3.83504\ttrain-rmse:1.97365\n",
      "[18768]\teval-rmse:3.83616\ttrain-rmse:1.9736\n",
      "[18769]\teval-rmse:3.83779\ttrain-rmse:1.97356\n",
      "[18770]\teval-rmse:3.83834\ttrain-rmse:1.97355\n",
      "[18771]\teval-rmse:3.8388\ttrain-rmse:1.97354\n",
      "[18772]\teval-rmse:3.83712\ttrain-rmse:1.9736\n",
      "[18773]\teval-rmse:3.83753\ttrain-rmse:1.97358\n",
      "[18774]\teval-rmse:3.83708\ttrain-rmse:1.97359\n",
      "[18775]\teval-rmse:3.83817\ttrain-rmse:1.97355\n",
      "[18776]\teval-rmse:3.8367\ttrain-rmse:1.97358\n",
      "[18777]\teval-rmse:3.83794\ttrain-rmse:1.97355\n",
      "[18778]\teval-rmse:3.83647\ttrain-rmse:1.97359\n",
      "[18779]\teval-rmse:3.83711\ttrain-rmse:1.97358\n",
      "[18780]\teval-rmse:3.83837\ttrain-rmse:1.97355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18781]\teval-rmse:3.84011\ttrain-rmse:1.9735\n",
      "[18782]\teval-rmse:3.83792\ttrain-rmse:1.97354\n",
      "[18783]\teval-rmse:3.83775\ttrain-rmse:1.97354\n",
      "[18784]\teval-rmse:3.83779\ttrain-rmse:1.97354\n",
      "[18785]\teval-rmse:3.83977\ttrain-rmse:1.97353\n",
      "[18786]\teval-rmse:3.8401\ttrain-rmse:1.97352\n",
      "[18787]\teval-rmse:3.84167\ttrain-rmse:1.97347\n",
      "[18788]\teval-rmse:3.84219\ttrain-rmse:1.97346\n",
      "[18789]\teval-rmse:3.84285\ttrain-rmse:1.97346\n",
      "[18790]\teval-rmse:3.84375\ttrain-rmse:1.97344\n",
      "[18791]\teval-rmse:3.84216\ttrain-rmse:1.97346\n",
      "[18792]\teval-rmse:3.84365\ttrain-rmse:1.97343\n",
      "[18793]\teval-rmse:3.84497\ttrain-rmse:1.9734\n",
      "[18794]\teval-rmse:3.84591\ttrain-rmse:1.97339\n",
      "[18795]\teval-rmse:3.84714\ttrain-rmse:1.97339\n",
      "[18796]\teval-rmse:3.84515\ttrain-rmse:1.97341\n",
      "[18797]\teval-rmse:3.84336\ttrain-rmse:1.97345\n",
      "[18798]\teval-rmse:3.84308\ttrain-rmse:1.97345\n",
      "[18799]\teval-rmse:3.84339\ttrain-rmse:1.97344\n",
      "[18800]\teval-rmse:3.84513\ttrain-rmse:1.97341\n",
      "[18801]\teval-rmse:3.84333\ttrain-rmse:1.97345\n",
      "[18802]\teval-rmse:3.84484\ttrain-rmse:1.97345\n",
      "[18803]\teval-rmse:3.84454\ttrain-rmse:1.97344\n",
      "[18804]\teval-rmse:3.844\ttrain-rmse:1.97345\n",
      "[18805]\teval-rmse:3.84363\ttrain-rmse:1.97331\n",
      "[18806]\teval-rmse:3.84197\ttrain-rmse:1.97332\n",
      "[18807]\teval-rmse:3.84046\ttrain-rmse:1.97335\n",
      "[18808]\teval-rmse:3.83868\ttrain-rmse:1.97339\n",
      "[18809]\teval-rmse:3.83907\ttrain-rmse:1.97337\n",
      "[18810]\teval-rmse:3.8371\ttrain-rmse:1.97345\n",
      "[18811]\teval-rmse:3.83879\ttrain-rmse:1.97341\n",
      "[18812]\teval-rmse:3.83746\ttrain-rmse:1.97344\n",
      "[18813]\teval-rmse:3.83641\ttrain-rmse:1.97345\n",
      "[18814]\teval-rmse:3.83457\ttrain-rmse:1.97354\n",
      "[18815]\teval-rmse:3.83397\ttrain-rmse:1.97357\n",
      "[18816]\teval-rmse:3.83371\ttrain-rmse:1.97357\n",
      "[18817]\teval-rmse:3.83435\ttrain-rmse:1.97355\n",
      "[18818]\teval-rmse:3.8342\ttrain-rmse:1.97355\n",
      "[18819]\teval-rmse:3.83595\ttrain-rmse:1.97348\n",
      "[18820]\teval-rmse:3.8365\ttrain-rmse:1.97346\n",
      "[18821]\teval-rmse:3.83665\ttrain-rmse:1.97345\n",
      "[18822]\teval-rmse:3.83582\ttrain-rmse:1.97347\n",
      "[18823]\teval-rmse:3.83533\ttrain-rmse:1.97349\n",
      "[18824]\teval-rmse:3.83707\ttrain-rmse:1.97343\n",
      "[18825]\teval-rmse:3.83524\ttrain-rmse:1.9735\n",
      "[18826]\teval-rmse:3.83486\ttrain-rmse:1.9735\n",
      "[18827]\teval-rmse:3.83449\ttrain-rmse:1.97351\n",
      "[18828]\teval-rmse:3.83417\ttrain-rmse:1.97337\n",
      "[18829]\teval-rmse:3.8338\ttrain-rmse:1.97324\n",
      "[18830]\teval-rmse:3.83242\ttrain-rmse:1.97329\n",
      "[18831]\teval-rmse:3.83426\ttrain-rmse:1.97322\n",
      "[18832]\teval-rmse:3.83389\ttrain-rmse:1.97322\n",
      "[18833]\teval-rmse:3.83373\ttrain-rmse:1.97322\n",
      "[18834]\teval-rmse:3.83181\ttrain-rmse:1.97332\n",
      "[18835]\teval-rmse:3.83311\ttrain-rmse:1.97328\n",
      "[18836]\teval-rmse:3.83362\ttrain-rmse:1.97325\n",
      "[18837]\teval-rmse:3.83217\ttrain-rmse:1.9733\n",
      "[18838]\teval-rmse:3.83414\ttrain-rmse:1.97327\n",
      "[18839]\teval-rmse:3.83532\ttrain-rmse:1.97323\n",
      "[18840]\teval-rmse:3.83596\ttrain-rmse:1.97321\n",
      "[18841]\teval-rmse:3.83643\ttrain-rmse:1.9732\n",
      "[18842]\teval-rmse:3.83738\ttrain-rmse:1.97317\n",
      "[18843]\teval-rmse:3.83868\ttrain-rmse:1.97314\n",
      "[18844]\teval-rmse:3.83684\ttrain-rmse:1.9732\n",
      "[18845]\teval-rmse:3.83646\ttrain-rmse:1.97307\n",
      "[18846]\teval-rmse:3.83606\ttrain-rmse:1.97308\n",
      "[18847]\teval-rmse:3.83579\ttrain-rmse:1.97308\n",
      "[18848]\teval-rmse:3.8363\ttrain-rmse:1.97305\n",
      "[18849]\teval-rmse:3.83576\ttrain-rmse:1.97308\n",
      "[18850]\teval-rmse:3.8362\ttrain-rmse:1.97307\n",
      "[18851]\teval-rmse:3.83688\ttrain-rmse:1.97305\n",
      "[18852]\teval-rmse:3.83691\ttrain-rmse:1.97305\n",
      "[18853]\teval-rmse:3.83842\ttrain-rmse:1.97298\n",
      "[18854]\teval-rmse:3.84004\ttrain-rmse:1.97296\n",
      "[18855]\teval-rmse:3.8384\ttrain-rmse:1.97298\n",
      "[18856]\teval-rmse:3.83768\ttrain-rmse:1.973\n",
      "[18857]\teval-rmse:3.83578\ttrain-rmse:1.97304\n",
      "[18858]\teval-rmse:3.83498\ttrain-rmse:1.97307\n",
      "[18859]\teval-rmse:3.83428\ttrain-rmse:1.97308\n",
      "[18860]\teval-rmse:3.83625\ttrain-rmse:1.97303\n",
      "[18861]\teval-rmse:3.83618\ttrain-rmse:1.97303\n",
      "[18862]\teval-rmse:3.83441\ttrain-rmse:1.97311\n",
      "[18863]\teval-rmse:3.83276\ttrain-rmse:1.97317\n",
      "[18864]\teval-rmse:3.83368\ttrain-rmse:1.97312\n",
      "[18865]\teval-rmse:3.83515\ttrain-rmse:1.97307\n",
      "[18866]\teval-rmse:3.83488\ttrain-rmse:1.97308\n",
      "[18867]\teval-rmse:3.83584\ttrain-rmse:1.97306\n",
      "[18868]\teval-rmse:3.83661\ttrain-rmse:1.97302\n",
      "[18869]\teval-rmse:3.83613\ttrain-rmse:1.97303\n",
      "[18870]\teval-rmse:3.83657\ttrain-rmse:1.97302\n",
      "[18871]\teval-rmse:3.83804\ttrain-rmse:1.97299\n",
      "[18872]\teval-rmse:3.83675\ttrain-rmse:1.97301\n",
      "[18873]\teval-rmse:3.83727\ttrain-rmse:1.973\n",
      "[18874]\teval-rmse:3.83709\ttrain-rmse:1.973\n",
      "[18875]\teval-rmse:3.83848\ttrain-rmse:1.97295\n",
      "[18876]\teval-rmse:3.8398\ttrain-rmse:1.9729\n",
      "[18877]\teval-rmse:3.8382\ttrain-rmse:1.97296\n",
      "[18878]\teval-rmse:3.84016\ttrain-rmse:1.97295\n",
      "[18879]\teval-rmse:3.83842\ttrain-rmse:1.97298\n",
      "[18880]\teval-rmse:3.83763\ttrain-rmse:1.97301\n",
      "[18881]\teval-rmse:3.83663\ttrain-rmse:1.97306\n",
      "[18882]\teval-rmse:3.83682\ttrain-rmse:1.97305\n",
      "[18883]\teval-rmse:3.83643\ttrain-rmse:1.97305\n",
      "[18884]\teval-rmse:3.83538\ttrain-rmse:1.97306\n",
      "[18885]\teval-rmse:3.83477\ttrain-rmse:1.97308\n",
      "[18886]\teval-rmse:3.83584\ttrain-rmse:1.97304\n",
      "[18887]\teval-rmse:3.83583\ttrain-rmse:1.97304\n",
      "[18888]\teval-rmse:3.83704\ttrain-rmse:1.97301\n",
      "[18889]\teval-rmse:3.8362\ttrain-rmse:1.97303\n",
      "[18890]\teval-rmse:3.83575\ttrain-rmse:1.97304\n",
      "[18891]\teval-rmse:3.83648\ttrain-rmse:1.97302\n",
      "[18892]\teval-rmse:3.83796\ttrain-rmse:1.97296\n",
      "[18893]\teval-rmse:3.8373\ttrain-rmse:1.97299\n",
      "[18894]\teval-rmse:3.83763\ttrain-rmse:1.97298\n",
      "[18895]\teval-rmse:3.83814\ttrain-rmse:1.97297\n",
      "[18896]\teval-rmse:3.8397\ttrain-rmse:1.97295\n",
      "[18897]\teval-rmse:3.83951\ttrain-rmse:1.97295\n",
      "[18898]\teval-rmse:3.83822\ttrain-rmse:1.97297\n",
      "[18899]\teval-rmse:3.84005\ttrain-rmse:1.97292\n",
      "[18900]\teval-rmse:3.83979\ttrain-rmse:1.97292\n",
      "[18901]\teval-rmse:3.84122\ttrain-rmse:1.97288\n",
      "[18902]\teval-rmse:3.84082\ttrain-rmse:1.97273\n",
      "[18903]\teval-rmse:3.83952\ttrain-rmse:1.97274\n",
      "[18904]\teval-rmse:3.83973\ttrain-rmse:1.97274\n",
      "[18905]\teval-rmse:3.84125\ttrain-rmse:1.97272\n",
      "[18906]\teval-rmse:3.83978\ttrain-rmse:1.97276\n",
      "[18907]\teval-rmse:3.83943\ttrain-rmse:1.97263\n",
      "[18908]\teval-rmse:3.83925\ttrain-rmse:1.97263\n",
      "[18909]\teval-rmse:3.83943\ttrain-rmse:1.97263\n",
      "[18910]\teval-rmse:3.84141\ttrain-rmse:1.97262\n",
      "[18911]\teval-rmse:3.84089\ttrain-rmse:1.97263\n",
      "[18912]\teval-rmse:3.84088\ttrain-rmse:1.97263\n",
      "[18913]\teval-rmse:3.83967\ttrain-rmse:1.97264\n",
      "[18914]\teval-rmse:3.83913\ttrain-rmse:1.97266\n",
      "[18915]\teval-rmse:3.83793\ttrain-rmse:1.97269\n",
      "[18916]\teval-rmse:3.83954\ttrain-rmse:1.97264\n",
      "[18917]\teval-rmse:3.84025\ttrain-rmse:1.97262\n",
      "[18918]\teval-rmse:3.83919\ttrain-rmse:1.97263\n",
      "[18919]\teval-rmse:3.83778\ttrain-rmse:1.97266\n",
      "[18920]\teval-rmse:3.83738\ttrain-rmse:1.97266\n",
      "[18921]\teval-rmse:3.83935\ttrain-rmse:1.97265\n",
      "[18922]\teval-rmse:3.84132\ttrain-rmse:1.97265\n",
      "[18923]\teval-rmse:3.84194\ttrain-rmse:1.97264\n",
      "[18924]\teval-rmse:3.84358\ttrain-rmse:1.97261\n",
      "[18925]\teval-rmse:3.84502\ttrain-rmse:1.97259\n",
      "[18926]\teval-rmse:3.84437\ttrain-rmse:1.9726\n",
      "[18927]\teval-rmse:3.84588\ttrain-rmse:1.97258\n",
      "[18928]\teval-rmse:3.84543\ttrain-rmse:1.97258\n",
      "[18929]\teval-rmse:3.84434\ttrain-rmse:1.97258\n",
      "[18930]\teval-rmse:3.846\ttrain-rmse:1.97258\n",
      "[18931]\teval-rmse:3.84599\ttrain-rmse:1.97258\n",
      "[18932]\teval-rmse:3.84467\ttrain-rmse:1.97258\n",
      "[18933]\teval-rmse:3.84373\ttrain-rmse:1.97259\n",
      "[18934]\teval-rmse:3.84232\ttrain-rmse:1.9726\n",
      "[18935]\teval-rmse:3.84305\ttrain-rmse:1.97258\n",
      "[18936]\teval-rmse:3.84456\ttrain-rmse:1.97256\n",
      "[18937]\teval-rmse:3.84335\ttrain-rmse:1.97256\n",
      "[18938]\teval-rmse:3.84194\ttrain-rmse:1.97259\n",
      "[18939]\teval-rmse:3.84355\ttrain-rmse:1.97256\n",
      "[18940]\teval-rmse:3.84205\ttrain-rmse:1.97258\n",
      "[18941]\teval-rmse:3.84377\ttrain-rmse:1.97257\n",
      "[18942]\teval-rmse:3.84356\ttrain-rmse:1.97257\n",
      "[18943]\teval-rmse:3.84185\ttrain-rmse:1.97259\n",
      "[18944]\teval-rmse:3.84023\ttrain-rmse:1.9726\n",
      "[18945]\teval-rmse:3.84219\ttrain-rmse:1.9726\n",
      "[18946]\teval-rmse:3.84097\ttrain-rmse:1.97262\n",
      "[18947]\teval-rmse:3.84029\ttrain-rmse:1.97263\n",
      "[18948]\teval-rmse:3.84089\ttrain-rmse:1.97262\n",
      "[18949]\teval-rmse:3.84204\ttrain-rmse:1.97259\n",
      "[18950]\teval-rmse:3.8427\ttrain-rmse:1.97258\n",
      "[18951]\teval-rmse:3.84206\ttrain-rmse:1.97259\n",
      "[18952]\teval-rmse:3.84126\ttrain-rmse:1.9726\n",
      "[18953]\teval-rmse:3.83962\ttrain-rmse:1.97263\n",
      "[18954]\teval-rmse:3.83935\ttrain-rmse:1.97263\n",
      "[18955]\teval-rmse:3.83986\ttrain-rmse:1.97261\n",
      "[18956]\teval-rmse:3.83968\ttrain-rmse:1.97262\n",
      "[18957]\teval-rmse:3.83812\ttrain-rmse:1.97267\n",
      "[18958]\teval-rmse:3.8376\ttrain-rmse:1.97267\n",
      "[18959]\teval-rmse:3.83733\ttrain-rmse:1.97267\n",
      "[18960]\teval-rmse:3.8368\ttrain-rmse:1.97269\n",
      "[18961]\teval-rmse:3.83842\ttrain-rmse:1.97264\n",
      "[18962]\teval-rmse:3.84025\ttrain-rmse:1.97261\n",
      "[18963]\teval-rmse:3.84071\ttrain-rmse:1.97261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18964]\teval-rmse:3.84166\ttrain-rmse:1.97259\n",
      "[18965]\teval-rmse:3.8408\ttrain-rmse:1.97259\n",
      "[18966]\teval-rmse:3.84276\ttrain-rmse:1.9726\n",
      "[18967]\teval-rmse:3.84458\ttrain-rmse:1.97256\n",
      "[18968]\teval-rmse:3.84416\ttrain-rmse:1.97242\n",
      "[18969]\teval-rmse:3.84308\ttrain-rmse:1.97241\n",
      "[18970]\teval-rmse:3.84243\ttrain-rmse:1.97243\n",
      "[18971]\teval-rmse:3.84308\ttrain-rmse:1.97242\n",
      "[18972]\teval-rmse:3.84186\ttrain-rmse:1.97244\n",
      "[18973]\teval-rmse:3.84341\ttrain-rmse:1.97243\n",
      "[18974]\teval-rmse:3.843\ttrain-rmse:1.97229\n",
      "[18975]\teval-rmse:3.84406\ttrain-rmse:1.97227\n",
      "[18976]\teval-rmse:3.84274\ttrain-rmse:1.97228\n",
      "[18977]\teval-rmse:3.84311\ttrain-rmse:1.97228\n",
      "[18978]\teval-rmse:3.84404\ttrain-rmse:1.97226\n",
      "[18979]\teval-rmse:3.84384\ttrain-rmse:1.97226\n",
      "[18980]\teval-rmse:3.8438\ttrain-rmse:1.97226\n",
      "[18981]\teval-rmse:3.8432\ttrain-rmse:1.97226\n",
      "[18982]\teval-rmse:3.84098\ttrain-rmse:1.97228\n",
      "[18983]\teval-rmse:3.84128\ttrain-rmse:1.97227\n",
      "[18984]\teval-rmse:3.84199\ttrain-rmse:1.97226\n",
      "[18985]\teval-rmse:3.8433\ttrain-rmse:1.97224\n",
      "[18986]\teval-rmse:3.8429\ttrain-rmse:1.97223\n",
      "[18987]\teval-rmse:3.84486\ttrain-rmse:1.97225\n",
      "[18988]\teval-rmse:3.84609\ttrain-rmse:1.97223\n",
      "[18989]\teval-rmse:3.84636\ttrain-rmse:1.97223\n",
      "[18990]\teval-rmse:3.84607\ttrain-rmse:1.97223\n",
      "[18991]\teval-rmse:3.84521\ttrain-rmse:1.97222\n",
      "[18992]\teval-rmse:3.84694\ttrain-rmse:1.97223\n",
      "[18993]\teval-rmse:3.84583\ttrain-rmse:1.97222\n",
      "[18994]\teval-rmse:3.84415\ttrain-rmse:1.97222\n",
      "[18995]\teval-rmse:3.84482\ttrain-rmse:1.97221\n",
      "[18996]\teval-rmse:3.84655\ttrain-rmse:1.97221\n",
      "[18997]\teval-rmse:3.84777\ttrain-rmse:1.97221\n",
      "[18998]\teval-rmse:3.84838\ttrain-rmse:1.97221\n",
      "[18999]\teval-rmse:3.84708\ttrain-rmse:1.97222\n",
      "[19000]\teval-rmse:3.84889\ttrain-rmse:1.97223\n",
      "[19001]\teval-rmse:3.85031\ttrain-rmse:1.97225\n",
      "[19002]\teval-rmse:3.84919\ttrain-rmse:1.97223\n",
      "[19003]\teval-rmse:3.84946\ttrain-rmse:1.97223\n",
      "[19004]\teval-rmse:3.85128\ttrain-rmse:1.97226\n",
      "[19005]\teval-rmse:3.85059\ttrain-rmse:1.97226\n",
      "[19006]\teval-rmse:3.85099\ttrain-rmse:1.97227\n",
      "[19007]\teval-rmse:3.85122\ttrain-rmse:1.97227\n",
      "[19008]\teval-rmse:3.84916\ttrain-rmse:1.97225\n",
      "[19009]\teval-rmse:3.84746\ttrain-rmse:1.97225\n",
      "[19010]\teval-rmse:3.84789\ttrain-rmse:1.97225\n",
      "[19011]\teval-rmse:3.84831\ttrain-rmse:1.97224\n",
      "[19012]\teval-rmse:3.84648\ttrain-rmse:1.97225\n",
      "[19013]\teval-rmse:3.84829\ttrain-rmse:1.97224\n",
      "[19014]\teval-rmse:3.85024\ttrain-rmse:1.97227\n",
      "[19015]\teval-rmse:3.8522\ttrain-rmse:1.97231\n",
      "[19016]\teval-rmse:3.85172\ttrain-rmse:1.97231\n",
      "[19017]\teval-rmse:3.85306\ttrain-rmse:1.97231\n",
      "[19018]\teval-rmse:3.85191\ttrain-rmse:1.97229\n",
      "[19019]\teval-rmse:3.85357\ttrain-rmse:1.97232\n",
      "[19020]\teval-rmse:3.85551\ttrain-rmse:1.97237\n",
      "[19021]\teval-rmse:3.85717\ttrain-rmse:1.9724\n",
      "[19022]\teval-rmse:3.85911\ttrain-rmse:1.97246\n",
      "[19023]\teval-rmse:3.85817\ttrain-rmse:1.97243\n",
      "[19024]\teval-rmse:3.85737\ttrain-rmse:1.97241\n",
      "[19025]\teval-rmse:3.85753\ttrain-rmse:1.97241\n",
      "[19026]\teval-rmse:3.85719\ttrain-rmse:1.9724\n",
      "[19027]\teval-rmse:3.85751\ttrain-rmse:1.9724\n",
      "[19028]\teval-rmse:3.85768\ttrain-rmse:1.97241\n",
      "[19029]\teval-rmse:3.85582\ttrain-rmse:1.97237\n",
      "[19030]\teval-rmse:3.85754\ttrain-rmse:1.97242\n",
      "[19031]\teval-rmse:3.85812\ttrain-rmse:1.97243\n",
      "[19032]\teval-rmse:3.85785\ttrain-rmse:1.97242\n",
      "[19033]\teval-rmse:3.85623\ttrain-rmse:1.97238\n",
      "[19034]\teval-rmse:3.8566\ttrain-rmse:1.97238\n",
      "[19035]\teval-rmse:3.8584\ttrain-rmse:1.97244\n",
      "[19036]\teval-rmse:3.85758\ttrain-rmse:1.97242\n",
      "[19037]\teval-rmse:3.856\ttrain-rmse:1.97237\n",
      "[19038]\teval-rmse:3.8553\ttrain-rmse:1.97236\n",
      "[19039]\teval-rmse:3.85668\ttrain-rmse:1.97239\n",
      "[19040]\teval-rmse:3.85484\ttrain-rmse:1.97235\n",
      "[19041]\teval-rmse:3.85406\ttrain-rmse:1.97233\n",
      "[19042]\teval-rmse:3.85225\ttrain-rmse:1.97231\n",
      "[19043]\teval-rmse:3.85355\ttrain-rmse:1.97232\n",
      "[19044]\teval-rmse:3.8518\ttrain-rmse:1.9723\n",
      "[19045]\teval-rmse:3.8522\ttrain-rmse:1.9723\n",
      "[19046]\teval-rmse:3.85106\ttrain-rmse:1.97228\n",
      "[19047]\teval-rmse:3.85239\ttrain-rmse:1.97228\n",
      "[19048]\teval-rmse:3.85405\ttrain-rmse:1.97229\n",
      "[19049]\teval-rmse:3.85246\ttrain-rmse:1.97226\n",
      "[19050]\teval-rmse:3.85377\ttrain-rmse:1.97228\n",
      "[19051]\teval-rmse:3.85488\ttrain-rmse:1.97229\n",
      "[19052]\teval-rmse:3.85462\ttrain-rmse:1.97228\n",
      "[19053]\teval-rmse:3.85315\ttrain-rmse:1.97225\n",
      "[19054]\teval-rmse:3.85132\ttrain-rmse:1.97223\n",
      "[19055]\teval-rmse:3.85202\ttrain-rmse:1.97225\n",
      "[19056]\teval-rmse:3.85374\ttrain-rmse:1.97228\n",
      "[19057]\teval-rmse:3.85236\ttrain-rmse:1.97225\n",
      "[19058]\teval-rmse:3.85396\ttrain-rmse:1.97226\n",
      "[19059]\teval-rmse:3.85361\ttrain-rmse:1.97225\n",
      "[19060]\teval-rmse:3.8551\ttrain-rmse:1.97229\n",
      "[19061]\teval-rmse:3.85452\ttrain-rmse:1.97228\n",
      "[19062]\teval-rmse:3.85534\ttrain-rmse:1.97229\n",
      "[19063]\teval-rmse:3.85374\ttrain-rmse:1.97225\n",
      "[19064]\teval-rmse:3.85374\ttrain-rmse:1.97225\n",
      "[19065]\teval-rmse:3.85327\ttrain-rmse:1.97224\n",
      "[19066]\teval-rmse:3.85295\ttrain-rmse:1.97223\n",
      "[19067]\teval-rmse:3.853\ttrain-rmse:1.97224\n",
      "[19068]\teval-rmse:3.85483\ttrain-rmse:1.97227\n",
      "[19069]\teval-rmse:3.85489\ttrain-rmse:1.97227\n",
      "[19070]\teval-rmse:3.85491\ttrain-rmse:1.97227\n",
      "[19071]\teval-rmse:3.85537\ttrain-rmse:1.97228\n",
      "[19072]\teval-rmse:3.85595\ttrain-rmse:1.97229\n",
      "[19073]\teval-rmse:3.8567\ttrain-rmse:1.97232\n",
      "[19074]\teval-rmse:3.85682\ttrain-rmse:1.97232\n",
      "[19075]\teval-rmse:3.85565\ttrain-rmse:1.97229\n",
      "[19076]\teval-rmse:3.85686\ttrain-rmse:1.97232\n",
      "[19077]\teval-rmse:3.85827\ttrain-rmse:1.97236\n",
      "[19078]\teval-rmse:3.85621\ttrain-rmse:1.97231\n",
      "[19079]\teval-rmse:3.85728\ttrain-rmse:1.97234\n",
      "[19080]\teval-rmse:3.85549\ttrain-rmse:1.9723\n",
      "[19081]\teval-rmse:3.855\ttrain-rmse:1.97229\n",
      "[19082]\teval-rmse:3.85361\ttrain-rmse:1.97226\n",
      "[19083]\teval-rmse:3.8529\ttrain-rmse:1.97224\n",
      "[19084]\teval-rmse:3.85297\ttrain-rmse:1.97224\n",
      "[19085]\teval-rmse:3.85143\ttrain-rmse:1.97223\n",
      "[19086]\teval-rmse:3.85249\ttrain-rmse:1.97224\n",
      "[19087]\teval-rmse:3.85134\ttrain-rmse:1.97221\n",
      "[19088]\teval-rmse:3.85251\ttrain-rmse:1.97222\n",
      "[19089]\teval-rmse:3.85226\ttrain-rmse:1.97222\n",
      "[19090]\teval-rmse:3.85348\ttrain-rmse:1.97225\n",
      "[19091]\teval-rmse:3.85233\ttrain-rmse:1.97222\n",
      "[19092]\teval-rmse:3.85257\ttrain-rmse:1.97223\n",
      "[19093]\teval-rmse:3.85419\ttrain-rmse:1.97227\n",
      "[19094]\teval-rmse:3.85376\ttrain-rmse:1.97214\n",
      "[19095]\teval-rmse:3.85195\ttrain-rmse:1.97211\n",
      "[19096]\teval-rmse:3.8539\ttrain-rmse:1.97216\n",
      "[19097]\teval-rmse:3.85528\ttrain-rmse:1.97218\n",
      "[19098]\teval-rmse:3.85481\ttrain-rmse:1.97217\n",
      "[19099]\teval-rmse:3.85497\ttrain-rmse:1.97217\n",
      "[19100]\teval-rmse:3.85692\ttrain-rmse:1.97223\n",
      "[19101]\teval-rmse:3.85807\ttrain-rmse:1.97227\n",
      "[19102]\teval-rmse:3.85977\ttrain-rmse:1.9723\n",
      "[19103]\teval-rmse:3.86171\ttrain-rmse:1.97237\n",
      "[19104]\teval-rmse:3.85958\ttrain-rmse:1.97229\n",
      "[19105]\teval-rmse:3.8592\ttrain-rmse:1.97227\n",
      "[19106]\teval-rmse:3.86069\ttrain-rmse:1.97232\n",
      "[19107]\teval-rmse:3.8588\ttrain-rmse:1.97226\n",
      "[19108]\teval-rmse:3.85689\ttrain-rmse:1.97219\n",
      "[19109]\teval-rmse:3.85528\ttrain-rmse:1.97215\n",
      "[19110]\teval-rmse:3.85709\ttrain-rmse:1.97221\n",
      "[19111]\teval-rmse:3.85616\ttrain-rmse:1.97218\n",
      "[19112]\teval-rmse:3.85567\ttrain-rmse:1.97203\n",
      "[19113]\teval-rmse:3.85498\ttrain-rmse:1.97202\n",
      "[19114]\teval-rmse:3.85605\ttrain-rmse:1.97204\n",
      "[19115]\teval-rmse:3.85777\ttrain-rmse:1.9721\n",
      "[19116]\teval-rmse:3.85837\ttrain-rmse:1.97212\n",
      "[19117]\teval-rmse:3.85687\ttrain-rmse:1.97208\n",
      "[19118]\teval-rmse:3.85711\ttrain-rmse:1.97208\n",
      "[19119]\teval-rmse:3.85577\ttrain-rmse:1.97205\n",
      "[19120]\teval-rmse:3.85376\ttrain-rmse:1.97201\n",
      "[19121]\teval-rmse:3.85275\ttrain-rmse:1.972\n",
      "[19122]\teval-rmse:3.8536\ttrain-rmse:1.97202\n",
      "[19123]\teval-rmse:3.85303\ttrain-rmse:1.97201\n",
      "[19124]\teval-rmse:3.85332\ttrain-rmse:1.97201\n",
      "[19125]\teval-rmse:3.85285\ttrain-rmse:1.972\n",
      "[19126]\teval-rmse:3.85222\ttrain-rmse:1.97199\n",
      "[19127]\teval-rmse:3.85108\ttrain-rmse:1.97197\n",
      "[19128]\teval-rmse:3.85161\ttrain-rmse:1.97198\n",
      "[19129]\teval-rmse:3.85179\ttrain-rmse:1.97198\n",
      "[19130]\teval-rmse:3.85242\ttrain-rmse:1.97199\n",
      "[19131]\teval-rmse:3.85349\ttrain-rmse:1.97202\n",
      "[19132]\teval-rmse:3.85258\ttrain-rmse:1.97201\n",
      "[19133]\teval-rmse:3.85233\ttrain-rmse:1.97201\n",
      "[19134]\teval-rmse:3.85187\ttrain-rmse:1.97186\n",
      "[19135]\teval-rmse:3.85161\ttrain-rmse:1.97186\n",
      "[19136]\teval-rmse:3.8498\ttrain-rmse:1.97182\n",
      "[19137]\teval-rmse:3.8514\ttrain-rmse:1.97182\n",
      "[19138]\teval-rmse:3.84961\ttrain-rmse:1.97178\n",
      "[19139]\teval-rmse:3.84762\ttrain-rmse:1.97177\n",
      "[19140]\teval-rmse:3.84802\ttrain-rmse:1.97177\n",
      "[19141]\teval-rmse:3.84873\ttrain-rmse:1.97178\n",
      "[19142]\teval-rmse:3.85048\ttrain-rmse:1.97182\n",
      "[19143]\teval-rmse:3.8514\ttrain-rmse:1.97184\n",
      "[19144]\teval-rmse:3.85261\ttrain-rmse:1.97187\n",
      "[19145]\teval-rmse:3.85351\ttrain-rmse:1.97189\n",
      "[19146]\teval-rmse:3.85261\ttrain-rmse:1.97188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19147]\teval-rmse:3.85122\ttrain-rmse:1.97187\n",
      "[19148]\teval-rmse:3.85044\ttrain-rmse:1.97185\n",
      "[19149]\teval-rmse:3.84999\ttrain-rmse:1.97172\n",
      "[19150]\teval-rmse:3.84953\ttrain-rmse:1.97159\n",
      "[19151]\teval-rmse:3.85115\ttrain-rmse:1.97161\n",
      "[19152]\teval-rmse:3.8507\ttrain-rmse:1.9716\n",
      "[19153]\teval-rmse:3.85013\ttrain-rmse:1.97159\n",
      "[19154]\teval-rmse:3.84903\ttrain-rmse:1.97158\n",
      "[19155]\teval-rmse:3.84747\ttrain-rmse:1.97159\n",
      "[19156]\teval-rmse:3.84565\ttrain-rmse:1.97159\n",
      "[19157]\teval-rmse:3.84687\ttrain-rmse:1.97161\n",
      "[19158]\teval-rmse:3.84529\ttrain-rmse:1.97159\n",
      "[19159]\teval-rmse:3.8437\ttrain-rmse:1.97161\n",
      "[19160]\teval-rmse:3.84419\ttrain-rmse:1.97161\n",
      "[19161]\teval-rmse:3.8446\ttrain-rmse:1.9716\n",
      "[19162]\teval-rmse:3.84314\ttrain-rmse:1.97162\n",
      "[19163]\teval-rmse:3.84204\ttrain-rmse:1.97161\n",
      "[19164]\teval-rmse:3.84012\ttrain-rmse:1.97165\n",
      "[19165]\teval-rmse:3.84177\ttrain-rmse:1.97162\n",
      "[19166]\teval-rmse:3.84121\ttrain-rmse:1.97163\n",
      "[19167]\teval-rmse:3.8398\ttrain-rmse:1.97164\n",
      "[19168]\teval-rmse:3.8394\ttrain-rmse:1.97163\n",
      "[19169]\teval-rmse:3.83911\ttrain-rmse:1.97163\n",
      "[19170]\teval-rmse:3.83871\ttrain-rmse:1.97149\n",
      "[19171]\teval-rmse:3.8371\ttrain-rmse:1.97151\n",
      "[19172]\teval-rmse:3.83582\ttrain-rmse:1.97152\n",
      "[19173]\teval-rmse:3.83731\ttrain-rmse:1.97148\n",
      "[19174]\teval-rmse:3.83926\ttrain-rmse:1.97148\n",
      "[19175]\teval-rmse:3.84122\ttrain-rmse:1.97143\n",
      "[19176]\teval-rmse:3.84303\ttrain-rmse:1.9714\n",
      "[19177]\teval-rmse:3.84429\ttrain-rmse:1.97139\n",
      "[19178]\teval-rmse:3.84284\ttrain-rmse:1.97138\n",
      "[19179]\teval-rmse:3.84375\ttrain-rmse:1.97137\n",
      "[19180]\teval-rmse:3.84546\ttrain-rmse:1.97137\n",
      "[19181]\teval-rmse:3.8469\ttrain-rmse:1.97139\n",
      "[19182]\teval-rmse:3.84716\ttrain-rmse:1.97139\n",
      "[19183]\teval-rmse:3.84854\ttrain-rmse:1.97141\n",
      "[19184]\teval-rmse:3.84963\ttrain-rmse:1.97141\n",
      "[19185]\teval-rmse:3.8501\ttrain-rmse:1.97142\n",
      "[19186]\teval-rmse:3.85205\ttrain-rmse:1.97146\n",
      "[19187]\teval-rmse:3.85139\ttrain-rmse:1.97144\n",
      "[19188]\teval-rmse:3.85246\ttrain-rmse:1.97145\n",
      "[19189]\teval-rmse:3.85321\ttrain-rmse:1.97147\n",
      "[19190]\teval-rmse:3.85205\ttrain-rmse:1.97144\n",
      "[19191]\teval-rmse:3.8516\ttrain-rmse:1.97131\n",
      "[19192]\teval-rmse:3.85002\ttrain-rmse:1.97127\n",
      "[19193]\teval-rmse:3.85143\ttrain-rmse:1.97129\n",
      "[19194]\teval-rmse:3.85065\ttrain-rmse:1.97127\n",
      "[19195]\teval-rmse:3.84979\ttrain-rmse:1.97126\n",
      "[19196]\teval-rmse:3.8504\ttrain-rmse:1.97128\n",
      "[19197]\teval-rmse:3.84911\ttrain-rmse:1.97126\n",
      "[19198]\teval-rmse:3.84943\ttrain-rmse:1.97126\n",
      "[19199]\teval-rmse:3.8511\ttrain-rmse:1.97128\n",
      "[19200]\teval-rmse:3.85087\ttrain-rmse:1.97128\n",
      "[19201]\teval-rmse:3.85063\ttrain-rmse:1.97127\n",
      "[19202]\teval-rmse:3.85038\ttrain-rmse:1.97127\n",
      "[19203]\teval-rmse:3.85042\ttrain-rmse:1.97127\n",
      "[19204]\teval-rmse:3.85055\ttrain-rmse:1.97127\n",
      "[19205]\teval-rmse:3.84918\ttrain-rmse:1.97124\n",
      "[19206]\teval-rmse:3.84896\ttrain-rmse:1.97123\n",
      "[19207]\teval-rmse:3.84986\ttrain-rmse:1.97125\n",
      "[19208]\teval-rmse:3.8518\ttrain-rmse:1.97129\n",
      "[19209]\teval-rmse:3.85102\ttrain-rmse:1.97127\n",
      "[19210]\teval-rmse:3.85173\ttrain-rmse:1.97128\n",
      "[19211]\teval-rmse:3.85367\ttrain-rmse:1.97133\n",
      "[19212]\teval-rmse:3.85208\ttrain-rmse:1.97131\n",
      "[19213]\teval-rmse:3.85249\ttrain-rmse:1.97131\n",
      "[19214]\teval-rmse:3.85105\ttrain-rmse:1.97128\n",
      "[19215]\teval-rmse:3.85143\ttrain-rmse:1.97128\n",
      "[19216]\teval-rmse:3.85286\ttrain-rmse:1.97132\n",
      "[19217]\teval-rmse:3.85445\ttrain-rmse:1.97136\n",
      "[19218]\teval-rmse:3.85378\ttrain-rmse:1.97134\n",
      "[19219]\teval-rmse:3.85405\ttrain-rmse:1.97134\n",
      "[19220]\teval-rmse:3.85521\ttrain-rmse:1.97137\n",
      "[19221]\teval-rmse:3.85473\ttrain-rmse:1.97124\n",
      "[19222]\teval-rmse:3.85406\ttrain-rmse:1.97121\n",
      "[19223]\teval-rmse:3.85537\ttrain-rmse:1.97126\n",
      "[19224]\teval-rmse:3.85381\ttrain-rmse:1.97122\n",
      "[19225]\teval-rmse:3.85334\ttrain-rmse:1.97121\n",
      "[19226]\teval-rmse:3.85276\ttrain-rmse:1.97119\n",
      "[19227]\teval-rmse:3.85289\ttrain-rmse:1.9712\n",
      "[19228]\teval-rmse:3.85142\ttrain-rmse:1.97117\n",
      "[19229]\teval-rmse:3.85141\ttrain-rmse:1.97117\n",
      "[19230]\teval-rmse:3.85297\ttrain-rmse:1.97119\n",
      "[19231]\teval-rmse:3.85316\ttrain-rmse:1.9712\n",
      "[19232]\teval-rmse:3.8529\ttrain-rmse:1.97119\n",
      "[19233]\teval-rmse:3.8538\ttrain-rmse:1.97122\n",
      "[19234]\teval-rmse:3.85218\ttrain-rmse:1.97117\n",
      "[19235]\teval-rmse:3.85388\ttrain-rmse:1.97121\n",
      "[19236]\teval-rmse:3.85434\ttrain-rmse:1.97122\n",
      "[19237]\teval-rmse:3.85384\ttrain-rmse:1.97122\n",
      "[19238]\teval-rmse:3.85411\ttrain-rmse:1.97122\n",
      "[19239]\teval-rmse:3.85604\ttrain-rmse:1.97128\n",
      "[19240]\teval-rmse:3.85524\ttrain-rmse:1.97126\n",
      "[19241]\teval-rmse:3.85717\ttrain-rmse:1.97132\n",
      "[19242]\teval-rmse:3.85743\ttrain-rmse:1.97133\n",
      "[19243]\teval-rmse:3.85698\ttrain-rmse:1.97119\n",
      "[19244]\teval-rmse:3.85508\ttrain-rmse:1.97113\n",
      "[19245]\teval-rmse:3.85459\ttrain-rmse:1.97111\n",
      "[19246]\teval-rmse:3.85257\ttrain-rmse:1.97106\n",
      "[19247]\teval-rmse:3.85058\ttrain-rmse:1.97103\n",
      "[19248]\teval-rmse:3.85221\ttrain-rmse:1.97106\n",
      "[19249]\teval-rmse:3.85175\ttrain-rmse:1.97105\n",
      "[19250]\teval-rmse:3.85007\ttrain-rmse:1.97101\n",
      "[19251]\teval-rmse:3.85128\ttrain-rmse:1.97102\n",
      "[19252]\teval-rmse:3.85069\ttrain-rmse:1.97101\n",
      "[19253]\teval-rmse:3.85021\ttrain-rmse:1.97101\n",
      "[19254]\teval-rmse:3.85188\ttrain-rmse:1.97103\n",
      "[19255]\teval-rmse:3.85347\ttrain-rmse:1.97107\n",
      "[19256]\teval-rmse:3.85527\ttrain-rmse:1.97113\n",
      "[19257]\teval-rmse:3.85388\ttrain-rmse:1.97108\n",
      "[19258]\teval-rmse:3.85238\ttrain-rmse:1.97104\n",
      "[19259]\teval-rmse:3.85285\ttrain-rmse:1.97105\n",
      "[19260]\teval-rmse:3.85457\ttrain-rmse:1.9711\n",
      "[19261]\teval-rmse:3.8534\ttrain-rmse:1.97107\n",
      "[19262]\teval-rmse:3.8519\ttrain-rmse:1.97104\n",
      "[19263]\teval-rmse:3.85022\ttrain-rmse:1.97101\n",
      "[19264]\teval-rmse:3.84886\ttrain-rmse:1.97099\n",
      "[19265]\teval-rmse:3.84937\ttrain-rmse:1.971\n",
      "[19266]\teval-rmse:3.84778\ttrain-rmse:1.97097\n",
      "[19267]\teval-rmse:3.84602\ttrain-rmse:1.97095\n",
      "[19268]\teval-rmse:3.84645\ttrain-rmse:1.97095\n",
      "[19269]\teval-rmse:3.84546\ttrain-rmse:1.97095\n",
      "[19270]\teval-rmse:3.84578\ttrain-rmse:1.97095\n",
      "[19271]\teval-rmse:3.84729\ttrain-rmse:1.97095\n",
      "[19272]\teval-rmse:3.84892\ttrain-rmse:1.97097\n",
      "[19273]\teval-rmse:3.84778\ttrain-rmse:1.97095\n",
      "[19274]\teval-rmse:3.84755\ttrain-rmse:1.97094\n",
      "[19275]\teval-rmse:3.84732\ttrain-rmse:1.97094\n",
      "[19276]\teval-rmse:3.84596\ttrain-rmse:1.97094\n",
      "[19277]\teval-rmse:3.84731\ttrain-rmse:1.97096\n",
      "[19278]\teval-rmse:3.84858\ttrain-rmse:1.97097\n",
      "[19279]\teval-rmse:3.84913\ttrain-rmse:1.97098\n",
      "[19280]\teval-rmse:3.84767\ttrain-rmse:1.97096\n",
      "[19281]\teval-rmse:3.84947\ttrain-rmse:1.97096\n",
      "[19282]\teval-rmse:3.84897\ttrain-rmse:1.97095\n",
      "[19283]\teval-rmse:3.84855\ttrain-rmse:1.97095\n",
      "[19284]\teval-rmse:3.85029\ttrain-rmse:1.97098\n",
      "[19285]\teval-rmse:3.84841\ttrain-rmse:1.97095\n",
      "[19286]\teval-rmse:3.84879\ttrain-rmse:1.97096\n",
      "[19287]\teval-rmse:3.84846\ttrain-rmse:1.97095\n",
      "[19288]\teval-rmse:3.84969\ttrain-rmse:1.97096\n",
      "[19289]\teval-rmse:3.85134\ttrain-rmse:1.971\n",
      "[19290]\teval-rmse:3.84997\ttrain-rmse:1.97097\n",
      "[19291]\teval-rmse:3.85148\ttrain-rmse:1.97101\n",
      "[19292]\teval-rmse:3.85202\ttrain-rmse:1.97102\n",
      "[19293]\teval-rmse:3.85044\ttrain-rmse:1.97099\n",
      "[19294]\teval-rmse:3.85192\ttrain-rmse:1.97102\n",
      "[19295]\teval-rmse:3.85278\ttrain-rmse:1.97104\n",
      "[19296]\teval-rmse:3.853\ttrain-rmse:1.97105\n",
      "[19297]\teval-rmse:3.85437\ttrain-rmse:1.9711\n",
      "[19298]\teval-rmse:3.85545\ttrain-rmse:1.97113\n",
      "[19299]\teval-rmse:3.85414\ttrain-rmse:1.97109\n",
      "[19300]\teval-rmse:3.85466\ttrain-rmse:1.97111\n",
      "[19301]\teval-rmse:3.85495\ttrain-rmse:1.97112\n",
      "[19302]\teval-rmse:3.85458\ttrain-rmse:1.97111\n",
      "[19303]\teval-rmse:3.8548\ttrain-rmse:1.97112\n",
      "[19304]\teval-rmse:3.85446\ttrain-rmse:1.97111\n",
      "[19305]\teval-rmse:3.8542\ttrain-rmse:1.9711\n",
      "[19306]\teval-rmse:3.8548\ttrain-rmse:1.97112\n",
      "[19307]\teval-rmse:3.85524\ttrain-rmse:1.97114\n",
      "[19308]\teval-rmse:3.85549\ttrain-rmse:1.97115\n",
      "[19309]\teval-rmse:3.85562\ttrain-rmse:1.97115\n",
      "[19310]\teval-rmse:3.85723\ttrain-rmse:1.97122\n",
      "[19311]\teval-rmse:3.85642\ttrain-rmse:1.97118\n",
      "[19312]\teval-rmse:3.85481\ttrain-rmse:1.97113\n",
      "[19313]\teval-rmse:3.85285\ttrain-rmse:1.97107\n",
      "[19314]\teval-rmse:3.85444\ttrain-rmse:1.97113\n",
      "[19315]\teval-rmse:3.85502\ttrain-rmse:1.97115\n",
      "[19316]\teval-rmse:3.8552\ttrain-rmse:1.97116\n",
      "[19317]\teval-rmse:3.85583\ttrain-rmse:1.97118\n",
      "[19318]\teval-rmse:3.85432\ttrain-rmse:1.97112\n",
      "[19319]\teval-rmse:3.85315\ttrain-rmse:1.97109\n",
      "[19320]\teval-rmse:3.85158\ttrain-rmse:1.97104\n",
      "[19321]\teval-rmse:3.85113\ttrain-rmse:1.97091\n",
      "[19322]\teval-rmse:3.84975\ttrain-rmse:1.97088\n",
      "[19323]\teval-rmse:3.84916\ttrain-rmse:1.97087\n",
      "[19324]\teval-rmse:3.8496\ttrain-rmse:1.97088\n",
      "[19325]\teval-rmse:3.84897\ttrain-rmse:1.97087\n",
      "[19326]\teval-rmse:3.84873\ttrain-rmse:1.97086\n",
      "[19327]\teval-rmse:3.84991\ttrain-rmse:1.97089\n",
      "[19328]\teval-rmse:3.85122\ttrain-rmse:1.97093\n",
      "[19329]\teval-rmse:3.85283\ttrain-rmse:1.97097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19330]\teval-rmse:3.85168\ttrain-rmse:1.97094\n",
      "[19331]\teval-rmse:3.85294\ttrain-rmse:1.97098\n",
      "[19332]\teval-rmse:3.85434\ttrain-rmse:1.97104\n",
      "[19333]\teval-rmse:3.85387\ttrain-rmse:1.97091\n",
      "[19334]\teval-rmse:3.85337\ttrain-rmse:1.97089\n",
      "[19335]\teval-rmse:3.85462\ttrain-rmse:1.97093\n",
      "[19336]\teval-rmse:3.85331\ttrain-rmse:1.97089\n",
      "[19337]\teval-rmse:3.85296\ttrain-rmse:1.97088\n",
      "[19338]\teval-rmse:3.85239\ttrain-rmse:1.97086\n",
      "[19339]\teval-rmse:3.8511\ttrain-rmse:1.97084\n",
      "[19340]\teval-rmse:3.85244\ttrain-rmse:1.97088\n",
      "[19341]\teval-rmse:3.85373\ttrain-rmse:1.97094\n",
      "[19342]\teval-rmse:3.85427\ttrain-rmse:1.97096\n",
      "[19343]\teval-rmse:3.85595\ttrain-rmse:1.97098\n",
      "[19344]\teval-rmse:3.85629\ttrain-rmse:1.971\n",
      "[19345]\teval-rmse:3.85686\ttrain-rmse:1.97103\n",
      "[19346]\teval-rmse:3.85849\ttrain-rmse:1.97111\n",
      "[19347]\teval-rmse:3.85777\ttrain-rmse:1.97108\n",
      "[19348]\teval-rmse:3.85633\ttrain-rmse:1.97105\n",
      "[19349]\teval-rmse:3.85768\ttrain-rmse:1.97112\n",
      "[19350]\teval-rmse:3.8573\ttrain-rmse:1.9711\n",
      "[19351]\teval-rmse:3.85522\ttrain-rmse:1.971\n",
      "[19352]\teval-rmse:3.85715\ttrain-rmse:1.97106\n",
      "[19353]\teval-rmse:3.85538\ttrain-rmse:1.971\n",
      "[19354]\teval-rmse:3.8557\ttrain-rmse:1.97101\n",
      "[19355]\teval-rmse:3.85604\ttrain-rmse:1.97103\n",
      "[19356]\teval-rmse:3.85577\ttrain-rmse:1.97102\n",
      "[19357]\teval-rmse:3.85483\ttrain-rmse:1.97098\n",
      "[19358]\teval-rmse:3.85435\ttrain-rmse:1.97096\n",
      "[19359]\teval-rmse:3.8541\ttrain-rmse:1.97095\n",
      "[19360]\teval-rmse:3.85537\ttrain-rmse:1.97101\n",
      "[19361]\teval-rmse:3.85622\ttrain-rmse:1.97105\n",
      "[19362]\teval-rmse:3.85577\ttrain-rmse:1.97093\n",
      "[19363]\teval-rmse:3.85421\ttrain-rmse:1.97086\n",
      "[19364]\teval-rmse:3.85234\ttrain-rmse:1.97078\n",
      "[19365]\teval-rmse:3.85304\ttrain-rmse:1.97081\n",
      "[19366]\teval-rmse:3.85258\ttrain-rmse:1.9708\n",
      "[19367]\teval-rmse:3.85232\ttrain-rmse:1.97079\n",
      "[19368]\teval-rmse:3.85387\ttrain-rmse:1.97085\n",
      "[19369]\teval-rmse:3.85228\ttrain-rmse:1.97079\n",
      "[19370]\teval-rmse:3.85421\ttrain-rmse:1.97084\n",
      "[19371]\teval-rmse:3.85553\ttrain-rmse:1.9709\n",
      "[19372]\teval-rmse:3.8537\ttrain-rmse:1.97082\n",
      "[19373]\teval-rmse:3.85275\ttrain-rmse:1.97078\n",
      "[19374]\teval-rmse:3.8525\ttrain-rmse:1.97077\n",
      "[19375]\teval-rmse:3.85409\ttrain-rmse:1.97081\n",
      "[19376]\teval-rmse:3.85292\ttrain-rmse:1.97078\n",
      "[19377]\teval-rmse:3.85393\ttrain-rmse:1.97082\n",
      "[19378]\teval-rmse:3.85322\ttrain-rmse:1.97079\n",
      "[19379]\teval-rmse:3.85469\ttrain-rmse:1.97086\n",
      "[19380]\teval-rmse:3.85634\ttrain-rmse:1.97094\n",
      "[19381]\teval-rmse:3.85676\ttrain-rmse:1.97096\n",
      "[19382]\teval-rmse:3.85648\ttrain-rmse:1.97095\n",
      "[19383]\teval-rmse:3.85613\ttrain-rmse:1.97094\n",
      "[19384]\teval-rmse:3.85692\ttrain-rmse:1.97098\n",
      "[19385]\teval-rmse:3.85885\ttrain-rmse:1.97104\n",
      "[19386]\teval-rmse:3.85988\ttrain-rmse:1.9711\n",
      "[19387]\teval-rmse:3.85959\ttrain-rmse:1.97109\n",
      "[19388]\teval-rmse:3.8584\ttrain-rmse:1.97104\n",
      "[19389]\teval-rmse:3.85964\ttrain-rmse:1.9711\n",
      "[19390]\teval-rmse:3.86115\ttrain-rmse:1.97119\n",
      "[19391]\teval-rmse:3.86113\ttrain-rmse:1.97119\n",
      "[19392]\teval-rmse:3.85991\ttrain-rmse:1.97114\n",
      "[19393]\teval-rmse:3.85945\ttrain-rmse:1.97111\n",
      "[19394]\teval-rmse:3.85985\ttrain-rmse:1.97113\n",
      "[19395]\teval-rmse:3.85925\ttrain-rmse:1.9711\n",
      "[19396]\teval-rmse:3.85731\ttrain-rmse:1.97099\n",
      "[19397]\teval-rmse:3.85659\ttrain-rmse:1.97095\n",
      "[19398]\teval-rmse:3.85852\ttrain-rmse:1.97102\n",
      "[19399]\teval-rmse:3.86009\ttrain-rmse:1.97109\n",
      "[19400]\teval-rmse:3.8605\ttrain-rmse:1.97112\n",
      "[19401]\teval-rmse:3.86001\ttrain-rmse:1.97109\n",
      "[19402]\teval-rmse:3.85796\ttrain-rmse:1.97097\n",
      "[19403]\teval-rmse:3.85722\ttrain-rmse:1.97095\n",
      "[19404]\teval-rmse:3.85914\ttrain-rmse:1.97102\n",
      "[19405]\teval-rmse:3.85713\ttrain-rmse:1.97091\n",
      "[19406]\teval-rmse:3.85573\ttrain-rmse:1.97085\n",
      "[19407]\teval-rmse:3.855\ttrain-rmse:1.97083\n",
      "[19408]\teval-rmse:3.85516\ttrain-rmse:1.97084\n",
      "[19409]\teval-rmse:3.85554\ttrain-rmse:1.97086\n",
      "[19410]\teval-rmse:3.85331\ttrain-rmse:1.97077\n",
      "[19411]\teval-rmse:3.85285\ttrain-rmse:1.97063\n",
      "[19412]\teval-rmse:3.85335\ttrain-rmse:1.97066\n",
      "[19413]\teval-rmse:3.85254\ttrain-rmse:1.97063\n",
      "[19414]\teval-rmse:3.8529\ttrain-rmse:1.97064\n",
      "[19415]\teval-rmse:3.85337\ttrain-rmse:1.97066\n",
      "[19416]\teval-rmse:3.85362\ttrain-rmse:1.97066\n",
      "[19417]\teval-rmse:3.85231\ttrain-rmse:1.97062\n",
      "[19418]\teval-rmse:3.85367\ttrain-rmse:1.97067\n",
      "[19419]\teval-rmse:3.85453\ttrain-rmse:1.9707\n",
      "[19420]\teval-rmse:3.85494\ttrain-rmse:1.97072\n",
      "[19421]\teval-rmse:3.85422\ttrain-rmse:1.97069\n",
      "[19422]\teval-rmse:3.85272\ttrain-rmse:1.97064\n",
      "[19423]\teval-rmse:3.85318\ttrain-rmse:1.97066\n",
      "[19424]\teval-rmse:3.85181\ttrain-rmse:1.97061\n",
      "[19425]\teval-rmse:3.85352\ttrain-rmse:1.97067\n",
      "[19426]\teval-rmse:3.85384\ttrain-rmse:1.97069\n",
      "[19427]\teval-rmse:3.85426\ttrain-rmse:1.97071\n",
      "[19428]\teval-rmse:3.85443\ttrain-rmse:1.97071\n",
      "[19429]\teval-rmse:3.85473\ttrain-rmse:1.97073\n",
      "[19430]\teval-rmse:3.85541\ttrain-rmse:1.97076\n",
      "[19431]\teval-rmse:3.85699\ttrain-rmse:1.97084\n",
      "[19432]\teval-rmse:3.8565\ttrain-rmse:1.97071\n",
      "[19433]\teval-rmse:3.85501\ttrain-rmse:1.97064\n",
      "[19434]\teval-rmse:3.85546\ttrain-rmse:1.97066\n",
      "[19435]\teval-rmse:3.85509\ttrain-rmse:1.97065\n",
      "[19436]\teval-rmse:3.85702\ttrain-rmse:1.97071\n",
      "[19437]\teval-rmse:3.8555\ttrain-rmse:1.97066\n",
      "[19438]\teval-rmse:3.85603\ttrain-rmse:1.97068\n",
      "[19439]\teval-rmse:3.85717\ttrain-rmse:1.97074\n",
      "[19440]\teval-rmse:3.85654\ttrain-rmse:1.97072\n",
      "[19441]\teval-rmse:3.85699\ttrain-rmse:1.97074\n",
      "[19442]\teval-rmse:3.85832\ttrain-rmse:1.97081\n",
      "[19443]\teval-rmse:3.85633\ttrain-rmse:1.97071\n",
      "[19444]\teval-rmse:3.85588\ttrain-rmse:1.97058\n",
      "[19445]\teval-rmse:3.85541\ttrain-rmse:1.97056\n",
      "[19446]\teval-rmse:3.85654\ttrain-rmse:1.97062\n",
      "[19447]\teval-rmse:3.85433\ttrain-rmse:1.97051\n",
      "[19448]\teval-rmse:3.85499\ttrain-rmse:1.97054\n",
      "[19449]\teval-rmse:3.85357\ttrain-rmse:1.97049\n",
      "[19450]\teval-rmse:3.85496\ttrain-rmse:1.97056\n",
      "[19451]\teval-rmse:3.85459\ttrain-rmse:1.97054\n",
      "[19452]\teval-rmse:3.85575\ttrain-rmse:1.9706\n",
      "[19453]\teval-rmse:3.85538\ttrain-rmse:1.97058\n",
      "[19454]\teval-rmse:3.85366\ttrain-rmse:1.9705\n",
      "[19455]\teval-rmse:3.85414\ttrain-rmse:1.97053\n",
      "[19456]\teval-rmse:3.85533\ttrain-rmse:1.97058\n",
      "[19457]\teval-rmse:3.85603\ttrain-rmse:1.97062\n",
      "[19458]\teval-rmse:3.85542\ttrain-rmse:1.97059\n",
      "[19459]\teval-rmse:3.85575\ttrain-rmse:1.97061\n",
      "[19460]\teval-rmse:3.85422\ttrain-rmse:1.97057\n",
      "[19461]\teval-rmse:3.8535\ttrain-rmse:1.97054\n",
      "[19462]\teval-rmse:3.85529\ttrain-rmse:1.97057\n",
      "[19463]\teval-rmse:3.85676\ttrain-rmse:1.97065\n",
      "[19464]\teval-rmse:3.85801\ttrain-rmse:1.97071\n",
      "[19465]\teval-rmse:3.85752\ttrain-rmse:1.97069\n",
      "[19466]\teval-rmse:3.85656\ttrain-rmse:1.97065\n",
      "[19467]\teval-rmse:3.8574\ttrain-rmse:1.9707\n",
      "[19468]\teval-rmse:3.85934\ttrain-rmse:1.97077\n",
      "[19469]\teval-rmse:3.85906\ttrain-rmse:1.97075\n",
      "[19470]\teval-rmse:3.85956\ttrain-rmse:1.97079\n",
      "[19471]\teval-rmse:3.85926\ttrain-rmse:1.97077\n",
      "[19472]\teval-rmse:3.86043\ttrain-rmse:1.97085\n",
      "[19473]\teval-rmse:3.86203\ttrain-rmse:1.97095\n",
      "[19474]\teval-rmse:3.86152\ttrain-rmse:1.97082\n",
      "[19475]\teval-rmse:3.86144\ttrain-rmse:1.97082\n",
      "[19476]\teval-rmse:3.85988\ttrain-rmse:1.97072\n",
      "[19477]\teval-rmse:3.85953\ttrain-rmse:1.9707\n",
      "[19478]\teval-rmse:3.8611\ttrain-rmse:1.97074\n",
      "[19479]\teval-rmse:3.8624\ttrain-rmse:1.97084\n",
      "[19480]\teval-rmse:3.86103\ttrain-rmse:1.97079\n",
      "[19481]\teval-rmse:3.86225\ttrain-rmse:1.97088\n",
      "[19482]\teval-rmse:3.86127\ttrain-rmse:1.97081\n",
      "[19483]\teval-rmse:3.86212\ttrain-rmse:1.97083\n",
      "[19484]\teval-rmse:3.86161\ttrain-rmse:1.9708\n",
      "[19485]\teval-rmse:3.86131\ttrain-rmse:1.97079\n",
      "[19486]\teval-rmse:3.86191\ttrain-rmse:1.97083\n",
      "[19487]\teval-rmse:3.86051\ttrain-rmse:1.97073\n",
      "[19488]\teval-rmse:3.85845\ttrain-rmse:1.9706\n",
      "[19489]\teval-rmse:3.85678\ttrain-rmse:1.97053\n",
      "[19490]\teval-rmse:3.8563\ttrain-rmse:1.97051\n",
      "[19491]\teval-rmse:3.85577\ttrain-rmse:1.9705\n",
      "[19492]\teval-rmse:3.85434\ttrain-rmse:1.97047\n",
      "[19493]\teval-rmse:3.85331\ttrain-rmse:1.97042\n",
      "[19494]\teval-rmse:3.8536\ttrain-rmse:1.97043\n",
      "[19495]\teval-rmse:3.85415\ttrain-rmse:1.97046\n",
      "[19496]\teval-rmse:3.8541\ttrain-rmse:1.97046\n",
      "[19497]\teval-rmse:3.85363\ttrain-rmse:1.97044\n",
      "[19498]\teval-rmse:3.85466\ttrain-rmse:1.97049\n",
      "[19499]\teval-rmse:3.85441\ttrain-rmse:1.97048\n",
      "[19500]\teval-rmse:3.85468\ttrain-rmse:1.97049\n",
      "[19501]\teval-rmse:3.85661\ttrain-rmse:1.97056\n",
      "[19502]\teval-rmse:3.85783\ttrain-rmse:1.97063\n",
      "[19503]\teval-rmse:3.85812\ttrain-rmse:1.97064\n",
      "[19504]\teval-rmse:3.85678\ttrain-rmse:1.97061\n",
      "[19505]\teval-rmse:3.85627\ttrain-rmse:1.97059\n",
      "[19506]\teval-rmse:3.85555\ttrain-rmse:1.97055\n",
      "[19507]\teval-rmse:3.85503\ttrain-rmse:1.97054\n",
      "[19508]\teval-rmse:3.85557\ttrain-rmse:1.97056\n",
      "[19509]\teval-rmse:3.85425\ttrain-rmse:1.97053\n",
      "[19510]\teval-rmse:3.85279\ttrain-rmse:1.97046\n",
      "[19511]\teval-rmse:3.85345\ttrain-rmse:1.97048\n",
      "[19512]\teval-rmse:3.85319\ttrain-rmse:1.97046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19513]\teval-rmse:3.85188\ttrain-rmse:1.97042\n",
      "[19514]\teval-rmse:3.8538\ttrain-rmse:1.97048\n",
      "[19515]\teval-rmse:3.8546\ttrain-rmse:1.97052\n",
      "[19516]\teval-rmse:3.85549\ttrain-rmse:1.97053\n",
      "[19517]\teval-rmse:3.8543\ttrain-rmse:1.97049\n",
      "[19518]\teval-rmse:3.8528\ttrain-rmse:1.97044\n",
      "[19519]\teval-rmse:3.85098\ttrain-rmse:1.97037\n",
      "[19520]\teval-rmse:3.84908\ttrain-rmse:1.97029\n",
      "[19521]\teval-rmse:3.84839\ttrain-rmse:1.97029\n",
      "[19522]\teval-rmse:3.84794\ttrain-rmse:1.97028\n",
      "[19523]\teval-rmse:3.84964\ttrain-rmse:1.97031\n",
      "[19524]\teval-rmse:3.84835\ttrain-rmse:1.97027\n",
      "[19525]\teval-rmse:3.84957\ttrain-rmse:1.97031\n",
      "[19526]\teval-rmse:3.85035\ttrain-rmse:1.97034\n",
      "[19527]\teval-rmse:3.85\ttrain-rmse:1.97033\n",
      "[19528]\teval-rmse:3.84955\ttrain-rmse:1.97022\n",
      "[19529]\teval-rmse:3.84992\ttrain-rmse:1.97023\n",
      "[19530]\teval-rmse:3.84899\ttrain-rmse:1.9702\n",
      "[19531]\teval-rmse:3.84864\ttrain-rmse:1.97019\n",
      "[19532]\teval-rmse:3.84841\ttrain-rmse:1.97018\n",
      "[19533]\teval-rmse:3.85002\ttrain-rmse:1.97024\n",
      "[19534]\teval-rmse:3.84864\ttrain-rmse:1.9702\n",
      "[19535]\teval-rmse:3.84926\ttrain-rmse:1.97023\n",
      "[19536]\teval-rmse:3.84922\ttrain-rmse:1.97023\n",
      "[19537]\teval-rmse:3.84877\ttrain-rmse:1.9701\n",
      "[19538]\teval-rmse:3.84678\ttrain-rmse:1.97003\n",
      "[19539]\teval-rmse:3.84634\ttrain-rmse:1.96991\n",
      "[19540]\teval-rmse:3.84543\ttrain-rmse:1.9699\n",
      "[19541]\teval-rmse:3.84722\ttrain-rmse:1.96993\n",
      "[19542]\teval-rmse:3.84519\ttrain-rmse:1.96987\n",
      "[19543]\teval-rmse:3.84679\ttrain-rmse:1.96991\n",
      "[19544]\teval-rmse:3.84551\ttrain-rmse:1.96988\n",
      "[19545]\teval-rmse:3.84598\ttrain-rmse:1.96989\n",
      "[19546]\teval-rmse:3.84735\ttrain-rmse:1.96993\n",
      "[19547]\teval-rmse:3.84894\ttrain-rmse:1.96999\n",
      "[19548]\teval-rmse:3.84999\ttrain-rmse:1.97003\n",
      "[19549]\teval-rmse:3.84954\ttrain-rmse:1.97002\n",
      "[19550]\teval-rmse:3.84909\ttrain-rmse:1.97001\n",
      "[19551]\teval-rmse:3.85067\ttrain-rmse:1.97002\n",
      "[19552]\teval-rmse:3.85008\ttrain-rmse:1.97\n",
      "[19553]\teval-rmse:3.84966\ttrain-rmse:1.96998\n",
      "[19554]\teval-rmse:3.84818\ttrain-rmse:1.96993\n",
      "[19555]\teval-rmse:3.84661\ttrain-rmse:1.96989\n",
      "[19556]\teval-rmse:3.84547\ttrain-rmse:1.96987\n",
      "[19557]\teval-rmse:3.84504\ttrain-rmse:1.96986\n",
      "[19558]\teval-rmse:3.84546\ttrain-rmse:1.96988\n",
      "[19559]\teval-rmse:3.84503\ttrain-rmse:1.96976\n",
      "[19560]\teval-rmse:3.84412\ttrain-rmse:1.96974\n",
      "[19561]\teval-rmse:3.84479\ttrain-rmse:1.96975\n",
      "[19562]\teval-rmse:3.8463\ttrain-rmse:1.96981\n",
      "[19563]\teval-rmse:3.84696\ttrain-rmse:1.96983\n",
      "[19564]\teval-rmse:3.84752\ttrain-rmse:1.96985\n",
      "[19565]\teval-rmse:3.84766\ttrain-rmse:1.96986\n",
      "[19566]\teval-rmse:3.84893\ttrain-rmse:1.96991\n",
      "[19567]\teval-rmse:3.8495\ttrain-rmse:1.96993\n",
      "[19568]\teval-rmse:3.84756\ttrain-rmse:1.96985\n",
      "[19569]\teval-rmse:3.8461\ttrain-rmse:1.9698\n",
      "[19570]\teval-rmse:3.84474\ttrain-rmse:1.96975\n",
      "[19571]\teval-rmse:3.84635\ttrain-rmse:1.9698\n",
      "[19572]\teval-rmse:3.84506\ttrain-rmse:1.9698\n",
      "[19573]\teval-rmse:3.84365\ttrain-rmse:1.96975\n",
      "[19574]\teval-rmse:3.84455\ttrain-rmse:1.96975\n",
      "[19575]\teval-rmse:3.84624\ttrain-rmse:1.96975\n",
      "[19576]\teval-rmse:3.84743\ttrain-rmse:1.96979\n",
      "[19577]\teval-rmse:3.84562\ttrain-rmse:1.96974\n",
      "[19578]\teval-rmse:3.84592\ttrain-rmse:1.96974\n",
      "[19579]\teval-rmse:3.84548\ttrain-rmse:1.96974\n",
      "[19580]\teval-rmse:3.84699\ttrain-rmse:1.96979\n",
      "[19581]\teval-rmse:3.84867\ttrain-rmse:1.9698\n",
      "[19582]\teval-rmse:3.85029\ttrain-rmse:1.96986\n",
      "[19583]\teval-rmse:3.85066\ttrain-rmse:1.96988\n",
      "[19584]\teval-rmse:3.85208\ttrain-rmse:1.96995\n",
      "[19585]\teval-rmse:3.8503\ttrain-rmse:1.96986\n",
      "[19586]\teval-rmse:3.84843\ttrain-rmse:1.96979\n",
      "[19587]\teval-rmse:3.84971\ttrain-rmse:1.96984\n",
      "[19588]\teval-rmse:3.84926\ttrain-rmse:1.96972\n",
      "[19589]\teval-rmse:3.84881\ttrain-rmse:1.9697\n",
      "[19590]\teval-rmse:3.8504\ttrain-rmse:1.96977\n",
      "[19591]\teval-rmse:3.85074\ttrain-rmse:1.96978\n",
      "[19592]\teval-rmse:3.85006\ttrain-rmse:1.96975\n",
      "[19593]\teval-rmse:3.84858\ttrain-rmse:1.96971\n",
      "[19594]\teval-rmse:3.84903\ttrain-rmse:1.96973\n",
      "[19595]\teval-rmse:3.8476\ttrain-rmse:1.96967\n",
      "[19596]\teval-rmse:3.84707\ttrain-rmse:1.96965\n",
      "[19597]\teval-rmse:3.84766\ttrain-rmse:1.96968\n",
      "[19598]\teval-rmse:3.84545\ttrain-rmse:1.96961\n",
      "[19599]\teval-rmse:3.84555\ttrain-rmse:1.96961\n",
      "[19600]\teval-rmse:3.8464\ttrain-rmse:1.96964\n",
      "[19601]\teval-rmse:3.84527\ttrain-rmse:1.96962\n",
      "[19602]\teval-rmse:3.84348\ttrain-rmse:1.96957\n",
      "[19603]\teval-rmse:3.84193\ttrain-rmse:1.96955\n",
      "[19604]\teval-rmse:3.84228\ttrain-rmse:1.96955\n",
      "[19605]\teval-rmse:3.84336\ttrain-rmse:1.96958\n",
      "[19606]\teval-rmse:3.84168\ttrain-rmse:1.96954\n",
      "[19607]\teval-rmse:3.84216\ttrain-rmse:1.96955\n",
      "[19608]\teval-rmse:3.84359\ttrain-rmse:1.96959\n",
      "[19609]\teval-rmse:3.84311\ttrain-rmse:1.96958\n",
      "[19610]\teval-rmse:3.84332\ttrain-rmse:1.96958\n",
      "[19611]\teval-rmse:3.84526\ttrain-rmse:1.96961\n",
      "[19612]\teval-rmse:3.84615\ttrain-rmse:1.96961\n",
      "[19613]\teval-rmse:3.84575\ttrain-rmse:1.96949\n",
      "[19614]\teval-rmse:3.84602\ttrain-rmse:1.9695\n",
      "[19615]\teval-rmse:3.84489\ttrain-rmse:1.96948\n",
      "[19616]\teval-rmse:3.84456\ttrain-rmse:1.96948\n",
      "[19617]\teval-rmse:3.84507\ttrain-rmse:1.96949\n",
      "[19618]\teval-rmse:3.84394\ttrain-rmse:1.96947\n",
      "[19619]\teval-rmse:3.84477\ttrain-rmse:1.9695\n",
      "[19620]\teval-rmse:3.84433\ttrain-rmse:1.96949\n",
      "[19621]\teval-rmse:3.84288\ttrain-rmse:1.96945\n",
      "[19622]\teval-rmse:3.84481\ttrain-rmse:1.96948\n",
      "[19623]\teval-rmse:3.84519\ttrain-rmse:1.96949\n",
      "[19624]\teval-rmse:3.84406\ttrain-rmse:1.96947\n",
      "[19625]\teval-rmse:3.84242\ttrain-rmse:1.96942\n",
      "[19626]\teval-rmse:3.84115\ttrain-rmse:1.96943\n",
      "[19627]\teval-rmse:3.84268\ttrain-rmse:1.96944\n",
      "[19628]\teval-rmse:3.84265\ttrain-rmse:1.96944\n",
      "[19629]\teval-rmse:3.84408\ttrain-rmse:1.96949\n",
      "[19630]\teval-rmse:3.84576\ttrain-rmse:1.96949\n",
      "[19631]\teval-rmse:3.84396\ttrain-rmse:1.96943\n",
      "[19632]\teval-rmse:3.84589\ttrain-rmse:1.96947\n",
      "[19633]\teval-rmse:3.84735\ttrain-rmse:1.96951\n",
      "[19634]\teval-rmse:3.84802\ttrain-rmse:1.96954\n",
      "[19635]\teval-rmse:3.84672\ttrain-rmse:1.96953\n",
      "[19636]\teval-rmse:3.84605\ttrain-rmse:1.96951\n",
      "[19637]\teval-rmse:3.84435\ttrain-rmse:1.96945\n",
      "[19638]\teval-rmse:3.84452\ttrain-rmse:1.96945\n",
      "[19639]\teval-rmse:3.84525\ttrain-rmse:1.96947\n",
      "[19640]\teval-rmse:3.84309\ttrain-rmse:1.96942\n",
      "[19641]\teval-rmse:3.84287\ttrain-rmse:1.96941\n",
      "[19642]\teval-rmse:3.84142\ttrain-rmse:1.9694\n",
      "[19643]\teval-rmse:3.8405\ttrain-rmse:1.96938\n",
      "[19644]\teval-rmse:3.84113\ttrain-rmse:1.96939\n",
      "[19645]\teval-rmse:3.84135\ttrain-rmse:1.96939\n",
      "[19646]\teval-rmse:3.83923\ttrain-rmse:1.96936\n",
      "[19647]\teval-rmse:3.84077\ttrain-rmse:1.96938\n",
      "[19648]\teval-rmse:3.84257\ttrain-rmse:1.96938\n",
      "[19649]\teval-rmse:3.84145\ttrain-rmse:1.96936\n",
      "[19650]\teval-rmse:3.8409\ttrain-rmse:1.96936\n",
      "[19651]\teval-rmse:3.84269\ttrain-rmse:1.96935\n",
      "[19652]\teval-rmse:3.84406\ttrain-rmse:1.96937\n",
      "[19653]\teval-rmse:3.84294\ttrain-rmse:1.96935\n",
      "[19654]\teval-rmse:3.84487\ttrain-rmse:1.96938\n",
      "[19655]\teval-rmse:3.84535\ttrain-rmse:1.96939\n",
      "[19656]\teval-rmse:3.84463\ttrain-rmse:1.96937\n",
      "[19657]\teval-rmse:3.84616\ttrain-rmse:1.96942\n",
      "[19658]\teval-rmse:3.84788\ttrain-rmse:1.96948\n",
      "[19659]\teval-rmse:3.84917\ttrain-rmse:1.96952\n",
      "[19660]\teval-rmse:3.84825\ttrain-rmse:1.96949\n",
      "[19661]\teval-rmse:3.84644\ttrain-rmse:1.96943\n",
      "[19662]\teval-rmse:3.8453\ttrain-rmse:1.96941\n",
      "[19663]\teval-rmse:3.84692\ttrain-rmse:1.96946\n",
      "[19664]\teval-rmse:3.84625\ttrain-rmse:1.96944\n",
      "[19665]\teval-rmse:3.8466\ttrain-rmse:1.96945\n",
      "[19666]\teval-rmse:3.84504\ttrain-rmse:1.9694\n",
      "[19667]\teval-rmse:3.84561\ttrain-rmse:1.96941\n",
      "[19668]\teval-rmse:3.84633\ttrain-rmse:1.96943\n",
      "[19669]\teval-rmse:3.84803\ttrain-rmse:1.96949\n",
      "[19670]\teval-rmse:3.8487\ttrain-rmse:1.96951\n",
      "[19671]\teval-rmse:3.84904\ttrain-rmse:1.96953\n",
      "[19672]\teval-rmse:3.85096\ttrain-rmse:1.96958\n",
      "[19673]\teval-rmse:3.85274\ttrain-rmse:1.96961\n",
      "[19674]\teval-rmse:3.85304\ttrain-rmse:1.96962\n",
      "[19675]\teval-rmse:3.85321\ttrain-rmse:1.96963\n",
      "[19676]\teval-rmse:3.85203\ttrain-rmse:1.96959\n",
      "[19677]\teval-rmse:3.85157\ttrain-rmse:1.96957\n",
      "[19678]\teval-rmse:3.85018\ttrain-rmse:1.96951\n",
      "[19679]\teval-rmse:3.8514\ttrain-rmse:1.96956\n",
      "[19680]\teval-rmse:3.84989\ttrain-rmse:1.96953\n",
      "[19681]\teval-rmse:3.84943\ttrain-rmse:1.96942\n",
      "[19682]\teval-rmse:3.85009\ttrain-rmse:1.96944\n",
      "[19683]\teval-rmse:3.84878\ttrain-rmse:1.96939\n",
      "[19684]\teval-rmse:3.85037\ttrain-rmse:1.96946\n",
      "[19685]\teval-rmse:3.8514\ttrain-rmse:1.96951\n",
      "[19686]\teval-rmse:3.85089\ttrain-rmse:1.96948\n",
      "[19687]\teval-rmse:3.8501\ttrain-rmse:1.96945\n",
      "[19688]\teval-rmse:3.85182\ttrain-rmse:1.96952\n",
      "[19689]\teval-rmse:3.85138\ttrain-rmse:1.96941\n",
      "[19690]\teval-rmse:3.85083\ttrain-rmse:1.96939\n",
      "[19691]\teval-rmse:3.85223\ttrain-rmse:1.96946\n",
      "[19692]\teval-rmse:3.85255\ttrain-rmse:1.96947\n",
      "[19693]\teval-rmse:3.853\ttrain-rmse:1.9695\n",
      "[19694]\teval-rmse:3.85273\ttrain-rmse:1.96949\n",
      "[19695]\teval-rmse:3.85235\ttrain-rmse:1.96948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19696]\teval-rmse:3.85361\ttrain-rmse:1.96954\n",
      "[19697]\teval-rmse:3.85208\ttrain-rmse:1.96951\n",
      "[19698]\teval-rmse:3.8517\ttrain-rmse:1.96949\n",
      "[19699]\teval-rmse:3.85168\ttrain-rmse:1.96949\n",
      "[19700]\teval-rmse:3.84994\ttrain-rmse:1.96941\n",
      "[19701]\teval-rmse:3.85162\ttrain-rmse:1.96947\n",
      "[19702]\teval-rmse:3.84989\ttrain-rmse:1.96938\n",
      "[19703]\teval-rmse:3.84849\ttrain-rmse:1.96934\n",
      "[19704]\teval-rmse:3.84896\ttrain-rmse:1.96936\n",
      "[19705]\teval-rmse:3.84956\ttrain-rmse:1.96939\n",
      "[19706]\teval-rmse:3.85133\ttrain-rmse:1.96941\n",
      "[19707]\teval-rmse:3.85054\ttrain-rmse:1.96939\n",
      "[19708]\teval-rmse:3.85141\ttrain-rmse:1.96941\n",
      "[19709]\teval-rmse:3.85109\ttrain-rmse:1.9694\n",
      "[19710]\teval-rmse:3.85038\ttrain-rmse:1.96938\n",
      "[19711]\teval-rmse:3.84889\ttrain-rmse:1.96931\n",
      "[19712]\teval-rmse:3.84928\ttrain-rmse:1.96933\n",
      "[19713]\teval-rmse:3.85086\ttrain-rmse:1.96938\n",
      "[19714]\teval-rmse:3.85165\ttrain-rmse:1.96941\n",
      "[19715]\teval-rmse:3.85182\ttrain-rmse:1.96942\n",
      "[19716]\teval-rmse:3.85318\ttrain-rmse:1.96949\n",
      "[19717]\teval-rmse:3.85291\ttrain-rmse:1.96948\n",
      "[19718]\teval-rmse:3.85369\ttrain-rmse:1.96951\n",
      "[19719]\teval-rmse:3.85195\ttrain-rmse:1.96942\n",
      "[19720]\teval-rmse:3.85253\ttrain-rmse:1.96945\n",
      "[19721]\teval-rmse:3.8512\ttrain-rmse:1.96942\n",
      "[19722]\teval-rmse:3.85143\ttrain-rmse:1.96944\n",
      "[19723]\teval-rmse:3.85152\ttrain-rmse:1.96944\n",
      "[19724]\teval-rmse:3.85081\ttrain-rmse:1.96941\n",
      "[19725]\teval-rmse:3.85045\ttrain-rmse:1.9694\n",
      "[19726]\teval-rmse:3.84896\ttrain-rmse:1.96933\n",
      "[19727]\teval-rmse:3.8489\ttrain-rmse:1.96932\n",
      "[19728]\teval-rmse:3.84959\ttrain-rmse:1.96936\n",
      "[19729]\teval-rmse:3.85126\ttrain-rmse:1.96938\n",
      "[19730]\teval-rmse:3.85263\ttrain-rmse:1.96945\n",
      "[19731]\teval-rmse:3.8537\ttrain-rmse:1.96951\n",
      "[19732]\teval-rmse:3.85528\ttrain-rmse:1.96958\n",
      "[19733]\teval-rmse:3.855\ttrain-rmse:1.96957\n",
      "[19734]\teval-rmse:3.85452\ttrain-rmse:1.96945\n",
      "[19735]\teval-rmse:3.85414\ttrain-rmse:1.96943\n",
      "[19736]\teval-rmse:3.8536\ttrain-rmse:1.9694\n",
      "[19737]\teval-rmse:3.85445\ttrain-rmse:1.96944\n",
      "[19738]\teval-rmse:3.85327\ttrain-rmse:1.9694\n",
      "[19739]\teval-rmse:3.85364\ttrain-rmse:1.96942\n",
      "[19740]\teval-rmse:3.85268\ttrain-rmse:1.96936\n",
      "[19741]\teval-rmse:3.85242\ttrain-rmse:1.96935\n",
      "[19742]\teval-rmse:3.85392\ttrain-rmse:1.96944\n",
      "[19743]\teval-rmse:3.85294\ttrain-rmse:1.96938\n",
      "[19744]\teval-rmse:3.8533\ttrain-rmse:1.9694\n",
      "[19745]\teval-rmse:3.85177\ttrain-rmse:1.96936\n",
      "[19746]\teval-rmse:3.85336\ttrain-rmse:1.96945\n",
      "[19747]\teval-rmse:3.85283\ttrain-rmse:1.96942\n",
      "[19748]\teval-rmse:3.85417\ttrain-rmse:1.96948\n",
      "[19749]\teval-rmse:3.8532\ttrain-rmse:1.96942\n",
      "[19750]\teval-rmse:3.85426\ttrain-rmse:1.96948\n",
      "[19751]\teval-rmse:3.85424\ttrain-rmse:1.96948\n",
      "[19752]\teval-rmse:3.85438\ttrain-rmse:1.96949\n",
      "[19753]\teval-rmse:3.8558\ttrain-rmse:1.96958\n",
      "[19754]\teval-rmse:3.85745\ttrain-rmse:1.96963\n",
      "[19755]\teval-rmse:3.85877\ttrain-rmse:1.96973\n",
      "[19756]\teval-rmse:3.85774\ttrain-rmse:1.96965\n",
      "[19757]\teval-rmse:3.85595\ttrain-rmse:1.96954\n",
      "[19758]\teval-rmse:3.85759\ttrain-rmse:1.96965\n",
      "[19759]\teval-rmse:3.85753\ttrain-rmse:1.96965\n",
      "[19760]\teval-rmse:3.85913\ttrain-rmse:1.96976\n",
      "[19761]\teval-rmse:3.85802\ttrain-rmse:1.96968\n",
      "[19762]\teval-rmse:3.8596\ttrain-rmse:1.96977\n",
      "[19763]\teval-rmse:3.86074\ttrain-rmse:1.96985\n",
      "[19764]\teval-rmse:3.85926\ttrain-rmse:1.96979\n",
      "[19765]\teval-rmse:3.86082\ttrain-rmse:1.96992\n",
      "[19766]\teval-rmse:3.86126\ttrain-rmse:1.96996\n",
      "[19767]\teval-rmse:3.85952\ttrain-rmse:1.96982\n",
      "[19768]\teval-rmse:3.85831\ttrain-rmse:1.96976\n",
      "[19769]\teval-rmse:3.85841\ttrain-rmse:1.96977\n",
      "[19770]\teval-rmse:3.85792\ttrain-rmse:1.96966\n",
      "[19771]\teval-rmse:3.85843\ttrain-rmse:1.9697\n",
      "[19772]\teval-rmse:3.85919\ttrain-rmse:1.96975\n",
      "[19773]\teval-rmse:3.85873\ttrain-rmse:1.96964\n",
      "[19774]\teval-rmse:3.86005\ttrain-rmse:1.96974\n",
      "[19775]\teval-rmse:3.85822\ttrain-rmse:1.96958\n",
      "[19776]\teval-rmse:3.85685\ttrain-rmse:1.96953\n",
      "[19777]\teval-rmse:3.85611\ttrain-rmse:1.96948\n",
      "[19778]\teval-rmse:3.85695\ttrain-rmse:1.96954\n",
      "[19779]\teval-rmse:3.85672\ttrain-rmse:1.96952\n",
      "[19780]\teval-rmse:3.85691\ttrain-rmse:1.96954\n",
      "[19781]\teval-rmse:3.85844\ttrain-rmse:1.96965\n",
      "[19782]\teval-rmse:3.85784\ttrain-rmse:1.96961\n",
      "[19783]\teval-rmse:3.85728\ttrain-rmse:1.96957\n",
      "[19784]\teval-rmse:3.85856\ttrain-rmse:1.96967\n",
      "[19785]\teval-rmse:3.8566\ttrain-rmse:1.96953\n",
      "[19786]\teval-rmse:3.85612\ttrain-rmse:1.96951\n",
      "[19787]\teval-rmse:3.85641\ttrain-rmse:1.96954\n",
      "[19788]\teval-rmse:3.85435\ttrain-rmse:1.96939\n",
      "[19789]\teval-rmse:3.8554\ttrain-rmse:1.96946\n",
      "[19790]\teval-rmse:3.85531\ttrain-rmse:1.96945\n",
      "[19791]\teval-rmse:3.8553\ttrain-rmse:1.96945\n",
      "[19792]\teval-rmse:3.85411\ttrain-rmse:1.96941\n",
      "[19793]\teval-rmse:3.85204\ttrain-rmse:1.96927\n",
      "[19794]\teval-rmse:3.85071\ttrain-rmse:1.96924\n",
      "[19795]\teval-rmse:3.85263\ttrain-rmse:1.9693\n",
      "[19796]\teval-rmse:3.85219\ttrain-rmse:1.96919\n",
      "[19797]\teval-rmse:3.85192\ttrain-rmse:1.96918\n",
      "[19798]\teval-rmse:3.85021\ttrain-rmse:1.96907\n",
      "[19799]\teval-rmse:3.8518\ttrain-rmse:1.96915\n",
      "[19800]\teval-rmse:3.85241\ttrain-rmse:1.9692\n",
      "[19801]\teval-rmse:3.85407\ttrain-rmse:1.9693\n",
      "[19802]\teval-rmse:3.85599\ttrain-rmse:1.96937\n",
      "[19803]\teval-rmse:3.85641\ttrain-rmse:1.9694\n",
      "[19804]\teval-rmse:3.85726\ttrain-rmse:1.96946\n",
      "[19805]\teval-rmse:3.85584\ttrain-rmse:1.96936\n",
      "[19806]\teval-rmse:3.85448\ttrain-rmse:1.96929\n",
      "[19807]\teval-rmse:3.8564\ttrain-rmse:1.96936\n",
      "[19808]\teval-rmse:3.85576\ttrain-rmse:1.96934\n",
      "[19809]\teval-rmse:3.85743\ttrain-rmse:1.96939\n",
      "[19810]\teval-rmse:3.858\ttrain-rmse:1.96943\n",
      "[19811]\teval-rmse:3.85751\ttrain-rmse:1.96932\n",
      "[19812]\teval-rmse:3.85641\ttrain-rmse:1.96925\n",
      "[19813]\teval-rmse:3.85635\ttrain-rmse:1.96924\n",
      "[19814]\teval-rmse:3.8559\ttrain-rmse:1.96912\n",
      "[19815]\teval-rmse:3.85781\ttrain-rmse:1.9692\n",
      "[19816]\teval-rmse:3.85639\ttrain-rmse:1.9691\n",
      "[19817]\teval-rmse:3.85591\ttrain-rmse:1.96898\n",
      "[19818]\teval-rmse:3.85659\ttrain-rmse:1.96903\n",
      "[19819]\teval-rmse:3.85595\ttrain-rmse:1.96899\n",
      "[19820]\teval-rmse:3.85722\ttrain-rmse:1.96908\n",
      "[19821]\teval-rmse:3.85649\ttrain-rmse:1.96903\n",
      "[19822]\teval-rmse:3.85473\ttrain-rmse:1.9689\n",
      "[19823]\teval-rmse:3.85665\ttrain-rmse:1.96898\n",
      "[19824]\teval-rmse:3.85521\ttrain-rmse:1.9689\n",
      "[19825]\teval-rmse:3.8567\ttrain-rmse:1.969\n",
      "[19826]\teval-rmse:3.85681\ttrain-rmse:1.96901\n",
      "[19827]\teval-rmse:3.85471\ttrain-rmse:1.96887\n",
      "[19828]\teval-rmse:3.85352\ttrain-rmse:1.96883\n",
      "[19829]\teval-rmse:3.85544\ttrain-rmse:1.9689\n",
      "[19830]\teval-rmse:3.85651\ttrain-rmse:1.96897\n",
      "[19831]\teval-rmse:3.85475\ttrain-rmse:1.96885\n",
      "[19832]\teval-rmse:3.85439\ttrain-rmse:1.96883\n",
      "[19833]\teval-rmse:3.85392\ttrain-rmse:1.96881\n",
      "[19834]\teval-rmse:3.85344\ttrain-rmse:1.96879\n",
      "[19835]\teval-rmse:3.85271\ttrain-rmse:1.96877\n",
      "[19836]\teval-rmse:3.85087\ttrain-rmse:1.9687\n",
      "[19837]\teval-rmse:3.85263\ttrain-rmse:1.96873\n",
      "[19838]\teval-rmse:3.8519\ttrain-rmse:1.96871\n",
      "[19839]\teval-rmse:3.8529\ttrain-rmse:1.96877\n",
      "[19840]\teval-rmse:3.85305\ttrain-rmse:1.96878\n",
      "[19841]\teval-rmse:3.85338\ttrain-rmse:1.9688\n",
      "[19842]\teval-rmse:3.85335\ttrain-rmse:1.9688\n",
      "[19843]\teval-rmse:3.8548\ttrain-rmse:1.96889\n",
      "[19844]\teval-rmse:3.85534\ttrain-rmse:1.96893\n",
      "[19845]\teval-rmse:3.85471\ttrain-rmse:1.96889\n",
      "[19846]\teval-rmse:3.85557\ttrain-rmse:1.96894\n",
      "[19847]\teval-rmse:3.85555\ttrain-rmse:1.96894\n",
      "[19848]\teval-rmse:3.85354\ttrain-rmse:1.96881\n",
      "[19849]\teval-rmse:3.85546\ttrain-rmse:1.96888\n",
      "[19850]\teval-rmse:3.85507\ttrain-rmse:1.96886\n",
      "[19851]\teval-rmse:3.85388\ttrain-rmse:1.96882\n",
      "[19852]\teval-rmse:3.85163\ttrain-rmse:1.96869\n",
      "[19853]\teval-rmse:3.85264\ttrain-rmse:1.96874\n",
      "[19854]\teval-rmse:3.85319\ttrain-rmse:1.96878\n",
      "[19855]\teval-rmse:3.85176\ttrain-rmse:1.96874\n",
      "[19856]\teval-rmse:3.84969\ttrain-rmse:1.96863\n",
      "[19857]\teval-rmse:3.84933\ttrain-rmse:1.96862\n",
      "[19858]\teval-rmse:3.85099\ttrain-rmse:1.96865\n",
      "[19859]\teval-rmse:3.8501\ttrain-rmse:1.96861\n",
      "[19860]\teval-rmse:3.85177\ttrain-rmse:1.96867\n",
      "[19861]\teval-rmse:3.85295\ttrain-rmse:1.96873\n",
      "[19862]\teval-rmse:3.85122\ttrain-rmse:1.96864\n",
      "[19863]\teval-rmse:3.85096\ttrain-rmse:1.96863\n",
      "[19864]\teval-rmse:3.85128\ttrain-rmse:1.96864\n",
      "[19865]\teval-rmse:3.85059\ttrain-rmse:1.96861\n",
      "[19866]\teval-rmse:3.851\ttrain-rmse:1.96863\n",
      "[19867]\teval-rmse:3.8511\ttrain-rmse:1.96864\n",
      "[19868]\teval-rmse:3.85064\ttrain-rmse:1.96852\n",
      "[19869]\teval-rmse:3.85192\ttrain-rmse:1.96859\n",
      "[19870]\teval-rmse:3.85048\ttrain-rmse:1.96856\n",
      "[19871]\teval-rmse:3.85196\ttrain-rmse:1.96864\n",
      "[19872]\teval-rmse:3.8515\ttrain-rmse:1.96862\n",
      "[19873]\teval-rmse:3.84944\ttrain-rmse:1.96852\n",
      "[19874]\teval-rmse:3.84899\ttrain-rmse:1.9684\n",
      "[19875]\teval-rmse:3.84713\ttrain-rmse:1.96831\n",
      "[19876]\teval-rmse:3.84602\ttrain-rmse:1.96826\n",
      "[19877]\teval-rmse:3.84446\ttrain-rmse:1.96821\n",
      "[19878]\teval-rmse:3.84497\ttrain-rmse:1.96822\n",
      "[19879]\teval-rmse:3.84474\ttrain-rmse:1.96822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19880]\teval-rmse:3.84528\ttrain-rmse:1.96824\n",
      "[19881]\teval-rmse:3.84381\ttrain-rmse:1.96819\n",
      "[19882]\teval-rmse:3.84424\ttrain-rmse:1.9682\n",
      "[19883]\teval-rmse:3.84554\ttrain-rmse:1.96825\n",
      "[19884]\teval-rmse:3.84568\ttrain-rmse:1.96825\n",
      "[19885]\teval-rmse:3.84517\ttrain-rmse:1.96825\n",
      "[19886]\teval-rmse:3.84362\ttrain-rmse:1.96819\n",
      "[19887]\teval-rmse:3.84228\ttrain-rmse:1.96815\n",
      "[19888]\teval-rmse:3.84157\ttrain-rmse:1.96813\n",
      "[19889]\teval-rmse:3.84136\ttrain-rmse:1.96812\n",
      "[19890]\teval-rmse:3.84285\ttrain-rmse:1.96817\n",
      "[19891]\teval-rmse:3.8435\ttrain-rmse:1.96818\n",
      "[19892]\teval-rmse:3.8451\ttrain-rmse:1.96822\n",
      "[19893]\teval-rmse:3.84415\ttrain-rmse:1.96818\n",
      "[19894]\teval-rmse:3.84372\ttrain-rmse:1.96807\n",
      "[19895]\teval-rmse:3.84405\ttrain-rmse:1.96808\n",
      "[19896]\teval-rmse:3.84371\ttrain-rmse:1.96807\n",
      "[19897]\teval-rmse:3.84426\ttrain-rmse:1.96809\n",
      "[19898]\teval-rmse:3.8447\ttrain-rmse:1.96811\n",
      "[19899]\teval-rmse:3.84521\ttrain-rmse:1.96813\n",
      "[19900]\teval-rmse:3.84688\ttrain-rmse:1.96818\n",
      "[19901]\teval-rmse:3.84644\ttrain-rmse:1.96816\n",
      "[19902]\teval-rmse:3.8482\ttrain-rmse:1.96819\n",
      "[19903]\teval-rmse:3.84688\ttrain-rmse:1.96816\n",
      "[19904]\teval-rmse:3.84653\ttrain-rmse:1.96816\n",
      "[19905]\teval-rmse:3.84613\ttrain-rmse:1.96804\n",
      "[19906]\teval-rmse:3.84412\ttrain-rmse:1.96796\n",
      "[19907]\teval-rmse:3.84343\ttrain-rmse:1.96795\n",
      "[19908]\teval-rmse:3.8431\ttrain-rmse:1.96795\n",
      "[19909]\teval-rmse:3.84137\ttrain-rmse:1.96789\n",
      "[19910]\teval-rmse:3.84159\ttrain-rmse:1.9679\n",
      "[19911]\teval-rmse:3.84126\ttrain-rmse:1.96789\n",
      "[19912]\teval-rmse:3.84051\ttrain-rmse:1.96788\n",
      "[19913]\teval-rmse:3.84113\ttrain-rmse:1.9679\n",
      "[19914]\teval-rmse:3.83936\ttrain-rmse:1.96785\n",
      "[19915]\teval-rmse:3.84007\ttrain-rmse:1.96787\n",
      "[19916]\teval-rmse:3.83847\ttrain-rmse:1.96785\n",
      "[19917]\teval-rmse:3.83978\ttrain-rmse:1.96788\n",
      "[19918]\teval-rmse:3.8409\ttrain-rmse:1.96791\n",
      "[19919]\teval-rmse:3.84202\ttrain-rmse:1.96795\n",
      "[19920]\teval-rmse:3.84041\ttrain-rmse:1.96791\n",
      "[19921]\teval-rmse:3.84\ttrain-rmse:1.9679\n",
      "[19922]\teval-rmse:3.83969\ttrain-rmse:1.9679\n",
      "[19923]\teval-rmse:3.83772\ttrain-rmse:1.96785\n",
      "[19924]\teval-rmse:3.83943\ttrain-rmse:1.96788\n",
      "[19925]\teval-rmse:3.84059\ttrain-rmse:1.96792\n",
      "[19926]\teval-rmse:3.83969\ttrain-rmse:1.9679\n",
      "[19927]\teval-rmse:3.84162\ttrain-rmse:1.96792\n",
      "[19928]\teval-rmse:3.84251\ttrain-rmse:1.96795\n",
      "[19929]\teval-rmse:3.84444\ttrain-rmse:1.96798\n",
      "[19930]\teval-rmse:3.84347\ttrain-rmse:1.96795\n",
      "[19931]\teval-rmse:3.8438\ttrain-rmse:1.96796\n",
      "[19932]\teval-rmse:3.84428\ttrain-rmse:1.96798\n",
      "[19933]\teval-rmse:3.84331\ttrain-rmse:1.96795\n",
      "[19934]\teval-rmse:3.84298\ttrain-rmse:1.96794\n",
      "[19935]\teval-rmse:3.84335\ttrain-rmse:1.96795\n",
      "[19936]\teval-rmse:3.84356\ttrain-rmse:1.96796\n",
      "[19937]\teval-rmse:3.84504\ttrain-rmse:1.96802\n",
      "[19938]\teval-rmse:3.84592\ttrain-rmse:1.96803\n",
      "[19939]\teval-rmse:3.84429\ttrain-rmse:1.96799\n",
      "[19940]\teval-rmse:3.84479\ttrain-rmse:1.96801\n",
      "[19941]\teval-rmse:3.84584\ttrain-rmse:1.96805\n",
      "[19942]\teval-rmse:3.84614\ttrain-rmse:1.96806\n",
      "[19943]\teval-rmse:3.84439\ttrain-rmse:1.96799\n",
      "[19944]\teval-rmse:3.84453\ttrain-rmse:1.96799\n",
      "[19945]\teval-rmse:3.84467\ttrain-rmse:1.968\n",
      "[19946]\teval-rmse:3.84491\ttrain-rmse:1.96801\n",
      "[19947]\teval-rmse:3.84542\ttrain-rmse:1.96803\n",
      "[19948]\teval-rmse:3.84645\ttrain-rmse:1.96807\n",
      "[19949]\teval-rmse:3.84838\ttrain-rmse:1.96812\n",
      "[19950]\teval-rmse:3.84851\ttrain-rmse:1.96813\n",
      "[19951]\teval-rmse:3.84985\ttrain-rmse:1.9682\n",
      "[19952]\teval-rmse:3.84763\ttrain-rmse:1.96808\n",
      "[19953]\teval-rmse:3.84693\ttrain-rmse:1.96807\n",
      "[19954]\teval-rmse:3.8473\ttrain-rmse:1.96809\n",
      "[19955]\teval-rmse:3.84686\ttrain-rmse:1.96798\n",
      "[19956]\teval-rmse:3.84746\ttrain-rmse:1.96801\n",
      "[19957]\teval-rmse:3.84597\ttrain-rmse:1.96799\n",
      "[19958]\teval-rmse:3.84483\ttrain-rmse:1.96796\n",
      "[19959]\teval-rmse:3.84653\ttrain-rmse:1.96805\n",
      "[19960]\teval-rmse:3.84487\ttrain-rmse:1.96797\n",
      "[19961]\teval-rmse:3.84318\ttrain-rmse:1.96791\n",
      "[19962]\teval-rmse:3.84341\ttrain-rmse:1.96792\n",
      "[19963]\teval-rmse:3.84195\ttrain-rmse:1.96789\n",
      "[19964]\teval-rmse:3.84317\ttrain-rmse:1.96794\n",
      "[19965]\teval-rmse:3.84307\ttrain-rmse:1.96793\n",
      "[19966]\teval-rmse:3.84379\ttrain-rmse:1.96796\n",
      "[19967]\teval-rmse:3.84445\ttrain-rmse:1.96799\n",
      "[19968]\teval-rmse:3.8448\ttrain-rmse:1.968\n",
      "[19969]\teval-rmse:3.84515\ttrain-rmse:1.96802\n",
      "[19970]\teval-rmse:3.84345\ttrain-rmse:1.96794\n",
      "[19971]\teval-rmse:3.84512\ttrain-rmse:1.968\n",
      "[19972]\teval-rmse:3.8445\ttrain-rmse:1.96797\n",
      "[19973]\teval-rmse:3.84248\ttrain-rmse:1.96791\n",
      "[19974]\teval-rmse:3.84374\ttrain-rmse:1.96793\n",
      "[19975]\teval-rmse:3.84511\ttrain-rmse:1.96798\n",
      "[19976]\teval-rmse:3.84343\ttrain-rmse:1.96792\n",
      "[19977]\teval-rmse:3.84511\ttrain-rmse:1.96793\n",
      "[19978]\teval-rmse:3.84661\ttrain-rmse:1.96796\n",
      "[19979]\teval-rmse:3.84489\ttrain-rmse:1.96792\n",
      "[19980]\teval-rmse:3.8445\ttrain-rmse:1.96781\n",
      "[19981]\teval-rmse:3.844\ttrain-rmse:1.9678\n",
      "[19982]\teval-rmse:3.84332\ttrain-rmse:1.96777\n",
      "[19983]\teval-rmse:3.84493\ttrain-rmse:1.96782\n",
      "[19984]\teval-rmse:3.84333\ttrain-rmse:1.96777\n",
      "[19985]\teval-rmse:3.84167\ttrain-rmse:1.96771\n",
      "[19986]\teval-rmse:3.84278\ttrain-rmse:1.96775\n",
      "[19987]\teval-rmse:3.84212\ttrain-rmse:1.96773\n",
      "[19988]\teval-rmse:3.84042\ttrain-rmse:1.96767\n",
      "[19989]\teval-rmse:3.83975\ttrain-rmse:1.96767\n",
      "[19990]\teval-rmse:3.83939\ttrain-rmse:1.96757\n",
      "[19991]\teval-rmse:3.84132\ttrain-rmse:1.96759\n",
      "[19992]\teval-rmse:3.84214\ttrain-rmse:1.9676\n",
      "[19993]\teval-rmse:3.84166\ttrain-rmse:1.96759\n",
      "[19994]\teval-rmse:3.84333\ttrain-rmse:1.9676\n",
      "[19995]\teval-rmse:3.84179\ttrain-rmse:1.96755\n",
      "[19996]\teval-rmse:3.84331\ttrain-rmse:1.96759\n",
      "[19997]\teval-rmse:3.84396\ttrain-rmse:1.96761\n",
      "[19998]\teval-rmse:3.84483\ttrain-rmse:1.96762\n",
      "[19999]\teval-rmse:3.8433\ttrain-rmse:1.96757\n",
      "[20000]\teval-rmse:3.84354\ttrain-rmse:1.96758\n",
      "[20001]\teval-rmse:3.84301\ttrain-rmse:1.96756\n",
      "[20002]\teval-rmse:3.84154\ttrain-rmse:1.96755\n",
      "[20003]\teval-rmse:3.84186\ttrain-rmse:1.96756\n",
      "[20004]\teval-rmse:3.84163\ttrain-rmse:1.96756\n",
      "[20005]\teval-rmse:3.84089\ttrain-rmse:1.96755\n",
      "[20006]\teval-rmse:3.84029\ttrain-rmse:1.96753\n",
      "[20007]\teval-rmse:3.84222\ttrain-rmse:1.96756\n",
      "[20008]\teval-rmse:3.8436\ttrain-rmse:1.96761\n",
      "[20009]\teval-rmse:3.84192\ttrain-rmse:1.96756\n",
      "[20010]\teval-rmse:3.8405\ttrain-rmse:1.96753\n",
      "[20011]\teval-rmse:3.83924\ttrain-rmse:1.9675\n",
      "[20012]\teval-rmse:3.83866\ttrain-rmse:1.96749\n",
      "[20013]\teval-rmse:3.83917\ttrain-rmse:1.9675\n",
      "[20014]\teval-rmse:3.83807\ttrain-rmse:1.96749\n",
      "[20015]\teval-rmse:3.84\ttrain-rmse:1.96751\n",
      "[20016]\teval-rmse:3.83935\ttrain-rmse:1.96751\n",
      "[20017]\teval-rmse:3.83776\ttrain-rmse:1.96748\n",
      "[20018]\teval-rmse:3.83969\ttrain-rmse:1.9675\n",
      "[20019]\teval-rmse:3.83834\ttrain-rmse:1.96748\n",
      "[20020]\teval-rmse:3.83971\ttrain-rmse:1.96751\n",
      "[20021]\teval-rmse:3.83995\ttrain-rmse:1.96751\n",
      "[20022]\teval-rmse:3.83974\ttrain-rmse:1.96751\n",
      "[20023]\teval-rmse:3.84152\ttrain-rmse:1.96754\n",
      "[20024]\teval-rmse:3.83935\ttrain-rmse:1.96749\n",
      "[20025]\teval-rmse:3.83914\ttrain-rmse:1.96749\n",
      "[20026]\teval-rmse:3.83772\ttrain-rmse:1.96748\n",
      "[20027]\teval-rmse:3.83855\ttrain-rmse:1.96749\n",
      "[20028]\teval-rmse:3.83819\ttrain-rmse:1.96738\n",
      "[20029]\teval-rmse:3.83928\ttrain-rmse:1.96739\n",
      "[20030]\teval-rmse:3.83888\ttrain-rmse:1.96739\n",
      "[20031]\teval-rmse:3.83763\ttrain-rmse:1.96737\n",
      "[20032]\teval-rmse:3.83569\ttrain-rmse:1.96735\n",
      "[20033]\teval-rmse:3.83436\ttrain-rmse:1.96737\n",
      "[20034]\teval-rmse:3.83575\ttrain-rmse:1.96738\n",
      "[20035]\teval-rmse:3.83713\ttrain-rmse:1.96738\n",
      "[20036]\teval-rmse:3.83735\ttrain-rmse:1.96738\n",
      "[20037]\teval-rmse:3.83695\ttrain-rmse:1.96738\n",
      "[20038]\teval-rmse:3.83484\ttrain-rmse:1.96735\n",
      "[20039]\teval-rmse:3.83536\ttrain-rmse:1.96735\n",
      "[20040]\teval-rmse:3.83371\ttrain-rmse:1.96735\n",
      "[20041]\teval-rmse:3.83503\ttrain-rmse:1.96735\n",
      "[20042]\teval-rmse:3.83458\ttrain-rmse:1.96735\n",
      "[20043]\teval-rmse:3.83476\ttrain-rmse:1.96736\n",
      "[20044]\teval-rmse:3.83336\ttrain-rmse:1.96738\n",
      "[20045]\teval-rmse:3.83489\ttrain-rmse:1.96738\n",
      "[20046]\teval-rmse:3.83571\ttrain-rmse:1.96738\n",
      "[20047]\teval-rmse:3.8374\ttrain-rmse:1.96736\n",
      "[20048]\teval-rmse:3.83933\ttrain-rmse:1.96738\n",
      "[20049]\teval-rmse:3.84093\ttrain-rmse:1.9674\n",
      "[20050]\teval-rmse:3.84261\ttrain-rmse:1.96743\n",
      "[20051]\teval-rmse:3.84116\ttrain-rmse:1.9674\n",
      "[20052]\teval-rmse:3.84253\ttrain-rmse:1.96743\n",
      "[20053]\teval-rmse:3.84197\ttrain-rmse:1.96742\n",
      "[20054]\teval-rmse:3.84324\ttrain-rmse:1.96745\n",
      "[20055]\teval-rmse:3.84267\ttrain-rmse:1.96745\n",
      "[20056]\teval-rmse:3.8431\ttrain-rmse:1.96746\n",
      "[20057]\teval-rmse:3.84437\ttrain-rmse:1.96748\n",
      "[20058]\teval-rmse:3.8438\ttrain-rmse:1.96747\n",
      "[20059]\teval-rmse:3.84484\ttrain-rmse:1.9675\n",
      "[20060]\teval-rmse:3.84337\ttrain-rmse:1.96747\n",
      "[20061]\teval-rmse:3.84202\ttrain-rmse:1.96745\n",
      "[20062]\teval-rmse:3.84253\ttrain-rmse:1.96747\n",
      "[20063]\teval-rmse:3.84077\ttrain-rmse:1.96743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20064]\teval-rmse:3.83945\ttrain-rmse:1.9674\n",
      "[20065]\teval-rmse:3.83793\ttrain-rmse:1.96738\n",
      "[20066]\teval-rmse:3.83739\ttrain-rmse:1.96739\n",
      "[20067]\teval-rmse:3.83907\ttrain-rmse:1.96737\n",
      "[20068]\teval-rmse:3.83816\ttrain-rmse:1.96736\n",
      "[20069]\teval-rmse:3.83691\ttrain-rmse:1.96735\n",
      "[20070]\teval-rmse:3.83582\ttrain-rmse:1.96735\n",
      "[20071]\teval-rmse:3.83435\ttrain-rmse:1.96734\n",
      "[20072]\teval-rmse:3.83366\ttrain-rmse:1.96734\n",
      "[20073]\teval-rmse:3.83259\ttrain-rmse:1.96735\n",
      "[20074]\teval-rmse:3.83226\ttrain-rmse:1.96725\n",
      "[20075]\teval-rmse:3.8328\ttrain-rmse:1.96725\n",
      "[20076]\teval-rmse:3.83167\ttrain-rmse:1.96725\n",
      "[20077]\teval-rmse:3.83007\ttrain-rmse:1.96726\n",
      "[20078]\teval-rmse:3.82924\ttrain-rmse:1.96728\n",
      "[20079]\teval-rmse:3.82896\ttrain-rmse:1.96728\n",
      "[20080]\teval-rmse:3.82969\ttrain-rmse:1.96727\n",
      "[20081]\teval-rmse:3.82989\ttrain-rmse:1.96727\n",
      "[20082]\teval-rmse:3.83042\ttrain-rmse:1.96726\n",
      "[20083]\teval-rmse:3.82885\ttrain-rmse:1.96728\n",
      "[20084]\teval-rmse:3.82887\ttrain-rmse:1.96728\n",
      "[20085]\teval-rmse:3.82727\ttrain-rmse:1.96731\n",
      "[20086]\teval-rmse:3.82889\ttrain-rmse:1.96728\n",
      "[20087]\teval-rmse:3.83034\ttrain-rmse:1.96726\n",
      "[20088]\teval-rmse:3.83188\ttrain-rmse:1.96725\n",
      "[20089]\teval-rmse:3.83341\ttrain-rmse:1.96725\n",
      "[20090]\teval-rmse:3.83362\ttrain-rmse:1.96725\n",
      "[20091]\teval-rmse:3.83416\ttrain-rmse:1.96725\n",
      "[20092]\teval-rmse:3.83455\ttrain-rmse:1.96726\n",
      "[20093]\teval-rmse:3.83494\ttrain-rmse:1.96726\n",
      "[20094]\teval-rmse:3.83535\ttrain-rmse:1.96727\n",
      "[20095]\teval-rmse:3.83695\ttrain-rmse:1.96728\n",
      "[20096]\teval-rmse:3.83851\ttrain-rmse:1.96731\n",
      "[20097]\teval-rmse:3.83869\ttrain-rmse:1.96731\n",
      "[20098]\teval-rmse:3.83898\ttrain-rmse:1.96732\n",
      "[20099]\teval-rmse:3.83834\ttrain-rmse:1.96731\n",
      "[20100]\teval-rmse:3.83898\ttrain-rmse:1.96733\n",
      "[20101]\teval-rmse:3.837\ttrain-rmse:1.9673\n",
      "[20102]\teval-rmse:3.83748\ttrain-rmse:1.96731\n",
      "[20103]\teval-rmse:3.83727\ttrain-rmse:1.9673\n",
      "[20104]\teval-rmse:3.83744\ttrain-rmse:1.96731\n",
      "[20105]\teval-rmse:3.83815\ttrain-rmse:1.96732\n",
      "[20106]\teval-rmse:3.83639\ttrain-rmse:1.96732\n",
      "[20107]\teval-rmse:3.83832\ttrain-rmse:1.96733\n",
      "[20108]\teval-rmse:3.84024\ttrain-rmse:1.96735\n",
      "[20109]\teval-rmse:3.83992\ttrain-rmse:1.96734\n",
      "[20110]\teval-rmse:3.83986\ttrain-rmse:1.96734\n",
      "[20111]\teval-rmse:3.83821\ttrain-rmse:1.96732\n",
      "[20112]\teval-rmse:3.83782\ttrain-rmse:1.96721\n",
      "[20113]\teval-rmse:3.8382\ttrain-rmse:1.96722\n",
      "[20114]\teval-rmse:3.84013\ttrain-rmse:1.96724\n",
      "[20115]\teval-rmse:3.83902\ttrain-rmse:1.96723\n",
      "[20116]\teval-rmse:3.83862\ttrain-rmse:1.96713\n",
      "[20117]\teval-rmse:3.83888\ttrain-rmse:1.96714\n",
      "[20118]\teval-rmse:3.83909\ttrain-rmse:1.96714\n",
      "[20119]\teval-rmse:3.83747\ttrain-rmse:1.96711\n",
      "[20120]\teval-rmse:3.83622\ttrain-rmse:1.96712\n",
      "[20121]\teval-rmse:3.8345\ttrain-rmse:1.9671\n",
      "[20122]\teval-rmse:3.83621\ttrain-rmse:1.96712\n",
      "[20123]\teval-rmse:3.83433\ttrain-rmse:1.96709\n",
      "[20124]\teval-rmse:3.83271\ttrain-rmse:1.96709\n",
      "[20125]\teval-rmse:3.83362\ttrain-rmse:1.96707\n",
      "[20126]\teval-rmse:3.83523\ttrain-rmse:1.96706\n",
      "[20127]\teval-rmse:3.83695\ttrain-rmse:1.96707\n",
      "[20128]\teval-rmse:3.83534\ttrain-rmse:1.96706\n",
      "[20129]\teval-rmse:3.83617\ttrain-rmse:1.96706\n",
      "[20130]\teval-rmse:3.8381\ttrain-rmse:1.96707\n",
      "[20131]\teval-rmse:3.8397\ttrain-rmse:1.96708\n",
      "[20132]\teval-rmse:3.83859\ttrain-rmse:1.96707\n",
      "[20133]\teval-rmse:3.83827\ttrain-rmse:1.96706\n",
      "[20134]\teval-rmse:3.83788\ttrain-rmse:1.96706\n",
      "[20135]\teval-rmse:3.83816\ttrain-rmse:1.96706\n",
      "[20136]\teval-rmse:3.83621\ttrain-rmse:1.96704\n",
      "[20137]\teval-rmse:3.83561\ttrain-rmse:1.96704\n",
      "[20138]\teval-rmse:3.83438\ttrain-rmse:1.96706\n",
      "[20139]\teval-rmse:3.83608\ttrain-rmse:1.96705\n",
      "[20140]\teval-rmse:3.83499\ttrain-rmse:1.96705\n",
      "[20141]\teval-rmse:3.8333\ttrain-rmse:1.96704\n",
      "[20142]\teval-rmse:3.83382\ttrain-rmse:1.96704\n",
      "[20143]\teval-rmse:3.83235\ttrain-rmse:1.96704\n",
      "[20144]\teval-rmse:3.83287\ttrain-rmse:1.96704\n",
      "[20145]\teval-rmse:3.8325\ttrain-rmse:1.96704\n",
      "[20146]\teval-rmse:3.8323\ttrain-rmse:1.96704\n",
      "[20147]\teval-rmse:3.83124\ttrain-rmse:1.96704\n",
      "[20148]\teval-rmse:3.83081\ttrain-rmse:1.96705\n",
      "[20149]\teval-rmse:3.83253\ttrain-rmse:1.96705\n",
      "[20150]\teval-rmse:3.83234\ttrain-rmse:1.96705\n",
      "[20151]\teval-rmse:3.83196\ttrain-rmse:1.96705\n",
      "[20152]\teval-rmse:3.83269\ttrain-rmse:1.96706\n",
      "[20153]\teval-rmse:3.83141\ttrain-rmse:1.96706\n",
      "[20154]\teval-rmse:3.83249\ttrain-rmse:1.96706\n",
      "[20155]\teval-rmse:3.8342\ttrain-rmse:1.96706\n",
      "[20156]\teval-rmse:3.83392\ttrain-rmse:1.96706\n",
      "[20157]\teval-rmse:3.83251\ttrain-rmse:1.96706\n",
      "[20158]\teval-rmse:3.8312\ttrain-rmse:1.96709\n",
      "[20159]\teval-rmse:3.83087\ttrain-rmse:1.96699\n",
      "[20160]\teval-rmse:3.83266\ttrain-rmse:1.96696\n",
      "[20161]\teval-rmse:3.83236\ttrain-rmse:1.96696\n",
      "[20162]\teval-rmse:3.83385\ttrain-rmse:1.96697\n",
      "[20163]\teval-rmse:3.83502\ttrain-rmse:1.96699\n",
      "[20164]\teval-rmse:3.83542\ttrain-rmse:1.967\n",
      "[20165]\teval-rmse:3.83702\ttrain-rmse:1.96698\n",
      "[20166]\teval-rmse:3.83593\ttrain-rmse:1.96697\n",
      "[20167]\teval-rmse:3.83761\ttrain-rmse:1.96696\n",
      "[20168]\teval-rmse:3.83796\ttrain-rmse:1.96696\n",
      "[20169]\teval-rmse:3.83731\ttrain-rmse:1.96695\n",
      "[20170]\teval-rmse:3.83561\ttrain-rmse:1.96693\n",
      "[20171]\teval-rmse:3.8361\ttrain-rmse:1.96693\n",
      "[20172]\teval-rmse:3.83488\ttrain-rmse:1.96692\n",
      "[20173]\teval-rmse:3.83419\ttrain-rmse:1.96691\n",
      "[20174]\teval-rmse:3.83477\ttrain-rmse:1.96692\n",
      "[20175]\teval-rmse:3.83669\ttrain-rmse:1.96693\n",
      "[20176]\teval-rmse:3.83537\ttrain-rmse:1.96692\n",
      "[20177]\teval-rmse:3.83659\ttrain-rmse:1.96693\n",
      "[20178]\teval-rmse:3.83517\ttrain-rmse:1.96692\n",
      "[20179]\teval-rmse:3.83453\ttrain-rmse:1.96693\n",
      "[20180]\teval-rmse:3.83505\ttrain-rmse:1.96693\n",
      "[20181]\teval-rmse:3.83501\ttrain-rmse:1.96693\n",
      "[20182]\teval-rmse:3.83642\ttrain-rmse:1.96695\n",
      "[20183]\teval-rmse:3.83604\ttrain-rmse:1.96685\n",
      "[20184]\teval-rmse:3.83429\ttrain-rmse:1.96685\n",
      "[20185]\teval-rmse:3.83255\ttrain-rmse:1.96683\n",
      "[20186]\teval-rmse:3.83448\ttrain-rmse:1.96683\n",
      "[20187]\teval-rmse:3.83428\ttrain-rmse:1.96683\n",
      "[20188]\teval-rmse:3.83273\ttrain-rmse:1.96684\n",
      "[20189]\teval-rmse:3.83426\ttrain-rmse:1.96684\n",
      "[20190]\teval-rmse:3.83494\ttrain-rmse:1.96684\n",
      "[20191]\teval-rmse:3.83316\ttrain-rmse:1.96682\n",
      "[20192]\teval-rmse:3.83176\ttrain-rmse:1.96685\n",
      "[20193]\teval-rmse:3.83157\ttrain-rmse:1.96685\n",
      "[20194]\teval-rmse:3.83011\ttrain-rmse:1.96687\n",
      "[20195]\teval-rmse:3.83031\ttrain-rmse:1.96686\n",
      "[20196]\teval-rmse:3.829\ttrain-rmse:1.96689\n",
      "[20197]\teval-rmse:3.82921\ttrain-rmse:1.96689\n",
      "[20198]\teval-rmse:3.82871\ttrain-rmse:1.9669\n",
      "[20199]\teval-rmse:3.82973\ttrain-rmse:1.96689\n",
      "[20200]\teval-rmse:3.83005\ttrain-rmse:1.96689\n",
      "[20201]\teval-rmse:3.83007\ttrain-rmse:1.96689\n",
      "[20202]\teval-rmse:3.83186\ttrain-rmse:1.96688\n",
      "[20203]\teval-rmse:3.83042\ttrain-rmse:1.96688\n",
      "[20204]\teval-rmse:3.83174\ttrain-rmse:1.96688\n",
      "[20205]\teval-rmse:3.83264\ttrain-rmse:1.96688\n",
      "[20206]\teval-rmse:3.83227\ttrain-rmse:1.96688\n",
      "[20207]\teval-rmse:3.83055\ttrain-rmse:1.96687\n",
      "[20208]\teval-rmse:3.83124\ttrain-rmse:1.96687\n",
      "[20209]\teval-rmse:3.8308\ttrain-rmse:1.96687\n",
      "[20210]\teval-rmse:3.8312\ttrain-rmse:1.96687\n",
      "[20211]\teval-rmse:3.83084\ttrain-rmse:1.96677\n",
      "[20212]\teval-rmse:3.83277\ttrain-rmse:1.96677\n",
      "[20213]\teval-rmse:3.83305\ttrain-rmse:1.96677\n",
      "[20214]\teval-rmse:3.83324\ttrain-rmse:1.96678\n",
      "[20215]\teval-rmse:3.8329\ttrain-rmse:1.96668\n",
      "[20216]\teval-rmse:3.83339\ttrain-rmse:1.96668\n",
      "[20217]\teval-rmse:3.83503\ttrain-rmse:1.9667\n",
      "[20218]\teval-rmse:3.83696\ttrain-rmse:1.96672\n",
      "[20219]\teval-rmse:3.83745\ttrain-rmse:1.96672\n",
      "[20220]\teval-rmse:3.83913\ttrain-rmse:1.96671\n",
      "[20221]\teval-rmse:3.83881\ttrain-rmse:1.9667\n",
      "[20222]\teval-rmse:3.84073\ttrain-rmse:1.96673\n",
      "[20223]\teval-rmse:3.83961\ttrain-rmse:1.96671\n",
      "[20224]\teval-rmse:3.84024\ttrain-rmse:1.96673\n",
      "[20225]\teval-rmse:3.8409\ttrain-rmse:1.96673\n",
      "[20226]\teval-rmse:3.84118\ttrain-rmse:1.96674\n",
      "[20227]\teval-rmse:3.84273\ttrain-rmse:1.9668\n",
      "[20228]\teval-rmse:3.84307\ttrain-rmse:1.9668\n",
      "[20229]\teval-rmse:3.84499\ttrain-rmse:1.96685\n",
      "[20230]\teval-rmse:3.84449\ttrain-rmse:1.96683\n",
      "[20231]\teval-rmse:3.846\ttrain-rmse:1.96688\n",
      "[20232]\teval-rmse:3.84485\ttrain-rmse:1.96685\n",
      "[20233]\teval-rmse:3.84426\ttrain-rmse:1.96683\n",
      "[20234]\teval-rmse:3.84401\ttrain-rmse:1.96682\n",
      "[20235]\teval-rmse:3.84455\ttrain-rmse:1.96684\n",
      "[20236]\teval-rmse:3.84365\ttrain-rmse:1.96681\n",
      "[20237]\teval-rmse:3.84492\ttrain-rmse:1.96686\n",
      "[20238]\teval-rmse:3.84457\ttrain-rmse:1.96685\n",
      "[20239]\teval-rmse:3.84328\ttrain-rmse:1.9668\n",
      "[20240]\teval-rmse:3.84285\ttrain-rmse:1.9667\n",
      "[20241]\teval-rmse:3.84228\ttrain-rmse:1.96668\n",
      "[20242]\teval-rmse:3.84356\ttrain-rmse:1.96672\n",
      "[20243]\teval-rmse:3.84181\ttrain-rmse:1.96667\n",
      "[20244]\teval-rmse:3.84004\ttrain-rmse:1.96664\n",
      "[20245]\teval-rmse:3.84164\ttrain-rmse:1.96666\n",
      "[20246]\teval-rmse:3.84356\ttrain-rmse:1.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20247]\teval-rmse:3.84227\ttrain-rmse:1.96666\n",
      "[20248]\teval-rmse:3.84163\ttrain-rmse:1.96664\n",
      "[20249]\teval-rmse:3.83987\ttrain-rmse:1.96661\n",
      "[20250]\teval-rmse:3.83939\ttrain-rmse:1.96661\n",
      "[20251]\teval-rmse:3.83955\ttrain-rmse:1.96661\n",
      "[20252]\teval-rmse:3.83844\ttrain-rmse:1.9666\n",
      "[20253]\teval-rmse:3.83814\ttrain-rmse:1.96659\n",
      "[20254]\teval-rmse:3.8376\ttrain-rmse:1.96658\n",
      "[20255]\teval-rmse:3.8369\ttrain-rmse:1.96657\n",
      "[20256]\teval-rmse:3.83555\ttrain-rmse:1.96658\n",
      "[20257]\teval-rmse:3.83408\ttrain-rmse:1.96657\n",
      "[20258]\teval-rmse:3.83217\ttrain-rmse:1.96656\n",
      "[20259]\teval-rmse:3.83198\ttrain-rmse:1.96656\n",
      "[20260]\teval-rmse:3.83023\ttrain-rmse:1.96655\n",
      "[20261]\teval-rmse:3.82854\ttrain-rmse:1.96657\n",
      "[20262]\teval-rmse:3.82819\ttrain-rmse:1.96657\n",
      "[20263]\teval-rmse:3.82682\ttrain-rmse:1.96659\n",
      "[20264]\teval-rmse:3.82837\ttrain-rmse:1.96657\n",
      "[20265]\teval-rmse:3.82865\ttrain-rmse:1.96656\n",
      "[20266]\teval-rmse:3.82898\ttrain-rmse:1.96656\n",
      "[20267]\teval-rmse:3.8288\ttrain-rmse:1.96656\n",
      "[20268]\teval-rmse:3.82742\ttrain-rmse:1.9666\n",
      "[20269]\teval-rmse:3.82574\ttrain-rmse:1.96662\n",
      "[20270]\teval-rmse:3.82424\ttrain-rmse:1.96665\n",
      "[20271]\teval-rmse:3.82321\ttrain-rmse:1.96667\n",
      "[20272]\teval-rmse:3.8234\ttrain-rmse:1.96666\n",
      "[20273]\teval-rmse:3.82213\ttrain-rmse:1.9667\n",
      "[20274]\teval-rmse:3.82188\ttrain-rmse:1.9667\n",
      "[20275]\teval-rmse:3.82088\ttrain-rmse:1.96673\n",
      "[20276]\teval-rmse:3.8194\ttrain-rmse:1.96678\n",
      "[20277]\teval-rmse:3.82081\ttrain-rmse:1.96673\n",
      "[20278]\teval-rmse:3.82034\ttrain-rmse:1.96676\n",
      "[20279]\teval-rmse:3.81919\ttrain-rmse:1.96679\n",
      "[20280]\teval-rmse:3.81873\ttrain-rmse:1.96681\n",
      "[20281]\teval-rmse:3.81937\ttrain-rmse:1.96679\n",
      "[20282]\teval-rmse:3.82009\ttrain-rmse:1.96676\n",
      "[20283]\teval-rmse:3.81877\ttrain-rmse:1.96681\n",
      "[20284]\teval-rmse:3.81838\ttrain-rmse:1.96682\n",
      "[20285]\teval-rmse:3.81987\ttrain-rmse:1.96677\n",
      "[20286]\teval-rmse:3.8201\ttrain-rmse:1.96676\n",
      "[20287]\teval-rmse:3.82165\ttrain-rmse:1.96672\n",
      "[20288]\teval-rmse:3.82203\ttrain-rmse:1.96671\n",
      "[20289]\teval-rmse:3.82267\ttrain-rmse:1.96669\n",
      "[20290]\teval-rmse:3.8215\ttrain-rmse:1.96674\n",
      "[20291]\teval-rmse:3.82169\ttrain-rmse:1.96673\n",
      "[20292]\teval-rmse:3.82299\ttrain-rmse:1.9667\n",
      "[20293]\teval-rmse:3.82242\ttrain-rmse:1.96672\n",
      "[20294]\teval-rmse:3.82171\ttrain-rmse:1.96674\n",
      "[20295]\teval-rmse:3.82132\ttrain-rmse:1.96676\n",
      "[20296]\teval-rmse:3.82075\ttrain-rmse:1.96678\n",
      "[20297]\teval-rmse:3.82147\ttrain-rmse:1.96676\n",
      "[20298]\teval-rmse:3.82282\ttrain-rmse:1.96673\n",
      "[20299]\teval-rmse:3.82421\ttrain-rmse:1.9667\n",
      "[20300]\teval-rmse:3.82426\ttrain-rmse:1.9667\n",
      "[20301]\teval-rmse:3.82605\ttrain-rmse:1.96663\n",
      "[20302]\teval-rmse:3.82776\ttrain-rmse:1.96662\n",
      "[20303]\teval-rmse:3.82672\ttrain-rmse:1.96663\n",
      "[20304]\teval-rmse:3.82538\ttrain-rmse:1.96664\n",
      "[20305]\teval-rmse:3.82732\ttrain-rmse:1.96662\n",
      "[20306]\teval-rmse:3.82779\ttrain-rmse:1.96662\n",
      "[20307]\teval-rmse:3.82712\ttrain-rmse:1.96663\n",
      "[20308]\teval-rmse:3.82744\ttrain-rmse:1.96662\n",
      "[20309]\teval-rmse:3.82717\ttrain-rmse:1.96663\n",
      "[20310]\teval-rmse:3.82829\ttrain-rmse:1.96663\n",
      "[20311]\teval-rmse:3.82968\ttrain-rmse:1.96662\n",
      "[20312]\teval-rmse:3.82763\ttrain-rmse:1.96662\n",
      "[20313]\teval-rmse:3.82594\ttrain-rmse:1.96665\n",
      "[20314]\teval-rmse:3.82465\ttrain-rmse:1.96668\n",
      "[20315]\teval-rmse:3.82627\ttrain-rmse:1.96666\n",
      "[20316]\teval-rmse:3.826\ttrain-rmse:1.96666\n",
      "[20317]\teval-rmse:3.8267\ttrain-rmse:1.96665\n",
      "[20318]\teval-rmse:3.8271\ttrain-rmse:1.96664\n",
      "[20319]\teval-rmse:3.82871\ttrain-rmse:1.9666\n",
      "[20320]\teval-rmse:3.82789\ttrain-rmse:1.9666\n",
      "[20321]\teval-rmse:3.82936\ttrain-rmse:1.9666\n",
      "[20322]\teval-rmse:3.82797\ttrain-rmse:1.96662\n",
      "[20323]\teval-rmse:3.82692\ttrain-rmse:1.96662\n",
      "[20324]\teval-rmse:3.82657\ttrain-rmse:1.96653\n",
      "[20325]\teval-rmse:3.82811\ttrain-rmse:1.96652\n",
      "[20326]\teval-rmse:3.82619\ttrain-rmse:1.96652\n",
      "[20327]\teval-rmse:3.82515\ttrain-rmse:1.96653\n",
      "[20328]\teval-rmse:3.82481\ttrain-rmse:1.96653\n",
      "[20329]\teval-rmse:3.82501\ttrain-rmse:1.96653\n",
      "[20330]\teval-rmse:3.82611\ttrain-rmse:1.96652\n",
      "[20331]\teval-rmse:3.82553\ttrain-rmse:1.96653\n",
      "[20332]\teval-rmse:3.82568\ttrain-rmse:1.96653\n",
      "[20333]\teval-rmse:3.82543\ttrain-rmse:1.96653\n",
      "[20334]\teval-rmse:3.82682\ttrain-rmse:1.96652\n",
      "[20335]\teval-rmse:3.82524\ttrain-rmse:1.96655\n",
      "[20336]\teval-rmse:3.82615\ttrain-rmse:1.96654\n",
      "[20337]\teval-rmse:3.82451\ttrain-rmse:1.96655\n",
      "[20338]\teval-rmse:3.82325\ttrain-rmse:1.96658\n",
      "[20339]\teval-rmse:3.8226\ttrain-rmse:1.96659\n",
      "[20340]\teval-rmse:3.82263\ttrain-rmse:1.96659\n",
      "[20341]\teval-rmse:3.82222\ttrain-rmse:1.9666\n",
      "[20342]\teval-rmse:3.82189\ttrain-rmse:1.96661\n",
      "[20343]\teval-rmse:3.82033\ttrain-rmse:1.96664\n",
      "[20344]\teval-rmse:3.82018\ttrain-rmse:1.96665\n",
      "[20345]\teval-rmse:3.82212\ttrain-rmse:1.96661\n",
      "[20346]\teval-rmse:3.82366\ttrain-rmse:1.96658\n",
      "[20347]\teval-rmse:3.82393\ttrain-rmse:1.96657\n",
      "[20348]\teval-rmse:3.82532\ttrain-rmse:1.96654\n",
      "[20349]\teval-rmse:3.82428\ttrain-rmse:1.96655\n",
      "[20350]\teval-rmse:3.82362\ttrain-rmse:1.96656\n",
      "[20351]\teval-rmse:3.82276\ttrain-rmse:1.96657\n",
      "[20352]\teval-rmse:3.82211\ttrain-rmse:1.96659\n",
      "[20353]\teval-rmse:3.82239\ttrain-rmse:1.96658\n",
      "[20354]\teval-rmse:3.8227\ttrain-rmse:1.96658\n",
      "[20355]\teval-rmse:3.82379\ttrain-rmse:1.96656\n",
      "[20356]\teval-rmse:3.82427\ttrain-rmse:1.96655\n",
      "[20357]\teval-rmse:3.82543\ttrain-rmse:1.96655\n",
      "[20358]\teval-rmse:3.82704\ttrain-rmse:1.9665\n",
      "[20359]\teval-rmse:3.82673\ttrain-rmse:1.9664\n",
      "[20360]\teval-rmse:3.82504\ttrain-rmse:1.96642\n",
      "[20361]\teval-rmse:3.82401\ttrain-rmse:1.96643\n",
      "[20362]\teval-rmse:3.82266\ttrain-rmse:1.96647\n",
      "[20363]\teval-rmse:3.82427\ttrain-rmse:1.96643\n",
      "[20364]\teval-rmse:3.82386\ttrain-rmse:1.96643\n",
      "[20365]\teval-rmse:3.82353\ttrain-rmse:1.96644\n",
      "[20366]\teval-rmse:3.82391\ttrain-rmse:1.96644\n",
      "[20367]\teval-rmse:3.82249\ttrain-rmse:1.96645\n",
      "[20368]\teval-rmse:3.82217\ttrain-rmse:1.96646\n",
      "[20369]\teval-rmse:3.82179\ttrain-rmse:1.96646\n",
      "[20370]\teval-rmse:3.82341\ttrain-rmse:1.96642\n",
      "[20371]\teval-rmse:3.82254\ttrain-rmse:1.96644\n",
      "[20372]\teval-rmse:3.82198\ttrain-rmse:1.96645\n",
      "[20373]\teval-rmse:3.82183\ttrain-rmse:1.96645\n",
      "[20374]\teval-rmse:3.81973\ttrain-rmse:1.96649\n",
      "[20375]\teval-rmse:3.81825\ttrain-rmse:1.96653\n",
      "[20376]\teval-rmse:3.81944\ttrain-rmse:1.9665\n",
      "[20377]\teval-rmse:3.82083\ttrain-rmse:1.96645\n",
      "[20378]\teval-rmse:3.82233\ttrain-rmse:1.96643\n",
      "[20379]\teval-rmse:3.82203\ttrain-rmse:1.96634\n",
      "[20380]\teval-rmse:3.82345\ttrain-rmse:1.96631\n",
      "[20381]\teval-rmse:3.82475\ttrain-rmse:1.9663\n",
      "[20382]\teval-rmse:3.82566\ttrain-rmse:1.96629\n",
      "[20383]\teval-rmse:3.82447\ttrain-rmse:1.96631\n",
      "[20384]\teval-rmse:3.82562\ttrain-rmse:1.96631\n",
      "[20385]\teval-rmse:3.82458\ttrain-rmse:1.96632\n",
      "[20386]\teval-rmse:3.82651\ttrain-rmse:1.9663\n",
      "[20387]\teval-rmse:3.82633\ttrain-rmse:1.9663\n",
      "[20388]\teval-rmse:3.82807\ttrain-rmse:1.9663\n",
      "[20389]\teval-rmse:3.82938\ttrain-rmse:1.9663\n",
      "[20390]\teval-rmse:3.8308\ttrain-rmse:1.96632\n",
      "[20391]\teval-rmse:3.83123\ttrain-rmse:1.96632\n",
      "[20392]\teval-rmse:3.83093\ttrain-rmse:1.96632\n",
      "[20393]\teval-rmse:3.83143\ttrain-rmse:1.96632\n",
      "[20394]\teval-rmse:3.83113\ttrain-rmse:1.96632\n",
      "[20395]\teval-rmse:3.82981\ttrain-rmse:1.96634\n",
      "[20396]\teval-rmse:3.83003\ttrain-rmse:1.96635\n",
      "[20397]\teval-rmse:3.82876\ttrain-rmse:1.96633\n",
      "[20398]\teval-rmse:3.82716\ttrain-rmse:1.96632\n",
      "[20399]\teval-rmse:3.82774\ttrain-rmse:1.96631\n",
      "[20400]\teval-rmse:3.82739\ttrain-rmse:1.96622\n",
      "[20401]\teval-rmse:3.82847\ttrain-rmse:1.96622\n",
      "[20402]\teval-rmse:3.82828\ttrain-rmse:1.96622\n",
      "[20403]\teval-rmse:3.82976\ttrain-rmse:1.96625\n",
      "[20404]\teval-rmse:3.82881\ttrain-rmse:1.96623\n",
      "[20405]\teval-rmse:3.82918\ttrain-rmse:1.96623\n",
      "[20406]\teval-rmse:3.82812\ttrain-rmse:1.96623\n",
      "[20407]\teval-rmse:3.82918\ttrain-rmse:1.96623\n",
      "[20408]\teval-rmse:3.82899\ttrain-rmse:1.96623\n",
      "[20409]\teval-rmse:3.83032\ttrain-rmse:1.96625\n",
      "[20410]\teval-rmse:3.83172\ttrain-rmse:1.96628\n",
      "[20411]\teval-rmse:3.83142\ttrain-rmse:1.96628\n",
      "[20412]\teval-rmse:3.82979\ttrain-rmse:1.96626\n",
      "[20413]\teval-rmse:3.82943\ttrain-rmse:1.96618\n",
      "[20414]\teval-rmse:3.82798\ttrain-rmse:1.96617\n",
      "[20415]\teval-rmse:3.8288\ttrain-rmse:1.96616\n",
      "[20416]\teval-rmse:3.82721\ttrain-rmse:1.96614\n",
      "[20417]\teval-rmse:3.8255\ttrain-rmse:1.96613\n",
      "[20418]\teval-rmse:3.82743\ttrain-rmse:1.96611\n",
      "[20419]\teval-rmse:3.82937\ttrain-rmse:1.9661\n",
      "[20420]\teval-rmse:3.829\ttrain-rmse:1.9661\n",
      "[20421]\teval-rmse:3.82842\ttrain-rmse:1.9661\n",
      "[20422]\teval-rmse:3.82631\ttrain-rmse:1.96609\n",
      "[20423]\teval-rmse:3.82504\ttrain-rmse:1.96611\n",
      "[20424]\teval-rmse:3.82338\ttrain-rmse:1.96613\n",
      "[20425]\teval-rmse:3.82196\ttrain-rmse:1.96615\n",
      "[20426]\teval-rmse:3.82048\ttrain-rmse:1.96618\n",
      "[20427]\teval-rmse:3.82197\ttrain-rmse:1.96615\n",
      "[20428]\teval-rmse:3.82219\ttrain-rmse:1.96615\n",
      "[20429]\teval-rmse:3.82351\ttrain-rmse:1.96612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20430]\teval-rmse:3.82196\ttrain-rmse:1.96615\n",
      "[20431]\teval-rmse:3.82256\ttrain-rmse:1.96614\n",
      "[20432]\teval-rmse:3.82424\ttrain-rmse:1.96608\n",
      "[20433]\teval-rmse:3.82383\ttrain-rmse:1.96609\n",
      "[20434]\teval-rmse:3.82416\ttrain-rmse:1.96609\n",
      "[20435]\teval-rmse:3.82442\ttrain-rmse:1.96609\n",
      "[20436]\teval-rmse:3.82287\ttrain-rmse:1.96611\n",
      "[20437]\teval-rmse:3.82232\ttrain-rmse:1.96612\n",
      "[20438]\teval-rmse:3.82077\ttrain-rmse:1.96615\n",
      "[20439]\teval-rmse:3.82038\ttrain-rmse:1.96616\n",
      "[20440]\teval-rmse:3.8196\ttrain-rmse:1.96618\n",
      "[20441]\teval-rmse:3.82014\ttrain-rmse:1.96617\n",
      "[20442]\teval-rmse:3.81983\ttrain-rmse:1.96618\n",
      "[20443]\teval-rmse:3.81981\ttrain-rmse:1.96618\n",
      "[20444]\teval-rmse:3.81966\ttrain-rmse:1.96618\n",
      "[20445]\teval-rmse:3.81998\ttrain-rmse:1.96617\n",
      "[20446]\teval-rmse:3.81866\ttrain-rmse:1.96623\n",
      "[20447]\teval-rmse:3.81852\ttrain-rmse:1.96623\n",
      "[20448]\teval-rmse:3.81923\ttrain-rmse:1.96621\n",
      "[20449]\teval-rmse:3.81876\ttrain-rmse:1.96623\n",
      "[20450]\teval-rmse:3.81933\ttrain-rmse:1.96621\n",
      "[20451]\teval-rmse:3.81919\ttrain-rmse:1.96622\n",
      "[20452]\teval-rmse:3.82076\ttrain-rmse:1.96617\n",
      "[20453]\teval-rmse:3.82047\ttrain-rmse:1.96608\n",
      "[20454]\teval-rmse:3.8186\ttrain-rmse:1.96613\n",
      "[20455]\teval-rmse:3.81982\ttrain-rmse:1.9661\n",
      "[20456]\teval-rmse:3.81842\ttrain-rmse:1.96614\n",
      "[20457]\teval-rmse:3.81889\ttrain-rmse:1.96613\n",
      "[20458]\teval-rmse:3.81959\ttrain-rmse:1.96611\n",
      "[20459]\teval-rmse:3.81906\ttrain-rmse:1.96612\n",
      "[20460]\teval-rmse:3.81934\ttrain-rmse:1.96611\n",
      "[20461]\teval-rmse:3.81902\ttrain-rmse:1.96612\n",
      "[20462]\teval-rmse:3.82064\ttrain-rmse:1.96607\n",
      "[20463]\teval-rmse:3.81979\ttrain-rmse:1.96609\n",
      "[20464]\teval-rmse:3.81932\ttrain-rmse:1.96611\n",
      "[20465]\teval-rmse:3.81853\ttrain-rmse:1.96613\n",
      "[20466]\teval-rmse:3.81738\ttrain-rmse:1.96617\n",
      "[20467]\teval-rmse:3.81844\ttrain-rmse:1.96615\n",
      "[20468]\teval-rmse:3.8168\ttrain-rmse:1.9662\n",
      "[20469]\teval-rmse:3.81517\ttrain-rmse:1.96626\n",
      "[20470]\teval-rmse:3.81382\ttrain-rmse:1.96633\n",
      "[20471]\teval-rmse:3.81353\ttrain-rmse:1.96633\n",
      "[20472]\teval-rmse:3.81522\ttrain-rmse:1.96624\n",
      "[20473]\teval-rmse:3.81379\ttrain-rmse:1.9663\n",
      "[20474]\teval-rmse:3.81511\ttrain-rmse:1.96624\n",
      "[20475]\teval-rmse:3.81482\ttrain-rmse:1.96625\n",
      "[20476]\teval-rmse:3.81423\ttrain-rmse:1.96628\n",
      "[20477]\teval-rmse:3.81558\ttrain-rmse:1.96622\n",
      "[20478]\teval-rmse:3.8139\ttrain-rmse:1.96629\n",
      "[20479]\teval-rmse:3.81223\ttrain-rmse:1.96638\n",
      "[20480]\teval-rmse:3.81295\ttrain-rmse:1.96634\n",
      "[20481]\teval-rmse:3.81465\ttrain-rmse:1.96626\n",
      "[20482]\teval-rmse:3.81596\ttrain-rmse:1.96619\n",
      "[20483]\teval-rmse:3.81667\ttrain-rmse:1.96617\n",
      "[20484]\teval-rmse:3.81583\ttrain-rmse:1.9662\n",
      "[20485]\teval-rmse:3.81485\ttrain-rmse:1.96625\n",
      "[20486]\teval-rmse:3.81431\ttrain-rmse:1.96627\n",
      "[20487]\teval-rmse:3.81469\ttrain-rmse:1.96625\n",
      "[20488]\teval-rmse:3.81425\ttrain-rmse:1.96627\n",
      "[20489]\teval-rmse:3.81288\ttrain-rmse:1.96634\n",
      "[20490]\teval-rmse:3.81443\ttrain-rmse:1.96628\n",
      "[20491]\teval-rmse:3.81414\ttrain-rmse:1.96629\n",
      "[20492]\teval-rmse:3.81548\ttrain-rmse:1.96623\n",
      "[20493]\teval-rmse:3.81704\ttrain-rmse:1.96617\n",
      "[20494]\teval-rmse:3.81768\ttrain-rmse:1.96615\n",
      "[20495]\teval-rmse:3.81839\ttrain-rmse:1.96612\n",
      "[20496]\teval-rmse:3.81762\ttrain-rmse:1.96615\n",
      "[20497]\teval-rmse:3.81796\ttrain-rmse:1.96614\n",
      "[20498]\teval-rmse:3.81772\ttrain-rmse:1.96614\n",
      "[20499]\teval-rmse:3.81941\ttrain-rmse:1.96607\n",
      "[20500]\teval-rmse:3.8191\ttrain-rmse:1.96596\n",
      "[20501]\teval-rmse:3.81757\ttrain-rmse:1.96601\n",
      "[20502]\teval-rmse:3.81704\ttrain-rmse:1.96603\n",
      "[20503]\teval-rmse:3.81605\ttrain-rmse:1.96606\n",
      "[20504]\teval-rmse:3.81559\ttrain-rmse:1.96608\n",
      "[20505]\teval-rmse:3.81445\ttrain-rmse:1.96614\n",
      "[20506]\teval-rmse:3.81316\ttrain-rmse:1.96621\n",
      "[20507]\teval-rmse:3.81287\ttrain-rmse:1.96612\n",
      "[20508]\teval-rmse:3.81259\ttrain-rmse:1.96604\n",
      "[20509]\teval-rmse:3.81369\ttrain-rmse:1.96599\n",
      "[20510]\teval-rmse:3.81532\ttrain-rmse:1.9659\n",
      "[20511]\teval-rmse:3.8152\ttrain-rmse:1.96591\n",
      "[20512]\teval-rmse:3.81475\ttrain-rmse:1.96592\n",
      "[20513]\teval-rmse:3.8167\ttrain-rmse:1.96587\n",
      "[20514]\teval-rmse:3.8157\ttrain-rmse:1.9659\n",
      "[20515]\teval-rmse:3.81749\ttrain-rmse:1.96582\n",
      "[20516]\teval-rmse:3.81611\ttrain-rmse:1.96587\n",
      "[20517]\teval-rmse:3.81449\ttrain-rmse:1.96595\n",
      "[20518]\teval-rmse:3.81427\ttrain-rmse:1.96595\n",
      "[20519]\teval-rmse:3.81397\ttrain-rmse:1.96586\n",
      "[20520]\teval-rmse:3.81506\ttrain-rmse:1.96582\n",
      "[20521]\teval-rmse:3.81531\ttrain-rmse:1.96581\n",
      "[20522]\teval-rmse:3.81602\ttrain-rmse:1.96578\n",
      "[20523]\teval-rmse:3.81719\ttrain-rmse:1.96574\n",
      "[20524]\teval-rmse:3.81789\ttrain-rmse:1.96572\n",
      "[20525]\teval-rmse:3.81859\ttrain-rmse:1.96569\n",
      "[20526]\teval-rmse:3.81759\ttrain-rmse:1.96572\n",
      "[20527]\teval-rmse:3.81621\ttrain-rmse:1.96576\n",
      "[20528]\teval-rmse:3.81607\ttrain-rmse:1.96577\n",
      "[20529]\teval-rmse:3.81554\ttrain-rmse:1.96579\n",
      "[20530]\teval-rmse:3.81541\ttrain-rmse:1.96579\n",
      "[20531]\teval-rmse:3.81388\ttrain-rmse:1.96585\n",
      "[20532]\teval-rmse:3.81238\ttrain-rmse:1.96591\n",
      "[20533]\teval-rmse:3.81087\ttrain-rmse:1.96598\n",
      "[20534]\teval-rmse:3.80998\ttrain-rmse:1.96602\n",
      "[20535]\teval-rmse:3.80877\ttrain-rmse:1.96609\n",
      "[20536]\teval-rmse:3.80857\ttrain-rmse:1.9661\n",
      "[20537]\teval-rmse:3.80784\ttrain-rmse:1.96614\n",
      "[20538]\teval-rmse:3.80774\ttrain-rmse:1.96614\n",
      "[20539]\teval-rmse:3.80909\ttrain-rmse:1.96606\n",
      "[20540]\teval-rmse:3.80746\ttrain-rmse:1.96615\n",
      "[20541]\teval-rmse:3.80653\ttrain-rmse:1.96619\n",
      "[20542]\teval-rmse:3.80691\ttrain-rmse:1.96617\n",
      "[20543]\teval-rmse:3.80797\ttrain-rmse:1.9661\n",
      "[20544]\teval-rmse:3.80775\ttrain-rmse:1.966\n",
      "[20545]\teval-rmse:3.80764\ttrain-rmse:1.966\n",
      "[20546]\teval-rmse:3.80606\ttrain-rmse:1.9661\n",
      "[20547]\teval-rmse:3.80588\ttrain-rmse:1.96611\n",
      "[20548]\teval-rmse:3.8054\ttrain-rmse:1.96615\n",
      "[20549]\teval-rmse:3.80514\ttrain-rmse:1.96616\n",
      "[20550]\teval-rmse:3.80476\ttrain-rmse:1.96618\n",
      "[20551]\teval-rmse:3.80624\ttrain-rmse:1.96608\n",
      "[20552]\teval-rmse:3.80749\ttrain-rmse:1.96601\n",
      "[20553]\teval-rmse:3.80708\ttrain-rmse:1.96603\n",
      "[20554]\teval-rmse:3.80903\ttrain-rmse:1.96594\n",
      "[20555]\teval-rmse:3.81012\ttrain-rmse:1.96588\n",
      "[20556]\teval-rmse:3.81048\ttrain-rmse:1.96587\n",
      "[20557]\teval-rmse:3.81159\ttrain-rmse:1.96581\n",
      "[20558]\teval-rmse:3.81274\ttrain-rmse:1.96578\n",
      "[20559]\teval-rmse:3.81145\ttrain-rmse:1.96585\n",
      "[20560]\teval-rmse:3.81048\ttrain-rmse:1.96589\n",
      "[20561]\teval-rmse:3.81143\ttrain-rmse:1.96584\n",
      "[20562]\teval-rmse:3.80994\ttrain-rmse:1.96591\n",
      "[20563]\teval-rmse:3.81025\ttrain-rmse:1.9659\n",
      "[20564]\teval-rmse:3.81195\ttrain-rmse:1.9658\n",
      "[20565]\teval-rmse:3.81029\ttrain-rmse:1.96588\n",
      "[20566]\teval-rmse:3.81198\ttrain-rmse:1.96579\n",
      "[20567]\teval-rmse:3.8107\ttrain-rmse:1.96587\n",
      "[20568]\teval-rmse:3.81225\ttrain-rmse:1.96579\n",
      "[20569]\teval-rmse:3.81246\ttrain-rmse:1.96578\n",
      "[20570]\teval-rmse:3.8128\ttrain-rmse:1.96577\n",
      "[20571]\teval-rmse:3.81458\ttrain-rmse:1.96569\n",
      "[20572]\teval-rmse:3.81456\ttrain-rmse:1.96569\n",
      "[20573]\teval-rmse:3.8141\ttrain-rmse:1.96571\n",
      "[20574]\teval-rmse:3.81581\ttrain-rmse:1.96563\n",
      "[20575]\teval-rmse:3.81718\ttrain-rmse:1.96559\n",
      "[20576]\teval-rmse:3.81593\ttrain-rmse:1.96565\n",
      "[20577]\teval-rmse:3.81478\ttrain-rmse:1.96569\n",
      "[20578]\teval-rmse:3.81449\ttrain-rmse:1.9657\n",
      "[20579]\teval-rmse:3.81534\ttrain-rmse:1.96566\n",
      "[20580]\teval-rmse:3.81489\ttrain-rmse:1.96569\n",
      "[20581]\teval-rmse:3.81441\ttrain-rmse:1.9657\n",
      "[20582]\teval-rmse:3.81291\ttrain-rmse:1.96575\n",
      "[20583]\teval-rmse:3.8144\ttrain-rmse:1.96571\n",
      "[20584]\teval-rmse:3.81458\ttrain-rmse:1.9657\n",
      "[20585]\teval-rmse:3.81381\ttrain-rmse:1.96574\n",
      "[20586]\teval-rmse:3.81228\ttrain-rmse:1.9658\n",
      "[20587]\teval-rmse:3.8108\ttrain-rmse:1.96587\n",
      "[20588]\teval-rmse:3.80925\ttrain-rmse:1.96595\n",
      "[20589]\teval-rmse:3.8089\ttrain-rmse:1.96597\n",
      "[20590]\teval-rmse:3.8087\ttrain-rmse:1.96598\n",
      "[20591]\teval-rmse:3.80834\ttrain-rmse:1.96601\n",
      "[20592]\teval-rmse:3.80798\ttrain-rmse:1.96603\n",
      "[20593]\teval-rmse:3.80931\ttrain-rmse:1.96595\n",
      "[20594]\teval-rmse:3.8092\ttrain-rmse:1.96596\n",
      "[20595]\teval-rmse:3.80988\ttrain-rmse:1.96592\n",
      "[20596]\teval-rmse:3.81028\ttrain-rmse:1.9659\n",
      "[20597]\teval-rmse:3.81207\ttrain-rmse:1.96581\n",
      "[20598]\teval-rmse:3.81183\ttrain-rmse:1.96572\n",
      "[20599]\teval-rmse:3.81061\ttrain-rmse:1.96579\n",
      "[20600]\teval-rmse:3.80911\ttrain-rmse:1.96587\n",
      "[20601]\teval-rmse:3.8106\ttrain-rmse:1.96581\n",
      "[20602]\teval-rmse:3.81033\ttrain-rmse:1.96582\n",
      "[20603]\teval-rmse:3.80859\ttrain-rmse:1.96589\n",
      "[20604]\teval-rmse:3.81053\ttrain-rmse:1.96581\n",
      "[20605]\teval-rmse:3.80942\ttrain-rmse:1.96587\n",
      "[20606]\teval-rmse:3.81031\ttrain-rmse:1.96582\n",
      "[20607]\teval-rmse:3.80882\ttrain-rmse:1.96591\n",
      "[20608]\teval-rmse:3.80905\ttrain-rmse:1.96589\n",
      "[20609]\teval-rmse:3.8083\ttrain-rmse:1.96594\n",
      "[20610]\teval-rmse:3.80644\ttrain-rmse:1.96604\n",
      "[20611]\teval-rmse:3.80661\ttrain-rmse:1.96603\n",
      "[20612]\teval-rmse:3.80642\ttrain-rmse:1.96604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20613]\teval-rmse:3.80502\ttrain-rmse:1.96614\n",
      "[20614]\teval-rmse:3.80446\ttrain-rmse:1.96618\n",
      "[20615]\teval-rmse:3.80468\ttrain-rmse:1.96616\n",
      "[20616]\teval-rmse:3.80615\ttrain-rmse:1.96606\n",
      "[20617]\teval-rmse:3.80809\ttrain-rmse:1.96597\n",
      "[20618]\teval-rmse:3.80646\ttrain-rmse:1.96608\n",
      "[20619]\teval-rmse:3.80528\ttrain-rmse:1.96616\n",
      "[20620]\teval-rmse:3.80684\ttrain-rmse:1.96605\n",
      "[20621]\teval-rmse:3.80733\ttrain-rmse:1.96602\n",
      "[20622]\teval-rmse:3.80828\ttrain-rmse:1.96595\n",
      "[20623]\teval-rmse:3.80702\ttrain-rmse:1.96604\n",
      "[20624]\teval-rmse:3.80769\ttrain-rmse:1.966\n",
      "[20625]\teval-rmse:3.80912\ttrain-rmse:1.96591\n",
      "[20626]\teval-rmse:3.8091\ttrain-rmse:1.96591\n",
      "[20627]\teval-rmse:3.808\ttrain-rmse:1.96598\n",
      "[20628]\teval-rmse:3.80821\ttrain-rmse:1.96597\n",
      "[20629]\teval-rmse:3.80763\ttrain-rmse:1.96601\n",
      "[20630]\teval-rmse:3.80599\ttrain-rmse:1.96611\n",
      "[20631]\teval-rmse:3.80589\ttrain-rmse:1.96612\n",
      "[20632]\teval-rmse:3.80739\ttrain-rmse:1.96603\n",
      "[20633]\teval-rmse:3.80599\ttrain-rmse:1.96612\n",
      "[20634]\teval-rmse:3.80624\ttrain-rmse:1.96611\n",
      "[20635]\teval-rmse:3.80479\ttrain-rmse:1.96621\n",
      "[20636]\teval-rmse:3.80454\ttrain-rmse:1.96622\n",
      "[20637]\teval-rmse:3.80626\ttrain-rmse:1.96611\n",
      "[20638]\teval-rmse:3.80647\ttrain-rmse:1.96609\n",
      "[20639]\teval-rmse:3.80789\ttrain-rmse:1.96601\n",
      "[20640]\teval-rmse:3.80626\ttrain-rmse:1.96611\n",
      "[20641]\teval-rmse:3.80532\ttrain-rmse:1.96616\n",
      "[20642]\teval-rmse:3.80498\ttrain-rmse:1.96618\n",
      "[20643]\teval-rmse:3.80458\ttrain-rmse:1.96621\n",
      "[20644]\teval-rmse:3.80365\ttrain-rmse:1.96626\n",
      "[20645]\teval-rmse:3.80501\ttrain-rmse:1.96616\n",
      "[20646]\teval-rmse:3.80376\ttrain-rmse:1.96625\n",
      "[20647]\teval-rmse:3.80336\ttrain-rmse:1.96628\n",
      "[20648]\teval-rmse:3.80531\ttrain-rmse:1.96618\n",
      "[20649]\teval-rmse:3.80578\ttrain-rmse:1.96614\n",
      "[20650]\teval-rmse:3.80484\ttrain-rmse:1.96619\n",
      "[20651]\teval-rmse:3.80466\ttrain-rmse:1.9662\n",
      "[20652]\teval-rmse:3.80441\ttrain-rmse:1.96611\n",
      "[20653]\teval-rmse:3.80384\ttrain-rmse:1.96616\n",
      "[20654]\teval-rmse:3.80239\ttrain-rmse:1.96625\n",
      "[20655]\teval-rmse:3.80282\ttrain-rmse:1.96622\n",
      "[20656]\teval-rmse:3.8043\ttrain-rmse:1.96612\n",
      "[20657]\teval-rmse:3.80307\ttrain-rmse:1.9662\n",
      "[20658]\teval-rmse:3.8045\ttrain-rmse:1.9661\n",
      "[20659]\teval-rmse:3.80512\ttrain-rmse:1.96607\n",
      "[20660]\teval-rmse:3.80577\ttrain-rmse:1.96603\n",
      "[20661]\teval-rmse:3.80452\ttrain-rmse:1.96612\n",
      "[20662]\teval-rmse:3.80563\ttrain-rmse:1.96605\n",
      "[20663]\teval-rmse:3.80537\ttrain-rmse:1.96606\n",
      "[20664]\teval-rmse:3.80701\ttrain-rmse:1.96596\n",
      "[20665]\teval-rmse:3.80578\ttrain-rmse:1.96603\n",
      "[20666]\teval-rmse:3.80573\ttrain-rmse:1.96603\n",
      "[20667]\teval-rmse:3.80768\ttrain-rmse:1.96594\n",
      "[20668]\teval-rmse:3.80582\ttrain-rmse:1.96605\n",
      "[20669]\teval-rmse:3.80677\ttrain-rmse:1.96597\n",
      "[20670]\teval-rmse:3.80668\ttrain-rmse:1.96598\n",
      "[20671]\teval-rmse:3.80543\ttrain-rmse:1.96607\n",
      "[20672]\teval-rmse:3.80594\ttrain-rmse:1.96604\n",
      "[20673]\teval-rmse:3.80591\ttrain-rmse:1.96604\n",
      "[20674]\teval-rmse:3.80582\ttrain-rmse:1.96605\n",
      "[20675]\teval-rmse:3.80387\ttrain-rmse:1.96616\n",
      "[20676]\teval-rmse:3.80567\ttrain-rmse:1.96603\n",
      "[20677]\teval-rmse:3.80629\ttrain-rmse:1.96599\n",
      "[20678]\teval-rmse:3.80505\ttrain-rmse:1.96608\n",
      "[20679]\teval-rmse:3.8036\ttrain-rmse:1.96618\n",
      "[20680]\teval-rmse:3.80555\ttrain-rmse:1.96608\n",
      "[20681]\teval-rmse:3.8075\ttrain-rmse:1.96599\n",
      "[20682]\teval-rmse:3.80791\ttrain-rmse:1.96596\n",
      "[20683]\teval-rmse:3.80955\ttrain-rmse:1.96585\n",
      "[20684]\teval-rmse:3.80928\ttrain-rmse:1.96586\n",
      "[20685]\teval-rmse:3.80886\ttrain-rmse:1.96589\n",
      "[20686]\teval-rmse:3.81049\ttrain-rmse:1.96578\n",
      "[20687]\teval-rmse:3.81028\ttrain-rmse:1.96579\n",
      "[20688]\teval-rmse:3.80979\ttrain-rmse:1.96581\n",
      "[20689]\teval-rmse:3.81027\ttrain-rmse:1.96579\n",
      "[20690]\teval-rmse:3.81137\ttrain-rmse:1.96573\n",
      "[20691]\teval-rmse:3.80957\ttrain-rmse:1.96581\n",
      "[20692]\teval-rmse:3.81106\ttrain-rmse:1.96573\n",
      "[20693]\teval-rmse:3.80946\ttrain-rmse:1.96582\n",
      "[20694]\teval-rmse:3.80786\ttrain-rmse:1.96591\n",
      "[20695]\teval-rmse:3.80667\ttrain-rmse:1.96599\n",
      "[20696]\teval-rmse:3.80705\ttrain-rmse:1.96596\n",
      "[20697]\teval-rmse:3.80762\ttrain-rmse:1.96593\n",
      "[20698]\teval-rmse:3.808\ttrain-rmse:1.96591\n",
      "[20699]\teval-rmse:3.8069\ttrain-rmse:1.96598\n",
      "[20700]\teval-rmse:3.80726\ttrain-rmse:1.96596\n",
      "[20701]\teval-rmse:3.807\ttrain-rmse:1.96587\n",
      "[20702]\teval-rmse:3.8084\ttrain-rmse:1.96578\n",
      "[20703]\teval-rmse:3.80997\ttrain-rmse:1.9657\n",
      "[20704]\teval-rmse:3.80901\ttrain-rmse:1.96574\n",
      "[20705]\teval-rmse:3.80857\ttrain-rmse:1.96576\n",
      "[20706]\teval-rmse:3.80692\ttrain-rmse:1.96586\n",
      "[20707]\teval-rmse:3.80634\ttrain-rmse:1.9659\n",
      "[20708]\teval-rmse:3.80434\ttrain-rmse:1.96602\n",
      "[20709]\teval-rmse:3.80491\ttrain-rmse:1.96599\n",
      "[20710]\teval-rmse:3.80495\ttrain-rmse:1.96598\n",
      "[20711]\teval-rmse:3.8044\ttrain-rmse:1.96602\n",
      "[20712]\teval-rmse:3.80361\ttrain-rmse:1.96608\n",
      "[20713]\teval-rmse:3.80344\ttrain-rmse:1.96609\n",
      "[20714]\teval-rmse:3.80386\ttrain-rmse:1.96606\n",
      "[20715]\teval-rmse:3.80246\ttrain-rmse:1.96616\n",
      "[20716]\teval-rmse:3.80334\ttrain-rmse:1.96609\n",
      "[20717]\teval-rmse:3.80242\ttrain-rmse:1.96617\n",
      "[20718]\teval-rmse:3.80195\ttrain-rmse:1.9662\n",
      "[20719]\teval-rmse:3.80259\ttrain-rmse:1.96615\n",
      "[20720]\teval-rmse:3.80321\ttrain-rmse:1.9661\n",
      "[20721]\teval-rmse:3.80328\ttrain-rmse:1.9661\n",
      "[20722]\teval-rmse:3.80236\ttrain-rmse:1.96615\n",
      "[20723]\teval-rmse:3.80377\ttrain-rmse:1.96604\n",
      "[20724]\teval-rmse:3.80262\ttrain-rmse:1.96613\n",
      "[20725]\teval-rmse:3.80293\ttrain-rmse:1.96611\n",
      "[20726]\teval-rmse:3.80449\ttrain-rmse:1.96599\n",
      "[20727]\teval-rmse:3.80439\ttrain-rmse:1.966\n",
      "[20728]\teval-rmse:3.80284\ttrain-rmse:1.96611\n",
      "[20729]\teval-rmse:3.8035\ttrain-rmse:1.96606\n",
      "[20730]\teval-rmse:3.80416\ttrain-rmse:1.96601\n",
      "[20731]\teval-rmse:3.80471\ttrain-rmse:1.96597\n",
      "[20732]\teval-rmse:3.80438\ttrain-rmse:1.966\n",
      "[20733]\teval-rmse:3.80308\ttrain-rmse:1.96609\n",
      "[20734]\teval-rmse:3.80168\ttrain-rmse:1.9662\n",
      "[20735]\teval-rmse:3.80241\ttrain-rmse:1.96614\n",
      "[20736]\teval-rmse:3.80185\ttrain-rmse:1.96619\n",
      "[20737]\teval-rmse:3.80238\ttrain-rmse:1.96614\n",
      "[20738]\teval-rmse:3.80267\ttrain-rmse:1.96612\n",
      "[20739]\teval-rmse:3.80211\ttrain-rmse:1.96616\n",
      "[20740]\teval-rmse:3.80061\ttrain-rmse:1.96629\n",
      "[20741]\teval-rmse:3.80042\ttrain-rmse:1.96618\n",
      "[20742]\teval-rmse:3.80083\ttrain-rmse:1.96615\n",
      "[20743]\teval-rmse:3.80142\ttrain-rmse:1.9661\n",
      "[20744]\teval-rmse:3.80298\ttrain-rmse:1.96599\n",
      "[20745]\teval-rmse:3.80388\ttrain-rmse:1.96593\n",
      "[20746]\teval-rmse:3.8034\ttrain-rmse:1.96596\n",
      "[20747]\teval-rmse:3.80285\ttrain-rmse:1.966\n",
      "[20748]\teval-rmse:3.80448\ttrain-rmse:1.96587\n",
      "[20749]\teval-rmse:3.80515\ttrain-rmse:1.96583\n",
      "[20750]\teval-rmse:3.80536\ttrain-rmse:1.96581\n",
      "[20751]\teval-rmse:3.80384\ttrain-rmse:1.96592\n",
      "[20752]\teval-rmse:3.8036\ttrain-rmse:1.96582\n",
      "[20753]\teval-rmse:3.8036\ttrain-rmse:1.96582\n",
      "[20754]\teval-rmse:3.80284\ttrain-rmse:1.96588\n",
      "[20755]\teval-rmse:3.80372\ttrain-rmse:1.96581\n",
      "[20756]\teval-rmse:3.80544\ttrain-rmse:1.96569\n",
      "[20757]\teval-rmse:3.80519\ttrain-rmse:1.96571\n",
      "[20758]\teval-rmse:3.80471\ttrain-rmse:1.96574\n",
      "[20759]\teval-rmse:3.80543\ttrain-rmse:1.96569\n",
      "[20760]\teval-rmse:3.80425\ttrain-rmse:1.96577\n",
      "[20761]\teval-rmse:3.80379\ttrain-rmse:1.9658\n",
      "[20762]\teval-rmse:3.80361\ttrain-rmse:1.96581\n",
      "[20763]\teval-rmse:3.80202\ttrain-rmse:1.96593\n",
      "[20764]\teval-rmse:3.80242\ttrain-rmse:1.9659\n",
      "[20765]\teval-rmse:3.80384\ttrain-rmse:1.9658\n",
      "[20766]\teval-rmse:3.80541\ttrain-rmse:1.96569\n",
      "[20767]\teval-rmse:3.80581\ttrain-rmse:1.96567\n",
      "[20768]\teval-rmse:3.80533\ttrain-rmse:1.9657\n",
      "[20769]\teval-rmse:3.80559\ttrain-rmse:1.96568\n",
      "[20770]\teval-rmse:3.80518\ttrain-rmse:1.96571\n",
      "[20771]\teval-rmse:3.80691\ttrain-rmse:1.9656\n",
      "[20772]\teval-rmse:3.80837\ttrain-rmse:1.96551\n",
      "[20773]\teval-rmse:3.80871\ttrain-rmse:1.9655\n",
      "[20774]\teval-rmse:3.80922\ttrain-rmse:1.96547\n",
      "[20775]\teval-rmse:3.80895\ttrain-rmse:1.96537\n",
      "[20776]\teval-rmse:3.81052\ttrain-rmse:1.9653\n",
      "[20777]\teval-rmse:3.81215\ttrain-rmse:1.96521\n",
      "[20778]\teval-rmse:3.81364\ttrain-rmse:1.96516\n",
      "[20779]\teval-rmse:3.81541\ttrain-rmse:1.96507\n",
      "[20780]\teval-rmse:3.81411\ttrain-rmse:1.96513\n",
      "[20781]\teval-rmse:3.81275\ttrain-rmse:1.96518\n",
      "[20782]\teval-rmse:3.81247\ttrain-rmse:1.96519\n",
      "[20783]\teval-rmse:3.81285\ttrain-rmse:1.96518\n",
      "[20784]\teval-rmse:3.81318\ttrain-rmse:1.96517\n",
      "[20785]\teval-rmse:3.81182\ttrain-rmse:1.96522\n",
      "[20786]\teval-rmse:3.81054\ttrain-rmse:1.96528\n",
      "[20787]\teval-rmse:3.80973\ttrain-rmse:1.96532\n",
      "[20788]\teval-rmse:3.80936\ttrain-rmse:1.96534\n",
      "[20789]\teval-rmse:3.809\ttrain-rmse:1.96536\n",
      "[20790]\teval-rmse:3.80876\ttrain-rmse:1.96528\n",
      "[20791]\teval-rmse:3.80947\ttrain-rmse:1.96524\n",
      "[20792]\teval-rmse:3.81079\ttrain-rmse:1.96518\n",
      "[20793]\teval-rmse:3.80876\ttrain-rmse:1.96527\n",
      "[20794]\teval-rmse:3.8084\ttrain-rmse:1.96528\n",
      "[20795]\teval-rmse:3.80698\ttrain-rmse:1.96537\n",
      "[20796]\teval-rmse:3.80624\ttrain-rmse:1.96541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20797]\teval-rmse:3.80759\ttrain-rmse:1.96534\n",
      "[20798]\teval-rmse:3.80793\ttrain-rmse:1.96532\n",
      "[20799]\teval-rmse:3.8075\ttrain-rmse:1.96535\n",
      "[20800]\teval-rmse:3.80837\ttrain-rmse:1.9653\n",
      "[20801]\teval-rmse:3.80892\ttrain-rmse:1.96527\n",
      "[20802]\teval-rmse:3.80943\ttrain-rmse:1.96525\n",
      "[20803]\teval-rmse:3.80856\ttrain-rmse:1.96529\n",
      "[20804]\teval-rmse:3.80699\ttrain-rmse:1.96538\n",
      "[20805]\teval-rmse:3.80831\ttrain-rmse:1.9653\n",
      "[20806]\teval-rmse:3.80866\ttrain-rmse:1.96528\n",
      "[20807]\teval-rmse:3.80741\ttrain-rmse:1.96535\n",
      "[20808]\teval-rmse:3.80578\ttrain-rmse:1.96544\n",
      "[20809]\teval-rmse:3.80692\ttrain-rmse:1.96538\n",
      "[20810]\teval-rmse:3.80753\ttrain-rmse:1.96535\n",
      "[20811]\teval-rmse:3.80659\ttrain-rmse:1.96539\n",
      "[20812]\teval-rmse:3.80852\ttrain-rmse:1.9653\n",
      "[20813]\teval-rmse:3.80957\ttrain-rmse:1.96525\n",
      "[20814]\teval-rmse:3.80921\ttrain-rmse:1.96527\n",
      "[20815]\teval-rmse:3.81089\ttrain-rmse:1.96517\n",
      "[20816]\teval-rmse:3.81154\ttrain-rmse:1.96514\n",
      "[20817]\teval-rmse:3.8101\ttrain-rmse:1.9652\n",
      "[20818]\teval-rmse:3.80891\ttrain-rmse:1.96526\n",
      "[20819]\teval-rmse:3.81085\ttrain-rmse:1.96519\n",
      "[20820]\teval-rmse:3.81264\ttrain-rmse:1.9651\n",
      "[20821]\teval-rmse:3.81432\ttrain-rmse:1.96501\n",
      "[20822]\teval-rmse:3.81503\ttrain-rmse:1.96498\n",
      "[20823]\teval-rmse:3.81658\ttrain-rmse:1.96492\n",
      "[20824]\teval-rmse:3.81628\ttrain-rmse:1.96493\n",
      "[20825]\teval-rmse:3.81632\ttrain-rmse:1.96493\n",
      "[20826]\teval-rmse:3.81481\ttrain-rmse:1.96499\n",
      "[20827]\teval-rmse:3.81651\ttrain-rmse:1.96492\n",
      "[20828]\teval-rmse:3.81653\ttrain-rmse:1.96492\n",
      "[20829]\teval-rmse:3.81492\ttrain-rmse:1.96498\n",
      "[20830]\teval-rmse:3.8134\ttrain-rmse:1.96505\n",
      "[20831]\teval-rmse:3.81265\ttrain-rmse:1.96508\n",
      "[20832]\teval-rmse:3.81216\ttrain-rmse:1.9651\n",
      "[20833]\teval-rmse:3.81302\ttrain-rmse:1.96506\n",
      "[20834]\teval-rmse:3.81471\ttrain-rmse:1.96499\n",
      "[20835]\teval-rmse:3.81533\ttrain-rmse:1.96496\n",
      "[20836]\teval-rmse:3.81434\ttrain-rmse:1.96499\n",
      "[20837]\teval-rmse:3.81384\ttrain-rmse:1.96501\n",
      "[20838]\teval-rmse:3.81385\ttrain-rmse:1.96501\n",
      "[20839]\teval-rmse:3.81514\ttrain-rmse:1.96496\n",
      "[20840]\teval-rmse:3.81331\ttrain-rmse:1.96503\n",
      "[20841]\teval-rmse:3.81499\ttrain-rmse:1.96496\n",
      "[20842]\teval-rmse:3.81476\ttrain-rmse:1.96496\n",
      "[20843]\teval-rmse:3.81431\ttrain-rmse:1.96498\n",
      "[20844]\teval-rmse:3.81593\ttrain-rmse:1.9649\n",
      "[20845]\teval-rmse:3.81493\ttrain-rmse:1.96493\n",
      "[20846]\teval-rmse:3.81559\ttrain-rmse:1.96491\n",
      "[20847]\teval-rmse:3.81396\ttrain-rmse:1.96497\n",
      "[20848]\teval-rmse:3.81321\ttrain-rmse:1.965\n",
      "[20849]\teval-rmse:3.81296\ttrain-rmse:1.96491\n",
      "[20850]\teval-rmse:3.8116\ttrain-rmse:1.96497\n",
      "[20851]\teval-rmse:3.81004\ttrain-rmse:1.96505\n",
      "[20852]\teval-rmse:3.80918\ttrain-rmse:1.96509\n",
      "[20853]\teval-rmse:3.80755\ttrain-rmse:1.96518\n",
      "[20854]\teval-rmse:3.80744\ttrain-rmse:1.96519\n",
      "[20855]\teval-rmse:3.80734\ttrain-rmse:1.96519\n",
      "[20856]\teval-rmse:3.80708\ttrain-rmse:1.9652\n",
      "[20857]\teval-rmse:3.8056\ttrain-rmse:1.9653\n",
      "[20858]\teval-rmse:3.80612\ttrain-rmse:1.96526\n",
      "[20859]\teval-rmse:3.80775\ttrain-rmse:1.96516\n",
      "[20860]\teval-rmse:3.8068\ttrain-rmse:1.9652\n",
      "[20861]\teval-rmse:3.807\ttrain-rmse:1.96519\n",
      "[20862]\teval-rmse:3.80869\ttrain-rmse:1.96508\n",
      "[20863]\teval-rmse:3.8081\ttrain-rmse:1.96511\n",
      "[20864]\teval-rmse:3.80815\ttrain-rmse:1.96511\n",
      "[20865]\teval-rmse:3.80658\ttrain-rmse:1.96521\n",
      "[20866]\teval-rmse:3.80793\ttrain-rmse:1.96513\n",
      "[20867]\teval-rmse:3.80928\ttrain-rmse:1.96505\n",
      "[20868]\teval-rmse:3.80853\ttrain-rmse:1.96509\n",
      "[20869]\teval-rmse:3.80958\ttrain-rmse:1.96503\n",
      "[20870]\teval-rmse:3.81019\ttrain-rmse:1.965\n",
      "[20871]\teval-rmse:3.81048\ttrain-rmse:1.96498\n",
      "[20872]\teval-rmse:3.81037\ttrain-rmse:1.96499\n",
      "[20873]\teval-rmse:3.81037\ttrain-rmse:1.96499\n",
      "[20874]\teval-rmse:3.80893\ttrain-rmse:1.96507\n",
      "[20875]\teval-rmse:3.80872\ttrain-rmse:1.96507\n",
      "[20876]\teval-rmse:3.81019\ttrain-rmse:1.965\n",
      "[20877]\teval-rmse:3.81023\ttrain-rmse:1.96499\n",
      "[20878]\teval-rmse:3.81011\ttrain-rmse:1.965\n",
      "[20879]\teval-rmse:3.81129\ttrain-rmse:1.96494\n",
      "[20880]\teval-rmse:3.81265\ttrain-rmse:1.96488\n",
      "[20881]\teval-rmse:3.81303\ttrain-rmse:1.96487\n",
      "[20882]\teval-rmse:3.81259\ttrain-rmse:1.96488\n",
      "[20883]\teval-rmse:3.81172\ttrain-rmse:1.96492\n",
      "[20884]\teval-rmse:3.81207\ttrain-rmse:1.9649\n",
      "[20885]\teval-rmse:3.81349\ttrain-rmse:1.96485\n",
      "[20886]\teval-rmse:3.8132\ttrain-rmse:1.96476\n",
      "[20887]\teval-rmse:3.81266\ttrain-rmse:1.96479\n",
      "[20888]\teval-rmse:3.81406\ttrain-rmse:1.96474\n",
      "[20889]\teval-rmse:3.81253\ttrain-rmse:1.9648\n",
      "[20890]\teval-rmse:3.81233\ttrain-rmse:1.9648\n",
      "[20891]\teval-rmse:3.81113\ttrain-rmse:1.96486\n",
      "[20892]\teval-rmse:3.81092\ttrain-rmse:1.96487\n",
      "[20893]\teval-rmse:3.80905\ttrain-rmse:1.96496\n",
      "[20894]\teval-rmse:3.80746\ttrain-rmse:1.96505\n",
      "[20895]\teval-rmse:3.80649\ttrain-rmse:1.96511\n",
      "[20896]\teval-rmse:3.80613\ttrain-rmse:1.96513\n",
      "[20897]\teval-rmse:3.80717\ttrain-rmse:1.96507\n",
      "[20898]\teval-rmse:3.80706\ttrain-rmse:1.96507\n",
      "[20899]\teval-rmse:3.80696\ttrain-rmse:1.96507\n",
      "[20900]\teval-rmse:3.80532\ttrain-rmse:1.96518\n",
      "[20901]\teval-rmse:3.80674\ttrain-rmse:1.96509\n",
      "[20902]\teval-rmse:3.8068\ttrain-rmse:1.96509\n",
      "[20903]\teval-rmse:3.8072\ttrain-rmse:1.96507\n",
      "[20904]\teval-rmse:3.80807\ttrain-rmse:1.96501\n",
      "[20905]\teval-rmse:3.80947\ttrain-rmse:1.96495\n",
      "[20906]\teval-rmse:3.80936\ttrain-rmse:1.96495\n",
      "[20907]\teval-rmse:3.80985\ttrain-rmse:1.96493\n",
      "[20908]\teval-rmse:3.81124\ttrain-rmse:1.96486\n",
      "[20909]\teval-rmse:3.8118\ttrain-rmse:1.96484\n",
      "[20910]\teval-rmse:3.81327\ttrain-rmse:1.96478\n",
      "[20911]\teval-rmse:3.81125\ttrain-rmse:1.96486\n",
      "[20912]\teval-rmse:3.81096\ttrain-rmse:1.96477\n",
      "[20913]\teval-rmse:3.81274\ttrain-rmse:1.96467\n",
      "[20914]\teval-rmse:3.81121\ttrain-rmse:1.96474\n",
      "[20915]\teval-rmse:3.81093\ttrain-rmse:1.96465\n",
      "[20916]\teval-rmse:3.8098\ttrain-rmse:1.9647\n",
      "[20917]\teval-rmse:3.80968\ttrain-rmse:1.96471\n",
      "[20918]\teval-rmse:3.80941\ttrain-rmse:1.96472\n",
      "[20919]\teval-rmse:3.80914\ttrain-rmse:1.96463\n",
      "[20920]\teval-rmse:3.81076\ttrain-rmse:1.96455\n",
      "[20921]\teval-rmse:3.81237\ttrain-rmse:1.96448\n",
      "[20922]\teval-rmse:3.8107\ttrain-rmse:1.96455\n",
      "[20923]\teval-rmse:3.81094\ttrain-rmse:1.96454\n",
      "[20924]\teval-rmse:3.8107\ttrain-rmse:1.96444\n",
      "[20925]\teval-rmse:3.81227\ttrain-rmse:1.96438\n",
      "[20926]\teval-rmse:3.8142\ttrain-rmse:1.96432\n",
      "[20927]\teval-rmse:3.81391\ttrain-rmse:1.96433\n",
      "[20928]\teval-rmse:3.81521\ttrain-rmse:1.96429\n",
      "[20929]\teval-rmse:3.81676\ttrain-rmse:1.96424\n",
      "[20930]\teval-rmse:3.81662\ttrain-rmse:1.96424\n",
      "[20931]\teval-rmse:3.81515\ttrain-rmse:1.96428\n",
      "[20932]\teval-rmse:3.81536\ttrain-rmse:1.96427\n",
      "[20933]\teval-rmse:3.81447\ttrain-rmse:1.96429\n",
      "[20934]\teval-rmse:3.81489\ttrain-rmse:1.96428\n",
      "[20935]\teval-rmse:3.81597\ttrain-rmse:1.96425\n",
      "[20936]\teval-rmse:3.81471\ttrain-rmse:1.9643\n",
      "[20937]\teval-rmse:3.81589\ttrain-rmse:1.96427\n",
      "[20938]\teval-rmse:3.81628\ttrain-rmse:1.96426\n",
      "[20939]\teval-rmse:3.81647\ttrain-rmse:1.96426\n",
      "[20940]\teval-rmse:3.81523\ttrain-rmse:1.96429\n",
      "[20941]\teval-rmse:3.81546\ttrain-rmse:1.96429\n",
      "[20942]\teval-rmse:3.81408\ttrain-rmse:1.96433\n",
      "[20943]\teval-rmse:3.81378\ttrain-rmse:1.96424\n",
      "[20944]\teval-rmse:3.81279\ttrain-rmse:1.96427\n",
      "[20945]\teval-rmse:3.81399\ttrain-rmse:1.96424\n",
      "[20946]\teval-rmse:3.81469\ttrain-rmse:1.96422\n",
      "[20947]\teval-rmse:3.8127\ttrain-rmse:1.96428\n",
      "[20948]\teval-rmse:3.81401\ttrain-rmse:1.96424\n",
      "[20949]\teval-rmse:3.81563\ttrain-rmse:1.9642\n",
      "[20950]\teval-rmse:3.81537\ttrain-rmse:1.96411\n",
      "[20951]\teval-rmse:3.81405\ttrain-rmse:1.96414\n",
      "[20952]\teval-rmse:3.8122\ttrain-rmse:1.9642\n",
      "[20953]\teval-rmse:3.81194\ttrain-rmse:1.96412\n",
      "[20954]\teval-rmse:3.81155\ttrain-rmse:1.96414\n",
      "[20955]\teval-rmse:3.81208\ttrain-rmse:1.96412\n",
      "[20956]\teval-rmse:3.8137\ttrain-rmse:1.96408\n",
      "[20957]\teval-rmse:3.81474\ttrain-rmse:1.96405\n",
      "[20958]\teval-rmse:3.81526\ttrain-rmse:1.96404\n",
      "[20959]\teval-rmse:3.81379\ttrain-rmse:1.96406\n",
      "[20960]\teval-rmse:3.81482\ttrain-rmse:1.96404\n",
      "[20961]\teval-rmse:3.81625\ttrain-rmse:1.96401\n",
      "[20962]\teval-rmse:3.81661\ttrain-rmse:1.964\n",
      "[20963]\teval-rmse:3.81698\ttrain-rmse:1.964\n",
      "[20964]\teval-rmse:3.81559\ttrain-rmse:1.96403\n",
      "[20965]\teval-rmse:3.81595\ttrain-rmse:1.96403\n",
      "[20966]\teval-rmse:3.81718\ttrain-rmse:1.96402\n",
      "[20967]\teval-rmse:3.816\ttrain-rmse:1.96405\n",
      "[20968]\teval-rmse:3.81521\ttrain-rmse:1.96407\n",
      "[20969]\teval-rmse:3.81496\ttrain-rmse:1.96407\n",
      "[20970]\teval-rmse:3.81349\ttrain-rmse:1.9641\n",
      "[20971]\teval-rmse:3.81326\ttrain-rmse:1.9641\n",
      "[20972]\teval-rmse:3.81486\ttrain-rmse:1.96406\n",
      "[20973]\teval-rmse:3.81482\ttrain-rmse:1.96406\n",
      "[20974]\teval-rmse:3.81604\ttrain-rmse:1.96403\n",
      "[20975]\teval-rmse:3.81742\ttrain-rmse:1.96402\n",
      "[20976]\teval-rmse:3.81572\ttrain-rmse:1.96403\n",
      "[20977]\teval-rmse:3.8153\ttrain-rmse:1.96405\n",
      "[20978]\teval-rmse:3.81658\ttrain-rmse:1.96401\n",
      "[20979]\teval-rmse:3.81635\ttrain-rmse:1.96402\n",
      "[20980]\teval-rmse:3.81779\ttrain-rmse:1.96399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20981]\teval-rmse:3.81631\ttrain-rmse:1.96401\n",
      "[20982]\teval-rmse:3.81792\ttrain-rmse:1.96397\n",
      "[20983]\teval-rmse:3.81621\ttrain-rmse:1.964\n",
      "[20984]\teval-rmse:3.81471\ttrain-rmse:1.96403\n",
      "[20985]\teval-rmse:3.81424\ttrain-rmse:1.96405\n",
      "[20986]\teval-rmse:3.81601\ttrain-rmse:1.96402\n",
      "[20987]\teval-rmse:3.81772\ttrain-rmse:1.96401\n",
      "[20988]\teval-rmse:3.81756\ttrain-rmse:1.96401\n",
      "[20989]\teval-rmse:3.81891\ttrain-rmse:1.964\n",
      "[20990]\teval-rmse:3.81892\ttrain-rmse:1.964\n",
      "[20991]\teval-rmse:3.81844\ttrain-rmse:1.96401\n",
      "[20992]\teval-rmse:3.81981\ttrain-rmse:1.96399\n",
      "[20993]\teval-rmse:3.82071\ttrain-rmse:1.96397\n",
      "[20994]\teval-rmse:3.82232\ttrain-rmse:1.96397\n",
      "[20995]\teval-rmse:3.82261\ttrain-rmse:1.96397\n",
      "[20996]\teval-rmse:3.82293\ttrain-rmse:1.96397\n",
      "[20997]\teval-rmse:3.82243\ttrain-rmse:1.96397\n",
      "[20998]\teval-rmse:3.82359\ttrain-rmse:1.96399\n",
      "[20999]\teval-rmse:3.8238\ttrain-rmse:1.96399\n",
      "[21000]\teval-rmse:3.8249\ttrain-rmse:1.96401\n",
      "[21001]\teval-rmse:3.82462\ttrain-rmse:1.96401\n",
      "[21002]\teval-rmse:3.82315\ttrain-rmse:1.96399\n",
      "[21003]\teval-rmse:3.82344\ttrain-rmse:1.96399\n",
      "[21004]\teval-rmse:3.82393\ttrain-rmse:1.96399\n",
      "[21005]\teval-rmse:3.82524\ttrain-rmse:1.964\n",
      "[21006]\teval-rmse:3.8249\ttrain-rmse:1.964\n",
      "[21007]\teval-rmse:3.82486\ttrain-rmse:1.964\n",
      "[21008]\teval-rmse:3.82661\ttrain-rmse:1.964\n",
      "[21009]\teval-rmse:3.82641\ttrain-rmse:1.964\n",
      "[21010]\teval-rmse:3.82474\ttrain-rmse:1.96399\n",
      "[21011]\teval-rmse:3.82416\ttrain-rmse:1.96398\n",
      "[21012]\teval-rmse:3.82284\ttrain-rmse:1.96399\n",
      "[21013]\teval-rmse:3.82158\ttrain-rmse:1.96399\n",
      "[21014]\teval-rmse:3.82153\ttrain-rmse:1.96399\n",
      "[21015]\teval-rmse:3.82028\ttrain-rmse:1.96399\n",
      "[21016]\teval-rmse:3.82011\ttrain-rmse:1.96399\n",
      "[21017]\teval-rmse:3.82042\ttrain-rmse:1.96399\n",
      "[21018]\teval-rmse:3.82218\ttrain-rmse:1.96399\n",
      "[21019]\teval-rmse:3.82376\ttrain-rmse:1.96401\n",
      "[21020]\teval-rmse:3.82359\ttrain-rmse:1.96401\n",
      "[21021]\teval-rmse:3.82215\ttrain-rmse:1.96401\n",
      "[21022]\teval-rmse:3.82155\ttrain-rmse:1.96402\n",
      "[21023]\teval-rmse:3.82122\ttrain-rmse:1.96402\n",
      "[21024]\teval-rmse:3.82018\ttrain-rmse:1.96404\n",
      "[21025]\teval-rmse:3.81889\ttrain-rmse:1.96405\n",
      "[21026]\teval-rmse:3.8192\ttrain-rmse:1.96406\n",
      "[21027]\teval-rmse:3.82009\ttrain-rmse:1.96403\n",
      "[21028]\teval-rmse:3.81923\ttrain-rmse:1.96403\n",
      "[21029]\teval-rmse:3.81765\ttrain-rmse:1.96402\n",
      "[21030]\teval-rmse:3.81789\ttrain-rmse:1.96402\n",
      "[21031]\teval-rmse:3.81855\ttrain-rmse:1.96401\n",
      "[21032]\teval-rmse:3.81773\ttrain-rmse:1.96402\n",
      "[21033]\teval-rmse:3.81829\ttrain-rmse:1.96402\n",
      "[21034]\teval-rmse:3.81781\ttrain-rmse:1.96402\n",
      "[21035]\teval-rmse:3.81643\ttrain-rmse:1.96404\n",
      "[21036]\teval-rmse:3.81579\ttrain-rmse:1.96405\n",
      "[21037]\teval-rmse:3.81706\ttrain-rmse:1.96403\n",
      "[21038]\teval-rmse:3.81657\ttrain-rmse:1.96404\n",
      "[21039]\teval-rmse:3.81539\ttrain-rmse:1.96408\n",
      "[21040]\teval-rmse:3.81439\ttrain-rmse:1.9641\n",
      "[21041]\teval-rmse:3.81349\ttrain-rmse:1.96412\n",
      "[21042]\teval-rmse:3.81486\ttrain-rmse:1.96409\n",
      "[21043]\teval-rmse:3.81597\ttrain-rmse:1.96407\n",
      "[21044]\teval-rmse:3.81753\ttrain-rmse:1.96407\n",
      "[21045]\teval-rmse:3.81812\ttrain-rmse:1.96407\n",
      "[21046]\teval-rmse:3.81815\ttrain-rmse:1.96407\n",
      "[21047]\teval-rmse:3.81834\ttrain-rmse:1.96407\n",
      "[21048]\teval-rmse:3.81754\ttrain-rmse:1.96408\n",
      "[21049]\teval-rmse:3.8174\ttrain-rmse:1.96408\n",
      "[21050]\teval-rmse:3.81823\ttrain-rmse:1.96407\n",
      "[21051]\teval-rmse:3.81842\ttrain-rmse:1.96407\n",
      "[21052]\teval-rmse:3.81811\ttrain-rmse:1.96399\n",
      "[21053]\teval-rmse:3.81844\ttrain-rmse:1.96399\n",
      "[21054]\teval-rmse:3.81796\ttrain-rmse:1.964\n",
      "[21055]\teval-rmse:3.81988\ttrain-rmse:1.96396\n",
      "[21056]\teval-rmse:3.81793\ttrain-rmse:1.96397\n",
      "[21057]\teval-rmse:3.8196\ttrain-rmse:1.96395\n",
      "[21058]\teval-rmse:3.81833\ttrain-rmse:1.96397\n",
      "[21059]\teval-rmse:3.81881\ttrain-rmse:1.96397\n",
      "[21060]\teval-rmse:3.81695\ttrain-rmse:1.96397\n",
      "[21061]\teval-rmse:3.81826\ttrain-rmse:1.96395\n",
      "[21062]\teval-rmse:3.81707\ttrain-rmse:1.96399\n",
      "[21063]\teval-rmse:3.81707\ttrain-rmse:1.96399\n",
      "[21064]\teval-rmse:3.81837\ttrain-rmse:1.96398\n",
      "[21065]\teval-rmse:3.81875\ttrain-rmse:1.96398\n",
      "[21066]\teval-rmse:3.81858\ttrain-rmse:1.96398\n",
      "[21067]\teval-rmse:3.82018\ttrain-rmse:1.96397\n",
      "[21068]\teval-rmse:3.8196\ttrain-rmse:1.96398\n",
      "[21069]\teval-rmse:3.81776\ttrain-rmse:1.96397\n",
      "[21070]\teval-rmse:3.81752\ttrain-rmse:1.96397\n",
      "[21071]\teval-rmse:3.8165\ttrain-rmse:1.96399\n",
      "[21072]\teval-rmse:3.81788\ttrain-rmse:1.96399\n",
      "[21073]\teval-rmse:3.81633\ttrain-rmse:1.964\n",
      "[21074]\teval-rmse:3.81591\ttrain-rmse:1.96402\n",
      "[21075]\teval-rmse:3.81784\ttrain-rmse:1.96398\n",
      "[21076]\teval-rmse:3.81661\ttrain-rmse:1.96399\n",
      "[21077]\teval-rmse:3.81694\ttrain-rmse:1.96399\n",
      "[21078]\teval-rmse:3.81539\ttrain-rmse:1.96402\n",
      "[21079]\teval-rmse:3.81603\ttrain-rmse:1.96402\n",
      "[21080]\teval-rmse:3.81589\ttrain-rmse:1.96402\n",
      "[21081]\teval-rmse:3.81674\ttrain-rmse:1.964\n",
      "[21082]\teval-rmse:3.81659\ttrain-rmse:1.96401\n",
      "[21083]\teval-rmse:3.81694\ttrain-rmse:1.96401\n",
      "[21084]\teval-rmse:3.81688\ttrain-rmse:1.96401\n",
      "[21085]\teval-rmse:3.81835\ttrain-rmse:1.96401\n",
      "[21086]\teval-rmse:3.81973\ttrain-rmse:1.96399\n",
      "[21087]\teval-rmse:3.82104\ttrain-rmse:1.96399\n",
      "[21088]\teval-rmse:3.82015\ttrain-rmse:1.96398\n",
      "[21089]\teval-rmse:3.82142\ttrain-rmse:1.96397\n",
      "[21090]\teval-rmse:3.82109\ttrain-rmse:1.96398\n",
      "[21091]\teval-rmse:3.81938\ttrain-rmse:1.96396\n",
      "[21092]\teval-rmse:3.81956\ttrain-rmse:1.96396\n",
      "[21093]\teval-rmse:3.81853\ttrain-rmse:1.96398\n",
      "[21094]\teval-rmse:3.81953\ttrain-rmse:1.96398\n",
      "[21095]\teval-rmse:3.81987\ttrain-rmse:1.96398\n",
      "[21096]\teval-rmse:3.81956\ttrain-rmse:1.96399\n",
      "[21097]\teval-rmse:3.82148\ttrain-rmse:1.96396\n",
      "[21098]\teval-rmse:3.82232\ttrain-rmse:1.96396\n",
      "[21099]\teval-rmse:3.82374\ttrain-rmse:1.96396\n",
      "[21100]\teval-rmse:3.82474\ttrain-rmse:1.96398\n",
      "[21101]\teval-rmse:3.82493\ttrain-rmse:1.96398\n",
      "[21102]\teval-rmse:3.82668\ttrain-rmse:1.96403\n",
      "[21103]\teval-rmse:3.82535\ttrain-rmse:1.96405\n",
      "[21104]\teval-rmse:3.82567\ttrain-rmse:1.96406\n",
      "[21105]\teval-rmse:3.82477\ttrain-rmse:1.96403\n",
      "[21106]\teval-rmse:3.82426\ttrain-rmse:1.96404\n",
      "[21107]\teval-rmse:3.82514\ttrain-rmse:1.96404\n",
      "[21108]\teval-rmse:3.82622\ttrain-rmse:1.96407\n",
      "[21109]\teval-rmse:3.82462\ttrain-rmse:1.96403\n",
      "[21110]\teval-rmse:3.82584\ttrain-rmse:1.96407\n",
      "[21111]\teval-rmse:3.82549\ttrain-rmse:1.96407\n",
      "[21112]\teval-rmse:3.8274\ttrain-rmse:1.96406\n",
      "[21113]\teval-rmse:3.82855\ttrain-rmse:1.96409\n",
      "[21114]\teval-rmse:3.82918\ttrain-rmse:1.96411\n",
      "[21115]\teval-rmse:3.83055\ttrain-rmse:1.96415\n",
      "[21116]\teval-rmse:3.82926\ttrain-rmse:1.96411\n",
      "[21117]\teval-rmse:3.82865\ttrain-rmse:1.9641\n",
      "[21118]\teval-rmse:3.82855\ttrain-rmse:1.96409\n",
      "[21119]\teval-rmse:3.82647\ttrain-rmse:1.96404\n",
      "[21120]\teval-rmse:3.82627\ttrain-rmse:1.96404\n",
      "[21121]\teval-rmse:3.82693\ttrain-rmse:1.96405\n",
      "[21122]\teval-rmse:3.82773\ttrain-rmse:1.96405\n",
      "[21123]\teval-rmse:3.82932\ttrain-rmse:1.96403\n",
      "[21124]\teval-rmse:3.82844\ttrain-rmse:1.96402\n",
      "[21125]\teval-rmse:3.82947\ttrain-rmse:1.96405\n",
      "[21126]\teval-rmse:3.82911\ttrain-rmse:1.96397\n",
      "[21127]\teval-rmse:3.8275\ttrain-rmse:1.96392\n",
      "[21128]\teval-rmse:3.82803\ttrain-rmse:1.96393\n",
      "[21129]\teval-rmse:3.82977\ttrain-rmse:1.96395\n",
      "[21130]\teval-rmse:3.82992\ttrain-rmse:1.96395\n",
      "[21131]\teval-rmse:3.82971\ttrain-rmse:1.96395\n",
      "[21132]\teval-rmse:3.83126\ttrain-rmse:1.96401\n",
      "[21133]\teval-rmse:3.83104\ttrain-rmse:1.964\n",
      "[21134]\teval-rmse:3.82957\ttrain-rmse:1.96397\n",
      "[21135]\teval-rmse:3.82815\ttrain-rmse:1.96395\n",
      "[21136]\teval-rmse:3.83007\ttrain-rmse:1.96396\n",
      "[21137]\teval-rmse:3.82881\ttrain-rmse:1.96394\n",
      "[21138]\teval-rmse:3.82984\ttrain-rmse:1.96396\n",
      "[21139]\teval-rmse:3.83\ttrain-rmse:1.96397\n",
      "[21140]\teval-rmse:3.83147\ttrain-rmse:1.96402\n",
      "[21141]\teval-rmse:3.83298\ttrain-rmse:1.96407\n",
      "[21142]\teval-rmse:3.83236\ttrain-rmse:1.96405\n",
      "[21143]\teval-rmse:3.83073\ttrain-rmse:1.96399\n",
      "[21144]\teval-rmse:3.83103\ttrain-rmse:1.96401\n",
      "[21145]\teval-rmse:3.83255\ttrain-rmse:1.96408\n",
      "[21146]\teval-rmse:3.83381\ttrain-rmse:1.96414\n",
      "[21147]\teval-rmse:3.83233\ttrain-rmse:1.96409\n",
      "[21148]\teval-rmse:3.83202\ttrain-rmse:1.96408\n",
      "[21149]\teval-rmse:3.83108\ttrain-rmse:1.96405\n",
      "[21150]\teval-rmse:3.8317\ttrain-rmse:1.96408\n",
      "[21151]\teval-rmse:3.83198\ttrain-rmse:1.96409\n",
      "[21152]\teval-rmse:3.83339\ttrain-rmse:1.96416\n",
      "[21153]\teval-rmse:3.83491\ttrain-rmse:1.96423\n",
      "[21154]\teval-rmse:3.83682\ttrain-rmse:1.96427\n",
      "[21155]\teval-rmse:3.83693\ttrain-rmse:1.96427\n",
      "[21156]\teval-rmse:3.83753\ttrain-rmse:1.96429\n",
      "[21157]\teval-rmse:3.83812\ttrain-rmse:1.96432\n",
      "[21158]\teval-rmse:3.83787\ttrain-rmse:1.96432\n",
      "[21159]\teval-rmse:3.83977\ttrain-rmse:1.96436\n",
      "[21160]\teval-rmse:3.84055\ttrain-rmse:1.96441\n",
      "[21161]\teval-rmse:3.83873\ttrain-rmse:1.96435\n",
      "[21162]\teval-rmse:3.84011\ttrain-rmse:1.96444\n",
      "[21163]\teval-rmse:3.84036\ttrain-rmse:1.96446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21164]\teval-rmse:3.84029\ttrain-rmse:1.96445\n",
      "[21165]\teval-rmse:3.83826\ttrain-rmse:1.96436\n",
      "[21166]\teval-rmse:3.83814\ttrain-rmse:1.96435\n",
      "[21167]\teval-rmse:3.83774\ttrain-rmse:1.96426\n",
      "[21168]\teval-rmse:3.83661\ttrain-rmse:1.96424\n",
      "[21169]\teval-rmse:3.83478\ttrain-rmse:1.96413\n",
      "[21170]\teval-rmse:3.83455\ttrain-rmse:1.96412\n",
      "[21171]\teval-rmse:3.83417\ttrain-rmse:1.96404\n",
      "[21172]\teval-rmse:3.83551\ttrain-rmse:1.96407\n",
      "[21173]\teval-rmse:3.83628\ttrain-rmse:1.96409\n",
      "[21174]\teval-rmse:3.83596\ttrain-rmse:1.96408\n",
      "[21175]\teval-rmse:3.83681\ttrain-rmse:1.96411\n",
      "[21176]\teval-rmse:3.83735\ttrain-rmse:1.96415\n",
      "[21177]\teval-rmse:3.83523\ttrain-rmse:1.96402\n",
      "[21178]\teval-rmse:3.83487\ttrain-rmse:1.96401\n",
      "[21179]\teval-rmse:3.83655\ttrain-rmse:1.96407\n",
      "[21180]\teval-rmse:3.8351\ttrain-rmse:1.96403\n",
      "[21181]\teval-rmse:3.8333\ttrain-rmse:1.96394\n",
      "[21182]\teval-rmse:3.83429\ttrain-rmse:1.96399\n",
      "[21183]\teval-rmse:3.83359\ttrain-rmse:1.96395\n",
      "[21184]\teval-rmse:3.83484\ttrain-rmse:1.96399\n",
      "[21185]\teval-rmse:3.83602\ttrain-rmse:1.96406\n",
      "[21186]\teval-rmse:3.8345\ttrain-rmse:1.964\n",
      "[21187]\teval-rmse:3.83506\ttrain-rmse:1.96403\n",
      "[21188]\teval-rmse:3.83472\ttrain-rmse:1.96402\n",
      "[21189]\teval-rmse:3.83439\ttrain-rmse:1.96402\n",
      "[21190]\teval-rmse:3.83406\ttrain-rmse:1.96401\n",
      "[21191]\teval-rmse:3.83373\ttrain-rmse:1.96399\n",
      "[21192]\teval-rmse:3.83421\ttrain-rmse:1.96402\n",
      "[21193]\teval-rmse:3.83467\ttrain-rmse:1.96404\n",
      "[21194]\teval-rmse:3.8351\ttrain-rmse:1.96406\n",
      "[21195]\teval-rmse:3.83664\ttrain-rmse:1.96415\n",
      "[21196]\teval-rmse:3.83444\ttrain-rmse:1.96403\n",
      "[21197]\teval-rmse:3.83557\ttrain-rmse:1.9641\n",
      "[21198]\teval-rmse:3.83499\ttrain-rmse:1.96408\n",
      "[21199]\teval-rmse:3.8332\ttrain-rmse:1.96397\n",
      "[21200]\teval-rmse:3.83339\ttrain-rmse:1.96398\n",
      "[21201]\teval-rmse:3.83179\ttrain-rmse:1.96393\n",
      "[21202]\teval-rmse:3.83053\ttrain-rmse:1.96393\n",
      "[21203]\teval-rmse:3.82999\ttrain-rmse:1.96391\n",
      "[21204]\teval-rmse:3.82962\ttrain-rmse:1.96391\n",
      "[21205]\teval-rmse:3.82821\ttrain-rmse:1.96392\n",
      "[21206]\teval-rmse:3.82833\ttrain-rmse:1.96392\n",
      "[21207]\teval-rmse:3.82668\ttrain-rmse:1.96389\n",
      "[21208]\teval-rmse:3.82577\ttrain-rmse:1.96386\n",
      "[21209]\teval-rmse:3.82415\ttrain-rmse:1.96385\n",
      "[21210]\teval-rmse:3.82413\ttrain-rmse:1.96385\n",
      "[21211]\teval-rmse:3.82532\ttrain-rmse:1.96388\n",
      "[21212]\teval-rmse:3.82346\ttrain-rmse:1.96385\n",
      "[21213]\teval-rmse:3.82296\ttrain-rmse:1.96385\n",
      "[21214]\teval-rmse:3.82394\ttrain-rmse:1.96387\n",
      "[21215]\teval-rmse:3.82532\ttrain-rmse:1.96392\n",
      "[21216]\teval-rmse:3.8262\ttrain-rmse:1.96392\n",
      "[21217]\teval-rmse:3.82748\ttrain-rmse:1.96397\n",
      "[21218]\teval-rmse:3.82728\ttrain-rmse:1.96396\n",
      "[21219]\teval-rmse:3.82516\ttrain-rmse:1.96391\n",
      "[21220]\teval-rmse:3.82368\ttrain-rmse:1.96387\n",
      "[21221]\teval-rmse:3.82174\ttrain-rmse:1.96386\n",
      "[21222]\teval-rmse:3.8221\ttrain-rmse:1.96387\n",
      "[21223]\teval-rmse:3.82055\ttrain-rmse:1.96388\n",
      "[21224]\teval-rmse:3.82057\ttrain-rmse:1.96388\n",
      "[21225]\teval-rmse:3.82013\ttrain-rmse:1.96388\n",
      "[21226]\teval-rmse:3.82136\ttrain-rmse:1.9639\n",
      "[21227]\teval-rmse:3.82032\ttrain-rmse:1.96391\n",
      "[21228]\teval-rmse:3.81929\ttrain-rmse:1.96392\n",
      "[21229]\teval-rmse:3.81758\ttrain-rmse:1.96392\n",
      "[21230]\teval-rmse:3.81709\ttrain-rmse:1.96393\n",
      "[21231]\teval-rmse:3.81536\ttrain-rmse:1.96393\n",
      "[21232]\teval-rmse:3.81458\ttrain-rmse:1.96395\n",
      "[21233]\teval-rmse:3.81402\ttrain-rmse:1.96397\n",
      "[21234]\teval-rmse:3.81531\ttrain-rmse:1.96394\n",
      "[21235]\teval-rmse:3.81507\ttrain-rmse:1.96395\n",
      "[21236]\teval-rmse:3.81511\ttrain-rmse:1.96395\n",
      "[21237]\teval-rmse:3.81686\ttrain-rmse:1.96388\n",
      "[21238]\teval-rmse:3.81749\ttrain-rmse:1.96388\n",
      "[21239]\teval-rmse:3.81696\ttrain-rmse:1.96389\n",
      "[21240]\teval-rmse:3.81668\ttrain-rmse:1.96381\n",
      "[21241]\teval-rmse:3.81549\ttrain-rmse:1.96383\n",
      "[21242]\teval-rmse:3.81534\ttrain-rmse:1.96383\n",
      "[21243]\teval-rmse:3.81503\ttrain-rmse:1.96384\n",
      "[21244]\teval-rmse:3.81451\ttrain-rmse:1.96384\n",
      "[21245]\teval-rmse:3.81289\ttrain-rmse:1.96386\n",
      "[21246]\teval-rmse:3.81433\ttrain-rmse:1.96383\n",
      "[21247]\teval-rmse:3.81252\ttrain-rmse:1.96386\n",
      "[21248]\teval-rmse:3.81136\ttrain-rmse:1.9639\n",
      "[21249]\teval-rmse:3.81035\ttrain-rmse:1.96392\n",
      "[21250]\teval-rmse:3.80983\ttrain-rmse:1.96394\n",
      "[21251]\teval-rmse:3.8097\ttrain-rmse:1.96394\n",
      "[21252]\teval-rmse:3.80991\ttrain-rmse:1.96393\n",
      "[21253]\teval-rmse:3.81038\ttrain-rmse:1.96392\n",
      "[21254]\teval-rmse:3.80914\ttrain-rmse:1.96397\n",
      "[21255]\teval-rmse:3.80716\ttrain-rmse:1.96404\n",
      "[21256]\teval-rmse:3.80551\ttrain-rmse:1.9641\n",
      "[21257]\teval-rmse:3.80744\ttrain-rmse:1.96402\n",
      "[21258]\teval-rmse:3.80904\ttrain-rmse:1.96395\n",
      "[21259]\teval-rmse:3.80937\ttrain-rmse:1.96394\n",
      "[21260]\teval-rmse:3.81027\ttrain-rmse:1.96392\n",
      "[21261]\teval-rmse:3.8108\ttrain-rmse:1.9639\n",
      "[21262]\teval-rmse:3.81234\ttrain-rmse:1.96385\n",
      "[21263]\teval-rmse:3.81087\ttrain-rmse:1.96389\n",
      "[21264]\teval-rmse:3.81074\ttrain-rmse:1.96389\n",
      "[21265]\teval-rmse:3.81034\ttrain-rmse:1.96391\n",
      "[21266]\teval-rmse:3.80886\ttrain-rmse:1.96397\n",
      "[21267]\teval-rmse:3.80978\ttrain-rmse:1.96394\n",
      "[21268]\teval-rmse:3.81118\ttrain-rmse:1.96391\n",
      "[21269]\teval-rmse:3.81096\ttrain-rmse:1.96392\n",
      "[21270]\teval-rmse:3.81234\ttrain-rmse:1.96389\n",
      "[21271]\teval-rmse:3.81036\ttrain-rmse:1.96394\n",
      "[21272]\teval-rmse:3.81022\ttrain-rmse:1.96395\n",
      "[21273]\teval-rmse:3.81009\ttrain-rmse:1.96395\n",
      "[21274]\teval-rmse:3.80982\ttrain-rmse:1.96396\n",
      "[21275]\teval-rmse:3.81014\ttrain-rmse:1.96395\n",
      "[21276]\teval-rmse:3.80854\ttrain-rmse:1.96398\n",
      "[21277]\teval-rmse:3.80726\ttrain-rmse:1.96403\n",
      "[21278]\teval-rmse:3.80856\ttrain-rmse:1.96398\n",
      "[21279]\teval-rmse:3.80829\ttrain-rmse:1.96399\n",
      "[21280]\teval-rmse:3.80817\ttrain-rmse:1.96399\n",
      "[21281]\teval-rmse:3.80901\ttrain-rmse:1.96396\n",
      "[21282]\teval-rmse:3.80969\ttrain-rmse:1.96393\n",
      "[21283]\teval-rmse:3.80922\ttrain-rmse:1.96395\n",
      "[21284]\teval-rmse:3.80758\ttrain-rmse:1.96402\n",
      "[21285]\teval-rmse:3.8079\ttrain-rmse:1.96401\n",
      "[21286]\teval-rmse:3.80742\ttrain-rmse:1.96403\n",
      "[21287]\teval-rmse:3.80585\ttrain-rmse:1.96409\n",
      "[21288]\teval-rmse:3.80586\ttrain-rmse:1.96409\n",
      "[21289]\teval-rmse:3.80624\ttrain-rmse:1.96407\n",
      "[21290]\teval-rmse:3.80468\ttrain-rmse:1.96413\n",
      "[21291]\teval-rmse:3.80628\ttrain-rmse:1.96405\n",
      "[21292]\teval-rmse:3.80677\ttrain-rmse:1.96403\n",
      "[21293]\teval-rmse:3.807\ttrain-rmse:1.96402\n",
      "[21294]\teval-rmse:3.80675\ttrain-rmse:1.96403\n",
      "[21295]\teval-rmse:3.80563\ttrain-rmse:1.9641\n",
      "[21296]\teval-rmse:3.80632\ttrain-rmse:1.96406\n",
      "[21297]\teval-rmse:3.80799\ttrain-rmse:1.964\n",
      "[21298]\teval-rmse:3.80777\ttrain-rmse:1.964\n",
      "[21299]\teval-rmse:3.80833\ttrain-rmse:1.96398\n",
      "[21300]\teval-rmse:3.80859\ttrain-rmse:1.96397\n",
      "[21301]\teval-rmse:3.80996\ttrain-rmse:1.96392\n",
      "[21302]\teval-rmse:3.80982\ttrain-rmse:1.96392\n",
      "[21303]\teval-rmse:3.81084\ttrain-rmse:1.9639\n",
      "[21304]\teval-rmse:3.80986\ttrain-rmse:1.96393\n",
      "[21305]\teval-rmse:3.80826\ttrain-rmse:1.96398\n",
      "[21306]\teval-rmse:3.80768\ttrain-rmse:1.96399\n",
      "[21307]\teval-rmse:3.8093\ttrain-rmse:1.96394\n",
      "[21308]\teval-rmse:3.81022\ttrain-rmse:1.96391\n",
      "[21309]\teval-rmse:3.81\ttrain-rmse:1.96391\n",
      "[21310]\teval-rmse:3.8104\ttrain-rmse:1.9639\n",
      "[21311]\teval-rmse:3.81028\ttrain-rmse:1.9639\n",
      "[21312]\teval-rmse:3.80881\ttrain-rmse:1.96394\n",
      "[21313]\teval-rmse:3.80853\ttrain-rmse:1.96395\n",
      "[21314]\teval-rmse:3.80945\ttrain-rmse:1.96391\n",
      "[21315]\teval-rmse:3.80986\ttrain-rmse:1.96389\n",
      "[21316]\teval-rmse:3.81179\ttrain-rmse:1.96383\n",
      "[21317]\teval-rmse:3.81098\ttrain-rmse:1.96386\n",
      "[21318]\teval-rmse:3.81075\ttrain-rmse:1.96386\n",
      "[21319]\teval-rmse:3.81021\ttrain-rmse:1.96388\n",
      "[21320]\teval-rmse:3.80882\ttrain-rmse:1.96393\n",
      "[21321]\teval-rmse:3.80753\ttrain-rmse:1.964\n",
      "[21322]\teval-rmse:3.8071\ttrain-rmse:1.96402\n",
      "[21323]\teval-rmse:3.8085\ttrain-rmse:1.96397\n",
      "[21324]\teval-rmse:3.80857\ttrain-rmse:1.96396\n",
      "[21325]\teval-rmse:3.80814\ttrain-rmse:1.96398\n",
      "[21326]\teval-rmse:3.80975\ttrain-rmse:1.96392\n",
      "[21327]\teval-rmse:3.80869\ttrain-rmse:1.96396\n",
      "[21328]\teval-rmse:3.80842\ttrain-rmse:1.96397\n",
      "[21329]\teval-rmse:3.80984\ttrain-rmse:1.96392\n",
      "[21330]\teval-rmse:3.80959\ttrain-rmse:1.96382\n",
      "[21331]\teval-rmse:3.80931\ttrain-rmse:1.96375\n",
      "[21332]\teval-rmse:3.8104\ttrain-rmse:1.96371\n",
      "[21333]\teval-rmse:3.8118\ttrain-rmse:1.96368\n",
      "[21334]\teval-rmse:3.81186\ttrain-rmse:1.96368\n",
      "[21335]\teval-rmse:3.81107\ttrain-rmse:1.96369\n",
      "[21336]\teval-rmse:3.81093\ttrain-rmse:1.9637\n",
      "[21337]\teval-rmse:3.81214\ttrain-rmse:1.96368\n",
      "[21338]\teval-rmse:3.81266\ttrain-rmse:1.96366\n",
      "[21339]\teval-rmse:3.81149\ttrain-rmse:1.96372\n",
      "[21340]\teval-rmse:3.81012\ttrain-rmse:1.96375\n",
      "[21341]\teval-rmse:3.80984\ttrain-rmse:1.96367\n",
      "[21342]\teval-rmse:3.81177\ttrain-rmse:1.96361\n",
      "[21343]\teval-rmse:3.81336\ttrain-rmse:1.96358\n",
      "[21344]\teval-rmse:3.81202\ttrain-rmse:1.96362\n",
      "[21345]\teval-rmse:3.81313\ttrain-rmse:1.96359\n",
      "[21346]\teval-rmse:3.8118\ttrain-rmse:1.96362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21347]\teval-rmse:3.80989\ttrain-rmse:1.96366\n",
      "[21348]\teval-rmse:3.80927\ttrain-rmse:1.96368\n",
      "[21349]\teval-rmse:3.809\ttrain-rmse:1.96369\n",
      "[21350]\teval-rmse:3.80777\ttrain-rmse:1.96374\n",
      "[21351]\teval-rmse:3.80648\ttrain-rmse:1.96378\n",
      "[21352]\teval-rmse:3.80704\ttrain-rmse:1.96376\n",
      "[21353]\teval-rmse:3.80817\ttrain-rmse:1.96372\n",
      "[21354]\teval-rmse:3.80796\ttrain-rmse:1.96373\n",
      "[21355]\teval-rmse:3.8088\ttrain-rmse:1.96369\n",
      "[21356]\teval-rmse:3.80858\ttrain-rmse:1.9637\n",
      "[21357]\teval-rmse:3.80744\ttrain-rmse:1.96376\n",
      "[21358]\teval-rmse:3.80586\ttrain-rmse:1.96385\n",
      "[21359]\teval-rmse:3.8069\ttrain-rmse:1.96381\n",
      "[21360]\teval-rmse:3.80529\ttrain-rmse:1.96388\n",
      "[21361]\teval-rmse:3.80478\ttrain-rmse:1.96391\n",
      "[21362]\teval-rmse:3.8064\ttrain-rmse:1.96383\n",
      "[21363]\teval-rmse:3.80619\ttrain-rmse:1.96384\n",
      "[21364]\teval-rmse:3.80786\ttrain-rmse:1.96375\n",
      "[21365]\teval-rmse:3.80625\ttrain-rmse:1.96382\n",
      "[21366]\teval-rmse:3.80599\ttrain-rmse:1.96383\n",
      "[21367]\teval-rmse:3.80442\ttrain-rmse:1.96389\n",
      "[21368]\teval-rmse:3.80429\ttrain-rmse:1.9639\n",
      "[21369]\teval-rmse:3.80596\ttrain-rmse:1.96379\n",
      "[21370]\teval-rmse:3.80474\ttrain-rmse:1.96387\n",
      "[21371]\teval-rmse:3.80599\ttrain-rmse:1.96381\n",
      "[21372]\teval-rmse:3.80734\ttrain-rmse:1.96376\n",
      "[21373]\teval-rmse:3.80581\ttrain-rmse:1.96381\n",
      "[21374]\teval-rmse:3.80669\ttrain-rmse:1.96378\n",
      "[21375]\teval-rmse:3.80722\ttrain-rmse:1.96375\n",
      "[21376]\teval-rmse:3.80594\ttrain-rmse:1.96383\n",
      "[21377]\teval-rmse:3.80754\ttrain-rmse:1.96377\n",
      "[21378]\teval-rmse:3.8064\ttrain-rmse:1.96383\n",
      "[21379]\teval-rmse:3.80559\ttrain-rmse:1.96386\n",
      "[21380]\teval-rmse:3.80464\ttrain-rmse:1.9639\n",
      "[21381]\teval-rmse:3.80609\ttrain-rmse:1.96384\n",
      "[21382]\teval-rmse:3.80454\ttrain-rmse:1.9639\n",
      "[21383]\teval-rmse:3.80443\ttrain-rmse:1.9639\n",
      "[21384]\teval-rmse:3.80324\ttrain-rmse:1.96396\n",
      "[21385]\teval-rmse:3.8038\ttrain-rmse:1.96394\n",
      "[21386]\teval-rmse:3.80344\ttrain-rmse:1.96396\n",
      "[21387]\teval-rmse:3.80511\ttrain-rmse:1.96388\n",
      "[21388]\teval-rmse:3.80385\ttrain-rmse:1.96394\n",
      "[21389]\teval-rmse:3.80411\ttrain-rmse:1.96392\n",
      "[21390]\teval-rmse:3.8048\ttrain-rmse:1.9639\n",
      "[21391]\teval-rmse:3.80283\ttrain-rmse:1.96401\n",
      "[21392]\teval-rmse:3.80152\ttrain-rmse:1.96408\n",
      "[21393]\teval-rmse:3.80117\ttrain-rmse:1.9641\n",
      "[21394]\teval-rmse:3.80059\ttrain-rmse:1.96413\n",
      "[21395]\teval-rmse:3.79944\ttrain-rmse:1.9642\n",
      "[21396]\teval-rmse:3.79852\ttrain-rmse:1.96425\n",
      "[21397]\teval-rmse:3.79868\ttrain-rmse:1.96423\n",
      "[21398]\teval-rmse:3.79904\ttrain-rmse:1.96421\n",
      "[21399]\teval-rmse:3.79932\ttrain-rmse:1.96419\n",
      "[21400]\teval-rmse:3.79923\ttrain-rmse:1.96419\n",
      "[21401]\teval-rmse:3.79879\ttrain-rmse:1.96422\n",
      "[21402]\teval-rmse:3.79684\ttrain-rmse:1.96435\n",
      "[21403]\teval-rmse:3.79568\ttrain-rmse:1.96444\n",
      "[21404]\teval-rmse:3.79715\ttrain-rmse:1.96432\n",
      "[21405]\teval-rmse:3.79599\ttrain-rmse:1.96442\n",
      "[21406]\teval-rmse:3.79529\ttrain-rmse:1.96446\n",
      "[21407]\teval-rmse:3.79454\ttrain-rmse:1.96452\n",
      "[21408]\teval-rmse:3.79615\ttrain-rmse:1.96441\n",
      "[21409]\teval-rmse:3.79525\ttrain-rmse:1.96446\n",
      "[21410]\teval-rmse:3.79478\ttrain-rmse:1.9645\n",
      "[21411]\teval-rmse:3.79358\ttrain-rmse:1.9646\n",
      "[21412]\teval-rmse:3.79414\ttrain-rmse:1.96456\n",
      "[21413]\teval-rmse:3.79399\ttrain-rmse:1.96457\n",
      "[21414]\teval-rmse:3.79568\ttrain-rmse:1.96445\n",
      "[21415]\teval-rmse:3.79552\ttrain-rmse:1.96446\n",
      "[21416]\teval-rmse:3.79658\ttrain-rmse:1.96439\n",
      "[21417]\teval-rmse:3.79624\ttrain-rmse:1.96442\n",
      "[21418]\teval-rmse:3.79692\ttrain-rmse:1.96437\n",
      "[21419]\teval-rmse:3.79551\ttrain-rmse:1.96447\n",
      "[21420]\teval-rmse:3.79617\ttrain-rmse:1.96443\n",
      "[21421]\teval-rmse:3.79601\ttrain-rmse:1.96444\n",
      "[21422]\teval-rmse:3.79531\ttrain-rmse:1.96448\n",
      "[21423]\teval-rmse:3.7967\ttrain-rmse:1.96438\n",
      "[21424]\teval-rmse:3.79524\ttrain-rmse:1.96449\n",
      "[21425]\teval-rmse:3.79478\ttrain-rmse:1.96452\n",
      "[21426]\teval-rmse:3.79646\ttrain-rmse:1.96441\n",
      "[21427]\teval-rmse:3.79527\ttrain-rmse:1.96449\n",
      "[21428]\teval-rmse:3.7969\ttrain-rmse:1.96438\n",
      "[21429]\teval-rmse:3.79713\ttrain-rmse:1.96437\n",
      "[21430]\teval-rmse:3.79696\ttrain-rmse:1.96438\n",
      "[21431]\teval-rmse:3.79722\ttrain-rmse:1.96436\n",
      "[21432]\teval-rmse:3.79753\ttrain-rmse:1.96434\n",
      "[21433]\teval-rmse:3.79903\ttrain-rmse:1.96425\n",
      "[21434]\teval-rmse:3.79939\ttrain-rmse:1.96423\n",
      "[21435]\teval-rmse:3.79793\ttrain-rmse:1.96431\n",
      "[21436]\teval-rmse:3.79833\ttrain-rmse:1.96429\n",
      "[21437]\teval-rmse:3.79874\ttrain-rmse:1.96426\n",
      "[21438]\teval-rmse:3.79754\ttrain-rmse:1.96434\n",
      "[21439]\teval-rmse:3.79646\ttrain-rmse:1.9644\n",
      "[21440]\teval-rmse:3.79492\ttrain-rmse:1.9645\n",
      "[21441]\teval-rmse:3.79687\ttrain-rmse:1.96438\n",
      "[21442]\teval-rmse:3.7957\ttrain-rmse:1.96448\n",
      "[21443]\teval-rmse:3.79563\ttrain-rmse:1.96448\n",
      "[21444]\teval-rmse:3.79548\ttrain-rmse:1.96449\n",
      "[21445]\teval-rmse:3.79527\ttrain-rmse:1.9645\n",
      "[21446]\teval-rmse:3.79448\ttrain-rmse:1.96456\n",
      "[21447]\teval-rmse:3.79321\ttrain-rmse:1.96465\n",
      "[21448]\teval-rmse:3.79243\ttrain-rmse:1.9647\n",
      "[21449]\teval-rmse:3.79245\ttrain-rmse:1.9647\n",
      "[21450]\teval-rmse:3.7923\ttrain-rmse:1.96471\n",
      "[21451]\teval-rmse:3.79112\ttrain-rmse:1.96482\n",
      "[21452]\teval-rmse:3.79108\ttrain-rmse:1.96482\n",
      "[21453]\teval-rmse:3.78966\ttrain-rmse:1.96495\n",
      "[21454]\teval-rmse:3.78961\ttrain-rmse:1.96495\n",
      "[21455]\teval-rmse:3.79155\ttrain-rmse:1.9648\n",
      "[21456]\teval-rmse:3.79192\ttrain-rmse:1.96477\n",
      "[21457]\teval-rmse:3.7902\ttrain-rmse:1.96492\n",
      "[21458]\teval-rmse:3.789\ttrain-rmse:1.96503\n",
      "[21459]\teval-rmse:3.78728\ttrain-rmse:1.96519\n",
      "[21460]\teval-rmse:3.78795\ttrain-rmse:1.96513\n",
      "[21461]\teval-rmse:3.78656\ttrain-rmse:1.96526\n",
      "[21462]\teval-rmse:3.78772\ttrain-rmse:1.96515\n",
      "[21463]\teval-rmse:3.78743\ttrain-rmse:1.96518\n",
      "[21464]\teval-rmse:3.78771\ttrain-rmse:1.96515\n",
      "[21465]\teval-rmse:3.78879\ttrain-rmse:1.96505\n",
      "[21466]\teval-rmse:3.78793\ttrain-rmse:1.96512\n",
      "[21467]\teval-rmse:3.78925\ttrain-rmse:1.965\n",
      "[21468]\teval-rmse:3.78839\ttrain-rmse:1.96507\n",
      "[21469]\teval-rmse:3.78893\ttrain-rmse:1.96502\n",
      "[21470]\teval-rmse:3.78929\ttrain-rmse:1.96499\n",
      "[21471]\teval-rmse:3.7891\ttrain-rmse:1.965\n",
      "[21472]\teval-rmse:3.78875\ttrain-rmse:1.96504\n",
      "[21473]\teval-rmse:3.79068\ttrain-rmse:1.96489\n",
      "[21474]\teval-rmse:3.79122\ttrain-rmse:1.96485\n",
      "[21475]\teval-rmse:3.79174\ttrain-rmse:1.96481\n",
      "[21476]\teval-rmse:3.79269\ttrain-rmse:1.96471\n",
      "[21477]\teval-rmse:3.79262\ttrain-rmse:1.96472\n",
      "[21478]\teval-rmse:3.79291\ttrain-rmse:1.9647\n",
      "[21479]\teval-rmse:3.79168\ttrain-rmse:1.96479\n",
      "[21480]\teval-rmse:3.79255\ttrain-rmse:1.96471\n",
      "[21481]\teval-rmse:3.79313\ttrain-rmse:1.96466\n",
      "[21482]\teval-rmse:3.79317\ttrain-rmse:1.96466\n",
      "[21483]\teval-rmse:3.79356\ttrain-rmse:1.96463\n",
      "[21484]\teval-rmse:3.79242\ttrain-rmse:1.96472\n",
      "[21485]\teval-rmse:3.79223\ttrain-rmse:1.96473\n",
      "[21486]\teval-rmse:3.79323\ttrain-rmse:1.96466\n",
      "[21487]\teval-rmse:3.79246\ttrain-rmse:1.96472\n",
      "[21488]\teval-rmse:3.79201\ttrain-rmse:1.96476\n",
      "[21489]\teval-rmse:3.79341\ttrain-rmse:1.96466\n",
      "[21490]\teval-rmse:3.79253\ttrain-rmse:1.96472\n",
      "[21491]\teval-rmse:3.79149\ttrain-rmse:1.96481\n",
      "[21492]\teval-rmse:3.79036\ttrain-rmse:1.96491\n",
      "[21493]\teval-rmse:3.79204\ttrain-rmse:1.96474\n",
      "[21494]\teval-rmse:3.79348\ttrain-rmse:1.96463\n",
      "[21495]\teval-rmse:3.79259\ttrain-rmse:1.96469\n",
      "[21496]\teval-rmse:3.79381\ttrain-rmse:1.9646\n",
      "[21497]\teval-rmse:3.79443\ttrain-rmse:1.96456\n",
      "[21498]\teval-rmse:3.7939\ttrain-rmse:1.9646\n",
      "[21499]\teval-rmse:3.79584\ttrain-rmse:1.96447\n",
      "[21500]\teval-rmse:3.79551\ttrain-rmse:1.9645\n",
      "[21501]\teval-rmse:3.79461\ttrain-rmse:1.96456\n",
      "[21502]\teval-rmse:3.79656\ttrain-rmse:1.96444\n",
      "[21503]\teval-rmse:3.79661\ttrain-rmse:1.96443\n",
      "[21504]\teval-rmse:3.79784\ttrain-rmse:1.96436\n",
      "[21505]\teval-rmse:3.79589\ttrain-rmse:1.96448\n",
      "[21506]\teval-rmse:3.79451\ttrain-rmse:1.96458\n",
      "[21507]\teval-rmse:3.79339\ttrain-rmse:1.96466\n",
      "[21508]\teval-rmse:3.79319\ttrain-rmse:1.96468\n",
      "[21509]\teval-rmse:3.79134\ttrain-rmse:1.96481\n",
      "[21510]\teval-rmse:3.78954\ttrain-rmse:1.96496\n",
      "[21511]\teval-rmse:3.78912\ttrain-rmse:1.965\n",
      "[21512]\teval-rmse:3.78802\ttrain-rmse:1.9651\n",
      "[21513]\teval-rmse:3.78759\ttrain-rmse:1.96515\n",
      "[21514]\teval-rmse:3.78823\ttrain-rmse:1.96509\n",
      "[21515]\teval-rmse:3.78819\ttrain-rmse:1.96509\n",
      "[21516]\teval-rmse:3.7895\ttrain-rmse:1.96497\n",
      "[21517]\teval-rmse:3.78898\ttrain-rmse:1.96501\n",
      "[21518]\teval-rmse:3.78894\ttrain-rmse:1.96502\n",
      "[21519]\teval-rmse:3.78923\ttrain-rmse:1.96499\n",
      "[21520]\teval-rmse:3.78945\ttrain-rmse:1.96497\n",
      "[21521]\teval-rmse:3.78893\ttrain-rmse:1.96502\n",
      "[21522]\teval-rmse:3.79019\ttrain-rmse:1.96491\n",
      "[21523]\teval-rmse:3.79126\ttrain-rmse:1.96481\n",
      "[21524]\teval-rmse:3.79051\ttrain-rmse:1.96487\n",
      "[21525]\teval-rmse:3.78948\ttrain-rmse:1.96497\n",
      "[21526]\teval-rmse:3.79142\ttrain-rmse:1.96482\n",
      "[21527]\teval-rmse:3.79066\ttrain-rmse:1.96488\n",
      "[21528]\teval-rmse:3.79022\ttrain-rmse:1.96493\n",
      "[21529]\teval-rmse:3.79175\ttrain-rmse:1.9648\n",
      "[21530]\teval-rmse:3.79139\ttrain-rmse:1.96484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21531]\teval-rmse:3.78997\ttrain-rmse:1.96495\n",
      "[21532]\teval-rmse:3.78826\ttrain-rmse:1.96511\n",
      "[21533]\teval-rmse:3.7902\ttrain-rmse:1.96496\n",
      "[21534]\teval-rmse:3.7908\ttrain-rmse:1.96491\n",
      "[21535]\teval-rmse:3.79044\ttrain-rmse:1.96494\n",
      "[21536]\teval-rmse:3.79076\ttrain-rmse:1.96491\n",
      "[21537]\teval-rmse:3.78929\ttrain-rmse:1.96505\n",
      "[21538]\teval-rmse:3.78993\ttrain-rmse:1.96499\n",
      "[21539]\teval-rmse:3.79059\ttrain-rmse:1.96493\n",
      "[21540]\teval-rmse:3.79123\ttrain-rmse:1.96487\n",
      "[21541]\teval-rmse:3.78977\ttrain-rmse:1.96501\n",
      "[21542]\teval-rmse:3.78964\ttrain-rmse:1.96502\n",
      "[21543]\teval-rmse:3.79142\ttrain-rmse:1.96484\n",
      "[21544]\teval-rmse:3.78966\ttrain-rmse:1.96501\n",
      "[21545]\teval-rmse:3.78936\ttrain-rmse:1.96504\n",
      "[21546]\teval-rmse:3.78932\ttrain-rmse:1.96504\n",
      "[21547]\teval-rmse:3.79005\ttrain-rmse:1.96497\n",
      "[21548]\teval-rmse:3.78961\ttrain-rmse:1.96501\n",
      "[21549]\teval-rmse:3.79034\ttrain-rmse:1.96494\n",
      "[21550]\teval-rmse:3.79029\ttrain-rmse:1.96495\n",
      "[21551]\teval-rmse:3.78927\ttrain-rmse:1.96504\n",
      "[21552]\teval-rmse:3.79059\ttrain-rmse:1.96492\n",
      "[21553]\teval-rmse:3.7909\ttrain-rmse:1.96489\n",
      "[21554]\teval-rmse:3.78947\ttrain-rmse:1.96502\n",
      "[21555]\teval-rmse:3.78982\ttrain-rmse:1.96499\n",
      "[21556]\teval-rmse:3.78916\ttrain-rmse:1.96505\n",
      "[21557]\teval-rmse:3.79054\ttrain-rmse:1.96492\n",
      "[21558]\teval-rmse:3.7898\ttrain-rmse:1.96499\n",
      "[21559]\teval-rmse:3.79133\ttrain-rmse:1.96484\n",
      "[21560]\teval-rmse:3.79081\ttrain-rmse:1.96489\n",
      "[21561]\teval-rmse:3.79275\ttrain-rmse:1.96475\n",
      "[21562]\teval-rmse:3.79469\ttrain-rmse:1.96462\n",
      "[21563]\teval-rmse:3.79318\ttrain-rmse:1.96475\n",
      "[21564]\teval-rmse:3.79265\ttrain-rmse:1.96479\n",
      "[21565]\teval-rmse:3.79162\ttrain-rmse:1.96489\n",
      "[21566]\teval-rmse:3.79223\ttrain-rmse:1.96484\n",
      "[21567]\teval-rmse:3.79112\ttrain-rmse:1.96494\n",
      "[21568]\teval-rmse:3.79093\ttrain-rmse:1.96485\n",
      "[21569]\teval-rmse:3.79152\ttrain-rmse:1.96479\n",
      "[21570]\teval-rmse:3.79324\ttrain-rmse:1.96464\n",
      "[21571]\teval-rmse:3.79271\ttrain-rmse:1.96469\n",
      "[21572]\teval-rmse:3.79288\ttrain-rmse:1.96468\n",
      "[21573]\teval-rmse:3.79452\ttrain-rmse:1.96455\n",
      "[21574]\teval-rmse:3.79616\ttrain-rmse:1.96441\n",
      "[21575]\teval-rmse:3.796\ttrain-rmse:1.96442\n",
      "[21576]\teval-rmse:3.79658\ttrain-rmse:1.96437\n",
      "[21577]\teval-rmse:3.79626\ttrain-rmse:1.9644\n",
      "[21578]\teval-rmse:3.79536\ttrain-rmse:1.96446\n",
      "[21579]\teval-rmse:3.79649\ttrain-rmse:1.96438\n",
      "[21580]\teval-rmse:3.79843\ttrain-rmse:1.96426\n",
      "[21581]\teval-rmse:3.79869\ttrain-rmse:1.96424\n",
      "[21582]\teval-rmse:3.79847\ttrain-rmse:1.96426\n",
      "[21583]\teval-rmse:3.79873\ttrain-rmse:1.96424\n",
      "[21584]\teval-rmse:3.799\ttrain-rmse:1.96422\n",
      "[21585]\teval-rmse:3.79986\ttrain-rmse:1.96416\n",
      "[21586]\teval-rmse:3.80049\ttrain-rmse:1.96412\n",
      "[21587]\teval-rmse:3.80205\ttrain-rmse:1.96403\n",
      "[21588]\teval-rmse:3.80231\ttrain-rmse:1.96401\n",
      "[21589]\teval-rmse:3.80264\ttrain-rmse:1.964\n",
      "[21590]\teval-rmse:3.80241\ttrain-rmse:1.96401\n",
      "[21591]\teval-rmse:3.80094\ttrain-rmse:1.96409\n",
      "[21592]\teval-rmse:3.8024\ttrain-rmse:1.96401\n",
      "[21593]\teval-rmse:3.80281\ttrain-rmse:1.96399\n",
      "[21594]\teval-rmse:3.80444\ttrain-rmse:1.96391\n",
      "[21595]\teval-rmse:3.80293\ttrain-rmse:1.96398\n",
      "[21596]\teval-rmse:3.80341\ttrain-rmse:1.96396\n",
      "[21597]\teval-rmse:3.80534\ttrain-rmse:1.96387\n",
      "[21598]\teval-rmse:3.80598\ttrain-rmse:1.96385\n",
      "[21599]\teval-rmse:3.80573\ttrain-rmse:1.96386\n",
      "[21600]\teval-rmse:3.80736\ttrain-rmse:1.96376\n",
      "[21601]\teval-rmse:3.80611\ttrain-rmse:1.96381\n",
      "[21602]\teval-rmse:3.80632\ttrain-rmse:1.9638\n",
      "[21603]\teval-rmse:3.80595\ttrain-rmse:1.96382\n",
      "[21604]\teval-rmse:3.80574\ttrain-rmse:1.96383\n",
      "[21605]\teval-rmse:3.80418\ttrain-rmse:1.96391\n",
      "[21606]\teval-rmse:3.80555\ttrain-rmse:1.96384\n",
      "[21607]\teval-rmse:3.80516\ttrain-rmse:1.96386\n",
      "[21608]\teval-rmse:3.80405\ttrain-rmse:1.96393\n",
      "[21609]\teval-rmse:3.80311\ttrain-rmse:1.96397\n",
      "[21610]\teval-rmse:3.80163\ttrain-rmse:1.96407\n",
      "[21611]\teval-rmse:3.80162\ttrain-rmse:1.96407\n",
      "[21612]\teval-rmse:3.80152\ttrain-rmse:1.96407\n",
      "[21613]\teval-rmse:3.80289\ttrain-rmse:1.96399\n",
      "[21614]\teval-rmse:3.80382\ttrain-rmse:1.96395\n",
      "[21615]\teval-rmse:3.80338\ttrain-rmse:1.96396\n",
      "[21616]\teval-rmse:3.805\ttrain-rmse:1.96385\n",
      "[21617]\teval-rmse:3.80503\ttrain-rmse:1.96385\n",
      "[21618]\teval-rmse:3.80532\ttrain-rmse:1.96384\n",
      "[21619]\teval-rmse:3.80509\ttrain-rmse:1.96385\n",
      "[21620]\teval-rmse:3.80596\ttrain-rmse:1.96381\n",
      "[21621]\teval-rmse:3.80651\ttrain-rmse:1.96379\n",
      "[21622]\teval-rmse:3.8053\ttrain-rmse:1.96386\n",
      "[21623]\teval-rmse:3.80472\ttrain-rmse:1.96389\n",
      "[21624]\teval-rmse:3.80324\ttrain-rmse:1.96398\n",
      "[21625]\teval-rmse:3.80432\ttrain-rmse:1.96393\n",
      "[21626]\teval-rmse:3.80492\ttrain-rmse:1.9639\n",
      "[21627]\teval-rmse:3.80413\ttrain-rmse:1.96394\n",
      "[21628]\teval-rmse:3.80372\ttrain-rmse:1.96396\n",
      "[21629]\teval-rmse:3.80535\ttrain-rmse:1.96385\n",
      "[21630]\teval-rmse:3.80563\ttrain-rmse:1.96384\n",
      "[21631]\teval-rmse:3.80619\ttrain-rmse:1.96382\n",
      "[21632]\teval-rmse:3.80498\ttrain-rmse:1.96389\n",
      "[21633]\teval-rmse:3.80652\ttrain-rmse:1.9638\n",
      "[21634]\teval-rmse:3.80631\ttrain-rmse:1.96381\n",
      "[21635]\teval-rmse:3.80481\ttrain-rmse:1.96388\n",
      "[21636]\teval-rmse:3.80354\ttrain-rmse:1.96393\n",
      "[21637]\teval-rmse:3.80304\ttrain-rmse:1.96396\n",
      "[21638]\teval-rmse:3.80231\ttrain-rmse:1.964\n",
      "[21639]\teval-rmse:3.80403\ttrain-rmse:1.96391\n",
      "[21640]\teval-rmse:3.80558\ttrain-rmse:1.96386\n",
      "[21641]\teval-rmse:3.80691\ttrain-rmse:1.96382\n",
      "[21642]\teval-rmse:3.80853\ttrain-rmse:1.96376\n",
      "[21643]\teval-rmse:3.80903\ttrain-rmse:1.96375\n",
      "[21644]\teval-rmse:3.80881\ttrain-rmse:1.96376\n",
      "[21645]\teval-rmse:3.80933\ttrain-rmse:1.96374\n",
      "[21646]\teval-rmse:3.80889\ttrain-rmse:1.96377\n",
      "[21647]\teval-rmse:3.80886\ttrain-rmse:1.96377\n",
      "[21648]\teval-rmse:3.8097\ttrain-rmse:1.96373\n",
      "[21649]\teval-rmse:3.80835\ttrain-rmse:1.96378\n",
      "[21650]\teval-rmse:3.80856\ttrain-rmse:1.96377\n",
      "[21651]\teval-rmse:3.80994\ttrain-rmse:1.96371\n",
      "[21652]\teval-rmse:3.81057\ttrain-rmse:1.9637\n",
      "[21653]\teval-rmse:3.81029\ttrain-rmse:1.96363\n",
      "[21654]\teval-rmse:3.80983\ttrain-rmse:1.96365\n",
      "[21655]\teval-rmse:3.80833\ttrain-rmse:1.96367\n",
      "[21656]\teval-rmse:3.8071\ttrain-rmse:1.96374\n",
      "[21657]\teval-rmse:3.80735\ttrain-rmse:1.96374\n",
      "[21658]\teval-rmse:3.80928\ttrain-rmse:1.96367\n",
      "[21659]\teval-rmse:3.81087\ttrain-rmse:1.96362\n",
      "[21660]\teval-rmse:3.81155\ttrain-rmse:1.9636\n",
      "[21661]\teval-rmse:3.81324\ttrain-rmse:1.96356\n",
      "[21662]\teval-rmse:3.81238\ttrain-rmse:1.96358\n",
      "[21663]\teval-rmse:3.81263\ttrain-rmse:1.96357\n",
      "[21664]\teval-rmse:3.81421\ttrain-rmse:1.96354\n",
      "[21665]\teval-rmse:3.81421\ttrain-rmse:1.96354\n",
      "[21666]\teval-rmse:3.81392\ttrain-rmse:1.96347\n",
      "[21667]\teval-rmse:3.81366\ttrain-rmse:1.96347\n",
      "[21668]\teval-rmse:3.81527\ttrain-rmse:1.96345\n",
      "[21669]\teval-rmse:3.81647\ttrain-rmse:1.96346\n",
      "[21670]\teval-rmse:3.81789\ttrain-rmse:1.96345\n",
      "[21671]\teval-rmse:3.81663\ttrain-rmse:1.96346\n",
      "[21672]\teval-rmse:3.81632\ttrain-rmse:1.96346\n",
      "[21673]\teval-rmse:3.81793\ttrain-rmse:1.96341\n",
      "[21674]\teval-rmse:3.81767\ttrain-rmse:1.96341\n",
      "[21675]\teval-rmse:3.8192\ttrain-rmse:1.96341\n",
      "[21676]\teval-rmse:3.81733\ttrain-rmse:1.96338\n",
      "[21677]\teval-rmse:3.81605\ttrain-rmse:1.96343\n",
      "[21678]\teval-rmse:3.8154\ttrain-rmse:1.96344\n",
      "[21679]\teval-rmse:3.8161\ttrain-rmse:1.96344\n",
      "[21680]\teval-rmse:3.81802\ttrain-rmse:1.9634\n",
      "[21681]\teval-rmse:3.81598\ttrain-rmse:1.96341\n",
      "[21682]\teval-rmse:3.81659\ttrain-rmse:1.96341\n",
      "[21683]\teval-rmse:3.81542\ttrain-rmse:1.96346\n",
      "[21684]\teval-rmse:3.81516\ttrain-rmse:1.96346\n",
      "[21685]\teval-rmse:3.81431\ttrain-rmse:1.96347\n",
      "[21686]\teval-rmse:3.81585\ttrain-rmse:1.96344\n",
      "[21687]\teval-rmse:3.81752\ttrain-rmse:1.96343\n",
      "[21688]\teval-rmse:3.81927\ttrain-rmse:1.96337\n",
      "[21689]\teval-rmse:3.81796\ttrain-rmse:1.96336\n",
      "[21690]\teval-rmse:3.81831\ttrain-rmse:1.96336\n",
      "[21691]\teval-rmse:3.81997\ttrain-rmse:1.96331\n",
      "[21692]\teval-rmse:3.8197\ttrain-rmse:1.96331\n",
      "[21693]\teval-rmse:3.8213\ttrain-rmse:1.96327\n",
      "[21694]\teval-rmse:3.82272\ttrain-rmse:1.96326\n",
      "[21695]\teval-rmse:3.82352\ttrain-rmse:1.96327\n",
      "[21696]\teval-rmse:3.82207\ttrain-rmse:1.96328\n",
      "[21697]\teval-rmse:3.82155\ttrain-rmse:1.96328\n",
      "[21698]\teval-rmse:3.82177\ttrain-rmse:1.96328\n",
      "[21699]\teval-rmse:3.82337\ttrain-rmse:1.96325\n",
      "[21700]\teval-rmse:3.8249\ttrain-rmse:1.96328\n",
      "[21701]\teval-rmse:3.82322\ttrain-rmse:1.96326\n",
      "[21702]\teval-rmse:3.82188\ttrain-rmse:1.96324\n",
      "[21703]\teval-rmse:3.82084\ttrain-rmse:1.96323\n",
      "[21704]\teval-rmse:3.82149\ttrain-rmse:1.96322\n",
      "[21705]\teval-rmse:3.82123\ttrain-rmse:1.96322\n",
      "[21706]\teval-rmse:3.82072\ttrain-rmse:1.96322\n",
      "[21707]\teval-rmse:3.82208\ttrain-rmse:1.96321\n",
      "[21708]\teval-rmse:3.82376\ttrain-rmse:1.96322\n",
      "[21709]\teval-rmse:3.82368\ttrain-rmse:1.96321\n",
      "[21710]\teval-rmse:3.82421\ttrain-rmse:1.96322\n",
      "[21711]\teval-rmse:3.82479\ttrain-rmse:1.96323\n",
      "[21712]\teval-rmse:3.82472\ttrain-rmse:1.96323\n",
      "[21713]\teval-rmse:3.82415\ttrain-rmse:1.96322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21714]\teval-rmse:3.82575\ttrain-rmse:1.96319\n",
      "[21715]\teval-rmse:3.82445\ttrain-rmse:1.96319\n",
      "[21716]\teval-rmse:3.82426\ttrain-rmse:1.96319\n",
      "[21717]\teval-rmse:3.8223\ttrain-rmse:1.96316\n",
      "[21718]\teval-rmse:3.82422\ttrain-rmse:1.96315\n",
      "[21719]\teval-rmse:3.82251\ttrain-rmse:1.96315\n",
      "[21720]\teval-rmse:3.82207\ttrain-rmse:1.96315\n",
      "[21721]\teval-rmse:3.8215\ttrain-rmse:1.96316\n",
      "[21722]\teval-rmse:3.82267\ttrain-rmse:1.96316\n",
      "[21723]\teval-rmse:3.82433\ttrain-rmse:1.96312\n",
      "[21724]\teval-rmse:3.82303\ttrain-rmse:1.96313\n",
      "[21725]\teval-rmse:3.82268\ttrain-rmse:1.96313\n",
      "[21726]\teval-rmse:3.82235\ttrain-rmse:1.96304\n",
      "[21727]\teval-rmse:3.82273\ttrain-rmse:1.96304\n",
      "[21728]\teval-rmse:3.82222\ttrain-rmse:1.96304\n",
      "[21729]\teval-rmse:3.82363\ttrain-rmse:1.96305\n",
      "[21730]\teval-rmse:3.82357\ttrain-rmse:1.96305\n",
      "[21731]\teval-rmse:3.82339\ttrain-rmse:1.96305\n",
      "[21732]\teval-rmse:3.82427\ttrain-rmse:1.96306\n",
      "[21733]\teval-rmse:3.82398\ttrain-rmse:1.96306\n",
      "[21734]\teval-rmse:3.82432\ttrain-rmse:1.96307\n",
      "[21735]\teval-rmse:3.82624\ttrain-rmse:1.96307\n",
      "[21736]\teval-rmse:3.82591\ttrain-rmse:1.96298\n",
      "[21737]\teval-rmse:3.82736\ttrain-rmse:1.96302\n",
      "[21738]\teval-rmse:3.82878\ttrain-rmse:1.96304\n",
      "[21739]\teval-rmse:3.82769\ttrain-rmse:1.96304\n",
      "[21740]\teval-rmse:3.82798\ttrain-rmse:1.96304\n",
      "[21741]\teval-rmse:3.82665\ttrain-rmse:1.96304\n",
      "[21742]\teval-rmse:3.82532\ttrain-rmse:1.96304\n",
      "[21743]\teval-rmse:3.82556\ttrain-rmse:1.96304\n",
      "[21744]\teval-rmse:3.82355\ttrain-rmse:1.96303\n",
      "[21745]\teval-rmse:3.822\ttrain-rmse:1.96302\n",
      "[21746]\teval-rmse:3.82166\ttrain-rmse:1.96302\n",
      "[21747]\teval-rmse:3.8232\ttrain-rmse:1.96303\n",
      "[21748]\teval-rmse:3.82375\ttrain-rmse:1.96302\n",
      "[21749]\teval-rmse:3.82482\ttrain-rmse:1.96305\n",
      "[21750]\teval-rmse:3.8236\ttrain-rmse:1.96305\n",
      "[21751]\teval-rmse:3.82183\ttrain-rmse:1.96304\n",
      "[21752]\teval-rmse:3.82078\ttrain-rmse:1.96305\n",
      "[21753]\teval-rmse:3.81958\ttrain-rmse:1.96308\n",
      "[21754]\teval-rmse:3.81828\ttrain-rmse:1.96311\n",
      "[21755]\teval-rmse:3.81771\ttrain-rmse:1.96312\n",
      "[21756]\teval-rmse:3.81714\ttrain-rmse:1.96313\n",
      "[21757]\teval-rmse:3.81612\ttrain-rmse:1.96315\n",
      "[21758]\teval-rmse:3.81627\ttrain-rmse:1.96315\n",
      "[21759]\teval-rmse:3.81819\ttrain-rmse:1.96312\n",
      "[21760]\teval-rmse:3.81776\ttrain-rmse:1.96313\n",
      "[21761]\teval-rmse:3.81918\ttrain-rmse:1.96311\n",
      "[21762]\teval-rmse:3.81886\ttrain-rmse:1.96311\n",
      "[21763]\teval-rmse:3.81839\ttrain-rmse:1.96312\n",
      "[21764]\teval-rmse:3.81777\ttrain-rmse:1.96312\n",
      "[21765]\teval-rmse:3.81859\ttrain-rmse:1.96311\n",
      "[21766]\teval-rmse:3.81948\ttrain-rmse:1.96308\n",
      "[21767]\teval-rmse:3.81969\ttrain-rmse:1.96308\n",
      "[21768]\teval-rmse:3.81811\ttrain-rmse:1.96309\n",
      "[21769]\teval-rmse:3.81806\ttrain-rmse:1.96309\n",
      "[21770]\teval-rmse:3.81998\ttrain-rmse:1.96307\n",
      "[21771]\teval-rmse:3.8198\ttrain-rmse:1.96307\n",
      "[21772]\teval-rmse:3.81955\ttrain-rmse:1.96307\n",
      "[21773]\teval-rmse:3.82116\ttrain-rmse:1.96303\n",
      "[21774]\teval-rmse:3.81987\ttrain-rmse:1.96306\n",
      "[21775]\teval-rmse:3.82043\ttrain-rmse:1.96305\n",
      "[21776]\teval-rmse:3.82063\ttrain-rmse:1.96306\n",
      "[21777]\teval-rmse:3.81936\ttrain-rmse:1.96306\n",
      "[21778]\teval-rmse:3.82026\ttrain-rmse:1.96303\n",
      "[21779]\teval-rmse:3.81981\ttrain-rmse:1.96303\n",
      "[21780]\teval-rmse:3.81861\ttrain-rmse:1.96304\n",
      "[21781]\teval-rmse:3.81885\ttrain-rmse:1.96304\n",
      "[21782]\teval-rmse:3.81686\ttrain-rmse:1.96307\n",
      "[21783]\teval-rmse:3.8181\ttrain-rmse:1.96307\n",
      "[21784]\teval-rmse:3.81877\ttrain-rmse:1.96305\n",
      "[21785]\teval-rmse:3.82017\ttrain-rmse:1.96305\n",
      "[21786]\teval-rmse:3.82146\ttrain-rmse:1.96305\n",
      "[21787]\teval-rmse:3.82004\ttrain-rmse:1.96307\n",
      "[21788]\teval-rmse:3.82003\ttrain-rmse:1.96307\n",
      "[21789]\teval-rmse:3.82195\ttrain-rmse:1.96305\n",
      "[21790]\teval-rmse:3.82305\ttrain-rmse:1.96306\n",
      "[21791]\teval-rmse:3.82285\ttrain-rmse:1.96306\n",
      "[21792]\teval-rmse:3.82313\ttrain-rmse:1.96306\n",
      "[21793]\teval-rmse:3.82333\ttrain-rmse:1.96306\n",
      "[21794]\teval-rmse:3.82172\ttrain-rmse:1.96306\n",
      "[21795]\teval-rmse:3.82228\ttrain-rmse:1.96305\n",
      "[21796]\teval-rmse:3.82279\ttrain-rmse:1.96306\n",
      "[21797]\teval-rmse:3.82361\ttrain-rmse:1.96306\n",
      "[21798]\teval-rmse:3.82409\ttrain-rmse:1.96307\n",
      "[21799]\teval-rmse:3.82446\ttrain-rmse:1.96307\n",
      "[21800]\teval-rmse:3.82612\ttrain-rmse:1.96307\n",
      "[21801]\teval-rmse:3.82582\ttrain-rmse:1.96306\n",
      "[21802]\teval-rmse:3.82609\ttrain-rmse:1.96307\n",
      "[21803]\teval-rmse:3.82662\ttrain-rmse:1.96308\n",
      "[21804]\teval-rmse:3.82714\ttrain-rmse:1.96309\n",
      "[21805]\teval-rmse:3.82539\ttrain-rmse:1.96306\n",
      "[21806]\teval-rmse:3.82571\ttrain-rmse:1.96306\n",
      "[21807]\teval-rmse:3.82691\ttrain-rmse:1.96308\n",
      "[21808]\teval-rmse:3.82584\ttrain-rmse:1.96307\n",
      "[21809]\teval-rmse:3.82503\ttrain-rmse:1.96305\n",
      "[21810]\teval-rmse:3.82353\ttrain-rmse:1.96305\n",
      "[21811]\teval-rmse:3.82198\ttrain-rmse:1.96306\n",
      "[21812]\teval-rmse:3.82068\ttrain-rmse:1.96307\n",
      "[21813]\teval-rmse:3.82123\ttrain-rmse:1.96307\n",
      "[21814]\teval-rmse:3.81962\ttrain-rmse:1.96307\n",
      "[21815]\teval-rmse:3.8181\ttrain-rmse:1.9631\n",
      "[21816]\teval-rmse:3.81953\ttrain-rmse:1.96309\n",
      "[21817]\teval-rmse:3.81817\ttrain-rmse:1.9631\n",
      "[21818]\teval-rmse:3.81769\ttrain-rmse:1.96311\n",
      "[21819]\teval-rmse:3.81808\ttrain-rmse:1.9631\n",
      "[21820]\teval-rmse:3.81866\ttrain-rmse:1.9631\n",
      "[21821]\teval-rmse:3.81834\ttrain-rmse:1.96301\n",
      "[21822]\teval-rmse:3.8187\ttrain-rmse:1.96301\n",
      "[21823]\teval-rmse:3.81852\ttrain-rmse:1.96301\n",
      "[21824]\teval-rmse:3.8182\ttrain-rmse:1.96293\n",
      "[21825]\teval-rmse:3.81789\ttrain-rmse:1.96293\n",
      "[21826]\teval-rmse:3.81656\ttrain-rmse:1.96297\n",
      "[21827]\teval-rmse:3.81707\ttrain-rmse:1.96297\n",
      "[21828]\teval-rmse:3.81762\ttrain-rmse:1.96297\n",
      "[21829]\teval-rmse:3.81605\ttrain-rmse:1.96296\n",
      "[21830]\teval-rmse:3.81696\ttrain-rmse:1.96295\n",
      "[21831]\teval-rmse:3.81829\ttrain-rmse:1.96296\n",
      "[21832]\teval-rmse:3.8189\ttrain-rmse:1.96296\n",
      "[21833]\teval-rmse:3.81872\ttrain-rmse:1.96296\n",
      "[21834]\teval-rmse:3.81961\ttrain-rmse:1.96295\n",
      "[21835]\teval-rmse:3.81805\ttrain-rmse:1.96294\n",
      "[21836]\teval-rmse:3.81788\ttrain-rmse:1.96294\n",
      "[21837]\teval-rmse:3.81742\ttrain-rmse:1.96294\n",
      "[21838]\teval-rmse:3.81903\ttrain-rmse:1.96289\n",
      "[21839]\teval-rmse:3.82046\ttrain-rmse:1.96288\n",
      "[21840]\teval-rmse:3.82221\ttrain-rmse:1.96284\n",
      "[21841]\teval-rmse:3.82162\ttrain-rmse:1.96284\n",
      "[21842]\teval-rmse:3.82144\ttrain-rmse:1.96284\n",
      "[21843]\teval-rmse:3.82189\ttrain-rmse:1.96284\n",
      "[21844]\teval-rmse:3.82278\ttrain-rmse:1.96286\n",
      "[21845]\teval-rmse:3.82172\ttrain-rmse:1.96286\n",
      "[21846]\teval-rmse:3.8217\ttrain-rmse:1.96286\n",
      "[21847]\teval-rmse:3.82231\ttrain-rmse:1.96287\n",
      "[21848]\teval-rmse:3.82422\ttrain-rmse:1.96287\n",
      "[21849]\teval-rmse:3.82369\ttrain-rmse:1.96286\n",
      "[21850]\teval-rmse:3.82205\ttrain-rmse:1.96284\n",
      "[21851]\teval-rmse:3.82186\ttrain-rmse:1.96285\n",
      "[21852]\teval-rmse:3.82324\ttrain-rmse:1.96286\n",
      "[21853]\teval-rmse:3.82447\ttrain-rmse:1.96288\n",
      "[21854]\teval-rmse:3.8245\ttrain-rmse:1.96288\n",
      "[21855]\teval-rmse:3.8243\ttrain-rmse:1.96288\n",
      "[21856]\teval-rmse:3.82585\ttrain-rmse:1.96292\n",
      "[21857]\teval-rmse:3.82391\ttrain-rmse:1.9629\n",
      "[21858]\teval-rmse:3.82341\ttrain-rmse:1.9629\n",
      "[21859]\teval-rmse:3.82274\ttrain-rmse:1.9629\n",
      "[21860]\teval-rmse:3.8224\ttrain-rmse:1.96282\n",
      "[21861]\teval-rmse:3.8208\ttrain-rmse:1.96279\n",
      "[21862]\teval-rmse:3.81923\ttrain-rmse:1.96278\n",
      "[21863]\teval-rmse:3.81837\ttrain-rmse:1.96278\n",
      "[21864]\teval-rmse:3.81696\ttrain-rmse:1.96281\n",
      "[21865]\teval-rmse:3.81665\ttrain-rmse:1.96281\n",
      "[21866]\teval-rmse:3.81635\ttrain-rmse:1.96281\n",
      "[21867]\teval-rmse:3.81827\ttrain-rmse:1.96279\n",
      "[21868]\teval-rmse:3.81779\ttrain-rmse:1.9628\n",
      "[21869]\teval-rmse:3.81917\ttrain-rmse:1.96277\n",
      "[21870]\teval-rmse:3.82109\ttrain-rmse:1.96275\n",
      "[21871]\teval-rmse:3.82276\ttrain-rmse:1.96273\n",
      "[21872]\teval-rmse:3.82452\ttrain-rmse:1.9627\n",
      "[21873]\teval-rmse:3.82399\ttrain-rmse:1.9627\n",
      "[21874]\teval-rmse:3.82277\ttrain-rmse:1.96268\n",
      "[21875]\teval-rmse:3.82211\ttrain-rmse:1.96269\n",
      "[21876]\teval-rmse:3.82131\ttrain-rmse:1.96268\n",
      "[21877]\teval-rmse:3.82191\ttrain-rmse:1.96268\n",
      "[21878]\teval-rmse:3.82334\ttrain-rmse:1.96268\n",
      "[21879]\teval-rmse:3.82471\ttrain-rmse:1.96269\n",
      "[21880]\teval-rmse:3.8252\ttrain-rmse:1.9627\n",
      "[21881]\teval-rmse:3.82635\ttrain-rmse:1.96272\n",
      "[21882]\teval-rmse:3.82465\ttrain-rmse:1.96273\n",
      "[21883]\teval-rmse:3.8248\ttrain-rmse:1.96273\n",
      "[21884]\teval-rmse:3.82348\ttrain-rmse:1.96275\n",
      "[21885]\teval-rmse:3.82405\ttrain-rmse:1.96275\n",
      "[21886]\teval-rmse:3.82533\ttrain-rmse:1.96276\n",
      "[21887]\teval-rmse:3.82724\ttrain-rmse:1.96277\n",
      "[21888]\teval-rmse:3.82772\ttrain-rmse:1.96277\n",
      "[21889]\teval-rmse:3.82876\ttrain-rmse:1.96279\n",
      "[21890]\teval-rmse:3.83066\ttrain-rmse:1.96281\n",
      "[21891]\teval-rmse:3.82903\ttrain-rmse:1.9628\n",
      "[21892]\teval-rmse:3.8293\ttrain-rmse:1.9628\n",
      "[21893]\teval-rmse:3.8298\ttrain-rmse:1.9628\n",
      "[21894]\teval-rmse:3.83145\ttrain-rmse:1.9628\n",
      "[21895]\teval-rmse:3.8331\ttrain-rmse:1.96279\n",
      "[21896]\teval-rmse:3.83118\ttrain-rmse:1.96273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21897]\teval-rmse:3.83063\ttrain-rmse:1.96272\n",
      "[21898]\teval-rmse:3.83175\ttrain-rmse:1.96274\n",
      "[21899]\teval-rmse:3.82979\ttrain-rmse:1.96268\n",
      "[21900]\teval-rmse:3.83154\ttrain-rmse:1.96267\n",
      "[21901]\teval-rmse:3.82989\ttrain-rmse:1.96264\n",
      "[21902]\teval-rmse:3.83125\ttrain-rmse:1.96266\n",
      "[21903]\teval-rmse:3.83232\ttrain-rmse:1.96269\n",
      "[21904]\teval-rmse:3.83289\ttrain-rmse:1.9627\n",
      "[21905]\teval-rmse:3.83389\ttrain-rmse:1.96273\n",
      "[21906]\teval-rmse:3.8343\ttrain-rmse:1.96275\n",
      "[21907]\teval-rmse:3.83232\ttrain-rmse:1.9627\n",
      "[21908]\teval-rmse:3.83195\ttrain-rmse:1.9626\n",
      "[21909]\teval-rmse:3.83029\ttrain-rmse:1.96255\n",
      "[21910]\teval-rmse:3.83086\ttrain-rmse:1.96256\n",
      "[21911]\teval-rmse:3.82908\ttrain-rmse:1.96252\n",
      "[21912]\teval-rmse:3.82767\ttrain-rmse:1.9625\n",
      "[21913]\teval-rmse:3.82714\ttrain-rmse:1.9625\n",
      "[21914]\teval-rmse:3.82661\ttrain-rmse:1.96249\n",
      "[21915]\teval-rmse:3.82609\ttrain-rmse:1.9625\n",
      "[21916]\teval-rmse:3.82631\ttrain-rmse:1.9625\n",
      "[21917]\teval-rmse:3.82748\ttrain-rmse:1.96251\n",
      "[21918]\teval-rmse:3.82613\ttrain-rmse:1.96249\n",
      "[21919]\teval-rmse:3.82566\ttrain-rmse:1.9625\n",
      "[21920]\teval-rmse:3.82459\ttrain-rmse:1.9625\n",
      "[21921]\teval-rmse:3.82625\ttrain-rmse:1.96247\n",
      "[21922]\teval-rmse:3.82619\ttrain-rmse:1.96247\n",
      "[21923]\teval-rmse:3.82649\ttrain-rmse:1.96247\n",
      "[21924]\teval-rmse:3.82491\ttrain-rmse:1.96245\n",
      "[21925]\teval-rmse:3.82336\ttrain-rmse:1.96245\n",
      "[21926]\teval-rmse:3.82204\ttrain-rmse:1.96248\n",
      "[21927]\teval-rmse:3.82099\ttrain-rmse:1.96249\n",
      "[21928]\teval-rmse:3.81914\ttrain-rmse:1.9625\n",
      "[21929]\teval-rmse:3.81887\ttrain-rmse:1.9625\n",
      "[21930]\teval-rmse:3.81845\ttrain-rmse:1.96251\n",
      "[21931]\teval-rmse:3.81726\ttrain-rmse:1.96253\n",
      "[21932]\teval-rmse:3.81608\ttrain-rmse:1.96257\n",
      "[21933]\teval-rmse:3.81555\ttrain-rmse:1.96258\n",
      "[21934]\teval-rmse:3.81583\ttrain-rmse:1.96258\n",
      "[21935]\teval-rmse:3.81728\ttrain-rmse:1.96255\n",
      "[21936]\teval-rmse:3.81786\ttrain-rmse:1.96254\n",
      "[21937]\teval-rmse:3.81809\ttrain-rmse:1.96253\n",
      "[21938]\teval-rmse:3.81964\ttrain-rmse:1.96251\n",
      "[21939]\teval-rmse:3.82031\ttrain-rmse:1.96251\n",
      "[21940]\teval-rmse:3.82169\ttrain-rmse:1.9625\n",
      "[21941]\teval-rmse:3.8221\ttrain-rmse:1.9625\n",
      "[21942]\teval-rmse:3.82255\ttrain-rmse:1.9625\n",
      "[21943]\teval-rmse:3.82204\ttrain-rmse:1.9625\n",
      "[21944]\teval-rmse:3.82148\ttrain-rmse:1.9625\n",
      "[21945]\teval-rmse:3.82149\ttrain-rmse:1.9625\n",
      "[21946]\teval-rmse:3.81946\ttrain-rmse:1.96253\n",
      "[21947]\teval-rmse:3.81946\ttrain-rmse:1.96253\n",
      "[21948]\teval-rmse:3.81897\ttrain-rmse:1.96254\n",
      "[21949]\teval-rmse:3.82034\ttrain-rmse:1.96253\n",
      "[21950]\teval-rmse:3.82177\ttrain-rmse:1.9625\n",
      "[21951]\teval-rmse:3.82056\ttrain-rmse:1.96253\n",
      "[21952]\teval-rmse:3.81985\ttrain-rmse:1.96254\n",
      "[21953]\teval-rmse:3.82128\ttrain-rmse:1.96253\n",
      "[21954]\teval-rmse:3.821\ttrain-rmse:1.96253\n",
      "[21955]\teval-rmse:3.81928\ttrain-rmse:1.96254\n",
      "[21956]\teval-rmse:3.8184\ttrain-rmse:1.96256\n",
      "[21957]\teval-rmse:3.82009\ttrain-rmse:1.96253\n",
      "[21958]\teval-rmse:3.82175\ttrain-rmse:1.96248\n",
      "[21959]\teval-rmse:3.82047\ttrain-rmse:1.96249\n",
      "[21960]\teval-rmse:3.81927\ttrain-rmse:1.9625\n",
      "[21961]\teval-rmse:3.81947\ttrain-rmse:1.9625\n",
      "[21962]\teval-rmse:3.81968\ttrain-rmse:1.9625\n",
      "[21963]\teval-rmse:3.81864\ttrain-rmse:1.96251\n",
      "[21964]\teval-rmse:3.82039\ttrain-rmse:1.96246\n",
      "[21965]\teval-rmse:3.82062\ttrain-rmse:1.96246\n",
      "[21966]\teval-rmse:3.81935\ttrain-rmse:1.96248\n",
      "[21967]\teval-rmse:3.81935\ttrain-rmse:1.96248\n",
      "[21968]\teval-rmse:3.82104\ttrain-rmse:1.96245\n",
      "[21969]\teval-rmse:3.82245\ttrain-rmse:1.96245\n",
      "[21970]\teval-rmse:3.82118\ttrain-rmse:1.96245\n",
      "[21971]\teval-rmse:3.82206\ttrain-rmse:1.96243\n",
      "[21972]\teval-rmse:3.82153\ttrain-rmse:1.96243\n",
      "[21973]\teval-rmse:3.82285\ttrain-rmse:1.96243\n",
      "[21974]\teval-rmse:3.82317\ttrain-rmse:1.96243\n",
      "[21975]\teval-rmse:3.82406\ttrain-rmse:1.96241\n",
      "[21976]\teval-rmse:3.82565\ttrain-rmse:1.9624\n",
      "[21977]\teval-rmse:3.82741\ttrain-rmse:1.96238\n",
      "[21978]\teval-rmse:3.82658\ttrain-rmse:1.96238\n",
      "[21979]\teval-rmse:3.82823\ttrain-rmse:1.96238\n",
      "[21980]\teval-rmse:3.82754\ttrain-rmse:1.96238\n",
      "[21981]\teval-rmse:3.82684\ttrain-rmse:1.96237\n",
      "[21982]\teval-rmse:3.82853\ttrain-rmse:1.96239\n",
      "[21983]\teval-rmse:3.82817\ttrain-rmse:1.96229\n",
      "[21984]\teval-rmse:3.82644\ttrain-rmse:1.96227\n",
      "[21985]\teval-rmse:3.82592\ttrain-rmse:1.96227\n",
      "[21986]\teval-rmse:3.82571\ttrain-rmse:1.96227\n",
      "[21987]\teval-rmse:3.82537\ttrain-rmse:1.96227\n",
      "[21988]\teval-rmse:3.82554\ttrain-rmse:1.96227\n",
      "[21989]\teval-rmse:3.8262\ttrain-rmse:1.96227\n",
      "[21990]\teval-rmse:3.82622\ttrain-rmse:1.96227\n",
      "[21991]\teval-rmse:3.82427\ttrain-rmse:1.96227\n",
      "[21992]\teval-rmse:3.82565\ttrain-rmse:1.96226\n",
      "[21993]\teval-rmse:3.8262\ttrain-rmse:1.96226\n",
      "[21994]\teval-rmse:3.82685\ttrain-rmse:1.96227\n",
      "[21995]\teval-rmse:3.82633\ttrain-rmse:1.96226\n",
      "[21996]\teval-rmse:3.82573\ttrain-rmse:1.96227\n",
      "[21997]\teval-rmse:3.82727\ttrain-rmse:1.96229\n",
      "[21998]\teval-rmse:3.8268\ttrain-rmse:1.96229\n",
      "[21999]\teval-rmse:3.82674\ttrain-rmse:1.96229\n",
      "[22000]\teval-rmse:3.82541\ttrain-rmse:1.96228\n",
      "[22001]\teval-rmse:3.82675\ttrain-rmse:1.96229\n",
      "[22002]\teval-rmse:3.82654\ttrain-rmse:1.96229\n",
      "[22003]\teval-rmse:3.82509\ttrain-rmse:1.96228\n",
      "[22004]\teval-rmse:3.8249\ttrain-rmse:1.96228\n",
      "[22005]\teval-rmse:3.82644\ttrain-rmse:1.96229\n",
      "[22006]\teval-rmse:3.82773\ttrain-rmse:1.9623\n",
      "[22007]\teval-rmse:3.8284\ttrain-rmse:1.96231\n",
      "[22008]\teval-rmse:3.83008\ttrain-rmse:1.96234\n",
      "[22009]\teval-rmse:3.83034\ttrain-rmse:1.96234\n",
      "[22010]\teval-rmse:3.82923\ttrain-rmse:1.96233\n",
      "[22011]\teval-rmse:3.83075\ttrain-rmse:1.96235\n",
      "[22012]\teval-rmse:3.82885\ttrain-rmse:1.96231\n",
      "[22013]\teval-rmse:3.82939\ttrain-rmse:1.96232\n",
      "[22014]\teval-rmse:3.82903\ttrain-rmse:1.96232\n",
      "[22015]\teval-rmse:3.82866\ttrain-rmse:1.96231\n",
      "[22016]\teval-rmse:3.8274\ttrain-rmse:1.96232\n",
      "[22017]\teval-rmse:3.82855\ttrain-rmse:1.96232\n",
      "[22018]\teval-rmse:3.82942\ttrain-rmse:1.96233\n",
      "[22019]\teval-rmse:3.82736\ttrain-rmse:1.96232\n",
      "[22020]\teval-rmse:3.82926\ttrain-rmse:1.96234\n",
      "[22021]\teval-rmse:3.83095\ttrain-rmse:1.96237\n",
      "[22022]\teval-rmse:3.82958\ttrain-rmse:1.96236\n",
      "[22023]\teval-rmse:3.83148\ttrain-rmse:1.96238\n",
      "[22024]\teval-rmse:3.83013\ttrain-rmse:1.96235\n",
      "[22025]\teval-rmse:3.82873\ttrain-rmse:1.96234\n",
      "[22026]\teval-rmse:3.82908\ttrain-rmse:1.96235\n",
      "[22027]\teval-rmse:3.83073\ttrain-rmse:1.96236\n",
      "[22028]\teval-rmse:3.83187\ttrain-rmse:1.96238\n",
      "[22029]\teval-rmse:3.83131\ttrain-rmse:1.96237\n",
      "[22030]\teval-rmse:3.8313\ttrain-rmse:1.96237\n",
      "[22031]\teval-rmse:3.83095\ttrain-rmse:1.96226\n",
      "[22032]\teval-rmse:3.83232\ttrain-rmse:1.9623\n",
      "[22033]\teval-rmse:3.83194\ttrain-rmse:1.96229\n",
      "[22034]\teval-rmse:3.83032\ttrain-rmse:1.96226\n",
      "[22035]\teval-rmse:3.82996\ttrain-rmse:1.96225\n",
      "[22036]\teval-rmse:3.83014\ttrain-rmse:1.96225\n",
      "[22037]\teval-rmse:3.82904\ttrain-rmse:1.96224\n",
      "[22038]\teval-rmse:3.82771\ttrain-rmse:1.96223\n",
      "[22039]\teval-rmse:3.82825\ttrain-rmse:1.96223\n",
      "[22040]\teval-rmse:3.82789\ttrain-rmse:1.96223\n",
      "[22041]\teval-rmse:3.82791\ttrain-rmse:1.96223\n",
      "[22042]\teval-rmse:3.82932\ttrain-rmse:1.96225\n",
      "[22043]\teval-rmse:3.82996\ttrain-rmse:1.96226\n",
      "[22044]\teval-rmse:3.82886\ttrain-rmse:1.96225\n",
      "[22045]\teval-rmse:3.8268\ttrain-rmse:1.96223\n",
      "[22046]\teval-rmse:3.82816\ttrain-rmse:1.96225\n",
      "[22047]\teval-rmse:3.82706\ttrain-rmse:1.96225\n",
      "[22048]\teval-rmse:3.82638\ttrain-rmse:1.96223\n",
      "[22049]\teval-rmse:3.82803\ttrain-rmse:1.96226\n",
      "[22050]\teval-rmse:3.82755\ttrain-rmse:1.96226\n",
      "[22051]\teval-rmse:3.82889\ttrain-rmse:1.96228\n",
      "[22052]\teval-rmse:3.82833\ttrain-rmse:1.96228\n",
      "[22053]\teval-rmse:3.82768\ttrain-rmse:1.96227\n",
      "[22054]\teval-rmse:3.826\ttrain-rmse:1.96224\n",
      "[22055]\teval-rmse:3.82601\ttrain-rmse:1.96224\n",
      "[22056]\teval-rmse:3.82514\ttrain-rmse:1.96224\n",
      "[22057]\teval-rmse:3.82352\ttrain-rmse:1.96223\n",
      "[22058]\teval-rmse:3.8241\ttrain-rmse:1.96223\n",
      "[22059]\teval-rmse:3.82524\ttrain-rmse:1.96223\n",
      "[22060]\teval-rmse:3.82354\ttrain-rmse:1.96222\n",
      "[22061]\teval-rmse:3.82216\ttrain-rmse:1.96221\n",
      "[22062]\teval-rmse:3.82078\ttrain-rmse:1.96222\n",
      "[22063]\teval-rmse:3.8208\ttrain-rmse:1.96222\n",
      "[22064]\teval-rmse:3.82099\ttrain-rmse:1.96222\n",
      "[22065]\teval-rmse:3.82254\ttrain-rmse:1.9622\n",
      "[22066]\teval-rmse:3.8222\ttrain-rmse:1.96211\n",
      "[22067]\teval-rmse:3.82411\ttrain-rmse:1.9621\n",
      "[22068]\teval-rmse:3.82279\ttrain-rmse:1.96211\n",
      "[22069]\teval-rmse:3.8233\ttrain-rmse:1.96211\n",
      "[22070]\teval-rmse:3.82142\ttrain-rmse:1.96212\n",
      "[22071]\teval-rmse:3.81975\ttrain-rmse:1.96213\n",
      "[22072]\teval-rmse:3.82098\ttrain-rmse:1.96212\n",
      "[22073]\teval-rmse:3.81925\ttrain-rmse:1.96213\n",
      "[22074]\teval-rmse:3.81796\ttrain-rmse:1.96217\n",
      "[22075]\teval-rmse:3.81647\ttrain-rmse:1.9622\n",
      "[22076]\teval-rmse:3.81807\ttrain-rmse:1.96216\n",
      "[22077]\teval-rmse:3.81704\ttrain-rmse:1.96218\n",
      "[22078]\teval-rmse:3.81554\ttrain-rmse:1.9622\n",
      "[22079]\teval-rmse:3.81588\ttrain-rmse:1.96219\n",
      "[22080]\teval-rmse:3.81698\ttrain-rmse:1.96217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22081]\teval-rmse:3.81889\ttrain-rmse:1.96215\n",
      "[22082]\teval-rmse:3.8176\ttrain-rmse:1.96217\n",
      "[22083]\teval-rmse:3.81814\ttrain-rmse:1.96216\n",
      "[22084]\teval-rmse:3.82005\ttrain-rmse:1.96214\n",
      "[22085]\teval-rmse:3.81987\ttrain-rmse:1.96214\n",
      "[22086]\teval-rmse:3.8196\ttrain-rmse:1.96214\n",
      "[22087]\teval-rmse:3.82099\ttrain-rmse:1.96212\n",
      "[22088]\teval-rmse:3.81958\ttrain-rmse:1.96215\n",
      "[22089]\teval-rmse:3.8193\ttrain-rmse:1.96215\n",
      "[22090]\teval-rmse:3.81988\ttrain-rmse:1.96214\n",
      "[22091]\teval-rmse:3.81988\ttrain-rmse:1.96214\n",
      "[22092]\teval-rmse:3.81934\ttrain-rmse:1.96215\n",
      "[22093]\teval-rmse:3.82093\ttrain-rmse:1.96213\n",
      "[22094]\teval-rmse:3.81962\ttrain-rmse:1.96216\n",
      "[22095]\teval-rmse:3.82\ttrain-rmse:1.96215\n",
      "[22096]\teval-rmse:3.81968\ttrain-rmse:1.96216\n",
      "[22097]\teval-rmse:3.81835\ttrain-rmse:1.96218\n",
      "[22098]\teval-rmse:3.81781\ttrain-rmse:1.96219\n",
      "[22099]\teval-rmse:3.81765\ttrain-rmse:1.96219\n",
      "[22100]\teval-rmse:3.81941\ttrain-rmse:1.96214\n",
      "[22101]\teval-rmse:3.81911\ttrain-rmse:1.96205\n",
      "[22102]\teval-rmse:3.81946\ttrain-rmse:1.96204\n",
      "[22103]\teval-rmse:3.81739\ttrain-rmse:1.96209\n",
      "[22104]\teval-rmse:3.81551\ttrain-rmse:1.96215\n",
      "[22105]\teval-rmse:3.81708\ttrain-rmse:1.96208\n",
      "[22106]\teval-rmse:3.81867\ttrain-rmse:1.96205\n",
      "[22107]\teval-rmse:3.81836\ttrain-rmse:1.96195\n",
      "[22108]\teval-rmse:3.8171\ttrain-rmse:1.96197\n",
      "[22109]\teval-rmse:3.81572\ttrain-rmse:1.962\n",
      "[22110]\teval-rmse:3.81571\ttrain-rmse:1.962\n",
      "[22111]\teval-rmse:3.81762\ttrain-rmse:1.96197\n",
      "[22112]\teval-rmse:3.81603\ttrain-rmse:1.96202\n",
      "[22113]\teval-rmse:3.81776\ttrain-rmse:1.96197\n",
      "[22114]\teval-rmse:3.81713\ttrain-rmse:1.96198\n",
      "[22115]\teval-rmse:3.81758\ttrain-rmse:1.96197\n",
      "[22116]\teval-rmse:3.81899\ttrain-rmse:1.96194\n",
      "[22117]\teval-rmse:3.81871\ttrain-rmse:1.96195\n",
      "[22118]\teval-rmse:3.81685\ttrain-rmse:1.962\n",
      "[22119]\teval-rmse:3.81725\ttrain-rmse:1.96198\n",
      "[22120]\teval-rmse:3.81894\ttrain-rmse:1.96195\n",
      "[22121]\teval-rmse:3.8174\ttrain-rmse:1.96198\n",
      "[22122]\teval-rmse:3.81709\ttrain-rmse:1.96198\n",
      "[22123]\teval-rmse:3.81683\ttrain-rmse:1.96198\n",
      "[22124]\teval-rmse:3.81552\ttrain-rmse:1.96203\n",
      "[22125]\teval-rmse:3.81496\ttrain-rmse:1.96205\n",
      "[22126]\teval-rmse:3.81333\ttrain-rmse:1.96212\n",
      "[22127]\teval-rmse:3.81318\ttrain-rmse:1.96212\n",
      "[22128]\teval-rmse:3.81171\ttrain-rmse:1.96217\n",
      "[22129]\teval-rmse:3.81216\ttrain-rmse:1.96215\n",
      "[22130]\teval-rmse:3.81392\ttrain-rmse:1.96209\n",
      "[22131]\teval-rmse:3.81432\ttrain-rmse:1.96207\n",
      "[22132]\teval-rmse:3.81562\ttrain-rmse:1.96203\n",
      "[22133]\teval-rmse:3.81667\ttrain-rmse:1.962\n",
      "[22134]\teval-rmse:3.81773\ttrain-rmse:1.96196\n",
      "[22135]\teval-rmse:3.81935\ttrain-rmse:1.96194\n",
      "[22136]\teval-rmse:3.81939\ttrain-rmse:1.96194\n",
      "[22137]\teval-rmse:3.81891\ttrain-rmse:1.96195\n",
      "[22138]\teval-rmse:3.81948\ttrain-rmse:1.96193\n",
      "[22139]\teval-rmse:3.81951\ttrain-rmse:1.96193\n",
      "[22140]\teval-rmse:3.82121\ttrain-rmse:1.96192\n",
      "[22141]\teval-rmse:3.81985\ttrain-rmse:1.96194\n",
      "[22142]\teval-rmse:3.81855\ttrain-rmse:1.96198\n",
      "[22143]\teval-rmse:3.81824\ttrain-rmse:1.96188\n",
      "[22144]\teval-rmse:3.81885\ttrain-rmse:1.96187\n",
      "[22145]\teval-rmse:3.81757\ttrain-rmse:1.9619\n",
      "[22146]\teval-rmse:3.81556\ttrain-rmse:1.96198\n",
      "[22147]\teval-rmse:3.81438\ttrain-rmse:1.96202\n",
      "[22148]\teval-rmse:3.81553\ttrain-rmse:1.96198\n",
      "[22149]\teval-rmse:3.81576\ttrain-rmse:1.96197\n",
      "[22150]\teval-rmse:3.81661\ttrain-rmse:1.96195\n",
      "[22151]\teval-rmse:3.81784\ttrain-rmse:1.96193\n",
      "[22152]\teval-rmse:3.81656\ttrain-rmse:1.96195\n",
      "[22153]\teval-rmse:3.81625\ttrain-rmse:1.96196\n",
      "[22154]\teval-rmse:3.81768\ttrain-rmse:1.96193\n",
      "[22155]\teval-rmse:3.81649\ttrain-rmse:1.96195\n",
      "[22156]\teval-rmse:3.81494\ttrain-rmse:1.96198\n",
      "[22157]\teval-rmse:3.81449\ttrain-rmse:1.96199\n",
      "[22158]\teval-rmse:3.81286\ttrain-rmse:1.96206\n",
      "[22159]\teval-rmse:3.81348\ttrain-rmse:1.96205\n",
      "[22160]\teval-rmse:3.81402\ttrain-rmse:1.96203\n",
      "[22161]\teval-rmse:3.81209\ttrain-rmse:1.96212\n",
      "[22162]\teval-rmse:3.81215\ttrain-rmse:1.96212\n",
      "[22163]\teval-rmse:3.81269\ttrain-rmse:1.9621\n",
      "[22164]\teval-rmse:3.8124\ttrain-rmse:1.96211\n",
      "[22165]\teval-rmse:3.81335\ttrain-rmse:1.96207\n",
      "[22166]\teval-rmse:3.8132\ttrain-rmse:1.96207\n",
      "[22167]\teval-rmse:3.81157\ttrain-rmse:1.96213\n",
      "[22168]\teval-rmse:3.81333\ttrain-rmse:1.96208\n",
      "[22169]\teval-rmse:3.81318\ttrain-rmse:1.96208\n",
      "[22170]\teval-rmse:3.81337\ttrain-rmse:1.96207\n",
      "[22171]\teval-rmse:3.81235\ttrain-rmse:1.96209\n",
      "[22172]\teval-rmse:3.81404\ttrain-rmse:1.96205\n",
      "[22173]\teval-rmse:3.81465\ttrain-rmse:1.96203\n",
      "[22174]\teval-rmse:3.81311\ttrain-rmse:1.96208\n",
      "[22175]\teval-rmse:3.81401\ttrain-rmse:1.96205\n",
      "[22176]\teval-rmse:3.81457\ttrain-rmse:1.96203\n",
      "[22177]\teval-rmse:3.81625\ttrain-rmse:1.96199\n",
      "[22178]\teval-rmse:3.81686\ttrain-rmse:1.96197\n",
      "[22179]\teval-rmse:3.8183\ttrain-rmse:1.96196\n",
      "[22180]\teval-rmse:3.82021\ttrain-rmse:1.96194\n",
      "[22181]\teval-rmse:3.82072\ttrain-rmse:1.96193\n",
      "[22182]\teval-rmse:3.81915\ttrain-rmse:1.96196\n",
      "[22183]\teval-rmse:3.81949\ttrain-rmse:1.96196\n",
      "[22184]\teval-rmse:3.82076\ttrain-rmse:1.96193\n",
      "[22185]\teval-rmse:3.82148\ttrain-rmse:1.96192\n",
      "[22186]\teval-rmse:3.82237\ttrain-rmse:1.96192\n",
      "[22187]\teval-rmse:3.82411\ttrain-rmse:1.96192\n",
      "[22188]\teval-rmse:3.82323\ttrain-rmse:1.96191\n",
      "[22189]\teval-rmse:3.82187\ttrain-rmse:1.96191\n",
      "[22190]\teval-rmse:3.82253\ttrain-rmse:1.9619\n",
      "[22191]\teval-rmse:3.82079\ttrain-rmse:1.9619\n",
      "[22192]\teval-rmse:3.82053\ttrain-rmse:1.96191\n",
      "[22193]\teval-rmse:3.82214\ttrain-rmse:1.9619\n",
      "[22194]\teval-rmse:3.8233\ttrain-rmse:1.96188\n",
      "[22195]\teval-rmse:3.82521\ttrain-rmse:1.96188\n",
      "[22196]\teval-rmse:3.82667\ttrain-rmse:1.96189\n",
      "[22197]\teval-rmse:3.82752\ttrain-rmse:1.96189\n",
      "[22198]\teval-rmse:3.82599\ttrain-rmse:1.96189\n",
      "[22199]\teval-rmse:3.82533\ttrain-rmse:1.96188\n",
      "[22200]\teval-rmse:3.82533\ttrain-rmse:1.96188\n",
      "[22201]\teval-rmse:3.82502\ttrain-rmse:1.96188\n",
      "[22202]\teval-rmse:3.82551\ttrain-rmse:1.96188\n",
      "[22203]\teval-rmse:3.82741\ttrain-rmse:1.96189\n",
      "[22204]\teval-rmse:3.82712\ttrain-rmse:1.96189\n",
      "[22205]\teval-rmse:3.82877\ttrain-rmse:1.9619\n",
      "[22206]\teval-rmse:3.82807\ttrain-rmse:1.9619\n",
      "[22207]\teval-rmse:3.82635\ttrain-rmse:1.96188\n",
      "[22208]\teval-rmse:3.82582\ttrain-rmse:1.96188\n",
      "[22209]\teval-rmse:3.82752\ttrain-rmse:1.96186\n",
      "[22210]\teval-rmse:3.82888\ttrain-rmse:1.96187\n",
      "[22211]\teval-rmse:3.82829\ttrain-rmse:1.96186\n",
      "[22212]\teval-rmse:3.82968\ttrain-rmse:1.96188\n",
      "[22213]\teval-rmse:3.82882\ttrain-rmse:1.96188\n",
      "[22214]\teval-rmse:3.82738\ttrain-rmse:1.96187\n",
      "[22215]\teval-rmse:3.82787\ttrain-rmse:1.96187\n",
      "[22216]\teval-rmse:3.82788\ttrain-rmse:1.96187\n",
      "[22217]\teval-rmse:3.82644\ttrain-rmse:1.96185\n",
      "[22218]\teval-rmse:3.8261\ttrain-rmse:1.96185\n",
      "[22219]\teval-rmse:3.82521\ttrain-rmse:1.96185\n",
      "[22220]\teval-rmse:3.82679\ttrain-rmse:1.96185\n",
      "[22221]\teval-rmse:3.82628\ttrain-rmse:1.96184\n",
      "[22222]\teval-rmse:3.8267\ttrain-rmse:1.96184\n",
      "[22223]\teval-rmse:3.82788\ttrain-rmse:1.96184\n",
      "[22224]\teval-rmse:3.82752\ttrain-rmse:1.96184\n",
      "[22225]\teval-rmse:3.82694\ttrain-rmse:1.96183\n",
      "[22226]\teval-rmse:3.82859\ttrain-rmse:1.96185\n",
      "[22227]\teval-rmse:3.83028\ttrain-rmse:1.96188\n",
      "[22228]\teval-rmse:3.83091\ttrain-rmse:1.96189\n",
      "[22229]\teval-rmse:3.83005\ttrain-rmse:1.96188\n",
      "[22230]\teval-rmse:3.8303\ttrain-rmse:1.96188\n",
      "[22231]\teval-rmse:3.82819\ttrain-rmse:1.96188\n",
      "[22232]\teval-rmse:3.82747\ttrain-rmse:1.96188\n",
      "[22233]\teval-rmse:3.82766\ttrain-rmse:1.96188\n",
      "[22234]\teval-rmse:3.82627\ttrain-rmse:1.96189\n",
      "[22235]\teval-rmse:3.82576\ttrain-rmse:1.9619\n",
      "[22236]\teval-rmse:3.82432\ttrain-rmse:1.96189\n",
      "[22237]\teval-rmse:3.82263\ttrain-rmse:1.9619\n",
      "[22238]\teval-rmse:3.82409\ttrain-rmse:1.96189\n",
      "[22239]\teval-rmse:3.82277\ttrain-rmse:1.96191\n",
      "[22240]\teval-rmse:3.82145\ttrain-rmse:1.96191\n",
      "[22241]\teval-rmse:3.82011\ttrain-rmse:1.96193\n",
      "[22242]\teval-rmse:3.81981\ttrain-rmse:1.96184\n",
      "[22243]\teval-rmse:3.81949\ttrain-rmse:1.96184\n",
      "[22244]\teval-rmse:3.81823\ttrain-rmse:1.96185\n",
      "[22245]\teval-rmse:3.8169\ttrain-rmse:1.96188\n",
      "[22246]\teval-rmse:3.81689\ttrain-rmse:1.96188\n",
      "[22247]\teval-rmse:3.81812\ttrain-rmse:1.96186\n",
      "[22248]\teval-rmse:3.81871\ttrain-rmse:1.96185\n",
      "[22249]\teval-rmse:3.81902\ttrain-rmse:1.96185\n",
      "[22250]\teval-rmse:3.81991\ttrain-rmse:1.96182\n",
      "[22251]\teval-rmse:3.81959\ttrain-rmse:1.96173\n",
      "[22252]\teval-rmse:3.8199\ttrain-rmse:1.96172\n",
      "[22253]\teval-rmse:3.81972\ttrain-rmse:1.96172\n",
      "[22254]\teval-rmse:3.82117\ttrain-rmse:1.96171\n",
      "[22255]\teval-rmse:3.81979\ttrain-rmse:1.96172\n",
      "[22256]\teval-rmse:3.81961\ttrain-rmse:1.96172\n",
      "[22257]\teval-rmse:3.81988\ttrain-rmse:1.96172\n",
      "[22258]\teval-rmse:3.82077\ttrain-rmse:1.9617\n",
      "[22259]\teval-rmse:3.82025\ttrain-rmse:1.96171\n",
      "[22260]\teval-rmse:3.81973\ttrain-rmse:1.96171\n",
      "[22261]\teval-rmse:3.82149\ttrain-rmse:1.9617\n",
      "[22262]\teval-rmse:3.82148\ttrain-rmse:1.9617\n",
      "[22263]\teval-rmse:3.8202\ttrain-rmse:1.96171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22264]\teval-rmse:3.81915\ttrain-rmse:1.96172\n",
      "[22265]\teval-rmse:3.81887\ttrain-rmse:1.96172\n",
      "[22266]\teval-rmse:3.8187\ttrain-rmse:1.96172\n",
      "[22267]\teval-rmse:3.81701\ttrain-rmse:1.96175\n",
      "[22268]\teval-rmse:3.81598\ttrain-rmse:1.96176\n",
      "[22269]\teval-rmse:3.81496\ttrain-rmse:1.96178\n",
      "[22270]\teval-rmse:3.81343\ttrain-rmse:1.96182\n",
      "[22271]\teval-rmse:3.81227\ttrain-rmse:1.96185\n",
      "[22272]\teval-rmse:3.81054\ttrain-rmse:1.96192\n",
      "[22273]\teval-rmse:3.80922\ttrain-rmse:1.96197\n",
      "[22274]\teval-rmse:3.80804\ttrain-rmse:1.96203\n",
      "[22275]\teval-rmse:3.80782\ttrain-rmse:1.96203\n",
      "[22276]\teval-rmse:3.80944\ttrain-rmse:1.96196\n",
      "[22277]\teval-rmse:3.80846\ttrain-rmse:1.96198\n",
      "[22278]\teval-rmse:3.80818\ttrain-rmse:1.96199\n",
      "[22279]\teval-rmse:3.80979\ttrain-rmse:1.96194\n",
      "[22280]\teval-rmse:3.80855\ttrain-rmse:1.96199\n",
      "[22281]\teval-rmse:3.80922\ttrain-rmse:1.96196\n",
      "[22282]\teval-rmse:3.80908\ttrain-rmse:1.96196\n",
      "[22283]\teval-rmse:3.80881\ttrain-rmse:1.96197\n",
      "[22284]\teval-rmse:3.81011\ttrain-rmse:1.96193\n",
      "[22285]\teval-rmse:3.80971\ttrain-rmse:1.96194\n",
      "[22286]\teval-rmse:3.80972\ttrain-rmse:1.96194\n",
      "[22287]\teval-rmse:3.80821\ttrain-rmse:1.96201\n",
      "[22288]\teval-rmse:3.80821\ttrain-rmse:1.96201\n",
      "[22289]\teval-rmse:3.80977\ttrain-rmse:1.96195\n",
      "[22290]\teval-rmse:3.80932\ttrain-rmse:1.96197\n",
      "[22291]\teval-rmse:3.81076\ttrain-rmse:1.96193\n",
      "[22292]\teval-rmse:3.81047\ttrain-rmse:1.96194\n",
      "[22293]\teval-rmse:3.8102\ttrain-rmse:1.96185\n",
      "[22294]\teval-rmse:3.81157\ttrain-rmse:1.9618\n",
      "[22295]\teval-rmse:3.81006\ttrain-rmse:1.96184\n",
      "[22296]\teval-rmse:3.80929\ttrain-rmse:1.96187\n",
      "[22297]\teval-rmse:3.80885\ttrain-rmse:1.96189\n",
      "[22298]\teval-rmse:3.81053\ttrain-rmse:1.96183\n",
      "[22299]\teval-rmse:3.80925\ttrain-rmse:1.96188\n",
      "[22300]\teval-rmse:3.80802\ttrain-rmse:1.96192\n",
      "[22301]\teval-rmse:3.80837\ttrain-rmse:1.96191\n",
      "[22302]\teval-rmse:3.80976\ttrain-rmse:1.96185\n",
      "[22303]\teval-rmse:3.80898\ttrain-rmse:1.96188\n",
      "[22304]\teval-rmse:3.80838\ttrain-rmse:1.9619\n",
      "[22305]\teval-rmse:3.80894\ttrain-rmse:1.96188\n",
      "[22306]\teval-rmse:3.80894\ttrain-rmse:1.96188\n",
      "[22307]\teval-rmse:3.80939\ttrain-rmse:1.96186\n",
      "[22308]\teval-rmse:3.8103\ttrain-rmse:1.96182\n",
      "[22309]\teval-rmse:3.81084\ttrain-rmse:1.9618\n",
      "[22310]\teval-rmse:3.81126\ttrain-rmse:1.96178\n",
      "[22311]\teval-rmse:3.81178\ttrain-rmse:1.96177\n",
      "[22312]\teval-rmse:3.81346\ttrain-rmse:1.96172\n",
      "[22313]\teval-rmse:3.81482\ttrain-rmse:1.9617\n",
      "[22314]\teval-rmse:3.81647\ttrain-rmse:1.96166\n",
      "[22315]\teval-rmse:3.8169\ttrain-rmse:1.96166\n",
      "[22316]\teval-rmse:3.81729\ttrain-rmse:1.96165\n",
      "[22317]\teval-rmse:3.81602\ttrain-rmse:1.96167\n",
      "[22318]\teval-rmse:3.81483\ttrain-rmse:1.96169\n",
      "[22319]\teval-rmse:3.81322\ttrain-rmse:1.96175\n",
      "[22320]\teval-rmse:3.81139\ttrain-rmse:1.96181\n",
      "[22321]\teval-rmse:3.81229\ttrain-rmse:1.96178\n",
      "[22322]\teval-rmse:3.81182\ttrain-rmse:1.96179\n",
      "[22323]\teval-rmse:3.81047\ttrain-rmse:1.96183\n",
      "[22324]\teval-rmse:3.80948\ttrain-rmse:1.96186\n",
      "[22325]\teval-rmse:3.81013\ttrain-rmse:1.96183\n",
      "[22326]\teval-rmse:3.81205\ttrain-rmse:1.96178\n",
      "[22327]\teval-rmse:3.81292\ttrain-rmse:1.96175\n",
      "[22328]\teval-rmse:3.81129\ttrain-rmse:1.96182\n",
      "[22329]\teval-rmse:3.81004\ttrain-rmse:1.96185\n",
      "[22330]\teval-rmse:3.80989\ttrain-rmse:1.96186\n",
      "[22331]\teval-rmse:3.80907\ttrain-rmse:1.96188\n",
      "[22332]\teval-rmse:3.81075\ttrain-rmse:1.96183\n",
      "[22333]\teval-rmse:3.80912\ttrain-rmse:1.96191\n",
      "[22334]\teval-rmse:3.80814\ttrain-rmse:1.96193\n",
      "[22335]\teval-rmse:3.80764\ttrain-rmse:1.96196\n",
      "[22336]\teval-rmse:3.80705\ttrain-rmse:1.96199\n",
      "[22337]\teval-rmse:3.80725\ttrain-rmse:1.96197\n",
      "[22338]\teval-rmse:3.80601\ttrain-rmse:1.96204\n",
      "[22339]\teval-rmse:3.80576\ttrain-rmse:1.96205\n",
      "[22340]\teval-rmse:3.8042\ttrain-rmse:1.96212\n",
      "[22341]\teval-rmse:3.80299\ttrain-rmse:1.9622\n",
      "[22342]\teval-rmse:3.80341\ttrain-rmse:1.96217\n",
      "[22343]\teval-rmse:3.80317\ttrain-rmse:1.96218\n",
      "[22344]\teval-rmse:3.80292\ttrain-rmse:1.96209\n",
      "[22345]\teval-rmse:3.80212\ttrain-rmse:1.96214\n",
      "[22346]\teval-rmse:3.80255\ttrain-rmse:1.9621\n",
      "[22347]\teval-rmse:3.80411\ttrain-rmse:1.96202\n",
      "[22348]\teval-rmse:3.80554\ttrain-rmse:1.96193\n",
      "[22349]\teval-rmse:3.80638\ttrain-rmse:1.9619\n",
      "[22350]\teval-rmse:3.80814\ttrain-rmse:1.96182\n",
      "[22351]\teval-rmse:3.80793\ttrain-rmse:1.96183\n",
      "[22352]\teval-rmse:3.80771\ttrain-rmse:1.96184\n",
      "[22353]\teval-rmse:3.8081\ttrain-rmse:1.96182\n",
      "[22354]\teval-rmse:3.81002\ttrain-rmse:1.96176\n",
      "[22355]\teval-rmse:3.81069\ttrain-rmse:1.96173\n",
      "[22356]\teval-rmse:3.81108\ttrain-rmse:1.96171\n",
      "[22357]\teval-rmse:3.81093\ttrain-rmse:1.96172\n",
      "[22358]\teval-rmse:3.80958\ttrain-rmse:1.96176\n",
      "[22359]\teval-rmse:3.81048\ttrain-rmse:1.96172\n",
      "[22360]\teval-rmse:3.80912\ttrain-rmse:1.96176\n",
      "[22361]\teval-rmse:3.81081\ttrain-rmse:1.9617\n",
      "[22362]\teval-rmse:3.80956\ttrain-rmse:1.96176\n",
      "[22363]\teval-rmse:3.8079\ttrain-rmse:1.96184\n",
      "[22364]\teval-rmse:3.80966\ttrain-rmse:1.96177\n",
      "[22365]\teval-rmse:3.81128\ttrain-rmse:1.96172\n",
      "[22366]\teval-rmse:3.81236\ttrain-rmse:1.96169\n",
      "[22367]\teval-rmse:3.8139\ttrain-rmse:1.96165\n",
      "[22368]\teval-rmse:3.81446\ttrain-rmse:1.96163\n",
      "[22369]\teval-rmse:3.81471\ttrain-rmse:1.96162\n",
      "[22370]\teval-rmse:3.81404\ttrain-rmse:1.96164\n",
      "[22371]\teval-rmse:3.81375\ttrain-rmse:1.96165\n",
      "[22372]\teval-rmse:3.81427\ttrain-rmse:1.96164\n",
      "[22373]\teval-rmse:3.81568\ttrain-rmse:1.96161\n",
      "[22374]\teval-rmse:3.81594\ttrain-rmse:1.9616\n",
      "[22375]\teval-rmse:3.81755\ttrain-rmse:1.96155\n",
      "[22376]\teval-rmse:3.81724\ttrain-rmse:1.96146\n",
      "[22377]\teval-rmse:3.81673\ttrain-rmse:1.96147\n",
      "[22378]\teval-rmse:3.81864\ttrain-rmse:1.96145\n",
      "[22379]\teval-rmse:3.81809\ttrain-rmse:1.96145\n",
      "[22380]\teval-rmse:3.81668\ttrain-rmse:1.96148\n",
      "[22381]\teval-rmse:3.81539\ttrain-rmse:1.96152\n",
      "[22382]\teval-rmse:3.81513\ttrain-rmse:1.96152\n",
      "[22383]\teval-rmse:3.81357\ttrain-rmse:1.96157\n",
      "[22384]\teval-rmse:3.81409\ttrain-rmse:1.96156\n",
      "[22385]\teval-rmse:3.81286\ttrain-rmse:1.96158\n",
      "[22386]\teval-rmse:3.81271\ttrain-rmse:1.96159\n",
      "[22387]\teval-rmse:3.81311\ttrain-rmse:1.96157\n",
      "[22388]\teval-rmse:3.81477\ttrain-rmse:1.96154\n",
      "[22389]\teval-rmse:3.81327\ttrain-rmse:1.96159\n",
      "[22390]\teval-rmse:3.81191\ttrain-rmse:1.96162\n",
      "[22391]\teval-rmse:3.81143\ttrain-rmse:1.96163\n",
      "[22392]\teval-rmse:3.81312\ttrain-rmse:1.96159\n",
      "[22393]\teval-rmse:3.8148\ttrain-rmse:1.96155\n",
      "[22394]\teval-rmse:3.81294\ttrain-rmse:1.96159\n",
      "[22395]\teval-rmse:3.81265\ttrain-rmse:1.96151\n",
      "[22396]\teval-rmse:3.81165\ttrain-rmse:1.96153\n",
      "[22397]\teval-rmse:3.81042\ttrain-rmse:1.96156\n",
      "[22398]\teval-rmse:3.81208\ttrain-rmse:1.96149\n",
      "[22399]\teval-rmse:3.81046\ttrain-rmse:1.96154\n",
      "[22400]\teval-rmse:3.8091\ttrain-rmse:1.96159\n",
      "[22401]\teval-rmse:3.80943\ttrain-rmse:1.96157\n",
      "[22402]\teval-rmse:3.80892\ttrain-rmse:1.96159\n",
      "[22403]\teval-rmse:3.80979\ttrain-rmse:1.96155\n",
      "[22404]\teval-rmse:3.8107\ttrain-rmse:1.96151\n",
      "[22405]\teval-rmse:3.811\ttrain-rmse:1.9615\n",
      "[22406]\teval-rmse:3.81151\ttrain-rmse:1.96148\n",
      "[22407]\teval-rmse:3.81074\ttrain-rmse:1.96151\n",
      "[22408]\teval-rmse:3.80922\ttrain-rmse:1.96158\n",
      "[22409]\teval-rmse:3.80824\ttrain-rmse:1.96161\n",
      "[22410]\teval-rmse:3.80677\ttrain-rmse:1.96169\n",
      "[22411]\teval-rmse:3.80657\ttrain-rmse:1.9617\n",
      "[22412]\teval-rmse:3.8082\ttrain-rmse:1.96163\n",
      "[22413]\teval-rmse:3.80623\ttrain-rmse:1.96175\n",
      "[22414]\teval-rmse:3.80735\ttrain-rmse:1.96168\n",
      "[22415]\teval-rmse:3.80712\ttrain-rmse:1.96158\n",
      "[22416]\teval-rmse:3.80562\ttrain-rmse:1.96165\n",
      "[22417]\teval-rmse:3.8042\ttrain-rmse:1.96173\n",
      "[22418]\teval-rmse:3.8053\ttrain-rmse:1.96166\n",
      "[22419]\teval-rmse:3.80621\ttrain-rmse:1.96161\n",
      "[22420]\teval-rmse:3.80596\ttrain-rmse:1.96162\n",
      "[22421]\teval-rmse:3.80642\ttrain-rmse:1.96159\n",
      "[22422]\teval-rmse:3.80494\ttrain-rmse:1.96168\n",
      "[22423]\teval-rmse:3.80456\ttrain-rmse:1.9617\n",
      "[22424]\teval-rmse:3.80309\ttrain-rmse:1.9618\n",
      "[22425]\teval-rmse:3.8013\ttrain-rmse:1.96195\n",
      "[22426]\teval-rmse:3.7997\ttrain-rmse:1.96205\n",
      "[22427]\teval-rmse:3.79947\ttrain-rmse:1.96196\n",
      "[22428]\teval-rmse:3.8001\ttrain-rmse:1.9619\n",
      "[22429]\teval-rmse:3.79987\ttrain-rmse:1.96181\n",
      "[22430]\teval-rmse:3.80153\ttrain-rmse:1.96171\n",
      "[22431]\teval-rmse:3.80099\ttrain-rmse:1.96174\n",
      "[22432]\teval-rmse:3.80237\ttrain-rmse:1.96166\n",
      "[22433]\teval-rmse:3.80213\ttrain-rmse:1.96167\n",
      "[22434]\teval-rmse:3.80118\ttrain-rmse:1.96171\n",
      "[22435]\teval-rmse:3.80274\ttrain-rmse:1.96162\n",
      "[22436]\teval-rmse:3.8015\ttrain-rmse:1.96172\n",
      "[22437]\teval-rmse:3.80007\ttrain-rmse:1.9618\n",
      "[22438]\teval-rmse:3.8012\ttrain-rmse:1.96171\n",
      "[22439]\teval-rmse:3.80248\ttrain-rmse:1.96161\n",
      "[22440]\teval-rmse:3.80092\ttrain-rmse:1.9617\n",
      "[22441]\teval-rmse:3.8002\ttrain-rmse:1.96174\n",
      "[22442]\teval-rmse:3.79843\ttrain-rmse:1.96188\n",
      "[22443]\teval-rmse:3.79898\ttrain-rmse:1.96183\n",
      "[22444]\teval-rmse:3.7985\ttrain-rmse:1.96186\n",
      "[22445]\teval-rmse:3.79828\ttrain-rmse:1.96187\n",
      "[22446]\teval-rmse:3.79711\ttrain-rmse:1.96198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22447]\teval-rmse:3.79851\ttrain-rmse:1.96188\n",
      "[22448]\teval-rmse:3.79853\ttrain-rmse:1.96188\n",
      "[22449]\teval-rmse:3.79812\ttrain-rmse:1.96192\n",
      "[22450]\teval-rmse:3.79942\ttrain-rmse:1.96183\n",
      "[22451]\teval-rmse:3.79782\ttrain-rmse:1.96197\n",
      "[22452]\teval-rmse:3.79942\ttrain-rmse:1.96183\n",
      "[22453]\teval-rmse:3.79923\ttrain-rmse:1.96183\n",
      "[22454]\teval-rmse:3.80116\ttrain-rmse:1.96174\n",
      "[22455]\teval-rmse:3.80095\ttrain-rmse:1.96175\n",
      "[22456]\teval-rmse:3.79916\ttrain-rmse:1.9619\n",
      "[22457]\teval-rmse:3.79791\ttrain-rmse:1.96198\n",
      "[22458]\teval-rmse:3.79925\ttrain-rmse:1.96189\n",
      "[22459]\teval-rmse:3.79851\ttrain-rmse:1.96196\n",
      "[22460]\teval-rmse:3.79828\ttrain-rmse:1.96185\n",
      "[22461]\teval-rmse:3.79864\ttrain-rmse:1.96182\n",
      "[22462]\teval-rmse:3.79905\ttrain-rmse:1.96179\n",
      "[22463]\teval-rmse:3.79751\ttrain-rmse:1.96189\n",
      "[22464]\teval-rmse:3.79944\ttrain-rmse:1.96179\n",
      "[22465]\teval-rmse:3.79898\ttrain-rmse:1.96182\n",
      "[22466]\teval-rmse:3.79806\ttrain-rmse:1.9619\n",
      "[22467]\teval-rmse:3.79631\ttrain-rmse:1.96203\n",
      "[22468]\teval-rmse:3.79795\ttrain-rmse:1.96191\n",
      "[22469]\teval-rmse:3.79926\ttrain-rmse:1.96181\n",
      "[22470]\teval-rmse:3.79996\ttrain-rmse:1.96177\n",
      "[22471]\teval-rmse:3.80003\ttrain-rmse:1.96176\n",
      "[22472]\teval-rmse:3.80166\ttrain-rmse:1.96162\n",
      "[22473]\teval-rmse:3.80129\ttrain-rmse:1.96164\n",
      "[22474]\teval-rmse:3.79977\ttrain-rmse:1.96177\n",
      "[22475]\teval-rmse:3.80063\ttrain-rmse:1.96172\n",
      "[22476]\teval-rmse:3.80043\ttrain-rmse:1.96163\n",
      "[22477]\teval-rmse:3.79883\ttrain-rmse:1.96177\n",
      "[22478]\teval-rmse:3.80059\ttrain-rmse:1.96165\n",
      "[22479]\teval-rmse:3.80219\ttrain-rmse:1.96155\n",
      "[22480]\teval-rmse:3.80273\ttrain-rmse:1.96151\n",
      "[22481]\teval-rmse:3.80113\ttrain-rmse:1.9616\n",
      "[22482]\teval-rmse:3.79919\ttrain-rmse:1.96177\n",
      "[22483]\teval-rmse:3.79877\ttrain-rmse:1.96179\n",
      "[22484]\teval-rmse:3.79903\ttrain-rmse:1.96177\n",
      "[22485]\teval-rmse:3.79988\ttrain-rmse:1.96171\n",
      "[22486]\teval-rmse:3.79815\ttrain-rmse:1.96188\n",
      "[22487]\teval-rmse:3.79844\ttrain-rmse:1.96185\n",
      "[22488]\teval-rmse:3.79977\ttrain-rmse:1.96176\n",
      "[22489]\teval-rmse:3.80093\ttrain-rmse:1.96165\n",
      "[22490]\teval-rmse:3.80128\ttrain-rmse:1.96163\n",
      "[22491]\teval-rmse:3.80034\ttrain-rmse:1.96167\n",
      "[22492]\teval-rmse:3.79891\ttrain-rmse:1.9618\n",
      "[22493]\teval-rmse:3.79871\ttrain-rmse:1.9618\n",
      "[22494]\teval-rmse:3.7982\ttrain-rmse:1.96185\n",
      "[22495]\teval-rmse:3.79802\ttrain-rmse:1.96186\n",
      "[22496]\teval-rmse:3.79665\ttrain-rmse:1.96199\n",
      "[22497]\teval-rmse:3.7981\ttrain-rmse:1.96189\n",
      "[22498]\teval-rmse:3.79897\ttrain-rmse:1.96183\n",
      "[22499]\teval-rmse:3.79958\ttrain-rmse:1.96177\n",
      "[22500]\teval-rmse:3.79843\ttrain-rmse:1.96185\n",
      "[22501]\teval-rmse:3.79901\ttrain-rmse:1.96179\n",
      "[22502]\teval-rmse:3.79878\ttrain-rmse:1.9617\n",
      "[22503]\teval-rmse:3.7983\ttrain-rmse:1.96173\n",
      "[22504]\teval-rmse:3.79715\ttrain-rmse:1.96184\n",
      "[22505]\teval-rmse:3.79576\ttrain-rmse:1.96194\n",
      "[22506]\teval-rmse:3.79557\ttrain-rmse:1.96195\n",
      "[22507]\teval-rmse:3.79693\ttrain-rmse:1.96185\n",
      "[22508]\teval-rmse:3.79731\ttrain-rmse:1.96181\n",
      "[22509]\teval-rmse:3.79684\ttrain-rmse:1.96184\n",
      "[22510]\teval-rmse:3.79562\ttrain-rmse:1.96196\n",
      "[22511]\teval-rmse:3.79625\ttrain-rmse:1.96192\n",
      "[22512]\teval-rmse:3.79581\ttrain-rmse:1.96195\n",
      "[22513]\teval-rmse:3.79544\ttrain-rmse:1.96197\n",
      "[22514]\teval-rmse:3.79526\ttrain-rmse:1.96198\n",
      "[22515]\teval-rmse:3.7957\ttrain-rmse:1.96193\n",
      "[22516]\teval-rmse:3.79762\ttrain-rmse:1.96183\n",
      "[22517]\teval-rmse:3.7987\ttrain-rmse:1.96173\n",
      "[22518]\teval-rmse:3.7986\ttrain-rmse:1.96173\n",
      "[22519]\teval-rmse:3.79948\ttrain-rmse:1.96165\n",
      "[22520]\teval-rmse:3.80117\ttrain-rmse:1.96154\n",
      "[22521]\teval-rmse:3.80154\ttrain-rmse:1.96151\n",
      "[22522]\teval-rmse:3.80196\ttrain-rmse:1.96148\n",
      "[22523]\teval-rmse:3.80233\ttrain-rmse:1.96145\n",
      "[22524]\teval-rmse:3.80241\ttrain-rmse:1.96144\n",
      "[22525]\teval-rmse:3.80123\ttrain-rmse:1.96151\n",
      "[22526]\teval-rmse:3.80029\ttrain-rmse:1.96155\n",
      "[22527]\teval-rmse:3.80204\ttrain-rmse:1.96144\n",
      "[22528]\teval-rmse:3.80227\ttrain-rmse:1.96142\n",
      "[22529]\teval-rmse:3.80387\ttrain-rmse:1.96131\n",
      "[22530]\teval-rmse:3.80529\ttrain-rmse:1.96121\n",
      "[22531]\teval-rmse:3.80658\ttrain-rmse:1.96115\n",
      "[22532]\teval-rmse:3.80608\ttrain-rmse:1.96118\n",
      "[22533]\teval-rmse:3.80641\ttrain-rmse:1.96117\n",
      "[22534]\teval-rmse:3.80712\ttrain-rmse:1.96113\n",
      "[22535]\teval-rmse:3.80846\ttrain-rmse:1.96106\n",
      "[22536]\teval-rmse:3.80721\ttrain-rmse:1.9611\n",
      "[22537]\teval-rmse:3.80539\ttrain-rmse:1.96122\n",
      "[22538]\teval-rmse:3.80383\ttrain-rmse:1.96129\n",
      "[22539]\teval-rmse:3.80513\ttrain-rmse:1.96123\n",
      "[22540]\teval-rmse:3.80642\ttrain-rmse:1.96115\n",
      "[22541]\teval-rmse:3.80675\ttrain-rmse:1.96113\n",
      "[22542]\teval-rmse:3.80511\ttrain-rmse:1.9612\n",
      "[22543]\teval-rmse:3.80473\ttrain-rmse:1.96122\n",
      "[22544]\teval-rmse:3.80424\ttrain-rmse:1.96124\n",
      "[22545]\teval-rmse:3.80399\ttrain-rmse:1.96125\n",
      "[22546]\teval-rmse:3.80508\ttrain-rmse:1.9612\n",
      "[22547]\teval-rmse:3.80437\ttrain-rmse:1.96125\n",
      "[22548]\teval-rmse:3.80477\ttrain-rmse:1.96122\n",
      "[22549]\teval-rmse:3.80618\ttrain-rmse:1.96113\n",
      "[22550]\teval-rmse:3.80464\ttrain-rmse:1.9612\n",
      "[22551]\teval-rmse:3.80471\ttrain-rmse:1.9612\n",
      "[22552]\teval-rmse:3.80663\ttrain-rmse:1.96113\n",
      "[22553]\teval-rmse:3.80821\ttrain-rmse:1.96106\n",
      "[22554]\teval-rmse:3.80678\ttrain-rmse:1.96115\n",
      "[22555]\teval-rmse:3.80503\ttrain-rmse:1.96126\n",
      "[22556]\teval-rmse:3.80382\ttrain-rmse:1.96132\n",
      "[22557]\teval-rmse:3.80254\ttrain-rmse:1.96139\n",
      "[22558]\teval-rmse:3.80392\ttrain-rmse:1.96131\n",
      "[22559]\teval-rmse:3.80554\ttrain-rmse:1.96123\n",
      "[22560]\teval-rmse:3.80409\ttrain-rmse:1.9613\n",
      "[22561]\teval-rmse:3.80284\ttrain-rmse:1.96137\n",
      "[22562]\teval-rmse:3.80307\ttrain-rmse:1.96135\n",
      "[22563]\teval-rmse:3.80269\ttrain-rmse:1.96137\n",
      "[22564]\teval-rmse:3.80197\ttrain-rmse:1.96141\n",
      "[22565]\teval-rmse:3.8016\ttrain-rmse:1.96144\n",
      "[22566]\teval-rmse:3.80111\ttrain-rmse:1.96147\n",
      "[22567]\teval-rmse:3.80196\ttrain-rmse:1.9614\n",
      "[22568]\teval-rmse:3.80217\ttrain-rmse:1.96138\n",
      "[22569]\teval-rmse:3.80197\ttrain-rmse:1.96129\n",
      "[22570]\teval-rmse:3.80103\ttrain-rmse:1.96133\n",
      "[22571]\teval-rmse:3.79977\ttrain-rmse:1.96141\n",
      "[22572]\teval-rmse:3.79924\ttrain-rmse:1.96144\n",
      "[22573]\teval-rmse:3.80085\ttrain-rmse:1.96134\n",
      "[22574]\teval-rmse:3.80225\ttrain-rmse:1.96126\n",
      "[22575]\teval-rmse:3.80131\ttrain-rmse:1.9613\n",
      "[22576]\teval-rmse:3.80323\ttrain-rmse:1.96121\n",
      "[22577]\teval-rmse:3.80515\ttrain-rmse:1.96114\n",
      "[22578]\teval-rmse:3.80503\ttrain-rmse:1.96114\n",
      "[22579]\teval-rmse:3.80553\ttrain-rmse:1.96112\n",
      "[22580]\teval-rmse:3.80528\ttrain-rmse:1.96113\n",
      "[22581]\teval-rmse:3.80667\ttrain-rmse:1.96106\n",
      "[22582]\teval-rmse:3.80671\ttrain-rmse:1.96106\n",
      "[22583]\teval-rmse:3.80833\ttrain-rmse:1.96098\n",
      "[22584]\teval-rmse:3.80635\ttrain-rmse:1.9611\n",
      "[22585]\teval-rmse:3.80486\ttrain-rmse:1.96117\n",
      "[22586]\teval-rmse:3.80336\ttrain-rmse:1.96128\n",
      "[22587]\teval-rmse:3.80359\ttrain-rmse:1.96126\n",
      "[22588]\teval-rmse:3.80398\ttrain-rmse:1.96124\n",
      "[22589]\teval-rmse:3.80224\ttrain-rmse:1.96138\n",
      "[22590]\teval-rmse:3.80113\ttrain-rmse:1.96145\n",
      "[22591]\teval-rmse:3.8\ttrain-rmse:1.96155\n",
      "[22592]\teval-rmse:3.79981\ttrain-rmse:1.96155\n",
      "[22593]\teval-rmse:3.7991\ttrain-rmse:1.96162\n",
      "[22594]\teval-rmse:3.79948\ttrain-rmse:1.96158\n",
      "[22595]\teval-rmse:3.80134\ttrain-rmse:1.96142\n",
      "[22596]\teval-rmse:3.80193\ttrain-rmse:1.96139\n",
      "[22597]\teval-rmse:3.80239\ttrain-rmse:1.96135\n",
      "[22598]\teval-rmse:3.80215\ttrain-rmse:1.96136\n",
      "[22599]\teval-rmse:3.80179\ttrain-rmse:1.96138\n",
      "[22600]\teval-rmse:3.80221\ttrain-rmse:1.96135\n",
      "[22601]\teval-rmse:3.80331\ttrain-rmse:1.96127\n",
      "[22602]\teval-rmse:3.80463\ttrain-rmse:1.9612\n",
      "[22603]\teval-rmse:3.80299\ttrain-rmse:1.96132\n",
      "[22604]\teval-rmse:3.80384\ttrain-rmse:1.96127\n",
      "[22605]\teval-rmse:3.80266\ttrain-rmse:1.96133\n",
      "[22606]\teval-rmse:3.80374\ttrain-rmse:1.96127\n",
      "[22607]\teval-rmse:3.80412\ttrain-rmse:1.96125\n",
      "[22608]\teval-rmse:3.80391\ttrain-rmse:1.96125\n",
      "[22609]\teval-rmse:3.80462\ttrain-rmse:1.9612\n",
      "[22610]\teval-rmse:3.80424\ttrain-rmse:1.96122\n",
      "[22611]\teval-rmse:3.80456\ttrain-rmse:1.9612\n",
      "[22612]\teval-rmse:3.80596\ttrain-rmse:1.96114\n",
      "[22613]\teval-rmse:3.80664\ttrain-rmse:1.96111\n",
      "[22614]\teval-rmse:3.80608\ttrain-rmse:1.96113\n",
      "[22615]\teval-rmse:3.80569\ttrain-rmse:1.96115\n",
      "[22616]\teval-rmse:3.80603\ttrain-rmse:1.96112\n",
      "[22617]\teval-rmse:3.80738\ttrain-rmse:1.96107\n",
      "[22618]\teval-rmse:3.80679\ttrain-rmse:1.96109\n",
      "[22619]\teval-rmse:3.80635\ttrain-rmse:1.96111\n",
      "[22620]\teval-rmse:3.80521\ttrain-rmse:1.96116\n",
      "[22621]\teval-rmse:3.80663\ttrain-rmse:1.96107\n",
      "[22622]\teval-rmse:3.80699\ttrain-rmse:1.96105\n",
      "[22623]\teval-rmse:3.80685\ttrain-rmse:1.96105\n",
      "[22624]\teval-rmse:3.80812\ttrain-rmse:1.96098\n",
      "[22625]\teval-rmse:3.80713\ttrain-rmse:1.96101\n",
      "[22626]\teval-rmse:3.80549\ttrain-rmse:1.96111\n",
      "[22627]\teval-rmse:3.80656\ttrain-rmse:1.96104\n",
      "[22628]\teval-rmse:3.80725\ttrain-rmse:1.96101\n",
      "[22629]\teval-rmse:3.80575\ttrain-rmse:1.9611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22630]\teval-rmse:3.8045\ttrain-rmse:1.96116\n",
      "[22631]\teval-rmse:3.80586\ttrain-rmse:1.9611\n",
      "[22632]\teval-rmse:3.80612\ttrain-rmse:1.96108\n",
      "[22633]\teval-rmse:3.80751\ttrain-rmse:1.96101\n",
      "[22634]\teval-rmse:3.80728\ttrain-rmse:1.96101\n",
      "[22635]\teval-rmse:3.80702\ttrain-rmse:1.96102\n",
      "[22636]\teval-rmse:3.80861\ttrain-rmse:1.96094\n",
      "[22637]\teval-rmse:3.80763\ttrain-rmse:1.96097\n",
      "[22638]\teval-rmse:3.80737\ttrain-rmse:1.96098\n",
      "[22639]\teval-rmse:3.80873\ttrain-rmse:1.96091\n",
      "[22640]\teval-rmse:3.80927\ttrain-rmse:1.96089\n",
      "[22641]\teval-rmse:3.81051\ttrain-rmse:1.96084\n",
      "[22642]\teval-rmse:3.81005\ttrain-rmse:1.96086\n",
      "[22643]\teval-rmse:3.81043\ttrain-rmse:1.96084\n",
      "[22644]\teval-rmse:3.81019\ttrain-rmse:1.96075\n",
      "[22645]\teval-rmse:3.81049\ttrain-rmse:1.96074\n",
      "[22646]\teval-rmse:3.81004\ttrain-rmse:1.96075\n",
      "[22647]\teval-rmse:3.81062\ttrain-rmse:1.96074\n",
      "[22648]\teval-rmse:3.8102\ttrain-rmse:1.96075\n",
      "[22649]\teval-rmse:3.80862\ttrain-rmse:1.96079\n",
      "[22650]\teval-rmse:3.80952\ttrain-rmse:1.96075\n",
      "[22651]\teval-rmse:3.81116\ttrain-rmse:1.96068\n",
      "[22652]\teval-rmse:3.81258\ttrain-rmse:1.96065\n",
      "[22653]\teval-rmse:3.8123\ttrain-rmse:1.96057\n",
      "[22654]\teval-rmse:3.81394\ttrain-rmse:1.96055\n",
      "[22655]\teval-rmse:3.81365\ttrain-rmse:1.96056\n",
      "[22656]\teval-rmse:3.81349\ttrain-rmse:1.96056\n",
      "[22657]\teval-rmse:3.81332\ttrain-rmse:1.96056\n",
      "[22658]\teval-rmse:3.81208\ttrain-rmse:1.96059\n",
      "[22659]\teval-rmse:3.81166\ttrain-rmse:1.9606\n",
      "[22660]\teval-rmse:3.81168\ttrain-rmse:1.9606\n",
      "[22661]\teval-rmse:3.81195\ttrain-rmse:1.96059\n",
      "[22662]\teval-rmse:3.81118\ttrain-rmse:1.9606\n",
      "[22663]\teval-rmse:3.8117\ttrain-rmse:1.9606\n",
      "[22664]\teval-rmse:3.81297\ttrain-rmse:1.96057\n",
      "[22665]\teval-rmse:3.81318\ttrain-rmse:1.96057\n",
      "[22666]\teval-rmse:3.81459\ttrain-rmse:1.96054\n",
      "[22667]\teval-rmse:3.81307\ttrain-rmse:1.96057\n",
      "[22668]\teval-rmse:3.81448\ttrain-rmse:1.96056\n",
      "[22669]\teval-rmse:3.81527\ttrain-rmse:1.96054\n",
      "[22670]\teval-rmse:3.81473\ttrain-rmse:1.96054\n",
      "[22671]\teval-rmse:3.81587\ttrain-rmse:1.96053\n",
      "[22672]\teval-rmse:3.81421\ttrain-rmse:1.96054\n",
      "[22673]\teval-rmse:3.81463\ttrain-rmse:1.96053\n",
      "[22674]\teval-rmse:3.8163\ttrain-rmse:1.96052\n",
      "[22675]\teval-rmse:3.81787\ttrain-rmse:1.9605\n",
      "[22676]\teval-rmse:3.81739\ttrain-rmse:1.9605\n",
      "[22677]\teval-rmse:3.81826\ttrain-rmse:1.9605\n",
      "[22678]\teval-rmse:3.81825\ttrain-rmse:1.9605\n",
      "[22679]\teval-rmse:3.81938\ttrain-rmse:1.9605\n",
      "[22680]\teval-rmse:3.8192\ttrain-rmse:1.9605\n",
      "[22681]\teval-rmse:3.81757\ttrain-rmse:1.96049\n",
      "[22682]\teval-rmse:3.81704\ttrain-rmse:1.9605\n",
      "[22683]\teval-rmse:3.81568\ttrain-rmse:1.96052\n",
      "[22684]\teval-rmse:3.81758\ttrain-rmse:1.96049\n",
      "[22685]\teval-rmse:3.81838\ttrain-rmse:1.96049\n",
      "[22686]\teval-rmse:3.81975\ttrain-rmse:1.96049\n",
      "[22687]\teval-rmse:3.81817\ttrain-rmse:1.9605\n",
      "[22688]\teval-rmse:3.81867\ttrain-rmse:1.9605\n",
      "[22689]\teval-rmse:3.8173\ttrain-rmse:1.9605\n",
      "[22690]\teval-rmse:3.8192\ttrain-rmse:1.96048\n",
      "[22691]\teval-rmse:3.81891\ttrain-rmse:1.96048\n",
      "[22692]\teval-rmse:3.8184\ttrain-rmse:1.96049\n",
      "[22693]\teval-rmse:3.81792\ttrain-rmse:1.96049\n",
      "[22694]\teval-rmse:3.81611\ttrain-rmse:1.96052\n",
      "[22695]\teval-rmse:3.81478\ttrain-rmse:1.96056\n",
      "[22696]\teval-rmse:3.81643\ttrain-rmse:1.96054\n",
      "[22697]\teval-rmse:3.81809\ttrain-rmse:1.96053\n",
      "[22698]\teval-rmse:3.81683\ttrain-rmse:1.96054\n",
      "[22699]\teval-rmse:3.81873\ttrain-rmse:1.96052\n",
      "[22700]\teval-rmse:3.82004\ttrain-rmse:1.96052\n",
      "[22701]\teval-rmse:3.82052\ttrain-rmse:1.96052\n",
      "[22702]\teval-rmse:3.82107\ttrain-rmse:1.96051\n",
      "[22703]\teval-rmse:3.82159\ttrain-rmse:1.96051\n",
      "[22704]\teval-rmse:3.82094\ttrain-rmse:1.96051\n",
      "[22705]\teval-rmse:3.8223\ttrain-rmse:1.96052\n",
      "[22706]\teval-rmse:3.8225\ttrain-rmse:1.96052\n",
      "[22707]\teval-rmse:3.82203\ttrain-rmse:1.96052\n",
      "[22708]\teval-rmse:3.82034\ttrain-rmse:1.96053\n",
      "[22709]\teval-rmse:3.82161\ttrain-rmse:1.96054\n",
      "[22710]\teval-rmse:3.82351\ttrain-rmse:1.96054\n",
      "[22711]\teval-rmse:3.82392\ttrain-rmse:1.96054\n",
      "[22712]\teval-rmse:3.82442\ttrain-rmse:1.96054\n",
      "[22713]\teval-rmse:3.82394\ttrain-rmse:1.96054\n",
      "[22714]\teval-rmse:3.82459\ttrain-rmse:1.96055\n",
      "[22715]\teval-rmse:3.82513\ttrain-rmse:1.96055\n",
      "[22716]\teval-rmse:3.82478\ttrain-rmse:1.96047\n",
      "[22717]\teval-rmse:3.82354\ttrain-rmse:1.96048\n",
      "[22718]\teval-rmse:3.8232\ttrain-rmse:1.9604\n",
      "[22719]\teval-rmse:3.82351\ttrain-rmse:1.9604\n",
      "[22720]\teval-rmse:3.823\ttrain-rmse:1.9604\n",
      "[22721]\teval-rmse:3.82353\ttrain-rmse:1.9604\n",
      "[22722]\teval-rmse:3.82378\ttrain-rmse:1.96041\n",
      "[22723]\teval-rmse:3.82432\ttrain-rmse:1.96041\n",
      "[22724]\teval-rmse:3.82489\ttrain-rmse:1.96042\n",
      "[22725]\teval-rmse:3.82406\ttrain-rmse:1.96041\n",
      "[22726]\teval-rmse:3.82235\ttrain-rmse:1.9604\n",
      "[22727]\teval-rmse:3.82348\ttrain-rmse:1.96041\n",
      "[22728]\teval-rmse:3.82328\ttrain-rmse:1.96041\n",
      "[22729]\teval-rmse:3.82345\ttrain-rmse:1.96041\n",
      "[22730]\teval-rmse:3.82187\ttrain-rmse:1.96041\n",
      "[22731]\teval-rmse:3.82186\ttrain-rmse:1.96041\n",
      "[22732]\teval-rmse:3.82237\ttrain-rmse:1.96041\n",
      "[22733]\teval-rmse:3.82232\ttrain-rmse:1.96041\n",
      "[22734]\teval-rmse:3.82072\ttrain-rmse:1.96039\n",
      "[22735]\teval-rmse:3.8204\ttrain-rmse:1.96039\n",
      "[22736]\teval-rmse:3.82096\ttrain-rmse:1.96039\n",
      "[22737]\teval-rmse:3.81929\ttrain-rmse:1.96038\n",
      "[22738]\teval-rmse:3.81843\ttrain-rmse:1.96039\n",
      "[22739]\teval-rmse:3.81795\ttrain-rmse:1.96039\n",
      "[22740]\teval-rmse:3.81639\ttrain-rmse:1.9604\n",
      "[22741]\teval-rmse:3.81519\ttrain-rmse:1.96044\n",
      "[22742]\teval-rmse:3.81391\ttrain-rmse:1.96045\n",
      "[22743]\teval-rmse:3.81446\ttrain-rmse:1.96044\n",
      "[22744]\teval-rmse:3.814\ttrain-rmse:1.96045\n",
      "[22745]\teval-rmse:3.81538\ttrain-rmse:1.96043\n",
      "[22746]\teval-rmse:3.81475\ttrain-rmse:1.96044\n",
      "[22747]\teval-rmse:3.81347\ttrain-rmse:1.96047\n",
      "[22748]\teval-rmse:3.81223\ttrain-rmse:1.96049\n",
      "[22749]\teval-rmse:3.81377\ttrain-rmse:1.96045\n",
      "[22750]\teval-rmse:3.81539\ttrain-rmse:1.9604\n",
      "[22751]\teval-rmse:3.81437\ttrain-rmse:1.96041\n",
      "[22752]\teval-rmse:3.8141\ttrain-rmse:1.96042\n",
      "[22753]\teval-rmse:3.81498\ttrain-rmse:1.96041\n",
      "[22754]\teval-rmse:3.81413\ttrain-rmse:1.96042\n",
      "[22755]\teval-rmse:3.81571\ttrain-rmse:1.9604\n",
      "[22756]\teval-rmse:3.81386\ttrain-rmse:1.96044\n",
      "[22757]\teval-rmse:3.8134\ttrain-rmse:1.96045\n",
      "[22758]\teval-rmse:3.81395\ttrain-rmse:1.96044\n",
      "[22759]\teval-rmse:3.81313\ttrain-rmse:1.96046\n",
      "[22760]\teval-rmse:3.81287\ttrain-rmse:1.96046\n",
      "[22761]\teval-rmse:3.81451\ttrain-rmse:1.96041\n",
      "[22762]\teval-rmse:3.81396\ttrain-rmse:1.96042\n",
      "[22763]\teval-rmse:3.81314\ttrain-rmse:1.96044\n",
      "[22764]\teval-rmse:3.81365\ttrain-rmse:1.96043\n",
      "[22765]\teval-rmse:3.81341\ttrain-rmse:1.96043\n",
      "[22766]\teval-rmse:3.81515\ttrain-rmse:1.96037\n",
      "[22767]\teval-rmse:3.81548\ttrain-rmse:1.96037\n",
      "[22768]\teval-rmse:3.81392\ttrain-rmse:1.9604\n",
      "[22769]\teval-rmse:3.81455\ttrain-rmse:1.96039\n",
      "[22770]\teval-rmse:3.81626\ttrain-rmse:1.96036\n",
      "[22771]\teval-rmse:3.81789\ttrain-rmse:1.96033\n",
      "[22772]\teval-rmse:3.81685\ttrain-rmse:1.96034\n",
      "[22773]\teval-rmse:3.81708\ttrain-rmse:1.96034\n",
      "[22774]\teval-rmse:3.81881\ttrain-rmse:1.96032\n",
      "[22775]\teval-rmse:3.81747\ttrain-rmse:1.96035\n",
      "[22776]\teval-rmse:3.81905\ttrain-rmse:1.96035\n",
      "[22777]\teval-rmse:3.81992\ttrain-rmse:1.96034\n",
      "[22778]\teval-rmse:3.81933\ttrain-rmse:1.96033\n",
      "[22779]\teval-rmse:3.81988\ttrain-rmse:1.96034\n",
      "[22780]\teval-rmse:3.82148\ttrain-rmse:1.96031\n",
      "[22781]\teval-rmse:3.82128\ttrain-rmse:1.96031\n",
      "[22782]\teval-rmse:3.82184\ttrain-rmse:1.96031\n",
      "[22783]\teval-rmse:3.81996\ttrain-rmse:1.96032\n",
      "[22784]\teval-rmse:3.82021\ttrain-rmse:1.96032\n",
      "[22785]\teval-rmse:3.81969\ttrain-rmse:1.96031\n",
      "[22786]\teval-rmse:3.81847\ttrain-rmse:1.96031\n",
      "[22787]\teval-rmse:3.81658\ttrain-rmse:1.96034\n",
      "[22788]\teval-rmse:3.8169\ttrain-rmse:1.96033\n",
      "[22789]\teval-rmse:3.81853\ttrain-rmse:1.96032\n",
      "[22790]\teval-rmse:3.81696\ttrain-rmse:1.96033\n",
      "[22791]\teval-rmse:3.81639\ttrain-rmse:1.96034\n",
      "[22792]\teval-rmse:3.81506\ttrain-rmse:1.96037\n",
      "[22793]\teval-rmse:3.81323\ttrain-rmse:1.96042\n",
      "[22794]\teval-rmse:3.81281\ttrain-rmse:1.96043\n",
      "[22795]\teval-rmse:3.81252\ttrain-rmse:1.96035\n",
      "[22796]\teval-rmse:3.81392\ttrain-rmse:1.96032\n",
      "[22797]\teval-rmse:3.81474\ttrain-rmse:1.9603\n",
      "[22798]\teval-rmse:3.81445\ttrain-rmse:1.96021\n",
      "[22799]\teval-rmse:3.81285\ttrain-rmse:1.96023\n",
      "[22800]\teval-rmse:3.81424\ttrain-rmse:1.9602\n",
      "[22801]\teval-rmse:3.81305\ttrain-rmse:1.96024\n",
      "[22802]\teval-rmse:3.81433\ttrain-rmse:1.96021\n",
      "[22803]\teval-rmse:3.81501\ttrain-rmse:1.9602\n",
      "[22804]\teval-rmse:3.8161\ttrain-rmse:1.96018\n",
      "[22805]\teval-rmse:3.81771\ttrain-rmse:1.96014\n",
      "[22806]\teval-rmse:3.81909\ttrain-rmse:1.96014\n",
      "[22807]\teval-rmse:3.81929\ttrain-rmse:1.96014\n",
      "[22808]\teval-rmse:3.82063\ttrain-rmse:1.96014\n",
      "[22809]\teval-rmse:3.82063\ttrain-rmse:1.96014\n",
      "[22810]\teval-rmse:3.81899\ttrain-rmse:1.96013\n",
      "[22811]\teval-rmse:3.81795\ttrain-rmse:1.96014\n",
      "[22812]\teval-rmse:3.81623\ttrain-rmse:1.96014\n",
      "[22813]\teval-rmse:3.8147\ttrain-rmse:1.96017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22814]\teval-rmse:3.81542\ttrain-rmse:1.96016\n",
      "[22815]\teval-rmse:3.81714\ttrain-rmse:1.96011\n",
      "[22816]\teval-rmse:3.81905\ttrain-rmse:1.9601\n",
      "[22817]\teval-rmse:3.8194\ttrain-rmse:1.96009\n",
      "[22818]\teval-rmse:3.82103\ttrain-rmse:1.96007\n",
      "[22819]\teval-rmse:3.82071\ttrain-rmse:1.96007\n",
      "[22820]\teval-rmse:3.82226\ttrain-rmse:1.96008\n",
      "[22821]\teval-rmse:3.82283\ttrain-rmse:1.96008\n",
      "[22822]\teval-rmse:3.82288\ttrain-rmse:1.96008\n",
      "[22823]\teval-rmse:3.82446\ttrain-rmse:1.9601\n",
      "[22824]\teval-rmse:3.8256\ttrain-rmse:1.96011\n",
      "[22825]\teval-rmse:3.82452\ttrain-rmse:1.9601\n",
      "[22826]\teval-rmse:3.82469\ttrain-rmse:1.96011\n",
      "[22827]\teval-rmse:3.82498\ttrain-rmse:1.96011\n",
      "[22828]\teval-rmse:3.82478\ttrain-rmse:1.9601\n",
      "[22829]\teval-rmse:3.82531\ttrain-rmse:1.96011\n",
      "[22830]\teval-rmse:3.82358\ttrain-rmse:1.9601\n",
      "[22831]\teval-rmse:3.822\ttrain-rmse:1.96008\n",
      "[22832]\teval-rmse:3.82077\ttrain-rmse:1.9601\n",
      "[22833]\teval-rmse:3.82105\ttrain-rmse:1.9601\n",
      "[22834]\teval-rmse:3.8198\ttrain-rmse:1.9601\n",
      "[22835]\teval-rmse:3.81951\ttrain-rmse:1.96001\n",
      "[22836]\teval-rmse:3.81886\ttrain-rmse:1.96001\n",
      "[22837]\teval-rmse:3.81828\ttrain-rmse:1.96002\n",
      "[22838]\teval-rmse:3.81811\ttrain-rmse:1.96002\n",
      "[22839]\teval-rmse:3.81783\ttrain-rmse:1.96002\n",
      "[22840]\teval-rmse:3.8192\ttrain-rmse:1.96001\n",
      "[22841]\teval-rmse:3.81798\ttrain-rmse:1.96001\n",
      "[22842]\teval-rmse:3.81769\ttrain-rmse:1.96001\n",
      "[22843]\teval-rmse:3.81642\ttrain-rmse:1.96001\n",
      "[22844]\teval-rmse:3.81475\ttrain-rmse:1.96004\n",
      "[22845]\teval-rmse:3.81458\ttrain-rmse:1.96004\n",
      "[22846]\teval-rmse:3.81546\ttrain-rmse:1.96003\n",
      "[22847]\teval-rmse:3.81393\ttrain-rmse:1.96005\n",
      "[22848]\teval-rmse:3.81274\ttrain-rmse:1.96008\n",
      "[22849]\teval-rmse:3.81257\ttrain-rmse:1.96009\n",
      "[22850]\teval-rmse:3.81232\ttrain-rmse:1.96009\n",
      "[22851]\teval-rmse:3.81296\ttrain-rmse:1.96008\n",
      "[22852]\teval-rmse:3.81452\ttrain-rmse:1.96006\n",
      "[22853]\teval-rmse:3.8135\ttrain-rmse:1.96008\n",
      "[22854]\teval-rmse:3.81373\ttrain-rmse:1.96007\n",
      "[22855]\teval-rmse:3.81235\ttrain-rmse:1.9601\n",
      "[22856]\teval-rmse:3.81108\ttrain-rmse:1.96013\n",
      "[22857]\teval-rmse:3.8092\ttrain-rmse:1.96019\n",
      "[22858]\teval-rmse:3.80941\ttrain-rmse:1.96018\n",
      "[22859]\teval-rmse:3.80966\ttrain-rmse:1.96017\n",
      "[22860]\teval-rmse:3.81157\ttrain-rmse:1.96013\n",
      "[22861]\teval-rmse:3.81318\ttrain-rmse:1.96009\n",
      "[22862]\teval-rmse:3.81427\ttrain-rmse:1.96006\n",
      "[22863]\teval-rmse:3.81398\ttrain-rmse:1.95999\n",
      "[22864]\teval-rmse:3.8142\ttrain-rmse:1.95998\n",
      "[22865]\teval-rmse:3.81439\ttrain-rmse:1.95998\n",
      "[22866]\teval-rmse:3.81359\ttrain-rmse:1.95999\n",
      "[22867]\teval-rmse:3.81385\ttrain-rmse:1.95999\n",
      "[22868]\teval-rmse:3.81358\ttrain-rmse:1.95999\n",
      "[22869]\teval-rmse:3.81399\ttrain-rmse:1.95998\n",
      "[22870]\teval-rmse:3.81245\ttrain-rmse:1.96\n",
      "[22871]\teval-rmse:3.81185\ttrain-rmse:1.96001\n",
      "[22872]\teval-rmse:3.81345\ttrain-rmse:1.95996\n",
      "[22873]\teval-rmse:3.81302\ttrain-rmse:1.95997\n",
      "[22874]\teval-rmse:3.81364\ttrain-rmse:1.95996\n",
      "[22875]\teval-rmse:3.81281\ttrain-rmse:1.95998\n",
      "[22876]\teval-rmse:3.81333\ttrain-rmse:1.95997\n",
      "[22877]\teval-rmse:3.81255\ttrain-rmse:1.95998\n",
      "[22878]\teval-rmse:3.81231\ttrain-rmse:1.95999\n",
      "[22879]\teval-rmse:3.81188\ttrain-rmse:1.95999\n",
      "[22880]\teval-rmse:3.81379\ttrain-rmse:1.95996\n",
      "[22881]\teval-rmse:3.81244\ttrain-rmse:1.95999\n",
      "[22882]\teval-rmse:3.81156\ttrain-rmse:1.96002\n",
      "[22883]\teval-rmse:3.80993\ttrain-rmse:1.96006\n",
      "[22884]\teval-rmse:3.80969\ttrain-rmse:1.96007\n",
      "[22885]\teval-rmse:3.80921\ttrain-rmse:1.96008\n",
      "[22886]\teval-rmse:3.80894\ttrain-rmse:1.96009\n",
      "[22887]\teval-rmse:3.80778\ttrain-rmse:1.96013\n",
      "[22888]\teval-rmse:3.80752\ttrain-rmse:1.96005\n",
      "[22889]\teval-rmse:3.80818\ttrain-rmse:1.96003\n",
      "[22890]\teval-rmse:3.80805\ttrain-rmse:1.96003\n",
      "[22891]\teval-rmse:3.80922\ttrain-rmse:1.95999\n",
      "[22892]\teval-rmse:3.80957\ttrain-rmse:1.95998\n",
      "[22893]\teval-rmse:3.81147\ttrain-rmse:1.95993\n",
      "[22894]\teval-rmse:3.81021\ttrain-rmse:1.95998\n",
      "[22895]\teval-rmse:3.80996\ttrain-rmse:1.95991\n",
      "[22896]\teval-rmse:3.81186\ttrain-rmse:1.95986\n",
      "[22897]\teval-rmse:3.81057\ttrain-rmse:1.95989\n",
      "[22898]\teval-rmse:3.81092\ttrain-rmse:1.95988\n",
      "[22899]\teval-rmse:3.81181\ttrain-rmse:1.95985\n",
      "[22900]\teval-rmse:3.8118\ttrain-rmse:1.95985\n",
      "[22901]\teval-rmse:3.81079\ttrain-rmse:1.95987\n",
      "[22902]\teval-rmse:3.81025\ttrain-rmse:1.95988\n",
      "[22903]\teval-rmse:3.81\ttrain-rmse:1.95989\n",
      "[22904]\teval-rmse:3.80973\ttrain-rmse:1.95981\n",
      "[22905]\teval-rmse:3.81163\ttrain-rmse:1.95977\n",
      "[22906]\teval-rmse:3.812\ttrain-rmse:1.95976\n",
      "[22907]\teval-rmse:3.81253\ttrain-rmse:1.95975\n",
      "[22908]\teval-rmse:3.81067\ttrain-rmse:1.95981\n",
      "[22909]\teval-rmse:3.81149\ttrain-rmse:1.95979\n",
      "[22910]\teval-rmse:3.80998\ttrain-rmse:1.95982\n",
      "[22911]\teval-rmse:3.80843\ttrain-rmse:1.95989\n",
      "[22912]\teval-rmse:3.80926\ttrain-rmse:1.95986\n",
      "[22913]\teval-rmse:3.8101\ttrain-rmse:1.95983\n",
      "[22914]\teval-rmse:3.80887\ttrain-rmse:1.95988\n",
      "[22915]\teval-rmse:3.80728\ttrain-rmse:1.95994\n",
      "[22916]\teval-rmse:3.8087\ttrain-rmse:1.95989\n",
      "[22917]\teval-rmse:3.80721\ttrain-rmse:1.95996\n",
      "[22918]\teval-rmse:3.80725\ttrain-rmse:1.95996\n",
      "[22919]\teval-rmse:3.80759\ttrain-rmse:1.95994\n",
      "[22920]\teval-rmse:3.80873\ttrain-rmse:1.95989\n",
      "[22921]\teval-rmse:3.80832\ttrain-rmse:1.95991\n",
      "[22922]\teval-rmse:3.80954\ttrain-rmse:1.95986\n",
      "[22923]\teval-rmse:3.81092\ttrain-rmse:1.95981\n",
      "[22924]\teval-rmse:3.81047\ttrain-rmse:1.95982\n",
      "[22925]\teval-rmse:3.81052\ttrain-rmse:1.95982\n",
      "[22926]\teval-rmse:3.81008\ttrain-rmse:1.95983\n",
      "[22927]\teval-rmse:3.80854\ttrain-rmse:1.95988\n",
      "[22928]\teval-rmse:3.81019\ttrain-rmse:1.95982\n",
      "[22929]\teval-rmse:3.80937\ttrain-rmse:1.95985\n",
      "[22930]\teval-rmse:3.80742\ttrain-rmse:1.95993\n",
      "[22931]\teval-rmse:3.80871\ttrain-rmse:1.95988\n",
      "[22932]\teval-rmse:3.80845\ttrain-rmse:1.95988\n",
      "[22933]\teval-rmse:3.8087\ttrain-rmse:1.95987\n",
      "[22934]\teval-rmse:3.80742\ttrain-rmse:1.95993\n",
      "[22935]\teval-rmse:3.80715\ttrain-rmse:1.95985\n",
      "[22936]\teval-rmse:3.806\ttrain-rmse:1.9599\n",
      "[22937]\teval-rmse:3.80574\ttrain-rmse:1.95983\n",
      "[22938]\teval-rmse:3.80499\ttrain-rmse:1.95986\n",
      "[22939]\teval-rmse:3.80352\ttrain-rmse:1.95994\n",
      "[22940]\teval-rmse:3.8019\ttrain-rmse:1.96002\n",
      "[22941]\teval-rmse:3.80223\ttrain-rmse:1.96\n",
      "[22942]\teval-rmse:3.80211\ttrain-rmse:1.96\n",
      "[22943]\teval-rmse:3.80372\ttrain-rmse:1.95991\n",
      "[22944]\teval-rmse:3.80488\ttrain-rmse:1.95985\n",
      "[22945]\teval-rmse:3.80543\ttrain-rmse:1.95983\n",
      "[22946]\teval-rmse:3.80573\ttrain-rmse:1.95982\n",
      "[22947]\teval-rmse:3.80547\ttrain-rmse:1.95974\n",
      "[22948]\teval-rmse:3.80395\ttrain-rmse:1.95982\n",
      "[22949]\teval-rmse:3.80371\ttrain-rmse:1.95983\n",
      "[22950]\teval-rmse:3.80527\ttrain-rmse:1.95976\n",
      "[22951]\teval-rmse:3.80513\ttrain-rmse:1.95977\n",
      "[22952]\teval-rmse:3.80569\ttrain-rmse:1.95974\n",
      "[22953]\teval-rmse:3.80543\ttrain-rmse:1.95975\n",
      "[22954]\teval-rmse:3.80412\ttrain-rmse:1.9598\n",
      "[22955]\teval-rmse:3.80604\ttrain-rmse:1.95974\n",
      "[22956]\teval-rmse:3.80663\ttrain-rmse:1.95971\n",
      "[22957]\teval-rmse:3.8082\ttrain-rmse:1.95965\n",
      "[22958]\teval-rmse:3.80856\ttrain-rmse:1.95964\n",
      "[22959]\teval-rmse:3.80757\ttrain-rmse:1.95967\n",
      "[22960]\teval-rmse:3.80629\ttrain-rmse:1.95973\n",
      "[22961]\teval-rmse:3.80796\ttrain-rmse:1.95966\n",
      "[22962]\teval-rmse:3.80961\ttrain-rmse:1.95962\n",
      "[22963]\teval-rmse:3.81122\ttrain-rmse:1.95956\n",
      "[22964]\teval-rmse:3.81235\ttrain-rmse:1.95953\n",
      "[22965]\teval-rmse:3.8118\ttrain-rmse:1.95954\n",
      "[22966]\teval-rmse:3.81317\ttrain-rmse:1.95951\n",
      "[22967]\teval-rmse:3.81374\ttrain-rmse:1.9595\n",
      "[22968]\teval-rmse:3.81328\ttrain-rmse:1.95951\n",
      "[22969]\teval-rmse:3.81209\ttrain-rmse:1.95954\n",
      "[22970]\teval-rmse:3.81108\ttrain-rmse:1.95956\n",
      "[22971]\teval-rmse:3.81135\ttrain-rmse:1.95955\n",
      "[22972]\teval-rmse:3.81001\ttrain-rmse:1.95959\n",
      "[22973]\teval-rmse:3.81054\ttrain-rmse:1.95957\n",
      "[22974]\teval-rmse:3.81192\ttrain-rmse:1.95955\n",
      "[22975]\teval-rmse:3.81071\ttrain-rmse:1.95957\n",
      "[22976]\teval-rmse:3.80942\ttrain-rmse:1.95961\n",
      "[22977]\teval-rmse:3.80893\ttrain-rmse:1.95962\n",
      "[22978]\teval-rmse:3.80998\ttrain-rmse:1.95959\n",
      "[22979]\teval-rmse:3.81033\ttrain-rmse:1.95958\n",
      "[22980]\teval-rmse:3.81006\ttrain-rmse:1.95958\n",
      "[22981]\teval-rmse:3.80991\ttrain-rmse:1.95959\n",
      "[22982]\teval-rmse:3.80863\ttrain-rmse:1.95964\n",
      "[22983]\teval-rmse:3.80934\ttrain-rmse:1.95962\n",
      "[22984]\teval-rmse:3.80834\ttrain-rmse:1.95965\n",
      "[22985]\teval-rmse:3.80974\ttrain-rmse:1.95961\n",
      "[22986]\teval-rmse:3.80997\ttrain-rmse:1.9596\n",
      "[22987]\teval-rmse:3.81054\ttrain-rmse:1.95959\n",
      "[22988]\teval-rmse:3.81216\ttrain-rmse:1.95956\n",
      "[22989]\teval-rmse:3.812\ttrain-rmse:1.95957\n",
      "[22990]\teval-rmse:3.81253\ttrain-rmse:1.95956\n",
      "[22991]\teval-rmse:3.811\ttrain-rmse:1.95958\n",
      "[22992]\teval-rmse:3.81072\ttrain-rmse:1.95951\n",
      "[22993]\teval-rmse:3.81208\ttrain-rmse:1.95949\n",
      "[22994]\teval-rmse:3.81295\ttrain-rmse:1.95948\n",
      "[22995]\teval-rmse:3.81267\ttrain-rmse:1.95941\n",
      "[22996]\teval-rmse:3.81348\ttrain-rmse:1.9594\n",
      "[22997]\teval-rmse:3.81259\ttrain-rmse:1.95941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22998]\teval-rmse:3.81417\ttrain-rmse:1.95939\n",
      "[22999]\teval-rmse:3.81538\ttrain-rmse:1.95939\n",
      "[23000]\teval-rmse:3.81662\ttrain-rmse:1.95939\n",
      "[23001]\teval-rmse:3.81679\ttrain-rmse:1.95939\n",
      "[23002]\teval-rmse:3.81708\ttrain-rmse:1.95939\n",
      "[23003]\teval-rmse:3.81879\ttrain-rmse:1.95936\n",
      "[23004]\teval-rmse:3.81715\ttrain-rmse:1.95935\n",
      "[23005]\teval-rmse:3.81534\ttrain-rmse:1.95935\n",
      "[23006]\teval-rmse:3.81481\ttrain-rmse:1.95936\n",
      "[23007]\teval-rmse:3.81536\ttrain-rmse:1.95935\n",
      "[23008]\teval-rmse:3.81453\ttrain-rmse:1.95936\n",
      "[23009]\teval-rmse:3.81391\ttrain-rmse:1.95937\n",
      "[23010]\teval-rmse:3.81431\ttrain-rmse:1.95936\n",
      "[23011]\teval-rmse:3.8162\ttrain-rmse:1.95934\n",
      "[23012]\teval-rmse:3.81589\ttrain-rmse:1.95934\n",
      "[23013]\teval-rmse:3.81544\ttrain-rmse:1.95935\n",
      "[23014]\teval-rmse:3.81734\ttrain-rmse:1.95933\n",
      "[23015]\teval-rmse:3.81855\ttrain-rmse:1.95933\n",
      "[23016]\teval-rmse:3.81809\ttrain-rmse:1.95933\n",
      "[23017]\teval-rmse:3.81876\ttrain-rmse:1.95934\n",
      "[23018]\teval-rmse:3.81956\ttrain-rmse:1.95934\n",
      "[23019]\teval-rmse:3.81751\ttrain-rmse:1.95934\n",
      "[23020]\teval-rmse:3.8172\ttrain-rmse:1.95934\n",
      "[23021]\teval-rmse:3.8186\ttrain-rmse:1.95934\n",
      "[23022]\teval-rmse:3.81754\ttrain-rmse:1.95935\n",
      "[23023]\teval-rmse:3.8191\ttrain-rmse:1.95935\n",
      "[23024]\teval-rmse:3.81964\ttrain-rmse:1.95935\n",
      "[23025]\teval-rmse:3.82152\ttrain-rmse:1.95935\n",
      "[23026]\teval-rmse:3.82204\ttrain-rmse:1.95935\n",
      "[23027]\teval-rmse:3.82156\ttrain-rmse:1.95935\n",
      "[23028]\teval-rmse:3.82109\ttrain-rmse:1.95934\n",
      "[23029]\teval-rmse:3.81918\ttrain-rmse:1.95934\n",
      "[23030]\teval-rmse:3.81958\ttrain-rmse:1.95934\n",
      "[23031]\teval-rmse:3.81817\ttrain-rmse:1.95935\n",
      "[23032]\teval-rmse:3.81759\ttrain-rmse:1.95936\n",
      "[23033]\teval-rmse:3.81706\ttrain-rmse:1.95936\n",
      "[23034]\teval-rmse:3.81548\ttrain-rmse:1.95937\n",
      "[23035]\teval-rmse:3.81602\ttrain-rmse:1.95937\n",
      "[23036]\teval-rmse:3.8174\ttrain-rmse:1.95937\n",
      "[23037]\teval-rmse:3.816\ttrain-rmse:1.95937\n",
      "[23038]\teval-rmse:3.81415\ttrain-rmse:1.95939\n",
      "[23039]\teval-rmse:3.81472\ttrain-rmse:1.95938\n",
      "[23040]\teval-rmse:3.81599\ttrain-rmse:1.95937\n",
      "[23041]\teval-rmse:3.8174\ttrain-rmse:1.95936\n",
      "[23042]\teval-rmse:3.81792\ttrain-rmse:1.95936\n",
      "[23043]\teval-rmse:3.81854\ttrain-rmse:1.95936\n",
      "[23044]\teval-rmse:3.81716\ttrain-rmse:1.95935\n",
      "[23045]\teval-rmse:3.81698\ttrain-rmse:1.95936\n",
      "[23046]\teval-rmse:3.81751\ttrain-rmse:1.95936\n",
      "[23047]\teval-rmse:3.81619\ttrain-rmse:1.95937\n",
      "[23048]\teval-rmse:3.8167\ttrain-rmse:1.95936\n",
      "[23049]\teval-rmse:3.81722\ttrain-rmse:1.95936\n",
      "[23050]\teval-rmse:3.81837\ttrain-rmse:1.95935\n",
      "[23051]\teval-rmse:3.81709\ttrain-rmse:1.95935\n",
      "[23052]\teval-rmse:3.81682\ttrain-rmse:1.95935\n",
      "[23053]\teval-rmse:3.81734\ttrain-rmse:1.95935\n",
      "[23054]\teval-rmse:3.8153\ttrain-rmse:1.95936\n",
      "[23055]\teval-rmse:3.81594\ttrain-rmse:1.95936\n",
      "[23056]\teval-rmse:3.81564\ttrain-rmse:1.95936\n",
      "[23057]\teval-rmse:3.81444\ttrain-rmse:1.95939\n",
      "[23058]\teval-rmse:3.81443\ttrain-rmse:1.95939\n",
      "[23059]\teval-rmse:3.81633\ttrain-rmse:1.95937\n",
      "[23060]\teval-rmse:3.81588\ttrain-rmse:1.95938\n",
      "[23061]\teval-rmse:3.81751\ttrain-rmse:1.95938\n",
      "[23062]\teval-rmse:3.81749\ttrain-rmse:1.95938\n",
      "[23063]\teval-rmse:3.81886\ttrain-rmse:1.95937\n",
      "[23064]\teval-rmse:3.82017\ttrain-rmse:1.95937\n",
      "[23065]\teval-rmse:3.82062\ttrain-rmse:1.95937\n",
      "[23066]\teval-rmse:3.81976\ttrain-rmse:1.95937\n",
      "[23067]\teval-rmse:3.82032\ttrain-rmse:1.95938\n",
      "[23068]\teval-rmse:3.81927\ttrain-rmse:1.95938\n",
      "[23069]\teval-rmse:3.82034\ttrain-rmse:1.95938\n",
      "[23070]\teval-rmse:3.82005\ttrain-rmse:1.95931\n",
      "[23071]\teval-rmse:3.8184\ttrain-rmse:1.95931\n",
      "[23072]\teval-rmse:3.81812\ttrain-rmse:1.95931\n",
      "[23073]\teval-rmse:3.81951\ttrain-rmse:1.95931\n",
      "[23074]\teval-rmse:3.81978\ttrain-rmse:1.95931\n",
      "[23075]\teval-rmse:3.82005\ttrain-rmse:1.95931\n",
      "[23076]\teval-rmse:3.82041\ttrain-rmse:1.95932\n",
      "[23077]\teval-rmse:3.82172\ttrain-rmse:1.95933\n",
      "[23078]\teval-rmse:3.82037\ttrain-rmse:1.95934\n",
      "[23079]\teval-rmse:3.82006\ttrain-rmse:1.95928\n",
      "[23080]\teval-rmse:3.81875\ttrain-rmse:1.95928\n",
      "[23081]\teval-rmse:3.81828\ttrain-rmse:1.95929\n",
      "[23082]\teval-rmse:3.81741\ttrain-rmse:1.95928\n",
      "[23083]\teval-rmse:3.8171\ttrain-rmse:1.95928\n",
      "[23084]\teval-rmse:3.81692\ttrain-rmse:1.95928\n",
      "[23085]\teval-rmse:3.81691\ttrain-rmse:1.95928\n",
      "[23086]\teval-rmse:3.81777\ttrain-rmse:1.95929\n",
      "[23087]\teval-rmse:3.81747\ttrain-rmse:1.95922\n",
      "[23088]\teval-rmse:3.81701\ttrain-rmse:1.95921\n",
      "[23089]\teval-rmse:3.81511\ttrain-rmse:1.95921\n",
      "[23090]\teval-rmse:3.81622\ttrain-rmse:1.95921\n",
      "[23091]\teval-rmse:3.81501\ttrain-rmse:1.95924\n",
      "[23092]\teval-rmse:3.81445\ttrain-rmse:1.95924\n",
      "[23093]\teval-rmse:3.81287\ttrain-rmse:1.95926\n",
      "[23094]\teval-rmse:3.8127\ttrain-rmse:1.95926\n",
      "[23095]\teval-rmse:3.81169\ttrain-rmse:1.95928\n",
      "[23096]\teval-rmse:3.81184\ttrain-rmse:1.95927\n",
      "[23097]\teval-rmse:3.81301\ttrain-rmse:1.95926\n",
      "[23098]\teval-rmse:3.81098\ttrain-rmse:1.95929\n",
      "[23099]\teval-rmse:3.81235\ttrain-rmse:1.95926\n",
      "[23100]\teval-rmse:3.81076\ttrain-rmse:1.95928\n",
      "[23101]\teval-rmse:3.81028\ttrain-rmse:1.95929\n",
      "[23102]\teval-rmse:3.80846\ttrain-rmse:1.95933\n",
      "[23103]\teval-rmse:3.80714\ttrain-rmse:1.95936\n",
      "[23104]\teval-rmse:3.80831\ttrain-rmse:1.95933\n",
      "[23105]\teval-rmse:3.80788\ttrain-rmse:1.95935\n",
      "[23106]\teval-rmse:3.80689\ttrain-rmse:1.95938\n",
      "[23107]\teval-rmse:3.80665\ttrain-rmse:1.95938\n",
      "[23108]\teval-rmse:3.80616\ttrain-rmse:1.95939\n",
      "[23109]\teval-rmse:3.80453\ttrain-rmse:1.95945\n",
      "[23110]\teval-rmse:3.80304\ttrain-rmse:1.95951\n",
      "[23111]\teval-rmse:3.80465\ttrain-rmse:1.95942\n",
      "[23112]\teval-rmse:3.80342\ttrain-rmse:1.95949\n",
      "[23113]\teval-rmse:3.80456\ttrain-rmse:1.95945\n",
      "[23114]\teval-rmse:3.80399\ttrain-rmse:1.95947\n",
      "[23115]\teval-rmse:3.80406\ttrain-rmse:1.95946\n",
      "[23116]\teval-rmse:3.80514\ttrain-rmse:1.95942\n",
      "[23117]\teval-rmse:3.80536\ttrain-rmse:1.95941\n",
      "[23118]\teval-rmse:3.80484\ttrain-rmse:1.95944\n",
      "[23119]\teval-rmse:3.80351\ttrain-rmse:1.95949\n",
      "[23120]\teval-rmse:3.8031\ttrain-rmse:1.95952\n",
      "[23121]\teval-rmse:3.80214\ttrain-rmse:1.95955\n",
      "[23122]\teval-rmse:3.80342\ttrain-rmse:1.9595\n",
      "[23123]\teval-rmse:3.80483\ttrain-rmse:1.95945\n",
      "[23124]\teval-rmse:3.80457\ttrain-rmse:1.95946\n",
      "[23125]\teval-rmse:3.80647\ttrain-rmse:1.9594\n",
      "[23126]\teval-rmse:3.80466\ttrain-rmse:1.95946\n",
      "[23127]\teval-rmse:3.80467\ttrain-rmse:1.95946\n",
      "[23128]\teval-rmse:3.80584\ttrain-rmse:1.95942\n",
      "[23129]\teval-rmse:3.80712\ttrain-rmse:1.95937\n",
      "[23130]\teval-rmse:3.80669\ttrain-rmse:1.95939\n",
      "[23131]\teval-rmse:3.80722\ttrain-rmse:1.95938\n",
      "[23132]\teval-rmse:3.80699\ttrain-rmse:1.95938\n",
      "[23133]\teval-rmse:3.80736\ttrain-rmse:1.95937\n",
      "[23134]\teval-rmse:3.80676\ttrain-rmse:1.95939\n",
      "[23135]\teval-rmse:3.80719\ttrain-rmse:1.95938\n",
      "[23136]\teval-rmse:3.80885\ttrain-rmse:1.95934\n",
      "[23137]\teval-rmse:3.80701\ttrain-rmse:1.95938\n",
      "[23138]\teval-rmse:3.80569\ttrain-rmse:1.95943\n",
      "[23139]\teval-rmse:3.80424\ttrain-rmse:1.95948\n",
      "[23140]\teval-rmse:3.80401\ttrain-rmse:1.95949\n",
      "[23141]\teval-rmse:3.80425\ttrain-rmse:1.95948\n",
      "[23142]\teval-rmse:3.80591\ttrain-rmse:1.95942\n",
      "[23143]\teval-rmse:3.80431\ttrain-rmse:1.95948\n",
      "[23144]\teval-rmse:3.80299\ttrain-rmse:1.95954\n",
      "[23145]\teval-rmse:3.80435\ttrain-rmse:1.95948\n",
      "[23146]\teval-rmse:3.80396\ttrain-rmse:1.9595\n",
      "[23147]\teval-rmse:3.80354\ttrain-rmse:1.95952\n",
      "[23148]\teval-rmse:3.8033\ttrain-rmse:1.95945\n",
      "[23149]\teval-rmse:3.80307\ttrain-rmse:1.95946\n",
      "[23150]\teval-rmse:3.80266\ttrain-rmse:1.95948\n",
      "[23151]\teval-rmse:3.80153\ttrain-rmse:1.95954\n",
      "[23152]\teval-rmse:3.80072\ttrain-rmse:1.95958\n",
      "[23153]\teval-rmse:3.80207\ttrain-rmse:1.95952\n",
      "[23154]\teval-rmse:3.80397\ttrain-rmse:1.95945\n",
      "[23155]\teval-rmse:3.80267\ttrain-rmse:1.95949\n",
      "[23156]\teval-rmse:3.8035\ttrain-rmse:1.95946\n",
      "[23157]\teval-rmse:3.80269\ttrain-rmse:1.95949\n",
      "[23158]\teval-rmse:3.80247\ttrain-rmse:1.95949\n",
      "[23159]\teval-rmse:3.80201\ttrain-rmse:1.95952\n",
      "[23160]\teval-rmse:3.80313\ttrain-rmse:1.95947\n",
      "[23161]\teval-rmse:3.80423\ttrain-rmse:1.95943\n",
      "[23162]\teval-rmse:3.804\ttrain-rmse:1.95944\n",
      "[23163]\teval-rmse:3.80349\ttrain-rmse:1.95946\n",
      "[23164]\teval-rmse:3.8022\ttrain-rmse:1.95951\n",
      "[23165]\teval-rmse:3.80361\ttrain-rmse:1.95945\n",
      "[23166]\teval-rmse:3.80393\ttrain-rmse:1.95944\n",
      "[23167]\teval-rmse:3.80296\ttrain-rmse:1.95948\n",
      "[23168]\teval-rmse:3.80353\ttrain-rmse:1.95946\n",
      "[23169]\teval-rmse:3.80207\ttrain-rmse:1.95951\n",
      "[23170]\teval-rmse:3.8024\ttrain-rmse:1.9595\n",
      "[23171]\teval-rmse:3.80118\ttrain-rmse:1.95957\n",
      "[23172]\teval-rmse:3.80136\ttrain-rmse:1.95956\n",
      "[23173]\teval-rmse:3.80134\ttrain-rmse:1.95956\n",
      "[23174]\teval-rmse:3.80122\ttrain-rmse:1.95957\n",
      "[23175]\teval-rmse:3.80284\ttrain-rmse:1.95947\n",
      "[23176]\teval-rmse:3.80238\ttrain-rmse:1.95949\n",
      "[23177]\teval-rmse:3.80226\ttrain-rmse:1.95949\n",
      "[23178]\teval-rmse:3.80416\ttrain-rmse:1.95942\n",
      "[23179]\teval-rmse:3.80241\ttrain-rmse:1.95949\n",
      "[23180]\teval-rmse:3.80302\ttrain-rmse:1.95946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23181]\teval-rmse:3.80356\ttrain-rmse:1.95944\n",
      "[23182]\teval-rmse:3.80278\ttrain-rmse:1.95947\n",
      "[23183]\teval-rmse:3.80295\ttrain-rmse:1.95947\n",
      "[23184]\teval-rmse:3.80274\ttrain-rmse:1.95947\n",
      "[23185]\teval-rmse:3.80143\ttrain-rmse:1.95953\n",
      "[23186]\teval-rmse:3.8014\ttrain-rmse:1.95953\n",
      "[23187]\teval-rmse:3.80094\ttrain-rmse:1.95955\n",
      "[23188]\teval-rmse:3.79938\ttrain-rmse:1.95963\n",
      "[23189]\teval-rmse:3.79794\ttrain-rmse:1.95971\n",
      "[23190]\teval-rmse:3.79651\ttrain-rmse:1.95979\n",
      "[23191]\teval-rmse:3.795\ttrain-rmse:1.95989\n",
      "[23192]\teval-rmse:3.79642\ttrain-rmse:1.9598\n",
      "[23193]\teval-rmse:3.79579\ttrain-rmse:1.95984\n",
      "[23194]\teval-rmse:3.79637\ttrain-rmse:1.9598\n",
      "[23195]\teval-rmse:3.79545\ttrain-rmse:1.95985\n",
      "[23196]\teval-rmse:3.79597\ttrain-rmse:1.95982\n",
      "[23197]\teval-rmse:3.79424\ttrain-rmse:1.95994\n",
      "[23198]\teval-rmse:3.79307\ttrain-rmse:1.96002\n",
      "[23199]\teval-rmse:3.79186\ttrain-rmse:1.96012\n",
      "[23200]\teval-rmse:3.79169\ttrain-rmse:1.96012\n",
      "[23201]\teval-rmse:3.79063\ttrain-rmse:1.96021\n",
      "[23202]\teval-rmse:3.78948\ttrain-rmse:1.96031\n",
      "[23203]\teval-rmse:3.78984\ttrain-rmse:1.96028\n",
      "[23204]\teval-rmse:3.79125\ttrain-rmse:1.96016\n",
      "[23205]\teval-rmse:3.79012\ttrain-rmse:1.96025\n",
      "[23206]\teval-rmse:3.79149\ttrain-rmse:1.96013\n",
      "[23207]\teval-rmse:3.79314\ttrain-rmse:1.96001\n",
      "[23208]\teval-rmse:3.79294\ttrain-rmse:1.96002\n",
      "[23209]\teval-rmse:3.79275\ttrain-rmse:1.96003\n",
      "[23210]\teval-rmse:3.79411\ttrain-rmse:1.95993\n",
      "[23211]\teval-rmse:3.79584\ttrain-rmse:1.95981\n",
      "[23212]\teval-rmse:3.79531\ttrain-rmse:1.95984\n",
      "[23213]\teval-rmse:3.79634\ttrain-rmse:1.95978\n",
      "[23214]\teval-rmse:3.79663\ttrain-rmse:1.95976\n",
      "[23215]\teval-rmse:3.79615\ttrain-rmse:1.95979\n",
      "[23216]\teval-rmse:3.7957\ttrain-rmse:1.95981\n",
      "[23217]\teval-rmse:3.7961\ttrain-rmse:1.95979\n",
      "[23218]\teval-rmse:3.796\ttrain-rmse:1.9598\n",
      "[23219]\teval-rmse:3.79661\ttrain-rmse:1.95976\n",
      "[23220]\teval-rmse:3.79503\ttrain-rmse:1.95986\n",
      "[23221]\teval-rmse:3.79494\ttrain-rmse:1.95987\n",
      "[23222]\teval-rmse:3.79531\ttrain-rmse:1.95984\n",
      "[23223]\teval-rmse:3.79454\ttrain-rmse:1.95989\n",
      "[23224]\teval-rmse:3.79617\ttrain-rmse:1.95979\n",
      "[23225]\teval-rmse:3.79598\ttrain-rmse:1.9598\n",
      "[23226]\teval-rmse:3.79521\ttrain-rmse:1.95985\n",
      "[23227]\teval-rmse:3.79468\ttrain-rmse:1.95988\n",
      "[23228]\teval-rmse:3.79324\ttrain-rmse:1.95999\n",
      "[23229]\teval-rmse:3.79273\ttrain-rmse:1.96003\n",
      "[23230]\teval-rmse:3.79308\ttrain-rmse:1.96\n",
      "[23231]\teval-rmse:3.79262\ttrain-rmse:1.96004\n",
      "[23232]\teval-rmse:3.79376\ttrain-rmse:1.95995\n",
      "[23233]\teval-rmse:3.79255\ttrain-rmse:1.96004\n",
      "[23234]\teval-rmse:3.79148\ttrain-rmse:1.96013\n",
      "[23235]\teval-rmse:3.79288\ttrain-rmse:1.96003\n",
      "[23236]\teval-rmse:3.79451\ttrain-rmse:1.9599\n",
      "[23237]\teval-rmse:3.79404\ttrain-rmse:1.95993\n",
      "[23238]\teval-rmse:3.79312\ttrain-rmse:1.95998\n",
      "[23239]\teval-rmse:3.79138\ttrain-rmse:1.96011\n",
      "[23240]\teval-rmse:3.78992\ttrain-rmse:1.96023\n",
      "[23241]\teval-rmse:3.78804\ttrain-rmse:1.96037\n",
      "[23242]\teval-rmse:3.78832\ttrain-rmse:1.96035\n",
      "[23243]\teval-rmse:3.79023\ttrain-rmse:1.96022\n",
      "[23244]\teval-rmse:3.79044\ttrain-rmse:1.9602\n",
      "[23245]\teval-rmse:3.79096\ttrain-rmse:1.96016\n",
      "[23246]\teval-rmse:3.79041\ttrain-rmse:1.9602\n",
      "[23247]\teval-rmse:3.78914\ttrain-rmse:1.96032\n",
      "[23248]\teval-rmse:3.79088\ttrain-rmse:1.96016\n",
      "[23249]\teval-rmse:3.78942\ttrain-rmse:1.96028\n",
      "[23250]\teval-rmse:3.78869\ttrain-rmse:1.96036\n",
      "[23251]\teval-rmse:3.79011\ttrain-rmse:1.96023\n",
      "[23252]\teval-rmse:3.78971\ttrain-rmse:1.96027\n",
      "[23253]\teval-rmse:3.78964\ttrain-rmse:1.96027\n",
      "[23254]\teval-rmse:3.79104\ttrain-rmse:1.96015\n",
      "[23255]\teval-rmse:3.79087\ttrain-rmse:1.96016\n",
      "[23256]\teval-rmse:3.7912\ttrain-rmse:1.96013\n",
      "[23257]\teval-rmse:3.79311\ttrain-rmse:1.96002\n",
      "[23258]\teval-rmse:3.79349\ttrain-rmse:1.95999\n",
      "[23259]\teval-rmse:3.79258\ttrain-rmse:1.96004\n",
      "[23260]\teval-rmse:3.7925\ttrain-rmse:1.96005\n",
      "[23261]\teval-rmse:3.79109\ttrain-rmse:1.96017\n",
      "[23262]\teval-rmse:3.7917\ttrain-rmse:1.96012\n",
      "[23263]\teval-rmse:3.79326\ttrain-rmse:1.96\n",
      "[23264]\teval-rmse:3.79255\ttrain-rmse:1.96006\n",
      "[23265]\teval-rmse:3.79247\ttrain-rmse:1.96007\n",
      "[23266]\teval-rmse:3.79389\ttrain-rmse:1.95995\n",
      "[23267]\teval-rmse:3.79348\ttrain-rmse:1.95998\n",
      "[23268]\teval-rmse:3.79304\ttrain-rmse:1.96001\n",
      "[23269]\teval-rmse:3.79439\ttrain-rmse:1.95991\n",
      "[23270]\teval-rmse:3.7932\ttrain-rmse:1.95999\n",
      "[23271]\teval-rmse:3.79479\ttrain-rmse:1.95988\n",
      "[23272]\teval-rmse:3.79533\ttrain-rmse:1.95984\n",
      "[23273]\teval-rmse:3.7954\ttrain-rmse:1.95983\n",
      "[23274]\teval-rmse:3.79664\ttrain-rmse:1.95975\n",
      "[23275]\teval-rmse:3.79803\ttrain-rmse:1.95966\n",
      "[23276]\teval-rmse:3.79656\ttrain-rmse:1.95977\n",
      "[23277]\teval-rmse:3.79658\ttrain-rmse:1.95976\n",
      "[23278]\teval-rmse:3.79697\ttrain-rmse:1.95974\n",
      "[23279]\teval-rmse:3.79738\ttrain-rmse:1.95971\n",
      "[23280]\teval-rmse:3.7961\ttrain-rmse:1.9598\n",
      "[23281]\teval-rmse:3.79638\ttrain-rmse:1.95978\n",
      "[23282]\teval-rmse:3.79546\ttrain-rmse:1.95982\n",
      "[23283]\teval-rmse:3.79614\ttrain-rmse:1.95978\n",
      "[23284]\teval-rmse:3.79594\ttrain-rmse:1.95979\n",
      "[23285]\teval-rmse:3.79446\ttrain-rmse:1.95989\n",
      "[23286]\teval-rmse:3.79404\ttrain-rmse:1.95992\n",
      "[23287]\teval-rmse:3.79361\ttrain-rmse:1.95995\n",
      "[23288]\teval-rmse:3.79526\ttrain-rmse:1.95982\n",
      "[23289]\teval-rmse:3.79688\ttrain-rmse:1.9597\n",
      "[23290]\teval-rmse:3.79494\ttrain-rmse:1.95983\n",
      "[23291]\teval-rmse:3.79597\ttrain-rmse:1.95975\n",
      "[23292]\teval-rmse:3.79535\ttrain-rmse:1.9598\n",
      "[23293]\teval-rmse:3.79527\ttrain-rmse:1.9598\n",
      "[23294]\teval-rmse:3.79506\ttrain-rmse:1.95973\n",
      "[23295]\teval-rmse:3.79504\ttrain-rmse:1.95973\n",
      "[23296]\teval-rmse:3.79378\ttrain-rmse:1.95982\n",
      "[23297]\teval-rmse:3.7952\ttrain-rmse:1.95972\n",
      "[23298]\teval-rmse:3.79659\ttrain-rmse:1.95962\n",
      "[23299]\teval-rmse:3.79567\ttrain-rmse:1.95966\n",
      "[23300]\teval-rmse:3.79423\ttrain-rmse:1.95976\n",
      "[23301]\teval-rmse:3.79406\ttrain-rmse:1.95969\n",
      "[23302]\teval-rmse:3.79388\ttrain-rmse:1.9597\n",
      "[23303]\teval-rmse:3.79368\ttrain-rmse:1.95971\n",
      "[23304]\teval-rmse:3.79542\ttrain-rmse:1.95958\n",
      "[23305]\teval-rmse:3.794\ttrain-rmse:1.95967\n",
      "[23306]\teval-rmse:3.79557\ttrain-rmse:1.95956\n",
      "[23307]\teval-rmse:3.79465\ttrain-rmse:1.95961\n",
      "[23308]\teval-rmse:3.79515\ttrain-rmse:1.95958\n",
      "[23309]\teval-rmse:3.79494\ttrain-rmse:1.95959\n",
      "[23310]\teval-rmse:3.79562\ttrain-rmse:1.95954\n",
      "[23311]\teval-rmse:3.79526\ttrain-rmse:1.95957\n",
      "[23312]\teval-rmse:3.79486\ttrain-rmse:1.9596\n",
      "[23313]\teval-rmse:3.79308\ttrain-rmse:1.95974\n",
      "[23314]\teval-rmse:3.79366\ttrain-rmse:1.9597\n",
      "[23315]\teval-rmse:3.79401\ttrain-rmse:1.95967\n",
      "[23316]\teval-rmse:3.79383\ttrain-rmse:1.95968\n",
      "[23317]\teval-rmse:3.7933\ttrain-rmse:1.95972\n",
      "[23318]\teval-rmse:3.79469\ttrain-rmse:1.95962\n",
      "[23319]\teval-rmse:3.79328\ttrain-rmse:1.95973\n",
      "[23320]\teval-rmse:3.7936\ttrain-rmse:1.9597\n",
      "[23321]\teval-rmse:3.79382\ttrain-rmse:1.95969\n",
      "[23322]\teval-rmse:3.79386\ttrain-rmse:1.95968\n",
      "[23323]\teval-rmse:3.79317\ttrain-rmse:1.95973\n",
      "[23324]\teval-rmse:3.79384\ttrain-rmse:1.95968\n",
      "[23325]\teval-rmse:3.79375\ttrain-rmse:1.95969\n",
      "[23326]\teval-rmse:3.79338\ttrain-rmse:1.95972\n",
      "[23327]\teval-rmse:3.79247\ttrain-rmse:1.95977\n",
      "[23328]\teval-rmse:3.79339\ttrain-rmse:1.9597\n",
      "[23329]\teval-rmse:3.79359\ttrain-rmse:1.95969\n",
      "[23330]\teval-rmse:3.79316\ttrain-rmse:1.95972\n",
      "[23331]\teval-rmse:3.79296\ttrain-rmse:1.95973\n",
      "[23332]\teval-rmse:3.79259\ttrain-rmse:1.95975\n",
      "[23333]\teval-rmse:3.79208\ttrain-rmse:1.95979\n",
      "[23334]\teval-rmse:3.79246\ttrain-rmse:1.95976\n",
      "[23335]\teval-rmse:3.79095\ttrain-rmse:1.95988\n",
      "[23336]\teval-rmse:3.78971\ttrain-rmse:1.95997\n",
      "[23337]\teval-rmse:3.78853\ttrain-rmse:1.96008\n",
      "[23338]\teval-rmse:3.78703\ttrain-rmse:1.96022\n",
      "[23339]\teval-rmse:3.78639\ttrain-rmse:1.96029\n",
      "[23340]\teval-rmse:3.78795\ttrain-rmse:1.96015\n",
      "[23341]\teval-rmse:3.78647\ttrain-rmse:1.96029\n",
      "[23342]\teval-rmse:3.78683\ttrain-rmse:1.96025\n",
      "[23343]\teval-rmse:3.78808\ttrain-rmse:1.96014\n",
      "[23344]\teval-rmse:3.7895\ttrain-rmse:1.96002\n",
      "[23345]\teval-rmse:3.78882\ttrain-rmse:1.96007\n",
      "[23346]\teval-rmse:3.78876\ttrain-rmse:1.96008\n",
      "[23347]\teval-rmse:3.78788\ttrain-rmse:1.96014\n",
      "[23348]\teval-rmse:3.78683\ttrain-rmse:1.96023\n",
      "[23349]\teval-rmse:3.78642\ttrain-rmse:1.96027\n",
      "[23350]\teval-rmse:3.78816\ttrain-rmse:1.96011\n",
      "[23351]\teval-rmse:3.78958\ttrain-rmse:1.96\n",
      "[23352]\teval-rmse:3.78816\ttrain-rmse:1.96013\n",
      "[23353]\teval-rmse:3.78843\ttrain-rmse:1.9601\n",
      "[23354]\teval-rmse:3.78692\ttrain-rmse:1.96025\n",
      "[23355]\teval-rmse:3.78686\ttrain-rmse:1.96025\n",
      "[23356]\teval-rmse:3.78534\ttrain-rmse:1.96042\n",
      "[23357]\teval-rmse:3.78518\ttrain-rmse:1.96043\n",
      "[23358]\teval-rmse:3.78371\ttrain-rmse:1.96057\n",
      "[23359]\teval-rmse:3.78258\ttrain-rmse:1.96069\n",
      "[23360]\teval-rmse:3.78148\ttrain-rmse:1.96081\n",
      "[23361]\teval-rmse:3.78112\ttrain-rmse:1.96085\n",
      "[23362]\teval-rmse:3.78028\ttrain-rmse:1.96092\n",
      "[23363]\teval-rmse:3.77987\ttrain-rmse:1.96097\n",
      "[23364]\teval-rmse:3.77956\ttrain-rmse:1.961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23365]\teval-rmse:3.77873\ttrain-rmse:1.96107\n",
      "[23366]\teval-rmse:3.77842\ttrain-rmse:1.96111\n",
      "[23367]\teval-rmse:3.77872\ttrain-rmse:1.96107\n",
      "[23368]\teval-rmse:3.77929\ttrain-rmse:1.961\n",
      "[23369]\teval-rmse:3.77999\ttrain-rmse:1.96091\n",
      "[23370]\teval-rmse:3.78094\ttrain-rmse:1.96081\n",
      "[23371]\teval-rmse:3.7796\ttrain-rmse:1.96096\n",
      "[23372]\teval-rmse:3.77855\ttrain-rmse:1.96109\n",
      "[23373]\teval-rmse:3.77981\ttrain-rmse:1.96092\n",
      "[23374]\teval-rmse:3.77847\ttrain-rmse:1.96108\n",
      "[23375]\teval-rmse:3.77834\ttrain-rmse:1.96108\n",
      "[23376]\teval-rmse:3.77852\ttrain-rmse:1.96106\n",
      "[23377]\teval-rmse:3.77815\ttrain-rmse:1.96111\n",
      "[23378]\teval-rmse:3.77989\ttrain-rmse:1.9609\n",
      "[23379]\teval-rmse:3.77977\ttrain-rmse:1.96091\n",
      "[23380]\teval-rmse:3.78168\ttrain-rmse:1.96074\n",
      "[23381]\teval-rmse:3.78302\ttrain-rmse:1.96059\n",
      "[23382]\teval-rmse:3.78286\ttrain-rmse:1.96052\n",
      "[23383]\teval-rmse:3.78426\ttrain-rmse:1.96038\n",
      "[23384]\teval-rmse:3.78323\ttrain-rmse:1.96048\n",
      "[23385]\teval-rmse:3.78214\ttrain-rmse:1.96059\n",
      "[23386]\teval-rmse:3.78236\ttrain-rmse:1.96057\n",
      "[23387]\teval-rmse:3.78297\ttrain-rmse:1.9605\n",
      "[23388]\teval-rmse:3.78322\ttrain-rmse:1.96048\n",
      "[23389]\teval-rmse:3.78211\ttrain-rmse:1.96059\n",
      "[23390]\teval-rmse:3.78146\ttrain-rmse:1.96066\n",
      "[23391]\teval-rmse:3.78114\ttrain-rmse:1.96069\n",
      "[23392]\teval-rmse:3.78083\ttrain-rmse:1.96073\n",
      "[23393]\teval-rmse:3.78107\ttrain-rmse:1.9607\n",
      "[23394]\teval-rmse:3.7817\ttrain-rmse:1.96063\n",
      "[23395]\teval-rmse:3.78069\ttrain-rmse:1.96074\n",
      "[23396]\teval-rmse:3.78141\ttrain-rmse:1.96066\n",
      "[23397]\teval-rmse:3.78175\ttrain-rmse:1.96062\n",
      "[23398]\teval-rmse:3.78041\ttrain-rmse:1.96076\n",
      "[23399]\teval-rmse:3.77898\ttrain-rmse:1.96094\n",
      "[23400]\teval-rmse:3.77755\ttrain-rmse:1.9611\n",
      "[23401]\teval-rmse:3.77827\ttrain-rmse:1.96102\n",
      "[23402]\teval-rmse:3.7774\ttrain-rmse:1.96113\n",
      "[23403]\teval-rmse:3.77766\ttrain-rmse:1.9611\n",
      "[23404]\teval-rmse:3.7786\ttrain-rmse:1.96098\n",
      "[23405]\teval-rmse:3.77969\ttrain-rmse:1.96086\n",
      "[23406]\teval-rmse:3.77836\ttrain-rmse:1.96101\n",
      "[23407]\teval-rmse:3.77893\ttrain-rmse:1.96094\n",
      "[23408]\teval-rmse:3.78057\ttrain-rmse:1.96075\n",
      "[23409]\teval-rmse:3.78248\ttrain-rmse:1.96059\n",
      "[23410]\teval-rmse:3.78384\ttrain-rmse:1.96044\n",
      "[23411]\teval-rmse:3.78299\ttrain-rmse:1.9605\n",
      "[23412]\teval-rmse:3.7836\ttrain-rmse:1.96044\n",
      "[23413]\teval-rmse:3.78422\ttrain-rmse:1.96038\n",
      "[23414]\teval-rmse:3.78563\ttrain-rmse:1.96024\n",
      "[23415]\teval-rmse:3.7861\ttrain-rmse:1.9602\n",
      "[23416]\teval-rmse:3.78636\ttrain-rmse:1.96017\n",
      "[23417]\teval-rmse:3.7881\ttrain-rmse:1.96001\n",
      "[23418]\teval-rmse:3.78968\ttrain-rmse:1.95987\n",
      "[23419]\teval-rmse:3.7916\ttrain-rmse:1.95975\n",
      "[23420]\teval-rmse:3.79324\ttrain-rmse:1.95961\n",
      "[23421]\teval-rmse:3.7913\ttrain-rmse:1.95975\n",
      "[23422]\teval-rmse:3.79207\ttrain-rmse:1.95969\n",
      "[23423]\teval-rmse:3.79321\ttrain-rmse:1.95961\n",
      "[23424]\teval-rmse:3.79477\ttrain-rmse:1.9595\n",
      "[23425]\teval-rmse:3.79302\ttrain-rmse:1.95963\n",
      "[23426]\teval-rmse:3.79282\ttrain-rmse:1.95964\n",
      "[23427]\teval-rmse:3.79286\ttrain-rmse:1.95964\n",
      "[23428]\teval-rmse:3.79427\ttrain-rmse:1.95954\n",
      "[23429]\teval-rmse:3.79386\ttrain-rmse:1.95957\n",
      "[23430]\teval-rmse:3.79239\ttrain-rmse:1.95969\n",
      "[23431]\teval-rmse:3.79264\ttrain-rmse:1.95967\n",
      "[23432]\teval-rmse:3.79289\ttrain-rmse:1.95965\n",
      "[23433]\teval-rmse:3.79347\ttrain-rmse:1.95961\n",
      "[23434]\teval-rmse:3.79223\ttrain-rmse:1.9597\n",
      "[23435]\teval-rmse:3.79206\ttrain-rmse:1.95971\n",
      "[23436]\teval-rmse:3.7924\ttrain-rmse:1.95968\n",
      "[23437]\teval-rmse:3.79224\ttrain-rmse:1.95961\n",
      "[23438]\teval-rmse:3.79248\ttrain-rmse:1.95959\n",
      "[23439]\teval-rmse:3.79158\ttrain-rmse:1.95965\n",
      "[23440]\teval-rmse:3.79188\ttrain-rmse:1.95962\n",
      "[23441]\teval-rmse:3.79172\ttrain-rmse:1.95956\n",
      "[23442]\teval-rmse:3.79307\ttrain-rmse:1.95945\n",
      "[23443]\teval-rmse:3.79188\ttrain-rmse:1.95954\n",
      "[23444]\teval-rmse:3.79214\ttrain-rmse:1.95952\n",
      "[23445]\teval-rmse:3.79305\ttrain-rmse:1.95945\n",
      "[23446]\teval-rmse:3.79258\ttrain-rmse:1.95949\n",
      "[23447]\teval-rmse:3.79214\ttrain-rmse:1.95952\n",
      "[23448]\teval-rmse:3.79249\ttrain-rmse:1.95949\n",
      "[23449]\teval-rmse:3.79379\ttrain-rmse:1.9594\n",
      "[23450]\teval-rmse:3.79188\ttrain-rmse:1.95953\n",
      "[23451]\teval-rmse:3.79221\ttrain-rmse:1.9595\n",
      "[23452]\teval-rmse:3.79312\ttrain-rmse:1.95943\n",
      "[23453]\teval-rmse:3.79243\ttrain-rmse:1.95948\n",
      "[23454]\teval-rmse:3.79223\ttrain-rmse:1.9594\n",
      "[23455]\teval-rmse:3.79373\ttrain-rmse:1.9593\n",
      "[23456]\teval-rmse:3.79194\ttrain-rmse:1.95943\n",
      "[23457]\teval-rmse:3.7904\ttrain-rmse:1.95956\n",
      "[23458]\teval-rmse:3.79025\ttrain-rmse:1.95948\n",
      "[23459]\teval-rmse:3.79052\ttrain-rmse:1.95946\n",
      "[23460]\teval-rmse:3.7888\ttrain-rmse:1.95959\n",
      "[23461]\teval-rmse:3.78873\ttrain-rmse:1.9596\n",
      "[23462]\teval-rmse:3.78833\ttrain-rmse:1.95963\n",
      "[23463]\teval-rmse:3.79007\ttrain-rmse:1.95949\n",
      "[23464]\teval-rmse:3.7899\ttrain-rmse:1.9595\n",
      "[23465]\teval-rmse:3.79128\ttrain-rmse:1.95939\n",
      "[23466]\teval-rmse:3.79301\ttrain-rmse:1.95925\n",
      "[23467]\teval-rmse:3.79142\ttrain-rmse:1.95936\n",
      "[23468]\teval-rmse:3.79267\ttrain-rmse:1.95928\n",
      "[23469]\teval-rmse:3.79373\ttrain-rmse:1.9592\n",
      "[23470]\teval-rmse:3.79355\ttrain-rmse:1.95921\n",
      "[23471]\teval-rmse:3.7921\ttrain-rmse:1.95931\n",
      "[23472]\teval-rmse:3.79092\ttrain-rmse:1.95941\n",
      "[23473]\teval-rmse:3.7915\ttrain-rmse:1.95937\n",
      "[23474]\teval-rmse:3.79104\ttrain-rmse:1.9594\n",
      "[23475]\teval-rmse:3.78948\ttrain-rmse:1.95952\n",
      "[23476]\teval-rmse:3.79105\ttrain-rmse:1.9594\n",
      "[23477]\teval-rmse:3.78965\ttrain-rmse:1.95951\n",
      "[23478]\teval-rmse:3.79129\ttrain-rmse:1.95938\n",
      "[23479]\teval-rmse:3.79007\ttrain-rmse:1.95948\n",
      "[23480]\teval-rmse:3.78991\ttrain-rmse:1.95949\n",
      "[23481]\teval-rmse:3.78972\ttrain-rmse:1.9595\n",
      "[23482]\teval-rmse:3.78996\ttrain-rmse:1.95948\n",
      "[23483]\teval-rmse:3.78907\ttrain-rmse:1.95954\n",
      "[23484]\teval-rmse:3.78867\ttrain-rmse:1.95957\n",
      "[23485]\teval-rmse:3.7885\ttrain-rmse:1.95958\n",
      "[23486]\teval-rmse:3.79023\ttrain-rmse:1.95943\n",
      "[23487]\teval-rmse:3.7883\ttrain-rmse:1.95958\n",
      "[23488]\teval-rmse:3.78916\ttrain-rmse:1.95951\n",
      "[23489]\teval-rmse:3.78776\ttrain-rmse:1.95963\n",
      "[23490]\teval-rmse:3.78624\ttrain-rmse:1.95978\n",
      "[23491]\teval-rmse:3.78793\ttrain-rmse:1.95962\n",
      "[23492]\teval-rmse:3.78793\ttrain-rmse:1.95962\n",
      "[23493]\teval-rmse:3.78904\ttrain-rmse:1.95951\n",
      "[23494]\teval-rmse:3.78963\ttrain-rmse:1.95947\n",
      "[23495]\teval-rmse:3.78999\ttrain-rmse:1.95944\n",
      "[23496]\teval-rmse:3.78911\ttrain-rmse:1.95949\n",
      "[23497]\teval-rmse:3.79019\ttrain-rmse:1.9594\n",
      "[23498]\teval-rmse:3.79004\ttrain-rmse:1.95933\n",
      "[23499]\teval-rmse:3.78862\ttrain-rmse:1.95945\n",
      "[23500]\teval-rmse:3.78713\ttrain-rmse:1.95958\n",
      "[23501]\teval-rmse:3.78804\ttrain-rmse:1.9595\n",
      "[23502]\teval-rmse:3.78829\ttrain-rmse:1.95948\n",
      "[23503]\teval-rmse:3.78811\ttrain-rmse:1.95941\n",
      "[23504]\teval-rmse:3.78817\ttrain-rmse:1.95941\n",
      "[23505]\teval-rmse:3.78881\ttrain-rmse:1.95935\n",
      "[23506]\teval-rmse:3.78874\ttrain-rmse:1.95936\n",
      "[23507]\teval-rmse:3.78759\ttrain-rmse:1.95946\n",
      "[23508]\teval-rmse:3.78742\ttrain-rmse:1.95947\n",
      "[23509]\teval-rmse:3.78874\ttrain-rmse:1.95936\n",
      "[23510]\teval-rmse:3.78991\ttrain-rmse:1.95927\n",
      "[23511]\teval-rmse:3.79026\ttrain-rmse:1.95924\n",
      "[23512]\teval-rmse:3.78876\ttrain-rmse:1.95935\n",
      "[23513]\teval-rmse:3.78761\ttrain-rmse:1.95945\n",
      "[23514]\teval-rmse:3.78897\ttrain-rmse:1.95934\n",
      "[23515]\teval-rmse:3.78931\ttrain-rmse:1.95931\n",
      "[23516]\teval-rmse:3.78924\ttrain-rmse:1.95931\n",
      "[23517]\teval-rmse:3.78835\ttrain-rmse:1.95937\n",
      "[23518]\teval-rmse:3.78888\ttrain-rmse:1.95933\n",
      "[23519]\teval-rmse:3.7891\ttrain-rmse:1.95932\n",
      "[23520]\teval-rmse:3.78869\ttrain-rmse:1.95935\n",
      "[23521]\teval-rmse:3.78754\ttrain-rmse:1.95944\n",
      "[23522]\teval-rmse:3.78813\ttrain-rmse:1.9594\n",
      "[23523]\teval-rmse:3.78806\ttrain-rmse:1.9594\n",
      "[23524]\teval-rmse:3.78938\ttrain-rmse:1.9593\n",
      "[23525]\teval-rmse:3.79088\ttrain-rmse:1.95921\n",
      "[23526]\teval-rmse:3.79007\ttrain-rmse:1.95926\n",
      "[23527]\teval-rmse:3.78886\ttrain-rmse:1.95935\n",
      "[23528]\teval-rmse:3.78868\ttrain-rmse:1.95936\n",
      "[23529]\teval-rmse:3.78832\ttrain-rmse:1.95939\n",
      "[23530]\teval-rmse:3.78677\ttrain-rmse:1.95951\n",
      "[23531]\teval-rmse:3.78763\ttrain-rmse:1.95945\n",
      "[23532]\teval-rmse:3.78926\ttrain-rmse:1.95932\n",
      "[23533]\teval-rmse:3.78803\ttrain-rmse:1.95942\n",
      "[23534]\teval-rmse:3.78861\ttrain-rmse:1.95938\n",
      "[23535]\teval-rmse:3.79017\ttrain-rmse:1.95925\n",
      "[23536]\teval-rmse:3.78966\ttrain-rmse:1.95929\n",
      "[23537]\teval-rmse:3.78952\ttrain-rmse:1.95922\n",
      "[23538]\teval-rmse:3.7911\ttrain-rmse:1.95911\n",
      "[23539]\teval-rmse:3.79034\ttrain-rmse:1.95916\n",
      "[23540]\teval-rmse:3.79085\ttrain-rmse:1.95913\n",
      "[23541]\teval-rmse:3.79087\ttrain-rmse:1.95913\n",
      "[23542]\teval-rmse:3.79249\ttrain-rmse:1.959\n",
      "[23543]\teval-rmse:3.7925\ttrain-rmse:1.959\n",
      "[23544]\teval-rmse:3.79284\ttrain-rmse:1.95898\n",
      "[23545]\teval-rmse:3.79441\ttrain-rmse:1.95888\n",
      "[23546]\teval-rmse:3.79296\ttrain-rmse:1.95896\n",
      "[23547]\teval-rmse:3.79276\ttrain-rmse:1.95897\n",
      "[23548]\teval-rmse:3.79339\ttrain-rmse:1.95894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23549]\teval-rmse:3.79344\ttrain-rmse:1.95893\n",
      "[23550]\teval-rmse:3.79296\ttrain-rmse:1.95897\n",
      "[23551]\teval-rmse:3.79453\ttrain-rmse:1.95887\n",
      "[23552]\teval-rmse:3.79561\ttrain-rmse:1.95882\n",
      "[23553]\teval-rmse:3.79694\ttrain-rmse:1.95876\n",
      "[23554]\teval-rmse:3.79683\ttrain-rmse:1.95877\n",
      "[23555]\teval-rmse:3.79561\ttrain-rmse:1.95883\n",
      "[23556]\teval-rmse:3.79734\ttrain-rmse:1.95878\n",
      "[23557]\teval-rmse:3.79622\ttrain-rmse:1.95885\n",
      "[23558]\teval-rmse:3.79507\ttrain-rmse:1.9589\n",
      "[23559]\teval-rmse:3.79382\ttrain-rmse:1.95897\n",
      "[23560]\teval-rmse:3.79441\ttrain-rmse:1.95894\n",
      "[23561]\teval-rmse:3.79316\ttrain-rmse:1.959\n",
      "[23562]\teval-rmse:3.79164\ttrain-rmse:1.95909\n",
      "[23563]\teval-rmse:3.79353\ttrain-rmse:1.95898\n",
      "[23564]\teval-rmse:3.79233\ttrain-rmse:1.95907\n",
      "[23565]\teval-rmse:3.79255\ttrain-rmse:1.95906\n",
      "[23566]\teval-rmse:3.79236\ttrain-rmse:1.959\n",
      "[23567]\teval-rmse:3.79084\ttrain-rmse:1.9591\n",
      "[23568]\teval-rmse:3.79241\ttrain-rmse:1.959\n",
      "[23569]\teval-rmse:3.79402\ttrain-rmse:1.95889\n",
      "[23570]\teval-rmse:3.79259\ttrain-rmse:1.95897\n",
      "[23571]\teval-rmse:3.7925\ttrain-rmse:1.95897\n",
      "[23572]\teval-rmse:3.79207\ttrain-rmse:1.959\n",
      "[23573]\teval-rmse:3.79297\ttrain-rmse:1.95893\n",
      "[23574]\teval-rmse:3.79278\ttrain-rmse:1.95887\n",
      "[23575]\teval-rmse:3.79103\ttrain-rmse:1.95897\n",
      "[23576]\teval-rmse:3.79029\ttrain-rmse:1.95902\n",
      "[23577]\teval-rmse:3.7901\ttrain-rmse:1.95903\n",
      "[23578]\teval-rmse:3.79046\ttrain-rmse:1.95901\n",
      "[23579]\teval-rmse:3.78977\ttrain-rmse:1.95906\n",
      "[23580]\teval-rmse:3.79005\ttrain-rmse:1.95904\n",
      "[23581]\teval-rmse:3.79028\ttrain-rmse:1.95903\n",
      "[23582]\teval-rmse:3.7901\ttrain-rmse:1.95904\n",
      "[23583]\teval-rmse:3.78902\ttrain-rmse:1.95911\n",
      "[23584]\teval-rmse:3.78834\ttrain-rmse:1.95917\n",
      "[23585]\teval-rmse:3.79001\ttrain-rmse:1.95905\n",
      "[23586]\teval-rmse:3.7914\ttrain-rmse:1.95895\n",
      "[23587]\teval-rmse:3.79099\ttrain-rmse:1.95898\n",
      "[23588]\teval-rmse:3.79128\ttrain-rmse:1.95896\n",
      "[23589]\teval-rmse:3.79203\ttrain-rmse:1.95892\n",
      "[23590]\teval-rmse:3.79112\ttrain-rmse:1.95897\n",
      "[23591]\teval-rmse:3.78965\ttrain-rmse:1.95907\n",
      "[23592]\teval-rmse:3.78947\ttrain-rmse:1.95908\n",
      "[23593]\teval-rmse:3.79087\ttrain-rmse:1.95899\n",
      "[23594]\teval-rmse:3.79248\ttrain-rmse:1.95888\n",
      "[23595]\teval-rmse:3.79205\ttrain-rmse:1.9589\n",
      "[23596]\teval-rmse:3.79167\ttrain-rmse:1.95893\n",
      "[23597]\teval-rmse:3.79224\ttrain-rmse:1.95889\n",
      "[23598]\teval-rmse:3.79069\ttrain-rmse:1.95898\n",
      "[23599]\teval-rmse:3.7926\ttrain-rmse:1.95887\n",
      "[23600]\teval-rmse:3.79216\ttrain-rmse:1.9589\n",
      "[23601]\teval-rmse:3.79351\ttrain-rmse:1.95882\n",
      "[23602]\teval-rmse:3.79209\ttrain-rmse:1.9589\n",
      "[23603]\teval-rmse:3.79208\ttrain-rmse:1.9589\n",
      "[23604]\teval-rmse:3.79083\ttrain-rmse:1.95899\n",
      "[23605]\teval-rmse:3.79064\ttrain-rmse:1.959\n",
      "[23606]\teval-rmse:3.79094\ttrain-rmse:1.95898\n",
      "[23607]\teval-rmse:3.7892\ttrain-rmse:1.95911\n",
      "[23608]\teval-rmse:3.78808\ttrain-rmse:1.95919\n",
      "[23609]\teval-rmse:3.78838\ttrain-rmse:1.95917\n",
      "[23610]\teval-rmse:3.78893\ttrain-rmse:1.95913\n",
      "[23611]\teval-rmse:3.79017\ttrain-rmse:1.95904\n",
      "[23612]\teval-rmse:3.78844\ttrain-rmse:1.95917\n",
      "[23613]\teval-rmse:3.78827\ttrain-rmse:1.95918\n",
      "[23614]\teval-rmse:3.78819\ttrain-rmse:1.95918\n",
      "[23615]\teval-rmse:3.78986\ttrain-rmse:1.95905\n",
      "[23616]\teval-rmse:3.79176\ttrain-rmse:1.95893\n",
      "[23617]\teval-rmse:3.793\ttrain-rmse:1.95885\n",
      "[23618]\teval-rmse:3.79122\ttrain-rmse:1.95897\n",
      "[23619]\teval-rmse:3.79076\ttrain-rmse:1.959\n",
      "[23620]\teval-rmse:3.79206\ttrain-rmse:1.95891\n",
      "[23621]\teval-rmse:3.7906\ttrain-rmse:1.95901\n",
      "[23622]\teval-rmse:3.7891\ttrain-rmse:1.95913\n",
      "[23623]\teval-rmse:3.78865\ttrain-rmse:1.95916\n",
      "[23624]\teval-rmse:3.78865\ttrain-rmse:1.95916\n",
      "[23625]\teval-rmse:3.78917\ttrain-rmse:1.95912\n",
      "[23626]\teval-rmse:3.79085\ttrain-rmse:1.959\n",
      "[23627]\teval-rmse:3.78995\ttrain-rmse:1.95905\n",
      "[23628]\teval-rmse:3.79017\ttrain-rmse:1.95904\n",
      "[23629]\teval-rmse:3.79208\ttrain-rmse:1.95892\n",
      "[23630]\teval-rmse:3.79139\ttrain-rmse:1.95897\n",
      "[23631]\teval-rmse:3.7933\ttrain-rmse:1.95886\n",
      "[23632]\teval-rmse:3.7952\ttrain-rmse:1.95876\n",
      "[23633]\teval-rmse:3.79406\ttrain-rmse:1.95883\n",
      "[23634]\teval-rmse:3.79435\ttrain-rmse:1.95881\n",
      "[23635]\teval-rmse:3.79458\ttrain-rmse:1.9588\n",
      "[23636]\teval-rmse:3.79385\ttrain-rmse:1.95885\n",
      "[23637]\teval-rmse:3.79222\ttrain-rmse:1.95894\n",
      "[23638]\teval-rmse:3.79181\ttrain-rmse:1.95897\n",
      "[23639]\teval-rmse:3.79239\ttrain-rmse:1.95893\n",
      "[23640]\teval-rmse:3.79296\ttrain-rmse:1.95889\n",
      "[23641]\teval-rmse:3.79359\ttrain-rmse:1.95884\n",
      "[23642]\teval-rmse:3.79496\ttrain-rmse:1.95876\n",
      "[23643]\teval-rmse:3.79478\ttrain-rmse:1.95877\n",
      "[23644]\teval-rmse:3.79635\ttrain-rmse:1.95867\n",
      "[23645]\teval-rmse:3.79725\ttrain-rmse:1.95862\n",
      "[23646]\teval-rmse:3.79576\ttrain-rmse:1.9587\n",
      "[23647]\teval-rmse:3.79427\ttrain-rmse:1.9588\n",
      "[23648]\teval-rmse:3.79517\ttrain-rmse:1.95874\n",
      "[23649]\teval-rmse:3.79464\ttrain-rmse:1.95877\n",
      "[23650]\teval-rmse:3.79302\ttrain-rmse:1.95886\n",
      "[23651]\teval-rmse:3.79347\ttrain-rmse:1.95883\n",
      "[23652]\teval-rmse:3.79378\ttrain-rmse:1.95881\n",
      "[23653]\teval-rmse:3.79541\ttrain-rmse:1.9587\n",
      "[23654]\teval-rmse:3.79704\ttrain-rmse:1.95859\n",
      "[23655]\teval-rmse:3.79584\ttrain-rmse:1.95867\n",
      "[23656]\teval-rmse:3.79588\ttrain-rmse:1.95867\n",
      "[23657]\teval-rmse:3.79761\ttrain-rmse:1.95857\n",
      "[23658]\teval-rmse:3.79864\ttrain-rmse:1.95852\n",
      "[23659]\teval-rmse:3.79684\ttrain-rmse:1.95861\n",
      "[23660]\teval-rmse:3.79737\ttrain-rmse:1.95858\n",
      "[23661]\teval-rmse:3.79692\ttrain-rmse:1.95861\n",
      "[23662]\teval-rmse:3.79566\ttrain-rmse:1.95868\n",
      "[23663]\teval-rmse:3.79628\ttrain-rmse:1.95864\n",
      "[23664]\teval-rmse:3.79755\ttrain-rmse:1.95858\n",
      "[23665]\teval-rmse:3.79591\ttrain-rmse:1.95866\n",
      "[23666]\teval-rmse:3.79608\ttrain-rmse:1.95865\n",
      "[23667]\teval-rmse:3.79482\ttrain-rmse:1.95873\n",
      "[23668]\teval-rmse:3.79461\ttrain-rmse:1.95874\n",
      "[23669]\teval-rmse:3.79423\ttrain-rmse:1.95877\n",
      "[23670]\teval-rmse:3.7935\ttrain-rmse:1.95881\n",
      "[23671]\teval-rmse:3.79409\ttrain-rmse:1.95878\n",
      "[23672]\teval-rmse:3.79493\ttrain-rmse:1.95872\n",
      "[23673]\teval-rmse:3.79492\ttrain-rmse:1.95873\n",
      "[23674]\teval-rmse:3.79448\ttrain-rmse:1.95875\n",
      "[23675]\teval-rmse:3.79339\ttrain-rmse:1.95883\n",
      "[23676]\teval-rmse:3.79506\ttrain-rmse:1.95872\n",
      "[23677]\teval-rmse:3.79663\ttrain-rmse:1.95862\n",
      "[23678]\teval-rmse:3.79826\ttrain-rmse:1.95853\n",
      "[23679]\teval-rmse:3.79882\ttrain-rmse:1.9585\n",
      "[23680]\teval-rmse:3.7986\ttrain-rmse:1.95843\n",
      "[23681]\teval-rmse:3.79711\ttrain-rmse:1.95851\n",
      "[23682]\teval-rmse:3.79691\ttrain-rmse:1.95852\n",
      "[23683]\teval-rmse:3.79579\ttrain-rmse:1.9586\n",
      "[23684]\teval-rmse:3.79745\ttrain-rmse:1.9585\n",
      "[23685]\teval-rmse:3.79618\ttrain-rmse:1.95857\n",
      "[23686]\teval-rmse:3.79494\ttrain-rmse:1.95865\n",
      "[23687]\teval-rmse:3.79452\ttrain-rmse:1.95867\n",
      "[23688]\teval-rmse:3.79619\ttrain-rmse:1.95857\n",
      "[23689]\teval-rmse:3.79502\ttrain-rmse:1.95864\n",
      "[23690]\teval-rmse:3.79692\ttrain-rmse:1.95855\n",
      "[23691]\teval-rmse:3.79782\ttrain-rmse:1.95849\n",
      "[23692]\teval-rmse:3.79781\ttrain-rmse:1.95849\n",
      "[23693]\teval-rmse:3.79806\ttrain-rmse:1.95848\n",
      "[23694]\teval-rmse:3.79711\ttrain-rmse:1.95852\n",
      "[23695]\teval-rmse:3.79877\ttrain-rmse:1.95843\n",
      "[23696]\teval-rmse:3.79796\ttrain-rmse:1.95847\n",
      "[23697]\teval-rmse:3.79664\ttrain-rmse:1.95854\n",
      "[23698]\teval-rmse:3.79695\ttrain-rmse:1.95853\n",
      "[23699]\teval-rmse:3.79761\ttrain-rmse:1.95849\n",
      "[23700]\teval-rmse:3.79739\ttrain-rmse:1.95842\n",
      "[23701]\teval-rmse:3.79895\ttrain-rmse:1.95834\n",
      "[23702]\teval-rmse:3.80029\ttrain-rmse:1.95827\n",
      "[23703]\teval-rmse:3.79849\ttrain-rmse:1.95837\n",
      "[23704]\teval-rmse:3.79828\ttrain-rmse:1.95838\n",
      "[23705]\teval-rmse:3.79885\ttrain-rmse:1.95835\n",
      "[23706]\teval-rmse:3.79969\ttrain-rmse:1.95831\n",
      "[23707]\teval-rmse:3.80105\ttrain-rmse:1.95824\n",
      "[23708]\teval-rmse:3.80188\ttrain-rmse:1.95821\n",
      "[23709]\teval-rmse:3.80141\ttrain-rmse:1.95823\n",
      "[23710]\teval-rmse:3.80128\ttrain-rmse:1.95823\n",
      "[23711]\teval-rmse:3.80152\ttrain-rmse:1.95822\n",
      "[23712]\teval-rmse:3.80278\ttrain-rmse:1.95817\n",
      "[23713]\teval-rmse:3.80265\ttrain-rmse:1.95818\n",
      "[23714]\teval-rmse:3.80319\ttrain-rmse:1.95816\n",
      "[23715]\teval-rmse:3.80171\ttrain-rmse:1.95821\n",
      "[23716]\teval-rmse:3.80342\ttrain-rmse:1.95815\n",
      "[23717]\teval-rmse:3.803\ttrain-rmse:1.95816\n",
      "[23718]\teval-rmse:3.80388\ttrain-rmse:1.95813\n",
      "[23719]\teval-rmse:3.80206\ttrain-rmse:1.95819\n",
      "[23720]\teval-rmse:3.80047\ttrain-rmse:1.95826\n",
      "[23721]\teval-rmse:3.79993\ttrain-rmse:1.95829\n",
      "[23722]\teval-rmse:3.80183\ttrain-rmse:1.9582\n",
      "[23723]\teval-rmse:3.8031\ttrain-rmse:1.95815\n",
      "[23724]\teval-rmse:3.80286\ttrain-rmse:1.95816\n",
      "[23725]\teval-rmse:3.80228\ttrain-rmse:1.95818\n",
      "[23726]\teval-rmse:3.80366\ttrain-rmse:1.95813\n",
      "[23727]\teval-rmse:3.80504\ttrain-rmse:1.95809\n",
      "[23728]\teval-rmse:3.80445\ttrain-rmse:1.9581\n",
      "[23729]\teval-rmse:3.80595\ttrain-rmse:1.95806\n",
      "[23730]\teval-rmse:3.8052\ttrain-rmse:1.95808\n",
      "[23731]\teval-rmse:3.80677\ttrain-rmse:1.95804\n",
      "[23732]\teval-rmse:3.80711\ttrain-rmse:1.95803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23733]\teval-rmse:3.80711\ttrain-rmse:1.95803\n",
      "[23734]\teval-rmse:3.80685\ttrain-rmse:1.95804\n",
      "[23735]\teval-rmse:3.80812\ttrain-rmse:1.95801\n",
      "[23736]\teval-rmse:3.80787\ttrain-rmse:1.95802\n",
      "[23737]\teval-rmse:3.80808\ttrain-rmse:1.95802\n",
      "[23738]\teval-rmse:3.80686\ttrain-rmse:1.95804\n",
      "[23739]\teval-rmse:3.80706\ttrain-rmse:1.95803\n",
      "[23740]\teval-rmse:3.80555\ttrain-rmse:1.95807\n",
      "[23741]\teval-rmse:3.80401\ttrain-rmse:1.95811\n",
      "[23742]\teval-rmse:3.80404\ttrain-rmse:1.95811\n",
      "[23743]\teval-rmse:3.80363\ttrain-rmse:1.95813\n",
      "[23744]\teval-rmse:3.80324\ttrain-rmse:1.95814\n",
      "[23745]\teval-rmse:3.80363\ttrain-rmse:1.95813\n",
      "[23746]\teval-rmse:3.80236\ttrain-rmse:1.95817\n",
      "[23747]\teval-rmse:3.80426\ttrain-rmse:1.95811\n",
      "[23748]\teval-rmse:3.80268\ttrain-rmse:1.95817\n",
      "[23749]\teval-rmse:3.80395\ttrain-rmse:1.95812\n",
      "[23750]\teval-rmse:3.8037\ttrain-rmse:1.95813\n",
      "[23751]\teval-rmse:3.80347\ttrain-rmse:1.95814\n",
      "[23752]\teval-rmse:3.80219\ttrain-rmse:1.95818\n",
      "[23753]\teval-rmse:3.80063\ttrain-rmse:1.95825\n",
      "[23754]\teval-rmse:3.7994\ttrain-rmse:1.95832\n",
      "[23755]\teval-rmse:3.79789\ttrain-rmse:1.9584\n",
      "[23756]\teval-rmse:3.79926\ttrain-rmse:1.95832\n",
      "[23757]\teval-rmse:3.80098\ttrain-rmse:1.95824\n",
      "[23758]\teval-rmse:3.79939\ttrain-rmse:1.95831\n",
      "[23759]\teval-rmse:3.7994\ttrain-rmse:1.95831\n",
      "[23760]\teval-rmse:3.79896\ttrain-rmse:1.95834\n",
      "[23761]\teval-rmse:3.79954\ttrain-rmse:1.95831\n",
      "[23762]\teval-rmse:3.79808\ttrain-rmse:1.95838\n",
      "[23763]\teval-rmse:3.79942\ttrain-rmse:1.95831\n",
      "[23764]\teval-rmse:3.79869\ttrain-rmse:1.95835\n",
      "[23765]\teval-rmse:3.79846\ttrain-rmse:1.95828\n",
      "[23766]\teval-rmse:3.79723\ttrain-rmse:1.95834\n",
      "[23767]\teval-rmse:3.79652\ttrain-rmse:1.95838\n",
      "[23768]\teval-rmse:3.79718\ttrain-rmse:1.95834\n",
      "[23769]\teval-rmse:3.79908\ttrain-rmse:1.95826\n",
      "[23770]\teval-rmse:3.79785\ttrain-rmse:1.95834\n",
      "[23771]\teval-rmse:3.79636\ttrain-rmse:1.95842\n",
      "[23772]\teval-rmse:3.79614\ttrain-rmse:1.95843\n",
      "[23773]\teval-rmse:3.79469\ttrain-rmse:1.95852\n",
      "[23774]\teval-rmse:3.79449\ttrain-rmse:1.95845\n",
      "[23775]\teval-rmse:3.79606\ttrain-rmse:1.95836\n",
      "[23776]\teval-rmse:3.79558\ttrain-rmse:1.95839\n",
      "[23777]\teval-rmse:3.79448\ttrain-rmse:1.95846\n",
      "[23778]\teval-rmse:3.7941\ttrain-rmse:1.95848\n",
      "[23779]\teval-rmse:3.79295\ttrain-rmse:1.95856\n",
      "[23780]\teval-rmse:3.79176\ttrain-rmse:1.95865\n",
      "[23781]\teval-rmse:3.79212\ttrain-rmse:1.95862\n",
      "[23782]\teval-rmse:3.79279\ttrain-rmse:1.95858\n",
      "[23783]\teval-rmse:3.79313\ttrain-rmse:1.95855\n",
      "[23784]\teval-rmse:3.79279\ttrain-rmse:1.95858\n",
      "[23785]\teval-rmse:3.79316\ttrain-rmse:1.95855\n",
      "[23786]\teval-rmse:3.79351\ttrain-rmse:1.95853\n",
      "[23787]\teval-rmse:3.79332\ttrain-rmse:1.95854\n",
      "[23788]\teval-rmse:3.79322\ttrain-rmse:1.95854\n",
      "[23789]\teval-rmse:3.79267\ttrain-rmse:1.95858\n",
      "[23790]\teval-rmse:3.79257\ttrain-rmse:1.95859\n",
      "[23791]\teval-rmse:3.79248\ttrain-rmse:1.95859\n",
      "[23792]\teval-rmse:3.7913\ttrain-rmse:1.95867\n",
      "[23793]\teval-rmse:3.79187\ttrain-rmse:1.95863\n",
      "[23794]\teval-rmse:3.79044\ttrain-rmse:1.95874\n",
      "[23795]\teval-rmse:3.78872\ttrain-rmse:1.95888\n",
      "[23796]\teval-rmse:3.78909\ttrain-rmse:1.95885\n",
      "[23797]\teval-rmse:3.78797\ttrain-rmse:1.95894\n",
      "[23798]\teval-rmse:3.78802\ttrain-rmse:1.95894\n",
      "[23799]\teval-rmse:3.78768\ttrain-rmse:1.95897\n",
      "[23800]\teval-rmse:3.78823\ttrain-rmse:1.95892\n",
      "[23801]\teval-rmse:3.7895\ttrain-rmse:1.95881\n",
      "[23802]\teval-rmse:3.79021\ttrain-rmse:1.95875\n",
      "[23803]\teval-rmse:3.78953\ttrain-rmse:1.9588\n",
      "[23804]\teval-rmse:3.78766\ttrain-rmse:1.95895\n",
      "[23805]\teval-rmse:3.78896\ttrain-rmse:1.95885\n",
      "[23806]\teval-rmse:3.78773\ttrain-rmse:1.95895\n",
      "[23807]\teval-rmse:3.78755\ttrain-rmse:1.95896\n",
      "[23808]\teval-rmse:3.78612\ttrain-rmse:1.95909\n",
      "[23809]\teval-rmse:3.78742\ttrain-rmse:1.95897\n",
      "[23810]\teval-rmse:3.78707\ttrain-rmse:1.959\n",
      "[23811]\teval-rmse:3.78871\ttrain-rmse:1.95886\n",
      "[23812]\teval-rmse:3.79037\ttrain-rmse:1.95873\n",
      "[23813]\teval-rmse:3.78914\ttrain-rmse:1.95883\n",
      "[23814]\teval-rmse:3.78738\ttrain-rmse:1.95898\n",
      "[23815]\teval-rmse:3.78722\ttrain-rmse:1.95899\n",
      "[23816]\teval-rmse:3.78856\ttrain-rmse:1.95888\n",
      "[23817]\teval-rmse:3.78959\ttrain-rmse:1.95879\n",
      "[23818]\teval-rmse:3.79085\ttrain-rmse:1.95869\n",
      "[23819]\teval-rmse:3.78912\ttrain-rmse:1.95883\n",
      "[23820]\teval-rmse:3.7879\ttrain-rmse:1.95893\n",
      "[23821]\teval-rmse:3.78953\ttrain-rmse:1.9588\n",
      "[23822]\teval-rmse:3.79007\ttrain-rmse:1.95876\n",
      "[23823]\teval-rmse:3.7917\ttrain-rmse:1.95863\n",
      "[23824]\teval-rmse:3.79305\ttrain-rmse:1.95853\n",
      "[23825]\teval-rmse:3.79179\ttrain-rmse:1.95862\n",
      "[23826]\teval-rmse:3.79241\ttrain-rmse:1.95858\n",
      "[23827]\teval-rmse:3.79204\ttrain-rmse:1.9586\n",
      "[23828]\teval-rmse:3.79345\ttrain-rmse:1.95851\n",
      "[23829]\teval-rmse:3.79236\ttrain-rmse:1.95858\n",
      "[23830]\teval-rmse:3.79394\ttrain-rmse:1.95848\n",
      "[23831]\teval-rmse:3.79503\ttrain-rmse:1.95841\n",
      "[23832]\teval-rmse:3.7956\ttrain-rmse:1.95838\n",
      "[23833]\teval-rmse:3.79581\ttrain-rmse:1.95836\n",
      "[23834]\teval-rmse:3.79537\ttrain-rmse:1.95839\n",
      "[23835]\teval-rmse:3.79394\ttrain-rmse:1.95848\n",
      "[23836]\teval-rmse:3.79566\ttrain-rmse:1.95837\n",
      "[23837]\teval-rmse:3.79412\ttrain-rmse:1.95847\n",
      "[23838]\teval-rmse:3.79401\ttrain-rmse:1.95847\n",
      "[23839]\teval-rmse:3.79424\ttrain-rmse:1.95846\n",
      "[23840]\teval-rmse:3.79298\ttrain-rmse:1.95854\n",
      "[23841]\teval-rmse:3.79457\ttrain-rmse:1.95844\n",
      "[23842]\teval-rmse:3.79516\ttrain-rmse:1.9584\n",
      "[23843]\teval-rmse:3.79622\ttrain-rmse:1.95835\n",
      "[23844]\teval-rmse:3.79478\ttrain-rmse:1.95843\n",
      "[23845]\teval-rmse:3.79302\ttrain-rmse:1.95854\n",
      "[23846]\teval-rmse:3.79249\ttrain-rmse:1.95857\n",
      "[23847]\teval-rmse:3.79274\ttrain-rmse:1.95856\n",
      "[23848]\teval-rmse:3.7923\ttrain-rmse:1.95859\n",
      "[23849]\teval-rmse:3.79314\ttrain-rmse:1.95853\n",
      "[23850]\teval-rmse:3.79404\ttrain-rmse:1.95847\n",
      "[23851]\teval-rmse:3.79567\ttrain-rmse:1.95835\n",
      "[23852]\teval-rmse:3.79549\ttrain-rmse:1.95829\n",
      "[23853]\teval-rmse:3.79602\ttrain-rmse:1.95826\n",
      "[23854]\teval-rmse:3.79758\ttrain-rmse:1.95817\n",
      "[23855]\teval-rmse:3.79892\ttrain-rmse:1.95811\n",
      "[23856]\teval-rmse:3.79847\ttrain-rmse:1.95813\n",
      "[23857]\teval-rmse:3.79825\ttrain-rmse:1.95806\n",
      "[23858]\teval-rmse:3.79848\ttrain-rmse:1.95805\n",
      "[23859]\teval-rmse:3.79686\ttrain-rmse:1.95813\n",
      "[23860]\teval-rmse:3.79542\ttrain-rmse:1.95822\n",
      "[23861]\teval-rmse:3.79655\ttrain-rmse:1.95815\n",
      "[23862]\teval-rmse:3.79744\ttrain-rmse:1.9581\n",
      "[23863]\teval-rmse:3.79595\ttrain-rmse:1.95819\n",
      "[23864]\teval-rmse:3.79767\ttrain-rmse:1.9581\n",
      "[23865]\teval-rmse:3.79689\ttrain-rmse:1.95814\n",
      "[23866]\teval-rmse:3.79795\ttrain-rmse:1.95808\n",
      "[23867]\teval-rmse:3.79743\ttrain-rmse:1.95811\n",
      "[23868]\teval-rmse:3.79856\ttrain-rmse:1.95805\n",
      "[23869]\teval-rmse:3.79844\ttrain-rmse:1.95806\n",
      "[23870]\teval-rmse:3.79749\ttrain-rmse:1.9581\n",
      "[23871]\teval-rmse:3.79738\ttrain-rmse:1.9581\n",
      "[23872]\teval-rmse:3.79796\ttrain-rmse:1.95807\n",
      "[23873]\teval-rmse:3.79885\ttrain-rmse:1.95802\n",
      "[23874]\teval-rmse:3.79772\ttrain-rmse:1.95809\n",
      "[23875]\teval-rmse:3.79935\ttrain-rmse:1.95802\n",
      "[23876]\teval-rmse:3.79785\ttrain-rmse:1.95809\n",
      "[23877]\teval-rmse:3.79808\ttrain-rmse:1.95808\n",
      "[23878]\teval-rmse:3.79963\ttrain-rmse:1.95801\n",
      "[23879]\teval-rmse:3.801\ttrain-rmse:1.95795\n",
      "[23880]\teval-rmse:3.80228\ttrain-rmse:1.95791\n",
      "[23881]\teval-rmse:3.80099\ttrain-rmse:1.95795\n",
      "[23882]\teval-rmse:3.801\ttrain-rmse:1.95795\n",
      "[23883]\teval-rmse:3.80224\ttrain-rmse:1.95791\n",
      "[23884]\teval-rmse:3.80278\ttrain-rmse:1.95789\n",
      "[23885]\teval-rmse:3.80129\ttrain-rmse:1.95794\n",
      "[23886]\teval-rmse:3.80151\ttrain-rmse:1.95793\n",
      "[23887]\teval-rmse:3.80154\ttrain-rmse:1.95793\n",
      "[23888]\teval-rmse:3.80057\ttrain-rmse:1.95797\n",
      "[23889]\teval-rmse:3.80222\ttrain-rmse:1.9579\n",
      "[23890]\teval-rmse:3.80251\ttrain-rmse:1.95789\n",
      "[23891]\teval-rmse:3.80401\ttrain-rmse:1.95785\n",
      "[23892]\teval-rmse:3.80377\ttrain-rmse:1.95785\n",
      "[23893]\teval-rmse:3.80352\ttrain-rmse:1.95786\n",
      "[23894]\teval-rmse:3.8044\ttrain-rmse:1.95784\n",
      "[23895]\teval-rmse:3.80573\ttrain-rmse:1.95781\n",
      "[23896]\teval-rmse:3.80499\ttrain-rmse:1.95782\n",
      "[23897]\teval-rmse:3.80564\ttrain-rmse:1.95781\n",
      "[23898]\teval-rmse:3.80617\ttrain-rmse:1.9578\n",
      "[23899]\teval-rmse:3.80602\ttrain-rmse:1.9578\n",
      "[23900]\teval-rmse:3.80658\ttrain-rmse:1.95779\n",
      "[23901]\teval-rmse:3.80792\ttrain-rmse:1.95777\n",
      "[23902]\teval-rmse:3.80765\ttrain-rmse:1.95777\n",
      "[23903]\teval-rmse:3.80763\ttrain-rmse:1.95777\n",
      "[23904]\teval-rmse:3.80817\ttrain-rmse:1.95777\n",
      "[23905]\teval-rmse:3.80655\ttrain-rmse:1.9578\n",
      "[23906]\teval-rmse:3.80528\ttrain-rmse:1.95782\n",
      "[23907]\teval-rmse:3.80569\ttrain-rmse:1.95781\n",
      "[23908]\teval-rmse:3.80611\ttrain-rmse:1.9578\n",
      "[23909]\teval-rmse:3.80596\ttrain-rmse:1.95781\n",
      "[23910]\teval-rmse:3.80701\ttrain-rmse:1.95779\n",
      "[23911]\teval-rmse:3.80651\ttrain-rmse:1.9578\n",
      "[23912]\teval-rmse:3.80783\ttrain-rmse:1.95778\n",
      "[23913]\teval-rmse:3.80655\ttrain-rmse:1.95782\n",
      "[23914]\teval-rmse:3.80652\ttrain-rmse:1.95782\n",
      "[23915]\teval-rmse:3.80738\ttrain-rmse:1.95779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23916]\teval-rmse:3.80586\ttrain-rmse:1.95782\n",
      "[23917]\teval-rmse:3.80638\ttrain-rmse:1.95781\n",
      "[23918]\teval-rmse:3.80773\ttrain-rmse:1.95779\n",
      "[23919]\teval-rmse:3.80795\ttrain-rmse:1.95779\n",
      "[23920]\teval-rmse:3.80822\ttrain-rmse:1.95778\n",
      "[23921]\teval-rmse:3.80795\ttrain-rmse:1.95771\n",
      "[23922]\teval-rmse:3.80751\ttrain-rmse:1.95772\n",
      "[23923]\teval-rmse:3.80696\ttrain-rmse:1.95774\n",
      "[23924]\teval-rmse:3.80614\ttrain-rmse:1.95775\n",
      "[23925]\teval-rmse:3.807\ttrain-rmse:1.95773\n",
      "[23926]\teval-rmse:3.80572\ttrain-rmse:1.95775\n",
      "[23927]\teval-rmse:3.80472\ttrain-rmse:1.95778\n",
      "[23928]\teval-rmse:3.80499\ttrain-rmse:1.95777\n",
      "[23929]\teval-rmse:3.80344\ttrain-rmse:1.95781\n",
      "[23930]\teval-rmse:3.80461\ttrain-rmse:1.95778\n",
      "[23931]\teval-rmse:3.806\ttrain-rmse:1.95776\n",
      "[23932]\teval-rmse:3.80621\ttrain-rmse:1.95776\n",
      "[23933]\teval-rmse:3.80544\ttrain-rmse:1.95777\n",
      "[23934]\teval-rmse:3.80382\ttrain-rmse:1.9578\n",
      "[23935]\teval-rmse:3.80399\ttrain-rmse:1.9578\n",
      "[23936]\teval-rmse:3.80273\ttrain-rmse:1.95784\n",
      "[23937]\teval-rmse:3.80324\ttrain-rmse:1.95782\n",
      "[23938]\teval-rmse:3.8046\ttrain-rmse:1.95779\n",
      "[23939]\teval-rmse:3.80337\ttrain-rmse:1.95781\n",
      "[23940]\teval-rmse:3.8047\ttrain-rmse:1.95778\n",
      "[23941]\teval-rmse:3.80631\ttrain-rmse:1.95776\n",
      "[23942]\teval-rmse:3.80573\ttrain-rmse:1.95776\n",
      "[23943]\teval-rmse:3.80449\ttrain-rmse:1.95779\n",
      "[23944]\teval-rmse:3.80283\ttrain-rmse:1.95782\n",
      "[23945]\teval-rmse:3.80316\ttrain-rmse:1.95781\n",
      "[23946]\teval-rmse:3.80378\ttrain-rmse:1.95779\n",
      "[23947]\teval-rmse:3.80256\ttrain-rmse:1.95782\n",
      "[23948]\teval-rmse:3.80342\ttrain-rmse:1.95778\n",
      "[23949]\teval-rmse:3.80347\ttrain-rmse:1.95778\n",
      "[23950]\teval-rmse:3.80389\ttrain-rmse:1.95777\n",
      "[23951]\teval-rmse:3.80336\ttrain-rmse:1.95779\n",
      "[23952]\teval-rmse:3.80398\ttrain-rmse:1.95778\n",
      "[23953]\teval-rmse:3.80236\ttrain-rmse:1.95781\n",
      "[23954]\teval-rmse:3.80323\ttrain-rmse:1.95779\n",
      "[23955]\teval-rmse:3.80453\ttrain-rmse:1.95776\n",
      "[23956]\teval-rmse:3.80326\ttrain-rmse:1.95779\n",
      "[23957]\teval-rmse:3.8043\ttrain-rmse:1.95777\n",
      "[23958]\teval-rmse:3.8062\ttrain-rmse:1.95772\n",
      "[23959]\teval-rmse:3.807\ttrain-rmse:1.9577\n",
      "[23960]\teval-rmse:3.80703\ttrain-rmse:1.9577\n",
      "[23961]\teval-rmse:3.80602\ttrain-rmse:1.95772\n",
      "[23962]\teval-rmse:3.80625\ttrain-rmse:1.95772\n",
      "[23963]\teval-rmse:3.80619\ttrain-rmse:1.95772\n",
      "[23964]\teval-rmse:3.80594\ttrain-rmse:1.95773\n",
      "[23965]\teval-rmse:3.80544\ttrain-rmse:1.95774\n",
      "[23966]\teval-rmse:3.80567\ttrain-rmse:1.95773\n",
      "[23967]\teval-rmse:3.80379\ttrain-rmse:1.95777\n",
      "[23968]\teval-rmse:3.8054\ttrain-rmse:1.95773\n",
      "[23969]\teval-rmse:3.80674\ttrain-rmse:1.95771\n",
      "[23970]\teval-rmse:3.80776\ttrain-rmse:1.95769\n",
      "[23971]\teval-rmse:3.80912\ttrain-rmse:1.95767\n",
      "[23972]\teval-rmse:3.80969\ttrain-rmse:1.95767\n",
      "[23973]\teval-rmse:3.80994\ttrain-rmse:1.95767\n",
      "[23974]\teval-rmse:3.80841\ttrain-rmse:1.95768\n",
      "[23975]\teval-rmse:3.80739\ttrain-rmse:1.95769\n",
      "[23976]\teval-rmse:3.80639\ttrain-rmse:1.95771\n",
      "[23977]\teval-rmse:3.80623\ttrain-rmse:1.95772\n",
      "[23978]\teval-rmse:3.80787\ttrain-rmse:1.95769\n",
      "[23979]\teval-rmse:3.80923\ttrain-rmse:1.95769\n",
      "[23980]\teval-rmse:3.81093\ttrain-rmse:1.95764\n",
      "[23981]\teval-rmse:3.8122\ttrain-rmse:1.95765\n",
      "[23982]\teval-rmse:3.81348\ttrain-rmse:1.95766\n",
      "[23983]\teval-rmse:3.81215\ttrain-rmse:1.95768\n",
      "[23984]\teval-rmse:3.81085\ttrain-rmse:1.95768\n",
      "[23985]\teval-rmse:3.80927\ttrain-rmse:1.95768\n",
      "[23986]\teval-rmse:3.8085\ttrain-rmse:1.95768\n",
      "[23987]\teval-rmse:3.80771\ttrain-rmse:1.95769\n",
      "[23988]\teval-rmse:3.80608\ttrain-rmse:1.95772\n",
      "[23989]\teval-rmse:3.80565\ttrain-rmse:1.95773\n",
      "[23990]\teval-rmse:3.80616\ttrain-rmse:1.95772\n",
      "[23991]\teval-rmse:3.80775\ttrain-rmse:1.95769\n",
      "[23992]\teval-rmse:3.80622\ttrain-rmse:1.95772\n",
      "[23993]\teval-rmse:3.80796\ttrain-rmse:1.9577\n",
      "[23994]\teval-rmse:3.80798\ttrain-rmse:1.9577\n",
      "[23995]\teval-rmse:3.80644\ttrain-rmse:1.95773\n",
      "[23996]\teval-rmse:3.806\ttrain-rmse:1.95774\n",
      "[23997]\teval-rmse:3.80552\ttrain-rmse:1.95774\n",
      "[23998]\teval-rmse:3.80614\ttrain-rmse:1.95773\n",
      "[23999]\teval-rmse:3.80645\ttrain-rmse:1.95773\n",
      "[24000]\teval-rmse:3.80805\ttrain-rmse:1.9577\n",
      "[24001]\teval-rmse:3.80754\ttrain-rmse:1.95771\n",
      "[24002]\teval-rmse:3.80839\ttrain-rmse:1.95769\n",
      "[24003]\teval-rmse:3.80681\ttrain-rmse:1.95771\n",
      "[24004]\teval-rmse:3.80841\ttrain-rmse:1.95766\n",
      "[24005]\teval-rmse:3.80659\ttrain-rmse:1.95768\n",
      "[24006]\teval-rmse:3.80457\ttrain-rmse:1.95771\n",
      "[24007]\teval-rmse:3.8058\ttrain-rmse:1.95768\n",
      "[24008]\teval-rmse:3.8066\ttrain-rmse:1.95766\n",
      "[24009]\teval-rmse:3.8085\ttrain-rmse:1.95762\n",
      "[24010]\teval-rmse:3.80833\ttrain-rmse:1.95763\n",
      "[24011]\teval-rmse:3.80775\ttrain-rmse:1.95764\n",
      "[24012]\teval-rmse:3.8089\ttrain-rmse:1.95762\n",
      "[24013]\teval-rmse:3.80843\ttrain-rmse:1.95763\n",
      "[24014]\teval-rmse:3.80894\ttrain-rmse:1.95762\n",
      "[24015]\teval-rmse:3.81054\ttrain-rmse:1.95757\n",
      "[24016]\teval-rmse:3.80944\ttrain-rmse:1.95758\n",
      "[24017]\teval-rmse:3.80918\ttrain-rmse:1.95759\n",
      "[24018]\teval-rmse:3.81077\ttrain-rmse:1.95754\n",
      "[24019]\teval-rmse:3.81242\ttrain-rmse:1.95754\n",
      "[24020]\teval-rmse:3.8138\ttrain-rmse:1.95754\n",
      "[24021]\teval-rmse:3.81511\ttrain-rmse:1.95754\n",
      "[24022]\teval-rmse:3.81492\ttrain-rmse:1.95754\n",
      "[24023]\teval-rmse:3.81515\ttrain-rmse:1.95754\n",
      "[24024]\teval-rmse:3.81671\ttrain-rmse:1.95755\n",
      "[24025]\teval-rmse:3.81501\ttrain-rmse:1.95754\n",
      "[24026]\teval-rmse:3.81661\ttrain-rmse:1.95754\n",
      "[24027]\teval-rmse:3.81658\ttrain-rmse:1.95754\n",
      "[24028]\teval-rmse:3.81499\ttrain-rmse:1.95754\n",
      "[24029]\teval-rmse:3.8131\ttrain-rmse:1.95754\n",
      "[24030]\teval-rmse:3.81464\ttrain-rmse:1.95754\n",
      "[24031]\teval-rmse:3.81437\ttrain-rmse:1.95746\n",
      "[24032]\teval-rmse:3.8138\ttrain-rmse:1.95746\n",
      "[24033]\teval-rmse:3.81543\ttrain-rmse:1.95746\n",
      "[24034]\teval-rmse:3.81539\ttrain-rmse:1.95746\n",
      "[24035]\teval-rmse:3.81602\ttrain-rmse:1.95746\n",
      "[24036]\teval-rmse:3.81752\ttrain-rmse:1.95747\n",
      "[24037]\teval-rmse:3.81724\ttrain-rmse:1.95747\n",
      "[24038]\teval-rmse:3.81674\ttrain-rmse:1.95747\n",
      "[24039]\teval-rmse:3.8162\ttrain-rmse:1.95747\n",
      "[24040]\teval-rmse:3.81515\ttrain-rmse:1.95747\n",
      "[24041]\teval-rmse:3.81466\ttrain-rmse:1.95748\n",
      "[24042]\teval-rmse:3.81438\ttrain-rmse:1.95748\n",
      "[24043]\teval-rmse:3.81456\ttrain-rmse:1.95748\n",
      "[24044]\teval-rmse:3.81428\ttrain-rmse:1.95748\n",
      "[24045]\teval-rmse:3.81476\ttrain-rmse:1.95748\n",
      "[24046]\teval-rmse:3.81318\ttrain-rmse:1.95748\n",
      "[24047]\teval-rmse:3.81336\ttrain-rmse:1.95748\n",
      "[24048]\teval-rmse:3.81307\ttrain-rmse:1.95748\n",
      "[24049]\teval-rmse:3.81457\ttrain-rmse:1.95749\n",
      "[24050]\teval-rmse:3.81645\ttrain-rmse:1.95748\n",
      "[24051]\teval-rmse:3.81479\ttrain-rmse:1.95747\n",
      "[24052]\teval-rmse:3.8134\ttrain-rmse:1.95747\n",
      "[24053]\teval-rmse:3.81489\ttrain-rmse:1.95748\n",
      "[24054]\teval-rmse:3.81334\ttrain-rmse:1.95747\n",
      "[24055]\teval-rmse:3.81363\ttrain-rmse:1.95747\n",
      "[24056]\teval-rmse:3.81471\ttrain-rmse:1.95748\n",
      "[24057]\teval-rmse:3.81336\ttrain-rmse:1.95747\n",
      "[24058]\teval-rmse:3.81307\ttrain-rmse:1.95741\n",
      "[24059]\teval-rmse:3.8115\ttrain-rmse:1.95741\n",
      "[24060]\teval-rmse:3.81339\ttrain-rmse:1.95739\n",
      "[24061]\teval-rmse:3.81477\ttrain-rmse:1.95739\n",
      "[24062]\teval-rmse:3.81354\ttrain-rmse:1.9574\n",
      "[24063]\teval-rmse:3.81199\ttrain-rmse:1.9574\n",
      "[24064]\teval-rmse:3.81016\ttrain-rmse:1.95742\n",
      "[24065]\teval-rmse:3.80883\ttrain-rmse:1.95744\n",
      "[24066]\teval-rmse:3.8072\ttrain-rmse:1.95747\n",
      "[24067]\teval-rmse:3.80621\ttrain-rmse:1.95749\n",
      "[24068]\teval-rmse:3.80522\ttrain-rmse:1.95752\n",
      "[24069]\teval-rmse:3.80577\ttrain-rmse:1.95751\n",
      "[24070]\teval-rmse:3.80523\ttrain-rmse:1.95752\n",
      "[24071]\teval-rmse:3.80573\ttrain-rmse:1.95751\n",
      "[24072]\teval-rmse:3.806\ttrain-rmse:1.9575\n",
      "[24073]\teval-rmse:3.80735\ttrain-rmse:1.95747\n",
      "[24074]\teval-rmse:3.80754\ttrain-rmse:1.95747\n",
      "[24075]\teval-rmse:3.80921\ttrain-rmse:1.95745\n",
      "[24076]\teval-rmse:3.80786\ttrain-rmse:1.95747\n",
      "[24077]\teval-rmse:3.80742\ttrain-rmse:1.95747\n",
      "[24078]\teval-rmse:3.80618\ttrain-rmse:1.9575\n",
      "[24079]\teval-rmse:3.80488\ttrain-rmse:1.95753\n",
      "[24080]\teval-rmse:3.8041\ttrain-rmse:1.95755\n",
      "[24081]\teval-rmse:3.8026\ttrain-rmse:1.9576\n",
      "[24082]\teval-rmse:3.80421\ttrain-rmse:1.95755\n",
      "[24083]\teval-rmse:3.80576\ttrain-rmse:1.9575\n",
      "[24084]\teval-rmse:3.80703\ttrain-rmse:1.95748\n",
      "[24085]\teval-rmse:3.80603\ttrain-rmse:1.9575\n",
      "[24086]\teval-rmse:3.80453\ttrain-rmse:1.95754\n",
      "[24087]\teval-rmse:3.80476\ttrain-rmse:1.95753\n",
      "[24088]\teval-rmse:3.80353\ttrain-rmse:1.95757\n",
      "[24089]\teval-rmse:3.80174\ttrain-rmse:1.95763\n",
      "[24090]\teval-rmse:3.80335\ttrain-rmse:1.95757\n",
      "[24091]\teval-rmse:3.8027\ttrain-rmse:1.9576\n",
      "[24092]\teval-rmse:3.80248\ttrain-rmse:1.9576\n",
      "[24093]\teval-rmse:3.8012\ttrain-rmse:1.95765\n",
      "[24094]\teval-rmse:3.80145\ttrain-rmse:1.95764\n",
      "[24095]\teval-rmse:3.80227\ttrain-rmse:1.95761\n",
      "[24096]\teval-rmse:3.80129\ttrain-rmse:1.95765\n",
      "[24097]\teval-rmse:3.80235\ttrain-rmse:1.95761\n",
      "[24098]\teval-rmse:3.80396\ttrain-rmse:1.95754\n",
      "[24099]\teval-rmse:3.8027\ttrain-rmse:1.95759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24100]\teval-rmse:3.80228\ttrain-rmse:1.95761\n",
      "[24101]\teval-rmse:3.80399\ttrain-rmse:1.95753\n",
      "[24102]\teval-rmse:3.8035\ttrain-rmse:1.95755\n",
      "[24103]\teval-rmse:3.80487\ttrain-rmse:1.95751\n",
      "[24104]\teval-rmse:3.80519\ttrain-rmse:1.9575\n",
      "[24105]\teval-rmse:3.8046\ttrain-rmse:1.95751\n",
      "[24106]\teval-rmse:3.80463\ttrain-rmse:1.95751\n",
      "[24107]\teval-rmse:3.80492\ttrain-rmse:1.95751\n",
      "[24108]\teval-rmse:3.80358\ttrain-rmse:1.95755\n",
      "[24109]\teval-rmse:3.80383\ttrain-rmse:1.95754\n",
      "[24110]\teval-rmse:3.80358\ttrain-rmse:1.95755\n",
      "[24111]\teval-rmse:3.80361\ttrain-rmse:1.95755\n",
      "[24112]\teval-rmse:3.80319\ttrain-rmse:1.95756\n",
      "[24113]\teval-rmse:3.80157\ttrain-rmse:1.95763\n",
      "[24114]\teval-rmse:3.80209\ttrain-rmse:1.95761\n",
      "[24115]\teval-rmse:3.80269\ttrain-rmse:1.95758\n",
      "[24116]\teval-rmse:3.80439\ttrain-rmse:1.95753\n",
      "[24117]\teval-rmse:3.80292\ttrain-rmse:1.95759\n",
      "[24118]\teval-rmse:3.80481\ttrain-rmse:1.95753\n",
      "[24119]\teval-rmse:3.80617\ttrain-rmse:1.95749\n",
      "[24120]\teval-rmse:3.80704\ttrain-rmse:1.95746\n",
      "[24121]\teval-rmse:3.80553\ttrain-rmse:1.95751\n",
      "[24122]\teval-rmse:3.80584\ttrain-rmse:1.9575\n",
      "[24123]\teval-rmse:3.80558\ttrain-rmse:1.95743\n",
      "[24124]\teval-rmse:3.80563\ttrain-rmse:1.95743\n",
      "[24125]\teval-rmse:3.80464\ttrain-rmse:1.95746\n",
      "[24126]\teval-rmse:3.80484\ttrain-rmse:1.95745\n",
      "[24127]\teval-rmse:3.8046\ttrain-rmse:1.95746\n",
      "[24128]\teval-rmse:3.80329\ttrain-rmse:1.9575\n",
      "[24129]\teval-rmse:3.80254\ttrain-rmse:1.95753\n",
      "[24130]\teval-rmse:3.80391\ttrain-rmse:1.95749\n",
      "[24131]\teval-rmse:3.80414\ttrain-rmse:1.95748\n",
      "[24132]\teval-rmse:3.80262\ttrain-rmse:1.95753\n",
      "[24133]\teval-rmse:3.80248\ttrain-rmse:1.95753\n",
      "[24134]\teval-rmse:3.80414\ttrain-rmse:1.95746\n",
      "[24135]\teval-rmse:3.8053\ttrain-rmse:1.95743\n",
      "[24136]\teval-rmse:3.80667\ttrain-rmse:1.95739\n",
      "[24137]\teval-rmse:3.8075\ttrain-rmse:1.95738\n",
      "[24138]\teval-rmse:3.80695\ttrain-rmse:1.95739\n",
      "[24139]\teval-rmse:3.80572\ttrain-rmse:1.95742\n",
      "[24140]\teval-rmse:3.80547\ttrain-rmse:1.95743\n",
      "[24141]\teval-rmse:3.80592\ttrain-rmse:1.95741\n",
      "[24142]\teval-rmse:3.80642\ttrain-rmse:1.9574\n",
      "[24143]\teval-rmse:3.80693\ttrain-rmse:1.95739\n",
      "[24144]\teval-rmse:3.80678\ttrain-rmse:1.95739\n",
      "[24145]\teval-rmse:3.80674\ttrain-rmse:1.95739\n",
      "[24146]\teval-rmse:3.80546\ttrain-rmse:1.95742\n",
      "[24147]\teval-rmse:3.80429\ttrain-rmse:1.95747\n",
      "[24148]\teval-rmse:3.80404\ttrain-rmse:1.95741\n",
      "[24149]\teval-rmse:3.80282\ttrain-rmse:1.95745\n",
      "[24150]\teval-rmse:3.80421\ttrain-rmse:1.95741\n",
      "[24151]\teval-rmse:3.80502\ttrain-rmse:1.95738\n",
      "[24152]\teval-rmse:3.80538\ttrain-rmse:1.95738\n",
      "[24153]\teval-rmse:3.80416\ttrain-rmse:1.95741\n",
      "[24154]\teval-rmse:3.80299\ttrain-rmse:1.95745\n",
      "[24155]\teval-rmse:3.80201\ttrain-rmse:1.95748\n",
      "[24156]\teval-rmse:3.80359\ttrain-rmse:1.95743\n",
      "[24157]\teval-rmse:3.80314\ttrain-rmse:1.95745\n",
      "[24158]\teval-rmse:3.80195\ttrain-rmse:1.95748\n",
      "[24159]\teval-rmse:3.80172\ttrain-rmse:1.95749\n",
      "[24160]\teval-rmse:3.80076\ttrain-rmse:1.95753\n",
      "[24161]\teval-rmse:3.80131\ttrain-rmse:1.9575\n",
      "[24162]\teval-rmse:3.80016\ttrain-rmse:1.95756\n",
      "[24163]\teval-rmse:3.80178\ttrain-rmse:1.9575\n",
      "[24164]\teval-rmse:3.80316\ttrain-rmse:1.95746\n",
      "[24165]\teval-rmse:3.80219\ttrain-rmse:1.95749\n",
      "[24166]\teval-rmse:3.80052\ttrain-rmse:1.95755\n",
      "[24167]\teval-rmse:3.8021\ttrain-rmse:1.95749\n",
      "[24168]\teval-rmse:3.80134\ttrain-rmse:1.95752\n",
      "[24169]\teval-rmse:3.80294\ttrain-rmse:1.95747\n",
      "[24170]\teval-rmse:3.8033\ttrain-rmse:1.95746\n",
      "[24171]\teval-rmse:3.805\ttrain-rmse:1.95741\n",
      "[24172]\teval-rmse:3.80557\ttrain-rmse:1.9574\n",
      "[24173]\teval-rmse:3.80542\ttrain-rmse:1.9574\n",
      "[24174]\teval-rmse:3.80394\ttrain-rmse:1.95745\n",
      "[24175]\teval-rmse:3.80195\ttrain-rmse:1.95752\n",
      "[24176]\teval-rmse:3.80171\ttrain-rmse:1.95744\n",
      "[24177]\teval-rmse:3.80123\ttrain-rmse:1.95746\n",
      "[24178]\teval-rmse:3.80287\ttrain-rmse:1.95741\n",
      "[24179]\teval-rmse:3.80442\ttrain-rmse:1.95736\n",
      "[24180]\teval-rmse:3.80418\ttrain-rmse:1.9573\n",
      "[24181]\teval-rmse:3.80482\ttrain-rmse:1.95728\n",
      "[24182]\teval-rmse:3.80457\ttrain-rmse:1.95729\n",
      "[24183]\teval-rmse:3.80646\ttrain-rmse:1.95724\n",
      "[24184]\teval-rmse:3.80596\ttrain-rmse:1.95725\n",
      "[24185]\teval-rmse:3.80434\ttrain-rmse:1.95728\n",
      "[24186]\teval-rmse:3.80412\ttrain-rmse:1.95729\n",
      "[24187]\teval-rmse:3.80572\ttrain-rmse:1.95725\n",
      "[24188]\teval-rmse:3.80722\ttrain-rmse:1.95721\n",
      "[24189]\teval-rmse:3.80764\ttrain-rmse:1.95721\n",
      "[24190]\teval-rmse:3.80815\ttrain-rmse:1.9572\n",
      "[24191]\teval-rmse:3.80769\ttrain-rmse:1.95721\n",
      "[24192]\teval-rmse:3.80744\ttrain-rmse:1.95721\n",
      "[24193]\teval-rmse:3.80615\ttrain-rmse:1.95724\n",
      "[24194]\teval-rmse:3.8059\ttrain-rmse:1.95724\n",
      "[24195]\teval-rmse:3.80624\ttrain-rmse:1.95723\n",
      "[24196]\teval-rmse:3.80749\ttrain-rmse:1.9572\n",
      "[24197]\teval-rmse:3.80778\ttrain-rmse:1.9572\n",
      "[24198]\teval-rmse:3.80649\ttrain-rmse:1.95724\n",
      "[24199]\teval-rmse:3.80809\ttrain-rmse:1.95721\n",
      "[24200]\teval-rmse:3.80842\ttrain-rmse:1.95721\n",
      "[24201]\teval-rmse:3.80792\ttrain-rmse:1.95721\n",
      "[24202]\teval-rmse:3.80712\ttrain-rmse:1.95722\n",
      "[24203]\teval-rmse:3.80901\ttrain-rmse:1.95719\n",
      "[24204]\teval-rmse:3.80875\ttrain-rmse:1.95719\n",
      "[24205]\teval-rmse:3.80824\ttrain-rmse:1.9572\n",
      "[24206]\teval-rmse:3.80958\ttrain-rmse:1.95718\n",
      "[24207]\teval-rmse:3.80805\ttrain-rmse:1.9572\n",
      "[24208]\teval-rmse:3.80884\ttrain-rmse:1.95719\n",
      "[24209]\teval-rmse:3.80698\ttrain-rmse:1.95723\n",
      "[24210]\teval-rmse:3.80862\ttrain-rmse:1.95721\n",
      "[24211]\teval-rmse:3.8105\ttrain-rmse:1.95717\n",
      "[24212]\teval-rmse:3.81164\ttrain-rmse:1.95716\n",
      "[24213]\teval-rmse:3.81117\ttrain-rmse:1.95716\n",
      "[24214]\teval-rmse:3.81168\ttrain-rmse:1.95716\n",
      "[24215]\teval-rmse:3.81356\ttrain-rmse:1.95714\n",
      "[24216]\teval-rmse:3.81478\ttrain-rmse:1.95714\n",
      "[24217]\teval-rmse:3.81314\ttrain-rmse:1.95716\n",
      "[24218]\teval-rmse:3.81398\ttrain-rmse:1.95715\n",
      "[24219]\teval-rmse:3.81276\ttrain-rmse:1.95716\n",
      "[24220]\teval-rmse:3.81087\ttrain-rmse:1.95719\n",
      "[24221]\teval-rmse:3.81069\ttrain-rmse:1.95719\n",
      "[24222]\teval-rmse:3.81205\ttrain-rmse:1.95718\n",
      "[24223]\teval-rmse:3.81041\ttrain-rmse:1.95721\n",
      "[24224]\teval-rmse:3.80841\ttrain-rmse:1.95727\n",
      "[24225]\teval-rmse:3.80815\ttrain-rmse:1.95727\n",
      "[24226]\teval-rmse:3.80849\ttrain-rmse:1.95726\n",
      "[24227]\teval-rmse:3.80795\ttrain-rmse:1.95728\n",
      "[24228]\teval-rmse:3.80675\ttrain-rmse:1.95731\n",
      "[24229]\teval-rmse:3.80525\ttrain-rmse:1.95737\n",
      "[24230]\teval-rmse:3.80665\ttrain-rmse:1.95731\n",
      "[24231]\teval-rmse:3.80513\ttrain-rmse:1.95735\n",
      "[24232]\teval-rmse:3.80539\ttrain-rmse:1.95734\n",
      "[24233]\teval-rmse:3.80538\ttrain-rmse:1.95734\n",
      "[24234]\teval-rmse:3.80587\ttrain-rmse:1.95733\n",
      "[24235]\teval-rmse:3.80563\ttrain-rmse:1.95733\n",
      "[24236]\teval-rmse:3.80538\ttrain-rmse:1.95734\n",
      "[24237]\teval-rmse:3.80656\ttrain-rmse:1.9573\n",
      "[24238]\teval-rmse:3.80522\ttrain-rmse:1.95733\n",
      "[24239]\teval-rmse:3.80479\ttrain-rmse:1.95734\n",
      "[24240]\teval-rmse:3.80435\ttrain-rmse:1.95736\n",
      "[24241]\teval-rmse:3.80568\ttrain-rmse:1.95731\n",
      "[24242]\teval-rmse:3.80388\ttrain-rmse:1.95738\n",
      "[24243]\teval-rmse:3.80576\ttrain-rmse:1.95733\n",
      "[24244]\teval-rmse:3.80608\ttrain-rmse:1.95732\n",
      "[24245]\teval-rmse:3.80564\ttrain-rmse:1.95733\n",
      "[24246]\teval-rmse:3.80443\ttrain-rmse:1.95739\n",
      "[24247]\teval-rmse:3.80418\ttrain-rmse:1.95732\n",
      "[24248]\teval-rmse:3.80545\ttrain-rmse:1.95728\n",
      "[24249]\teval-rmse:3.80607\ttrain-rmse:1.95727\n",
      "[24250]\teval-rmse:3.80744\ttrain-rmse:1.95724\n",
      "[24251]\teval-rmse:3.80666\ttrain-rmse:1.95725\n",
      "[24252]\teval-rmse:3.80542\ttrain-rmse:1.95728\n",
      "[24253]\teval-rmse:3.80383\ttrain-rmse:1.95736\n",
      "[24254]\teval-rmse:3.80335\ttrain-rmse:1.95737\n",
      "[24255]\teval-rmse:3.80321\ttrain-rmse:1.95738\n",
      "[24256]\teval-rmse:3.80353\ttrain-rmse:1.95737\n",
      "[24257]\teval-rmse:3.80517\ttrain-rmse:1.95732\n",
      "[24258]\teval-rmse:3.80384\ttrain-rmse:1.95738\n",
      "[24259]\teval-rmse:3.80205\ttrain-rmse:1.95748\n",
      "[24260]\teval-rmse:3.80181\ttrain-rmse:1.95741\n",
      "[24261]\teval-rmse:3.80312\ttrain-rmse:1.95733\n",
      "[24262]\teval-rmse:3.80165\ttrain-rmse:1.95742\n",
      "[24263]\teval-rmse:3.80323\ttrain-rmse:1.95736\n",
      "[24264]\teval-rmse:3.80457\ttrain-rmse:1.95732\n",
      "[24265]\teval-rmse:3.80627\ttrain-rmse:1.95727\n",
      "[24266]\teval-rmse:3.80578\ttrain-rmse:1.9573\n",
      "[24267]\teval-rmse:3.80695\ttrain-rmse:1.95725\n",
      "[24268]\teval-rmse:3.80542\ttrain-rmse:1.95732\n",
      "[24269]\teval-rmse:3.8073\ttrain-rmse:1.95727\n",
      "[24270]\teval-rmse:3.809\ttrain-rmse:1.95722\n",
      "[24271]\teval-rmse:3.80876\ttrain-rmse:1.95722\n",
      "[24272]\teval-rmse:3.8085\ttrain-rmse:1.95723\n",
      "[24273]\teval-rmse:3.80854\ttrain-rmse:1.95723\n",
      "[24274]\teval-rmse:3.80726\ttrain-rmse:1.95725\n",
      "[24275]\teval-rmse:3.80762\ttrain-rmse:1.95724\n",
      "[24276]\teval-rmse:3.80634\ttrain-rmse:1.95728\n",
      "[24277]\teval-rmse:3.80619\ttrain-rmse:1.95728\n",
      "[24278]\teval-rmse:3.80751\ttrain-rmse:1.95722\n",
      "[24279]\teval-rmse:3.80632\ttrain-rmse:1.95725\n",
      "[24280]\teval-rmse:3.80667\ttrain-rmse:1.95724\n",
      "[24281]\teval-rmse:3.80699\ttrain-rmse:1.95722\n",
      "[24282]\teval-rmse:3.80857\ttrain-rmse:1.95719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24283]\teval-rmse:3.80689\ttrain-rmse:1.95725\n",
      "[24284]\teval-rmse:3.8085\ttrain-rmse:1.9572\n",
      "[24285]\teval-rmse:3.80731\ttrain-rmse:1.95722\n",
      "[24286]\teval-rmse:3.80752\ttrain-rmse:1.95721\n",
      "[24287]\teval-rmse:3.80773\ttrain-rmse:1.9572\n",
      "[24288]\teval-rmse:3.80623\ttrain-rmse:1.95727\n",
      "[24289]\teval-rmse:3.80441\ttrain-rmse:1.95737\n",
      "[24290]\teval-rmse:3.80501\ttrain-rmse:1.95735\n",
      "[24291]\teval-rmse:3.80479\ttrain-rmse:1.95727\n",
      "[24292]\teval-rmse:3.80507\ttrain-rmse:1.95725\n",
      "[24293]\teval-rmse:3.80649\ttrain-rmse:1.95719\n",
      "[24294]\teval-rmse:3.80788\ttrain-rmse:1.95716\n",
      "[24295]\teval-rmse:3.80772\ttrain-rmse:1.95716\n",
      "[24296]\teval-rmse:3.80713\ttrain-rmse:1.95718\n",
      "[24297]\teval-rmse:3.80798\ttrain-rmse:1.95714\n",
      "[24298]\teval-rmse:3.80915\ttrain-rmse:1.9571\n",
      "[24299]\teval-rmse:3.8095\ttrain-rmse:1.95709\n",
      "[24300]\teval-rmse:3.80802\ttrain-rmse:1.95714\n",
      "[24301]\teval-rmse:3.80681\ttrain-rmse:1.95717\n",
      "[24302]\teval-rmse:3.80637\ttrain-rmse:1.95717\n",
      "[24303]\teval-rmse:3.80476\ttrain-rmse:1.95721\n",
      "[24304]\teval-rmse:3.80455\ttrain-rmse:1.95714\n",
      "[24305]\teval-rmse:3.80356\ttrain-rmse:1.95716\n",
      "[24306]\teval-rmse:3.80334\ttrain-rmse:1.95717\n",
      "[24307]\teval-rmse:3.80313\ttrain-rmse:1.9571\n",
      "[24308]\teval-rmse:3.80319\ttrain-rmse:1.9571\n",
      "[24309]\teval-rmse:3.8022\ttrain-rmse:1.95713\n",
      "[24310]\teval-rmse:3.80273\ttrain-rmse:1.95711\n",
      "[24311]\teval-rmse:3.80258\ttrain-rmse:1.95711\n",
      "[24312]\teval-rmse:3.80235\ttrain-rmse:1.95712\n",
      "[24313]\teval-rmse:3.80373\ttrain-rmse:1.95705\n",
      "[24314]\teval-rmse:3.80218\ttrain-rmse:1.95712\n",
      "[24315]\teval-rmse:3.80378\ttrain-rmse:1.95705\n",
      "[24316]\teval-rmse:3.80363\ttrain-rmse:1.95706\n",
      "[24317]\teval-rmse:3.80349\ttrain-rmse:1.95706\n",
      "[24318]\teval-rmse:3.80509\ttrain-rmse:1.957\n",
      "[24319]\teval-rmse:3.80621\ttrain-rmse:1.95696\n",
      "[24320]\teval-rmse:3.80493\ttrain-rmse:1.95701\n",
      "[24321]\teval-rmse:3.80444\ttrain-rmse:1.95702\n",
      "[24322]\teval-rmse:3.80392\ttrain-rmse:1.95704\n",
      "[24323]\teval-rmse:3.80367\ttrain-rmse:1.95697\n",
      "[24324]\teval-rmse:3.80426\ttrain-rmse:1.95696\n",
      "[24325]\teval-rmse:3.80373\ttrain-rmse:1.95698\n",
      "[24326]\teval-rmse:3.80328\ttrain-rmse:1.95699\n",
      "[24327]\teval-rmse:3.80314\ttrain-rmse:1.957\n",
      "[24328]\teval-rmse:3.80448\ttrain-rmse:1.95693\n",
      "[24329]\teval-rmse:3.80301\ttrain-rmse:1.957\n",
      "[24330]\teval-rmse:3.80142\ttrain-rmse:1.95705\n",
      "[24331]\teval-rmse:3.801\ttrain-rmse:1.95707\n",
      "[24332]\teval-rmse:3.80227\ttrain-rmse:1.95703\n",
      "[24333]\teval-rmse:3.80364\ttrain-rmse:1.95699\n",
      "[24334]\teval-rmse:3.8045\ttrain-rmse:1.95697\n",
      "[24335]\teval-rmse:3.80427\ttrain-rmse:1.95697\n",
      "[24336]\teval-rmse:3.80491\ttrain-rmse:1.95694\n",
      "[24337]\teval-rmse:3.80373\ttrain-rmse:1.95699\n",
      "[24338]\teval-rmse:3.80192\ttrain-rmse:1.95706\n",
      "[24339]\teval-rmse:3.80352\ttrain-rmse:1.95702\n",
      "[24340]\teval-rmse:3.80382\ttrain-rmse:1.957\n",
      "[24341]\teval-rmse:3.80443\ttrain-rmse:1.95698\n",
      "[24342]\teval-rmse:3.80291\ttrain-rmse:1.95702\n",
      "[24343]\teval-rmse:3.80243\ttrain-rmse:1.95703\n",
      "[24344]\teval-rmse:3.80396\ttrain-rmse:1.95699\n",
      "[24345]\teval-rmse:3.80372\ttrain-rmse:1.957\n",
      "[24346]\teval-rmse:3.80428\ttrain-rmse:1.95697\n",
      "[24347]\teval-rmse:3.80563\ttrain-rmse:1.95692\n",
      "[24348]\teval-rmse:3.80614\ttrain-rmse:1.95691\n",
      "[24349]\teval-rmse:3.80453\ttrain-rmse:1.95694\n",
      "[24350]\teval-rmse:3.80503\ttrain-rmse:1.95692\n",
      "[24351]\teval-rmse:3.80555\ttrain-rmse:1.95691\n",
      "[24352]\teval-rmse:3.80406\ttrain-rmse:1.95694\n",
      "[24353]\teval-rmse:3.80243\ttrain-rmse:1.95699\n",
      "[24354]\teval-rmse:3.80431\ttrain-rmse:1.95693\n",
      "[24355]\teval-rmse:3.8062\ttrain-rmse:1.95689\n",
      "[24356]\teval-rmse:3.80677\ttrain-rmse:1.95687\n",
      "[24357]\teval-rmse:3.80528\ttrain-rmse:1.9569\n",
      "[24358]\teval-rmse:3.80429\ttrain-rmse:1.95693\n",
      "[24359]\teval-rmse:3.80387\ttrain-rmse:1.95694\n",
      "[24360]\teval-rmse:3.80259\ttrain-rmse:1.95699\n",
      "[24361]\teval-rmse:3.80261\ttrain-rmse:1.95699\n",
      "[24362]\teval-rmse:3.80292\ttrain-rmse:1.95698\n",
      "[24363]\teval-rmse:3.80139\ttrain-rmse:1.95703\n",
      "[24364]\teval-rmse:3.80267\ttrain-rmse:1.95699\n",
      "[24365]\teval-rmse:3.80402\ttrain-rmse:1.95693\n",
      "[24366]\teval-rmse:3.80463\ttrain-rmse:1.95691\n",
      "[24367]\teval-rmse:3.80335\ttrain-rmse:1.95697\n",
      "[24368]\teval-rmse:3.8042\ttrain-rmse:1.95693\n",
      "[24369]\teval-rmse:3.80269\ttrain-rmse:1.957\n",
      "[24370]\teval-rmse:3.80144\ttrain-rmse:1.95704\n",
      "[24371]\teval-rmse:3.80283\ttrain-rmse:1.95699\n",
      "[24372]\teval-rmse:3.80395\ttrain-rmse:1.95694\n",
      "[24373]\teval-rmse:3.80244\ttrain-rmse:1.95699\n",
      "[24374]\teval-rmse:3.80119\ttrain-rmse:1.95703\n",
      "[24375]\teval-rmse:3.80182\ttrain-rmse:1.95701\n",
      "[24376]\teval-rmse:3.80002\ttrain-rmse:1.95707\n",
      "[24377]\teval-rmse:3.7995\ttrain-rmse:1.9571\n",
      "[24378]\teval-rmse:3.80056\ttrain-rmse:1.95704\n",
      "[24379]\teval-rmse:3.80207\ttrain-rmse:1.95697\n",
      "[24380]\teval-rmse:3.8016\ttrain-rmse:1.95699\n",
      "[24381]\teval-rmse:3.80012\ttrain-rmse:1.95707\n",
      "[24382]\teval-rmse:3.79821\ttrain-rmse:1.95717\n",
      "[24383]\teval-rmse:3.79693\ttrain-rmse:1.95723\n",
      "[24384]\teval-rmse:3.7983\ttrain-rmse:1.95714\n",
      "[24385]\teval-rmse:3.79808\ttrain-rmse:1.95715\n",
      "[24386]\teval-rmse:3.79865\ttrain-rmse:1.95712\n",
      "[24387]\teval-rmse:3.79868\ttrain-rmse:1.95712\n",
      "[24388]\teval-rmse:3.79827\ttrain-rmse:1.95714\n",
      "[24389]\teval-rmse:3.79805\ttrain-rmse:1.95707\n",
      "[24390]\teval-rmse:3.79809\ttrain-rmse:1.95707\n",
      "[24391]\teval-rmse:3.79765\ttrain-rmse:1.95709\n",
      "[24392]\teval-rmse:3.79885\ttrain-rmse:1.95702\n",
      "[24393]\teval-rmse:3.80074\ttrain-rmse:1.95695\n",
      "[24394]\teval-rmse:3.79977\ttrain-rmse:1.95699\n",
      "[24395]\teval-rmse:3.79783\ttrain-rmse:1.95709\n",
      "[24396]\teval-rmse:3.7966\ttrain-rmse:1.95716\n",
      "[24397]\teval-rmse:3.79764\ttrain-rmse:1.9571\n",
      "[24398]\teval-rmse:3.7969\ttrain-rmse:1.95714\n",
      "[24399]\teval-rmse:3.7984\ttrain-rmse:1.95706\n",
      "[24400]\teval-rmse:3.79866\ttrain-rmse:1.95704\n",
      "[24401]\teval-rmse:3.8\ttrain-rmse:1.95699\n",
      "[24402]\teval-rmse:3.79977\ttrain-rmse:1.957\n",
      "[24403]\teval-rmse:3.79936\ttrain-rmse:1.95701\n",
      "[24404]\teval-rmse:3.79741\ttrain-rmse:1.95712\n",
      "[24405]\teval-rmse:3.79719\ttrain-rmse:1.95705\n",
      "[24406]\teval-rmse:3.79752\ttrain-rmse:1.95703\n",
      "[24407]\teval-rmse:3.79809\ttrain-rmse:1.95701\n",
      "[24408]\teval-rmse:3.79929\ttrain-rmse:1.95694\n",
      "[24409]\teval-rmse:3.79805\ttrain-rmse:1.95701\n",
      "[24410]\teval-rmse:3.79975\ttrain-rmse:1.95692\n",
      "[24411]\teval-rmse:3.80103\ttrain-rmse:1.95687\n",
      "[24412]\teval-rmse:3.8023\ttrain-rmse:1.95683\n",
      "[24413]\teval-rmse:3.80207\ttrain-rmse:1.95677\n",
      "[24414]\teval-rmse:3.8024\ttrain-rmse:1.95675\n",
      "[24415]\teval-rmse:3.80429\ttrain-rmse:1.9567\n",
      "[24416]\teval-rmse:3.80425\ttrain-rmse:1.9567\n",
      "[24417]\teval-rmse:3.80488\ttrain-rmse:1.95668\n",
      "[24418]\teval-rmse:3.80338\ttrain-rmse:1.95674\n",
      "[24419]\teval-rmse:3.80391\ttrain-rmse:1.95671\n",
      "[24420]\teval-rmse:3.80392\ttrain-rmse:1.95671\n",
      "[24421]\teval-rmse:3.80368\ttrain-rmse:1.95672\n",
      "[24422]\teval-rmse:3.80528\ttrain-rmse:1.95666\n",
      "[24423]\teval-rmse:3.80484\ttrain-rmse:1.95667\n",
      "[24424]\teval-rmse:3.80595\ttrain-rmse:1.95663\n",
      "[24425]\teval-rmse:3.8057\ttrain-rmse:1.95664\n",
      "[24426]\teval-rmse:3.80415\ttrain-rmse:1.95669\n",
      "[24427]\teval-rmse:3.80392\ttrain-rmse:1.9567\n",
      "[24428]\teval-rmse:3.80552\ttrain-rmse:1.95664\n",
      "[24429]\teval-rmse:3.80603\ttrain-rmse:1.95662\n",
      "[24430]\teval-rmse:3.80587\ttrain-rmse:1.95663\n",
      "[24431]\teval-rmse:3.80675\ttrain-rmse:1.9566\n",
      "[24432]\teval-rmse:3.8073\ttrain-rmse:1.95658\n",
      "[24433]\teval-rmse:3.80705\ttrain-rmse:1.95659\n",
      "[24434]\teval-rmse:3.80679\ttrain-rmse:1.95659\n",
      "[24435]\teval-rmse:3.80527\ttrain-rmse:1.95662\n",
      "[24436]\teval-rmse:3.80502\ttrain-rmse:1.95656\n",
      "[24437]\teval-rmse:3.80487\ttrain-rmse:1.95656\n",
      "[24438]\teval-rmse:3.80539\ttrain-rmse:1.95655\n",
      "[24439]\teval-rmse:3.80411\ttrain-rmse:1.9566\n",
      "[24440]\teval-rmse:3.80264\ttrain-rmse:1.95665\n",
      "[24441]\teval-rmse:3.80064\ttrain-rmse:1.95674\n",
      "[24442]\teval-rmse:3.8001\ttrain-rmse:1.95676\n",
      "[24443]\teval-rmse:3.80199\ttrain-rmse:1.95669\n",
      "[24444]\teval-rmse:3.80279\ttrain-rmse:1.95667\n",
      "[24445]\teval-rmse:3.8044\ttrain-rmse:1.9566\n",
      "[24446]\teval-rmse:3.8051\ttrain-rmse:1.95658\n",
      "[24447]\teval-rmse:3.80573\ttrain-rmse:1.95655\n",
      "[24448]\teval-rmse:3.80578\ttrain-rmse:1.95655\n",
      "[24449]\teval-rmse:3.80695\ttrain-rmse:1.95652\n",
      "[24450]\teval-rmse:3.80823\ttrain-rmse:1.95648\n",
      "[24451]\teval-rmse:3.80722\ttrain-rmse:1.9565\n",
      "[24452]\teval-rmse:3.80882\ttrain-rmse:1.95648\n",
      "[24453]\teval-rmse:3.80796\ttrain-rmse:1.9565\n",
      "[24454]\teval-rmse:3.80881\ttrain-rmse:1.95649\n",
      "[24455]\teval-rmse:3.80943\ttrain-rmse:1.95647\n",
      "[24456]\teval-rmse:3.81106\ttrain-rmse:1.95646\n",
      "[24457]\teval-rmse:3.81129\ttrain-rmse:1.95646\n",
      "[24458]\teval-rmse:3.81158\ttrain-rmse:1.95645\n",
      "[24459]\teval-rmse:3.81132\ttrain-rmse:1.95645\n",
      "[24460]\teval-rmse:3.81076\ttrain-rmse:1.95646\n",
      "[24461]\teval-rmse:3.81094\ttrain-rmse:1.95646\n",
      "[24462]\teval-rmse:3.81282\ttrain-rmse:1.95644\n",
      "[24463]\teval-rmse:3.81178\ttrain-rmse:1.95645\n",
      "[24464]\teval-rmse:3.81316\ttrain-rmse:1.95645\n",
      "[24465]\teval-rmse:3.8116\ttrain-rmse:1.95645\n",
      "[24466]\teval-rmse:3.81029\ttrain-rmse:1.95646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24467]\teval-rmse:3.81153\ttrain-rmse:1.95644\n",
      "[24468]\teval-rmse:3.81114\ttrain-rmse:1.95644\n",
      "[24469]\teval-rmse:3.81012\ttrain-rmse:1.95646\n",
      "[24470]\teval-rmse:3.81137\ttrain-rmse:1.95645\n",
      "[24471]\teval-rmse:3.81076\ttrain-rmse:1.95645\n",
      "[24472]\teval-rmse:3.8094\ttrain-rmse:1.95646\n",
      "[24473]\teval-rmse:3.80999\ttrain-rmse:1.95645\n",
      "[24474]\teval-rmse:3.80862\ttrain-rmse:1.95648\n",
      "[24475]\teval-rmse:3.80732\ttrain-rmse:1.95651\n",
      "[24476]\teval-rmse:3.80884\ttrain-rmse:1.95648\n",
      "[24477]\teval-rmse:3.80833\ttrain-rmse:1.95648\n",
      "[24478]\teval-rmse:3.80868\ttrain-rmse:1.95647\n",
      "[24479]\teval-rmse:3.81007\ttrain-rmse:1.95645\n",
      "[24480]\teval-rmse:3.80956\ttrain-rmse:1.95646\n",
      "[24481]\teval-rmse:3.80929\ttrain-rmse:1.95646\n",
      "[24482]\teval-rmse:3.81032\ttrain-rmse:1.95645\n",
      "[24483]\teval-rmse:3.8117\ttrain-rmse:1.95644\n",
      "[24484]\teval-rmse:3.81082\ttrain-rmse:1.95644\n",
      "[24485]\teval-rmse:3.81115\ttrain-rmse:1.95644\n",
      "[24486]\teval-rmse:3.81284\ttrain-rmse:1.95641\n",
      "[24487]\teval-rmse:3.81335\ttrain-rmse:1.95641\n",
      "[24488]\teval-rmse:3.81504\ttrain-rmse:1.95638\n",
      "[24489]\teval-rmse:3.81484\ttrain-rmse:1.95639\n",
      "[24490]\teval-rmse:3.81533\ttrain-rmse:1.95639\n",
      "[24491]\teval-rmse:3.81692\ttrain-rmse:1.9564\n",
      "[24492]\teval-rmse:3.8152\ttrain-rmse:1.9564\n",
      "[24493]\teval-rmse:3.81637\ttrain-rmse:1.9564\n",
      "[24494]\teval-rmse:3.81576\ttrain-rmse:1.95639\n",
      "[24495]\teval-rmse:3.81735\ttrain-rmse:1.95638\n",
      "[24496]\teval-rmse:3.81576\ttrain-rmse:1.95638\n",
      "[24497]\teval-rmse:3.81535\ttrain-rmse:1.95638\n",
      "[24498]\teval-rmse:3.81472\ttrain-rmse:1.95637\n",
      "[24499]\teval-rmse:3.81412\ttrain-rmse:1.95637\n",
      "[24500]\teval-rmse:3.81255\ttrain-rmse:1.95637\n",
      "[24501]\teval-rmse:3.81309\ttrain-rmse:1.95637\n",
      "[24502]\teval-rmse:3.81153\ttrain-rmse:1.95637\n",
      "[24503]\teval-rmse:3.81021\ttrain-rmse:1.95639\n",
      "[24504]\teval-rmse:3.80891\ttrain-rmse:1.95642\n",
      "[24505]\teval-rmse:3.80741\ttrain-rmse:1.95645\n",
      "[24506]\teval-rmse:3.80606\ttrain-rmse:1.95648\n",
      "[24507]\teval-rmse:3.80485\ttrain-rmse:1.95651\n",
      "[24508]\teval-rmse:3.80442\ttrain-rmse:1.95652\n",
      "[24509]\teval-rmse:3.80603\ttrain-rmse:1.95648\n",
      "[24510]\teval-rmse:3.80741\ttrain-rmse:1.95644\n",
      "[24511]\teval-rmse:3.80762\ttrain-rmse:1.95644\n",
      "[24512]\teval-rmse:3.80782\ttrain-rmse:1.95643\n",
      "[24513]\teval-rmse:3.80756\ttrain-rmse:1.95644\n",
      "[24514]\teval-rmse:3.80891\ttrain-rmse:1.95642\n",
      "[24515]\teval-rmse:3.8079\ttrain-rmse:1.95644\n",
      "[24516]\teval-rmse:3.80773\ttrain-rmse:1.95644\n",
      "[24517]\teval-rmse:3.80943\ttrain-rmse:1.95643\n",
      "[24518]\teval-rmse:3.81074\ttrain-rmse:1.95642\n",
      "[24519]\teval-rmse:3.81228\ttrain-rmse:1.95641\n",
      "[24520]\teval-rmse:3.81145\ttrain-rmse:1.95641\n",
      "[24521]\teval-rmse:3.81022\ttrain-rmse:1.95644\n",
      "[24522]\teval-rmse:3.8104\ttrain-rmse:1.95643\n",
      "[24523]\teval-rmse:3.80993\ttrain-rmse:1.95644\n",
      "[24524]\teval-rmse:3.81048\ttrain-rmse:1.95643\n",
      "[24525]\teval-rmse:3.81111\ttrain-rmse:1.95643\n",
      "[24526]\teval-rmse:3.81009\ttrain-rmse:1.95644\n",
      "[24527]\teval-rmse:3.80844\ttrain-rmse:1.95645\n",
      "[24528]\teval-rmse:3.80789\ttrain-rmse:1.95645\n",
      "[24529]\teval-rmse:3.80815\ttrain-rmse:1.95645\n",
      "[24530]\teval-rmse:3.80798\ttrain-rmse:1.95645\n",
      "[24531]\teval-rmse:3.80827\ttrain-rmse:1.95645\n",
      "[24532]\teval-rmse:3.80809\ttrain-rmse:1.95645\n",
      "[24533]\teval-rmse:3.80792\ttrain-rmse:1.95646\n",
      "[24534]\teval-rmse:3.8093\ttrain-rmse:1.95644\n",
      "[24535]\teval-rmse:3.80884\ttrain-rmse:1.95646\n",
      "[24536]\teval-rmse:3.80917\ttrain-rmse:1.95645\n",
      "[24537]\teval-rmse:3.80872\ttrain-rmse:1.95646\n",
      "[24538]\teval-rmse:3.80716\ttrain-rmse:1.95648\n",
      "[24539]\teval-rmse:3.80666\ttrain-rmse:1.95649\n",
      "[24540]\teval-rmse:3.80643\ttrain-rmse:1.95643\n",
      "[24541]\teval-rmse:3.80599\ttrain-rmse:1.95644\n",
      "[24542]\teval-rmse:3.80629\ttrain-rmse:1.95644\n",
      "[24543]\teval-rmse:3.80654\ttrain-rmse:1.95643\n",
      "[24544]\teval-rmse:3.80766\ttrain-rmse:1.95641\n",
      "[24545]\teval-rmse:3.80743\ttrain-rmse:1.95635\n",
      "[24546]\teval-rmse:3.80897\ttrain-rmse:1.95633\n",
      "[24547]\teval-rmse:3.80871\ttrain-rmse:1.95633\n",
      "[24548]\teval-rmse:3.80892\ttrain-rmse:1.95633\n",
      "[24549]\teval-rmse:3.80846\ttrain-rmse:1.95634\n",
      "[24550]\teval-rmse:3.81033\ttrain-rmse:1.95631\n",
      "[24551]\teval-rmse:3.81187\ttrain-rmse:1.95631\n",
      "[24552]\teval-rmse:3.81032\ttrain-rmse:1.95632\n",
      "[24553]\teval-rmse:3.81191\ttrain-rmse:1.95629\n",
      "[24554]\teval-rmse:3.81135\ttrain-rmse:1.9563\n",
      "[24555]\teval-rmse:3.8118\ttrain-rmse:1.9563\n",
      "[24556]\teval-rmse:3.81319\ttrain-rmse:1.9563\n",
      "[24557]\teval-rmse:3.81186\ttrain-rmse:1.9563\n",
      "[24558]\teval-rmse:3.81054\ttrain-rmse:1.9563\n",
      "[24559]\teval-rmse:3.81223\ttrain-rmse:1.95626\n",
      "[24560]\teval-rmse:3.8129\ttrain-rmse:1.95626\n",
      "[24561]\teval-rmse:3.81242\ttrain-rmse:1.95627\n",
      "[24562]\teval-rmse:3.81185\ttrain-rmse:1.95628\n",
      "[24563]\teval-rmse:3.81182\ttrain-rmse:1.95628\n",
      "[24564]\teval-rmse:3.81157\ttrain-rmse:1.95621\n",
      "[24565]\teval-rmse:3.81101\ttrain-rmse:1.95622\n",
      "[24566]\teval-rmse:3.80949\ttrain-rmse:1.95623\n",
      "[24567]\teval-rmse:3.81011\ttrain-rmse:1.95623\n",
      "[24568]\teval-rmse:3.81114\ttrain-rmse:1.95622\n",
      "[24569]\teval-rmse:3.81086\ttrain-rmse:1.95622\n",
      "[24570]\teval-rmse:3.81025\ttrain-rmse:1.95622\n",
      "[24571]\teval-rmse:3.81001\ttrain-rmse:1.95616\n",
      "[24572]\teval-rmse:3.81147\ttrain-rmse:1.95616\n",
      "[24573]\teval-rmse:3.80973\ttrain-rmse:1.95617\n",
      "[24574]\teval-rmse:3.81083\ttrain-rmse:1.95616\n",
      "[24575]\teval-rmse:3.81258\ttrain-rmse:1.95617\n",
      "[24576]\teval-rmse:3.81154\ttrain-rmse:1.95618\n",
      "[24577]\teval-rmse:3.81341\ttrain-rmse:1.95617\n",
      "[24578]\teval-rmse:3.81402\ttrain-rmse:1.95617\n",
      "[24579]\teval-rmse:3.81453\ttrain-rmse:1.95618\n",
      "[24580]\teval-rmse:3.81433\ttrain-rmse:1.95618\n",
      "[24581]\teval-rmse:3.8131\ttrain-rmse:1.95617\n",
      "[24582]\teval-rmse:3.81342\ttrain-rmse:1.95617\n",
      "[24583]\teval-rmse:3.81361\ttrain-rmse:1.95617\n",
      "[24584]\teval-rmse:3.81197\ttrain-rmse:1.95616\n",
      "[24585]\teval-rmse:3.81169\ttrain-rmse:1.95617\n",
      "[24586]\teval-rmse:3.81122\ttrain-rmse:1.95618\n",
      "[24587]\teval-rmse:3.80939\ttrain-rmse:1.95619\n",
      "[24588]\teval-rmse:3.80939\ttrain-rmse:1.95619\n",
      "[24589]\teval-rmse:3.80999\ttrain-rmse:1.95619\n",
      "[24590]\teval-rmse:3.81046\ttrain-rmse:1.95618\n",
      "[24591]\teval-rmse:3.80944\ttrain-rmse:1.9562\n",
      "[24592]\teval-rmse:3.81102\ttrain-rmse:1.95616\n",
      "[24593]\teval-rmse:3.80916\ttrain-rmse:1.95618\n",
      "[24594]\teval-rmse:3.80889\ttrain-rmse:1.95619\n",
      "[24595]\teval-rmse:3.81054\ttrain-rmse:1.95618\n",
      "[24596]\teval-rmse:3.81036\ttrain-rmse:1.95618\n",
      "[24597]\teval-rmse:3.81059\ttrain-rmse:1.95618\n",
      "[24598]\teval-rmse:3.80907\ttrain-rmse:1.9562\n",
      "[24599]\teval-rmse:3.80938\ttrain-rmse:1.95619\n",
      "[24600]\teval-rmse:3.80911\ttrain-rmse:1.9562\n",
      "[24601]\teval-rmse:3.80776\ttrain-rmse:1.95621\n",
      "[24602]\teval-rmse:3.80804\ttrain-rmse:1.95621\n",
      "[24603]\teval-rmse:3.80781\ttrain-rmse:1.95615\n",
      "[24604]\teval-rmse:3.80914\ttrain-rmse:1.95613\n",
      "[24605]\teval-rmse:3.8089\ttrain-rmse:1.95607\n",
      "[24606]\teval-rmse:3.81058\ttrain-rmse:1.95604\n",
      "[24607]\teval-rmse:3.80922\ttrain-rmse:1.95605\n",
      "[24608]\teval-rmse:3.80801\ttrain-rmse:1.95605\n",
      "[24609]\teval-rmse:3.80649\ttrain-rmse:1.95607\n",
      "[24610]\teval-rmse:3.80776\ttrain-rmse:1.95606\n",
      "[24611]\teval-rmse:3.80823\ttrain-rmse:1.95605\n",
      "[24612]\teval-rmse:3.80777\ttrain-rmse:1.95606\n",
      "[24613]\teval-rmse:3.80751\ttrain-rmse:1.95606\n",
      "[24614]\teval-rmse:3.80725\ttrain-rmse:1.95607\n",
      "[24615]\teval-rmse:3.80812\ttrain-rmse:1.95606\n",
      "[24616]\teval-rmse:3.80971\ttrain-rmse:1.95605\n",
      "[24617]\teval-rmse:3.80944\ttrain-rmse:1.95599\n",
      "[24618]\teval-rmse:3.80861\ttrain-rmse:1.95599\n",
      "[24619]\teval-rmse:3.80943\ttrain-rmse:1.95598\n",
      "[24620]\teval-rmse:3.81055\ttrain-rmse:1.95598\n",
      "[24621]\teval-rmse:3.80924\ttrain-rmse:1.95599\n",
      "[24622]\teval-rmse:3.81058\ttrain-rmse:1.95598\n",
      "[24623]\teval-rmse:3.80927\ttrain-rmse:1.95601\n",
      "[24624]\teval-rmse:3.80909\ttrain-rmse:1.95601\n",
      "[24625]\teval-rmse:3.80957\ttrain-rmse:1.95601\n",
      "[24626]\teval-rmse:3.80899\ttrain-rmse:1.95601\n",
      "[24627]\teval-rmse:3.8085\ttrain-rmse:1.95601\n",
      "[24628]\teval-rmse:3.80823\ttrain-rmse:1.95595\n",
      "[24629]\teval-rmse:3.80841\ttrain-rmse:1.95595\n",
      "[24630]\teval-rmse:3.80711\ttrain-rmse:1.95595\n",
      "[24631]\teval-rmse:3.80552\ttrain-rmse:1.95597\n",
      "[24632]\teval-rmse:3.80581\ttrain-rmse:1.95597\n",
      "[24633]\teval-rmse:3.80583\ttrain-rmse:1.95597\n",
      "[24634]\teval-rmse:3.80533\ttrain-rmse:1.95598\n",
      "[24635]\teval-rmse:3.80531\ttrain-rmse:1.95598\n",
      "[24636]\teval-rmse:3.80506\ttrain-rmse:1.95598\n",
      "[24637]\teval-rmse:3.80657\ttrain-rmse:1.95598\n",
      "[24638]\teval-rmse:3.80769\ttrain-rmse:1.95597\n",
      "[24639]\teval-rmse:3.80753\ttrain-rmse:1.95597\n",
      "[24640]\teval-rmse:3.80601\ttrain-rmse:1.95598\n",
      "[24641]\teval-rmse:3.80535\ttrain-rmse:1.95599\n",
      "[24642]\teval-rmse:3.80383\ttrain-rmse:1.95602\n",
      "[24643]\teval-rmse:3.8024\ttrain-rmse:1.95605\n",
      "[24644]\teval-rmse:3.80113\ttrain-rmse:1.95608\n",
      "[24645]\teval-rmse:3.80199\ttrain-rmse:1.95605\n",
      "[24646]\teval-rmse:3.80147\ttrain-rmse:1.95606\n",
      "[24647]\teval-rmse:3.80229\ttrain-rmse:1.95604\n",
      "[24648]\teval-rmse:3.8008\ttrain-rmse:1.95608\n",
      "[24649]\teval-rmse:3.80123\ttrain-rmse:1.95606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24650]\teval-rmse:3.8028\ttrain-rmse:1.95602\n",
      "[24651]\teval-rmse:3.80083\ttrain-rmse:1.95607\n",
      "[24652]\teval-rmse:3.80097\ttrain-rmse:1.95606\n",
      "[24653]\teval-rmse:3.80076\ttrain-rmse:1.95607\n",
      "[24654]\teval-rmse:3.79872\ttrain-rmse:1.95612\n",
      "[24655]\teval-rmse:3.80008\ttrain-rmse:1.95608\n",
      "[24656]\teval-rmse:3.79849\ttrain-rmse:1.95613\n",
      "[24657]\teval-rmse:3.79966\ttrain-rmse:1.9561\n",
      "[24658]\teval-rmse:3.8003\ttrain-rmse:1.95608\n",
      "[24659]\teval-rmse:3.80143\ttrain-rmse:1.95604\n",
      "[24660]\teval-rmse:3.80119\ttrain-rmse:1.95605\n",
      "[24661]\teval-rmse:3.80054\ttrain-rmse:1.95607\n",
      "[24662]\teval-rmse:3.80031\ttrain-rmse:1.95607\n",
      "[24663]\teval-rmse:3.80046\ttrain-rmse:1.95607\n",
      "[24664]\teval-rmse:3.799\ttrain-rmse:1.95612\n",
      "[24665]\teval-rmse:3.79775\ttrain-rmse:1.95618\n",
      "[24666]\teval-rmse:3.79836\ttrain-rmse:1.95616\n",
      "[24667]\teval-rmse:3.79996\ttrain-rmse:1.95611\n",
      "[24668]\teval-rmse:3.80185\ttrain-rmse:1.95605\n",
      "[24669]\teval-rmse:3.8017\ttrain-rmse:1.95605\n",
      "[24670]\teval-rmse:3.80127\ttrain-rmse:1.95607\n",
      "[24671]\teval-rmse:3.80262\ttrain-rmse:1.95603\n",
      "[24672]\teval-rmse:3.80102\ttrain-rmse:1.95608\n",
      "[24673]\teval-rmse:3.8006\ttrain-rmse:1.95609\n",
      "[24674]\teval-rmse:3.8004\ttrain-rmse:1.95604\n",
      "[24675]\teval-rmse:3.80092\ttrain-rmse:1.95602\n",
      "[24676]\teval-rmse:3.80218\ttrain-rmse:1.95599\n",
      "[24677]\teval-rmse:3.80374\ttrain-rmse:1.95596\n",
      "[24678]\teval-rmse:3.80329\ttrain-rmse:1.95597\n",
      "[24679]\teval-rmse:3.8038\ttrain-rmse:1.95596\n",
      "[24680]\teval-rmse:3.80495\ttrain-rmse:1.95594\n",
      "[24681]\teval-rmse:3.80311\ttrain-rmse:1.95598\n",
      "[24682]\teval-rmse:3.80364\ttrain-rmse:1.95596\n",
      "[24683]\teval-rmse:3.80321\ttrain-rmse:1.95598\n",
      "[24684]\teval-rmse:3.80404\ttrain-rmse:1.95596\n",
      "[24685]\teval-rmse:3.80455\ttrain-rmse:1.95595\n",
      "[24686]\teval-rmse:3.80611\ttrain-rmse:1.95593\n",
      "[24687]\teval-rmse:3.80747\ttrain-rmse:1.95592\n",
      "[24688]\teval-rmse:3.80701\ttrain-rmse:1.95593\n",
      "[24689]\teval-rmse:3.80828\ttrain-rmse:1.95593\n",
      "[24690]\teval-rmse:3.80782\ttrain-rmse:1.95593\n",
      "[24691]\teval-rmse:3.80916\ttrain-rmse:1.95592\n",
      "[24692]\teval-rmse:3.81083\ttrain-rmse:1.95589\n",
      "[24693]\teval-rmse:3.81217\ttrain-rmse:1.9559\n",
      "[24694]\teval-rmse:3.81085\ttrain-rmse:1.95592\n",
      "[24695]\teval-rmse:3.81136\ttrain-rmse:1.95592\n",
      "[24696]\teval-rmse:3.81186\ttrain-rmse:1.95593\n",
      "[24697]\teval-rmse:3.81158\ttrain-rmse:1.95593\n",
      "[24698]\teval-rmse:3.81054\ttrain-rmse:1.95594\n",
      "[24699]\teval-rmse:3.81026\ttrain-rmse:1.95594\n",
      "[24700]\teval-rmse:3.81194\ttrain-rmse:1.95596\n",
      "[24701]\teval-rmse:3.81167\ttrain-rmse:1.95596\n",
      "[24702]\teval-rmse:3.80959\ttrain-rmse:1.95593\n",
      "[24703]\teval-rmse:3.81062\ttrain-rmse:1.95594\n",
      "[24704]\teval-rmse:3.81196\ttrain-rmse:1.95595\n",
      "[24705]\teval-rmse:3.81243\ttrain-rmse:1.95596\n",
      "[24706]\teval-rmse:3.81082\ttrain-rmse:1.95594\n",
      "[24707]\teval-rmse:3.81209\ttrain-rmse:1.95595\n",
      "[24708]\teval-rmse:3.81021\ttrain-rmse:1.95593\n",
      "[24709]\teval-rmse:3.81174\ttrain-rmse:1.95595\n",
      "[24710]\teval-rmse:3.81219\ttrain-rmse:1.95596\n",
      "[24711]\teval-rmse:3.81095\ttrain-rmse:1.95594\n",
      "[24712]\teval-rmse:3.81055\ttrain-rmse:1.95594\n",
      "[24713]\teval-rmse:3.80977\ttrain-rmse:1.95593\n",
      "[24714]\teval-rmse:3.81028\ttrain-rmse:1.95594\n",
      "[24715]\teval-rmse:3.81049\ttrain-rmse:1.95594\n",
      "[24716]\teval-rmse:3.80882\ttrain-rmse:1.95594\n",
      "[24717]\teval-rmse:3.80823\ttrain-rmse:1.95593\n",
      "[24718]\teval-rmse:3.80765\ttrain-rmse:1.95593\n",
      "[24719]\teval-rmse:3.80918\ttrain-rmse:1.95594\n",
      "[24720]\teval-rmse:3.81073\ttrain-rmse:1.95595\n",
      "[24721]\teval-rmse:3.81228\ttrain-rmse:1.95597\n",
      "[24722]\teval-rmse:3.81199\ttrain-rmse:1.95597\n",
      "[24723]\teval-rmse:3.81042\ttrain-rmse:1.95595\n",
      "[24724]\teval-rmse:3.80835\ttrain-rmse:1.95594\n",
      "[24725]\teval-rmse:3.80895\ttrain-rmse:1.95595\n",
      "[24726]\teval-rmse:3.80868\ttrain-rmse:1.95595\n",
      "[24727]\teval-rmse:3.80766\ttrain-rmse:1.95596\n",
      "[24728]\teval-rmse:3.8072\ttrain-rmse:1.95597\n",
      "[24729]\teval-rmse:3.80694\ttrain-rmse:1.95597\n",
      "[24730]\teval-rmse:3.80506\ttrain-rmse:1.95599\n",
      "[24731]\teval-rmse:3.80345\ttrain-rmse:1.95601\n",
      "[24732]\teval-rmse:3.80364\ttrain-rmse:1.95601\n",
      "[24733]\teval-rmse:3.80392\ttrain-rmse:1.956\n",
      "[24734]\teval-rmse:3.80376\ttrain-rmse:1.956\n",
      "[24735]\teval-rmse:3.8018\ttrain-rmse:1.95605\n",
      "[24736]\teval-rmse:3.80208\ttrain-rmse:1.95604\n",
      "[24737]\teval-rmse:3.8011\ttrain-rmse:1.95607\n",
      "[24738]\teval-rmse:3.80241\ttrain-rmse:1.95604\n",
      "[24739]\teval-rmse:3.80089\ttrain-rmse:1.95608\n",
      "[24740]\teval-rmse:3.79931\ttrain-rmse:1.95611\n",
      "[24741]\teval-rmse:3.79985\ttrain-rmse:1.9561\n",
      "[24742]\teval-rmse:3.80047\ttrain-rmse:1.95609\n",
      "[24743]\teval-rmse:3.80181\ttrain-rmse:1.95605\n",
      "[24744]\teval-rmse:3.80201\ttrain-rmse:1.95604\n",
      "[24745]\teval-rmse:3.80389\ttrain-rmse:1.95599\n",
      "[24746]\teval-rmse:3.80503\ttrain-rmse:1.95597\n",
      "[24747]\teval-rmse:3.80458\ttrain-rmse:1.95598\n",
      "[24748]\teval-rmse:3.80588\ttrain-rmse:1.95597\n",
      "[24749]\teval-rmse:3.80621\ttrain-rmse:1.95597\n",
      "[24750]\teval-rmse:3.80675\ttrain-rmse:1.95597\n",
      "[24751]\teval-rmse:3.80545\ttrain-rmse:1.956\n",
      "[24752]\teval-rmse:3.80651\ttrain-rmse:1.95599\n",
      "[24753]\teval-rmse:3.8076\ttrain-rmse:1.95599\n",
      "[24754]\teval-rmse:3.80609\ttrain-rmse:1.95599\n",
      "[24755]\teval-rmse:3.80451\ttrain-rmse:1.956\n",
      "[24756]\teval-rmse:3.80551\ttrain-rmse:1.95599\n",
      "[24757]\teval-rmse:3.8061\ttrain-rmse:1.95599\n",
      "[24758]\teval-rmse:3.80587\ttrain-rmse:1.95592\n",
      "[24759]\teval-rmse:3.80688\ttrain-rmse:1.95592\n",
      "[24760]\teval-rmse:3.80554\ttrain-rmse:1.95592\n",
      "[24761]\teval-rmse:3.80528\ttrain-rmse:1.95593\n",
      "[24762]\teval-rmse:3.80648\ttrain-rmse:1.95592\n",
      "[24763]\teval-rmse:3.80801\ttrain-rmse:1.95591\n",
      "[24764]\teval-rmse:3.8068\ttrain-rmse:1.95594\n",
      "[24765]\teval-rmse:3.807\ttrain-rmse:1.95594\n",
      "[24766]\teval-rmse:3.80675\ttrain-rmse:1.95594\n",
      "[24767]\teval-rmse:3.80726\ttrain-rmse:1.95594\n",
      "[24768]\teval-rmse:3.80561\ttrain-rmse:1.95595\n",
      "[24769]\teval-rmse:3.8059\ttrain-rmse:1.95594\n",
      "[24770]\teval-rmse:3.80702\ttrain-rmse:1.95595\n",
      "[24771]\teval-rmse:3.80859\ttrain-rmse:1.95595\n",
      "[24772]\teval-rmse:3.80803\ttrain-rmse:1.95596\n",
      "[24773]\teval-rmse:3.80863\ttrain-rmse:1.95596\n",
      "[24774]\teval-rmse:3.8102\ttrain-rmse:1.95593\n",
      "[24775]\teval-rmse:3.80889\ttrain-rmse:1.95596\n",
      "[24776]\teval-rmse:3.80836\ttrain-rmse:1.95595\n",
      "[24777]\teval-rmse:3.80784\ttrain-rmse:1.95595\n",
      "[24778]\teval-rmse:3.80778\ttrain-rmse:1.95595\n",
      "[24779]\teval-rmse:3.80699\ttrain-rmse:1.95595\n",
      "[24780]\teval-rmse:3.80534\ttrain-rmse:1.95597\n",
      "[24781]\teval-rmse:3.80329\ttrain-rmse:1.95598\n",
      "[24782]\teval-rmse:3.8036\ttrain-rmse:1.95597\n",
      "[24783]\teval-rmse:3.80408\ttrain-rmse:1.95597\n",
      "[24784]\teval-rmse:3.80363\ttrain-rmse:1.95598\n",
      "[24785]\teval-rmse:3.80393\ttrain-rmse:1.95598\n",
      "[24786]\teval-rmse:3.80265\ttrain-rmse:1.95599\n",
      "[24787]\teval-rmse:3.80191\ttrain-rmse:1.956\n",
      "[24788]\teval-rmse:3.80309\ttrain-rmse:1.95599\n",
      "[24789]\teval-rmse:3.80468\ttrain-rmse:1.95596\n",
      "[24790]\teval-rmse:3.80368\ttrain-rmse:1.95598\n",
      "[24791]\teval-rmse:3.80504\ttrain-rmse:1.95598\n",
      "[24792]\teval-rmse:3.80658\ttrain-rmse:1.95598\n",
      "[24793]\teval-rmse:3.80633\ttrain-rmse:1.95598\n",
      "[24794]\teval-rmse:3.80429\ttrain-rmse:1.95598\n",
      "[24795]\teval-rmse:3.80463\ttrain-rmse:1.95598\n",
      "[24796]\teval-rmse:3.80651\ttrain-rmse:1.95594\n",
      "[24797]\teval-rmse:3.80692\ttrain-rmse:1.95594\n",
      "[24798]\teval-rmse:3.80489\ttrain-rmse:1.95594\n",
      "[24799]\teval-rmse:3.80619\ttrain-rmse:1.95594\n",
      "[24800]\teval-rmse:3.80573\ttrain-rmse:1.95594\n",
      "[24801]\teval-rmse:3.80635\ttrain-rmse:1.95594\n",
      "[24802]\teval-rmse:3.80589\ttrain-rmse:1.95595\n",
      "[24803]\teval-rmse:3.80689\ttrain-rmse:1.95595\n",
      "[24804]\teval-rmse:3.80607\ttrain-rmse:1.95595\n",
      "[24805]\teval-rmse:3.80633\ttrain-rmse:1.95595\n",
      "[24806]\teval-rmse:3.80653\ttrain-rmse:1.95594\n",
      "[24807]\teval-rmse:3.80841\ttrain-rmse:1.95591\n",
      "[24808]\teval-rmse:3.80965\ttrain-rmse:1.95592\n",
      "[24809]\teval-rmse:3.81132\ttrain-rmse:1.95589\n",
      "[24810]\teval-rmse:3.81047\ttrain-rmse:1.95588\n",
      "[24811]\teval-rmse:3.80965\ttrain-rmse:1.95588\n",
      "[24812]\teval-rmse:3.81015\ttrain-rmse:1.95589\n",
      "[24813]\teval-rmse:3.81203\ttrain-rmse:1.95587\n",
      "[24814]\teval-rmse:3.81174\ttrain-rmse:1.95587\n",
      "[24815]\teval-rmse:3.81361\ttrain-rmse:1.95586\n",
      "[24816]\teval-rmse:3.81332\ttrain-rmse:1.95586\n",
      "[24817]\teval-rmse:3.81433\ttrain-rmse:1.95588\n",
      "[24818]\teval-rmse:3.81556\ttrain-rmse:1.9559\n",
      "[24819]\teval-rmse:3.81351\ttrain-rmse:1.95587\n",
      "[24820]\teval-rmse:3.81246\ttrain-rmse:1.95588\n",
      "[24821]\teval-rmse:3.81217\ttrain-rmse:1.95588\n",
      "[24822]\teval-rmse:3.8135\ttrain-rmse:1.95589\n",
      "[24823]\teval-rmse:3.8132\ttrain-rmse:1.95589\n",
      "[24824]\teval-rmse:3.81271\ttrain-rmse:1.95588\n",
      "[24825]\teval-rmse:3.81192\ttrain-rmse:1.95588\n",
      "[24826]\teval-rmse:3.81297\ttrain-rmse:1.95589\n",
      "[24827]\teval-rmse:3.8127\ttrain-rmse:1.95589\n",
      "[24828]\teval-rmse:3.81327\ttrain-rmse:1.95589\n",
      "[24829]\teval-rmse:3.81298\ttrain-rmse:1.9559\n",
      "[24830]\teval-rmse:3.8125\ttrain-rmse:1.95589\n",
      "[24831]\teval-rmse:3.81281\ttrain-rmse:1.95589\n",
      "[24832]\teval-rmse:3.81123\ttrain-rmse:1.95587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24833]\teval-rmse:3.81117\ttrain-rmse:1.95587\n",
      "[24834]\teval-rmse:3.81276\ttrain-rmse:1.95588\n",
      "[24835]\teval-rmse:3.81151\ttrain-rmse:1.95589\n",
      "[24836]\teval-rmse:3.81082\ttrain-rmse:1.95589\n",
      "[24837]\teval-rmse:3.81135\ttrain-rmse:1.95589\n",
      "[24838]\teval-rmse:3.81164\ttrain-rmse:1.95589\n",
      "[24839]\teval-rmse:3.81037\ttrain-rmse:1.95589\n",
      "[24840]\teval-rmse:3.80984\ttrain-rmse:1.95589\n",
      "[24841]\teval-rmse:3.81033\ttrain-rmse:1.95589\n",
      "[24842]\teval-rmse:3.80951\ttrain-rmse:1.95589\n",
      "[24843]\teval-rmse:3.80895\ttrain-rmse:1.9559\n",
      "[24844]\teval-rmse:3.80929\ttrain-rmse:1.9559\n",
      "[24845]\teval-rmse:3.80995\ttrain-rmse:1.9559\n",
      "[24846]\teval-rmse:3.8112\ttrain-rmse:1.95591\n",
      "[24847]\teval-rmse:3.81169\ttrain-rmse:1.95591\n",
      "[24848]\teval-rmse:3.81202\ttrain-rmse:1.95592\n",
      "[24849]\teval-rmse:3.81231\ttrain-rmse:1.95592\n",
      "[24850]\teval-rmse:3.81203\ttrain-rmse:1.95592\n",
      "[24851]\teval-rmse:3.81185\ttrain-rmse:1.95591\n",
      "[24852]\teval-rmse:3.81237\ttrain-rmse:1.95592\n",
      "[24853]\teval-rmse:3.8137\ttrain-rmse:1.95594\n",
      "[24854]\teval-rmse:3.81312\ttrain-rmse:1.95595\n",
      "[24855]\teval-rmse:3.81264\ttrain-rmse:1.95594\n",
      "[24856]\teval-rmse:3.81279\ttrain-rmse:1.95595\n",
      "[24857]\teval-rmse:3.81111\ttrain-rmse:1.95592\n",
      "[24858]\teval-rmse:3.81033\ttrain-rmse:1.95591\n",
      "[24859]\teval-rmse:3.81086\ttrain-rmse:1.95591\n",
      "[24860]\teval-rmse:3.81058\ttrain-rmse:1.95586\n",
      "[24861]\teval-rmse:3.81166\ttrain-rmse:1.95588\n",
      "[24862]\teval-rmse:3.80999\ttrain-rmse:1.95585\n",
      "[24863]\teval-rmse:3.80896\ttrain-rmse:1.95586\n",
      "[24864]\teval-rmse:3.80849\ttrain-rmse:1.95587\n",
      "[24865]\teval-rmse:3.81036\ttrain-rmse:1.95585\n",
      "[24866]\teval-rmse:3.80898\ttrain-rmse:1.95585\n",
      "[24867]\teval-rmse:3.81022\ttrain-rmse:1.95585\n",
      "[24868]\teval-rmse:3.81004\ttrain-rmse:1.95585\n",
      "[24869]\teval-rmse:3.81026\ttrain-rmse:1.95585\n",
      "[24870]\teval-rmse:3.8105\ttrain-rmse:1.95585\n",
      "[24871]\teval-rmse:3.80919\ttrain-rmse:1.95584\n",
      "[24872]\teval-rmse:3.80942\ttrain-rmse:1.95584\n",
      "[24873]\teval-rmse:3.80915\ttrain-rmse:1.95585\n",
      "[24874]\teval-rmse:3.80889\ttrain-rmse:1.95585\n",
      "[24875]\teval-rmse:3.80971\ttrain-rmse:1.95585\n",
      "[24876]\teval-rmse:3.81004\ttrain-rmse:1.95585\n",
      "[24877]\teval-rmse:3.80901\ttrain-rmse:1.95586\n",
      "[24878]\teval-rmse:3.80798\ttrain-rmse:1.95588\n",
      "[24879]\teval-rmse:3.80647\ttrain-rmse:1.95587\n",
      "[24880]\teval-rmse:3.80731\ttrain-rmse:1.95587\n",
      "[24881]\teval-rmse:3.80855\ttrain-rmse:1.95588\n",
      "[24882]\teval-rmse:3.80668\ttrain-rmse:1.95588\n",
      "[24883]\teval-rmse:3.80654\ttrain-rmse:1.95588\n",
      "[24884]\teval-rmse:3.80669\ttrain-rmse:1.95588\n",
      "[24885]\teval-rmse:3.80833\ttrain-rmse:1.95589\n",
      "[24886]\teval-rmse:3.80702\ttrain-rmse:1.95589\n",
      "[24887]\teval-rmse:3.8075\ttrain-rmse:1.95588\n",
      "[24888]\teval-rmse:3.8075\ttrain-rmse:1.95588\n",
      "[24889]\teval-rmse:3.80867\ttrain-rmse:1.95589\n",
      "[24890]\teval-rmse:3.81019\ttrain-rmse:1.95589\n",
      "[24891]\teval-rmse:3.81155\ttrain-rmse:1.9559\n",
      "[24892]\teval-rmse:3.81127\ttrain-rmse:1.9559\n",
      "[24893]\teval-rmse:3.81284\ttrain-rmse:1.95593\n",
      "[24894]\teval-rmse:3.81407\ttrain-rmse:1.95594\n",
      "[24895]\teval-rmse:3.81429\ttrain-rmse:1.95595\n",
      "[24896]\teval-rmse:3.81428\ttrain-rmse:1.95595\n",
      "[24897]\teval-rmse:3.8124\ttrain-rmse:1.95591\n",
      "[24898]\teval-rmse:3.81196\ttrain-rmse:1.9559\n",
      "[24899]\teval-rmse:3.81013\ttrain-rmse:1.95589\n",
      "[24900]\teval-rmse:3.8117\ttrain-rmse:1.9559\n",
      "[24901]\teval-rmse:3.81187\ttrain-rmse:1.9559\n",
      "[24902]\teval-rmse:3.81124\ttrain-rmse:1.95589\n",
      "[24903]\teval-rmse:3.81246\ttrain-rmse:1.95591\n",
      "[24904]\teval-rmse:3.81142\ttrain-rmse:1.95592\n",
      "[24905]\teval-rmse:3.8095\ttrain-rmse:1.9559\n",
      "[24906]\teval-rmse:3.80923\ttrain-rmse:1.9559\n",
      "[24907]\teval-rmse:3.8082\ttrain-rmse:1.95591\n",
      "[24908]\teval-rmse:3.80953\ttrain-rmse:1.95592\n",
      "[24909]\teval-rmse:3.80822\ttrain-rmse:1.95591\n",
      "[24910]\teval-rmse:3.807\ttrain-rmse:1.95594\n",
      "[24911]\teval-rmse:3.80777\ttrain-rmse:1.95593\n",
      "[24912]\teval-rmse:3.80761\ttrain-rmse:1.95593\n",
      "[24913]\teval-rmse:3.80574\ttrain-rmse:1.95594\n",
      "[24914]\teval-rmse:3.80557\ttrain-rmse:1.95594\n",
      "[24915]\teval-rmse:3.8069\ttrain-rmse:1.95593\n",
      "[24916]\teval-rmse:3.80711\ttrain-rmse:1.95593\n",
      "[24917]\teval-rmse:3.80713\ttrain-rmse:1.95593\n",
      "[24918]\teval-rmse:3.80583\ttrain-rmse:1.95594\n",
      "[24919]\teval-rmse:3.80556\ttrain-rmse:1.95594\n",
      "[24920]\teval-rmse:3.80532\ttrain-rmse:1.95594\n",
      "[24921]\teval-rmse:3.80485\ttrain-rmse:1.95595\n",
      "[24922]\teval-rmse:3.80469\ttrain-rmse:1.95595\n",
      "[24923]\teval-rmse:3.80537\ttrain-rmse:1.95594\n",
      "[24924]\teval-rmse:3.80409\ttrain-rmse:1.95598\n",
      "[24925]\teval-rmse:3.80383\ttrain-rmse:1.95599\n",
      "[24926]\teval-rmse:3.80502\ttrain-rmse:1.95598\n",
      "[24927]\teval-rmse:3.80501\ttrain-rmse:1.95598\n",
      "[24928]\teval-rmse:3.80529\ttrain-rmse:1.95598\n",
      "[24929]\teval-rmse:3.80716\ttrain-rmse:1.95594\n",
      "[24930]\teval-rmse:3.8069\ttrain-rmse:1.95588\n",
      "[24931]\teval-rmse:3.80526\ttrain-rmse:1.95589\n",
      "[24932]\teval-rmse:3.80501\ttrain-rmse:1.95584\n",
      "[24933]\teval-rmse:3.80301\ttrain-rmse:1.95586\n",
      "[24934]\teval-rmse:3.80098\ttrain-rmse:1.9559\n",
      "[24935]\teval-rmse:3.79946\ttrain-rmse:1.95594\n",
      "[24936]\teval-rmse:3.79796\ttrain-rmse:1.95598\n",
      "[24937]\teval-rmse:3.7968\ttrain-rmse:1.95603\n",
      "[24938]\teval-rmse:3.79499\ttrain-rmse:1.95609\n",
      "[24939]\teval-rmse:3.79633\ttrain-rmse:1.95604\n",
      "[24940]\teval-rmse:3.79436\ttrain-rmse:1.95614\n",
      "[24941]\teval-rmse:3.79571\ttrain-rmse:1.95607\n",
      "[24942]\teval-rmse:3.79527\ttrain-rmse:1.95609\n",
      "[24943]\teval-rmse:3.79551\ttrain-rmse:1.95608\n",
      "[24944]\teval-rmse:3.79394\ttrain-rmse:1.95615\n",
      "[24945]\teval-rmse:3.79397\ttrain-rmse:1.95615\n",
      "[24946]\teval-rmse:3.79456\ttrain-rmse:1.95612\n",
      "[24947]\teval-rmse:3.79297\ttrain-rmse:1.95618\n",
      "[24948]\teval-rmse:3.79176\ttrain-rmse:1.95625\n",
      "[24949]\teval-rmse:3.79196\ttrain-rmse:1.95624\n",
      "[24950]\teval-rmse:3.79079\ttrain-rmse:1.9563\n",
      "[24951]\teval-rmse:3.7893\ttrain-rmse:1.9564\n",
      "[24952]\teval-rmse:3.79047\ttrain-rmse:1.95632\n",
      "[24953]\teval-rmse:3.79214\ttrain-rmse:1.95623\n",
      "[24954]\teval-rmse:3.79215\ttrain-rmse:1.95623\n",
      "[24955]\teval-rmse:3.79315\ttrain-rmse:1.95618\n",
      "[24956]\teval-rmse:3.79196\ttrain-rmse:1.95624\n",
      "[24957]\teval-rmse:3.79177\ttrain-rmse:1.95625\n",
      "[24958]\teval-rmse:3.78987\ttrain-rmse:1.95636\n",
      "[24959]\teval-rmse:3.78954\ttrain-rmse:1.95638\n",
      "[24960]\teval-rmse:3.79123\ttrain-rmse:1.95627\n",
      "[24961]\teval-rmse:3.7916\ttrain-rmse:1.95625\n",
      "[24962]\teval-rmse:3.79293\ttrain-rmse:1.95618\n",
      "[24963]\teval-rmse:3.79172\ttrain-rmse:1.95623\n",
      "[24964]\teval-rmse:3.79161\ttrain-rmse:1.95624\n",
      "[24965]\teval-rmse:3.79242\ttrain-rmse:1.9562\n",
      "[24966]\teval-rmse:3.79222\ttrain-rmse:1.95621\n",
      "[24967]\teval-rmse:3.79334\ttrain-rmse:1.95615\n",
      "[24968]\teval-rmse:3.79495\ttrain-rmse:1.95609\n",
      "[24969]\teval-rmse:3.7958\ttrain-rmse:1.95604\n",
      "[24970]\teval-rmse:3.79385\ttrain-rmse:1.95613\n",
      "[24971]\teval-rmse:3.79573\ttrain-rmse:1.95606\n",
      "[24972]\teval-rmse:3.79712\ttrain-rmse:1.95599\n",
      "[24973]\teval-rmse:3.79556\ttrain-rmse:1.95604\n",
      "[24974]\teval-rmse:3.79705\ttrain-rmse:1.95598\n",
      "[24975]\teval-rmse:3.79692\ttrain-rmse:1.95598\n",
      "[24976]\teval-rmse:3.79597\ttrain-rmse:1.95602\n",
      "[24977]\teval-rmse:3.79576\ttrain-rmse:1.95602\n",
      "[24978]\teval-rmse:3.79555\ttrain-rmse:1.95596\n",
      "[24979]\teval-rmse:3.79512\ttrain-rmse:1.95598\n",
      "[24980]\teval-rmse:3.7949\ttrain-rmse:1.95598\n",
      "[24981]\teval-rmse:3.79336\ttrain-rmse:1.95605\n",
      "[24982]\teval-rmse:3.79164\ttrain-rmse:1.95614\n",
      "[24983]\teval-rmse:3.78987\ttrain-rmse:1.95626\n",
      "[24984]\teval-rmse:3.79047\ttrain-rmse:1.95622\n",
      "[24985]\teval-rmse:3.79215\ttrain-rmse:1.95612\n",
      "[24986]\teval-rmse:3.79195\ttrain-rmse:1.95612\n",
      "[24987]\teval-rmse:3.79223\ttrain-rmse:1.95611\n",
      "[24988]\teval-rmse:3.79047\ttrain-rmse:1.95622\n",
      "[24989]\teval-rmse:3.78892\ttrain-rmse:1.95632\n",
      "[24990]\teval-rmse:3.79054\ttrain-rmse:1.95623\n",
      "[24991]\teval-rmse:3.79006\ttrain-rmse:1.95626\n",
      "[24992]\teval-rmse:3.79069\ttrain-rmse:1.95623\n",
      "[24993]\teval-rmse:3.7905\ttrain-rmse:1.95624\n",
      "[24994]\teval-rmse:3.79032\ttrain-rmse:1.95625\n",
      "[24995]\teval-rmse:3.79036\ttrain-rmse:1.95624\n",
      "[24996]\teval-rmse:3.78944\ttrain-rmse:1.95629\n",
      "[24997]\teval-rmse:3.79058\ttrain-rmse:1.95623\n",
      "[24998]\teval-rmse:3.79109\ttrain-rmse:1.95619\n",
      "[24999]\teval-rmse:3.79055\ttrain-rmse:1.95622\n",
      "[25000]\teval-rmse:3.79108\ttrain-rmse:1.95619\n",
      "[25001]\teval-rmse:3.79088\ttrain-rmse:1.95619\n",
      "[25002]\teval-rmse:3.79243\ttrain-rmse:1.95613\n",
      "[25003]\teval-rmse:3.79304\ttrain-rmse:1.9561\n",
      "[25004]\teval-rmse:3.79284\ttrain-rmse:1.9561\n",
      "[25005]\teval-rmse:3.79336\ttrain-rmse:1.95608\n",
      "[25006]\teval-rmse:3.79395\ttrain-rmse:1.95605\n",
      "[25007]\teval-rmse:3.7953\ttrain-rmse:1.95599\n",
      "[25008]\teval-rmse:3.79509\ttrain-rmse:1.956\n",
      "[25009]\teval-rmse:3.7957\ttrain-rmse:1.95598\n",
      "[25010]\teval-rmse:3.79604\ttrain-rmse:1.95597\n",
      "[25011]\teval-rmse:3.79435\ttrain-rmse:1.95604\n",
      "[25012]\teval-rmse:3.79469\ttrain-rmse:1.95602\n",
      "[25013]\teval-rmse:3.7949\ttrain-rmse:1.95602\n",
      "[25014]\teval-rmse:3.7944\ttrain-rmse:1.95603\n",
      "[25015]\teval-rmse:3.79362\ttrain-rmse:1.95606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25016]\teval-rmse:3.79195\ttrain-rmse:1.95614\n",
      "[25017]\teval-rmse:3.79252\ttrain-rmse:1.95612\n",
      "[25018]\teval-rmse:3.79127\ttrain-rmse:1.95617\n",
      "[25019]\teval-rmse:3.79181\ttrain-rmse:1.95614\n",
      "[25020]\teval-rmse:3.79171\ttrain-rmse:1.95614\n",
      "[25021]\teval-rmse:3.79012\ttrain-rmse:1.95624\n",
      "[25022]\teval-rmse:3.78969\ttrain-rmse:1.95626\n",
      "[25023]\teval-rmse:3.79037\ttrain-rmse:1.95622\n",
      "[25024]\teval-rmse:3.78993\ttrain-rmse:1.95624\n",
      "[25025]\teval-rmse:3.78845\ttrain-rmse:1.95631\n",
      "[25026]\teval-rmse:3.78728\ttrain-rmse:1.95638\n",
      "[25027]\teval-rmse:3.78764\ttrain-rmse:1.95635\n",
      "[25028]\teval-rmse:3.78617\ttrain-rmse:1.95646\n",
      "[25029]\teval-rmse:3.78508\ttrain-rmse:1.95653\n",
      "[25030]\teval-rmse:3.78564\ttrain-rmse:1.9565\n",
      "[25031]\teval-rmse:3.78597\ttrain-rmse:1.95647\n",
      "[25032]\teval-rmse:3.78559\ttrain-rmse:1.9565\n",
      "[25033]\teval-rmse:3.78542\ttrain-rmse:1.95651\n",
      "[25034]\teval-rmse:3.78659\ttrain-rmse:1.95643\n",
      "[25035]\teval-rmse:3.78509\ttrain-rmse:1.95655\n",
      "[25036]\teval-rmse:3.78371\ttrain-rmse:1.95667\n",
      "[25037]\teval-rmse:3.78434\ttrain-rmse:1.95661\n",
      "[25038]\teval-rmse:3.78354\ttrain-rmse:1.95668\n",
      "[25039]\teval-rmse:3.78542\ttrain-rmse:1.95656\n",
      "[25040]\teval-rmse:3.78348\ttrain-rmse:1.95673\n",
      "[25041]\teval-rmse:3.7835\ttrain-rmse:1.95673\n",
      "[25042]\teval-rmse:3.78334\ttrain-rmse:1.95674\n",
      "[25043]\teval-rmse:3.78168\ttrain-rmse:1.9569\n",
      "[25044]\teval-rmse:3.78287\ttrain-rmse:1.95679\n",
      "[25045]\teval-rmse:3.78447\ttrain-rmse:1.95666\n",
      "[25046]\teval-rmse:3.78434\ttrain-rmse:1.95658\n",
      "[25047]\teval-rmse:3.78346\ttrain-rmse:1.95664\n",
      "[25048]\teval-rmse:3.78345\ttrain-rmse:1.95664\n",
      "[25049]\teval-rmse:3.78201\ttrain-rmse:1.95674\n",
      "[25050]\teval-rmse:3.7837\ttrain-rmse:1.9566\n",
      "[25051]\teval-rmse:3.78408\ttrain-rmse:1.95657\n",
      "[25052]\teval-rmse:3.784\ttrain-rmse:1.95657\n",
      "[25053]\teval-rmse:3.78384\ttrain-rmse:1.95658\n",
      "[25054]\teval-rmse:3.78267\ttrain-rmse:1.95667\n",
      "[25055]\teval-rmse:3.78272\ttrain-rmse:1.95666\n",
      "[25056]\teval-rmse:3.78257\ttrain-rmse:1.95667\n",
      "[25057]\teval-rmse:3.78208\ttrain-rmse:1.95671\n",
      "[25058]\teval-rmse:3.78201\ttrain-rmse:1.95671\n",
      "[25059]\teval-rmse:3.78256\ttrain-rmse:1.95666\n",
      "[25060]\teval-rmse:3.78319\ttrain-rmse:1.9566\n",
      "[25061]\teval-rmse:3.78352\ttrain-rmse:1.95657\n",
      "[25062]\teval-rmse:3.78265\ttrain-rmse:1.95663\n",
      "[25063]\teval-rmse:3.78249\ttrain-rmse:1.95657\n",
      "[25064]\teval-rmse:3.78418\ttrain-rmse:1.95646\n",
      "[25065]\teval-rmse:3.78329\ttrain-rmse:1.95651\n",
      "[25066]\teval-rmse:3.78314\ttrain-rmse:1.95646\n",
      "[25067]\teval-rmse:3.78124\ttrain-rmse:1.95663\n",
      "[25068]\teval-rmse:3.78089\ttrain-rmse:1.95666\n",
      "[25069]\teval-rmse:3.78074\ttrain-rmse:1.95667\n",
      "[25070]\teval-rmse:3.77947\ttrain-rmse:1.95679\n",
      "[25071]\teval-rmse:3.77805\ttrain-rmse:1.95695\n",
      "[25072]\teval-rmse:3.77692\ttrain-rmse:1.95706\n",
      "[25073]\teval-rmse:3.77607\ttrain-rmse:1.95713\n",
      "[25074]\teval-rmse:3.77747\ttrain-rmse:1.95698\n",
      "[25075]\teval-rmse:3.77711\ttrain-rmse:1.95701\n",
      "[25076]\teval-rmse:3.77573\ttrain-rmse:1.95714\n",
      "[25077]\teval-rmse:3.77606\ttrain-rmse:1.9571\n",
      "[25078]\teval-rmse:3.77462\ttrain-rmse:1.95727\n",
      "[25079]\teval-rmse:3.77567\ttrain-rmse:1.95717\n",
      "[25080]\teval-rmse:3.77621\ttrain-rmse:1.9571\n",
      "[25081]\teval-rmse:3.77437\ttrain-rmse:1.95732\n",
      "[25082]\teval-rmse:3.77326\ttrain-rmse:1.95744\n",
      "[25083]\teval-rmse:3.7719\ttrain-rmse:1.9576\n",
      "[25084]\teval-rmse:3.77258\ttrain-rmse:1.95751\n",
      "[25085]\teval-rmse:3.77254\ttrain-rmse:1.95752\n",
      "[25086]\teval-rmse:3.77113\ttrain-rmse:1.95771\n",
      "[25087]\teval-rmse:3.77249\ttrain-rmse:1.95756\n",
      "[25088]\teval-rmse:3.77246\ttrain-rmse:1.95756\n",
      "[25089]\teval-rmse:3.77111\ttrain-rmse:1.9577\n",
      "[25090]\teval-rmse:3.77129\ttrain-rmse:1.95768\n",
      "[25091]\teval-rmse:3.77155\ttrain-rmse:1.95765\n",
      "[25092]\teval-rmse:3.77014\ttrain-rmse:1.95785\n",
      "[25093]\teval-rmse:3.76934\ttrain-rmse:1.95793\n",
      "[25094]\teval-rmse:3.76871\ttrain-rmse:1.958\n",
      "[25095]\teval-rmse:3.76905\ttrain-rmse:1.95795\n",
      "[25096]\teval-rmse:3.76795\ttrain-rmse:1.9581\n",
      "[25097]\teval-rmse:3.76901\ttrain-rmse:1.95794\n",
      "[25098]\teval-rmse:3.77091\ttrain-rmse:1.95775\n",
      "[25099]\teval-rmse:3.77182\ttrain-rmse:1.95765\n",
      "[25100]\teval-rmse:3.77191\ttrain-rmse:1.95764\n",
      "[25101]\teval-rmse:3.77356\ttrain-rmse:1.95747\n",
      "[25102]\teval-rmse:3.77442\ttrain-rmse:1.95738\n",
      "[25103]\teval-rmse:3.77608\ttrain-rmse:1.95722\n",
      "[25104]\teval-rmse:3.77441\ttrain-rmse:1.95741\n",
      "[25105]\teval-rmse:3.7741\ttrain-rmse:1.95744\n",
      "[25106]\teval-rmse:3.77524\ttrain-rmse:1.9573\n",
      "[25107]\teval-rmse:3.77461\ttrain-rmse:1.95738\n",
      "[25108]\teval-rmse:3.77457\ttrain-rmse:1.95738\n",
      "[25109]\teval-rmse:3.77547\ttrain-rmse:1.95729\n",
      "[25110]\teval-rmse:3.77435\ttrain-rmse:1.95741\n",
      "[25111]\teval-rmse:3.77495\ttrain-rmse:1.95733\n",
      "[25112]\teval-rmse:3.77511\ttrain-rmse:1.95731\n",
      "[25113]\teval-rmse:3.77546\ttrain-rmse:1.95727\n",
      "[25114]\teval-rmse:3.77398\ttrain-rmse:1.95741\n",
      "[25115]\teval-rmse:3.77364\ttrain-rmse:1.95745\n",
      "[25116]\teval-rmse:3.77353\ttrain-rmse:1.95746\n",
      "[25117]\teval-rmse:3.77514\ttrain-rmse:1.9573\n",
      "[25118]\teval-rmse:3.77604\ttrain-rmse:1.95721\n",
      "[25119]\teval-rmse:3.77592\ttrain-rmse:1.95722\n",
      "[25120]\teval-rmse:3.77586\ttrain-rmse:1.95722\n",
      "[25121]\teval-rmse:3.77646\ttrain-rmse:1.95715\n",
      "[25122]\teval-rmse:3.77529\ttrain-rmse:1.95725\n",
      "[25123]\teval-rmse:3.77594\ttrain-rmse:1.95719\n",
      "[25124]\teval-rmse:3.77424\ttrain-rmse:1.95743\n",
      "[25125]\teval-rmse:3.7743\ttrain-rmse:1.95742\n",
      "[25126]\teval-rmse:3.77286\ttrain-rmse:1.95756\n",
      "[25127]\teval-rmse:3.77425\ttrain-rmse:1.95739\n",
      "[25128]\teval-rmse:3.77279\ttrain-rmse:1.95756\n",
      "[25129]\teval-rmse:3.77245\ttrain-rmse:1.95761\n",
      "[25130]\teval-rmse:3.77135\ttrain-rmse:1.95772\n",
      "[25131]\teval-rmse:3.77099\ttrain-rmse:1.95776\n",
      "[25132]\teval-rmse:3.76953\ttrain-rmse:1.95797\n",
      "[25133]\teval-rmse:3.77012\ttrain-rmse:1.9579\n",
      "[25134]\teval-rmse:3.77201\ttrain-rmse:1.95772\n",
      "[25135]\teval-rmse:3.77197\ttrain-rmse:1.95772\n",
      "[25136]\teval-rmse:3.77286\ttrain-rmse:1.95759\n",
      "[25137]\teval-rmse:3.77283\ttrain-rmse:1.95759\n",
      "[25138]\teval-rmse:3.77171\ttrain-rmse:1.95775\n",
      "[25139]\teval-rmse:3.7716\ttrain-rmse:1.95776\n",
      "[25140]\teval-rmse:3.77148\ttrain-rmse:1.95777\n",
      "[25141]\teval-rmse:3.77208\ttrain-rmse:1.9577\n",
      "[25142]\teval-rmse:3.77249\ttrain-rmse:1.95764\n",
      "[25143]\teval-rmse:3.77116\ttrain-rmse:1.95779\n",
      "[25144]\teval-rmse:3.77104\ttrain-rmse:1.95779\n",
      "[25145]\teval-rmse:3.76963\ttrain-rmse:1.95796\n",
      "[25146]\teval-rmse:3.76952\ttrain-rmse:1.95796\n",
      "[25147]\teval-rmse:3.76919\ttrain-rmse:1.95801\n",
      "[25148]\teval-rmse:3.76839\ttrain-rmse:1.95809\n",
      "[25149]\teval-rmse:3.769\ttrain-rmse:1.958\n",
      "[25150]\teval-rmse:3.76918\ttrain-rmse:1.95798\n",
      "[25151]\teval-rmse:3.76957\ttrain-rmse:1.95792\n",
      "[25152]\teval-rmse:3.77087\ttrain-rmse:1.95777\n",
      "[25153]\teval-rmse:3.77084\ttrain-rmse:1.95777\n",
      "[25154]\teval-rmse:3.77092\ttrain-rmse:1.95776\n",
      "[25155]\teval-rmse:3.77253\ttrain-rmse:1.95758\n",
      "[25156]\teval-rmse:3.77112\ttrain-rmse:1.95774\n",
      "[25157]\teval-rmse:3.76982\ttrain-rmse:1.95791\n",
      "[25158]\teval-rmse:3.77098\ttrain-rmse:1.95775\n",
      "[25159]\teval-rmse:3.77236\ttrain-rmse:1.95756\n",
      "[25160]\teval-rmse:3.77392\ttrain-rmse:1.9574\n",
      "[25161]\teval-rmse:3.77366\ttrain-rmse:1.95744\n",
      "[25162]\teval-rmse:3.77425\ttrain-rmse:1.95737\n",
      "[25163]\teval-rmse:3.77463\ttrain-rmse:1.95733\n",
      "[25164]\teval-rmse:3.77417\ttrain-rmse:1.95737\n",
      "[25165]\teval-rmse:3.77256\ttrain-rmse:1.95757\n",
      "[25166]\teval-rmse:3.77293\ttrain-rmse:1.95752\n",
      "[25167]\teval-rmse:3.77385\ttrain-rmse:1.9574\n",
      "[25168]\teval-rmse:3.77347\ttrain-rmse:1.95744\n",
      "[25169]\teval-rmse:3.77362\ttrain-rmse:1.95742\n",
      "[25170]\teval-rmse:3.77452\ttrain-rmse:1.95732\n",
      "[25171]\teval-rmse:3.77314\ttrain-rmse:1.9575\n",
      "[25172]\teval-rmse:3.77378\ttrain-rmse:1.95742\n",
      "[25173]\teval-rmse:3.77439\ttrain-rmse:1.95735\n",
      "[25174]\teval-rmse:3.77356\ttrain-rmse:1.95742\n",
      "[25175]\teval-rmse:3.77422\ttrain-rmse:1.95735\n",
      "[25176]\teval-rmse:3.77314\ttrain-rmse:1.95748\n",
      "[25177]\teval-rmse:3.77302\ttrain-rmse:1.95749\n",
      "[25178]\teval-rmse:3.77438\ttrain-rmse:1.95732\n",
      "[25179]\teval-rmse:3.77594\ttrain-rmse:1.95717\n",
      "[25180]\teval-rmse:3.7759\ttrain-rmse:1.95717\n",
      "[25181]\teval-rmse:3.77557\ttrain-rmse:1.9572\n",
      "[25182]\teval-rmse:3.77573\ttrain-rmse:1.95718\n",
      "[25183]\teval-rmse:3.7756\ttrain-rmse:1.95719\n",
      "[25184]\teval-rmse:3.7773\ttrain-rmse:1.95704\n",
      "[25185]\teval-rmse:3.77899\ttrain-rmse:1.95689\n",
      "[25186]\teval-rmse:3.7776\ttrain-rmse:1.95701\n",
      "[25187]\teval-rmse:3.77655\ttrain-rmse:1.95711\n",
      "[25188]\teval-rmse:3.7752\ttrain-rmse:1.95724\n",
      "[25189]\teval-rmse:3.77688\ttrain-rmse:1.95704\n",
      "[25190]\teval-rmse:3.77717\ttrain-rmse:1.95701\n",
      "[25191]\teval-rmse:3.77651\ttrain-rmse:1.95707\n",
      "[25192]\teval-rmse:3.7778\ttrain-rmse:1.95692\n",
      "[25193]\teval-rmse:3.77668\ttrain-rmse:1.95702\n",
      "[25194]\teval-rmse:3.77636\ttrain-rmse:1.95705\n",
      "[25195]\teval-rmse:3.77771\ttrain-rmse:1.95693\n",
      "[25196]\teval-rmse:3.77898\ttrain-rmse:1.9568\n",
      "[25197]\teval-rmse:3.77999\ttrain-rmse:1.9567\n",
      "[25198]\teval-rmse:3.78053\ttrain-rmse:1.95666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25199]\teval-rmse:3.78066\ttrain-rmse:1.95664\n",
      "[25200]\teval-rmse:3.78227\ttrain-rmse:1.9565\n",
      "[25201]\teval-rmse:3.78251\ttrain-rmse:1.95648\n",
      "[25202]\teval-rmse:3.7842\ttrain-rmse:1.95637\n",
      "[25203]\teval-rmse:3.78331\ttrain-rmse:1.95643\n",
      "[25204]\teval-rmse:3.78315\ttrain-rmse:1.95644\n",
      "[25205]\teval-rmse:3.78301\ttrain-rmse:1.95638\n",
      "[25206]\teval-rmse:3.78293\ttrain-rmse:1.95638\n",
      "[25207]\teval-rmse:3.78174\ttrain-rmse:1.95647\n",
      "[25208]\teval-rmse:3.78125\ttrain-rmse:1.95651\n",
      "[25209]\teval-rmse:3.78084\ttrain-rmse:1.95654\n",
      "[25210]\teval-rmse:3.7819\ttrain-rmse:1.95645\n",
      "[25211]\teval-rmse:3.78069\ttrain-rmse:1.95654\n",
      "[25212]\teval-rmse:3.78053\ttrain-rmse:1.95655\n",
      "[25213]\teval-rmse:3.77985\ttrain-rmse:1.9566\n",
      "[25214]\teval-rmse:3.77843\ttrain-rmse:1.95672\n",
      "[25215]\teval-rmse:3.78\ttrain-rmse:1.9566\n",
      "[25216]\teval-rmse:3.77811\ttrain-rmse:1.95677\n",
      "[25217]\teval-rmse:3.77944\ttrain-rmse:1.95665\n",
      "[25218]\teval-rmse:3.7797\ttrain-rmse:1.95663\n",
      "[25219]\teval-rmse:3.77834\ttrain-rmse:1.95676\n",
      "[25220]\teval-rmse:3.77891\ttrain-rmse:1.95671\n",
      "[25221]\teval-rmse:3.77892\ttrain-rmse:1.95671\n",
      "[25222]\teval-rmse:3.77824\ttrain-rmse:1.95677\n",
      "[25223]\teval-rmse:3.77846\ttrain-rmse:1.95674\n",
      "[25224]\teval-rmse:3.77872\ttrain-rmse:1.95672\n",
      "[25225]\teval-rmse:3.77767\ttrain-rmse:1.9568\n",
      "[25226]\teval-rmse:3.77598\ttrain-rmse:1.95697\n",
      "[25227]\teval-rmse:3.77632\ttrain-rmse:1.95693\n",
      "[25228]\teval-rmse:3.77706\ttrain-rmse:1.95686\n",
      "[25229]\teval-rmse:3.77593\ttrain-rmse:1.95697\n",
      "[25230]\teval-rmse:3.77449\ttrain-rmse:1.9571\n",
      "[25231]\teval-rmse:3.77603\ttrain-rmse:1.95695\n",
      "[25232]\teval-rmse:3.77436\ttrain-rmse:1.95713\n",
      "[25233]\teval-rmse:3.77605\ttrain-rmse:1.95697\n",
      "[25234]\teval-rmse:3.77522\ttrain-rmse:1.95704\n",
      "[25235]\teval-rmse:3.77485\ttrain-rmse:1.95708\n",
      "[25236]\teval-rmse:3.77608\ttrain-rmse:1.95697\n",
      "[25237]\teval-rmse:3.77596\ttrain-rmse:1.95698\n",
      "[25238]\teval-rmse:3.77647\ttrain-rmse:1.95693\n",
      "[25239]\teval-rmse:3.77808\ttrain-rmse:1.95679\n",
      "[25240]\teval-rmse:3.77939\ttrain-rmse:1.95669\n",
      "[25241]\teval-rmse:3.78052\ttrain-rmse:1.95659\n",
      "[25242]\teval-rmse:3.78038\ttrain-rmse:1.9566\n",
      "[25243]\teval-rmse:3.78032\ttrain-rmse:1.9566\n",
      "[25244]\teval-rmse:3.78187\ttrain-rmse:1.95646\n",
      "[25245]\teval-rmse:3.78172\ttrain-rmse:1.95648\n",
      "[25246]\teval-rmse:3.78208\ttrain-rmse:1.95645\n",
      "[25247]\teval-rmse:3.78193\ttrain-rmse:1.95646\n",
      "[25248]\teval-rmse:3.78185\ttrain-rmse:1.95646\n",
      "[25249]\teval-rmse:3.78187\ttrain-rmse:1.95646\n",
      "[25250]\teval-rmse:3.77999\ttrain-rmse:1.95661\n",
      "[25251]\teval-rmse:3.77964\ttrain-rmse:1.95664\n",
      "[25252]\teval-rmse:3.77991\ttrain-rmse:1.95662\n",
      "[25253]\teval-rmse:3.78021\ttrain-rmse:1.9566\n",
      "[25254]\teval-rmse:3.77911\ttrain-rmse:1.9567\n",
      "[25255]\teval-rmse:3.77945\ttrain-rmse:1.95667\n",
      "[25256]\teval-rmse:3.77939\ttrain-rmse:1.95667\n",
      "[25257]\teval-rmse:3.78127\ttrain-rmse:1.95653\n",
      "[25258]\teval-rmse:3.78184\ttrain-rmse:1.95649\n",
      "[25259]\teval-rmse:3.78235\ttrain-rmse:1.95646\n",
      "[25260]\teval-rmse:3.78389\ttrain-rmse:1.95636\n",
      "[25261]\teval-rmse:3.78386\ttrain-rmse:1.95636\n",
      "[25262]\teval-rmse:3.78384\ttrain-rmse:1.95637\n",
      "[25263]\teval-rmse:3.78434\ttrain-rmse:1.95634\n",
      "[25264]\teval-rmse:3.78622\ttrain-rmse:1.95622\n",
      "[25265]\teval-rmse:3.78652\ttrain-rmse:1.9562\n",
      "[25266]\teval-rmse:3.78634\ttrain-rmse:1.95621\n",
      "[25267]\teval-rmse:3.78634\ttrain-rmse:1.95621\n",
      "[25268]\teval-rmse:3.78635\ttrain-rmse:1.95621\n",
      "[25269]\teval-rmse:3.78694\ttrain-rmse:1.95617\n",
      "[25270]\teval-rmse:3.78759\ttrain-rmse:1.95613\n",
      "[25271]\teval-rmse:3.78712\ttrain-rmse:1.95616\n",
      "[25272]\teval-rmse:3.78695\ttrain-rmse:1.95617\n",
      "[25273]\teval-rmse:3.78604\ttrain-rmse:1.95623\n",
      "[25274]\teval-rmse:3.78697\ttrain-rmse:1.95617\n",
      "[25275]\teval-rmse:3.78607\ttrain-rmse:1.95622\n",
      "[25276]\teval-rmse:3.78488\ttrain-rmse:1.95631\n",
      "[25277]\teval-rmse:3.7837\ttrain-rmse:1.9564\n",
      "[25278]\teval-rmse:3.78328\ttrain-rmse:1.95643\n",
      "[25279]\teval-rmse:3.7824\ttrain-rmse:1.95649\n",
      "[25280]\teval-rmse:3.78275\ttrain-rmse:1.95646\n",
      "[25281]\teval-rmse:3.78231\ttrain-rmse:1.95649\n",
      "[25282]\teval-rmse:3.78066\ttrain-rmse:1.95661\n",
      "[25283]\teval-rmse:3.78106\ttrain-rmse:1.95658\n",
      "[25284]\teval-rmse:3.7822\ttrain-rmse:1.9565\n",
      "[25285]\teval-rmse:3.78388\ttrain-rmse:1.95636\n",
      "[25286]\teval-rmse:3.7845\ttrain-rmse:1.95631\n",
      "[25287]\teval-rmse:3.78326\ttrain-rmse:1.95638\n",
      "[25288]\teval-rmse:3.7831\ttrain-rmse:1.95632\n",
      "[25289]\teval-rmse:3.78308\ttrain-rmse:1.95632\n",
      "[25290]\teval-rmse:3.78185\ttrain-rmse:1.9564\n",
      "[25291]\teval-rmse:3.78208\ttrain-rmse:1.95638\n",
      "[25292]\teval-rmse:3.78312\ttrain-rmse:1.9563\n",
      "[25293]\teval-rmse:3.78362\ttrain-rmse:1.95627\n",
      "[25294]\teval-rmse:3.78346\ttrain-rmse:1.95622\n",
      "[25295]\teval-rmse:3.78334\ttrain-rmse:1.95616\n",
      "[25296]\teval-rmse:3.78245\ttrain-rmse:1.95622\n",
      "[25297]\teval-rmse:3.78206\ttrain-rmse:1.95625\n",
      "[25298]\teval-rmse:3.78226\ttrain-rmse:1.95623\n",
      "[25299]\teval-rmse:3.78394\ttrain-rmse:1.95612\n",
      "[25300]\teval-rmse:3.78422\ttrain-rmse:1.95611\n",
      "[25301]\teval-rmse:3.78333\ttrain-rmse:1.95617\n",
      "[25302]\teval-rmse:3.78414\ttrain-rmse:1.95612\n",
      "[25303]\teval-rmse:3.78325\ttrain-rmse:1.95617\n",
      "[25304]\teval-rmse:3.78351\ttrain-rmse:1.95616\n",
      "[25305]\teval-rmse:3.78375\ttrain-rmse:1.95614\n",
      "[25306]\teval-rmse:3.78317\ttrain-rmse:1.95618\n",
      "[25307]\teval-rmse:3.78276\ttrain-rmse:1.9562\n",
      "[25308]\teval-rmse:3.78261\ttrain-rmse:1.95615\n",
      "[25309]\teval-rmse:3.78318\ttrain-rmse:1.95612\n",
      "[25310]\teval-rmse:3.78303\ttrain-rmse:1.95613\n",
      "[25311]\teval-rmse:3.78389\ttrain-rmse:1.95608\n",
      "[25312]\teval-rmse:3.78493\ttrain-rmse:1.95602\n",
      "[25313]\teval-rmse:3.78451\ttrain-rmse:1.95604\n",
      "[25314]\teval-rmse:3.78639\ttrain-rmse:1.95592\n",
      "[25315]\teval-rmse:3.7852\ttrain-rmse:1.956\n",
      "[25316]\teval-rmse:3.78386\ttrain-rmse:1.95608\n",
      "[25317]\teval-rmse:3.78472\ttrain-rmse:1.95603\n",
      "[25318]\teval-rmse:3.78456\ttrain-rmse:1.95604\n",
      "[25319]\teval-rmse:3.78612\ttrain-rmse:1.95596\n",
      "[25320]\teval-rmse:3.78727\ttrain-rmse:1.95591\n",
      "[25321]\teval-rmse:3.7871\ttrain-rmse:1.95592\n",
      "[25322]\teval-rmse:3.78845\ttrain-rmse:1.95586\n",
      "[25323]\teval-rmse:3.7881\ttrain-rmse:1.95588\n",
      "[25324]\teval-rmse:3.78896\ttrain-rmse:1.95582\n",
      "[25325]\teval-rmse:3.78878\ttrain-rmse:1.95583\n",
      "[25326]\teval-rmse:3.78863\ttrain-rmse:1.95578\n",
      "[25327]\teval-rmse:3.78682\ttrain-rmse:1.95586\n",
      "[25328]\teval-rmse:3.78561\ttrain-rmse:1.95593\n",
      "[25329]\teval-rmse:3.78523\ttrain-rmse:1.95596\n",
      "[25330]\teval-rmse:3.78574\ttrain-rmse:1.95592\n",
      "[25331]\teval-rmse:3.78475\ttrain-rmse:1.95599\n",
      "[25332]\teval-rmse:3.78547\ttrain-rmse:1.95594\n",
      "[25333]\teval-rmse:3.78672\ttrain-rmse:1.95588\n",
      "[25334]\teval-rmse:3.7886\ttrain-rmse:1.95577\n",
      "[25335]\teval-rmse:3.78719\ttrain-rmse:1.95584\n",
      "[25336]\teval-rmse:3.78773\ttrain-rmse:1.95581\n",
      "[25337]\teval-rmse:3.78769\ttrain-rmse:1.95581\n",
      "[25338]\teval-rmse:3.78937\ttrain-rmse:1.95572\n",
      "[25339]\teval-rmse:3.7892\ttrain-rmse:1.95573\n",
      "[25340]\teval-rmse:3.78909\ttrain-rmse:1.95573\n",
      "[25341]\teval-rmse:3.7875\ttrain-rmse:1.95581\n",
      "[25342]\teval-rmse:3.78804\ttrain-rmse:1.95578\n",
      "[25343]\teval-rmse:3.78757\ttrain-rmse:1.95581\n",
      "[25344]\teval-rmse:3.78748\ttrain-rmse:1.95581\n",
      "[25345]\teval-rmse:3.78882\ttrain-rmse:1.95576\n",
      "[25346]\teval-rmse:3.79041\ttrain-rmse:1.95566\n",
      "[25347]\teval-rmse:3.79144\ttrain-rmse:1.95562\n",
      "[25348]\teval-rmse:3.79246\ttrain-rmse:1.95559\n",
      "[25349]\teval-rmse:3.79297\ttrain-rmse:1.95557\n",
      "[25350]\teval-rmse:3.79244\ttrain-rmse:1.95558\n",
      "[25351]\teval-rmse:3.79191\ttrain-rmse:1.9556\n",
      "[25352]\teval-rmse:3.79211\ttrain-rmse:1.95559\n",
      "[25353]\teval-rmse:3.79066\ttrain-rmse:1.95565\n",
      "[25354]\teval-rmse:3.79121\ttrain-rmse:1.95563\n",
      "[25355]\teval-rmse:3.79276\ttrain-rmse:1.95558\n",
      "[25356]\teval-rmse:3.79242\ttrain-rmse:1.9556\n",
      "[25357]\teval-rmse:3.79403\ttrain-rmse:1.95555\n",
      "[25358]\teval-rmse:3.79532\ttrain-rmse:1.95552\n",
      "[25359]\teval-rmse:3.79592\ttrain-rmse:1.95551\n",
      "[25360]\teval-rmse:3.79592\ttrain-rmse:1.95551\n",
      "[25361]\teval-rmse:3.79543\ttrain-rmse:1.95552\n",
      "[25362]\teval-rmse:3.79492\ttrain-rmse:1.95554\n",
      "[25363]\teval-rmse:3.79479\ttrain-rmse:1.95555\n",
      "[25364]\teval-rmse:3.79495\ttrain-rmse:1.95554\n",
      "[25365]\teval-rmse:3.79594\ttrain-rmse:1.95553\n",
      "[25366]\teval-rmse:3.79727\ttrain-rmse:1.9555\n",
      "[25367]\teval-rmse:3.79832\ttrain-rmse:1.95548\n",
      "[25368]\teval-rmse:3.79915\ttrain-rmse:1.95547\n",
      "[25369]\teval-rmse:3.79782\ttrain-rmse:1.95549\n",
      "[25370]\teval-rmse:3.79726\ttrain-rmse:1.9555\n",
      "[25371]\teval-rmse:3.79573\ttrain-rmse:1.95554\n",
      "[25372]\teval-rmse:3.79568\ttrain-rmse:1.95554\n",
      "[25373]\teval-rmse:3.79496\ttrain-rmse:1.95555\n",
      "[25374]\teval-rmse:3.79663\ttrain-rmse:1.95553\n",
      "[25375]\teval-rmse:3.79624\ttrain-rmse:1.95554\n",
      "[25376]\teval-rmse:3.79607\ttrain-rmse:1.95554\n",
      "[25377]\teval-rmse:3.79529\ttrain-rmse:1.95555\n",
      "[25378]\teval-rmse:3.7938\ttrain-rmse:1.95557\n",
      "[25379]\teval-rmse:3.79324\ttrain-rmse:1.95559\n",
      "[25380]\teval-rmse:3.79483\ttrain-rmse:1.95555\n",
      "[25381]\teval-rmse:3.79671\ttrain-rmse:1.95547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25382]\teval-rmse:3.79548\ttrain-rmse:1.95549\n",
      "[25383]\teval-rmse:3.79467\ttrain-rmse:1.95551\n",
      "[25384]\teval-rmse:3.79481\ttrain-rmse:1.9555\n",
      "[25385]\teval-rmse:3.79669\ttrain-rmse:1.95543\n",
      "[25386]\teval-rmse:3.79836\ttrain-rmse:1.95539\n",
      "[25387]\teval-rmse:3.79713\ttrain-rmse:1.95541\n",
      "[25388]\teval-rmse:3.79653\ttrain-rmse:1.95542\n",
      "[25389]\teval-rmse:3.79679\ttrain-rmse:1.95541\n",
      "[25390]\teval-rmse:3.79527\ttrain-rmse:1.95545\n",
      "[25391]\teval-rmse:3.79524\ttrain-rmse:1.95545\n",
      "[25392]\teval-rmse:3.79691\ttrain-rmse:1.95538\n",
      "[25393]\teval-rmse:3.79677\ttrain-rmse:1.95538\n",
      "[25394]\teval-rmse:3.79707\ttrain-rmse:1.95538\n",
      "[25395]\teval-rmse:3.79549\ttrain-rmse:1.95542\n",
      "[25396]\teval-rmse:3.79527\ttrain-rmse:1.95543\n",
      "[25397]\teval-rmse:3.7955\ttrain-rmse:1.95542\n",
      "[25398]\teval-rmse:3.79528\ttrain-rmse:1.95543\n",
      "[25399]\teval-rmse:3.79402\ttrain-rmse:1.95546\n",
      "[25400]\teval-rmse:3.79526\ttrain-rmse:1.95542\n",
      "[25401]\teval-rmse:3.79403\ttrain-rmse:1.95546\n",
      "[25402]\teval-rmse:3.79456\ttrain-rmse:1.95544\n",
      "[25403]\teval-rmse:3.79593\ttrain-rmse:1.9554\n",
      "[25404]\teval-rmse:3.79518\ttrain-rmse:1.95542\n",
      "[25405]\teval-rmse:3.79647\ttrain-rmse:1.95538\n",
      "[25406]\teval-rmse:3.79835\ttrain-rmse:1.95531\n",
      "[25407]\teval-rmse:3.79709\ttrain-rmse:1.95533\n",
      "[25408]\teval-rmse:3.79825\ttrain-rmse:1.95531\n",
      "[25409]\teval-rmse:3.79781\ttrain-rmse:1.95532\n",
      "[25410]\teval-rmse:3.79918\ttrain-rmse:1.95529\n",
      "[25411]\teval-rmse:3.79919\ttrain-rmse:1.95529\n",
      "[25412]\teval-rmse:3.79905\ttrain-rmse:1.95529\n",
      "[25413]\teval-rmse:3.79853\ttrain-rmse:1.9553\n",
      "[25414]\teval-rmse:3.7991\ttrain-rmse:1.95529\n",
      "[25415]\teval-rmse:3.7986\ttrain-rmse:1.9553\n",
      "[25416]\teval-rmse:3.79963\ttrain-rmse:1.95528\n",
      "[25417]\teval-rmse:3.79837\ttrain-rmse:1.95533\n",
      "[25418]\teval-rmse:3.79883\ttrain-rmse:1.95532\n",
      "[25419]\teval-rmse:3.79932\ttrain-rmse:1.95531\n",
      "[25420]\teval-rmse:3.79892\ttrain-rmse:1.95532\n",
      "[25421]\teval-rmse:3.79924\ttrain-rmse:1.95531\n",
      "[25422]\teval-rmse:3.80077\ttrain-rmse:1.95529\n",
      "[25423]\teval-rmse:3.80106\ttrain-rmse:1.95529\n",
      "[25424]\teval-rmse:3.80068\ttrain-rmse:1.95529\n",
      "[25425]\teval-rmse:3.79934\ttrain-rmse:1.95531\n",
      "[25426]\teval-rmse:3.79996\ttrain-rmse:1.9553\n",
      "[25427]\teval-rmse:3.79836\ttrain-rmse:1.95532\n",
      "[25428]\teval-rmse:3.79719\ttrain-rmse:1.95534\n",
      "[25429]\teval-rmse:3.797\ttrain-rmse:1.95529\n",
      "[25430]\teval-rmse:3.79578\ttrain-rmse:1.95531\n",
      "[25431]\teval-rmse:3.79737\ttrain-rmse:1.95527\n",
      "[25432]\teval-rmse:3.7982\ttrain-rmse:1.95526\n",
      "[25433]\teval-rmse:3.79808\ttrain-rmse:1.95526\n",
      "[25434]\teval-rmse:3.79757\ttrain-rmse:1.95526\n",
      "[25435]\teval-rmse:3.79631\ttrain-rmse:1.95532\n",
      "[25436]\teval-rmse:3.79682\ttrain-rmse:1.95531\n",
      "[25437]\teval-rmse:3.79643\ttrain-rmse:1.95531\n",
      "[25438]\teval-rmse:3.79688\ttrain-rmse:1.95531\n",
      "[25439]\teval-rmse:3.79792\ttrain-rmse:1.95529\n",
      "[25440]\teval-rmse:3.79854\ttrain-rmse:1.95528\n",
      "[25441]\teval-rmse:3.79998\ttrain-rmse:1.95527\n",
      "[25442]\teval-rmse:3.79958\ttrain-rmse:1.95528\n",
      "[25443]\teval-rmse:3.80119\ttrain-rmse:1.95527\n",
      "[25444]\teval-rmse:3.80167\ttrain-rmse:1.95527\n",
      "[25445]\teval-rmse:3.79998\ttrain-rmse:1.95527\n",
      "[25446]\teval-rmse:3.79997\ttrain-rmse:1.95527\n",
      "[25447]\teval-rmse:3.80185\ttrain-rmse:1.95522\n",
      "[25448]\teval-rmse:3.80056\ttrain-rmse:1.95522\n",
      "[25449]\teval-rmse:3.79898\ttrain-rmse:1.95524\n",
      "[25450]\teval-rmse:3.79848\ttrain-rmse:1.95524\n",
      "[25451]\teval-rmse:3.79767\ttrain-rmse:1.95525\n",
      "[25452]\teval-rmse:3.79642\ttrain-rmse:1.95529\n",
      "[25453]\teval-rmse:3.7962\ttrain-rmse:1.95529\n",
      "[25454]\teval-rmse:3.79647\ttrain-rmse:1.95528\n",
      "[25455]\teval-rmse:3.79777\ttrain-rmse:1.95526\n",
      "[25456]\teval-rmse:3.79728\ttrain-rmse:1.95527\n",
      "[25457]\teval-rmse:3.79789\ttrain-rmse:1.95526\n",
      "[25458]\teval-rmse:3.79938\ttrain-rmse:1.95525\n",
      "[25459]\teval-rmse:3.79777\ttrain-rmse:1.95527\n",
      "[25460]\teval-rmse:3.79797\ttrain-rmse:1.95527\n",
      "[25461]\teval-rmse:3.7972\ttrain-rmse:1.95528\n",
      "[25462]\teval-rmse:3.79697\ttrain-rmse:1.95529\n",
      "[25463]\teval-rmse:3.79855\ttrain-rmse:1.95522\n",
      "[25464]\teval-rmse:3.80008\ttrain-rmse:1.95521\n",
      "[25465]\teval-rmse:3.79983\ttrain-rmse:1.95522\n",
      "[25466]\teval-rmse:3.7985\ttrain-rmse:1.95523\n",
      "[25467]\teval-rmse:3.79649\ttrain-rmse:1.95527\n",
      "[25468]\teval-rmse:3.79645\ttrain-rmse:1.95527\n",
      "[25469]\teval-rmse:3.79648\ttrain-rmse:1.95527\n",
      "[25470]\teval-rmse:3.79806\ttrain-rmse:1.9552\n",
      "[25471]\teval-rmse:3.79964\ttrain-rmse:1.95518\n",
      "[25472]\teval-rmse:3.79831\ttrain-rmse:1.9552\n",
      "[25473]\teval-rmse:3.797\ttrain-rmse:1.95522\n",
      "[25474]\teval-rmse:3.79656\ttrain-rmse:1.95523\n",
      "[25475]\teval-rmse:3.79605\ttrain-rmse:1.95525\n",
      "[25476]\teval-rmse:3.79666\ttrain-rmse:1.95524\n",
      "[25477]\teval-rmse:3.79824\ttrain-rmse:1.95521\n",
      "[25478]\teval-rmse:3.79982\ttrain-rmse:1.95518\n",
      "[25479]\teval-rmse:3.80033\ttrain-rmse:1.95517\n",
      "[25480]\teval-rmse:3.80136\ttrain-rmse:1.95516\n",
      "[25481]\teval-rmse:3.80165\ttrain-rmse:1.95516\n",
      "[25482]\teval-rmse:3.80119\ttrain-rmse:1.95516\n",
      "[25483]\teval-rmse:3.80179\ttrain-rmse:1.95516\n",
      "[25484]\teval-rmse:3.80198\ttrain-rmse:1.95516\n",
      "[25485]\teval-rmse:3.80324\ttrain-rmse:1.95516\n",
      "[25486]\teval-rmse:3.80307\ttrain-rmse:1.95517\n",
      "[25487]\teval-rmse:3.80258\ttrain-rmse:1.95516\n",
      "[25488]\teval-rmse:3.80242\ttrain-rmse:1.95516\n",
      "[25489]\teval-rmse:3.80198\ttrain-rmse:1.95517\n",
      "[25490]\teval-rmse:3.80355\ttrain-rmse:1.95515\n",
      "[25491]\teval-rmse:3.80201\ttrain-rmse:1.95515\n",
      "[25492]\teval-rmse:3.80312\ttrain-rmse:1.95515\n",
      "[25493]\teval-rmse:3.80335\ttrain-rmse:1.95515\n",
      "[25494]\teval-rmse:3.80294\ttrain-rmse:1.95515\n",
      "[25495]\teval-rmse:3.80412\ttrain-rmse:1.95515\n",
      "[25496]\teval-rmse:3.80357\ttrain-rmse:1.95515\n",
      "[25497]\teval-rmse:3.80226\ttrain-rmse:1.95515\n",
      "[25498]\teval-rmse:3.8027\ttrain-rmse:1.95515\n",
      "[25499]\teval-rmse:3.80324\ttrain-rmse:1.95515\n",
      "[25500]\teval-rmse:3.80192\ttrain-rmse:1.95515\n",
      "[25501]\teval-rmse:3.80038\ttrain-rmse:1.95517\n",
      "[25502]\teval-rmse:3.79881\ttrain-rmse:1.95519\n",
      "[25503]\teval-rmse:3.7968\ttrain-rmse:1.95524\n",
      "[25504]\teval-rmse:3.79847\ttrain-rmse:1.95517\n",
      "[25505]\teval-rmse:3.79771\ttrain-rmse:1.95518\n",
      "[25506]\teval-rmse:3.79691\ttrain-rmse:1.9552\n",
      "[25507]\teval-rmse:3.7974\ttrain-rmse:1.95519\n",
      "[25508]\teval-rmse:3.79624\ttrain-rmse:1.95522\n",
      "[25509]\teval-rmse:3.79475\ttrain-rmse:1.95526\n",
      "[25510]\teval-rmse:3.79453\ttrain-rmse:1.95527\n",
      "[25511]\teval-rmse:3.79349\ttrain-rmse:1.9553\n",
      "[25512]\teval-rmse:3.79189\ttrain-rmse:1.95536\n",
      "[25513]\teval-rmse:3.79213\ttrain-rmse:1.95535\n",
      "[25514]\teval-rmse:3.79401\ttrain-rmse:1.95526\n",
      "[25515]\teval-rmse:3.79388\ttrain-rmse:1.95527\n",
      "[25516]\teval-rmse:3.79527\ttrain-rmse:1.95522\n",
      "[25517]\teval-rmse:3.79506\ttrain-rmse:1.95523\n",
      "[25518]\teval-rmse:3.79484\ttrain-rmse:1.95524\n",
      "[25519]\teval-rmse:3.79336\ttrain-rmse:1.9553\n",
      "[25520]\teval-rmse:3.79416\ttrain-rmse:1.95527\n",
      "[25521]\teval-rmse:3.79322\ttrain-rmse:1.95531\n",
      "[25522]\teval-rmse:3.79199\ttrain-rmse:1.95535\n",
      "[25523]\teval-rmse:3.79317\ttrain-rmse:1.95531\n",
      "[25524]\teval-rmse:3.79262\ttrain-rmse:1.95532\n",
      "[25525]\teval-rmse:3.79377\ttrain-rmse:1.95528\n",
      "[25526]\teval-rmse:3.79357\ttrain-rmse:1.95523\n",
      "[25527]\teval-rmse:3.79337\ttrain-rmse:1.95524\n",
      "[25528]\teval-rmse:3.79189\ttrain-rmse:1.95529\n",
      "[25529]\teval-rmse:3.79169\ttrain-rmse:1.9553\n",
      "[25530]\teval-rmse:3.79327\ttrain-rmse:1.95521\n",
      "[25531]\teval-rmse:3.79462\ttrain-rmse:1.95517\n",
      "[25532]\teval-rmse:3.79442\ttrain-rmse:1.95512\n",
      "[25533]\teval-rmse:3.79575\ttrain-rmse:1.95508\n",
      "[25534]\teval-rmse:3.79528\ttrain-rmse:1.9551\n",
      "[25535]\teval-rmse:3.7938\ttrain-rmse:1.95514\n",
      "[25536]\teval-rmse:3.7934\ttrain-rmse:1.95516\n",
      "[25537]\teval-rmse:3.79465\ttrain-rmse:1.95511\n",
      "[25538]\teval-rmse:3.79419\ttrain-rmse:1.95513\n",
      "[25539]\teval-rmse:3.79553\ttrain-rmse:1.95508\n",
      "[25540]\teval-rmse:3.79711\ttrain-rmse:1.95501\n",
      "[25541]\teval-rmse:3.79816\ttrain-rmse:1.95499\n",
      "[25542]\teval-rmse:3.79763\ttrain-rmse:1.955\n",
      "[25543]\teval-rmse:3.79641\ttrain-rmse:1.95503\n",
      "[25544]\teval-rmse:3.79621\ttrain-rmse:1.95503\n",
      "[25545]\teval-rmse:3.79808\ttrain-rmse:1.95497\n",
      "[25546]\teval-rmse:3.79867\ttrain-rmse:1.95495\n",
      "[25547]\teval-rmse:3.80031\ttrain-rmse:1.95493\n",
      "[25548]\teval-rmse:3.80011\ttrain-rmse:1.95487\n",
      "[25549]\teval-rmse:3.79958\ttrain-rmse:1.95489\n",
      "[25550]\teval-rmse:3.8001\ttrain-rmse:1.95488\n",
      "[25551]\teval-rmse:3.79912\ttrain-rmse:1.95491\n",
      "[25552]\teval-rmse:3.80027\ttrain-rmse:1.9549\n",
      "[25553]\teval-rmse:3.80053\ttrain-rmse:1.95489\n",
      "[25554]\teval-rmse:3.79954\ttrain-rmse:1.95492\n",
      "[25555]\teval-rmse:3.80116\ttrain-rmse:1.95489\n",
      "[25556]\teval-rmse:3.80173\ttrain-rmse:1.95489\n",
      "[25557]\teval-rmse:3.80075\ttrain-rmse:1.95492\n",
      "[25558]\teval-rmse:3.80203\ttrain-rmse:1.95491\n",
      "[25559]\teval-rmse:3.80315\ttrain-rmse:1.95491\n",
      "[25560]\teval-rmse:3.80444\ttrain-rmse:1.95492\n",
      "[25561]\teval-rmse:3.8044\ttrain-rmse:1.95491\n",
      "[25562]\teval-rmse:3.80546\ttrain-rmse:1.95492\n",
      "[25563]\teval-rmse:3.80645\ttrain-rmse:1.95493\n",
      "[25564]\teval-rmse:3.80517\ttrain-rmse:1.95493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25565]\teval-rmse:3.80395\ttrain-rmse:1.95496\n",
      "[25566]\teval-rmse:3.80419\ttrain-rmse:1.95496\n",
      "[25567]\teval-rmse:3.80541\ttrain-rmse:1.95497\n",
      "[25568]\teval-rmse:3.80382\ttrain-rmse:1.95496\n",
      "[25569]\teval-rmse:3.80228\ttrain-rmse:1.95496\n",
      "[25570]\teval-rmse:3.80025\ttrain-rmse:1.95495\n",
      "[25571]\teval-rmse:3.79905\ttrain-rmse:1.95497\n",
      "[25572]\teval-rmse:3.80029\ttrain-rmse:1.95496\n",
      "[25573]\teval-rmse:3.80161\ttrain-rmse:1.95494\n",
      "[25574]\teval-rmse:3.80244\ttrain-rmse:1.95494\n",
      "[25575]\teval-rmse:3.80083\ttrain-rmse:1.95494\n",
      "[25576]\teval-rmse:3.79983\ttrain-rmse:1.95497\n",
      "[25577]\teval-rmse:3.79968\ttrain-rmse:1.95497\n",
      "[25578]\teval-rmse:3.79804\ttrain-rmse:1.95499\n",
      "[25579]\teval-rmse:3.79781\ttrain-rmse:1.955\n",
      "[25580]\teval-rmse:3.79777\ttrain-rmse:1.955\n",
      "[25581]\teval-rmse:3.79791\ttrain-rmse:1.955\n",
      "[25582]\teval-rmse:3.79768\ttrain-rmse:1.955\n",
      "[25583]\teval-rmse:3.79619\ttrain-rmse:1.95503\n",
      "[25584]\teval-rmse:3.79598\ttrain-rmse:1.95504\n",
      "[25585]\teval-rmse:3.79547\ttrain-rmse:1.95506\n",
      "[25586]\teval-rmse:3.79573\ttrain-rmse:1.95506\n",
      "[25587]\teval-rmse:3.79551\ttrain-rmse:1.95507\n",
      "[25588]\teval-rmse:3.79404\ttrain-rmse:1.95511\n",
      "[25589]\teval-rmse:3.79204\ttrain-rmse:1.95518\n",
      "[25590]\teval-rmse:3.79253\ttrain-rmse:1.95516\n",
      "[25591]\teval-rmse:3.7942\ttrain-rmse:1.95512\n",
      "[25592]\teval-rmse:3.79406\ttrain-rmse:1.95512\n",
      "[25593]\teval-rmse:3.79434\ttrain-rmse:1.95511\n",
      "[25594]\teval-rmse:3.79306\ttrain-rmse:1.95515\n",
      "[25595]\teval-rmse:3.79406\ttrain-rmse:1.95512\n",
      "[25596]\teval-rmse:3.79465\ttrain-rmse:1.9551\n",
      "[25597]\teval-rmse:3.79619\ttrain-rmse:1.95506\n",
      "[25598]\teval-rmse:3.79464\ttrain-rmse:1.95509\n",
      "[25599]\teval-rmse:3.79549\ttrain-rmse:1.95507\n",
      "[25600]\teval-rmse:3.7958\ttrain-rmse:1.95506\n",
      "[25601]\teval-rmse:3.79401\ttrain-rmse:1.95512\n",
      "[25602]\teval-rmse:3.79306\ttrain-rmse:1.95516\n",
      "[25603]\teval-rmse:3.79261\ttrain-rmse:1.95517\n",
      "[25604]\teval-rmse:3.79322\ttrain-rmse:1.95515\n",
      "[25605]\teval-rmse:3.79352\ttrain-rmse:1.95514\n",
      "[25606]\teval-rmse:3.792\ttrain-rmse:1.95518\n",
      "[25607]\teval-rmse:3.79388\ttrain-rmse:1.9551\n",
      "[25608]\teval-rmse:3.7924\ttrain-rmse:1.95516\n",
      "[25609]\teval-rmse:3.79223\ttrain-rmse:1.9551\n",
      "[25610]\teval-rmse:3.79223\ttrain-rmse:1.9551\n",
      "[25611]\teval-rmse:3.79203\ttrain-rmse:1.95511\n",
      "[25612]\teval-rmse:3.79161\ttrain-rmse:1.95512\n",
      "[25613]\teval-rmse:3.79179\ttrain-rmse:1.95512\n",
      "[25614]\teval-rmse:3.79347\ttrain-rmse:1.95503\n",
      "[25615]\teval-rmse:3.79329\ttrain-rmse:1.95497\n",
      "[25616]\teval-rmse:3.79329\ttrain-rmse:1.95497\n",
      "[25617]\teval-rmse:3.7949\ttrain-rmse:1.9549\n",
      "[25618]\teval-rmse:3.79374\ttrain-rmse:1.95493\n",
      "[25619]\teval-rmse:3.79397\ttrain-rmse:1.95492\n",
      "[25620]\teval-rmse:3.79522\ttrain-rmse:1.95488\n",
      "[25621]\teval-rmse:3.79369\ttrain-rmse:1.95494\n",
      "[25622]\teval-rmse:3.7923\ttrain-rmse:1.955\n",
      "[25623]\teval-rmse:3.7928\ttrain-rmse:1.95497\n",
      "[25624]\teval-rmse:3.79136\ttrain-rmse:1.95505\n",
      "[25625]\teval-rmse:3.79042\ttrain-rmse:1.95509\n",
      "[25626]\teval-rmse:3.78897\ttrain-rmse:1.95515\n",
      "[25627]\teval-rmse:3.78849\ttrain-rmse:1.95518\n",
      "[25628]\teval-rmse:3.78846\ttrain-rmse:1.95518\n",
      "[25629]\teval-rmse:3.78773\ttrain-rmse:1.95522\n",
      "[25630]\teval-rmse:3.78923\ttrain-rmse:1.95514\n",
      "[25631]\teval-rmse:3.78968\ttrain-rmse:1.95511\n",
      "[25632]\teval-rmse:3.78855\ttrain-rmse:1.95516\n",
      "[25633]\teval-rmse:3.78711\ttrain-rmse:1.95523\n",
      "[25634]\teval-rmse:3.78665\ttrain-rmse:1.95526\n",
      "[25635]\teval-rmse:3.78788\ttrain-rmse:1.95518\n",
      "[25636]\teval-rmse:3.78697\ttrain-rmse:1.95523\n",
      "[25637]\teval-rmse:3.78678\ttrain-rmse:1.95524\n",
      "[25638]\teval-rmse:3.7864\ttrain-rmse:1.95526\n",
      "[25639]\teval-rmse:3.78622\ttrain-rmse:1.95527\n",
      "[25640]\teval-rmse:3.78758\ttrain-rmse:1.95521\n",
      "[25641]\teval-rmse:3.78721\ttrain-rmse:1.95523\n",
      "[25642]\teval-rmse:3.78806\ttrain-rmse:1.95517\n",
      "[25643]\teval-rmse:3.78969\ttrain-rmse:1.95509\n",
      "[25644]\teval-rmse:3.79081\ttrain-rmse:1.95504\n",
      "[25645]\teval-rmse:3.79111\ttrain-rmse:1.95503\n",
      "[25646]\teval-rmse:3.78988\ttrain-rmse:1.95508\n",
      "[25647]\teval-rmse:3.78895\ttrain-rmse:1.95513\n",
      "[25648]\teval-rmse:3.78956\ttrain-rmse:1.9551\n",
      "[25649]\teval-rmse:3.78908\ttrain-rmse:1.95512\n",
      "[25650]\teval-rmse:3.78754\ttrain-rmse:1.9552\n",
      "[25651]\teval-rmse:3.78736\ttrain-rmse:1.95515\n",
      "[25652]\teval-rmse:3.78817\ttrain-rmse:1.95511\n",
      "[25653]\teval-rmse:3.78696\ttrain-rmse:1.95519\n",
      "[25654]\teval-rmse:3.78553\ttrain-rmse:1.95528\n",
      "[25655]\teval-rmse:3.78536\ttrain-rmse:1.95529\n",
      "[25656]\teval-rmse:3.78489\ttrain-rmse:1.95531\n",
      "[25657]\teval-rmse:3.78372\ttrain-rmse:1.95539\n",
      "[25658]\teval-rmse:3.78509\ttrain-rmse:1.9553\n",
      "[25659]\teval-rmse:3.78681\ttrain-rmse:1.9552\n",
      "[25660]\teval-rmse:3.78766\ttrain-rmse:1.95515\n",
      "[25661]\teval-rmse:3.78794\ttrain-rmse:1.95514\n",
      "[25662]\teval-rmse:3.78825\ttrain-rmse:1.95512\n",
      "[25663]\teval-rmse:3.78657\ttrain-rmse:1.95521\n",
      "[25664]\teval-rmse:3.78617\ttrain-rmse:1.95523\n",
      "[25665]\teval-rmse:3.78764\ttrain-rmse:1.95516\n",
      "[25666]\teval-rmse:3.78796\ttrain-rmse:1.95514\n",
      "[25667]\teval-rmse:3.78927\ttrain-rmse:1.95508\n",
      "[25668]\teval-rmse:3.79061\ttrain-rmse:1.95503\n",
      "[25669]\teval-rmse:3.79049\ttrain-rmse:1.95504\n",
      "[25670]\teval-rmse:3.79203\ttrain-rmse:1.95499\n",
      "[25671]\teval-rmse:3.7936\ttrain-rmse:1.95491\n",
      "[25672]\teval-rmse:3.7931\ttrain-rmse:1.95493\n",
      "[25673]\teval-rmse:3.79162\ttrain-rmse:1.95498\n",
      "[25674]\teval-rmse:3.79211\ttrain-rmse:1.95496\n",
      "[25675]\teval-rmse:3.79293\ttrain-rmse:1.95493\n",
      "[25676]\teval-rmse:3.79459\ttrain-rmse:1.95485\n",
      "[25677]\teval-rmse:3.79335\ttrain-rmse:1.95491\n",
      "[25678]\teval-rmse:3.79219\ttrain-rmse:1.95497\n",
      "[25679]\teval-rmse:3.7927\ttrain-rmse:1.95495\n",
      "[25680]\teval-rmse:3.79404\ttrain-rmse:1.95492\n",
      "[25681]\teval-rmse:3.79457\ttrain-rmse:1.95491\n",
      "[25682]\teval-rmse:3.79308\ttrain-rmse:1.95495\n",
      "[25683]\teval-rmse:3.79441\ttrain-rmse:1.95492\n",
      "[25684]\teval-rmse:3.79296\ttrain-rmse:1.95497\n",
      "[25685]\teval-rmse:3.79319\ttrain-rmse:1.95496\n",
      "[25686]\teval-rmse:3.79319\ttrain-rmse:1.95496\n",
      "[25687]\teval-rmse:3.79162\ttrain-rmse:1.95501\n",
      "[25688]\teval-rmse:3.78985\ttrain-rmse:1.95509\n",
      "[25689]\teval-rmse:3.78789\ttrain-rmse:1.95519\n",
      "[25690]\teval-rmse:3.78956\ttrain-rmse:1.95509\n",
      "[25691]\teval-rmse:3.78981\ttrain-rmse:1.95507\n",
      "[25692]\teval-rmse:3.7886\ttrain-rmse:1.95514\n",
      "[25693]\teval-rmse:3.78739\ttrain-rmse:1.95522\n",
      "[25694]\teval-rmse:3.78719\ttrain-rmse:1.95523\n",
      "[25695]\teval-rmse:3.78628\ttrain-rmse:1.95528\n",
      "[25696]\teval-rmse:3.78485\ttrain-rmse:1.95535\n",
      "[25697]\teval-rmse:3.78589\ttrain-rmse:1.95528\n",
      "[25698]\teval-rmse:3.78592\ttrain-rmse:1.95528\n",
      "[25699]\teval-rmse:3.78645\ttrain-rmse:1.95525\n",
      "[25700]\teval-rmse:3.78533\ttrain-rmse:1.95531\n",
      "[25701]\teval-rmse:3.78494\ttrain-rmse:1.95533\n",
      "[25702]\teval-rmse:3.78375\ttrain-rmse:1.9554\n",
      "[25703]\teval-rmse:3.78406\ttrain-rmse:1.95538\n",
      "[25704]\teval-rmse:3.78461\ttrain-rmse:1.95535\n",
      "[25705]\teval-rmse:3.78309\ttrain-rmse:1.95544\n",
      "[25706]\teval-rmse:3.78442\ttrain-rmse:1.95536\n",
      "[25707]\teval-rmse:3.78324\ttrain-rmse:1.95543\n",
      "[25708]\teval-rmse:3.78512\ttrain-rmse:1.95531\n",
      "[25709]\teval-rmse:3.7868\ttrain-rmse:1.95522\n",
      "[25710]\teval-rmse:3.78839\ttrain-rmse:1.95515\n",
      "[25711]\teval-rmse:3.78861\ttrain-rmse:1.95514\n",
      "[25712]\teval-rmse:3.78993\ttrain-rmse:1.95507\n",
      "[25713]\teval-rmse:3.78835\ttrain-rmse:1.95515\n",
      "[25714]\teval-rmse:3.7879\ttrain-rmse:1.95517\n",
      "[25715]\teval-rmse:3.78636\ttrain-rmse:1.95525\n",
      "[25716]\teval-rmse:3.78749\ttrain-rmse:1.95518\n",
      "[25717]\teval-rmse:3.78658\ttrain-rmse:1.95523\n",
      "[25718]\teval-rmse:3.78612\ttrain-rmse:1.95526\n",
      "[25719]\teval-rmse:3.78737\ttrain-rmse:1.9552\n",
      "[25720]\teval-rmse:3.78727\ttrain-rmse:1.95521\n",
      "[25721]\teval-rmse:3.78884\ttrain-rmse:1.95511\n",
      "[25722]\teval-rmse:3.79021\ttrain-rmse:1.95504\n",
      "[25723]\teval-rmse:3.79047\ttrain-rmse:1.95503\n",
      "[25724]\teval-rmse:3.79027\ttrain-rmse:1.95504\n",
      "[25725]\teval-rmse:3.78985\ttrain-rmse:1.95506\n",
      "[25726]\teval-rmse:3.79021\ttrain-rmse:1.95504\n",
      "[25727]\teval-rmse:3.79041\ttrain-rmse:1.95504\n",
      "[25728]\teval-rmse:3.79204\ttrain-rmse:1.95498\n",
      "[25729]\teval-rmse:3.79183\ttrain-rmse:1.95499\n",
      "[25730]\teval-rmse:3.79315\ttrain-rmse:1.95496\n",
      "[25731]\teval-rmse:3.79313\ttrain-rmse:1.95496\n",
      "[25732]\teval-rmse:3.79421\ttrain-rmse:1.95493\n",
      "[25733]\teval-rmse:3.79603\ttrain-rmse:1.95488\n",
      "[25734]\teval-rmse:3.79427\ttrain-rmse:1.95493\n",
      "[25735]\teval-rmse:3.79594\ttrain-rmse:1.95486\n",
      "[25736]\teval-rmse:3.79571\ttrain-rmse:1.95486\n",
      "[25737]\teval-rmse:3.7972\ttrain-rmse:1.95484\n",
      "[25738]\teval-rmse:3.79749\ttrain-rmse:1.95483\n",
      "[25739]\teval-rmse:3.79903\ttrain-rmse:1.95482\n",
      "[25740]\teval-rmse:3.79777\ttrain-rmse:1.95484\n",
      "[25741]\teval-rmse:3.79805\ttrain-rmse:1.95483\n",
      "[25742]\teval-rmse:3.79762\ttrain-rmse:1.95485\n",
      "[25743]\teval-rmse:3.79917\ttrain-rmse:1.95483\n",
      "[25744]\teval-rmse:3.79893\ttrain-rmse:1.95484\n",
      "[25745]\teval-rmse:3.79912\ttrain-rmse:1.95484\n",
      "[25746]\teval-rmse:3.80045\ttrain-rmse:1.95483\n",
      "[25747]\teval-rmse:3.80042\ttrain-rmse:1.95483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25748]\teval-rmse:3.80061\ttrain-rmse:1.95483\n",
      "[25749]\teval-rmse:3.80144\ttrain-rmse:1.95482\n",
      "[25750]\teval-rmse:3.8019\ttrain-rmse:1.95482\n",
      "[25751]\teval-rmse:3.80069\ttrain-rmse:1.95483\n",
      "[25752]\teval-rmse:3.7999\ttrain-rmse:1.95484\n",
      "[25753]\teval-rmse:3.7997\ttrain-rmse:1.95479\n",
      "[25754]\teval-rmse:3.79949\ttrain-rmse:1.95479\n",
      "[25755]\teval-rmse:3.80136\ttrain-rmse:1.95474\n",
      "[25756]\teval-rmse:3.80187\ttrain-rmse:1.95474\n",
      "[25757]\teval-rmse:3.80245\ttrain-rmse:1.95474\n",
      "[25758]\teval-rmse:3.80377\ttrain-rmse:1.95474\n",
      "[25759]\teval-rmse:3.8053\ttrain-rmse:1.95475\n",
      "[25760]\teval-rmse:3.80505\ttrain-rmse:1.95476\n",
      "[25761]\teval-rmse:3.80459\ttrain-rmse:1.95475\n",
      "[25762]\teval-rmse:3.80411\ttrain-rmse:1.95475\n",
      "[25763]\teval-rmse:3.8036\ttrain-rmse:1.95475\n",
      "[25764]\teval-rmse:3.80491\ttrain-rmse:1.95477\n",
      "[25765]\teval-rmse:3.80643\ttrain-rmse:1.95479\n",
      "[25766]\teval-rmse:3.80698\ttrain-rmse:1.95479\n",
      "[25767]\teval-rmse:3.80673\ttrain-rmse:1.95479\n",
      "[25768]\teval-rmse:3.80629\ttrain-rmse:1.95478\n",
      "[25769]\teval-rmse:3.80603\ttrain-rmse:1.95478\n",
      "[25770]\teval-rmse:3.80647\ttrain-rmse:1.95478\n",
      "[25771]\teval-rmse:3.80545\ttrain-rmse:1.9548\n",
      "[25772]\teval-rmse:3.80385\ttrain-rmse:1.95478\n",
      "[25773]\teval-rmse:3.80364\ttrain-rmse:1.95477\n",
      "[25774]\teval-rmse:3.80514\ttrain-rmse:1.9548\n",
      "[25775]\teval-rmse:3.80665\ttrain-rmse:1.95483\n",
      "[25776]\teval-rmse:3.80498\ttrain-rmse:1.95479\n",
      "[25777]\teval-rmse:3.80544\ttrain-rmse:1.9548\n",
      "[25778]\teval-rmse:3.8068\ttrain-rmse:1.95482\n",
      "[25779]\teval-rmse:3.80693\ttrain-rmse:1.95482\n",
      "[25780]\teval-rmse:3.80774\ttrain-rmse:1.95481\n",
      "[25781]\teval-rmse:3.80619\ttrain-rmse:1.95478\n",
      "[25782]\teval-rmse:3.80749\ttrain-rmse:1.9548\n",
      "[25783]\teval-rmse:3.80702\ttrain-rmse:1.9548\n",
      "[25784]\teval-rmse:3.80783\ttrain-rmse:1.95481\n",
      "[25785]\teval-rmse:3.80945\ttrain-rmse:1.95485\n",
      "[25786]\teval-rmse:3.81102\ttrain-rmse:1.9549\n",
      "[25787]\teval-rmse:3.80966\ttrain-rmse:1.9549\n",
      "[25788]\teval-rmse:3.81097\ttrain-rmse:1.95494\n",
      "[25789]\teval-rmse:3.81257\ttrain-rmse:1.955\n",
      "[25790]\teval-rmse:3.81301\ttrain-rmse:1.95501\n",
      "[25791]\teval-rmse:3.81451\ttrain-rmse:1.95505\n",
      "[25792]\teval-rmse:3.81285\ttrain-rmse:1.95498\n",
      "[25793]\teval-rmse:3.81312\ttrain-rmse:1.95499\n",
      "[25794]\teval-rmse:3.81157\ttrain-rmse:1.95493\n",
      "[25795]\teval-rmse:3.81131\ttrain-rmse:1.95492\n",
      "[25796]\teval-rmse:3.81076\ttrain-rmse:1.95491\n",
      "[25797]\teval-rmse:3.80972\ttrain-rmse:1.95491\n",
      "[25798]\teval-rmse:3.80888\ttrain-rmse:1.95489\n",
      "[25799]\teval-rmse:3.80887\ttrain-rmse:1.95489\n",
      "[25800]\teval-rmse:3.80799\ttrain-rmse:1.95487\n",
      "[25801]\teval-rmse:3.80715\ttrain-rmse:1.95486\n",
      "[25802]\teval-rmse:3.80858\ttrain-rmse:1.9549\n",
      "[25803]\teval-rmse:3.80724\ttrain-rmse:1.95491\n",
      "[25804]\teval-rmse:3.80538\ttrain-rmse:1.95488\n",
      "[25805]\teval-rmse:3.80725\ttrain-rmse:1.95485\n",
      "[25806]\teval-rmse:3.80663\ttrain-rmse:1.95484\n",
      "[25807]\teval-rmse:3.80769\ttrain-rmse:1.95486\n",
      "[25808]\teval-rmse:3.80891\ttrain-rmse:1.95487\n",
      "[25809]\teval-rmse:3.80842\ttrain-rmse:1.95486\n",
      "[25810]\teval-rmse:3.80707\ttrain-rmse:1.95487\n",
      "[25811]\teval-rmse:3.80825\ttrain-rmse:1.9549\n",
      "[25812]\teval-rmse:3.80689\ttrain-rmse:1.95487\n",
      "[25813]\teval-rmse:3.80532\ttrain-rmse:1.95484\n",
      "[25814]\teval-rmse:3.80718\ttrain-rmse:1.95481\n",
      "[25815]\teval-rmse:3.80868\ttrain-rmse:1.95484\n",
      "[25816]\teval-rmse:3.81033\ttrain-rmse:1.95482\n",
      "[25817]\teval-rmse:3.80928\ttrain-rmse:1.95483\n",
      "[25818]\teval-rmse:3.80952\ttrain-rmse:1.95483\n",
      "[25819]\teval-rmse:3.80798\ttrain-rmse:1.95481\n",
      "[25820]\teval-rmse:3.80829\ttrain-rmse:1.95481\n",
      "[25821]\teval-rmse:3.80994\ttrain-rmse:1.95484\n",
      "[25822]\teval-rmse:3.81072\ttrain-rmse:1.95487\n",
      "[25823]\teval-rmse:3.81099\ttrain-rmse:1.95487\n",
      "[25824]\teval-rmse:3.81128\ttrain-rmse:1.95488\n",
      "[25825]\teval-rmse:3.81263\ttrain-rmse:1.95492\n",
      "[25826]\teval-rmse:3.81383\ttrain-rmse:1.95495\n",
      "[25827]\teval-rmse:3.81568\ttrain-rmse:1.95495\n",
      "[25828]\teval-rmse:3.81694\ttrain-rmse:1.95501\n",
      "[25829]\teval-rmse:3.81586\ttrain-rmse:1.955\n",
      "[25830]\teval-rmse:3.81712\ttrain-rmse:1.95506\n",
      "[25831]\teval-rmse:3.81682\ttrain-rmse:1.95501\n",
      "[25832]\teval-rmse:3.81794\ttrain-rmse:1.95507\n",
      "[25833]\teval-rmse:3.81815\ttrain-rmse:1.95508\n",
      "[25834]\teval-rmse:3.81838\ttrain-rmse:1.95509\n",
      "[25835]\teval-rmse:3.81961\ttrain-rmse:1.95516\n",
      "[25836]\teval-rmse:3.82011\ttrain-rmse:1.95519\n",
      "[25837]\teval-rmse:3.82195\ttrain-rmse:1.95522\n",
      "[25838]\teval-rmse:3.82344\ttrain-rmse:1.95532\n",
      "[25839]\teval-rmse:3.82498\ttrain-rmse:1.9554\n",
      "[25840]\teval-rmse:3.82624\ttrain-rmse:1.95549\n",
      "[25841]\teval-rmse:3.82618\ttrain-rmse:1.95548\n",
      "[25842]\teval-rmse:3.82505\ttrain-rmse:1.95545\n",
      "[25843]\teval-rmse:3.8241\ttrain-rmse:1.95538\n",
      "[25844]\teval-rmse:3.82214\ttrain-rmse:1.95524\n",
      "[25845]\teval-rmse:3.82097\ttrain-rmse:1.95517\n",
      "[25846]\teval-rmse:3.82252\ttrain-rmse:1.9552\n",
      "[25847]\teval-rmse:3.82275\ttrain-rmse:1.95521\n",
      "[25848]\teval-rmse:3.82372\ttrain-rmse:1.95528\n",
      "[25849]\teval-rmse:3.82204\ttrain-rmse:1.95517\n",
      "[25850]\teval-rmse:3.82198\ttrain-rmse:1.95517\n",
      "[25851]\teval-rmse:3.82165\ttrain-rmse:1.95511\n",
      "[25852]\teval-rmse:3.82316\ttrain-rmse:1.95518\n",
      "[25853]\teval-rmse:3.82282\ttrain-rmse:1.95517\n",
      "[25854]\teval-rmse:3.82251\ttrain-rmse:1.95511\n",
      "[25855]\teval-rmse:3.82191\ttrain-rmse:1.95508\n",
      "[25856]\teval-rmse:3.82337\ttrain-rmse:1.95517\n",
      "[25857]\teval-rmse:3.82363\ttrain-rmse:1.95518\n",
      "[25858]\teval-rmse:3.8249\ttrain-rmse:1.95525\n",
      "[25859]\teval-rmse:3.82619\ttrain-rmse:1.95534\n",
      "[25860]\teval-rmse:3.82587\ttrain-rmse:1.95532\n",
      "[25861]\teval-rmse:3.82555\ttrain-rmse:1.9553\n",
      "[25862]\teval-rmse:3.82518\ttrain-rmse:1.95528\n",
      "[25863]\teval-rmse:3.82384\ttrain-rmse:1.95519\n",
      "[25864]\teval-rmse:3.82252\ttrain-rmse:1.9551\n",
      "[25865]\teval-rmse:3.8209\ttrain-rmse:1.955\n",
      "[25866]\teval-rmse:3.81914\ttrain-rmse:1.95493\n",
      "[25867]\teval-rmse:3.81773\ttrain-rmse:1.95486\n",
      "[25868]\teval-rmse:3.81794\ttrain-rmse:1.95487\n",
      "[25869]\teval-rmse:3.81764\ttrain-rmse:1.95481\n",
      "[25870]\teval-rmse:3.81785\ttrain-rmse:1.95482\n",
      "[25871]\teval-rmse:3.81933\ttrain-rmse:1.9549\n",
      "[25872]\teval-rmse:3.81905\ttrain-rmse:1.95488\n",
      "[25873]\teval-rmse:3.81714\ttrain-rmse:1.95478\n",
      "[25874]\teval-rmse:3.81732\ttrain-rmse:1.95479\n",
      "[25875]\teval-rmse:3.81727\ttrain-rmse:1.95479\n",
      "[25876]\teval-rmse:3.81852\ttrain-rmse:1.95485\n",
      "[25877]\teval-rmse:3.81978\ttrain-rmse:1.95492\n",
      "[25878]\teval-rmse:3.82056\ttrain-rmse:1.95497\n",
      "[25879]\teval-rmse:3.81946\ttrain-rmse:1.95495\n",
      "[25880]\teval-rmse:3.81912\ttrain-rmse:1.95494\n",
      "[25881]\teval-rmse:3.81781\ttrain-rmse:1.95492\n",
      "[25882]\teval-rmse:3.81821\ttrain-rmse:1.95494\n",
      "[25883]\teval-rmse:3.81853\ttrain-rmse:1.95496\n",
      "[25884]\teval-rmse:3.82011\ttrain-rmse:1.95503\n",
      "[25885]\teval-rmse:3.81984\ttrain-rmse:1.95501\n",
      "[25886]\teval-rmse:3.81807\ttrain-rmse:1.95491\n",
      "[25887]\teval-rmse:3.81848\ttrain-rmse:1.95493\n",
      "[25888]\teval-rmse:3.81893\ttrain-rmse:1.95495\n",
      "[25889]\teval-rmse:3.8202\ttrain-rmse:1.95502\n",
      "[25890]\teval-rmse:3.82067\ttrain-rmse:1.95505\n",
      "[25891]\teval-rmse:3.82039\ttrain-rmse:1.955\n",
      "[25892]\teval-rmse:3.81928\ttrain-rmse:1.95498\n",
      "[25893]\teval-rmse:3.81791\ttrain-rmse:1.9549\n",
      "[25894]\teval-rmse:3.81782\ttrain-rmse:1.95489\n",
      "[25895]\teval-rmse:3.81761\ttrain-rmse:1.95488\n",
      "[25896]\teval-rmse:3.81731\ttrain-rmse:1.95488\n",
      "[25897]\teval-rmse:3.81805\ttrain-rmse:1.95491\n",
      "[25898]\teval-rmse:3.81715\ttrain-rmse:1.95487\n",
      "[25899]\teval-rmse:3.81759\ttrain-rmse:1.95489\n",
      "[25900]\teval-rmse:3.81866\ttrain-rmse:1.95495\n",
      "[25901]\teval-rmse:3.81887\ttrain-rmse:1.95497\n",
      "[25902]\teval-rmse:3.81827\ttrain-rmse:1.95493\n",
      "[25903]\teval-rmse:3.81848\ttrain-rmse:1.95494\n",
      "[25904]\teval-rmse:3.81684\ttrain-rmse:1.95486\n",
      "[25905]\teval-rmse:3.8149\ttrain-rmse:1.95476\n",
      "[25906]\teval-rmse:3.81648\ttrain-rmse:1.95484\n",
      "[25907]\teval-rmse:3.81591\ttrain-rmse:1.95481\n",
      "[25908]\teval-rmse:3.81615\ttrain-rmse:1.95483\n",
      "[25909]\teval-rmse:3.81688\ttrain-rmse:1.95486\n",
      "[25910]\teval-rmse:3.81473\ttrain-rmse:1.95475\n",
      "[25911]\teval-rmse:3.81445\ttrain-rmse:1.9547\n",
      "[25912]\teval-rmse:3.81457\ttrain-rmse:1.95471\n",
      "[25913]\teval-rmse:3.81611\ttrain-rmse:1.95476\n",
      "[25914]\teval-rmse:3.81587\ttrain-rmse:1.95475\n",
      "[25915]\teval-rmse:3.81644\ttrain-rmse:1.95478\n",
      "[25916]\teval-rmse:3.81774\ttrain-rmse:1.95484\n",
      "[25917]\teval-rmse:3.81926\ttrain-rmse:1.95493\n",
      "[25918]\teval-rmse:3.81966\ttrain-rmse:1.95495\n",
      "[25919]\teval-rmse:3.81912\ttrain-rmse:1.95492\n",
      "[25920]\teval-rmse:3.81921\ttrain-rmse:1.95492\n",
      "[25921]\teval-rmse:3.81913\ttrain-rmse:1.95492\n",
      "[25922]\teval-rmse:3.81767\ttrain-rmse:1.95486\n",
      "[25923]\teval-rmse:3.81921\ttrain-rmse:1.95495\n",
      "[25924]\teval-rmse:3.82038\ttrain-rmse:1.95502\n",
      "[25925]\teval-rmse:3.82004\ttrain-rmse:1.95501\n",
      "[25926]\teval-rmse:3.81859\ttrain-rmse:1.95493\n",
      "[25927]\teval-rmse:3.81806\ttrain-rmse:1.95489\n",
      "[25928]\teval-rmse:3.81927\ttrain-rmse:1.95497\n",
      "[25929]\teval-rmse:3.81904\ttrain-rmse:1.95495\n",
      "[25930]\teval-rmse:3.81773\ttrain-rmse:1.9549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25931]\teval-rmse:3.8176\ttrain-rmse:1.95489\n",
      "[25932]\teval-rmse:3.81923\ttrain-rmse:1.95491\n",
      "[25933]\teval-rmse:3.81892\ttrain-rmse:1.95486\n",
      "[25934]\teval-rmse:3.81858\ttrain-rmse:1.95485\n",
      "[25935]\teval-rmse:3.818\ttrain-rmse:1.95483\n",
      "[25936]\teval-rmse:3.81985\ttrain-rmse:1.95484\n",
      "[25937]\teval-rmse:3.81933\ttrain-rmse:1.95482\n",
      "[25938]\teval-rmse:3.82062\ttrain-rmse:1.95488\n",
      "[25939]\teval-rmse:3.8203\ttrain-rmse:1.95483\n",
      "[25940]\teval-rmse:3.82061\ttrain-rmse:1.95484\n",
      "[25941]\teval-rmse:3.8211\ttrain-rmse:1.95488\n",
      "[25942]\teval-rmse:3.82101\ttrain-rmse:1.95487\n",
      "[25943]\teval-rmse:3.82111\ttrain-rmse:1.95488\n",
      "[25944]\teval-rmse:3.82034\ttrain-rmse:1.95483\n",
      "[25945]\teval-rmse:3.81923\ttrain-rmse:1.95481\n",
      "[25946]\teval-rmse:3.81865\ttrain-rmse:1.95478\n",
      "[25947]\teval-rmse:3.81779\ttrain-rmse:1.95473\n",
      "[25948]\teval-rmse:3.81758\ttrain-rmse:1.95471\n",
      "[25949]\teval-rmse:3.81943\ttrain-rmse:1.95473\n",
      "[25950]\teval-rmse:3.81997\ttrain-rmse:1.95476\n",
      "[25951]\teval-rmse:3.81939\ttrain-rmse:1.95473\n",
      "[25952]\teval-rmse:3.81807\ttrain-rmse:1.95467\n",
      "[25953]\teval-rmse:3.81744\ttrain-rmse:1.95465\n",
      "[25954]\teval-rmse:3.81824\ttrain-rmse:1.95469\n",
      "[25955]\teval-rmse:3.81867\ttrain-rmse:1.95471\n",
      "[25956]\teval-rmse:3.81658\ttrain-rmse:1.9546\n",
      "[25957]\teval-rmse:3.81704\ttrain-rmse:1.95462\n",
      "[25958]\teval-rmse:3.81517\ttrain-rmse:1.95454\n",
      "[25959]\teval-rmse:3.8159\ttrain-rmse:1.95456\n",
      "[25960]\teval-rmse:3.81481\ttrain-rmse:1.95455\n",
      "[25961]\teval-rmse:3.81418\ttrain-rmse:1.95452\n",
      "[25962]\teval-rmse:3.81492\ttrain-rmse:1.95456\n",
      "[25963]\teval-rmse:3.81408\ttrain-rmse:1.95452\n",
      "[25964]\teval-rmse:3.81325\ttrain-rmse:1.95448\n",
      "[25965]\teval-rmse:3.81296\ttrain-rmse:1.95444\n",
      "[25966]\teval-rmse:3.81321\ttrain-rmse:1.95445\n",
      "[25967]\teval-rmse:3.8147\ttrain-rmse:1.95449\n",
      "[25968]\teval-rmse:3.81512\ttrain-rmse:1.95451\n",
      "[25969]\teval-rmse:3.815\ttrain-rmse:1.95451\n",
      "[25970]\teval-rmse:3.81515\ttrain-rmse:1.95451\n",
      "[25971]\teval-rmse:3.81459\ttrain-rmse:1.95449\n",
      "[25972]\teval-rmse:3.81473\ttrain-rmse:1.95449\n",
      "[25973]\teval-rmse:3.81444\ttrain-rmse:1.95444\n",
      "[25974]\teval-rmse:3.81563\ttrain-rmse:1.95448\n",
      "[25975]\teval-rmse:3.81531\ttrain-rmse:1.95448\n",
      "[25976]\teval-rmse:3.81577\ttrain-rmse:1.9545\n",
      "[25977]\teval-rmse:3.81704\ttrain-rmse:1.95455\n",
      "[25978]\teval-rmse:3.81681\ttrain-rmse:1.95455\n",
      "[25979]\teval-rmse:3.81866\ttrain-rmse:1.95457\n",
      "[25980]\teval-rmse:3.81938\ttrain-rmse:1.95461\n",
      "[25981]\teval-rmse:3.82072\ttrain-rmse:1.9547\n",
      "[25982]\teval-rmse:3.81932\ttrain-rmse:1.95466\n",
      "[25983]\teval-rmse:3.82087\ttrain-rmse:1.95469\n",
      "[25984]\teval-rmse:3.82249\ttrain-rmse:1.9548\n",
      "[25985]\teval-rmse:3.82087\ttrain-rmse:1.95469\n",
      "[25986]\teval-rmse:3.81887\ttrain-rmse:1.95457\n",
      "[25987]\teval-rmse:3.81931\ttrain-rmse:1.9546\n",
      "[25988]\teval-rmse:3.82003\ttrain-rmse:1.95463\n",
      "[25989]\teval-rmse:3.81871\ttrain-rmse:1.95457\n",
      "[25990]\teval-rmse:3.82022\ttrain-rmse:1.95466\n",
      "[25991]\teval-rmse:3.82175\ttrain-rmse:1.95469\n",
      "[25992]\teval-rmse:3.82036\ttrain-rmse:1.9546\n",
      "[25993]\teval-rmse:3.81984\ttrain-rmse:1.95457\n",
      "[25994]\teval-rmse:3.81921\ttrain-rmse:1.95454\n",
      "[25995]\teval-rmse:3.82038\ttrain-rmse:1.95461\n",
      "[25996]\teval-rmse:3.8217\ttrain-rmse:1.95469\n",
      "[25997]\teval-rmse:3.82274\ttrain-rmse:1.95476\n",
      "[25998]\teval-rmse:3.8222\ttrain-rmse:1.95473\n",
      "[25999]\teval-rmse:3.8233\ttrain-rmse:1.95481\n",
      "[26000]\teval-rmse:3.82514\ttrain-rmse:1.95485\n",
      "[26001]\teval-rmse:3.82555\ttrain-rmse:1.95488\n",
      "[26002]\teval-rmse:3.82707\ttrain-rmse:1.955\n",
      "[26003]\teval-rmse:3.82505\ttrain-rmse:1.95484\n",
      "[26004]\teval-rmse:3.82624\ttrain-rmse:1.95493\n",
      "[26005]\teval-rmse:3.82617\ttrain-rmse:1.95493\n",
      "[26006]\teval-rmse:3.82666\ttrain-rmse:1.95497\n",
      "[26007]\teval-rmse:3.82519\ttrain-rmse:1.95488\n",
      "[26008]\teval-rmse:3.82488\ttrain-rmse:1.95482\n",
      "[26009]\teval-rmse:3.82451\ttrain-rmse:1.95481\n",
      "[26010]\teval-rmse:3.82388\ttrain-rmse:1.95476\n",
      "[26011]\teval-rmse:3.82572\ttrain-rmse:1.9549\n",
      "[26012]\teval-rmse:3.82517\ttrain-rmse:1.95487\n",
      "[26013]\teval-rmse:3.82484\ttrain-rmse:1.95484\n",
      "[26014]\teval-rmse:3.82425\ttrain-rmse:1.9548\n",
      "[26015]\teval-rmse:3.8244\ttrain-rmse:1.95481\n",
      "[26016]\teval-rmse:3.82486\ttrain-rmse:1.95484\n",
      "[26017]\teval-rmse:3.82557\ttrain-rmse:1.95488\n",
      "[26018]\teval-rmse:3.82683\ttrain-rmse:1.95498\n",
      "[26019]\teval-rmse:3.82706\ttrain-rmse:1.955\n",
      "[26020]\teval-rmse:3.82645\ttrain-rmse:1.95496\n",
      "[26021]\teval-rmse:3.82771\ttrain-rmse:1.95504\n",
      "[26022]\teval-rmse:3.82596\ttrain-rmse:1.9549\n",
      "[26023]\teval-rmse:3.82616\ttrain-rmse:1.95492\n",
      "[26024]\teval-rmse:3.82637\ttrain-rmse:1.95493\n",
      "[26025]\teval-rmse:3.8271\ttrain-rmse:1.95499\n",
      "[26026]\teval-rmse:3.82754\ttrain-rmse:1.95503\n",
      "[26027]\teval-rmse:3.82799\ttrain-rmse:1.95506\n",
      "[26028]\teval-rmse:3.82791\ttrain-rmse:1.95506\n",
      "[26029]\teval-rmse:3.82845\ttrain-rmse:1.9551\n",
      "[26030]\teval-rmse:3.82807\ttrain-rmse:1.95508\n",
      "[26031]\teval-rmse:3.82633\ttrain-rmse:1.95494\n",
      "[26032]\teval-rmse:3.82708\ttrain-rmse:1.95499\n",
      "[26033]\teval-rmse:3.82837\ttrain-rmse:1.9551\n",
      "[26034]\teval-rmse:3.8296\ttrain-rmse:1.95521\n",
      "[26035]\teval-rmse:3.82815\ttrain-rmse:1.95514\n",
      "[26036]\teval-rmse:3.82666\ttrain-rmse:1.95501\n",
      "[26037]\teval-rmse:3.82794\ttrain-rmse:1.95512\n",
      "[26038]\teval-rmse:3.82834\ttrain-rmse:1.95515\n",
      "[26039]\teval-rmse:3.82987\ttrain-rmse:1.95522\n",
      "[26040]\teval-rmse:3.82847\ttrain-rmse:1.95509\n",
      "[26041]\teval-rmse:3.82837\ttrain-rmse:1.95509\n",
      "[26042]\teval-rmse:3.82813\ttrain-rmse:1.95507\n",
      "[26043]\teval-rmse:3.82632\ttrain-rmse:1.95493\n",
      "[26044]\teval-rmse:3.82578\ttrain-rmse:1.95489\n",
      "[26045]\teval-rmse:3.82699\ttrain-rmse:1.95499\n",
      "[26046]\teval-rmse:3.82727\ttrain-rmse:1.95501\n",
      "[26047]\teval-rmse:3.8291\ttrain-rmse:1.95506\n",
      "[26048]\teval-rmse:3.82774\ttrain-rmse:1.95495\n",
      "[26049]\teval-rmse:3.82818\ttrain-rmse:1.95498\n",
      "[26050]\teval-rmse:3.82961\ttrain-rmse:1.9551\n",
      "[26051]\teval-rmse:3.82787\ttrain-rmse:1.95496\n",
      "[26052]\teval-rmse:3.82915\ttrain-rmse:1.95506\n",
      "[26053]\teval-rmse:3.83069\ttrain-rmse:1.95517\n",
      "[26054]\teval-rmse:3.8292\ttrain-rmse:1.95507\n",
      "[26055]\teval-rmse:3.82866\ttrain-rmse:1.95503\n",
      "[26056]\teval-rmse:3.82808\ttrain-rmse:1.95498\n",
      "[26057]\teval-rmse:3.82878\ttrain-rmse:1.95503\n",
      "[26058]\teval-rmse:3.83028\ttrain-rmse:1.95515\n",
      "[26059]\teval-rmse:3.82996\ttrain-rmse:1.95513\n",
      "[26060]\teval-rmse:3.83146\ttrain-rmse:1.95526\n",
      "[26061]\teval-rmse:3.82961\ttrain-rmse:1.9551\n",
      "[26062]\teval-rmse:3.82897\ttrain-rmse:1.95505\n",
      "[26063]\teval-rmse:3.82922\ttrain-rmse:1.95507\n",
      "[26064]\teval-rmse:3.82936\ttrain-rmse:1.95508\n",
      "[26065]\teval-rmse:3.83085\ttrain-rmse:1.95519\n",
      "[26066]\teval-rmse:3.8321\ttrain-rmse:1.9553\n",
      "[26067]\teval-rmse:3.8317\ttrain-rmse:1.95529\n",
      "[26068]\teval-rmse:3.83205\ttrain-rmse:1.95532\n",
      "[26069]\teval-rmse:3.83361\ttrain-rmse:1.95544\n",
      "[26070]\teval-rmse:3.83331\ttrain-rmse:1.95541\n",
      "[26071]\teval-rmse:3.83256\ttrain-rmse:1.95534\n",
      "[26072]\teval-rmse:3.83312\ttrain-rmse:1.95539\n",
      "[26073]\teval-rmse:3.83425\ttrain-rmse:1.95551\n",
      "[26074]\teval-rmse:3.83446\ttrain-rmse:1.95553\n",
      "[26075]\teval-rmse:3.83543\ttrain-rmse:1.95563\n",
      "[26076]\teval-rmse:3.83424\ttrain-rmse:1.95557\n",
      "[26077]\teval-rmse:3.83217\ttrain-rmse:1.95537\n",
      "[26078]\teval-rmse:3.83047\ttrain-rmse:1.95521\n",
      "[26079]\teval-rmse:3.83011\ttrain-rmse:1.95514\n",
      "[26080]\teval-rmse:3.83035\ttrain-rmse:1.95517\n",
      "[26081]\teval-rmse:3.83071\ttrain-rmse:1.9552\n",
      "[26082]\teval-rmse:3.83038\ttrain-rmse:1.95517\n",
      "[26083]\teval-rmse:3.82974\ttrain-rmse:1.95512\n",
      "[26084]\teval-rmse:3.82945\ttrain-rmse:1.9551\n",
      "[26085]\teval-rmse:3.82872\ttrain-rmse:1.95504\n",
      "[26086]\teval-rmse:3.82733\ttrain-rmse:1.95493\n",
      "[26087]\teval-rmse:3.82787\ttrain-rmse:1.95497\n",
      "[26088]\teval-rmse:3.8264\ttrain-rmse:1.95491\n",
      "[26089]\teval-rmse:3.82469\ttrain-rmse:1.95478\n",
      "[26090]\teval-rmse:3.82483\ttrain-rmse:1.95479\n",
      "[26091]\teval-rmse:3.82411\ttrain-rmse:1.95473\n",
      "[26092]\teval-rmse:3.82493\ttrain-rmse:1.9548\n",
      "[26093]\teval-rmse:3.8238\ttrain-rmse:1.95477\n",
      "[26094]\teval-rmse:3.82212\ttrain-rmse:1.95465\n",
      "[26095]\teval-rmse:3.82203\ttrain-rmse:1.95464\n",
      "[26096]\teval-rmse:3.8233\ttrain-rmse:1.95471\n",
      "[26097]\teval-rmse:3.82352\ttrain-rmse:1.95472\n",
      "[26098]\teval-rmse:3.82211\ttrain-rmse:1.95463\n",
      "[26099]\teval-rmse:3.82099\ttrain-rmse:1.9546\n",
      "[26100]\teval-rmse:3.82064\ttrain-rmse:1.9546\n",
      "[26101]\teval-rmse:3.81933\ttrain-rmse:1.95452\n",
      "[26102]\teval-rmse:3.81789\ttrain-rmse:1.95443\n",
      "[26103]\teval-rmse:3.81759\ttrain-rmse:1.95443\n",
      "[26104]\teval-rmse:3.81861\ttrain-rmse:1.95449\n",
      "[26105]\teval-rmse:3.81977\ttrain-rmse:1.95456\n",
      "[26106]\teval-rmse:3.81904\ttrain-rmse:1.95451\n",
      "[26107]\teval-rmse:3.82033\ttrain-rmse:1.95459\n",
      "[26108]\teval-rmse:3.82162\ttrain-rmse:1.95467\n",
      "[26109]\teval-rmse:3.82152\ttrain-rmse:1.95467\n",
      "[26110]\teval-rmse:3.8218\ttrain-rmse:1.95468\n",
      "[26111]\teval-rmse:3.82047\ttrain-rmse:1.95465\n",
      "[26112]\teval-rmse:3.81906\ttrain-rmse:1.95456\n",
      "[26113]\teval-rmse:3.81933\ttrain-rmse:1.95458\n",
      "[26114]\teval-rmse:3.81985\ttrain-rmse:1.95461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26115]\teval-rmse:3.81887\ttrain-rmse:1.95456\n",
      "[26116]\teval-rmse:3.81932\ttrain-rmse:1.95458\n",
      "[26117]\teval-rmse:3.81842\ttrain-rmse:1.95453\n",
      "[26118]\teval-rmse:3.81975\ttrain-rmse:1.9546\n",
      "[26119]\teval-rmse:3.81831\ttrain-rmse:1.95452\n",
      "[26120]\teval-rmse:3.81991\ttrain-rmse:1.95462\n",
      "[26121]\teval-rmse:3.82036\ttrain-rmse:1.95465\n",
      "[26122]\teval-rmse:3.81896\ttrain-rmse:1.95461\n",
      "[26123]\teval-rmse:3.82051\ttrain-rmse:1.95471\n",
      "[26124]\teval-rmse:3.81873\ttrain-rmse:1.95462\n",
      "[26125]\teval-rmse:3.81922\ttrain-rmse:1.95465\n",
      "[26126]\teval-rmse:3.81951\ttrain-rmse:1.95466\n",
      "[26127]\teval-rmse:3.82073\ttrain-rmse:1.95474\n",
      "[26128]\teval-rmse:3.82044\ttrain-rmse:1.95472\n",
      "[26129]\teval-rmse:3.82208\ttrain-rmse:1.95476\n",
      "[26130]\teval-rmse:3.82392\ttrain-rmse:1.9548\n",
      "[26131]\teval-rmse:3.82279\ttrain-rmse:1.95477\n",
      "[26132]\teval-rmse:3.82255\ttrain-rmse:1.95476\n",
      "[26133]\teval-rmse:3.82303\ttrain-rmse:1.95479\n",
      "[26134]\teval-rmse:3.82143\ttrain-rmse:1.95469\n",
      "[26135]\teval-rmse:3.82184\ttrain-rmse:1.95471\n",
      "[26136]\teval-rmse:3.82269\ttrain-rmse:1.95476\n",
      "[26137]\teval-rmse:3.82083\ttrain-rmse:1.95466\n",
      "[26138]\teval-rmse:3.82212\ttrain-rmse:1.95473\n",
      "[26139]\teval-rmse:3.8223\ttrain-rmse:1.95475\n",
      "[26140]\teval-rmse:3.82369\ttrain-rmse:1.95484\n",
      "[26141]\teval-rmse:3.82167\ttrain-rmse:1.9547\n",
      "[26142]\teval-rmse:3.82034\ttrain-rmse:1.95461\n",
      "[26143]\teval-rmse:3.82005\ttrain-rmse:1.95459\n",
      "[26144]\teval-rmse:3.8197\ttrain-rmse:1.95458\n",
      "[26145]\teval-rmse:3.81824\ttrain-rmse:1.95449\n",
      "[26146]\teval-rmse:3.81942\ttrain-rmse:1.95457\n",
      "[26147]\teval-rmse:3.82095\ttrain-rmse:1.9546\n",
      "[26148]\teval-rmse:3.8215\ttrain-rmse:1.95463\n",
      "[26149]\teval-rmse:3.8219\ttrain-rmse:1.95466\n",
      "[26150]\teval-rmse:3.82036\ttrain-rmse:1.95457\n",
      "[26151]\teval-rmse:3.82004\ttrain-rmse:1.95451\n",
      "[26152]\teval-rmse:3.82159\ttrain-rmse:1.95455\n",
      "[26153]\teval-rmse:3.82167\ttrain-rmse:1.95455\n",
      "[26154]\teval-rmse:3.82238\ttrain-rmse:1.95459\n",
      "[26155]\teval-rmse:3.82051\ttrain-rmse:1.95448\n",
      "[26156]\teval-rmse:3.82185\ttrain-rmse:1.95457\n",
      "[26157]\teval-rmse:3.82154\ttrain-rmse:1.95455\n",
      "[26158]\teval-rmse:3.82315\ttrain-rmse:1.95459\n",
      "[26159]\teval-rmse:3.8228\ttrain-rmse:1.95457\n",
      "[26160]\teval-rmse:3.82336\ttrain-rmse:1.9546\n",
      "[26161]\teval-rmse:3.82283\ttrain-rmse:1.95456\n",
      "[26162]\teval-rmse:3.82279\ttrain-rmse:1.95456\n",
      "[26163]\teval-rmse:3.82301\ttrain-rmse:1.95458\n",
      "[26164]\teval-rmse:3.82484\ttrain-rmse:1.95462\n",
      "[26165]\teval-rmse:3.8245\ttrain-rmse:1.95457\n",
      "[26166]\teval-rmse:3.82425\ttrain-rmse:1.95455\n",
      "[26167]\teval-rmse:3.82445\ttrain-rmse:1.95456\n",
      "[26168]\teval-rmse:3.82598\ttrain-rmse:1.95468\n",
      "[26169]\teval-rmse:3.82726\ttrain-rmse:1.95478\n",
      "[26170]\teval-rmse:3.82877\ttrain-rmse:1.9549\n",
      "[26171]\teval-rmse:3.82783\ttrain-rmse:1.95482\n",
      "[26172]\teval-rmse:3.82937\ttrain-rmse:1.95489\n",
      "[26173]\teval-rmse:3.83066\ttrain-rmse:1.95499\n",
      "[26174]\teval-rmse:3.83026\ttrain-rmse:1.95498\n",
      "[26175]\teval-rmse:3.83023\ttrain-rmse:1.95497\n",
      "[26176]\teval-rmse:3.82812\ttrain-rmse:1.95481\n",
      "[26177]\teval-rmse:3.82923\ttrain-rmse:1.9549\n",
      "[26178]\teval-rmse:3.82745\ttrain-rmse:1.95477\n",
      "[26179]\teval-rmse:3.82868\ttrain-rmse:1.95487\n",
      "[26180]\teval-rmse:3.83029\ttrain-rmse:1.95494\n",
      "[26181]\teval-rmse:3.8318\ttrain-rmse:1.95501\n",
      "[26182]\teval-rmse:3.83033\ttrain-rmse:1.95488\n",
      "[26183]\teval-rmse:3.83215\ttrain-rmse:1.95495\n",
      "[26184]\teval-rmse:3.83073\ttrain-rmse:1.95483\n",
      "[26185]\teval-rmse:3.82936\ttrain-rmse:1.95472\n",
      "[26186]\teval-rmse:3.82982\ttrain-rmse:1.95475\n",
      "[26187]\teval-rmse:3.8299\ttrain-rmse:1.95476\n",
      "[26188]\teval-rmse:3.82931\ttrain-rmse:1.95471\n",
      "[26189]\teval-rmse:3.82976\ttrain-rmse:1.95474\n",
      "[26190]\teval-rmse:3.82916\ttrain-rmse:1.9547\n",
      "[26191]\teval-rmse:3.83018\ttrain-rmse:1.95478\n",
      "[26192]\teval-rmse:3.83201\ttrain-rmse:1.95485\n",
      "[26193]\teval-rmse:3.83218\ttrain-rmse:1.95487\n",
      "[26194]\teval-rmse:3.83055\ttrain-rmse:1.95474\n",
      "[26195]\teval-rmse:3.83129\ttrain-rmse:1.9548\n",
      "[26196]\teval-rmse:3.83169\ttrain-rmse:1.95483\n",
      "[26197]\teval-rmse:3.83132\ttrain-rmse:1.95477\n",
      "[26198]\teval-rmse:3.83234\ttrain-rmse:1.95485\n",
      "[26199]\teval-rmse:3.83116\ttrain-rmse:1.9548\n",
      "[26200]\teval-rmse:3.83233\ttrain-rmse:1.95491\n",
      "[26201]\teval-rmse:3.83169\ttrain-rmse:1.95486\n",
      "[26202]\teval-rmse:3.83187\ttrain-rmse:1.95487\n",
      "[26203]\teval-rmse:3.83069\ttrain-rmse:1.95482\n",
      "[26204]\teval-rmse:3.83061\ttrain-rmse:1.95481\n",
      "[26205]\teval-rmse:3.82847\ttrain-rmse:1.95466\n",
      "[26206]\teval-rmse:3.82683\ttrain-rmse:1.95455\n",
      "[26207]\teval-rmse:3.82545\ttrain-rmse:1.95445\n",
      "[26208]\teval-rmse:3.82556\ttrain-rmse:1.95446\n",
      "[26209]\teval-rmse:3.82504\ttrain-rmse:1.95442\n",
      "[26210]\teval-rmse:3.82532\ttrain-rmse:1.95444\n",
      "[26211]\teval-rmse:3.8255\ttrain-rmse:1.95445\n",
      "[26212]\teval-rmse:3.82547\ttrain-rmse:1.95445\n",
      "[26213]\teval-rmse:3.82461\ttrain-rmse:1.9544\n",
      "[26214]\teval-rmse:3.82292\ttrain-rmse:1.9543\n",
      "[26215]\teval-rmse:3.82266\ttrain-rmse:1.95429\n",
      "[26216]\teval-rmse:3.82406\ttrain-rmse:1.95437\n",
      "[26217]\teval-rmse:3.82435\ttrain-rmse:1.95438\n",
      "[26218]\teval-rmse:3.82286\ttrain-rmse:1.9543\n",
      "[26219]\teval-rmse:3.82254\ttrain-rmse:1.95428\n",
      "[26220]\teval-rmse:3.82412\ttrain-rmse:1.95436\n",
      "[26221]\teval-rmse:3.82272\ttrain-rmse:1.95427\n",
      "[26222]\teval-rmse:3.82435\ttrain-rmse:1.95438\n",
      "[26223]\teval-rmse:3.82506\ttrain-rmse:1.95443\n",
      "[26224]\teval-rmse:3.82362\ttrain-rmse:1.95433\n",
      "[26225]\teval-rmse:3.8241\ttrain-rmse:1.95436\n",
      "[26226]\teval-rmse:3.82526\ttrain-rmse:1.95443\n",
      "[26227]\teval-rmse:3.82491\ttrain-rmse:1.95437\n",
      "[26228]\teval-rmse:3.82675\ttrain-rmse:1.95442\n",
      "[26229]\teval-rmse:3.82528\ttrain-rmse:1.95431\n",
      "[26230]\teval-rmse:3.82656\ttrain-rmse:1.95439\n",
      "[26231]\teval-rmse:3.82588\ttrain-rmse:1.95436\n",
      "[26232]\teval-rmse:3.82604\ttrain-rmse:1.95437\n",
      "[26233]\teval-rmse:3.82458\ttrain-rmse:1.95432\n",
      "[26234]\teval-rmse:3.82421\ttrain-rmse:1.9543\n",
      "[26235]\teval-rmse:3.82417\ttrain-rmse:1.9543\n",
      "[26236]\teval-rmse:3.82418\ttrain-rmse:1.9543\n",
      "[26237]\teval-rmse:3.82546\ttrain-rmse:1.95439\n",
      "[26238]\teval-rmse:3.82375\ttrain-rmse:1.95426\n",
      "[26239]\teval-rmse:3.82412\ttrain-rmse:1.95429\n",
      "[26240]\teval-rmse:3.82464\ttrain-rmse:1.95432\n",
      "[26241]\teval-rmse:3.82438\ttrain-rmse:1.9543\n",
      "[26242]\teval-rmse:3.82482\ttrain-rmse:1.95433\n",
      "[26243]\teval-rmse:3.82457\ttrain-rmse:1.95431\n",
      "[26244]\teval-rmse:3.82313\ttrain-rmse:1.95421\n",
      "[26245]\teval-rmse:3.82442\ttrain-rmse:1.9543\n",
      "[26246]\teval-rmse:3.82603\ttrain-rmse:1.95436\n",
      "[26247]\teval-rmse:3.82702\ttrain-rmse:1.95443\n",
      "[26248]\teval-rmse:3.82714\ttrain-rmse:1.95444\n",
      "[26249]\teval-rmse:3.82846\ttrain-rmse:1.95454\n",
      "[26250]\teval-rmse:3.82963\ttrain-rmse:1.95464\n",
      "[26251]\teval-rmse:3.83007\ttrain-rmse:1.95467\n",
      "[26252]\teval-rmse:3.83157\ttrain-rmse:1.95479\n",
      "[26253]\teval-rmse:3.83127\ttrain-rmse:1.95476\n",
      "[26254]\teval-rmse:3.82977\ttrain-rmse:1.95463\n",
      "[26255]\teval-rmse:3.83016\ttrain-rmse:1.95466\n",
      "[26256]\teval-rmse:3.82894\ttrain-rmse:1.95456\n",
      "[26257]\teval-rmse:3.82885\ttrain-rmse:1.95456\n",
      "[26258]\teval-rmse:3.82714\ttrain-rmse:1.95442\n",
      "[26259]\teval-rmse:3.82706\ttrain-rmse:1.95441\n",
      "[26260]\teval-rmse:3.82645\ttrain-rmse:1.95436\n",
      "[26261]\teval-rmse:3.82472\ttrain-rmse:1.95425\n",
      "[26262]\teval-rmse:3.82493\ttrain-rmse:1.95426\n",
      "[26263]\teval-rmse:3.82677\ttrain-rmse:1.95432\n",
      "[26264]\teval-rmse:3.82835\ttrain-rmse:1.95444\n",
      "[26265]\teval-rmse:3.8288\ttrain-rmse:1.95447\n",
      "[26266]\teval-rmse:3.82931\ttrain-rmse:1.9545\n",
      "[26267]\teval-rmse:3.82906\ttrain-rmse:1.95449\n",
      "[26268]\teval-rmse:3.82924\ttrain-rmse:1.9545\n",
      "[26269]\teval-rmse:3.82968\ttrain-rmse:1.95453\n",
      "[26270]\teval-rmse:3.82979\ttrain-rmse:1.95454\n",
      "[26271]\teval-rmse:3.82943\ttrain-rmse:1.95453\n",
      "[26272]\teval-rmse:3.8296\ttrain-rmse:1.95454\n",
      "[26273]\teval-rmse:3.83\ttrain-rmse:1.95457\n",
      "[26274]\teval-rmse:3.8315\ttrain-rmse:1.95469\n",
      "[26275]\teval-rmse:3.83065\ttrain-rmse:1.95462\n",
      "[26276]\teval-rmse:3.83193\ttrain-rmse:1.95473\n",
      "[26277]\teval-rmse:3.83346\ttrain-rmse:1.95487\n",
      "[26278]\teval-rmse:3.83198\ttrain-rmse:1.95479\n",
      "[26279]\teval-rmse:3.83022\ttrain-rmse:1.95464\n",
      "[26280]\teval-rmse:3.82949\ttrain-rmse:1.95458\n",
      "[26281]\teval-rmse:3.82943\ttrain-rmse:1.95457\n",
      "[26282]\teval-rmse:3.82851\ttrain-rmse:1.9545\n",
      "[26283]\teval-rmse:3.82892\ttrain-rmse:1.95453\n",
      "[26284]\teval-rmse:3.82798\ttrain-rmse:1.95447\n",
      "[26285]\teval-rmse:3.82714\ttrain-rmse:1.9544\n",
      "[26286]\teval-rmse:3.82736\ttrain-rmse:1.95442\n",
      "[26287]\teval-rmse:3.82735\ttrain-rmse:1.95442\n",
      "[26288]\teval-rmse:3.82667\ttrain-rmse:1.95439\n",
      "[26289]\teval-rmse:3.82796\ttrain-rmse:1.95448\n",
      "[26290]\teval-rmse:3.82763\ttrain-rmse:1.95446\n",
      "[26291]\teval-rmse:3.82616\ttrain-rmse:1.95436\n",
      "[26292]\teval-rmse:3.82625\ttrain-rmse:1.95437\n",
      "[26293]\teval-rmse:3.82782\ttrain-rmse:1.95449\n",
      "[26294]\teval-rmse:3.82609\ttrain-rmse:1.95438\n",
      "[26295]\teval-rmse:3.82582\ttrain-rmse:1.95436\n",
      "[26296]\teval-rmse:3.82743\ttrain-rmse:1.95442\n",
      "[26297]\teval-rmse:3.8257\ttrain-rmse:1.95429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26298]\teval-rmse:3.82534\ttrain-rmse:1.95426\n",
      "[26299]\teval-rmse:3.82718\ttrain-rmse:1.95432\n",
      "[26300]\teval-rmse:3.82714\ttrain-rmse:1.95431\n",
      "[26301]\teval-rmse:3.82867\ttrain-rmse:1.95443\n",
      "[26302]\teval-rmse:3.8283\ttrain-rmse:1.95441\n",
      "[26303]\teval-rmse:3.82951\ttrain-rmse:1.95451\n",
      "[26304]\teval-rmse:3.82731\ttrain-rmse:1.95436\n",
      "[26305]\teval-rmse:3.82881\ttrain-rmse:1.95447\n",
      "[26306]\teval-rmse:3.82922\ttrain-rmse:1.9545\n",
      "[26307]\teval-rmse:3.83075\ttrain-rmse:1.95463\n",
      "[26308]\teval-rmse:3.829\ttrain-rmse:1.95448\n",
      "[26309]\teval-rmse:3.82867\ttrain-rmse:1.95441\n",
      "[26310]\teval-rmse:3.82791\ttrain-rmse:1.95436\n",
      "[26311]\teval-rmse:3.82645\ttrain-rmse:1.95424\n",
      "[26312]\teval-rmse:3.82719\ttrain-rmse:1.95429\n",
      "[26313]\teval-rmse:3.82867\ttrain-rmse:1.95439\n",
      "[26314]\teval-rmse:3.83049\ttrain-rmse:1.95445\n",
      "[26315]\teval-rmse:3.83174\ttrain-rmse:1.95456\n",
      "[26316]\teval-rmse:3.83024\ttrain-rmse:1.95443\n",
      "[26317]\teval-rmse:3.82855\ttrain-rmse:1.95429\n",
      "[26318]\teval-rmse:3.82758\ttrain-rmse:1.95423\n",
      "[26319]\teval-rmse:3.82751\ttrain-rmse:1.95423\n",
      "[26320]\teval-rmse:3.82903\ttrain-rmse:1.95434\n",
      "[26321]\teval-rmse:3.83035\ttrain-rmse:1.95445\n",
      "[26322]\teval-rmse:3.83165\ttrain-rmse:1.95456\n",
      "[26323]\teval-rmse:3.83026\ttrain-rmse:1.95444\n",
      "[26324]\teval-rmse:3.83099\ttrain-rmse:1.95447\n",
      "[26325]\teval-rmse:3.8298\ttrain-rmse:1.95442\n",
      "[26326]\teval-rmse:3.83019\ttrain-rmse:1.95445\n",
      "[26327]\teval-rmse:3.83172\ttrain-rmse:1.95458\n",
      "[26328]\teval-rmse:3.83284\ttrain-rmse:1.95468\n",
      "[26329]\teval-rmse:3.83246\ttrain-rmse:1.95466\n",
      "[26330]\teval-rmse:3.83399\ttrain-rmse:1.9548\n",
      "[26331]\teval-rmse:3.83228\ttrain-rmse:1.95465\n",
      "[26332]\teval-rmse:3.8327\ttrain-rmse:1.95469\n",
      "[26333]\teval-rmse:3.8332\ttrain-rmse:1.95474\n",
      "[26334]\teval-rmse:3.83437\ttrain-rmse:1.95485\n",
      "[26335]\teval-rmse:3.83486\ttrain-rmse:1.9549\n",
      "[26336]\teval-rmse:3.83331\ttrain-rmse:1.95477\n",
      "[26337]\teval-rmse:3.83457\ttrain-rmse:1.95488\n",
      "[26338]\teval-rmse:3.83525\ttrain-rmse:1.95494\n",
      "[26339]\teval-rmse:3.83358\ttrain-rmse:1.95479\n",
      "[26340]\teval-rmse:3.83506\ttrain-rmse:1.95491\n",
      "[26341]\teval-rmse:3.83283\ttrain-rmse:1.95473\n",
      "[26342]\teval-rmse:3.83245\ttrain-rmse:1.95467\n",
      "[26343]\teval-rmse:3.83075\ttrain-rmse:1.95453\n",
      "[26344]\teval-rmse:3.82954\ttrain-rmse:1.95444\n",
      "[26345]\teval-rmse:3.82805\ttrain-rmse:1.95434\n",
      "[26346]\teval-rmse:3.82632\ttrain-rmse:1.95423\n",
      "[26347]\teval-rmse:3.82679\ttrain-rmse:1.95426\n",
      "[26348]\teval-rmse:3.82735\ttrain-rmse:1.9543\n",
      "[26349]\teval-rmse:3.8262\ttrain-rmse:1.95426\n",
      "[26350]\teval-rmse:3.82768\ttrain-rmse:1.95437\n",
      "[26351]\teval-rmse:3.82596\ttrain-rmse:1.95424\n",
      "[26352]\teval-rmse:3.82623\ttrain-rmse:1.95426\n",
      "[26353]\teval-rmse:3.82508\ttrain-rmse:1.95422\n",
      "[26354]\teval-rmse:3.82691\ttrain-rmse:1.95428\n",
      "[26355]\teval-rmse:3.82832\ttrain-rmse:1.95436\n",
      "[26356]\teval-rmse:3.8277\ttrain-rmse:1.95432\n",
      "[26357]\teval-rmse:3.82632\ttrain-rmse:1.95423\n",
      "[26358]\teval-rmse:3.8278\ttrain-rmse:1.95433\n",
      "[26359]\teval-rmse:3.82719\ttrain-rmse:1.95428\n",
      "[26360]\teval-rmse:3.82542\ttrain-rmse:1.95416\n",
      "[26361]\teval-rmse:3.82638\ttrain-rmse:1.95423\n",
      "[26362]\teval-rmse:3.82474\ttrain-rmse:1.95413\n",
      "[26363]\teval-rmse:3.82522\ttrain-rmse:1.95416\n",
      "[26364]\teval-rmse:3.82488\ttrain-rmse:1.9541\n",
      "[26365]\teval-rmse:3.82455\ttrain-rmse:1.95404\n",
      "[26366]\teval-rmse:3.82313\ttrain-rmse:1.95395\n",
      "[26367]\teval-rmse:3.82335\ttrain-rmse:1.95396\n",
      "[26368]\teval-rmse:3.82518\ttrain-rmse:1.95401\n",
      "[26369]\teval-rmse:3.82528\ttrain-rmse:1.95402\n",
      "[26370]\teval-rmse:3.82386\ttrain-rmse:1.95392\n",
      "[26371]\teval-rmse:3.82304\ttrain-rmse:1.95387\n",
      "[26372]\teval-rmse:3.82424\ttrain-rmse:1.95395\n",
      "[26373]\teval-rmse:3.82248\ttrain-rmse:1.95387\n",
      "[26374]\teval-rmse:3.82192\ttrain-rmse:1.95384\n",
      "[26375]\teval-rmse:3.82216\ttrain-rmse:1.95385\n",
      "[26376]\teval-rmse:3.82192\ttrain-rmse:1.95383\n",
      "[26377]\teval-rmse:3.82354\ttrain-rmse:1.95388\n",
      "[26378]\teval-rmse:3.82209\ttrain-rmse:1.95384\n",
      "[26379]\teval-rmse:3.82175\ttrain-rmse:1.95377\n",
      "[26380]\teval-rmse:3.82215\ttrain-rmse:1.95379\n",
      "[26381]\teval-rmse:3.82228\ttrain-rmse:1.9538\n",
      "[26382]\teval-rmse:3.82193\ttrain-rmse:1.95378\n",
      "[26383]\teval-rmse:3.8216\ttrain-rmse:1.95377\n",
      "[26384]\teval-rmse:3.82125\ttrain-rmse:1.95376\n",
      "[26385]\teval-rmse:3.82153\ttrain-rmse:1.95378\n",
      "[26386]\teval-rmse:3.8199\ttrain-rmse:1.9537\n",
      "[26387]\teval-rmse:3.81958\ttrain-rmse:1.95363\n",
      "[26388]\teval-rmse:3.81926\ttrain-rmse:1.95357\n",
      "[26389]\teval-rmse:3.82049\ttrain-rmse:1.95364\n",
      "[26390]\teval-rmse:3.81991\ttrain-rmse:1.95361\n",
      "[26391]\teval-rmse:3.81826\ttrain-rmse:1.95352\n",
      "[26392]\teval-rmse:3.81851\ttrain-rmse:1.95353\n",
      "[26393]\teval-rmse:3.8174\ttrain-rmse:1.95351\n",
      "[26394]\teval-rmse:3.81716\ttrain-rmse:1.9535\n",
      "[26395]\teval-rmse:3.81895\ttrain-rmse:1.95356\n",
      "[26396]\teval-rmse:3.82079\ttrain-rmse:1.9536\n",
      "[26397]\teval-rmse:3.82202\ttrain-rmse:1.95367\n",
      "[26398]\teval-rmse:3.82176\ttrain-rmse:1.95366\n",
      "[26399]\teval-rmse:3.82199\ttrain-rmse:1.95367\n",
      "[26400]\teval-rmse:3.82058\ttrain-rmse:1.95363\n",
      "[26401]\teval-rmse:3.81888\ttrain-rmse:1.95353\n",
      "[26402]\teval-rmse:3.82072\ttrain-rmse:1.95357\n",
      "[26403]\teval-rmse:3.82049\ttrain-rmse:1.95356\n",
      "[26404]\teval-rmse:3.81888\ttrain-rmse:1.95348\n",
      "[26405]\teval-rmse:3.81825\ttrain-rmse:1.95345\n",
      "[26406]\teval-rmse:3.81762\ttrain-rmse:1.95342\n",
      "[26407]\teval-rmse:3.81881\ttrain-rmse:1.95347\n",
      "[26408]\teval-rmse:3.81717\ttrain-rmse:1.95338\n",
      "[26409]\teval-rmse:3.81557\ttrain-rmse:1.95331\n",
      "[26410]\teval-rmse:3.81573\ttrain-rmse:1.95331\n",
      "[26411]\teval-rmse:3.8154\ttrain-rmse:1.95331\n",
      "[26412]\teval-rmse:3.8138\ttrain-rmse:1.95324\n",
      "[26413]\teval-rmse:3.81431\ttrain-rmse:1.95325\n",
      "[26414]\teval-rmse:3.8126\ttrain-rmse:1.95321\n",
      "[26415]\teval-rmse:3.81413\ttrain-rmse:1.95325\n",
      "[26416]\teval-rmse:3.81384\ttrain-rmse:1.95324\n",
      "[26417]\teval-rmse:3.81356\ttrain-rmse:1.95323\n",
      "[26418]\teval-rmse:3.81468\ttrain-rmse:1.95326\n",
      "[26419]\teval-rmse:3.81495\ttrain-rmse:1.95327\n",
      "[26420]\teval-rmse:3.81333\ttrain-rmse:1.95322\n",
      "[26421]\teval-rmse:3.81378\ttrain-rmse:1.95323\n",
      "[26422]\teval-rmse:3.81247\ttrain-rmse:1.9532\n",
      "[26423]\teval-rmse:3.81108\ttrain-rmse:1.95315\n",
      "[26424]\teval-rmse:3.80981\ttrain-rmse:1.95313\n",
      "[26425]\teval-rmse:3.8095\ttrain-rmse:1.95313\n",
      "[26426]\teval-rmse:3.81107\ttrain-rmse:1.95317\n",
      "[26427]\teval-rmse:3.8093\ttrain-rmse:1.95315\n",
      "[26428]\teval-rmse:3.80878\ttrain-rmse:1.95315\n",
      "[26429]\teval-rmse:3.81041\ttrain-rmse:1.95319\n",
      "[26430]\teval-rmse:3.81011\ttrain-rmse:1.95319\n",
      "[26431]\teval-rmse:3.80851\ttrain-rmse:1.95315\n",
      "[26432]\teval-rmse:3.80798\ttrain-rmse:1.95314\n",
      "[26433]\teval-rmse:3.80638\ttrain-rmse:1.95311\n",
      "[26434]\teval-rmse:3.80694\ttrain-rmse:1.95311\n",
      "[26435]\teval-rmse:3.80749\ttrain-rmse:1.95311\n",
      "[26436]\teval-rmse:3.80795\ttrain-rmse:1.95312\n",
      "[26437]\teval-rmse:3.80817\ttrain-rmse:1.95312\n",
      "[26438]\teval-rmse:3.80832\ttrain-rmse:1.95312\n",
      "[26439]\teval-rmse:3.80703\ttrain-rmse:1.95311\n",
      "[26440]\teval-rmse:3.80502\ttrain-rmse:1.95311\n",
      "[26441]\teval-rmse:3.80456\ttrain-rmse:1.95312\n",
      "[26442]\teval-rmse:3.804\ttrain-rmse:1.95311\n",
      "[26443]\teval-rmse:3.80245\ttrain-rmse:1.9531\n",
      "[26444]\teval-rmse:3.80294\ttrain-rmse:1.9531\n",
      "[26445]\teval-rmse:3.80343\ttrain-rmse:1.9531\n",
      "[26446]\teval-rmse:3.80284\ttrain-rmse:1.95311\n",
      "[26447]\teval-rmse:3.80417\ttrain-rmse:1.95311\n",
      "[26448]\teval-rmse:3.80549\ttrain-rmse:1.95311\n",
      "[26449]\teval-rmse:3.80627\ttrain-rmse:1.95313\n",
      "[26450]\teval-rmse:3.80471\ttrain-rmse:1.9531\n",
      "[26451]\teval-rmse:3.80515\ttrain-rmse:1.95311\n",
      "[26452]\teval-rmse:3.80487\ttrain-rmse:1.95311\n",
      "[26453]\teval-rmse:3.80534\ttrain-rmse:1.95312\n",
      "[26454]\teval-rmse:3.80584\ttrain-rmse:1.95312\n",
      "[26455]\teval-rmse:3.80481\ttrain-rmse:1.95313\n",
      "[26456]\teval-rmse:3.80617\ttrain-rmse:1.95313\n",
      "[26457]\teval-rmse:3.80747\ttrain-rmse:1.95314\n",
      "[26458]\teval-rmse:3.80797\ttrain-rmse:1.95315\n",
      "[26459]\teval-rmse:3.80776\ttrain-rmse:1.95315\n",
      "[26460]\teval-rmse:3.80825\ttrain-rmse:1.95316\n",
      "[26461]\teval-rmse:3.80624\ttrain-rmse:1.95314\n",
      "[26462]\teval-rmse:3.80499\ttrain-rmse:1.95315\n",
      "[26463]\teval-rmse:3.80521\ttrain-rmse:1.95315\n",
      "[26464]\teval-rmse:3.80675\ttrain-rmse:1.95314\n",
      "[26465]\teval-rmse:3.80711\ttrain-rmse:1.95314\n",
      "[26466]\teval-rmse:3.80683\ttrain-rmse:1.95314\n",
      "[26467]\teval-rmse:3.80517\ttrain-rmse:1.95311\n",
      "[26468]\teval-rmse:3.8057\ttrain-rmse:1.95312\n",
      "[26469]\teval-rmse:3.80551\ttrain-rmse:1.95312\n",
      "[26470]\teval-rmse:3.80532\ttrain-rmse:1.95312\n",
      "[26471]\teval-rmse:3.80471\ttrain-rmse:1.95312\n",
      "[26472]\teval-rmse:3.80346\ttrain-rmse:1.9531\n",
      "[26473]\teval-rmse:3.80321\ttrain-rmse:1.9531\n",
      "[26474]\teval-rmse:3.80166\ttrain-rmse:1.95309\n",
      "[26475]\teval-rmse:3.80122\ttrain-rmse:1.9531\n",
      "[26476]\teval-rmse:3.80202\ttrain-rmse:1.95308\n",
      "[26477]\teval-rmse:3.80334\ttrain-rmse:1.95309\n",
      "[26478]\teval-rmse:3.80148\ttrain-rmse:1.9531\n",
      "[26479]\teval-rmse:3.80253\ttrain-rmse:1.95309\n",
      "[26480]\teval-rmse:3.80249\ttrain-rmse:1.95309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26481]\teval-rmse:3.80297\ttrain-rmse:1.95309\n",
      "[26482]\teval-rmse:3.80445\ttrain-rmse:1.95308\n",
      "[26483]\teval-rmse:3.80471\ttrain-rmse:1.95308\n",
      "[26484]\teval-rmse:3.8053\ttrain-rmse:1.95309\n",
      "[26485]\teval-rmse:3.80365\ttrain-rmse:1.95309\n",
      "[26486]\teval-rmse:3.80407\ttrain-rmse:1.95309\n",
      "[26487]\teval-rmse:3.80284\ttrain-rmse:1.95309\n",
      "[26488]\teval-rmse:3.80128\ttrain-rmse:1.95308\n",
      "[26489]\teval-rmse:3.80161\ttrain-rmse:1.95308\n",
      "[26490]\teval-rmse:3.80144\ttrain-rmse:1.95308\n",
      "[26491]\teval-rmse:3.79993\ttrain-rmse:1.95311\n",
      "[26492]\teval-rmse:3.80129\ttrain-rmse:1.95311\n",
      "[26493]\teval-rmse:3.80106\ttrain-rmse:1.95311\n",
      "[26494]\teval-rmse:3.79954\ttrain-rmse:1.95314\n",
      "[26495]\teval-rmse:3.79977\ttrain-rmse:1.95313\n",
      "[26496]\teval-rmse:3.79825\ttrain-rmse:1.95317\n",
      "[26497]\teval-rmse:3.79695\ttrain-rmse:1.95319\n",
      "[26498]\teval-rmse:3.79852\ttrain-rmse:1.95317\n",
      "[26499]\teval-rmse:3.79884\ttrain-rmse:1.95316\n",
      "[26500]\teval-rmse:3.79992\ttrain-rmse:1.95314\n",
      "[26501]\teval-rmse:3.80124\ttrain-rmse:1.95314\n",
      "[26502]\teval-rmse:3.80212\ttrain-rmse:1.95313\n",
      "[26503]\teval-rmse:3.80163\ttrain-rmse:1.95313\n",
      "[26504]\teval-rmse:3.80206\ttrain-rmse:1.95312\n",
      "[26505]\teval-rmse:3.80055\ttrain-rmse:1.95314\n",
      "[26506]\teval-rmse:3.80089\ttrain-rmse:1.95313\n",
      "[26507]\teval-rmse:3.80114\ttrain-rmse:1.95313\n",
      "[26508]\teval-rmse:3.8016\ttrain-rmse:1.95313\n",
      "[26509]\teval-rmse:3.80137\ttrain-rmse:1.95314\n",
      "[26510]\teval-rmse:3.80114\ttrain-rmse:1.95314\n",
      "[26511]\teval-rmse:3.79962\ttrain-rmse:1.95316\n",
      "[26512]\teval-rmse:3.79945\ttrain-rmse:1.95317\n",
      "[26513]\teval-rmse:3.80002\ttrain-rmse:1.95317\n",
      "[26514]\teval-rmse:3.80088\ttrain-rmse:1.95315\n",
      "[26515]\teval-rmse:3.80063\ttrain-rmse:1.95316\n",
      "[26516]\teval-rmse:3.80185\ttrain-rmse:1.95316\n",
      "[26517]\teval-rmse:3.80055\ttrain-rmse:1.95315\n",
      "[26518]\teval-rmse:3.80042\ttrain-rmse:1.95315\n",
      "[26519]\teval-rmse:3.79889\ttrain-rmse:1.95316\n",
      "[26520]\teval-rmse:3.79731\ttrain-rmse:1.95319\n",
      "[26521]\teval-rmse:3.79784\ttrain-rmse:1.95318\n",
      "[26522]\teval-rmse:3.79765\ttrain-rmse:1.95312\n",
      "[26523]\teval-rmse:3.79718\ttrain-rmse:1.95312\n",
      "[26524]\teval-rmse:3.79904\ttrain-rmse:1.95308\n",
      "[26525]\teval-rmse:3.79879\ttrain-rmse:1.95308\n",
      "[26526]\teval-rmse:3.798\ttrain-rmse:1.95309\n",
      "[26527]\teval-rmse:3.79636\ttrain-rmse:1.95314\n",
      "[26528]\teval-rmse:3.79615\ttrain-rmse:1.95308\n",
      "[26529]\teval-rmse:3.79646\ttrain-rmse:1.95307\n",
      "[26530]\teval-rmse:3.79807\ttrain-rmse:1.95305\n",
      "[26531]\teval-rmse:3.79968\ttrain-rmse:1.95303\n",
      "[26532]\teval-rmse:3.79965\ttrain-rmse:1.95303\n",
      "[26533]\teval-rmse:3.79996\ttrain-rmse:1.95303\n",
      "[26534]\teval-rmse:3.80046\ttrain-rmse:1.95302\n",
      "[26535]\teval-rmse:3.7985\ttrain-rmse:1.95307\n",
      "[26536]\teval-rmse:3.7973\ttrain-rmse:1.95311\n",
      "[26537]\teval-rmse:3.79786\ttrain-rmse:1.95309\n",
      "[26538]\teval-rmse:3.79638\ttrain-rmse:1.95315\n",
      "[26539]\teval-rmse:3.79772\ttrain-rmse:1.95311\n",
      "[26540]\teval-rmse:3.79756\ttrain-rmse:1.95312\n",
      "[26541]\teval-rmse:3.7963\ttrain-rmse:1.95313\n",
      "[26542]\teval-rmse:3.79636\ttrain-rmse:1.95313\n",
      "[26543]\teval-rmse:3.79692\ttrain-rmse:1.95312\n",
      "[26544]\teval-rmse:3.7967\ttrain-rmse:1.95306\n",
      "[26545]\teval-rmse:3.79707\ttrain-rmse:1.95305\n",
      "[26546]\teval-rmse:3.79581\ttrain-rmse:1.95309\n",
      "[26547]\teval-rmse:3.79767\ttrain-rmse:1.95304\n",
      "[26548]\teval-rmse:3.79907\ttrain-rmse:1.953\n",
      "[26549]\teval-rmse:3.79854\ttrain-rmse:1.95301\n",
      "[26550]\teval-rmse:3.79901\ttrain-rmse:1.95301\n",
      "[26551]\teval-rmse:3.79875\ttrain-rmse:1.95301\n",
      "[26552]\teval-rmse:3.79812\ttrain-rmse:1.95303\n",
      "[26553]\teval-rmse:3.79919\ttrain-rmse:1.95301\n",
      "[26554]\teval-rmse:3.79971\ttrain-rmse:1.953\n",
      "[26555]\teval-rmse:3.79954\ttrain-rmse:1.95301\n",
      "[26556]\teval-rmse:3.79985\ttrain-rmse:1.953\n",
      "[26557]\teval-rmse:3.80171\ttrain-rmse:1.95297\n",
      "[26558]\teval-rmse:3.80045\ttrain-rmse:1.95297\n",
      "[26559]\teval-rmse:3.80205\ttrain-rmse:1.95296\n",
      "[26560]\teval-rmse:3.8016\ttrain-rmse:1.95296\n",
      "[26561]\teval-rmse:3.80079\ttrain-rmse:1.95298\n",
      "[26562]\teval-rmse:3.79899\ttrain-rmse:1.95302\n",
      "[26563]\teval-rmse:3.79734\ttrain-rmse:1.95307\n",
      "[26564]\teval-rmse:3.79688\ttrain-rmse:1.95307\n",
      "[26565]\teval-rmse:3.79717\ttrain-rmse:1.95307\n",
      "[26566]\teval-rmse:3.79742\ttrain-rmse:1.95306\n",
      "[26567]\teval-rmse:3.79766\ttrain-rmse:1.95305\n",
      "[26568]\teval-rmse:3.79744\ttrain-rmse:1.95306\n",
      "[26569]\teval-rmse:3.79909\ttrain-rmse:1.95302\n",
      "[26570]\teval-rmse:3.79726\ttrain-rmse:1.95308\n",
      "[26571]\teval-rmse:3.79896\ttrain-rmse:1.95302\n",
      "[26572]\teval-rmse:3.80032\ttrain-rmse:1.95301\n",
      "[26573]\teval-rmse:3.79907\ttrain-rmse:1.95302\n",
      "[26574]\teval-rmse:3.80063\ttrain-rmse:1.95298\n",
      "[26575]\teval-rmse:3.80045\ttrain-rmse:1.95298\n",
      "[26576]\teval-rmse:3.80098\ttrain-rmse:1.95297\n",
      "[26577]\teval-rmse:3.8023\ttrain-rmse:1.95295\n",
      "[26578]\teval-rmse:3.80072\ttrain-rmse:1.95299\n",
      "[26579]\teval-rmse:3.79911\ttrain-rmse:1.95304\n",
      "[26580]\teval-rmse:3.7976\ttrain-rmse:1.95308\n",
      "[26581]\teval-rmse:3.79792\ttrain-rmse:1.95307\n",
      "[26582]\teval-rmse:3.79839\ttrain-rmse:1.95306\n",
      "[26583]\teval-rmse:3.79953\ttrain-rmse:1.95302\n",
      "[26584]\teval-rmse:3.79933\ttrain-rmse:1.95296\n",
      "[26585]\teval-rmse:3.80067\ttrain-rmse:1.95295\n",
      "[26586]\teval-rmse:3.80226\ttrain-rmse:1.95293\n",
      "[26587]\teval-rmse:3.80307\ttrain-rmse:1.95293\n",
      "[26588]\teval-rmse:3.80441\ttrain-rmse:1.95293\n",
      "[26589]\teval-rmse:3.80277\ttrain-rmse:1.95291\n",
      "[26590]\teval-rmse:3.80259\ttrain-rmse:1.95291\n",
      "[26591]\teval-rmse:3.80102\ttrain-rmse:1.95293\n",
      "[26592]\teval-rmse:3.80053\ttrain-rmse:1.95293\n",
      "[26593]\teval-rmse:3.80009\ttrain-rmse:1.95294\n",
      "[26594]\teval-rmse:3.79879\ttrain-rmse:1.95295\n",
      "[26595]\teval-rmse:3.79684\ttrain-rmse:1.95302\n",
      "[26596]\teval-rmse:3.79665\ttrain-rmse:1.95296\n",
      "[26597]\teval-rmse:3.79663\ttrain-rmse:1.95296\n",
      "[26598]\teval-rmse:3.79585\ttrain-rmse:1.95297\n",
      "[26599]\teval-rmse:3.79636\ttrain-rmse:1.95296\n",
      "[26600]\teval-rmse:3.79611\ttrain-rmse:1.95297\n",
      "[26601]\teval-rmse:3.79485\ttrain-rmse:1.95302\n",
      "[26602]\teval-rmse:3.7944\ttrain-rmse:1.95304\n",
      "[26603]\teval-rmse:3.79466\ttrain-rmse:1.95303\n",
      "[26604]\teval-rmse:3.79652\ttrain-rmse:1.95297\n",
      "[26605]\teval-rmse:3.79524\ttrain-rmse:1.95301\n",
      "[26606]\teval-rmse:3.79448\ttrain-rmse:1.95303\n",
      "[26607]\teval-rmse:3.79589\ttrain-rmse:1.95297\n",
      "[26608]\teval-rmse:3.79753\ttrain-rmse:1.95291\n",
      "[26609]\teval-rmse:3.79927\ttrain-rmse:1.95286\n",
      "[26610]\teval-rmse:3.80113\ttrain-rmse:1.95282\n",
      "[26611]\teval-rmse:3.80271\ttrain-rmse:1.95279\n",
      "[26612]\teval-rmse:3.80169\ttrain-rmse:1.95281\n",
      "[26613]\teval-rmse:3.80008\ttrain-rmse:1.95282\n",
      "[26614]\teval-rmse:3.80162\ttrain-rmse:1.95281\n",
      "[26615]\teval-rmse:3.80061\ttrain-rmse:1.95283\n",
      "[26616]\teval-rmse:3.79985\ttrain-rmse:1.95283\n",
      "[26617]\teval-rmse:3.79824\ttrain-rmse:1.95285\n",
      "[26618]\teval-rmse:3.79905\ttrain-rmse:1.95284\n",
      "[26619]\teval-rmse:3.79853\ttrain-rmse:1.95285\n",
      "[26620]\teval-rmse:3.79852\ttrain-rmse:1.95285\n",
      "[26621]\teval-rmse:3.79868\ttrain-rmse:1.95285\n",
      "[26622]\teval-rmse:3.79904\ttrain-rmse:1.95284\n",
      "[26623]\teval-rmse:3.79882\ttrain-rmse:1.95278\n",
      "[26624]\teval-rmse:3.79884\ttrain-rmse:1.95278\n",
      "[26625]\teval-rmse:3.79728\ttrain-rmse:1.9528\n",
      "[26626]\teval-rmse:3.79578\ttrain-rmse:1.95286\n",
      "[26627]\teval-rmse:3.79563\ttrain-rmse:1.95286\n",
      "[26628]\teval-rmse:3.79445\ttrain-rmse:1.95289\n",
      "[26629]\teval-rmse:3.79554\ttrain-rmse:1.95284\n",
      "[26630]\teval-rmse:3.79582\ttrain-rmse:1.95283\n",
      "[26631]\teval-rmse:3.79741\ttrain-rmse:1.9528\n",
      "[26632]\teval-rmse:3.799\ttrain-rmse:1.95277\n",
      "[26633]\teval-rmse:3.80054\ttrain-rmse:1.95276\n",
      "[26634]\teval-rmse:3.80178\ttrain-rmse:1.95275\n",
      "[26635]\teval-rmse:3.79994\ttrain-rmse:1.95276\n",
      "[26636]\teval-rmse:3.79978\ttrain-rmse:1.95276\n",
      "[26637]\teval-rmse:3.79858\ttrain-rmse:1.9528\n",
      "[26638]\teval-rmse:3.79686\ttrain-rmse:1.95287\n",
      "[26639]\teval-rmse:3.79745\ttrain-rmse:1.95284\n",
      "[26640]\teval-rmse:3.79793\ttrain-rmse:1.95284\n",
      "[26641]\teval-rmse:3.79856\ttrain-rmse:1.95281\n",
      "[26642]\teval-rmse:3.79904\ttrain-rmse:1.95281\n",
      "[26643]\teval-rmse:3.79777\ttrain-rmse:1.95282\n",
      "[26644]\teval-rmse:3.79678\ttrain-rmse:1.95285\n",
      "[26645]\teval-rmse:3.79756\ttrain-rmse:1.95283\n",
      "[26646]\teval-rmse:3.79839\ttrain-rmse:1.95281\n",
      "[26647]\teval-rmse:3.7972\ttrain-rmse:1.95284\n",
      "[26648]\teval-rmse:3.7977\ttrain-rmse:1.95283\n",
      "[26649]\teval-rmse:3.79619\ttrain-rmse:1.95286\n",
      "[26650]\teval-rmse:3.79473\ttrain-rmse:1.95289\n",
      "[26651]\teval-rmse:3.79587\ttrain-rmse:1.95284\n",
      "[26652]\teval-rmse:3.79751\ttrain-rmse:1.95279\n",
      "[26653]\teval-rmse:3.79885\ttrain-rmse:1.95277\n",
      "[26654]\teval-rmse:3.79807\ttrain-rmse:1.95278\n",
      "[26655]\teval-rmse:3.7973\ttrain-rmse:1.95279\n",
      "[26656]\teval-rmse:3.79891\ttrain-rmse:1.95277\n",
      "[26657]\teval-rmse:3.79818\ttrain-rmse:1.95279\n",
      "[26658]\teval-rmse:3.79774\ttrain-rmse:1.95281\n",
      "[26659]\teval-rmse:3.798\ttrain-rmse:1.9528\n",
      "[26660]\teval-rmse:3.7993\ttrain-rmse:1.95276\n",
      "[26661]\teval-rmse:3.79832\ttrain-rmse:1.95278\n",
      "[26662]\teval-rmse:3.79776\ttrain-rmse:1.95279\n",
      "[26663]\teval-rmse:3.79725\ttrain-rmse:1.9528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26664]\teval-rmse:3.79571\ttrain-rmse:1.95283\n",
      "[26665]\teval-rmse:3.79737\ttrain-rmse:1.95277\n",
      "[26666]\teval-rmse:3.79862\ttrain-rmse:1.95275\n",
      "[26667]\teval-rmse:3.79915\ttrain-rmse:1.95274\n",
      "[26668]\teval-rmse:3.80049\ttrain-rmse:1.95271\n",
      "[26669]\teval-rmse:3.80022\ttrain-rmse:1.95271\n",
      "[26670]\teval-rmse:3.80046\ttrain-rmse:1.95271\n",
      "[26671]\teval-rmse:3.7989\ttrain-rmse:1.95272\n",
      "[26672]\teval-rmse:3.79843\ttrain-rmse:1.95272\n",
      "[26673]\teval-rmse:3.79692\ttrain-rmse:1.95274\n",
      "[26674]\teval-rmse:3.79649\ttrain-rmse:1.95276\n",
      "[26675]\teval-rmse:3.79673\ttrain-rmse:1.95275\n",
      "[26676]\teval-rmse:3.79678\ttrain-rmse:1.95274\n",
      "[26677]\teval-rmse:3.7952\ttrain-rmse:1.9528\n",
      "[26678]\teval-rmse:3.79423\ttrain-rmse:1.95283\n",
      "[26679]\teval-rmse:3.79305\ttrain-rmse:1.95286\n",
      "[26680]\teval-rmse:3.79176\ttrain-rmse:1.9529\n",
      "[26681]\teval-rmse:3.79332\ttrain-rmse:1.95285\n",
      "[26682]\teval-rmse:3.79312\ttrain-rmse:1.9528\n",
      "[26683]\teval-rmse:3.79441\ttrain-rmse:1.95275\n",
      "[26684]\teval-rmse:3.79427\ttrain-rmse:1.95275\n",
      "[26685]\teval-rmse:3.79477\ttrain-rmse:1.95273\n",
      "[26686]\teval-rmse:3.79322\ttrain-rmse:1.95279\n",
      "[26687]\teval-rmse:3.79359\ttrain-rmse:1.95277\n",
      "[26688]\teval-rmse:3.79417\ttrain-rmse:1.95275\n",
      "[26689]\teval-rmse:3.79291\ttrain-rmse:1.95278\n",
      "[26690]\teval-rmse:3.79477\ttrain-rmse:1.95272\n",
      "[26691]\teval-rmse:3.79585\ttrain-rmse:1.95268\n",
      "[26692]\teval-rmse:3.79584\ttrain-rmse:1.95268\n",
      "[26693]\teval-rmse:3.79569\ttrain-rmse:1.95268\n",
      "[26694]\teval-rmse:3.79394\ttrain-rmse:1.95275\n",
      "[26695]\teval-rmse:3.79395\ttrain-rmse:1.95275\n",
      "[26696]\teval-rmse:3.79272\ttrain-rmse:1.95278\n",
      "[26697]\teval-rmse:3.79328\ttrain-rmse:1.95276\n",
      "[26698]\teval-rmse:3.7933\ttrain-rmse:1.95276\n",
      "[26699]\teval-rmse:3.79316\ttrain-rmse:1.95276\n",
      "[26700]\teval-rmse:3.79297\ttrain-rmse:1.95271\n",
      "[26701]\teval-rmse:3.79277\ttrain-rmse:1.95266\n",
      "[26702]\teval-rmse:3.79435\ttrain-rmse:1.9526\n",
      "[26703]\teval-rmse:3.79312\ttrain-rmse:1.95263\n",
      "[26704]\teval-rmse:3.79335\ttrain-rmse:1.95262\n",
      "[26705]\teval-rmse:3.79239\ttrain-rmse:1.95266\n",
      "[26706]\teval-rmse:3.79144\ttrain-rmse:1.95269\n",
      "[26707]\teval-rmse:3.79305\ttrain-rmse:1.95264\n",
      "[26708]\teval-rmse:3.79436\ttrain-rmse:1.95261\n",
      "[26709]\teval-rmse:3.79273\ttrain-rmse:1.95268\n",
      "[26710]\teval-rmse:3.79156\ttrain-rmse:1.95273\n",
      "[26711]\teval-rmse:3.79312\ttrain-rmse:1.95268\n",
      "[26712]\teval-rmse:3.79289\ttrain-rmse:1.95269\n",
      "[26713]\teval-rmse:3.79266\ttrain-rmse:1.95269\n",
      "[26714]\teval-rmse:3.79129\ttrain-rmse:1.95276\n",
      "[26715]\teval-rmse:3.79316\ttrain-rmse:1.95269\n",
      "[26716]\teval-rmse:3.79198\ttrain-rmse:1.95273\n",
      "[26717]\teval-rmse:3.79305\ttrain-rmse:1.95267\n",
      "[26718]\teval-rmse:3.79328\ttrain-rmse:1.95266\n",
      "[26719]\teval-rmse:3.79441\ttrain-rmse:1.95261\n",
      "[26720]\teval-rmse:3.79366\ttrain-rmse:1.95263\n",
      "[26721]\teval-rmse:3.79352\ttrain-rmse:1.95263\n",
      "[26722]\teval-rmse:3.79383\ttrain-rmse:1.95262\n",
      "[26723]\teval-rmse:3.79235\ttrain-rmse:1.95269\n",
      "[26724]\teval-rmse:3.79286\ttrain-rmse:1.95267\n",
      "[26725]\teval-rmse:3.79263\ttrain-rmse:1.95268\n",
      "[26726]\teval-rmse:3.79214\ttrain-rmse:1.9527\n",
      "[26727]\teval-rmse:3.79373\ttrain-rmse:1.95265\n",
      "[26728]\teval-rmse:3.79276\ttrain-rmse:1.95269\n",
      "[26729]\teval-rmse:3.79181\ttrain-rmse:1.95272\n",
      "[26730]\teval-rmse:3.7921\ttrain-rmse:1.95271\n",
      "[26731]\teval-rmse:3.79265\ttrain-rmse:1.95268\n",
      "[26732]\teval-rmse:3.79405\ttrain-rmse:1.95263\n",
      "[26733]\teval-rmse:3.79569\ttrain-rmse:1.95259\n",
      "[26734]\teval-rmse:3.79411\ttrain-rmse:1.95262\n",
      "[26735]\teval-rmse:3.79326\ttrain-rmse:1.95266\n",
      "[26736]\teval-rmse:3.79199\ttrain-rmse:1.9527\n",
      "[26737]\teval-rmse:3.79308\ttrain-rmse:1.95266\n",
      "[26738]\teval-rmse:3.79493\ttrain-rmse:1.9526\n",
      "[26739]\teval-rmse:3.79319\ttrain-rmse:1.95267\n",
      "[26740]\teval-rmse:3.79199\ttrain-rmse:1.95271\n",
      "[26741]\teval-rmse:3.79047\ttrain-rmse:1.95279\n",
      "[26742]\teval-rmse:3.79074\ttrain-rmse:1.95278\n",
      "[26743]\teval-rmse:3.79056\ttrain-rmse:1.95273\n",
      "[26744]\teval-rmse:3.79242\ttrain-rmse:1.95265\n",
      "[26745]\teval-rmse:3.79221\ttrain-rmse:1.95266\n",
      "[26746]\teval-rmse:3.79337\ttrain-rmse:1.95261\n",
      "[26747]\teval-rmse:3.79213\ttrain-rmse:1.95266\n",
      "[26748]\teval-rmse:3.79194\ttrain-rmse:1.95261\n",
      "[26749]\teval-rmse:3.79329\ttrain-rmse:1.95255\n",
      "[26750]\teval-rmse:3.79254\ttrain-rmse:1.95257\n",
      "[26751]\teval-rmse:3.79204\ttrain-rmse:1.95258\n",
      "[26752]\teval-rmse:3.79356\ttrain-rmse:1.95254\n",
      "[26753]\teval-rmse:3.79193\ttrain-rmse:1.95262\n",
      "[26754]\teval-rmse:3.79358\ttrain-rmse:1.95256\n",
      "[26755]\teval-rmse:3.7944\ttrain-rmse:1.95253\n",
      "[26756]\teval-rmse:3.79316\ttrain-rmse:1.95257\n",
      "[26757]\teval-rmse:3.79454\ttrain-rmse:1.95251\n",
      "[26758]\teval-rmse:3.79584\ttrain-rmse:1.95248\n",
      "[26759]\teval-rmse:3.79607\ttrain-rmse:1.95247\n",
      "[26760]\teval-rmse:3.79562\ttrain-rmse:1.95249\n",
      "[26761]\teval-rmse:3.79716\ttrain-rmse:1.95246\n",
      "[26762]\teval-rmse:3.79768\ttrain-rmse:1.95245\n",
      "[26763]\teval-rmse:3.79645\ttrain-rmse:1.95246\n",
      "[26764]\teval-rmse:3.79702\ttrain-rmse:1.95245\n",
      "[26765]\teval-rmse:3.79835\ttrain-rmse:1.95242\n",
      "[26766]\teval-rmse:3.79882\ttrain-rmse:1.95241\n",
      "[26767]\teval-rmse:3.79859\ttrain-rmse:1.95237\n",
      "[26768]\teval-rmse:3.79915\ttrain-rmse:1.95235\n",
      "[26769]\teval-rmse:3.80041\ttrain-rmse:1.95235\n",
      "[26770]\teval-rmse:3.79891\ttrain-rmse:1.95236\n",
      "[26771]\teval-rmse:3.80007\ttrain-rmse:1.95233\n",
      "[26772]\teval-rmse:3.80031\ttrain-rmse:1.95233\n",
      "[26773]\teval-rmse:3.79875\ttrain-rmse:1.95234\n",
      "[26774]\teval-rmse:3.79954\ttrain-rmse:1.95234\n",
      "[26775]\teval-rmse:3.8001\ttrain-rmse:1.95234\n",
      "[26776]\teval-rmse:3.79987\ttrain-rmse:1.95234\n",
      "[26777]\teval-rmse:3.80113\ttrain-rmse:1.95233\n",
      "[26778]\teval-rmse:3.80267\ttrain-rmse:1.95233\n",
      "[26779]\teval-rmse:3.80421\ttrain-rmse:1.95233\n",
      "[26780]\teval-rmse:3.80447\ttrain-rmse:1.95233\n",
      "[26781]\teval-rmse:3.805\ttrain-rmse:1.95233\n",
      "[26782]\teval-rmse:3.80685\ttrain-rmse:1.95232\n",
      "[26783]\teval-rmse:3.80624\ttrain-rmse:1.95232\n",
      "[26784]\teval-rmse:3.80493\ttrain-rmse:1.95232\n",
      "[26785]\teval-rmse:3.80329\ttrain-rmse:1.95232\n",
      "[26786]\teval-rmse:3.80514\ttrain-rmse:1.9523\n",
      "[26787]\teval-rmse:3.80358\ttrain-rmse:1.9523\n",
      "[26788]\teval-rmse:3.8034\ttrain-rmse:1.9523\n",
      "[26789]\teval-rmse:3.80176\ttrain-rmse:1.95232\n",
      "[26790]\teval-rmse:3.80075\ttrain-rmse:1.95234\n",
      "[26791]\teval-rmse:3.80109\ttrain-rmse:1.95233\n",
      "[26792]\teval-rmse:3.79978\ttrain-rmse:1.95236\n",
      "[26793]\teval-rmse:3.79878\ttrain-rmse:1.95238\n",
      "[26794]\teval-rmse:3.79912\ttrain-rmse:1.95237\n",
      "[26795]\teval-rmse:3.79851\ttrain-rmse:1.95238\n",
      "[26796]\teval-rmse:3.79826\ttrain-rmse:1.95239\n",
      "[26797]\teval-rmse:3.79954\ttrain-rmse:1.95238\n",
      "[26798]\teval-rmse:3.7976\ttrain-rmse:1.95243\n",
      "[26799]\teval-rmse:3.79608\ttrain-rmse:1.95245\n",
      "[26800]\teval-rmse:3.79476\ttrain-rmse:1.95247\n",
      "[26801]\teval-rmse:3.79558\ttrain-rmse:1.95245\n",
      "[26802]\teval-rmse:3.79536\ttrain-rmse:1.95245\n",
      "[26803]\teval-rmse:3.79494\ttrain-rmse:1.95246\n",
      "[26804]\teval-rmse:3.79573\ttrain-rmse:1.95244\n",
      "[26805]\teval-rmse:3.79604\ttrain-rmse:1.95243\n",
      "[26806]\teval-rmse:3.79479\ttrain-rmse:1.95246\n",
      "[26807]\teval-rmse:3.79355\ttrain-rmse:1.95249\n",
      "[26808]\teval-rmse:3.79338\ttrain-rmse:1.95243\n",
      "[26809]\teval-rmse:3.79366\ttrain-rmse:1.95242\n",
      "[26810]\teval-rmse:3.79239\ttrain-rmse:1.95247\n",
      "[26811]\teval-rmse:3.79113\ttrain-rmse:1.95252\n",
      "[26812]\teval-rmse:3.79099\ttrain-rmse:1.95252\n",
      "[26813]\teval-rmse:3.79152\ttrain-rmse:1.95251\n",
      "[26814]\teval-rmse:3.79078\ttrain-rmse:1.95253\n",
      "[26815]\teval-rmse:3.79159\ttrain-rmse:1.9525\n",
      "[26816]\teval-rmse:3.79318\ttrain-rmse:1.95246\n",
      "[26817]\teval-rmse:3.79194\ttrain-rmse:1.9525\n",
      "[26818]\teval-rmse:3.79276\ttrain-rmse:1.95247\n",
      "[26819]\teval-rmse:3.79104\ttrain-rmse:1.95255\n",
      "[26820]\teval-rmse:3.79085\ttrain-rmse:1.95256\n",
      "[26821]\teval-rmse:3.79138\ttrain-rmse:1.95253\n",
      "[26822]\teval-rmse:3.79255\ttrain-rmse:1.95248\n",
      "[26823]\teval-rmse:3.7941\ttrain-rmse:1.95243\n",
      "[26824]\teval-rmse:3.7939\ttrain-rmse:1.95243\n",
      "[26825]\teval-rmse:3.79472\ttrain-rmse:1.95242\n",
      "[26826]\teval-rmse:3.794\ttrain-rmse:1.95244\n",
      "[26827]\teval-rmse:3.79386\ttrain-rmse:1.95245\n",
      "[26828]\teval-rmse:3.79372\ttrain-rmse:1.95245\n",
      "[26829]\teval-rmse:3.7922\ttrain-rmse:1.95251\n",
      "[26830]\teval-rmse:3.79406\ttrain-rmse:1.95245\n",
      "[26831]\teval-rmse:3.79282\ttrain-rmse:1.95248\n",
      "[26832]\teval-rmse:3.79186\ttrain-rmse:1.95251\n",
      "[26833]\teval-rmse:3.79169\ttrain-rmse:1.95246\n",
      "[26834]\teval-rmse:3.79295\ttrain-rmse:1.9524\n",
      "[26835]\teval-rmse:3.79397\ttrain-rmse:1.95236\n",
      "[26836]\teval-rmse:3.79426\ttrain-rmse:1.95235\n",
      "[26837]\teval-rmse:3.79405\ttrain-rmse:1.95229\n",
      "[26838]\teval-rmse:3.79391\ttrain-rmse:1.9523\n",
      "[26839]\teval-rmse:3.79243\ttrain-rmse:1.95235\n",
      "[26840]\teval-rmse:3.79293\ttrain-rmse:1.95234\n",
      "[26841]\teval-rmse:3.79457\ttrain-rmse:1.95228\n",
      "[26842]\teval-rmse:3.793\ttrain-rmse:1.95232\n",
      "[26843]\teval-rmse:3.79148\ttrain-rmse:1.95236\n",
      "[26844]\teval-rmse:3.79126\ttrain-rmse:1.95237\n",
      "[26845]\teval-rmse:3.78978\ttrain-rmse:1.95242\n",
      "[26846]\teval-rmse:3.79109\ttrain-rmse:1.95237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26847]\teval-rmse:3.78989\ttrain-rmse:1.95241\n",
      "[26848]\teval-rmse:3.79124\ttrain-rmse:1.95237\n",
      "[26849]\teval-rmse:3.78972\ttrain-rmse:1.95242\n",
      "[26850]\teval-rmse:3.79158\ttrain-rmse:1.95234\n",
      "[26851]\teval-rmse:3.79138\ttrain-rmse:1.95229\n",
      "[26852]\teval-rmse:3.78992\ttrain-rmse:1.95236\n",
      "[26853]\teval-rmse:3.79133\ttrain-rmse:1.9523\n",
      "[26854]\teval-rmse:3.79008\ttrain-rmse:1.95234\n",
      "[26855]\teval-rmse:3.79059\ttrain-rmse:1.95231\n",
      "[26856]\teval-rmse:3.7894\ttrain-rmse:1.95236\n",
      "[26857]\teval-rmse:3.7887\ttrain-rmse:1.95239\n",
      "[26858]\teval-rmse:3.78747\ttrain-rmse:1.95245\n",
      "[26859]\teval-rmse:3.7888\ttrain-rmse:1.9524\n",
      "[26860]\teval-rmse:3.78735\ttrain-rmse:1.95246\n",
      "[26861]\teval-rmse:3.78695\ttrain-rmse:1.95248\n",
      "[26862]\teval-rmse:3.78723\ttrain-rmse:1.95246\n",
      "[26863]\teval-rmse:3.78775\ttrain-rmse:1.95244\n",
      "[26864]\teval-rmse:3.78703\ttrain-rmse:1.95247\n",
      "[26865]\teval-rmse:3.78656\ttrain-rmse:1.9525\n",
      "[26866]\teval-rmse:3.78516\ttrain-rmse:1.95259\n",
      "[26867]\teval-rmse:3.785\ttrain-rmse:1.9526\n",
      "[26868]\teval-rmse:3.78582\ttrain-rmse:1.95256\n",
      "[26869]\teval-rmse:3.78715\ttrain-rmse:1.95247\n",
      "[26870]\teval-rmse:3.7885\ttrain-rmse:1.9524\n",
      "[26871]\teval-rmse:3.78979\ttrain-rmse:1.95235\n",
      "[26872]\teval-rmse:3.79137\ttrain-rmse:1.95228\n",
      "[26873]\teval-rmse:3.79115\ttrain-rmse:1.95229\n",
      "[26874]\teval-rmse:3.79062\ttrain-rmse:1.9523\n",
      "[26875]\teval-rmse:3.79094\ttrain-rmse:1.95229\n",
      "[26876]\teval-rmse:3.79022\ttrain-rmse:1.95232\n",
      "[26877]\teval-rmse:3.79129\ttrain-rmse:1.95228\n",
      "[26878]\teval-rmse:3.79007\ttrain-rmse:1.95232\n",
      "[26879]\teval-rmse:3.79032\ttrain-rmse:1.95231\n",
      "[26880]\teval-rmse:3.78937\ttrain-rmse:1.95235\n",
      "[26881]\teval-rmse:3.7896\ttrain-rmse:1.95234\n",
      "[26882]\teval-rmse:3.78917\ttrain-rmse:1.95236\n",
      "[26883]\teval-rmse:3.78768\ttrain-rmse:1.95244\n",
      "[26884]\teval-rmse:3.7875\ttrain-rmse:1.95244\n",
      "[26885]\teval-rmse:3.78771\ttrain-rmse:1.95243\n",
      "[26886]\teval-rmse:3.78819\ttrain-rmse:1.95241\n",
      "[26887]\teval-rmse:3.78854\ttrain-rmse:1.95239\n",
      "[26888]\teval-rmse:3.78807\ttrain-rmse:1.95242\n",
      "[26889]\teval-rmse:3.78966\ttrain-rmse:1.95236\n",
      "[26890]\teval-rmse:3.78951\ttrain-rmse:1.9523\n",
      "[26891]\teval-rmse:3.78836\ttrain-rmse:1.95234\n",
      "[26892]\teval-rmse:3.78919\ttrain-rmse:1.9523\n",
      "[26893]\teval-rmse:3.78844\ttrain-rmse:1.95233\n",
      "[26894]\teval-rmse:3.78792\ttrain-rmse:1.95236\n",
      "[26895]\teval-rmse:3.78671\ttrain-rmse:1.95241\n",
      "[26896]\teval-rmse:3.78554\ttrain-rmse:1.95246\n",
      "[26897]\teval-rmse:3.78513\ttrain-rmse:1.95249\n",
      "[26898]\teval-rmse:3.78495\ttrain-rmse:1.9525\n",
      "[26899]\teval-rmse:3.78328\ttrain-rmse:1.9526\n",
      "[26900]\teval-rmse:3.78158\ttrain-rmse:1.95272\n",
      "[26901]\teval-rmse:3.78312\ttrain-rmse:1.95263\n",
      "[26902]\teval-rmse:3.78266\ttrain-rmse:1.95266\n",
      "[26903]\teval-rmse:3.78299\ttrain-rmse:1.95264\n",
      "[26904]\teval-rmse:3.7828\ttrain-rmse:1.95265\n",
      "[26905]\teval-rmse:3.78138\ttrain-rmse:1.95273\n",
      "[26906]\teval-rmse:3.78129\ttrain-rmse:1.95274\n",
      "[26907]\teval-rmse:3.7829\ttrain-rmse:1.95264\n",
      "[26908]\teval-rmse:3.78251\ttrain-rmse:1.95266\n",
      "[26909]\teval-rmse:3.78437\ttrain-rmse:1.95256\n",
      "[26910]\teval-rmse:3.78496\ttrain-rmse:1.95252\n",
      "[26911]\teval-rmse:3.78384\ttrain-rmse:1.95258\n",
      "[26912]\teval-rmse:3.78344\ttrain-rmse:1.9526\n",
      "[26913]\teval-rmse:3.78204\ttrain-rmse:1.95268\n",
      "[26914]\teval-rmse:3.78207\ttrain-rmse:1.95268\n",
      "[26915]\teval-rmse:3.78263\ttrain-rmse:1.95264\n",
      "[26916]\teval-rmse:3.78282\ttrain-rmse:1.95262\n",
      "[26917]\teval-rmse:3.78162\ttrain-rmse:1.95269\n",
      "[26918]\teval-rmse:3.78153\ttrain-rmse:1.9527\n",
      "[26919]\teval-rmse:3.77982\ttrain-rmse:1.95281\n",
      "[26920]\teval-rmse:3.77865\ttrain-rmse:1.9529\n",
      "[26921]\teval-rmse:3.77748\ttrain-rmse:1.95298\n",
      "[26922]\teval-rmse:3.7766\ttrain-rmse:1.95305\n",
      "[26923]\teval-rmse:3.77653\ttrain-rmse:1.95305\n",
      "[26924]\teval-rmse:3.77716\ttrain-rmse:1.953\n",
      "[26925]\teval-rmse:3.77869\ttrain-rmse:1.95289\n",
      "[26926]\teval-rmse:3.77955\ttrain-rmse:1.95282\n",
      "[26927]\teval-rmse:3.77946\ttrain-rmse:1.95283\n",
      "[26928]\teval-rmse:3.77932\ttrain-rmse:1.95284\n",
      "[26929]\teval-rmse:3.77988\ttrain-rmse:1.95279\n",
      "[26930]\teval-rmse:3.77922\ttrain-rmse:1.95284\n",
      "[26931]\teval-rmse:3.78108\ttrain-rmse:1.95272\n",
      "[26932]\teval-rmse:3.7814\ttrain-rmse:1.9527\n",
      "[26933]\teval-rmse:3.78223\ttrain-rmse:1.95263\n",
      "[26934]\teval-rmse:3.78187\ttrain-rmse:1.95266\n",
      "[26935]\teval-rmse:3.78353\ttrain-rmse:1.95256\n",
      "[26936]\teval-rmse:3.78382\ttrain-rmse:1.95254\n",
      "[26937]\teval-rmse:3.78419\ttrain-rmse:1.95252\n",
      "[26938]\teval-rmse:3.78298\ttrain-rmse:1.9526\n",
      "[26939]\teval-rmse:3.78414\ttrain-rmse:1.95252\n",
      "[26940]\teval-rmse:3.78377\ttrain-rmse:1.95255\n",
      "[26941]\teval-rmse:3.78358\ttrain-rmse:1.95256\n",
      "[26942]\teval-rmse:3.78316\ttrain-rmse:1.95258\n",
      "[26943]\teval-rmse:3.78301\ttrain-rmse:1.95259\n",
      "[26944]\teval-rmse:3.78252\ttrain-rmse:1.95262\n",
      "[26945]\teval-rmse:3.78211\ttrain-rmse:1.95264\n",
      "[26946]\teval-rmse:3.78121\ttrain-rmse:1.9527\n",
      "[26947]\teval-rmse:3.78254\ttrain-rmse:1.95262\n",
      "[26948]\teval-rmse:3.78215\ttrain-rmse:1.95264\n",
      "[26949]\teval-rmse:3.78098\ttrain-rmse:1.95272\n",
      "[26950]\teval-rmse:3.78231\ttrain-rmse:1.95264\n",
      "[26951]\teval-rmse:3.78259\ttrain-rmse:1.95262\n",
      "[26952]\teval-rmse:3.78415\ttrain-rmse:1.95252\n",
      "[26953]\teval-rmse:3.78547\ttrain-rmse:1.95245\n",
      "[26954]\teval-rmse:3.78435\ttrain-rmse:1.95251\n",
      "[26955]\teval-rmse:3.78424\ttrain-rmse:1.95252\n",
      "[26956]\teval-rmse:3.78411\ttrain-rmse:1.95247\n",
      "[26957]\teval-rmse:3.7832\ttrain-rmse:1.95252\n",
      "[26958]\teval-rmse:3.78279\ttrain-rmse:1.95254\n",
      "[26959]\teval-rmse:3.78435\ttrain-rmse:1.95245\n",
      "[26960]\teval-rmse:3.78265\ttrain-rmse:1.95256\n",
      "[26961]\teval-rmse:3.78391\ttrain-rmse:1.95249\n",
      "[26962]\teval-rmse:3.78413\ttrain-rmse:1.95248\n",
      "[26963]\teval-rmse:3.78474\ttrain-rmse:1.95245\n",
      "[26964]\teval-rmse:3.7863\ttrain-rmse:1.95237\n",
      "[26965]\teval-rmse:3.78481\ttrain-rmse:1.95244\n",
      "[26966]\teval-rmse:3.78643\ttrain-rmse:1.95236\n",
      "[26967]\teval-rmse:3.78692\ttrain-rmse:1.95233\n",
      "[26968]\teval-rmse:3.78723\ttrain-rmse:1.95232\n",
      "[26969]\teval-rmse:3.78759\ttrain-rmse:1.9523\n",
      "[26970]\teval-rmse:3.78914\ttrain-rmse:1.95222\n",
      "[26971]\teval-rmse:3.79031\ttrain-rmse:1.95218\n",
      "[26972]\teval-rmse:3.79112\ttrain-rmse:1.95216\n",
      "[26973]\teval-rmse:3.79257\ttrain-rmse:1.95212\n",
      "[26974]\teval-rmse:3.79243\ttrain-rmse:1.95212\n",
      "[26975]\teval-rmse:3.79243\ttrain-rmse:1.95212\n",
      "[26976]\teval-rmse:3.79148\ttrain-rmse:1.95216\n",
      "[26977]\teval-rmse:3.79306\ttrain-rmse:1.95209\n",
      "[26978]\teval-rmse:3.79154\ttrain-rmse:1.95213\n",
      "[26979]\teval-rmse:3.79036\ttrain-rmse:1.95217\n",
      "[26980]\teval-rmse:3.78915\ttrain-rmse:1.95221\n",
      "[26981]\teval-rmse:3.78893\ttrain-rmse:1.95222\n",
      "[26982]\teval-rmse:3.78731\ttrain-rmse:1.9523\n",
      "[26983]\teval-rmse:3.78887\ttrain-rmse:1.95223\n",
      "[26984]\teval-rmse:3.78845\ttrain-rmse:1.95225\n",
      "[26985]\teval-rmse:3.78773\ttrain-rmse:1.95228\n",
      "[26986]\teval-rmse:3.78775\ttrain-rmse:1.95228\n",
      "[26987]\teval-rmse:3.78655\ttrain-rmse:1.95234\n",
      "[26988]\teval-rmse:3.78692\ttrain-rmse:1.95232\n",
      "[26989]\teval-rmse:3.78538\ttrain-rmse:1.9524\n",
      "[26990]\teval-rmse:3.78519\ttrain-rmse:1.95241\n",
      "[26991]\teval-rmse:3.78704\ttrain-rmse:1.95231\n",
      "[26992]\teval-rmse:3.78585\ttrain-rmse:1.95237\n",
      "[26993]\teval-rmse:3.78668\ttrain-rmse:1.95232\n",
      "[26994]\teval-rmse:3.78555\ttrain-rmse:1.95239\n",
      "[26995]\teval-rmse:3.78616\ttrain-rmse:1.95235\n",
      "[26996]\teval-rmse:3.78666\ttrain-rmse:1.95233\n",
      "[26997]\teval-rmse:3.78699\ttrain-rmse:1.95231\n",
      "[26998]\teval-rmse:3.78584\ttrain-rmse:1.95237\n",
      "[26999]\teval-rmse:3.78701\ttrain-rmse:1.95232\n",
      "[27000]\teval-rmse:3.78853\ttrain-rmse:1.95225\n",
      "[27001]\teval-rmse:3.78875\ttrain-rmse:1.95224\n",
      "[27002]\teval-rmse:3.78897\ttrain-rmse:1.95223\n",
      "[27003]\teval-rmse:3.79012\ttrain-rmse:1.9522\n",
      "[27004]\teval-rmse:3.78939\ttrain-rmse:1.95223\n",
      "[27005]\teval-rmse:3.79096\ttrain-rmse:1.95216\n",
      "[27006]\teval-rmse:3.79148\ttrain-rmse:1.95215\n",
      "[27007]\teval-rmse:3.79098\ttrain-rmse:1.95217\n",
      "[27008]\teval-rmse:3.78942\ttrain-rmse:1.95223\n",
      "[27009]\teval-rmse:3.78924\ttrain-rmse:1.95218\n",
      "[27010]\teval-rmse:3.79076\ttrain-rmse:1.95214\n",
      "[27011]\teval-rmse:3.79139\ttrain-rmse:1.95213\n",
      "[27012]\teval-rmse:3.79163\ttrain-rmse:1.95212\n",
      "[27013]\teval-rmse:3.79145\ttrain-rmse:1.95213\n",
      "[27014]\teval-rmse:3.79142\ttrain-rmse:1.95213\n",
      "[27015]\teval-rmse:3.79199\ttrain-rmse:1.95211\n",
      "[27016]\teval-rmse:3.79125\ttrain-rmse:1.95213\n",
      "[27017]\teval-rmse:3.7931\ttrain-rmse:1.95206\n",
      "[27018]\teval-rmse:3.79269\ttrain-rmse:1.95208\n",
      "[27019]\teval-rmse:3.79433\ttrain-rmse:1.95202\n",
      "[27020]\teval-rmse:3.7923\ttrain-rmse:1.95206\n",
      "[27021]\teval-rmse:3.79391\ttrain-rmse:1.95202\n",
      "[27022]\teval-rmse:3.79268\ttrain-rmse:1.95205\n",
      "[27023]\teval-rmse:3.79254\ttrain-rmse:1.95206\n",
      "[27024]\teval-rmse:3.79388\ttrain-rmse:1.95202\n",
      "[27025]\teval-rmse:3.79368\ttrain-rmse:1.95202\n",
      "[27026]\teval-rmse:3.79484\ttrain-rmse:1.952\n",
      "[27027]\teval-rmse:3.7936\ttrain-rmse:1.95204\n",
      "[27028]\teval-rmse:3.79494\ttrain-rmse:1.95201\n",
      "[27029]\teval-rmse:3.79658\ttrain-rmse:1.95196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27030]\teval-rmse:3.79636\ttrain-rmse:1.95196\n",
      "[27031]\teval-rmse:3.7962\ttrain-rmse:1.95196\n",
      "[27032]\teval-rmse:3.79652\ttrain-rmse:1.95196\n",
      "[27033]\teval-rmse:3.796\ttrain-rmse:1.95197\n",
      "[27034]\teval-rmse:3.79623\ttrain-rmse:1.95197\n",
      "[27035]\teval-rmse:3.79759\ttrain-rmse:1.95195\n",
      "[27036]\teval-rmse:3.799\ttrain-rmse:1.95195\n",
      "[27037]\teval-rmse:3.79917\ttrain-rmse:1.95195\n",
      "[27038]\teval-rmse:3.79901\ttrain-rmse:1.95195\n",
      "[27039]\teval-rmse:3.79965\ttrain-rmse:1.95195\n",
      "[27040]\teval-rmse:3.80128\ttrain-rmse:1.95196\n",
      "[27041]\teval-rmse:3.80083\ttrain-rmse:1.95196\n",
      "[27042]\teval-rmse:3.80209\ttrain-rmse:1.95197\n",
      "[27043]\teval-rmse:3.80024\ttrain-rmse:1.95196\n",
      "[27044]\teval-rmse:3.7984\ttrain-rmse:1.95196\n",
      "[27045]\teval-rmse:3.79991\ttrain-rmse:1.95196\n",
      "[27046]\teval-rmse:3.79964\ttrain-rmse:1.95196\n",
      "[27047]\teval-rmse:3.79831\ttrain-rmse:1.95198\n",
      "[27048]\teval-rmse:3.79731\ttrain-rmse:1.952\n",
      "[27049]\teval-rmse:3.79753\ttrain-rmse:1.952\n",
      "[27050]\teval-rmse:3.7986\ttrain-rmse:1.952\n",
      "[27051]\teval-rmse:3.79707\ttrain-rmse:1.95201\n",
      "[27052]\teval-rmse:3.79525\ttrain-rmse:1.95203\n",
      "[27053]\teval-rmse:3.7951\ttrain-rmse:1.95204\n",
      "[27054]\teval-rmse:3.79362\ttrain-rmse:1.95206\n",
      "[27055]\teval-rmse:3.79311\ttrain-rmse:1.95208\n",
      "[27056]\teval-rmse:3.79469\ttrain-rmse:1.95202\n",
      "[27057]\teval-rmse:3.79578\ttrain-rmse:1.952\n",
      "[27058]\teval-rmse:3.79659\ttrain-rmse:1.95197\n",
      "[27059]\teval-rmse:3.79743\ttrain-rmse:1.95197\n",
      "[27060]\teval-rmse:3.79721\ttrain-rmse:1.95197\n",
      "[27061]\teval-rmse:3.79595\ttrain-rmse:1.95198\n",
      "[27062]\teval-rmse:3.79709\ttrain-rmse:1.95198\n",
      "[27063]\teval-rmse:3.7961\ttrain-rmse:1.952\n",
      "[27064]\teval-rmse:3.79634\ttrain-rmse:1.952\n",
      "[27065]\teval-rmse:3.79536\ttrain-rmse:1.95203\n",
      "[27066]\teval-rmse:3.79515\ttrain-rmse:1.95203\n",
      "[27067]\teval-rmse:3.79418\ttrain-rmse:1.95207\n",
      "[27068]\teval-rmse:3.79218\ttrain-rmse:1.95208\n",
      "[27069]\teval-rmse:3.79403\ttrain-rmse:1.95201\n",
      "[27070]\teval-rmse:3.79561\ttrain-rmse:1.95198\n",
      "[27071]\teval-rmse:3.7941\ttrain-rmse:1.952\n",
      "[27072]\teval-rmse:3.7957\ttrain-rmse:1.95197\n",
      "[27073]\teval-rmse:3.79684\ttrain-rmse:1.95196\n",
      "[27074]\teval-rmse:3.79585\ttrain-rmse:1.95199\n",
      "[27075]\teval-rmse:3.79634\ttrain-rmse:1.95198\n",
      "[27076]\teval-rmse:3.79475\ttrain-rmse:1.95201\n",
      "[27077]\teval-rmse:3.79276\ttrain-rmse:1.95202\n",
      "[27078]\teval-rmse:3.79261\ttrain-rmse:1.95203\n",
      "[27079]\teval-rmse:3.79138\ttrain-rmse:1.95208\n",
      "[27080]\teval-rmse:3.79119\ttrain-rmse:1.95203\n",
      "[27081]\teval-rmse:3.78994\ttrain-rmse:1.95207\n",
      "[27082]\teval-rmse:3.7905\ttrain-rmse:1.95205\n",
      "[27083]\teval-rmse:3.79213\ttrain-rmse:1.95201\n",
      "[27084]\teval-rmse:3.79193\ttrain-rmse:1.95197\n",
      "[27085]\teval-rmse:3.79018\ttrain-rmse:1.952\n",
      "[27086]\teval-rmse:3.78999\ttrain-rmse:1.952\n",
      "[27087]\teval-rmse:3.7917\ttrain-rmse:1.95197\n",
      "[27088]\teval-rmse:3.79354\ttrain-rmse:1.95191\n",
      "[27089]\teval-rmse:3.79336\ttrain-rmse:1.95191\n",
      "[27090]\teval-rmse:3.79209\ttrain-rmse:1.95195\n",
      "[27091]\teval-rmse:3.79029\ttrain-rmse:1.95199\n",
      "[27092]\teval-rmse:3.79184\ttrain-rmse:1.95192\n",
      "[27093]\teval-rmse:3.7917\ttrain-rmse:1.95193\n",
      "[27094]\teval-rmse:3.79285\ttrain-rmse:1.95191\n",
      "[27095]\teval-rmse:3.7944\ttrain-rmse:1.95187\n",
      "[27096]\teval-rmse:3.7924\ttrain-rmse:1.9519\n",
      "[27097]\teval-rmse:3.79321\ttrain-rmse:1.95187\n",
      "[27098]\teval-rmse:3.792\ttrain-rmse:1.9519\n",
      "[27099]\teval-rmse:3.7908\ttrain-rmse:1.95193\n",
      "[27100]\teval-rmse:3.79207\ttrain-rmse:1.9519\n",
      "[27101]\teval-rmse:3.79308\ttrain-rmse:1.95187\n",
      "[27102]\teval-rmse:3.79224\ttrain-rmse:1.95189\n",
      "[27103]\teval-rmse:3.79101\ttrain-rmse:1.95193\n",
      "[27104]\teval-rmse:3.79227\ttrain-rmse:1.9519\n",
      "[27105]\teval-rmse:3.79212\ttrain-rmse:1.95191\n",
      "[27106]\teval-rmse:3.79168\ttrain-rmse:1.95192\n",
      "[27107]\teval-rmse:3.79122\ttrain-rmse:1.95193\n",
      "[27108]\teval-rmse:3.78976\ttrain-rmse:1.95198\n",
      "[27109]\teval-rmse:3.78963\ttrain-rmse:1.95198\n",
      "[27110]\teval-rmse:3.79028\ttrain-rmse:1.95196\n",
      "[27111]\teval-rmse:3.78979\ttrain-rmse:1.95199\n",
      "[27112]\teval-rmse:3.7893\ttrain-rmse:1.952\n",
      "[27113]\teval-rmse:3.78918\ttrain-rmse:1.95201\n",
      "[27114]\teval-rmse:3.78774\ttrain-rmse:1.95206\n",
      "[27115]\teval-rmse:3.78752\ttrain-rmse:1.95207\n",
      "[27116]\teval-rmse:3.78735\ttrain-rmse:1.95203\n",
      "[27117]\teval-rmse:3.78664\ttrain-rmse:1.95206\n",
      "[27118]\teval-rmse:3.78651\ttrain-rmse:1.95201\n",
      "[27119]\teval-rmse:3.78488\ttrain-rmse:1.95208\n",
      "[27120]\teval-rmse:3.78536\ttrain-rmse:1.95206\n",
      "[27121]\teval-rmse:3.78586\ttrain-rmse:1.95203\n",
      "[27122]\teval-rmse:3.78607\ttrain-rmse:1.95202\n",
      "[27123]\teval-rmse:3.7869\ttrain-rmse:1.95199\n",
      "[27124]\teval-rmse:3.78721\ttrain-rmse:1.95198\n",
      "[27125]\teval-rmse:3.78864\ttrain-rmse:1.95193\n",
      "[27126]\teval-rmse:3.78825\ttrain-rmse:1.95194\n",
      "[27127]\teval-rmse:3.7901\ttrain-rmse:1.95186\n",
      "[27128]\teval-rmse:3.79196\ttrain-rmse:1.95179\n",
      "[27129]\teval-rmse:3.79253\ttrain-rmse:1.95178\n",
      "[27130]\teval-rmse:3.79408\ttrain-rmse:1.95174\n",
      "[27131]\teval-rmse:3.79228\ttrain-rmse:1.95178\n",
      "[27132]\teval-rmse:3.79077\ttrain-rmse:1.95183\n",
      "[27133]\teval-rmse:3.79034\ttrain-rmse:1.95185\n",
      "[27134]\teval-rmse:3.79182\ttrain-rmse:1.9518\n",
      "[27135]\teval-rmse:3.79076\ttrain-rmse:1.95183\n",
      "[27136]\teval-rmse:3.78954\ttrain-rmse:1.95188\n",
      "[27137]\teval-rmse:3.78941\ttrain-rmse:1.95189\n",
      "[27138]\teval-rmse:3.78847\ttrain-rmse:1.95193\n",
      "[27139]\teval-rmse:3.78804\ttrain-rmse:1.95195\n",
      "[27140]\teval-rmse:3.78657\ttrain-rmse:1.95201\n",
      "[27141]\teval-rmse:3.78619\ttrain-rmse:1.95203\n",
      "[27142]\teval-rmse:3.78778\ttrain-rmse:1.95196\n",
      "[27143]\teval-rmse:3.78932\ttrain-rmse:1.9519\n",
      "[27144]\teval-rmse:3.7899\ttrain-rmse:1.95187\n",
      "[27145]\teval-rmse:3.78896\ttrain-rmse:1.95191\n",
      "[27146]\teval-rmse:3.78878\ttrain-rmse:1.95187\n",
      "[27147]\teval-rmse:3.7886\ttrain-rmse:1.95183\n",
      "[27148]\teval-rmse:3.78767\ttrain-rmse:1.95187\n",
      "[27149]\teval-rmse:3.78925\ttrain-rmse:1.95181\n",
      "[27150]\teval-rmse:3.78903\ttrain-rmse:1.95182\n",
      "[27151]\teval-rmse:3.78758\ttrain-rmse:1.95188\n",
      "[27152]\teval-rmse:3.78715\ttrain-rmse:1.95189\n",
      "[27153]\teval-rmse:3.78672\ttrain-rmse:1.95191\n",
      "[27154]\teval-rmse:3.78773\ttrain-rmse:1.95187\n",
      "[27155]\teval-rmse:3.7868\ttrain-rmse:1.95191\n",
      "[27156]\teval-rmse:3.78629\ttrain-rmse:1.95193\n",
      "[27157]\teval-rmse:3.78516\ttrain-rmse:1.952\n",
      "[27158]\teval-rmse:3.78596\ttrain-rmse:1.95196\n",
      "[27159]\teval-rmse:3.78474\ttrain-rmse:1.95202\n",
      "[27160]\teval-rmse:3.78321\ttrain-rmse:1.95209\n",
      "[27161]\teval-rmse:3.78506\ttrain-rmse:1.95199\n",
      "[27162]\teval-rmse:3.78574\ttrain-rmse:1.95197\n",
      "[27163]\teval-rmse:3.78431\ttrain-rmse:1.95204\n",
      "[27164]\teval-rmse:3.78616\ttrain-rmse:1.95194\n",
      "[27165]\teval-rmse:3.7847\ttrain-rmse:1.95202\n",
      "[27166]\teval-rmse:3.78421\ttrain-rmse:1.95205\n",
      "[27167]\teval-rmse:3.78351\ttrain-rmse:1.95209\n",
      "[27168]\teval-rmse:3.78201\ttrain-rmse:1.95217\n",
      "[27169]\teval-rmse:3.78336\ttrain-rmse:1.95209\n",
      "[27170]\teval-rmse:3.78522\ttrain-rmse:1.95199\n",
      "[27171]\teval-rmse:3.7852\ttrain-rmse:1.95199\n",
      "[27172]\teval-rmse:3.78655\ttrain-rmse:1.95192\n",
      "[27173]\teval-rmse:3.78617\ttrain-rmse:1.95194\n",
      "[27174]\teval-rmse:3.78597\ttrain-rmse:1.95195\n",
      "[27175]\teval-rmse:3.78582\ttrain-rmse:1.95196\n",
      "[27176]\teval-rmse:3.78582\ttrain-rmse:1.95196\n",
      "[27177]\teval-rmse:3.78536\ttrain-rmse:1.95198\n",
      "[27178]\teval-rmse:3.78391\ttrain-rmse:1.95206\n",
      "[27179]\teval-rmse:3.782\ttrain-rmse:1.95217\n",
      "[27180]\teval-rmse:3.78199\ttrain-rmse:1.95217\n",
      "[27181]\teval-rmse:3.78339\ttrain-rmse:1.95209\n",
      "[27182]\teval-rmse:3.78221\ttrain-rmse:1.95216\n",
      "[27183]\teval-rmse:3.78251\ttrain-rmse:1.95214\n",
      "[27184]\teval-rmse:3.78277\ttrain-rmse:1.95213\n",
      "[27185]\teval-rmse:3.7828\ttrain-rmse:1.95213\n",
      "[27186]\teval-rmse:3.78303\ttrain-rmse:1.95211\n",
      "[27187]\teval-rmse:3.78459\ttrain-rmse:1.95202\n",
      "[27188]\teval-rmse:3.78389\ttrain-rmse:1.95206\n",
      "[27189]\teval-rmse:3.78248\ttrain-rmse:1.95215\n",
      "[27190]\teval-rmse:3.78273\ttrain-rmse:1.95213\n",
      "[27191]\teval-rmse:3.78263\ttrain-rmse:1.95214\n",
      "[27192]\teval-rmse:3.78325\ttrain-rmse:1.9521\n",
      "[27193]\teval-rmse:3.78462\ttrain-rmse:1.95202\n",
      "[27194]\teval-rmse:3.78416\ttrain-rmse:1.95204\n",
      "[27195]\teval-rmse:3.78448\ttrain-rmse:1.95203\n",
      "[27196]\teval-rmse:3.78406\ttrain-rmse:1.95205\n",
      "[27197]\teval-rmse:3.78562\ttrain-rmse:1.95196\n",
      "[27198]\teval-rmse:3.78612\ttrain-rmse:1.95194\n",
      "[27199]\teval-rmse:3.78773\ttrain-rmse:1.95186\n",
      "[27200]\teval-rmse:3.78652\ttrain-rmse:1.95192\n",
      "[27201]\teval-rmse:3.78712\ttrain-rmse:1.95189\n",
      "[27202]\teval-rmse:3.7867\ttrain-rmse:1.95191\n",
      "[27203]\teval-rmse:3.78699\ttrain-rmse:1.9519\n",
      "[27204]\teval-rmse:3.78827\ttrain-rmse:1.95184\n",
      "[27205]\teval-rmse:3.78784\ttrain-rmse:1.95186\n",
      "[27206]\teval-rmse:3.78737\ttrain-rmse:1.95188\n",
      "[27207]\teval-rmse:3.7879\ttrain-rmse:1.95186\n",
      "[27208]\teval-rmse:3.78902\ttrain-rmse:1.95181\n",
      "[27209]\teval-rmse:3.78958\ttrain-rmse:1.95179\n",
      "[27210]\teval-rmse:3.79038\ttrain-rmse:1.95176\n",
      "[27211]\teval-rmse:3.79192\ttrain-rmse:1.95169\n",
      "[27212]\teval-rmse:3.79139\ttrain-rmse:1.95171\n",
      "[27213]\teval-rmse:3.7922\ttrain-rmse:1.95168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27214]\teval-rmse:3.79197\ttrain-rmse:1.95169\n",
      "[27215]\teval-rmse:3.79174\ttrain-rmse:1.9517\n",
      "[27216]\teval-rmse:3.79256\ttrain-rmse:1.95167\n",
      "[27217]\teval-rmse:3.79303\ttrain-rmse:1.95165\n",
      "[27218]\teval-rmse:3.79428\ttrain-rmse:1.95162\n",
      "[27219]\teval-rmse:3.79462\ttrain-rmse:1.95162\n",
      "[27220]\teval-rmse:3.79365\ttrain-rmse:1.95165\n",
      "[27221]\teval-rmse:3.79268\ttrain-rmse:1.95168\n",
      "[27222]\teval-rmse:3.79147\ttrain-rmse:1.95171\n",
      "[27223]\teval-rmse:3.79127\ttrain-rmse:1.95166\n",
      "[27224]\teval-rmse:3.79125\ttrain-rmse:1.95166\n",
      "[27225]\teval-rmse:3.79263\ttrain-rmse:1.95163\n",
      "[27226]\teval-rmse:3.79181\ttrain-rmse:1.95165\n",
      "[27227]\teval-rmse:3.79064\ttrain-rmse:1.95168\n",
      "[27228]\teval-rmse:3.79015\ttrain-rmse:1.9517\n",
      "[27229]\teval-rmse:3.78971\ttrain-rmse:1.95172\n",
      "[27230]\teval-rmse:3.78949\ttrain-rmse:1.95173\n",
      "[27231]\teval-rmse:3.79093\ttrain-rmse:1.95169\n",
      "[27232]\teval-rmse:3.7902\ttrain-rmse:1.95171\n",
      "[27233]\teval-rmse:3.78946\ttrain-rmse:1.95173\n",
      "[27234]\teval-rmse:3.79097\ttrain-rmse:1.95168\n",
      "[27235]\teval-rmse:3.79117\ttrain-rmse:1.95168\n",
      "[27236]\teval-rmse:3.79104\ttrain-rmse:1.95168\n",
      "[27237]\teval-rmse:3.79088\ttrain-rmse:1.95164\n",
      "[27238]\teval-rmse:3.79111\ttrain-rmse:1.95163\n",
      "[27239]\teval-rmse:3.79235\ttrain-rmse:1.9516\n",
      "[27240]\teval-rmse:3.7926\ttrain-rmse:1.9516\n",
      "[27241]\teval-rmse:3.79318\ttrain-rmse:1.95159\n",
      "[27242]\teval-rmse:3.79502\ttrain-rmse:1.95153\n",
      "[27243]\teval-rmse:3.79482\ttrain-rmse:1.95148\n",
      "[27244]\teval-rmse:3.79605\ttrain-rmse:1.95146\n",
      "[27245]\teval-rmse:3.79589\ttrain-rmse:1.95147\n",
      "[27246]\teval-rmse:3.79465\ttrain-rmse:1.95148\n",
      "[27247]\teval-rmse:3.79494\ttrain-rmse:1.95148\n",
      "[27248]\teval-rmse:3.79375\ttrain-rmse:1.95152\n",
      "[27249]\teval-rmse:3.79431\ttrain-rmse:1.9515\n",
      "[27250]\teval-rmse:3.79385\ttrain-rmse:1.95151\n",
      "[27251]\teval-rmse:3.79384\ttrain-rmse:1.95151\n",
      "[27252]\teval-rmse:3.79287\ttrain-rmse:1.95154\n",
      "[27253]\teval-rmse:3.79263\ttrain-rmse:1.95155\n",
      "[27254]\teval-rmse:3.79421\ttrain-rmse:1.95151\n",
      "[27255]\teval-rmse:3.79275\ttrain-rmse:1.95155\n",
      "[27256]\teval-rmse:3.79259\ttrain-rmse:1.9515\n",
      "[27257]\teval-rmse:3.79288\ttrain-rmse:1.9515\n",
      "[27258]\teval-rmse:3.79451\ttrain-rmse:1.95147\n",
      "[27259]\teval-rmse:3.79613\ttrain-rmse:1.95145\n",
      "[27260]\teval-rmse:3.79772\ttrain-rmse:1.95143\n",
      "[27261]\teval-rmse:3.79722\ttrain-rmse:1.95144\n",
      "[27262]\teval-rmse:3.79798\ttrain-rmse:1.95143\n",
      "[27263]\teval-rmse:3.79646\ttrain-rmse:1.95144\n",
      "[27264]\teval-rmse:3.79499\ttrain-rmse:1.95145\n",
      "[27265]\teval-rmse:3.79444\ttrain-rmse:1.95146\n",
      "[27266]\teval-rmse:3.79468\ttrain-rmse:1.95146\n",
      "[27267]\teval-rmse:3.79444\ttrain-rmse:1.95147\n",
      "[27268]\teval-rmse:3.79347\ttrain-rmse:1.9515\n",
      "[27269]\teval-rmse:3.79304\ttrain-rmse:1.95151\n",
      "[27270]\teval-rmse:3.79128\ttrain-rmse:1.95155\n",
      "[27271]\teval-rmse:3.79187\ttrain-rmse:1.95153\n",
      "[27272]\teval-rmse:3.79311\ttrain-rmse:1.9515\n",
      "[27273]\teval-rmse:3.79215\ttrain-rmse:1.95153\n",
      "[27274]\teval-rmse:3.79347\ttrain-rmse:1.95151\n",
      "[27275]\teval-rmse:3.79223\ttrain-rmse:1.95153\n",
      "[27276]\teval-rmse:3.79243\ttrain-rmse:1.95153\n",
      "[27277]\teval-rmse:3.79198\ttrain-rmse:1.95154\n",
      "[27278]\teval-rmse:3.79223\ttrain-rmse:1.95154\n",
      "[27279]\teval-rmse:3.79148\ttrain-rmse:1.95156\n",
      "[27280]\teval-rmse:3.79022\ttrain-rmse:1.95159\n",
      "[27281]\teval-rmse:3.78948\ttrain-rmse:1.95162\n",
      "[27282]\teval-rmse:3.78831\ttrain-rmse:1.95166\n",
      "[27283]\teval-rmse:3.78758\ttrain-rmse:1.95168\n",
      "[27284]\teval-rmse:3.78715\ttrain-rmse:1.9517\n",
      "[27285]\teval-rmse:3.7854\ttrain-rmse:1.95178\n",
      "[27286]\teval-rmse:3.78676\ttrain-rmse:1.95172\n",
      "[27287]\teval-rmse:3.78724\ttrain-rmse:1.9517\n",
      "[27288]\teval-rmse:3.78826\ttrain-rmse:1.95166\n",
      "[27289]\teval-rmse:3.78876\ttrain-rmse:1.95164\n",
      "[27290]\teval-rmse:3.7873\ttrain-rmse:1.9517\n",
      "[27291]\teval-rmse:3.78881\ttrain-rmse:1.95164\n",
      "[27292]\teval-rmse:3.79016\ttrain-rmse:1.9516\n",
      "[27293]\teval-rmse:3.79106\ttrain-rmse:1.95159\n",
      "[27294]\teval-rmse:3.79186\ttrain-rmse:1.95157\n",
      "[27295]\teval-rmse:3.79244\ttrain-rmse:1.95156\n",
      "[27296]\teval-rmse:3.79345\ttrain-rmse:1.95154\n",
      "[27297]\teval-rmse:3.7919\ttrain-rmse:1.95156\n",
      "[27298]\teval-rmse:3.79167\ttrain-rmse:1.95157\n",
      "[27299]\teval-rmse:3.79025\ttrain-rmse:1.9516\n",
      "[27300]\teval-rmse:3.79176\ttrain-rmse:1.95155\n",
      "[27301]\teval-rmse:3.79055\ttrain-rmse:1.95158\n",
      "[27302]\teval-rmse:3.79213\ttrain-rmse:1.95152\n",
      "[27303]\teval-rmse:3.79242\ttrain-rmse:1.95151\n",
      "[27304]\teval-rmse:3.79227\ttrain-rmse:1.95152\n",
      "[27305]\teval-rmse:3.79152\ttrain-rmse:1.95154\n",
      "[27306]\teval-rmse:3.78987\ttrain-rmse:1.95158\n",
      "[27307]\teval-rmse:3.7915\ttrain-rmse:1.95153\n",
      "[27308]\teval-rmse:3.79136\ttrain-rmse:1.95153\n",
      "[27309]\teval-rmse:3.79192\ttrain-rmse:1.95152\n",
      "[27310]\teval-rmse:3.79245\ttrain-rmse:1.95151\n",
      "[27311]\teval-rmse:3.79122\ttrain-rmse:1.95154\n",
      "[27312]\teval-rmse:3.79232\ttrain-rmse:1.95151\n",
      "[27313]\teval-rmse:3.7929\ttrain-rmse:1.95149\n",
      "[27314]\teval-rmse:3.7944\ttrain-rmse:1.95147\n",
      "[27315]\teval-rmse:3.79566\ttrain-rmse:1.95145\n",
      "[27316]\teval-rmse:3.79723\ttrain-rmse:1.95143\n",
      "[27317]\teval-rmse:3.79679\ttrain-rmse:1.95144\n",
      "[27318]\teval-rmse:3.79842\ttrain-rmse:1.95143\n",
      "[27319]\teval-rmse:3.80004\ttrain-rmse:1.95143\n",
      "[27320]\teval-rmse:3.80157\ttrain-rmse:1.95145\n",
      "[27321]\teval-rmse:3.80154\ttrain-rmse:1.95145\n",
      "[27322]\teval-rmse:3.80306\ttrain-rmse:1.95147\n",
      "[27323]\teval-rmse:3.80287\ttrain-rmse:1.95147\n",
      "[27324]\teval-rmse:3.80362\ttrain-rmse:1.95148\n",
      "[27325]\teval-rmse:3.80259\ttrain-rmse:1.95149\n",
      "[27326]\teval-rmse:3.80231\ttrain-rmse:1.95149\n",
      "[27327]\teval-rmse:3.80208\ttrain-rmse:1.95149\n",
      "[27328]\teval-rmse:3.80338\ttrain-rmse:1.95151\n",
      "[27329]\teval-rmse:3.80418\ttrain-rmse:1.95155\n",
      "[27330]\teval-rmse:3.80533\ttrain-rmse:1.95159\n",
      "[27331]\teval-rmse:3.80658\ttrain-rmse:1.95164\n",
      "[27332]\teval-rmse:3.80522\ttrain-rmse:1.9516\n",
      "[27333]\teval-rmse:3.80574\ttrain-rmse:1.95161\n",
      "[27334]\teval-rmse:3.80516\ttrain-rmse:1.9516\n",
      "[27335]\teval-rmse:3.80677\ttrain-rmse:1.95164\n",
      "[27336]\teval-rmse:3.80624\ttrain-rmse:1.95162\n",
      "[27337]\teval-rmse:3.80636\ttrain-rmse:1.95163\n",
      "[27338]\teval-rmse:3.80792\ttrain-rmse:1.95163\n",
      "[27339]\teval-rmse:3.80736\ttrain-rmse:1.95161\n",
      "[27340]\teval-rmse:3.80892\ttrain-rmse:1.95168\n",
      "[27341]\teval-rmse:3.80786\ttrain-rmse:1.95168\n",
      "[27342]\teval-rmse:3.80765\ttrain-rmse:1.95167\n",
      "[27343]\teval-rmse:3.80787\ttrain-rmse:1.95168\n",
      "[27344]\teval-rmse:3.80757\ttrain-rmse:1.95168\n",
      "[27345]\teval-rmse:3.80703\ttrain-rmse:1.95166\n",
      "[27346]\teval-rmse:3.80746\ttrain-rmse:1.95168\n",
      "[27347]\teval-rmse:3.80615\ttrain-rmse:1.95164\n",
      "[27348]\teval-rmse:3.80511\ttrain-rmse:1.95164\n",
      "[27349]\teval-rmse:3.80486\ttrain-rmse:1.9516\n",
      "[27350]\teval-rmse:3.80636\ttrain-rmse:1.95167\n",
      "[27351]\teval-rmse:3.80616\ttrain-rmse:1.95166\n",
      "[27352]\teval-rmse:3.80563\ttrain-rmse:1.95165\n",
      "[27353]\teval-rmse:3.80746\ttrain-rmse:1.95164\n",
      "[27354]\teval-rmse:3.80896\ttrain-rmse:1.95168\n",
      "[27355]\teval-rmse:3.80869\ttrain-rmse:1.95163\n",
      "[27356]\teval-rmse:3.80919\ttrain-rmse:1.95165\n",
      "[27357]\teval-rmse:3.80755\ttrain-rmse:1.9516\n",
      "[27358]\teval-rmse:3.80591\ttrain-rmse:1.95153\n",
      "[27359]\teval-rmse:3.80543\ttrain-rmse:1.95152\n",
      "[27360]\teval-rmse:3.80589\ttrain-rmse:1.95154\n",
      "[27361]\teval-rmse:3.80564\ttrain-rmse:1.95149\n",
      "[27362]\teval-rmse:3.80424\ttrain-rmse:1.95145\n",
      "[27363]\teval-rmse:3.80417\ttrain-rmse:1.95145\n",
      "[27364]\teval-rmse:3.80547\ttrain-rmse:1.95148\n",
      "[27365]\teval-rmse:3.80677\ttrain-rmse:1.9515\n",
      "[27366]\teval-rmse:3.80656\ttrain-rmse:1.9515\n",
      "[27367]\teval-rmse:3.80524\ttrain-rmse:1.95147\n",
      "[27368]\teval-rmse:3.80523\ttrain-rmse:1.95147\n",
      "[27369]\teval-rmse:3.80706\ttrain-rmse:1.95145\n",
      "[27370]\teval-rmse:3.80784\ttrain-rmse:1.95148\n",
      "[27371]\teval-rmse:3.80776\ttrain-rmse:1.95148\n",
      "[27372]\teval-rmse:3.80746\ttrain-rmse:1.95147\n",
      "[27373]\teval-rmse:3.80761\ttrain-rmse:1.95148\n",
      "[27374]\teval-rmse:3.80655\ttrain-rmse:1.95148\n",
      "[27375]\teval-rmse:3.80528\ttrain-rmse:1.95145\n",
      "[27376]\teval-rmse:3.80449\ttrain-rmse:1.95142\n",
      "[27377]\teval-rmse:3.80392\ttrain-rmse:1.95141\n",
      "[27378]\teval-rmse:3.80542\ttrain-rmse:1.95146\n",
      "[27379]\teval-rmse:3.80556\ttrain-rmse:1.95147\n",
      "[27380]\teval-rmse:3.80684\ttrain-rmse:1.9515\n",
      "[27381]\teval-rmse:3.80676\ttrain-rmse:1.95149\n",
      "[27382]\teval-rmse:3.80548\ttrain-rmse:1.95145\n",
      "[27383]\teval-rmse:3.80488\ttrain-rmse:1.95144\n",
      "[27384]\teval-rmse:3.80641\ttrain-rmse:1.95147\n",
      "[27385]\teval-rmse:3.80456\ttrain-rmse:1.95141\n",
      "[27386]\teval-rmse:3.8064\ttrain-rmse:1.95139\n",
      "[27387]\teval-rmse:3.80477\ttrain-rmse:1.95134\n",
      "[27388]\teval-rmse:3.80373\ttrain-rmse:1.95135\n",
      "[27389]\teval-rmse:3.80392\ttrain-rmse:1.95136\n",
      "[27390]\teval-rmse:3.80517\ttrain-rmse:1.95138\n",
      "[27391]\teval-rmse:3.80514\ttrain-rmse:1.95138\n",
      "[27392]\teval-rmse:3.80675\ttrain-rmse:1.95142\n",
      "[27393]\teval-rmse:3.80669\ttrain-rmse:1.95141\n",
      "[27394]\teval-rmse:3.80716\ttrain-rmse:1.95142\n",
      "[27395]\teval-rmse:3.80741\ttrain-rmse:1.95143\n",
      "[27396]\teval-rmse:3.80715\ttrain-rmse:1.95139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27397]\teval-rmse:3.80826\ttrain-rmse:1.95143\n",
      "[27398]\teval-rmse:3.80663\ttrain-rmse:1.95139\n",
      "[27399]\teval-rmse:3.80638\ttrain-rmse:1.95134\n",
      "[27400]\teval-rmse:3.80533\ttrain-rmse:1.95135\n",
      "[27401]\teval-rmse:3.80402\ttrain-rmse:1.95131\n",
      "[27402]\teval-rmse:3.80355\ttrain-rmse:1.95131\n",
      "[27403]\teval-rmse:3.80508\ttrain-rmse:1.95134\n",
      "[27404]\teval-rmse:3.80404\ttrain-rmse:1.95135\n",
      "[27405]\teval-rmse:3.80375\ttrain-rmse:1.95135\n",
      "[27406]\teval-rmse:3.80528\ttrain-rmse:1.95138\n",
      "[27407]\teval-rmse:3.80401\ttrain-rmse:1.95135\n",
      "[27408]\teval-rmse:3.80585\ttrain-rmse:1.95134\n",
      "[27409]\teval-rmse:3.80714\ttrain-rmse:1.95137\n",
      "[27410]\teval-rmse:3.80684\ttrain-rmse:1.95137\n",
      "[27411]\teval-rmse:3.80529\ttrain-rmse:1.95133\n",
      "[27412]\teval-rmse:3.80504\ttrain-rmse:1.95132\n",
      "[27413]\teval-rmse:3.80444\ttrain-rmse:1.95131\n",
      "[27414]\teval-rmse:3.80387\ttrain-rmse:1.9513\n",
      "[27415]\teval-rmse:3.80571\ttrain-rmse:1.95129\n",
      "[27416]\teval-rmse:3.80676\ttrain-rmse:1.95133\n",
      "[27417]\teval-rmse:3.8051\ttrain-rmse:1.95128\n",
      "[27418]\teval-rmse:3.80344\ttrain-rmse:1.95125\n",
      "[27419]\teval-rmse:3.80214\ttrain-rmse:1.95126\n",
      "[27420]\teval-rmse:3.80054\ttrain-rmse:1.95123\n",
      "[27421]\teval-rmse:3.80211\ttrain-rmse:1.95125\n",
      "[27422]\teval-rmse:3.80257\ttrain-rmse:1.95125\n",
      "[27423]\teval-rmse:3.8023\ttrain-rmse:1.95125\n",
      "[27424]\teval-rmse:3.80414\ttrain-rmse:1.95123\n",
      "[27425]\teval-rmse:3.80389\ttrain-rmse:1.95123\n",
      "[27426]\teval-rmse:3.80368\ttrain-rmse:1.95123\n",
      "[27427]\teval-rmse:3.8049\ttrain-rmse:1.95125\n",
      "[27428]\teval-rmse:3.80442\ttrain-rmse:1.95125\n",
      "[27429]\teval-rmse:3.80545\ttrain-rmse:1.95127\n",
      "[27430]\teval-rmse:3.80515\ttrain-rmse:1.95127\n",
      "[27431]\teval-rmse:3.80571\ttrain-rmse:1.95129\n",
      "[27432]\teval-rmse:3.80541\ttrain-rmse:1.95129\n",
      "[27433]\teval-rmse:3.80693\ttrain-rmse:1.95135\n",
      "[27434]\teval-rmse:3.80823\ttrain-rmse:1.95138\n",
      "[27435]\teval-rmse:3.80877\ttrain-rmse:1.9514\n",
      "[27436]\teval-rmse:3.809\ttrain-rmse:1.95141\n",
      "[27437]\teval-rmse:3.80737\ttrain-rmse:1.95136\n",
      "[27438]\teval-rmse:3.80885\ttrain-rmse:1.95139\n",
      "[27439]\teval-rmse:3.80748\ttrain-rmse:1.95134\n",
      "[27440]\teval-rmse:3.80927\ttrain-rmse:1.95141\n",
      "[27441]\teval-rmse:3.80868\ttrain-rmse:1.9514\n",
      "[27442]\teval-rmse:3.80705\ttrain-rmse:1.95134\n",
      "[27443]\teval-rmse:3.80578\ttrain-rmse:1.95132\n",
      "[27444]\teval-rmse:3.80474\ttrain-rmse:1.95132\n",
      "[27445]\teval-rmse:3.80551\ttrain-rmse:1.95134\n",
      "[27446]\teval-rmse:3.80712\ttrain-rmse:1.95138\n",
      "[27447]\teval-rmse:3.80687\ttrain-rmse:1.95135\n",
      "[27448]\teval-rmse:3.80583\ttrain-rmse:1.95135\n",
      "[27449]\teval-rmse:3.80693\ttrain-rmse:1.95139\n",
      "[27450]\teval-rmse:3.80845\ttrain-rmse:1.95144\n",
      "[27451]\teval-rmse:3.80818\ttrain-rmse:1.95143\n",
      "[27452]\teval-rmse:3.80797\ttrain-rmse:1.95142\n",
      "[27453]\teval-rmse:3.80739\ttrain-rmse:1.9514\n",
      "[27454]\teval-rmse:3.80784\ttrain-rmse:1.95142\n",
      "[27455]\teval-rmse:3.80967\ttrain-rmse:1.95142\n",
      "[27456]\teval-rmse:3.80822\ttrain-rmse:1.95132\n",
      "[27457]\teval-rmse:3.80899\ttrain-rmse:1.95135\n",
      "[27458]\teval-rmse:3.81019\ttrain-rmse:1.95139\n",
      "[27459]\teval-rmse:3.81144\ttrain-rmse:1.95142\n",
      "[27460]\teval-rmse:3.81089\ttrain-rmse:1.9514\n",
      "[27461]\teval-rmse:3.81102\ttrain-rmse:1.95141\n",
      "[27462]\teval-rmse:3.81249\ttrain-rmse:1.95147\n",
      "[27463]\teval-rmse:3.81268\ttrain-rmse:1.95148\n",
      "[27464]\teval-rmse:3.81339\ttrain-rmse:1.9515\n",
      "[27465]\teval-rmse:3.81253\ttrain-rmse:1.95146\n",
      "[27466]\teval-rmse:3.8119\ttrain-rmse:1.95144\n",
      "[27467]\teval-rmse:3.81158\ttrain-rmse:1.95143\n",
      "[27468]\teval-rmse:3.81072\ttrain-rmse:1.9514\n",
      "[27469]\teval-rmse:3.81122\ttrain-rmse:1.95142\n",
      "[27470]\teval-rmse:3.81015\ttrain-rmse:1.95142\n",
      "[27471]\teval-rmse:3.80958\ttrain-rmse:1.9514\n",
      "[27472]\teval-rmse:3.80978\ttrain-rmse:1.95141\n",
      "[27473]\teval-rmse:3.81029\ttrain-rmse:1.95144\n",
      "[27474]\teval-rmse:3.81028\ttrain-rmse:1.95144\n",
      "[27475]\teval-rmse:3.80968\ttrain-rmse:1.95141\n",
      "[27476]\teval-rmse:3.80831\ttrain-rmse:1.95138\n",
      "[27477]\teval-rmse:3.80782\ttrain-rmse:1.95136\n",
      "[27478]\teval-rmse:3.80858\ttrain-rmse:1.95136\n",
      "[27479]\teval-rmse:3.80906\ttrain-rmse:1.95137\n",
      "[27480]\teval-rmse:3.80751\ttrain-rmse:1.95132\n",
      "[27481]\teval-rmse:3.80647\ttrain-rmse:1.95132\n",
      "[27482]\teval-rmse:3.80485\ttrain-rmse:1.95128\n",
      "[27483]\teval-rmse:3.80456\ttrain-rmse:1.95128\n",
      "[27484]\teval-rmse:3.80607\ttrain-rmse:1.95131\n",
      "[27485]\teval-rmse:3.80471\ttrain-rmse:1.95127\n",
      "[27486]\teval-rmse:3.80521\ttrain-rmse:1.95128\n",
      "[27487]\teval-rmse:3.80677\ttrain-rmse:1.95128\n",
      "[27488]\teval-rmse:3.80775\ttrain-rmse:1.95131\n",
      "[27489]\teval-rmse:3.80645\ttrain-rmse:1.95128\n",
      "[27490]\teval-rmse:3.80456\ttrain-rmse:1.95124\n",
      "[27491]\teval-rmse:3.80449\ttrain-rmse:1.95124\n",
      "[27492]\teval-rmse:3.80633\ttrain-rmse:1.95122\n",
      "[27493]\teval-rmse:3.80506\ttrain-rmse:1.95122\n",
      "[27494]\teval-rmse:3.8045\ttrain-rmse:1.95121\n",
      "[27495]\teval-rmse:3.80426\ttrain-rmse:1.95121\n",
      "[27496]\teval-rmse:3.80323\ttrain-rmse:1.95122\n",
      "[27497]\teval-rmse:3.80265\ttrain-rmse:1.95122\n",
      "[27498]\teval-rmse:3.80312\ttrain-rmse:1.95122\n",
      "[27499]\teval-rmse:3.80364\ttrain-rmse:1.95124\n",
      "[27500]\teval-rmse:3.80358\ttrain-rmse:1.95124\n",
      "[27501]\teval-rmse:3.80201\ttrain-rmse:1.9512\n",
      "[27502]\teval-rmse:3.80173\ttrain-rmse:1.95121\n",
      "[27503]\teval-rmse:3.80044\ttrain-rmse:1.95119\n",
      "[27504]\teval-rmse:3.79964\ttrain-rmse:1.95119\n",
      "[27505]\teval-rmse:3.79839\ttrain-rmse:1.95119\n",
      "[27506]\teval-rmse:3.79686\ttrain-rmse:1.9512\n",
      "[27507]\teval-rmse:3.79638\ttrain-rmse:1.9512\n",
      "[27508]\teval-rmse:3.79683\ttrain-rmse:1.9512\n",
      "[27509]\teval-rmse:3.79818\ttrain-rmse:1.95119\n",
      "[27510]\teval-rmse:3.7966\ttrain-rmse:1.9512\n",
      "[27511]\teval-rmse:3.79844\ttrain-rmse:1.95115\n",
      "[27512]\teval-rmse:3.79692\ttrain-rmse:1.95117\n",
      "[27513]\teval-rmse:3.79669\ttrain-rmse:1.95117\n",
      "[27514]\teval-rmse:3.79713\ttrain-rmse:1.95117\n",
      "[27515]\teval-rmse:3.79692\ttrain-rmse:1.95112\n",
      "[27516]\teval-rmse:3.7964\ttrain-rmse:1.95113\n",
      "[27517]\teval-rmse:3.79797\ttrain-rmse:1.95112\n",
      "[27518]\teval-rmse:3.79667\ttrain-rmse:1.95113\n",
      "[27519]\teval-rmse:3.79724\ttrain-rmse:1.95112\n",
      "[27520]\teval-rmse:3.79742\ttrain-rmse:1.95112\n",
      "[27521]\teval-rmse:3.79559\ttrain-rmse:1.95113\n",
      "[27522]\teval-rmse:3.79589\ttrain-rmse:1.95113\n",
      "[27523]\teval-rmse:3.79535\ttrain-rmse:1.95113\n",
      "[27524]\teval-rmse:3.79514\ttrain-rmse:1.95109\n",
      "[27525]\teval-rmse:3.79676\ttrain-rmse:1.95107\n",
      "[27526]\teval-rmse:3.7979\ttrain-rmse:1.95107\n",
      "[27527]\teval-rmse:3.79769\ttrain-rmse:1.95103\n",
      "[27528]\teval-rmse:3.79899\ttrain-rmse:1.95104\n",
      "[27529]\teval-rmse:3.80058\ttrain-rmse:1.95104\n",
      "[27530]\teval-rmse:3.80241\ttrain-rmse:1.95101\n",
      "[27531]\teval-rmse:3.80186\ttrain-rmse:1.95101\n",
      "[27532]\teval-rmse:3.8018\ttrain-rmse:1.95101\n",
      "[27533]\teval-rmse:3.79998\ttrain-rmse:1.951\n",
      "[27534]\teval-rmse:3.80182\ttrain-rmse:1.95097\n",
      "[27535]\teval-rmse:3.80105\ttrain-rmse:1.95097\n",
      "[27536]\teval-rmse:3.80132\ttrain-rmse:1.95097\n",
      "[27537]\teval-rmse:3.79948\ttrain-rmse:1.95096\n",
      "[27538]\teval-rmse:3.79926\ttrain-rmse:1.95097\n",
      "[27539]\teval-rmse:3.79899\ttrain-rmse:1.95097\n",
      "[27540]\teval-rmse:3.79739\ttrain-rmse:1.95098\n",
      "[27541]\teval-rmse:3.79613\ttrain-rmse:1.951\n",
      "[27542]\teval-rmse:3.79763\ttrain-rmse:1.95098\n",
      "[27543]\teval-rmse:3.79842\ttrain-rmse:1.95097\n",
      "[27544]\teval-rmse:3.79901\ttrain-rmse:1.95097\n",
      "[27545]\teval-rmse:3.79848\ttrain-rmse:1.95098\n",
      "[27546]\teval-rmse:3.79722\ttrain-rmse:1.95099\n",
      "[27547]\teval-rmse:3.79801\ttrain-rmse:1.95097\n",
      "[27548]\teval-rmse:3.79924\ttrain-rmse:1.95096\n",
      "[27549]\teval-rmse:3.80086\ttrain-rmse:1.95096\n",
      "[27550]\teval-rmse:3.80216\ttrain-rmse:1.95096\n",
      "[27551]\teval-rmse:3.80193\ttrain-rmse:1.95097\n",
      "[27552]\teval-rmse:3.80066\ttrain-rmse:1.95096\n",
      "[27553]\teval-rmse:3.80194\ttrain-rmse:1.95097\n",
      "[27554]\teval-rmse:3.80355\ttrain-rmse:1.95095\n",
      "[27555]\teval-rmse:3.80411\ttrain-rmse:1.95095\n",
      "[27556]\teval-rmse:3.80594\ttrain-rmse:1.95094\n",
      "[27557]\teval-rmse:3.80512\ttrain-rmse:1.95093\n",
      "[27558]\teval-rmse:3.80357\ttrain-rmse:1.95091\n",
      "[27559]\teval-rmse:3.80306\ttrain-rmse:1.95091\n",
      "[27560]\teval-rmse:3.80433\ttrain-rmse:1.95092\n",
      "[27561]\teval-rmse:3.80274\ttrain-rmse:1.9509\n",
      "[27562]\teval-rmse:3.80121\ttrain-rmse:1.9509\n",
      "[27563]\teval-rmse:3.80249\ttrain-rmse:1.9509\n",
      "[27564]\teval-rmse:3.80116\ttrain-rmse:1.9509\n",
      "[27565]\teval-rmse:3.80115\ttrain-rmse:1.9509\n",
      "[27566]\teval-rmse:3.80168\ttrain-rmse:1.9509\n",
      "[27567]\teval-rmse:3.80221\ttrain-rmse:1.9509\n",
      "[27568]\teval-rmse:3.80193\ttrain-rmse:1.9509\n",
      "[27569]\teval-rmse:3.80346\ttrain-rmse:1.95091\n",
      "[27570]\teval-rmse:3.80344\ttrain-rmse:1.95091\n",
      "[27571]\teval-rmse:3.80211\ttrain-rmse:1.95092\n",
      "[27572]\teval-rmse:3.80258\ttrain-rmse:1.95093\n",
      "[27573]\teval-rmse:3.80091\ttrain-rmse:1.95092\n",
      "[27574]\teval-rmse:3.80136\ttrain-rmse:1.95092\n",
      "[27575]\teval-rmse:3.79969\ttrain-rmse:1.95092\n",
      "[27576]\teval-rmse:3.79868\ttrain-rmse:1.95094\n",
      "[27577]\teval-rmse:3.79992\ttrain-rmse:1.95093\n",
      "[27578]\teval-rmse:3.79842\ttrain-rmse:1.95094\n",
      "[27579]\teval-rmse:3.79794\ttrain-rmse:1.95095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27580]\teval-rmse:3.79744\ttrain-rmse:1.95095\n",
      "[27581]\teval-rmse:3.79723\ttrain-rmse:1.95095\n",
      "[27582]\teval-rmse:3.79885\ttrain-rmse:1.95092\n",
      "[27583]\teval-rmse:3.80013\ttrain-rmse:1.95091\n",
      "[27584]\teval-rmse:3.79833\ttrain-rmse:1.95093\n",
      "[27585]\teval-rmse:3.79733\ttrain-rmse:1.95095\n",
      "[27586]\teval-rmse:3.79656\ttrain-rmse:1.95097\n",
      "[27587]\teval-rmse:3.79507\ttrain-rmse:1.951\n",
      "[27588]\teval-rmse:3.79359\ttrain-rmse:1.95105\n",
      "[27589]\teval-rmse:3.79517\ttrain-rmse:1.95101\n",
      "[27590]\teval-rmse:3.79567\ttrain-rmse:1.95101\n",
      "[27591]\teval-rmse:3.79593\ttrain-rmse:1.951\n",
      "[27592]\teval-rmse:3.79719\ttrain-rmse:1.95098\n",
      "[27593]\teval-rmse:3.79881\ttrain-rmse:1.95097\n",
      "[27594]\teval-rmse:3.79935\ttrain-rmse:1.95096\n",
      "[27595]\teval-rmse:3.80041\ttrain-rmse:1.95095\n",
      "[27596]\teval-rmse:3.80169\ttrain-rmse:1.95094\n",
      "[27597]\teval-rmse:3.80167\ttrain-rmse:1.95094\n",
      "[27598]\teval-rmse:3.80144\ttrain-rmse:1.95094\n",
      "[27599]\teval-rmse:3.80121\ttrain-rmse:1.9509\n",
      "[27600]\teval-rmse:3.80076\ttrain-rmse:1.95091\n",
      "[27601]\teval-rmse:3.80206\ttrain-rmse:1.95091\n",
      "[27602]\teval-rmse:3.80367\ttrain-rmse:1.95089\n",
      "[27603]\teval-rmse:3.80489\ttrain-rmse:1.95091\n",
      "[27604]\teval-rmse:3.80469\ttrain-rmse:1.95091\n",
      "[27605]\teval-rmse:3.80495\ttrain-rmse:1.95091\n",
      "[27606]\teval-rmse:3.80439\ttrain-rmse:1.9509\n",
      "[27607]\teval-rmse:3.80389\ttrain-rmse:1.9509\n",
      "[27608]\teval-rmse:3.80339\ttrain-rmse:1.9509\n",
      "[27609]\teval-rmse:3.80402\ttrain-rmse:1.9509\n",
      "[27610]\teval-rmse:3.80248\ttrain-rmse:1.9509\n",
      "[27611]\teval-rmse:3.80169\ttrain-rmse:1.95089\n",
      "[27612]\teval-rmse:3.80247\ttrain-rmse:1.95088\n",
      "[27613]\teval-rmse:3.80184\ttrain-rmse:1.95089\n",
      "[27614]\teval-rmse:3.80209\ttrain-rmse:1.95088\n",
      "[27615]\teval-rmse:3.80253\ttrain-rmse:1.95088\n",
      "[27616]\teval-rmse:3.80229\ttrain-rmse:1.95083\n",
      "[27617]\teval-rmse:3.80098\ttrain-rmse:1.95084\n",
      "[27618]\teval-rmse:3.79941\ttrain-rmse:1.95084\n",
      "[27619]\teval-rmse:3.79993\ttrain-rmse:1.95084\n",
      "[27620]\teval-rmse:3.79975\ttrain-rmse:1.95084\n",
      "[27621]\teval-rmse:3.80087\ttrain-rmse:1.95084\n",
      "[27622]\teval-rmse:3.80199\ttrain-rmse:1.95083\n",
      "[27623]\teval-rmse:3.80243\ttrain-rmse:1.95083\n",
      "[27624]\teval-rmse:3.80321\ttrain-rmse:1.95084\n",
      "[27625]\teval-rmse:3.80264\ttrain-rmse:1.95083\n",
      "[27626]\teval-rmse:3.80101\ttrain-rmse:1.95083\n",
      "[27627]\teval-rmse:3.80078\ttrain-rmse:1.95083\n",
      "[27628]\teval-rmse:3.80201\ttrain-rmse:1.95083\n",
      "[27629]\teval-rmse:3.80224\ttrain-rmse:1.95083\n",
      "[27630]\teval-rmse:3.80064\ttrain-rmse:1.95082\n",
      "[27631]\teval-rmse:3.79884\ttrain-rmse:1.95084\n",
      "[27632]\teval-rmse:3.79809\ttrain-rmse:1.95084\n",
      "[27633]\teval-rmse:3.79766\ttrain-rmse:1.95085\n",
      "[27634]\teval-rmse:3.79926\ttrain-rmse:1.95084\n",
      "[27635]\teval-rmse:3.79803\ttrain-rmse:1.95086\n",
      "[27636]\teval-rmse:3.79672\ttrain-rmse:1.95087\n",
      "[27637]\teval-rmse:3.79627\ttrain-rmse:1.95088\n",
      "[27638]\teval-rmse:3.7975\ttrain-rmse:1.95086\n",
      "[27639]\teval-rmse:3.79619\ttrain-rmse:1.95089\n",
      "[27640]\teval-rmse:3.79696\ttrain-rmse:1.95088\n",
      "[27641]\teval-rmse:3.79853\ttrain-rmse:1.95087\n",
      "[27642]\teval-rmse:3.79903\ttrain-rmse:1.95087\n",
      "[27643]\teval-rmse:3.80061\ttrain-rmse:1.95086\n",
      "[27644]\teval-rmse:3.80137\ttrain-rmse:1.95086\n",
      "[27645]\teval-rmse:3.8029\ttrain-rmse:1.95087\n",
      "[27646]\teval-rmse:3.80416\ttrain-rmse:1.95088\n",
      "[27647]\teval-rmse:3.80437\ttrain-rmse:1.95089\n",
      "[27648]\teval-rmse:3.80282\ttrain-rmse:1.95087\n",
      "[27649]\teval-rmse:3.80404\ttrain-rmse:1.95088\n",
      "[27650]\teval-rmse:3.80532\ttrain-rmse:1.9509\n",
      "[27651]\teval-rmse:3.80662\ttrain-rmse:1.95092\n",
      "[27652]\teval-rmse:3.80815\ttrain-rmse:1.95095\n",
      "[27653]\teval-rmse:3.80789\ttrain-rmse:1.95091\n",
      "[27654]\teval-rmse:3.80806\ttrain-rmse:1.95091\n",
      "[27655]\teval-rmse:3.80675\ttrain-rmse:1.95088\n",
      "[27656]\teval-rmse:3.8073\ttrain-rmse:1.9509\n",
      "[27657]\teval-rmse:3.80595\ttrain-rmse:1.95087\n",
      "[27658]\teval-rmse:3.80459\ttrain-rmse:1.95084\n",
      "[27659]\teval-rmse:3.80511\ttrain-rmse:1.95085\n",
      "[27660]\teval-rmse:3.80407\ttrain-rmse:1.95086\n",
      "[27661]\teval-rmse:3.80449\ttrain-rmse:1.95086\n",
      "[27662]\teval-rmse:3.80609\ttrain-rmse:1.95089\n",
      "[27663]\teval-rmse:3.80587\ttrain-rmse:1.95089\n",
      "[27664]\teval-rmse:3.80702\ttrain-rmse:1.95092\n",
      "[27665]\teval-rmse:3.80535\ttrain-rmse:1.95089\n",
      "[27666]\teval-rmse:3.80378\ttrain-rmse:1.95086\n",
      "[27667]\teval-rmse:3.804\ttrain-rmse:1.95086\n",
      "[27668]\teval-rmse:3.80375\ttrain-rmse:1.95082\n",
      "[27669]\teval-rmse:3.80242\ttrain-rmse:1.9508\n",
      "[27670]\teval-rmse:3.80088\ttrain-rmse:1.95079\n",
      "[27671]\teval-rmse:3.80035\ttrain-rmse:1.95079\n",
      "[27672]\teval-rmse:3.80019\ttrain-rmse:1.95079\n",
      "[27673]\teval-rmse:3.79893\ttrain-rmse:1.95079\n",
      "[27674]\teval-rmse:3.79735\ttrain-rmse:1.95078\n",
      "[27675]\teval-rmse:3.79897\ttrain-rmse:1.95079\n",
      "[27676]\teval-rmse:3.80012\ttrain-rmse:1.95081\n",
      "[27677]\teval-rmse:3.80141\ttrain-rmse:1.95082\n",
      "[27678]\teval-rmse:3.80013\ttrain-rmse:1.95081\n",
      "[27679]\teval-rmse:3.79913\ttrain-rmse:1.95083\n",
      "[27680]\teval-rmse:3.79894\ttrain-rmse:1.95083\n",
      "[27681]\teval-rmse:3.7995\ttrain-rmse:1.95083\n",
      "[27682]\teval-rmse:3.80002\ttrain-rmse:1.95083\n",
      "[27683]\teval-rmse:3.80049\ttrain-rmse:1.95083\n",
      "[27684]\teval-rmse:3.80001\ttrain-rmse:1.95083\n",
      "[27685]\teval-rmse:3.80113\ttrain-rmse:1.95084\n",
      "[27686]\teval-rmse:3.80273\ttrain-rmse:1.95086\n",
      "[27687]\teval-rmse:3.80249\ttrain-rmse:1.95082\n",
      "[27688]\teval-rmse:3.80222\ttrain-rmse:1.95081\n",
      "[27689]\teval-rmse:3.80269\ttrain-rmse:1.95082\n",
      "[27690]\teval-rmse:3.80369\ttrain-rmse:1.95085\n",
      "[27691]\teval-rmse:3.80344\ttrain-rmse:1.95084\n",
      "[27692]\teval-rmse:3.80241\ttrain-rmse:1.95085\n",
      "[27693]\teval-rmse:3.8008\ttrain-rmse:1.95082\n",
      "[27694]\teval-rmse:3.8021\ttrain-rmse:1.95084\n",
      "[27695]\teval-rmse:3.80085\ttrain-rmse:1.95082\n",
      "[27696]\teval-rmse:3.80221\ttrain-rmse:1.95085\n",
      "[27697]\teval-rmse:3.80066\ttrain-rmse:1.95083\n",
      "[27698]\teval-rmse:3.80224\ttrain-rmse:1.95085\n",
      "[27699]\teval-rmse:3.80196\ttrain-rmse:1.95085\n",
      "[27700]\teval-rmse:3.80243\ttrain-rmse:1.95086\n",
      "[27701]\teval-rmse:3.80162\ttrain-rmse:1.95085\n",
      "[27702]\teval-rmse:3.8031\ttrain-rmse:1.95087\n",
      "[27703]\teval-rmse:3.8033\ttrain-rmse:1.95087\n",
      "[27704]\teval-rmse:3.80373\ttrain-rmse:1.95089\n",
      "[27705]\teval-rmse:3.80217\ttrain-rmse:1.95087\n",
      "[27706]\teval-rmse:3.80377\ttrain-rmse:1.95089\n",
      "[27707]\teval-rmse:3.80453\ttrain-rmse:1.95088\n",
      "[27708]\teval-rmse:3.80366\ttrain-rmse:1.95086\n",
      "[27709]\teval-rmse:3.805\ttrain-rmse:1.95091\n",
      "[27710]\teval-rmse:3.80545\ttrain-rmse:1.95092\n",
      "[27711]\teval-rmse:3.80388\ttrain-rmse:1.95088\n",
      "[27712]\teval-rmse:3.80503\ttrain-rmse:1.95093\n",
      "[27713]\teval-rmse:3.80337\ttrain-rmse:1.9509\n",
      "[27714]\teval-rmse:3.80309\ttrain-rmse:1.9509\n",
      "[27715]\teval-rmse:3.80176\ttrain-rmse:1.95087\n",
      "[27716]\teval-rmse:3.80301\ttrain-rmse:1.95088\n",
      "[27717]\teval-rmse:3.80254\ttrain-rmse:1.95088\n",
      "[27718]\teval-rmse:3.80409\ttrain-rmse:1.95087\n",
      "[27719]\teval-rmse:3.80385\ttrain-rmse:1.95086\n",
      "[27720]\teval-rmse:3.80339\ttrain-rmse:1.95085\n",
      "[27721]\teval-rmse:3.80257\ttrain-rmse:1.95083\n",
      "[27722]\teval-rmse:3.80418\ttrain-rmse:1.95088\n",
      "[27723]\teval-rmse:3.80257\ttrain-rmse:1.95085\n",
      "[27724]\teval-rmse:3.80303\ttrain-rmse:1.95086\n",
      "[27725]\teval-rmse:3.80351\ttrain-rmse:1.95087\n",
      "[27726]\teval-rmse:3.8022\ttrain-rmse:1.95087\n",
      "[27727]\teval-rmse:3.80341\ttrain-rmse:1.95091\n",
      "[27728]\teval-rmse:3.80206\ttrain-rmse:1.95088\n",
      "[27729]\teval-rmse:3.80178\ttrain-rmse:1.95089\n",
      "[27730]\teval-rmse:3.79973\ttrain-rmse:1.95083\n",
      "[27731]\teval-rmse:3.80021\ttrain-rmse:1.95083\n",
      "[27732]\teval-rmse:3.7992\ttrain-rmse:1.95085\n",
      "[27733]\teval-rmse:3.80044\ttrain-rmse:1.95087\n",
      "[27734]\teval-rmse:3.80037\ttrain-rmse:1.95087\n",
      "[27735]\teval-rmse:3.80057\ttrain-rmse:1.95087\n",
      "[27736]\teval-rmse:3.80131\ttrain-rmse:1.95088\n",
      "[27737]\teval-rmse:3.80315\ttrain-rmse:1.95086\n",
      "[27738]\teval-rmse:3.80111\ttrain-rmse:1.95081\n",
      "[27739]\teval-rmse:3.8006\ttrain-rmse:1.95081\n",
      "[27740]\teval-rmse:3.80162\ttrain-rmse:1.95083\n",
      "[27741]\teval-rmse:3.80291\ttrain-rmse:1.95087\n",
      "[27742]\teval-rmse:3.8024\ttrain-rmse:1.95086\n",
      "[27743]\teval-rmse:3.80282\ttrain-rmse:1.95087\n",
      "[27744]\teval-rmse:3.80307\ttrain-rmse:1.95087\n",
      "[27745]\teval-rmse:3.80428\ttrain-rmse:1.95091\n",
      "[27746]\teval-rmse:3.80475\ttrain-rmse:1.95092\n",
      "[27747]\teval-rmse:3.8045\ttrain-rmse:1.95088\n",
      "[27748]\teval-rmse:3.80429\ttrain-rmse:1.95087\n",
      "[27749]\teval-rmse:3.80376\ttrain-rmse:1.95087\n",
      "[27750]\teval-rmse:3.80529\ttrain-rmse:1.9509\n",
      "[27751]\teval-rmse:3.80324\ttrain-rmse:1.95083\n",
      "[27752]\teval-rmse:3.80454\ttrain-rmse:1.95086\n",
      "[27753]\teval-rmse:3.8035\ttrain-rmse:1.95087\n",
      "[27754]\teval-rmse:3.80502\ttrain-rmse:1.95093\n",
      "[27755]\teval-rmse:3.80662\ttrain-rmse:1.95097\n",
      "[27756]\teval-rmse:3.80791\ttrain-rmse:1.95104\n",
      "[27757]\teval-rmse:3.80768\ttrain-rmse:1.95103\n",
      "[27758]\teval-rmse:3.80744\ttrain-rmse:1.95102\n",
      "[27759]\teval-rmse:3.80576\ttrain-rmse:1.95098\n",
      "[27760]\teval-rmse:3.80448\ttrain-rmse:1.95097\n",
      "[27761]\teval-rmse:3.80392\ttrain-rmse:1.95096\n",
      "[27762]\teval-rmse:3.80183\ttrain-rmse:1.95088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27763]\teval-rmse:3.80234\ttrain-rmse:1.9509\n",
      "[27764]\teval-rmse:3.80361\ttrain-rmse:1.95093\n",
      "[27765]\teval-rmse:3.80199\ttrain-rmse:1.95089\n",
      "[27766]\teval-rmse:3.80253\ttrain-rmse:1.9509\n",
      "[27767]\teval-rmse:3.80118\ttrain-rmse:1.95091\n",
      "[27768]\teval-rmse:3.80062\ttrain-rmse:1.9509\n",
      "[27769]\teval-rmse:3.80016\ttrain-rmse:1.95089\n",
      "[27770]\teval-rmse:3.80058\ttrain-rmse:1.95089\n",
      "[27771]\teval-rmse:3.80188\ttrain-rmse:1.95092\n",
      "[27772]\teval-rmse:3.8017\ttrain-rmse:1.95091\n",
      "[27773]\teval-rmse:3.80189\ttrain-rmse:1.95092\n",
      "[27774]\teval-rmse:3.80213\ttrain-rmse:1.95093\n",
      "[27775]\teval-rmse:3.80253\ttrain-rmse:1.95094\n",
      "[27776]\teval-rmse:3.80198\ttrain-rmse:1.95093\n",
      "[27777]\teval-rmse:3.80342\ttrain-rmse:1.95098\n",
      "[27778]\teval-rmse:3.8021\ttrain-rmse:1.95098\n",
      "[27779]\teval-rmse:3.80394\ttrain-rmse:1.95096\n",
      "[27780]\teval-rmse:3.80442\ttrain-rmse:1.95097\n",
      "[27781]\teval-rmse:3.80338\ttrain-rmse:1.95098\n",
      "[27782]\teval-rmse:3.80202\ttrain-rmse:1.95098\n",
      "[27783]\teval-rmse:3.8004\ttrain-rmse:1.95094\n",
      "[27784]\teval-rmse:3.80192\ttrain-rmse:1.95096\n",
      "[27785]\teval-rmse:3.80211\ttrain-rmse:1.95097\n",
      "[27786]\teval-rmse:3.80393\ttrain-rmse:1.95095\n",
      "[27787]\teval-rmse:3.8047\ttrain-rmse:1.95096\n",
      "[27788]\teval-rmse:3.80614\ttrain-rmse:1.95102\n",
      "[27789]\teval-rmse:3.80408\ttrain-rmse:1.95094\n",
      "[27790]\teval-rmse:3.80274\ttrain-rmse:1.95089\n",
      "[27791]\teval-rmse:3.80351\ttrain-rmse:1.95088\n",
      "[27792]\teval-rmse:3.80268\ttrain-rmse:1.95087\n",
      "[27793]\teval-rmse:3.80134\ttrain-rmse:1.95088\n",
      "[27794]\teval-rmse:3.8001\ttrain-rmse:1.95088\n",
      "[27795]\teval-rmse:3.79989\ttrain-rmse:1.95088\n",
      "[27796]\teval-rmse:3.79888\ttrain-rmse:1.9509\n",
      "[27797]\teval-rmse:3.7976\ttrain-rmse:1.95088\n",
      "[27798]\teval-rmse:3.79913\ttrain-rmse:1.95089\n",
      "[27799]\teval-rmse:3.80015\ttrain-rmse:1.95091\n",
      "[27800]\teval-rmse:3.79845\ttrain-rmse:1.95087\n",
      "[27801]\teval-rmse:3.79869\ttrain-rmse:1.95088\n",
      "[27802]\teval-rmse:3.80021\ttrain-rmse:1.95086\n",
      "[27803]\teval-rmse:3.79896\ttrain-rmse:1.95087\n",
      "[27804]\teval-rmse:3.79939\ttrain-rmse:1.95088\n",
      "[27805]\teval-rmse:3.79807\ttrain-rmse:1.95086\n",
      "[27806]\teval-rmse:3.79657\ttrain-rmse:1.95085\n",
      "[27807]\teval-rmse:3.79578\ttrain-rmse:1.95085\n",
      "[27808]\teval-rmse:3.79729\ttrain-rmse:1.95086\n",
      "[27809]\teval-rmse:3.79707\ttrain-rmse:1.95082\n",
      "[27810]\teval-rmse:3.7969\ttrain-rmse:1.95083\n",
      "[27811]\teval-rmse:3.79537\ttrain-rmse:1.95083\n",
      "[27812]\teval-rmse:3.79686\ttrain-rmse:1.95083\n",
      "[27813]\teval-rmse:3.79869\ttrain-rmse:1.95079\n",
      "[27814]\teval-rmse:3.80003\ttrain-rmse:1.95082\n",
      "[27815]\teval-rmse:3.80054\ttrain-rmse:1.95083\n",
      "[27816]\teval-rmse:3.80187\ttrain-rmse:1.95086\n",
      "[27817]\teval-rmse:3.80084\ttrain-rmse:1.95087\n",
      "[27818]\teval-rmse:3.8003\ttrain-rmse:1.95086\n",
      "[27819]\teval-rmse:3.79951\ttrain-rmse:1.95084\n",
      "[27820]\teval-rmse:3.79752\ttrain-rmse:1.95081\n",
      "[27821]\teval-rmse:3.79624\ttrain-rmse:1.95083\n",
      "[27822]\teval-rmse:3.79754\ttrain-rmse:1.95084\n",
      "[27823]\teval-rmse:3.79732\ttrain-rmse:1.9508\n",
      "[27824]\teval-rmse:3.79861\ttrain-rmse:1.95083\n",
      "[27825]\teval-rmse:3.79702\ttrain-rmse:1.9508\n",
      "[27826]\teval-rmse:3.79544\ttrain-rmse:1.95078\n",
      "[27827]\teval-rmse:3.79623\ttrain-rmse:1.95076\n",
      "[27828]\teval-rmse:3.79576\ttrain-rmse:1.95076\n",
      "[27829]\teval-rmse:3.79558\ttrain-rmse:1.95076\n",
      "[27830]\teval-rmse:3.79473\ttrain-rmse:1.95076\n",
      "[27831]\teval-rmse:3.79316\ttrain-rmse:1.95076\n",
      "[27832]\teval-rmse:3.79485\ttrain-rmse:1.95076\n",
      "[27833]\teval-rmse:3.79464\ttrain-rmse:1.95072\n",
      "[27834]\teval-rmse:3.7951\ttrain-rmse:1.95072\n",
      "[27835]\teval-rmse:3.79526\ttrain-rmse:1.95072\n",
      "[27836]\teval-rmse:3.79648\ttrain-rmse:1.95072\n",
      "[27837]\teval-rmse:3.79521\ttrain-rmse:1.95072\n",
      "[27838]\teval-rmse:3.79443\ttrain-rmse:1.95071\n",
      "[27839]\teval-rmse:3.79422\ttrain-rmse:1.95072\n",
      "[27840]\teval-rmse:3.79607\ttrain-rmse:1.95067\n",
      "[27841]\teval-rmse:3.7974\ttrain-rmse:1.95068\n",
      "[27842]\teval-rmse:3.79613\ttrain-rmse:1.95067\n",
      "[27843]\teval-rmse:3.79415\ttrain-rmse:1.95067\n",
      "[27844]\teval-rmse:3.79399\ttrain-rmse:1.95067\n",
      "[27845]\teval-rmse:3.79474\ttrain-rmse:1.95066\n",
      "[27846]\teval-rmse:3.79632\ttrain-rmse:1.95066\n",
      "[27847]\teval-rmse:3.79532\ttrain-rmse:1.95068\n",
      "[27848]\teval-rmse:3.79512\ttrain-rmse:1.95069\n",
      "[27849]\teval-rmse:3.7957\ttrain-rmse:1.95069\n",
      "[27850]\teval-rmse:3.79449\ttrain-rmse:1.95069\n",
      "[27851]\teval-rmse:3.79548\ttrain-rmse:1.95069\n",
      "[27852]\teval-rmse:3.79547\ttrain-rmse:1.95069\n",
      "[27853]\teval-rmse:3.79594\ttrain-rmse:1.95069\n",
      "[27854]\teval-rmse:3.79442\ttrain-rmse:1.95068\n",
      "[27855]\teval-rmse:3.79458\ttrain-rmse:1.95068\n",
      "[27856]\teval-rmse:3.79542\ttrain-rmse:1.95068\n",
      "[27857]\teval-rmse:3.79443\ttrain-rmse:1.95071\n",
      "[27858]\teval-rmse:3.79437\ttrain-rmse:1.95071\n",
      "[27859]\teval-rmse:3.79577\ttrain-rmse:1.95071\n",
      "[27860]\teval-rmse:3.796\ttrain-rmse:1.95071\n",
      "[27861]\teval-rmse:3.79579\ttrain-rmse:1.95068\n",
      "[27862]\teval-rmse:3.79454\ttrain-rmse:1.95067\n",
      "[27863]\teval-rmse:3.7941\ttrain-rmse:1.95068\n",
      "[27864]\teval-rmse:3.79567\ttrain-rmse:1.95068\n",
      "[27865]\teval-rmse:3.79711\ttrain-rmse:1.9507\n",
      "[27866]\teval-rmse:3.79629\ttrain-rmse:1.95069\n",
      "[27867]\teval-rmse:3.79494\ttrain-rmse:1.9507\n",
      "[27868]\teval-rmse:3.79473\ttrain-rmse:1.9507\n",
      "[27869]\teval-rmse:3.79374\ttrain-rmse:1.95072\n",
      "[27870]\teval-rmse:3.79501\ttrain-rmse:1.95073\n",
      "[27871]\teval-rmse:3.79482\ttrain-rmse:1.9507\n",
      "[27872]\teval-rmse:3.79529\ttrain-rmse:1.9507\n",
      "[27873]\teval-rmse:3.79659\ttrain-rmse:1.95071\n",
      "[27874]\teval-rmse:3.79529\ttrain-rmse:1.95069\n",
      "[27875]\teval-rmse:3.79513\ttrain-rmse:1.95069\n",
      "[27876]\teval-rmse:3.79388\ttrain-rmse:1.9507\n",
      "[27877]\teval-rmse:3.79487\ttrain-rmse:1.95071\n",
      "[27878]\teval-rmse:3.79565\ttrain-rmse:1.95071\n",
      "[27879]\teval-rmse:3.79548\ttrain-rmse:1.95071\n",
      "[27880]\teval-rmse:3.796\ttrain-rmse:1.95072\n",
      "[27881]\teval-rmse:3.79652\ttrain-rmse:1.95073\n",
      "[27882]\teval-rmse:3.79809\ttrain-rmse:1.95074\n",
      "[27883]\teval-rmse:3.7979\ttrain-rmse:1.9507\n",
      "[27884]\teval-rmse:3.79836\ttrain-rmse:1.95071\n",
      "[27885]\teval-rmse:3.7988\ttrain-rmse:1.95072\n",
      "[27886]\teval-rmse:3.80031\ttrain-rmse:1.9507\n",
      "[27887]\teval-rmse:3.80081\ttrain-rmse:1.95072\n",
      "[27888]\teval-rmse:3.80099\ttrain-rmse:1.95072\n",
      "[27889]\teval-rmse:3.80228\ttrain-rmse:1.95074\n",
      "[27890]\teval-rmse:3.80411\ttrain-rmse:1.95073\n",
      "[27891]\teval-rmse:3.8028\ttrain-rmse:1.95069\n",
      "[27892]\teval-rmse:3.80303\ttrain-rmse:1.9507\n",
      "[27893]\teval-rmse:3.80428\ttrain-rmse:1.95075\n",
      "[27894]\teval-rmse:3.80384\ttrain-rmse:1.95074\n",
      "[27895]\teval-rmse:3.80518\ttrain-rmse:1.95079\n",
      "[27896]\teval-rmse:3.807\ttrain-rmse:1.95078\n",
      "[27897]\teval-rmse:3.80563\ttrain-rmse:1.95073\n",
      "[27898]\teval-rmse:3.80672\ttrain-rmse:1.95078\n",
      "[27899]\teval-rmse:3.80717\ttrain-rmse:1.9508\n",
      "[27900]\teval-rmse:3.80747\ttrain-rmse:1.95081\n",
      "[27901]\teval-rmse:3.80739\ttrain-rmse:1.95081\n",
      "[27902]\teval-rmse:3.806\ttrain-rmse:1.95079\n",
      "[27903]\teval-rmse:3.80757\ttrain-rmse:1.95087\n",
      "[27904]\teval-rmse:3.80785\ttrain-rmse:1.95088\n",
      "[27905]\teval-rmse:3.80967\ttrain-rmse:1.95089\n",
      "[27906]\teval-rmse:3.80935\ttrain-rmse:1.95088\n",
      "[27907]\teval-rmse:3.81086\ttrain-rmse:1.95095\n",
      "[27908]\teval-rmse:3.81186\ttrain-rmse:1.95102\n",
      "[27909]\teval-rmse:3.81023\ttrain-rmse:1.95093\n",
      "[27910]\teval-rmse:3.81035\ttrain-rmse:1.95094\n",
      "[27911]\teval-rmse:3.80976\ttrain-rmse:1.95092\n",
      "[27912]\teval-rmse:3.8105\ttrain-rmse:1.95092\n",
      "[27913]\teval-rmse:3.8107\ttrain-rmse:1.95094\n",
      "[27914]\teval-rmse:3.81041\ttrain-rmse:1.95092\n",
      "[27915]\teval-rmse:3.80995\ttrain-rmse:1.9509\n",
      "[27916]\teval-rmse:3.80967\ttrain-rmse:1.95087\n",
      "[27917]\teval-rmse:3.81094\ttrain-rmse:1.95093\n",
      "[27918]\teval-rmse:3.81276\ttrain-rmse:1.95095\n",
      "[27919]\teval-rmse:3.81247\ttrain-rmse:1.95093\n",
      "[27920]\teval-rmse:3.81299\ttrain-rmse:1.95097\n",
      "[27921]\teval-rmse:3.81213\ttrain-rmse:1.95091\n",
      "[27922]\teval-rmse:3.81365\ttrain-rmse:1.95099\n",
      "[27923]\teval-rmse:3.81336\ttrain-rmse:1.95098\n",
      "[27924]\teval-rmse:3.81324\ttrain-rmse:1.95097\n",
      "[27925]\teval-rmse:3.81371\ttrain-rmse:1.95099\n",
      "[27926]\teval-rmse:3.81526\ttrain-rmse:1.95103\n",
      "[27927]\teval-rmse:3.816\ttrain-rmse:1.95106\n",
      "[27928]\teval-rmse:3.81781\ttrain-rmse:1.9511\n",
      "[27929]\teval-rmse:3.81909\ttrain-rmse:1.95119\n",
      "[27930]\teval-rmse:3.8177\ttrain-rmse:1.95109\n",
      "[27931]\teval-rmse:3.81895\ttrain-rmse:1.95119\n",
      "[27932]\teval-rmse:3.81728\ttrain-rmse:1.95106\n",
      "[27933]\teval-rmse:3.81774\ttrain-rmse:1.95109\n",
      "[27934]\teval-rmse:3.81635\ttrain-rmse:1.95098\n",
      "[27935]\teval-rmse:3.81471\ttrain-rmse:1.95089\n",
      "[27936]\teval-rmse:3.8162\ttrain-rmse:1.95098\n",
      "[27937]\teval-rmse:3.81591\ttrain-rmse:1.95097\n",
      "[27938]\teval-rmse:3.8148\ttrain-rmse:1.95094\n",
      "[27939]\teval-rmse:3.815\ttrain-rmse:1.95095\n",
      "[27940]\teval-rmse:3.81628\ttrain-rmse:1.95102\n",
      "[27941]\teval-rmse:3.81665\ttrain-rmse:1.95104\n",
      "[27942]\teval-rmse:3.81577\ttrain-rmse:1.95099\n",
      "[27943]\teval-rmse:3.81542\ttrain-rmse:1.95097\n",
      "[27944]\teval-rmse:3.81452\ttrain-rmse:1.95091\n",
      "[27945]\teval-rmse:3.81283\ttrain-rmse:1.95081\n",
      "[27946]\teval-rmse:3.81254\ttrain-rmse:1.95081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27947]\teval-rmse:3.8123\ttrain-rmse:1.9508\n",
      "[27948]\teval-rmse:3.81273\ttrain-rmse:1.95082\n",
      "[27949]\teval-rmse:3.81266\ttrain-rmse:1.95082\n",
      "[27950]\teval-rmse:3.81122\ttrain-rmse:1.95075\n",
      "[27951]\teval-rmse:3.81094\ttrain-rmse:1.95071\n",
      "[27952]\teval-rmse:3.81197\ttrain-rmse:1.95077\n",
      "[27953]\teval-rmse:3.81188\ttrain-rmse:1.95077\n",
      "[27954]\teval-rmse:3.8123\ttrain-rmse:1.95079\n",
      "[27955]\teval-rmse:3.81364\ttrain-rmse:1.95088\n",
      "[27956]\teval-rmse:3.81222\ttrain-rmse:1.95079\n",
      "[27957]\teval-rmse:3.81243\ttrain-rmse:1.9508\n",
      "[27958]\teval-rmse:3.81159\ttrain-rmse:1.95076\n",
      "[27959]\teval-rmse:3.81256\ttrain-rmse:1.95081\n",
      "[27960]\teval-rmse:3.81186\ttrain-rmse:1.95076\n",
      "[27961]\teval-rmse:3.81028\ttrain-rmse:1.95069\n",
      "[27962]\teval-rmse:3.81188\ttrain-rmse:1.95078\n",
      "[27963]\teval-rmse:3.81155\ttrain-rmse:1.95077\n",
      "[27964]\teval-rmse:3.81175\ttrain-rmse:1.95078\n",
      "[27965]\teval-rmse:3.81195\ttrain-rmse:1.95079\n",
      "[27966]\teval-rmse:3.81135\ttrain-rmse:1.95076\n",
      "[27967]\teval-rmse:3.8118\ttrain-rmse:1.95079\n",
      "[27968]\teval-rmse:3.81335\ttrain-rmse:1.95085\n",
      "[27969]\teval-rmse:3.81204\ttrain-rmse:1.95077\n",
      "[27970]\teval-rmse:3.81172\ttrain-rmse:1.95075\n",
      "[27971]\teval-rmse:3.81085\ttrain-rmse:1.95071\n",
      "[27972]\teval-rmse:3.81022\ttrain-rmse:1.95069\n",
      "[27973]\teval-rmse:3.80882\ttrain-rmse:1.95066\n",
      "[27974]\teval-rmse:3.8077\ttrain-rmse:1.95061\n",
      "[27975]\teval-rmse:3.80921\ttrain-rmse:1.95068\n",
      "[27976]\teval-rmse:3.80898\ttrain-rmse:1.95067\n",
      "[27977]\teval-rmse:3.80892\ttrain-rmse:1.95067\n",
      "[27978]\teval-rmse:3.80753\ttrain-rmse:1.95065\n",
      "[27979]\teval-rmse:3.80563\ttrain-rmse:1.95056\n",
      "[27980]\teval-rmse:3.80428\ttrain-rmse:1.95051\n",
      "[27981]\teval-rmse:3.80292\ttrain-rmse:1.95048\n",
      "[27982]\teval-rmse:3.80271\ttrain-rmse:1.95048\n",
      "[27983]\teval-rmse:3.80084\ttrain-rmse:1.95043\n",
      "[27984]\teval-rmse:3.80205\ttrain-rmse:1.95045\n",
      "[27985]\teval-rmse:3.80256\ttrain-rmse:1.95046\n",
      "[27986]\teval-rmse:3.8028\ttrain-rmse:1.95047\n",
      "[27987]\teval-rmse:3.80142\ttrain-rmse:1.95044\n",
      "[27988]\teval-rmse:3.80087\ttrain-rmse:1.95043\n",
      "[27989]\teval-rmse:3.80125\ttrain-rmse:1.95044\n",
      "[27990]\teval-rmse:3.79964\ttrain-rmse:1.95042\n",
      "[27991]\teval-rmse:3.80115\ttrain-rmse:1.9504\n",
      "[27992]\teval-rmse:3.80064\ttrain-rmse:1.95039\n",
      "[27993]\teval-rmse:3.80221\ttrain-rmse:1.95042\n",
      "[27994]\teval-rmse:3.80236\ttrain-rmse:1.95042\n",
      "[27995]\teval-rmse:3.80361\ttrain-rmse:1.95044\n",
      "[27996]\teval-rmse:3.80199\ttrain-rmse:1.9504\n",
      "[27997]\teval-rmse:3.80321\ttrain-rmse:1.95043\n",
      "[27998]\teval-rmse:3.80478\ttrain-rmse:1.95047\n",
      "[27999]\teval-rmse:3.80417\ttrain-rmse:1.95045\n",
      "[28000]\teval-rmse:3.80577\ttrain-rmse:1.95045\n",
      "[28001]\teval-rmse:3.80556\ttrain-rmse:1.95044\n",
      "[28002]\teval-rmse:3.80706\ttrain-rmse:1.95045\n",
      "[28003]\teval-rmse:3.80547\ttrain-rmse:1.95039\n",
      "[28004]\teval-rmse:3.80489\ttrain-rmse:1.95038\n",
      "[28005]\teval-rmse:3.80649\ttrain-rmse:1.95041\n",
      "[28006]\teval-rmse:3.80471\ttrain-rmse:1.95036\n",
      "[28007]\teval-rmse:3.80288\ttrain-rmse:1.95032\n",
      "[28008]\teval-rmse:3.80282\ttrain-rmse:1.95032\n",
      "[28009]\teval-rmse:3.80179\ttrain-rmse:1.95033\n",
      "[28010]\teval-rmse:3.80336\ttrain-rmse:1.95035\n",
      "[28011]\teval-rmse:3.80148\ttrain-rmse:1.95032\n",
      "[28012]\teval-rmse:3.80023\ttrain-rmse:1.9503\n",
      "[28013]\teval-rmse:3.80175\ttrain-rmse:1.95032\n",
      "[28014]\teval-rmse:3.80223\ttrain-rmse:1.95032\n",
      "[28015]\teval-rmse:3.8009\ttrain-rmse:1.95031\n",
      "[28016]\teval-rmse:3.79953\ttrain-rmse:1.9503\n",
      "[28017]\teval-rmse:3.80054\ttrain-rmse:1.95031\n",
      "[28018]\teval-rmse:3.80102\ttrain-rmse:1.95031\n",
      "[28019]\teval-rmse:3.79999\ttrain-rmse:1.95033\n",
      "[28020]\teval-rmse:3.80055\ttrain-rmse:1.95033\n",
      "[28021]\teval-rmse:3.80133\ttrain-rmse:1.95035\n",
      "[28022]\teval-rmse:3.80155\ttrain-rmse:1.95035\n",
      "[28023]\teval-rmse:3.80099\ttrain-rmse:1.95035\n",
      "[28024]\teval-rmse:3.79967\ttrain-rmse:1.95034\n",
      "[28025]\teval-rmse:3.80041\ttrain-rmse:1.95035\n",
      "[28026]\teval-rmse:3.80018\ttrain-rmse:1.95035\n",
      "[28027]\teval-rmse:3.79916\ttrain-rmse:1.95036\n",
      "[28028]\teval-rmse:3.79944\ttrain-rmse:1.95037\n",
      "[28029]\teval-rmse:3.79922\ttrain-rmse:1.95033\n",
      "[28030]\teval-rmse:3.80061\ttrain-rmse:1.95035\n",
      "[28031]\teval-rmse:3.80084\ttrain-rmse:1.95036\n",
      "[28032]\teval-rmse:3.79955\ttrain-rmse:1.95036\n",
      "[28033]\teval-rmse:3.79905\ttrain-rmse:1.95037\n",
      "[28034]\teval-rmse:3.79887\ttrain-rmse:1.95037\n",
      "[28035]\teval-rmse:3.7983\ttrain-rmse:1.95036\n",
      "[28036]\teval-rmse:3.80013\ttrain-rmse:1.95034\n",
      "[28037]\teval-rmse:3.7999\ttrain-rmse:1.9503\n",
      "[28038]\teval-rmse:3.7984\ttrain-rmse:1.95027\n",
      "[28039]\teval-rmse:3.79894\ttrain-rmse:1.95028\n",
      "[28040]\teval-rmse:3.79831\ttrain-rmse:1.95027\n",
      "[28041]\teval-rmse:3.79783\ttrain-rmse:1.95027\n",
      "[28042]\teval-rmse:3.79755\ttrain-rmse:1.95027\n",
      "[28043]\teval-rmse:3.79624\ttrain-rmse:1.95029\n",
      "[28044]\teval-rmse:3.7978\ttrain-rmse:1.95031\n",
      "[28045]\teval-rmse:3.79759\ttrain-rmse:1.95031\n",
      "[28046]\teval-rmse:3.79635\ttrain-rmse:1.95033\n",
      "[28047]\teval-rmse:3.79684\ttrain-rmse:1.95033\n",
      "[28048]\teval-rmse:3.7973\ttrain-rmse:1.95033\n",
      "[28049]\teval-rmse:3.79685\ttrain-rmse:1.95033\n",
      "[28050]\teval-rmse:3.79834\ttrain-rmse:1.95035\n",
      "[28051]\teval-rmse:3.79963\ttrain-rmse:1.95038\n",
      "[28052]\teval-rmse:3.7983\ttrain-rmse:1.95035\n",
      "[28053]\teval-rmse:3.7978\ttrain-rmse:1.95036\n",
      "[28054]\teval-rmse:3.79753\ttrain-rmse:1.95036\n",
      "[28055]\teval-rmse:3.79747\ttrain-rmse:1.95036\n",
      "[28056]\teval-rmse:3.79647\ttrain-rmse:1.95038\n",
      "[28057]\teval-rmse:3.79768\ttrain-rmse:1.95039\n",
      "[28058]\teval-rmse:3.79781\ttrain-rmse:1.9504\n",
      "[28059]\teval-rmse:3.79704\ttrain-rmse:1.95038\n",
      "[28060]\teval-rmse:3.7975\ttrain-rmse:1.95039\n",
      "[28061]\teval-rmse:3.79614\ttrain-rmse:1.95038\n",
      "[28062]\teval-rmse:3.7976\ttrain-rmse:1.9504\n",
      "[28063]\teval-rmse:3.79628\ttrain-rmse:1.95042\n",
      "[28064]\teval-rmse:3.79657\ttrain-rmse:1.95042\n",
      "[28065]\teval-rmse:3.79557\ttrain-rmse:1.95044\n",
      "[28066]\teval-rmse:3.79539\ttrain-rmse:1.95044\n",
      "[28067]\teval-rmse:3.79489\ttrain-rmse:1.95044\n",
      "[28068]\teval-rmse:3.79646\ttrain-rmse:1.95044\n",
      "[28069]\teval-rmse:3.79446\ttrain-rmse:1.95042\n",
      "[28070]\teval-rmse:3.7932\ttrain-rmse:1.95041\n",
      "[28071]\teval-rmse:3.79503\ttrain-rmse:1.95036\n",
      "[28072]\teval-rmse:3.79373\ttrain-rmse:1.95037\n",
      "[28073]\teval-rmse:3.79355\ttrain-rmse:1.95037\n",
      "[28074]\teval-rmse:3.79402\ttrain-rmse:1.95037\n",
      "[28075]\teval-rmse:3.79458\ttrain-rmse:1.95037\n",
      "[28076]\teval-rmse:3.79607\ttrain-rmse:1.95039\n",
      "[28077]\teval-rmse:3.79477\ttrain-rmse:1.95039\n",
      "[28078]\teval-rmse:3.7959\ttrain-rmse:1.9504\n",
      "[28079]\teval-rmse:3.79392\ttrain-rmse:1.95038\n",
      "[28080]\teval-rmse:3.79376\ttrain-rmse:1.95038\n",
      "[28081]\teval-rmse:3.79359\ttrain-rmse:1.95039\n",
      "[28082]\teval-rmse:3.79486\ttrain-rmse:1.9504\n",
      "[28083]\teval-rmse:3.79481\ttrain-rmse:1.95039\n",
      "[28084]\teval-rmse:3.79509\ttrain-rmse:1.9504\n",
      "[28085]\teval-rmse:3.79634\ttrain-rmse:1.9504\n",
      "[28086]\teval-rmse:3.79672\ttrain-rmse:1.95041\n",
      "[28087]\teval-rmse:3.79666\ttrain-rmse:1.9504\n",
      "[28088]\teval-rmse:3.79543\ttrain-rmse:1.95043\n",
      "[28089]\teval-rmse:3.79383\ttrain-rmse:1.95043\n",
      "[28090]\teval-rmse:3.79523\ttrain-rmse:1.95045\n",
      "[28091]\teval-rmse:3.79666\ttrain-rmse:1.95047\n",
      "[28092]\teval-rmse:3.79644\ttrain-rmse:1.95048\n",
      "[28093]\teval-rmse:3.7949\ttrain-rmse:1.95047\n",
      "[28094]\teval-rmse:3.79338\ttrain-rmse:1.95047\n",
      "[28095]\teval-rmse:3.79394\ttrain-rmse:1.95048\n",
      "[28096]\teval-rmse:3.79472\ttrain-rmse:1.95047\n",
      "[28097]\teval-rmse:3.79629\ttrain-rmse:1.95047\n",
      "[28098]\teval-rmse:3.79611\ttrain-rmse:1.95043\n",
      "[28099]\teval-rmse:3.79762\ttrain-rmse:1.95043\n",
      "[28100]\teval-rmse:3.79686\ttrain-rmse:1.95043\n",
      "[28101]\teval-rmse:3.79629\ttrain-rmse:1.95043\n",
      "[28102]\teval-rmse:3.79577\ttrain-rmse:1.95042\n",
      "[28103]\teval-rmse:3.79419\ttrain-rmse:1.9504\n",
      "[28104]\teval-rmse:3.79435\ttrain-rmse:1.9504\n",
      "[28105]\teval-rmse:3.79454\ttrain-rmse:1.9504\n",
      "[28106]\teval-rmse:3.79415\ttrain-rmse:1.95041\n",
      "[28107]\teval-rmse:3.79317\ttrain-rmse:1.95043\n",
      "[28108]\teval-rmse:3.79219\ttrain-rmse:1.95046\n",
      "[28109]\teval-rmse:3.79235\ttrain-rmse:1.95046\n",
      "[28110]\teval-rmse:3.79418\ttrain-rmse:1.95041\n",
      "[28111]\teval-rmse:3.79298\ttrain-rmse:1.9504\n",
      "[28112]\teval-rmse:3.79376\ttrain-rmse:1.9504\n",
      "[28113]\teval-rmse:3.79255\ttrain-rmse:1.95041\n",
      "[28114]\teval-rmse:3.791\ttrain-rmse:1.95043\n",
      "[28115]\teval-rmse:3.79004\ttrain-rmse:1.95046\n",
      "[28116]\teval-rmse:3.79187\ttrain-rmse:1.9504\n",
      "[28117]\teval-rmse:3.79168\ttrain-rmse:1.95041\n",
      "[28118]\teval-rmse:3.79041\ttrain-rmse:1.95042\n",
      "[28119]\teval-rmse:3.79006\ttrain-rmse:1.95042\n",
      "[28120]\teval-rmse:3.78982\ttrain-rmse:1.95043\n",
      "[28121]\teval-rmse:3.79139\ttrain-rmse:1.95043\n",
      "[28122]\teval-rmse:3.79191\ttrain-rmse:1.95042\n",
      "[28123]\teval-rmse:3.79146\ttrain-rmse:1.95043\n",
      "[28124]\teval-rmse:3.793\ttrain-rmse:1.95041\n",
      "[28125]\teval-rmse:3.79176\ttrain-rmse:1.95042\n",
      "[28126]\teval-rmse:3.79162\ttrain-rmse:1.95042\n",
      "[28127]\teval-rmse:3.79043\ttrain-rmse:1.95042\n",
      "[28128]\teval-rmse:3.79025\ttrain-rmse:1.95039\n",
      "[28129]\teval-rmse:3.79078\ttrain-rmse:1.95038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28130]\teval-rmse:3.79016\ttrain-rmse:1.95038\n",
      "[28131]\teval-rmse:3.78863\ttrain-rmse:1.95041\n",
      "[28132]\teval-rmse:3.79046\ttrain-rmse:1.95035\n",
      "[28133]\teval-rmse:3.79098\ttrain-rmse:1.95034\n",
      "[28134]\teval-rmse:3.79002\ttrain-rmse:1.95038\n",
      "[28135]\teval-rmse:3.78847\ttrain-rmse:1.95039\n",
      "[28136]\teval-rmse:3.79\ttrain-rmse:1.95036\n",
      "[28137]\teval-rmse:3.79057\ttrain-rmse:1.95035\n",
      "[28138]\teval-rmse:3.79101\ttrain-rmse:1.95034\n",
      "[28139]\teval-rmse:3.78952\ttrain-rmse:1.95037\n",
      "[28140]\teval-rmse:3.79081\ttrain-rmse:1.95036\n",
      "[28141]\teval-rmse:3.79238\ttrain-rmse:1.95035\n",
      "[28142]\teval-rmse:3.79202\ttrain-rmse:1.95034\n",
      "[28143]\teval-rmse:3.79249\ttrain-rmse:1.95035\n",
      "[28144]\teval-rmse:3.79347\ttrain-rmse:1.95035\n",
      "[28145]\teval-rmse:3.79368\ttrain-rmse:1.95035\n",
      "[28146]\teval-rmse:3.79384\ttrain-rmse:1.95035\n",
      "[28147]\teval-rmse:3.79408\ttrain-rmse:1.95035\n",
      "[28148]\teval-rmse:3.79564\ttrain-rmse:1.95036\n",
      "[28149]\teval-rmse:3.79482\ttrain-rmse:1.95034\n",
      "[28150]\teval-rmse:3.79593\ttrain-rmse:1.95036\n",
      "[28151]\teval-rmse:3.79471\ttrain-rmse:1.95035\n",
      "[28152]\teval-rmse:3.79456\ttrain-rmse:1.95035\n",
      "[28153]\teval-rmse:3.79499\ttrain-rmse:1.95036\n",
      "[28154]\teval-rmse:3.79318\ttrain-rmse:1.95034\n",
      "[28155]\teval-rmse:3.79471\ttrain-rmse:1.95033\n",
      "[28156]\teval-rmse:3.79628\ttrain-rmse:1.95033\n",
      "[28157]\teval-rmse:3.79579\ttrain-rmse:1.95033\n",
      "[28158]\teval-rmse:3.79535\ttrain-rmse:1.95032\n",
      "[28159]\teval-rmse:3.7966\ttrain-rmse:1.95034\n",
      "[28160]\teval-rmse:3.79534\ttrain-rmse:1.95036\n",
      "[28161]\teval-rmse:3.79516\ttrain-rmse:1.95036\n",
      "[28162]\teval-rmse:3.79498\ttrain-rmse:1.95036\n",
      "[28163]\teval-rmse:3.79544\ttrain-rmse:1.95037\n",
      "[28164]\teval-rmse:3.79566\ttrain-rmse:1.95037\n",
      "[28165]\teval-rmse:3.79541\ttrain-rmse:1.95037\n",
      "[28166]\teval-rmse:3.79595\ttrain-rmse:1.95038\n",
      "[28167]\teval-rmse:3.79587\ttrain-rmse:1.95038\n",
      "[28168]\teval-rmse:3.79566\ttrain-rmse:1.95035\n",
      "[28169]\teval-rmse:3.79434\ttrain-rmse:1.95033\n",
      "[28170]\teval-rmse:3.7931\ttrain-rmse:1.95033\n",
      "[28171]\teval-rmse:3.79439\ttrain-rmse:1.95033\n",
      "[28172]\teval-rmse:3.79314\ttrain-rmse:1.95033\n",
      "[28173]\teval-rmse:3.79262\ttrain-rmse:1.95034\n",
      "[28174]\teval-rmse:3.79211\ttrain-rmse:1.95034\n",
      "[28175]\teval-rmse:3.79368\ttrain-rmse:1.95033\n",
      "[28176]\teval-rmse:3.79316\ttrain-rmse:1.95035\n",
      "[28177]\teval-rmse:3.79238\ttrain-rmse:1.95035\n",
      "[28178]\teval-rmse:3.79261\ttrain-rmse:1.95035\n",
      "[28179]\teval-rmse:3.79109\ttrain-rmse:1.95035\n",
      "[28180]\teval-rmse:3.7909\ttrain-rmse:1.95031\n",
      "[28181]\teval-rmse:3.79074\ttrain-rmse:1.95031\n",
      "[28182]\teval-rmse:3.78977\ttrain-rmse:1.95034\n",
      "[28183]\teval-rmse:3.79033\ttrain-rmse:1.95034\n",
      "[28184]\teval-rmse:3.78882\ttrain-rmse:1.95035\n",
      "[28185]\teval-rmse:3.78934\ttrain-rmse:1.95035\n",
      "[28186]\teval-rmse:3.78958\ttrain-rmse:1.95035\n",
      "[28187]\teval-rmse:3.79115\ttrain-rmse:1.95029\n",
      "[28188]\teval-rmse:3.7914\ttrain-rmse:1.95029\n",
      "[28189]\teval-rmse:3.79065\ttrain-rmse:1.95029\n",
      "[28190]\teval-rmse:3.79213\ttrain-rmse:1.95027\n",
      "[28191]\teval-rmse:3.79324\ttrain-rmse:1.95028\n",
      "[28192]\teval-rmse:3.79344\ttrain-rmse:1.95028\n",
      "[28193]\teval-rmse:3.79327\ttrain-rmse:1.95025\n",
      "[28194]\teval-rmse:3.79288\ttrain-rmse:1.95025\n",
      "[28195]\teval-rmse:3.79313\ttrain-rmse:1.95025\n",
      "[28196]\teval-rmse:3.79183\ttrain-rmse:1.95026\n",
      "[28197]\teval-rmse:3.79059\ttrain-rmse:1.95027\n",
      "[28198]\teval-rmse:3.79009\ttrain-rmse:1.95028\n",
      "[28199]\teval-rmse:3.78855\ttrain-rmse:1.9503\n",
      "[28200]\teval-rmse:3.78675\ttrain-rmse:1.95034\n",
      "[28201]\teval-rmse:3.78603\ttrain-rmse:1.95035\n",
      "[28202]\teval-rmse:3.78683\ttrain-rmse:1.95033\n",
      "[28203]\teval-rmse:3.78531\ttrain-rmse:1.95037\n",
      "[28204]\teval-rmse:3.78552\ttrain-rmse:1.95036\n",
      "[28205]\teval-rmse:3.78536\ttrain-rmse:1.95037\n",
      "[28206]\teval-rmse:3.78442\ttrain-rmse:1.95041\n",
      "[28207]\teval-rmse:3.78626\ttrain-rmse:1.95033\n",
      "[28208]\teval-rmse:3.78497\ttrain-rmse:1.95037\n",
      "[28209]\teval-rmse:3.78424\ttrain-rmse:1.95039\n",
      "[28210]\teval-rmse:3.78559\ttrain-rmse:1.95035\n",
      "[28211]\teval-rmse:3.78605\ttrain-rmse:1.95033\n",
      "[28212]\teval-rmse:3.78459\ttrain-rmse:1.95038\n",
      "[28213]\teval-rmse:3.78507\ttrain-rmse:1.95036\n",
      "[28214]\teval-rmse:3.78661\ttrain-rmse:1.95032\n",
      "[28215]\teval-rmse:3.78568\ttrain-rmse:1.95036\n",
      "[28216]\teval-rmse:3.78725\ttrain-rmse:1.95029\n",
      "[28217]\teval-rmse:3.78723\ttrain-rmse:1.95029\n",
      "[28218]\teval-rmse:3.78805\ttrain-rmse:1.95027\n",
      "[28219]\teval-rmse:3.78858\ttrain-rmse:1.95027\n",
      "[28220]\teval-rmse:3.78876\ttrain-rmse:1.95027\n",
      "[28221]\teval-rmse:3.7906\ttrain-rmse:1.9502\n",
      "[28222]\teval-rmse:3.7901\ttrain-rmse:1.9502\n",
      "[28223]\teval-rmse:3.79164\ttrain-rmse:1.95018\n",
      "[28224]\teval-rmse:3.79286\ttrain-rmse:1.95017\n",
      "[28225]\teval-rmse:3.79313\ttrain-rmse:1.95017\n",
      "[28226]\teval-rmse:3.79439\ttrain-rmse:1.95016\n",
      "[28227]\teval-rmse:3.79291\ttrain-rmse:1.95016\n",
      "[28228]\teval-rmse:3.7932\ttrain-rmse:1.95016\n",
      "[28229]\teval-rmse:3.79474\ttrain-rmse:1.95015\n",
      "[28230]\teval-rmse:3.79516\ttrain-rmse:1.95015\n",
      "[28231]\teval-rmse:3.7946\ttrain-rmse:1.95015\n",
      "[28232]\teval-rmse:3.79585\ttrain-rmse:1.95017\n",
      "[28233]\teval-rmse:3.79618\ttrain-rmse:1.95017\n",
      "[28234]\teval-rmse:3.7954\ttrain-rmse:1.95017\n",
      "[28235]\teval-rmse:3.79653\ttrain-rmse:1.95019\n",
      "[28236]\teval-rmse:3.796\ttrain-rmse:1.9502\n",
      "[28237]\teval-rmse:3.79642\ttrain-rmse:1.9502\n",
      "[28238]\teval-rmse:3.79589\ttrain-rmse:1.95021\n",
      "[28239]\teval-rmse:3.7967\ttrain-rmse:1.95022\n",
      "[28240]\teval-rmse:3.79586\ttrain-rmse:1.9502\n",
      "[28241]\teval-rmse:3.79565\ttrain-rmse:1.9502\n",
      "[28242]\teval-rmse:3.79518\ttrain-rmse:1.9502\n",
      "[28243]\teval-rmse:3.79348\ttrain-rmse:1.95018\n",
      "[28244]\teval-rmse:3.79426\ttrain-rmse:1.95018\n",
      "[28245]\teval-rmse:3.7958\ttrain-rmse:1.95019\n",
      "[28246]\teval-rmse:3.79559\ttrain-rmse:1.95015\n",
      "[28247]\teval-rmse:3.79534\ttrain-rmse:1.95015\n",
      "[28248]\teval-rmse:3.79478\ttrain-rmse:1.95015\n",
      "[28249]\teval-rmse:3.79601\ttrain-rmse:1.95016\n",
      "[28250]\teval-rmse:3.79758\ttrain-rmse:1.9502\n",
      "[28251]\teval-rmse:3.79878\ttrain-rmse:1.95023\n",
      "[28252]\teval-rmse:3.80031\ttrain-rmse:1.95026\n",
      "[28253]\teval-rmse:3.79877\ttrain-rmse:1.95024\n",
      "[28254]\teval-rmse:3.79822\ttrain-rmse:1.95023\n",
      "[28255]\teval-rmse:3.79662\ttrain-rmse:1.95019\n",
      "[28256]\teval-rmse:3.795\ttrain-rmse:1.95018\n",
      "[28257]\teval-rmse:3.79514\ttrain-rmse:1.95019\n",
      "[28258]\teval-rmse:3.79462\ttrain-rmse:1.95018\n",
      "[28259]\teval-rmse:3.7954\ttrain-rmse:1.95016\n",
      "[28260]\teval-rmse:3.795\ttrain-rmse:1.95016\n",
      "[28261]\teval-rmse:3.79546\ttrain-rmse:1.95017\n",
      "[28262]\teval-rmse:3.79447\ttrain-rmse:1.95019\n",
      "[28263]\teval-rmse:3.79427\ttrain-rmse:1.95019\n",
      "[28264]\teval-rmse:3.79481\ttrain-rmse:1.9502\n",
      "[28265]\teval-rmse:3.79347\ttrain-rmse:1.95019\n",
      "[28266]\teval-rmse:3.79327\ttrain-rmse:1.95019\n",
      "[28267]\teval-rmse:3.79174\ttrain-rmse:1.95018\n",
      "[28268]\teval-rmse:3.79195\ttrain-rmse:1.95018\n",
      "[28269]\teval-rmse:3.79113\ttrain-rmse:1.95018\n",
      "[28270]\teval-rmse:3.78964\ttrain-rmse:1.95019\n",
      "[28271]\teval-rmse:3.78999\ttrain-rmse:1.95019\n",
      "[28272]\teval-rmse:3.78948\ttrain-rmse:1.95021\n",
      "[28273]\teval-rmse:3.78826\ttrain-rmse:1.95023\n",
      "[28274]\teval-rmse:3.78781\ttrain-rmse:1.95025\n",
      "[28275]\teval-rmse:3.78903\ttrain-rmse:1.95023\n",
      "[28276]\teval-rmse:3.78926\ttrain-rmse:1.95023\n",
      "[28277]\teval-rmse:3.7904\ttrain-rmse:1.95023\n",
      "[28278]\teval-rmse:3.79016\ttrain-rmse:1.95023\n",
      "[28279]\teval-rmse:3.79094\ttrain-rmse:1.95023\n",
      "[28280]\teval-rmse:3.78943\ttrain-rmse:1.95023\n",
      "[28281]\teval-rmse:3.78789\ttrain-rmse:1.95025\n",
      "[28282]\teval-rmse:3.78595\ttrain-rmse:1.95027\n",
      "[28283]\teval-rmse:3.7844\ttrain-rmse:1.95032\n",
      "[28284]\teval-rmse:3.78486\ttrain-rmse:1.9503\n",
      "[28285]\teval-rmse:3.78443\ttrain-rmse:1.95032\n",
      "[28286]\teval-rmse:3.78429\ttrain-rmse:1.95029\n",
      "[28287]\teval-rmse:3.78584\ttrain-rmse:1.95024\n",
      "[28288]\teval-rmse:3.78489\ttrain-rmse:1.95028\n",
      "[28289]\teval-rmse:3.78367\ttrain-rmse:1.95031\n",
      "[28290]\teval-rmse:3.78444\ttrain-rmse:1.95029\n",
      "[28291]\teval-rmse:3.78267\ttrain-rmse:1.95035\n",
      "[28292]\teval-rmse:3.7845\ttrain-rmse:1.95026\n",
      "[28293]\teval-rmse:3.78576\ttrain-rmse:1.95022\n",
      "[28294]\teval-rmse:3.7876\ttrain-rmse:1.95014\n",
      "[28295]\teval-rmse:3.78608\ttrain-rmse:1.95017\n",
      "[28296]\teval-rmse:3.78484\ttrain-rmse:1.95021\n",
      "[28297]\teval-rmse:3.78391\ttrain-rmse:1.95025\n",
      "[28298]\teval-rmse:3.78347\ttrain-rmse:1.95026\n",
      "[28299]\teval-rmse:3.78299\ttrain-rmse:1.95028\n",
      "[28300]\teval-rmse:3.78262\ttrain-rmse:1.9503\n",
      "[28301]\teval-rmse:3.78138\ttrain-rmse:1.95035\n",
      "[28302]\teval-rmse:3.78184\ttrain-rmse:1.95033\n",
      "[28303]\teval-rmse:3.77989\ttrain-rmse:1.9504\n",
      "[28304]\teval-rmse:3.78048\ttrain-rmse:1.95038\n",
      "[28305]\teval-rmse:3.78126\ttrain-rmse:1.95034\n",
      "[28306]\teval-rmse:3.78106\ttrain-rmse:1.95035\n",
      "[28307]\teval-rmse:3.78263\ttrain-rmse:1.95029\n",
      "[28308]\teval-rmse:3.78309\ttrain-rmse:1.95028\n",
      "[28309]\teval-rmse:3.7839\ttrain-rmse:1.95025\n",
      "[28310]\teval-rmse:3.78248\ttrain-rmse:1.95029\n",
      "[28311]\teval-rmse:3.78233\ttrain-rmse:1.95026\n",
      "[28312]\teval-rmse:3.78083\ttrain-rmse:1.95032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28313]\teval-rmse:3.78267\ttrain-rmse:1.95023\n",
      "[28314]\teval-rmse:3.7842\ttrain-rmse:1.95017\n",
      "[28315]\teval-rmse:3.78544\ttrain-rmse:1.95012\n",
      "[28316]\teval-rmse:3.7839\ttrain-rmse:1.95018\n",
      "[28317]\teval-rmse:3.78531\ttrain-rmse:1.95013\n",
      "[28318]\teval-rmse:3.78406\ttrain-rmse:1.95018\n",
      "[28319]\teval-rmse:3.78257\ttrain-rmse:1.95024\n",
      "[28320]\teval-rmse:3.78276\ttrain-rmse:1.95023\n",
      "[28321]\teval-rmse:3.78407\ttrain-rmse:1.95018\n",
      "[28322]\teval-rmse:3.78459\ttrain-rmse:1.95016\n",
      "[28323]\teval-rmse:3.78611\ttrain-rmse:1.95011\n",
      "[28324]\teval-rmse:3.78632\ttrain-rmse:1.95011\n",
      "[28325]\teval-rmse:3.78507\ttrain-rmse:1.95015\n",
      "[28326]\teval-rmse:3.78391\ttrain-rmse:1.95019\n",
      "[28327]\teval-rmse:3.78544\ttrain-rmse:1.95013\n",
      "[28328]\teval-rmse:3.78559\ttrain-rmse:1.95013\n",
      "[28329]\teval-rmse:3.78583\ttrain-rmse:1.95012\n",
      "[28330]\teval-rmse:3.78467\ttrain-rmse:1.95016\n",
      "[28331]\teval-rmse:3.78445\ttrain-rmse:1.95017\n",
      "[28332]\teval-rmse:3.78398\ttrain-rmse:1.95018\n",
      "[28333]\teval-rmse:3.78425\ttrain-rmse:1.95017\n",
      "[28334]\teval-rmse:3.78352\ttrain-rmse:1.9502\n",
      "[28335]\teval-rmse:3.78463\ttrain-rmse:1.95017\n",
      "[28336]\teval-rmse:3.78319\ttrain-rmse:1.95022\n",
      "[28337]\teval-rmse:3.78344\ttrain-rmse:1.95022\n",
      "[28338]\teval-rmse:3.78425\ttrain-rmse:1.95017\n",
      "[28339]\teval-rmse:3.78578\ttrain-rmse:1.95012\n",
      "[28340]\teval-rmse:3.78561\ttrain-rmse:1.95013\n",
      "[28341]\teval-rmse:3.78407\ttrain-rmse:1.95018\n",
      "[28342]\teval-rmse:3.78454\ttrain-rmse:1.95016\n",
      "[28343]\teval-rmse:3.78281\ttrain-rmse:1.95022\n",
      "[28344]\teval-rmse:3.78188\ttrain-rmse:1.95027\n",
      "[28345]\teval-rmse:3.78074\ttrain-rmse:1.95032\n",
      "[28346]\teval-rmse:3.78031\ttrain-rmse:1.95034\n",
      "[28347]\teval-rmse:3.78215\ttrain-rmse:1.95024\n",
      "[28348]\teval-rmse:3.78169\ttrain-rmse:1.95026\n",
      "[28349]\teval-rmse:3.7819\ttrain-rmse:1.95025\n",
      "[28350]\teval-rmse:3.78322\ttrain-rmse:1.95019\n",
      "[28351]\teval-rmse:3.78281\ttrain-rmse:1.95021\n",
      "[28352]\teval-rmse:3.78382\ttrain-rmse:1.95017\n",
      "[28353]\teval-rmse:3.78367\ttrain-rmse:1.95018\n",
      "[28354]\teval-rmse:3.7839\ttrain-rmse:1.95017\n",
      "[28355]\teval-rmse:3.78275\ttrain-rmse:1.95022\n",
      "[28356]\teval-rmse:3.78238\ttrain-rmse:1.95024\n",
      "[28357]\teval-rmse:3.78146\ttrain-rmse:1.95028\n",
      "[28358]\teval-rmse:3.78307\ttrain-rmse:1.95022\n",
      "[28359]\teval-rmse:3.78269\ttrain-rmse:1.95023\n",
      "[28360]\teval-rmse:3.78402\ttrain-rmse:1.95018\n",
      "[28361]\teval-rmse:3.78564\ttrain-rmse:1.9501\n",
      "[28362]\teval-rmse:3.78412\ttrain-rmse:1.95016\n",
      "[28363]\teval-rmse:3.78471\ttrain-rmse:1.95013\n",
      "[28364]\teval-rmse:3.78322\ttrain-rmse:1.95019\n",
      "[28365]\teval-rmse:3.78284\ttrain-rmse:1.95021\n",
      "[28366]\teval-rmse:3.78362\ttrain-rmse:1.95018\n",
      "[28367]\teval-rmse:3.78521\ttrain-rmse:1.95012\n",
      "[28368]\teval-rmse:3.78474\ttrain-rmse:1.95013\n",
      "[28369]\teval-rmse:3.78321\ttrain-rmse:1.95019\n",
      "[28370]\teval-rmse:3.78352\ttrain-rmse:1.95019\n",
      "[28371]\teval-rmse:3.78331\ttrain-rmse:1.95019\n",
      "[28372]\teval-rmse:3.78515\ttrain-rmse:1.95011\n",
      "[28373]\teval-rmse:3.78515\ttrain-rmse:1.95011\n",
      "[28374]\teval-rmse:3.78502\ttrain-rmse:1.95011\n",
      "[28375]\teval-rmse:3.78523\ttrain-rmse:1.95011\n",
      "[28376]\teval-rmse:3.78506\ttrain-rmse:1.95007\n",
      "[28377]\teval-rmse:3.78541\ttrain-rmse:1.95006\n",
      "[28378]\teval-rmse:3.78494\ttrain-rmse:1.95008\n",
      "[28379]\teval-rmse:3.78522\ttrain-rmse:1.95007\n",
      "[28380]\teval-rmse:3.78428\ttrain-rmse:1.95011\n",
      "[28381]\teval-rmse:3.7831\ttrain-rmse:1.95016\n",
      "[28382]\teval-rmse:3.78189\ttrain-rmse:1.95021\n",
      "[28383]\teval-rmse:3.78217\ttrain-rmse:1.9502\n",
      "[28384]\teval-rmse:3.78172\ttrain-rmse:1.95022\n",
      "[28385]\teval-rmse:3.78051\ttrain-rmse:1.95027\n",
      "[28386]\teval-rmse:3.78015\ttrain-rmse:1.95029\n",
      "[28387]\teval-rmse:3.78138\ttrain-rmse:1.95024\n",
      "[28388]\teval-rmse:3.7809\ttrain-rmse:1.95026\n",
      "[28389]\teval-rmse:3.78125\ttrain-rmse:1.95025\n",
      "[28390]\teval-rmse:3.78287\ttrain-rmse:1.95017\n",
      "[28391]\teval-rmse:3.78163\ttrain-rmse:1.95022\n",
      "[28392]\teval-rmse:3.78143\ttrain-rmse:1.95023\n",
      "[28393]\teval-rmse:3.78189\ttrain-rmse:1.95021\n",
      "[28394]\teval-rmse:3.78042\ttrain-rmse:1.95028\n",
      "[28395]\teval-rmse:3.77868\ttrain-rmse:1.95037\n",
      "[28396]\teval-rmse:3.78\ttrain-rmse:1.9503\n",
      "[28397]\teval-rmse:3.78134\ttrain-rmse:1.95023\n",
      "[28398]\teval-rmse:3.78269\ttrain-rmse:1.95017\n",
      "[28399]\teval-rmse:3.78395\ttrain-rmse:1.95013\n",
      "[28400]\teval-rmse:3.78553\ttrain-rmse:1.95008\n",
      "[28401]\teval-rmse:3.78579\ttrain-rmse:1.95007\n",
      "[28402]\teval-rmse:3.78693\ttrain-rmse:1.95006\n",
      "[28403]\teval-rmse:3.78773\ttrain-rmse:1.95003\n",
      "[28404]\teval-rmse:3.78853\ttrain-rmse:1.95001\n",
      "[28405]\teval-rmse:3.78932\ttrain-rmse:1.95\n",
      "[28406]\teval-rmse:3.78917\ttrain-rmse:1.95\n",
      "[28407]\teval-rmse:3.78868\ttrain-rmse:1.95002\n",
      "[28408]\teval-rmse:3.78818\ttrain-rmse:1.95003\n",
      "[28409]\teval-rmse:3.787\ttrain-rmse:1.95005\n",
      "[28410]\teval-rmse:3.78857\ttrain-rmse:1.95003\n",
      "[28411]\teval-rmse:3.79005\ttrain-rmse:1.95\n",
      "[28412]\teval-rmse:3.79166\ttrain-rmse:1.94994\n",
      "[28413]\teval-rmse:3.7902\ttrain-rmse:1.94995\n",
      "[28414]\teval-rmse:3.79019\ttrain-rmse:1.94995\n",
      "[28415]\teval-rmse:3.79\ttrain-rmse:1.94996\n",
      "[28416]\teval-rmse:3.79018\ttrain-rmse:1.94996\n",
      "[28417]\teval-rmse:3.78999\ttrain-rmse:1.94996\n",
      "[28418]\teval-rmse:3.79029\ttrain-rmse:1.94996\n",
      "[28419]\teval-rmse:3.78989\ttrain-rmse:1.94996\n",
      "[28420]\teval-rmse:3.79146\ttrain-rmse:1.94996\n",
      "[28421]\teval-rmse:3.79195\ttrain-rmse:1.94995\n",
      "[28422]\teval-rmse:3.79214\ttrain-rmse:1.94995\n",
      "[28423]\teval-rmse:3.79254\ttrain-rmse:1.94995\n",
      "[28424]\teval-rmse:3.79248\ttrain-rmse:1.94995\n",
      "[28425]\teval-rmse:3.79089\ttrain-rmse:1.94995\n",
      "[28426]\teval-rmse:3.78971\ttrain-rmse:1.94996\n",
      "[28427]\teval-rmse:3.79025\ttrain-rmse:1.94995\n",
      "[28428]\teval-rmse:3.78978\ttrain-rmse:1.94996\n",
      "[28429]\teval-rmse:3.78856\ttrain-rmse:1.94999\n",
      "[28430]\teval-rmse:3.78701\ttrain-rmse:1.95002\n",
      "[28431]\teval-rmse:3.78747\ttrain-rmse:1.95\n",
      "[28432]\teval-rmse:3.78869\ttrain-rmse:1.94998\n",
      "[28433]\teval-rmse:3.78851\ttrain-rmse:1.94998\n",
      "[28434]\teval-rmse:3.78869\ttrain-rmse:1.94998\n",
      "[28435]\teval-rmse:3.79053\ttrain-rmse:1.94992\n",
      "[28436]\teval-rmse:3.79077\ttrain-rmse:1.94991\n",
      "[28437]\teval-rmse:3.78957\ttrain-rmse:1.94993\n",
      "[28438]\teval-rmse:3.78933\ttrain-rmse:1.94994\n",
      "[28439]\teval-rmse:3.78894\ttrain-rmse:1.94995\n",
      "[28440]\teval-rmse:3.79046\ttrain-rmse:1.94992\n",
      "[28441]\teval-rmse:3.79177\ttrain-rmse:1.9499\n",
      "[28442]\teval-rmse:3.79157\ttrain-rmse:1.94991\n",
      "[28443]\teval-rmse:3.79031\ttrain-rmse:1.94992\n",
      "[28444]\teval-rmse:3.79184\ttrain-rmse:1.94987\n",
      "[28445]\teval-rmse:3.79055\ttrain-rmse:1.94989\n",
      "[28446]\teval-rmse:3.79238\ttrain-rmse:1.94983\n",
      "[28447]\teval-rmse:3.79107\ttrain-rmse:1.94985\n",
      "[28448]\teval-rmse:3.79236\ttrain-rmse:1.94983\n",
      "[28449]\teval-rmse:3.79217\ttrain-rmse:1.94984\n",
      "[28450]\teval-rmse:3.79198\ttrain-rmse:1.9498\n",
      "[28451]\teval-rmse:3.79249\ttrain-rmse:1.94979\n",
      "[28452]\teval-rmse:3.79229\ttrain-rmse:1.94979\n",
      "[28453]\teval-rmse:3.79256\ttrain-rmse:1.94979\n",
      "[28454]\teval-rmse:3.79088\ttrain-rmse:1.94981\n",
      "[28455]\teval-rmse:3.78934\ttrain-rmse:1.94984\n",
      "[28456]\teval-rmse:3.78816\ttrain-rmse:1.94987\n",
      "[28457]\teval-rmse:3.78928\ttrain-rmse:1.94984\n",
      "[28458]\teval-rmse:3.7891\ttrain-rmse:1.94985\n",
      "[28459]\teval-rmse:3.78864\ttrain-rmse:1.94986\n",
      "[28460]\teval-rmse:3.79047\ttrain-rmse:1.9498\n",
      "[28461]\teval-rmse:3.78998\ttrain-rmse:1.94982\n",
      "[28462]\teval-rmse:3.78899\ttrain-rmse:1.94984\n",
      "[28463]\teval-rmse:3.78775\ttrain-rmse:1.94988\n",
      "[28464]\teval-rmse:3.78735\ttrain-rmse:1.94989\n",
      "[28465]\teval-rmse:3.78816\ttrain-rmse:1.94986\n",
      "[28466]\teval-rmse:3.78668\ttrain-rmse:1.94991\n",
      "[28467]\teval-rmse:3.78722\ttrain-rmse:1.94989\n",
      "[28468]\teval-rmse:3.78603\ttrain-rmse:1.94993\n",
      "[28469]\teval-rmse:3.78761\ttrain-rmse:1.94988\n",
      "[28470]\teval-rmse:3.78813\ttrain-rmse:1.94987\n",
      "[28471]\teval-rmse:3.7894\ttrain-rmse:1.94983\n",
      "[28472]\teval-rmse:3.78844\ttrain-rmse:1.94987\n",
      "[28473]\teval-rmse:3.79005\ttrain-rmse:1.94981\n",
      "[28474]\teval-rmse:3.79085\ttrain-rmse:1.94978\n",
      "[28475]\teval-rmse:3.79067\ttrain-rmse:1.94978\n",
      "[28476]\teval-rmse:3.79096\ttrain-rmse:1.94978\n",
      "[28477]\teval-rmse:3.78949\ttrain-rmse:1.94981\n",
      "[28478]\teval-rmse:3.79079\ttrain-rmse:1.94978\n",
      "[28479]\teval-rmse:3.78951\ttrain-rmse:1.94981\n",
      "[28480]\teval-rmse:3.79135\ttrain-rmse:1.94975\n",
      "[28481]\teval-rmse:3.79119\ttrain-rmse:1.94975\n",
      "[28482]\teval-rmse:3.79144\ttrain-rmse:1.94975\n",
      "[28483]\teval-rmse:3.79176\ttrain-rmse:1.94974\n",
      "[28484]\teval-rmse:3.79009\ttrain-rmse:1.94978\n",
      "[28485]\teval-rmse:3.78959\ttrain-rmse:1.94979\n",
      "[28486]\teval-rmse:3.78992\ttrain-rmse:1.94978\n",
      "[28487]\teval-rmse:3.7904\ttrain-rmse:1.94977\n",
      "[28488]\teval-rmse:3.7906\ttrain-rmse:1.94977\n",
      "[28489]\teval-rmse:3.79175\ttrain-rmse:1.94974\n",
      "[28490]\teval-rmse:3.79204\ttrain-rmse:1.94974\n",
      "[28491]\teval-rmse:3.79076\ttrain-rmse:1.94976\n",
      "[28492]\teval-rmse:3.79178\ttrain-rmse:1.94974\n",
      "[28493]\teval-rmse:3.79081\ttrain-rmse:1.94977\n",
      "[28494]\teval-rmse:3.79008\ttrain-rmse:1.94979\n",
      "[28495]\teval-rmse:3.78934\ttrain-rmse:1.94981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28496]\teval-rmse:3.78956\ttrain-rmse:1.9498\n",
      "[28497]\teval-rmse:3.78938\ttrain-rmse:1.94981\n",
      "[28498]\teval-rmse:3.79065\ttrain-rmse:1.94978\n",
      "[28499]\teval-rmse:3.79088\ttrain-rmse:1.94978\n",
      "[28500]\teval-rmse:3.79246\ttrain-rmse:1.94974\n",
      "[28501]\teval-rmse:3.79228\ttrain-rmse:1.94975\n",
      "[28502]\teval-rmse:3.79108\ttrain-rmse:1.94977\n",
      "[28503]\teval-rmse:3.79089\ttrain-rmse:1.94973\n",
      "[28504]\teval-rmse:3.79074\ttrain-rmse:1.94973\n",
      "[28505]\teval-rmse:3.79232\ttrain-rmse:1.9497\n",
      "[28506]\teval-rmse:3.79213\ttrain-rmse:1.94971\n",
      "[28507]\teval-rmse:3.79067\ttrain-rmse:1.94973\n",
      "[28508]\teval-rmse:3.79125\ttrain-rmse:1.94972\n",
      "[28509]\teval-rmse:3.79277\ttrain-rmse:1.94968\n",
      "[28510]\teval-rmse:3.79101\ttrain-rmse:1.94971\n",
      "[28511]\teval-rmse:3.79225\ttrain-rmse:1.94969\n",
      "[28512]\teval-rmse:3.79178\ttrain-rmse:1.9497\n",
      "[28513]\teval-rmse:3.79124\ttrain-rmse:1.94971\n",
      "[28514]\teval-rmse:3.79\ttrain-rmse:1.94974\n",
      "[28515]\teval-rmse:3.79055\ttrain-rmse:1.94973\n",
      "[28516]\teval-rmse:3.79109\ttrain-rmse:1.94972\n",
      "[28517]\teval-rmse:3.79087\ttrain-rmse:1.94972\n",
      "[28518]\teval-rmse:3.7927\ttrain-rmse:1.94967\n",
      "[28519]\teval-rmse:3.79318\ttrain-rmse:1.94966\n",
      "[28520]\teval-rmse:3.79189\ttrain-rmse:1.94968\n",
      "[28521]\teval-rmse:3.79325\ttrain-rmse:1.94965\n",
      "[28522]\teval-rmse:3.7917\ttrain-rmse:1.94968\n",
      "[28523]\teval-rmse:3.79354\ttrain-rmse:1.94963\n",
      "[28524]\teval-rmse:3.79303\ttrain-rmse:1.94965\n",
      "[28525]\teval-rmse:3.79383\ttrain-rmse:1.94963\n",
      "[28526]\teval-rmse:3.79207\ttrain-rmse:1.94967\n",
      "[28527]\teval-rmse:3.79085\ttrain-rmse:1.94971\n",
      "[28528]\teval-rmse:3.79044\ttrain-rmse:1.94972\n",
      "[28529]\teval-rmse:3.79228\ttrain-rmse:1.94967\n",
      "[28530]\teval-rmse:3.7913\ttrain-rmse:1.9497\n",
      "[28531]\teval-rmse:3.79002\ttrain-rmse:1.94973\n",
      "[28532]\teval-rmse:3.79057\ttrain-rmse:1.94971\n",
      "[28533]\teval-rmse:3.79032\ttrain-rmse:1.94972\n",
      "[28534]\teval-rmse:3.79088\ttrain-rmse:1.94971\n",
      "[28535]\teval-rmse:3.79192\ttrain-rmse:1.94968\n",
      "[28536]\teval-rmse:3.79117\ttrain-rmse:1.94969\n",
      "[28537]\teval-rmse:3.79099\ttrain-rmse:1.9497\n",
      "[28538]\teval-rmse:3.78953\ttrain-rmse:1.94974\n",
      "[28539]\teval-rmse:3.78905\ttrain-rmse:1.94975\n",
      "[28540]\teval-rmse:3.78954\ttrain-rmse:1.94974\n",
      "[28541]\teval-rmse:3.79112\ttrain-rmse:1.9497\n",
      "[28542]\teval-rmse:3.79188\ttrain-rmse:1.94968\n",
      "[28543]\teval-rmse:3.79189\ttrain-rmse:1.94968\n",
      "[28544]\teval-rmse:3.79303\ttrain-rmse:1.94965\n",
      "[28545]\teval-rmse:3.79458\ttrain-rmse:1.94963\n",
      "[28546]\teval-rmse:3.79441\ttrain-rmse:1.94963\n",
      "[28547]\teval-rmse:3.7932\ttrain-rmse:1.94965\n",
      "[28548]\teval-rmse:3.79372\ttrain-rmse:1.94964\n",
      "[28549]\teval-rmse:3.79321\ttrain-rmse:1.94966\n",
      "[28550]\teval-rmse:3.79345\ttrain-rmse:1.94965\n",
      "[28551]\teval-rmse:3.79221\ttrain-rmse:1.94968\n",
      "[28552]\teval-rmse:3.79102\ttrain-rmse:1.9497\n",
      "[28553]\teval-rmse:3.79084\ttrain-rmse:1.94971\n",
      "[28554]\teval-rmse:3.78965\ttrain-rmse:1.94974\n",
      "[28555]\teval-rmse:3.79115\ttrain-rmse:1.9497\n",
      "[28556]\teval-rmse:3.791\ttrain-rmse:1.9497\n",
      "[28557]\teval-rmse:3.78975\ttrain-rmse:1.94974\n",
      "[28558]\teval-rmse:3.78848\ttrain-rmse:1.94978\n",
      "[28559]\teval-rmse:3.7901\ttrain-rmse:1.94971\n",
      "[28560]\teval-rmse:3.79065\ttrain-rmse:1.9497\n",
      "[28561]\teval-rmse:3.79227\ttrain-rmse:1.94964\n",
      "[28562]\teval-rmse:3.79183\ttrain-rmse:1.94965\n",
      "[28563]\teval-rmse:3.79213\ttrain-rmse:1.94965\n",
      "[28564]\teval-rmse:3.79265\ttrain-rmse:1.94964\n",
      "[28565]\teval-rmse:3.79423\ttrain-rmse:1.9496\n",
      "[28566]\teval-rmse:3.79607\ttrain-rmse:1.94956\n",
      "[28567]\teval-rmse:3.79427\ttrain-rmse:1.94959\n",
      "[28568]\teval-rmse:3.79272\ttrain-rmse:1.94962\n",
      "[28569]\teval-rmse:3.79406\ttrain-rmse:1.94959\n",
      "[28570]\teval-rmse:3.79568\ttrain-rmse:1.94957\n",
      "[28571]\teval-rmse:3.79631\ttrain-rmse:1.94956\n",
      "[28572]\teval-rmse:3.79613\ttrain-rmse:1.94952\n",
      "[28573]\teval-rmse:3.7973\ttrain-rmse:1.9495\n",
      "[28574]\teval-rmse:3.79583\ttrain-rmse:1.94952\n",
      "[28575]\teval-rmse:3.79562\ttrain-rmse:1.94952\n",
      "[28576]\teval-rmse:3.79597\ttrain-rmse:1.94952\n",
      "[28577]\teval-rmse:3.7957\ttrain-rmse:1.94953\n",
      "[28578]\teval-rmse:3.79553\ttrain-rmse:1.94953\n",
      "[28579]\teval-rmse:3.7951\ttrain-rmse:1.94954\n",
      "[28580]\teval-rmse:3.79468\ttrain-rmse:1.94954\n",
      "[28581]\teval-rmse:3.79306\ttrain-rmse:1.94957\n",
      "[28582]\teval-rmse:3.79364\ttrain-rmse:1.94955\n",
      "[28583]\teval-rmse:3.79391\ttrain-rmse:1.94955\n",
      "[28584]\teval-rmse:3.79388\ttrain-rmse:1.94955\n",
      "[28585]\teval-rmse:3.79468\ttrain-rmse:1.94954\n",
      "[28586]\teval-rmse:3.79344\ttrain-rmse:1.94956\n",
      "[28587]\teval-rmse:3.79471\ttrain-rmse:1.94953\n",
      "[28588]\teval-rmse:3.7945\ttrain-rmse:1.94954\n",
      "[28589]\teval-rmse:3.79305\ttrain-rmse:1.94956\n",
      "[28590]\teval-rmse:3.79488\ttrain-rmse:1.94952\n",
      "[28591]\teval-rmse:3.79309\ttrain-rmse:1.94956\n",
      "[28592]\teval-rmse:3.79336\ttrain-rmse:1.94955\n",
      "[28593]\teval-rmse:3.79488\ttrain-rmse:1.94951\n",
      "[28594]\teval-rmse:3.79625\ttrain-rmse:1.94949\n",
      "[28595]\teval-rmse:3.79652\ttrain-rmse:1.94948\n",
      "[28596]\teval-rmse:3.79528\ttrain-rmse:1.9495\n",
      "[28597]\teval-rmse:3.79398\ttrain-rmse:1.94952\n",
      "[28598]\teval-rmse:3.79372\ttrain-rmse:1.94953\n",
      "[28599]\teval-rmse:3.79488\ttrain-rmse:1.94951\n",
      "[28600]\teval-rmse:3.79467\ttrain-rmse:1.94952\n",
      "[28601]\teval-rmse:3.7942\ttrain-rmse:1.94953\n",
      "[28602]\teval-rmse:3.794\ttrain-rmse:1.94953\n",
      "[28603]\teval-rmse:3.79559\ttrain-rmse:1.94951\n",
      "[28604]\teval-rmse:3.79557\ttrain-rmse:1.94951\n",
      "[28605]\teval-rmse:3.79693\ttrain-rmse:1.94949\n",
      "[28606]\teval-rmse:3.7965\ttrain-rmse:1.94949\n",
      "[28607]\teval-rmse:3.79681\ttrain-rmse:1.94949\n",
      "[28608]\teval-rmse:3.79629\ttrain-rmse:1.94949\n",
      "[28609]\teval-rmse:3.79504\ttrain-rmse:1.94951\n",
      "[28610]\teval-rmse:3.79383\ttrain-rmse:1.94954\n",
      "[28611]\teval-rmse:3.79541\ttrain-rmse:1.94951\n",
      "[28612]\teval-rmse:3.79409\ttrain-rmse:1.94953\n",
      "[28613]\teval-rmse:3.79561\ttrain-rmse:1.94951\n",
      "[28614]\teval-rmse:3.79428\ttrain-rmse:1.94953\n",
      "[28615]\teval-rmse:3.7928\ttrain-rmse:1.94956\n",
      "[28616]\teval-rmse:3.79132\ttrain-rmse:1.9496\n",
      "[28617]\teval-rmse:3.79004\ttrain-rmse:1.94965\n",
      "[28618]\teval-rmse:3.78934\ttrain-rmse:1.94968\n",
      "[28619]\teval-rmse:3.78781\ttrain-rmse:1.94973\n",
      "[28620]\teval-rmse:3.78608\ttrain-rmse:1.94981\n",
      "[28621]\teval-rmse:3.7857\ttrain-rmse:1.94983\n",
      "[28622]\teval-rmse:3.78557\ttrain-rmse:1.94978\n",
      "[28623]\teval-rmse:3.78541\ttrain-rmse:1.94974\n",
      "[28624]\teval-rmse:3.78471\ttrain-rmse:1.94977\n",
      "[28625]\teval-rmse:3.78654\ttrain-rmse:1.94969\n",
      "[28626]\teval-rmse:3.78641\ttrain-rmse:1.9497\n",
      "[28627]\teval-rmse:3.78602\ttrain-rmse:1.94972\n",
      "[28628]\teval-rmse:3.78455\ttrain-rmse:1.94978\n",
      "[28629]\teval-rmse:3.78534\ttrain-rmse:1.94974\n",
      "[28630]\teval-rmse:3.78556\ttrain-rmse:1.94973\n",
      "[28631]\teval-rmse:3.78682\ttrain-rmse:1.94967\n",
      "[28632]\teval-rmse:3.78644\ttrain-rmse:1.94968\n",
      "[28633]\teval-rmse:3.78795\ttrain-rmse:1.94962\n",
      "[28634]\teval-rmse:3.78777\ttrain-rmse:1.94957\n",
      "[28635]\teval-rmse:3.7881\ttrain-rmse:1.94956\n",
      "[28636]\teval-rmse:3.78796\ttrain-rmse:1.94956\n",
      "[28637]\teval-rmse:3.78819\ttrain-rmse:1.94955\n",
      "[28638]\teval-rmse:3.78802\ttrain-rmse:1.94956\n",
      "[28639]\teval-rmse:3.78822\ttrain-rmse:1.94955\n",
      "[28640]\teval-rmse:3.78805\ttrain-rmse:1.94956\n",
      "[28641]\teval-rmse:3.78833\ttrain-rmse:1.94955\n",
      "[28642]\teval-rmse:3.78704\ttrain-rmse:1.9496\n",
      "[28643]\teval-rmse:3.78737\ttrain-rmse:1.94958\n",
      "[28644]\teval-rmse:3.78587\ttrain-rmse:1.94966\n",
      "[28645]\teval-rmse:3.78696\ttrain-rmse:1.9496\n",
      "[28646]\teval-rmse:3.78679\ttrain-rmse:1.94956\n",
      "[28647]\teval-rmse:3.78562\ttrain-rmse:1.94962\n",
      "[28648]\teval-rmse:3.78414\ttrain-rmse:1.94969\n",
      "[28649]\teval-rmse:3.78268\ttrain-rmse:1.94978\n",
      "[28650]\teval-rmse:3.78325\ttrain-rmse:1.94974\n",
      "[28651]\teval-rmse:3.78428\ttrain-rmse:1.94968\n",
      "[28652]\teval-rmse:3.78476\ttrain-rmse:1.94966\n",
      "[28653]\teval-rmse:3.78503\ttrain-rmse:1.94964\n",
      "[28654]\teval-rmse:3.78385\ttrain-rmse:1.9497\n",
      "[28655]\teval-rmse:3.78293\ttrain-rmse:1.94975\n",
      "[28656]\teval-rmse:3.78316\ttrain-rmse:1.94973\n",
      "[28657]\teval-rmse:3.78446\ttrain-rmse:1.94966\n",
      "[28658]\teval-rmse:3.78275\ttrain-rmse:1.94975\n",
      "[28659]\teval-rmse:3.7823\ttrain-rmse:1.94978\n",
      "[28660]\teval-rmse:3.78337\ttrain-rmse:1.94973\n",
      "[28661]\teval-rmse:3.78521\ttrain-rmse:1.94964\n",
      "[28662]\teval-rmse:3.78678\ttrain-rmse:1.94957\n",
      "[28663]\teval-rmse:3.7884\ttrain-rmse:1.94951\n",
      "[28664]\teval-rmse:3.78825\ttrain-rmse:1.94947\n",
      "[28665]\teval-rmse:3.78706\ttrain-rmse:1.94951\n",
      "[28666]\teval-rmse:3.78588\ttrain-rmse:1.94957\n",
      "[28667]\teval-rmse:3.78693\ttrain-rmse:1.94952\n",
      "[28668]\teval-rmse:3.78796\ttrain-rmse:1.94947\n",
      "[28669]\teval-rmse:3.78646\ttrain-rmse:1.94954\n",
      "[28670]\teval-rmse:3.7875\ttrain-rmse:1.94949\n",
      "[28671]\teval-rmse:3.78803\ttrain-rmse:1.94947\n",
      "[28672]\teval-rmse:3.78655\ttrain-rmse:1.94954\n",
      "[28673]\teval-rmse:3.78638\ttrain-rmse:1.94949\n",
      "[28674]\teval-rmse:3.78791\ttrain-rmse:1.94942\n",
      "[28675]\teval-rmse:3.78641\ttrain-rmse:1.94949\n",
      "[28676]\teval-rmse:3.78523\ttrain-rmse:1.94954\n",
      "[28677]\teval-rmse:3.78507\ttrain-rmse:1.94955\n",
      "[28678]\teval-rmse:3.78508\ttrain-rmse:1.94955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28679]\teval-rmse:3.78463\ttrain-rmse:1.94957\n",
      "[28680]\teval-rmse:3.78514\ttrain-rmse:1.94954\n",
      "[28681]\teval-rmse:3.78513\ttrain-rmse:1.94954\n",
      "[28682]\teval-rmse:3.78672\ttrain-rmse:1.94947\n",
      "[28683]\teval-rmse:3.78524\ttrain-rmse:1.94953\n",
      "[28684]\teval-rmse:3.7833\ttrain-rmse:1.94962\n",
      "[28685]\teval-rmse:3.78184\ttrain-rmse:1.94972\n",
      "[28686]\teval-rmse:3.7802\ttrain-rmse:1.94982\n",
      "[28687]\teval-rmse:3.77872\ttrain-rmse:1.94992\n",
      "[28688]\teval-rmse:3.77923\ttrain-rmse:1.94989\n",
      "[28689]\teval-rmse:3.77782\ttrain-rmse:1.94999\n",
      "[28690]\teval-rmse:3.77862\ttrain-rmse:1.94993\n",
      "[28691]\teval-rmse:3.77919\ttrain-rmse:1.94989\n",
      "[28692]\teval-rmse:3.77828\ttrain-rmse:1.94994\n",
      "[28693]\teval-rmse:3.77887\ttrain-rmse:1.94989\n",
      "[28694]\teval-rmse:3.77846\ttrain-rmse:1.94992\n",
      "[28695]\teval-rmse:3.78008\ttrain-rmse:1.9498\n",
      "[28696]\teval-rmse:3.77994\ttrain-rmse:1.94981\n",
      "[28697]\teval-rmse:3.78051\ttrain-rmse:1.94977\n",
      "[28698]\teval-rmse:3.7821\ttrain-rmse:1.94968\n",
      "[28699]\teval-rmse:3.78257\ttrain-rmse:1.94965\n",
      "[28700]\teval-rmse:3.78294\ttrain-rmse:1.94963\n",
      "[28701]\teval-rmse:3.7813\ttrain-rmse:1.94971\n",
      "[28702]\teval-rmse:3.78191\ttrain-rmse:1.94968\n",
      "[28703]\teval-rmse:3.78099\ttrain-rmse:1.94972\n",
      "[28704]\teval-rmse:3.77982\ttrain-rmse:1.94981\n",
      "[28705]\teval-rmse:3.77791\ttrain-rmse:1.94993\n",
      "[28706]\teval-rmse:3.77793\ttrain-rmse:1.94993\n",
      "[28707]\teval-rmse:3.77977\ttrain-rmse:1.94983\n",
      "[28708]\teval-rmse:3.78013\ttrain-rmse:1.9498\n",
      "[28709]\teval-rmse:3.78139\ttrain-rmse:1.94971\n",
      "[28710]\teval-rmse:3.78196\ttrain-rmse:1.94967\n",
      "[28711]\teval-rmse:3.78349\ttrain-rmse:1.94958\n",
      "[28712]\teval-rmse:3.78374\ttrain-rmse:1.94956\n",
      "[28713]\teval-rmse:3.78335\ttrain-rmse:1.94959\n",
      "[28714]\teval-rmse:3.78382\ttrain-rmse:1.94956\n",
      "[28715]\teval-rmse:3.78211\ttrain-rmse:1.94965\n",
      "[28716]\teval-rmse:3.78239\ttrain-rmse:1.94964\n",
      "[28717]\teval-rmse:3.78098\ttrain-rmse:1.94972\n",
      "[28718]\teval-rmse:3.77955\ttrain-rmse:1.94982\n",
      "[28719]\teval-rmse:3.7781\ttrain-rmse:1.94993\n",
      "[28720]\teval-rmse:3.77767\ttrain-rmse:1.94996\n",
      "[28721]\teval-rmse:3.77723\ttrain-rmse:1.95\n",
      "[28722]\teval-rmse:3.77714\ttrain-rmse:1.95\n",
      "[28723]\teval-rmse:3.77669\ttrain-rmse:1.95004\n",
      "[28724]\teval-rmse:3.77627\ttrain-rmse:1.95007\n",
      "[28725]\teval-rmse:3.77686\ttrain-rmse:1.95002\n",
      "[28726]\teval-rmse:3.77641\ttrain-rmse:1.95005\n",
      "[28727]\teval-rmse:3.7767\ttrain-rmse:1.95003\n",
      "[28728]\teval-rmse:3.7778\ttrain-rmse:1.94994\n",
      "[28729]\teval-rmse:3.7783\ttrain-rmse:1.94991\n",
      "[28730]\teval-rmse:3.7796\ttrain-rmse:1.94982\n",
      "[28731]\teval-rmse:3.77846\ttrain-rmse:1.9499\n",
      "[28732]\teval-rmse:3.77756\ttrain-rmse:1.94995\n",
      "[28733]\teval-rmse:3.77907\ttrain-rmse:1.94984\n",
      "[28734]\teval-rmse:3.77957\ttrain-rmse:1.94981\n",
      "[28735]\teval-rmse:3.77812\ttrain-rmse:1.94991\n",
      "[28736]\teval-rmse:3.77963\ttrain-rmse:1.94981\n",
      "[28737]\teval-rmse:3.78147\ttrain-rmse:1.94971\n",
      "[28738]\teval-rmse:3.78103\ttrain-rmse:1.94974\n",
      "[28739]\teval-rmse:3.78265\ttrain-rmse:1.94965\n",
      "[28740]\teval-rmse:3.78326\ttrain-rmse:1.94961\n",
      "[28741]\teval-rmse:3.78329\ttrain-rmse:1.94961\n",
      "[28742]\teval-rmse:3.78512\ttrain-rmse:1.94951\n",
      "[28743]\teval-rmse:3.7856\ttrain-rmse:1.94949\n",
      "[28744]\teval-rmse:3.78711\ttrain-rmse:1.94942\n",
      "[28745]\teval-rmse:3.78817\ttrain-rmse:1.94938\n",
      "[28746]\teval-rmse:3.788\ttrain-rmse:1.94938\n",
      "[28747]\teval-rmse:3.78906\ttrain-rmse:1.94934\n",
      "[28748]\teval-rmse:3.78754\ttrain-rmse:1.9494\n",
      "[28749]\teval-rmse:3.78609\ttrain-rmse:1.94947\n",
      "[28750]\teval-rmse:3.78514\ttrain-rmse:1.94951\n",
      "[28751]\teval-rmse:3.7837\ttrain-rmse:1.9496\n",
      "[28752]\teval-rmse:3.78532\ttrain-rmse:1.9495\n",
      "[28753]\teval-rmse:3.78519\ttrain-rmse:1.94951\n",
      "[28754]\teval-rmse:3.78656\ttrain-rmse:1.94945\n",
      "[28755]\teval-rmse:3.7854\ttrain-rmse:1.9495\n",
      "[28756]\teval-rmse:3.78425\ttrain-rmse:1.94955\n",
      "[28757]\teval-rmse:3.78278\ttrain-rmse:1.94963\n",
      "[28758]\teval-rmse:3.78429\ttrain-rmse:1.94955\n",
      "[28759]\teval-rmse:3.78559\ttrain-rmse:1.94948\n",
      "[28760]\teval-rmse:3.78367\ttrain-rmse:1.94957\n",
      "[28761]\teval-rmse:3.78355\ttrain-rmse:1.94952\n",
      "[28762]\teval-rmse:3.78468\ttrain-rmse:1.94946\n",
      "[28763]\teval-rmse:3.78455\ttrain-rmse:1.94942\n",
      "[28764]\teval-rmse:3.78442\ttrain-rmse:1.94943\n",
      "[28765]\teval-rmse:3.78325\ttrain-rmse:1.94948\n",
      "[28766]\teval-rmse:3.78176\ttrain-rmse:1.94957\n",
      "[28767]\teval-rmse:3.78161\ttrain-rmse:1.94953\n",
      "[28768]\teval-rmse:3.78313\ttrain-rmse:1.94944\n",
      "[28769]\teval-rmse:3.78466\ttrain-rmse:1.94936\n",
      "[28770]\teval-rmse:3.78619\ttrain-rmse:1.94929\n",
      "[28771]\teval-rmse:3.78605\ttrain-rmse:1.9493\n",
      "[28772]\teval-rmse:3.78486\ttrain-rmse:1.94935\n",
      "[28773]\teval-rmse:3.78509\ttrain-rmse:1.94934\n",
      "[28774]\teval-rmse:3.78634\ttrain-rmse:1.94929\n",
      "[28775]\teval-rmse:3.7862\ttrain-rmse:1.94929\n",
      "[28776]\teval-rmse:3.78477\ttrain-rmse:1.94936\n",
      "[28777]\teval-rmse:3.78434\ttrain-rmse:1.94938\n",
      "[28778]\teval-rmse:3.78285\ttrain-rmse:1.94945\n",
      "[28779]\teval-rmse:3.7816\ttrain-rmse:1.94952\n",
      "[28780]\teval-rmse:3.78037\ttrain-rmse:1.9496\n",
      "[28781]\teval-rmse:3.7819\ttrain-rmse:1.94951\n",
      "[28782]\teval-rmse:3.78227\ttrain-rmse:1.94949\n",
      "[28783]\teval-rmse:3.78114\ttrain-rmse:1.94956\n",
      "[28784]\teval-rmse:3.77965\ttrain-rmse:1.94965\n",
      "[28785]\teval-rmse:3.7811\ttrain-rmse:1.94957\n",
      "[28786]\teval-rmse:3.78169\ttrain-rmse:1.94953\n",
      "[28787]\teval-rmse:3.78227\ttrain-rmse:1.9495\n",
      "[28788]\teval-rmse:3.78081\ttrain-rmse:1.94959\n",
      "[28789]\teval-rmse:3.78066\ttrain-rmse:1.94954\n",
      "[28790]\teval-rmse:3.78056\ttrain-rmse:1.94955\n",
      "[28791]\teval-rmse:3.78213\ttrain-rmse:1.94946\n",
      "[28792]\teval-rmse:3.78169\ttrain-rmse:1.94949\n",
      "[28793]\teval-rmse:3.78124\ttrain-rmse:1.94951\n",
      "[28794]\teval-rmse:3.78252\ttrain-rmse:1.94944\n",
      "[28795]\teval-rmse:3.78139\ttrain-rmse:1.9495\n",
      "[28796]\teval-rmse:3.78124\ttrain-rmse:1.94946\n",
      "[28797]\teval-rmse:3.77934\ttrain-rmse:1.94956\n",
      "[28798]\teval-rmse:3.77958\ttrain-rmse:1.94955\n",
      "[28799]\teval-rmse:3.78038\ttrain-rmse:1.9495\n",
      "[28800]\teval-rmse:3.78152\ttrain-rmse:1.94943\n",
      "[28801]\teval-rmse:3.78231\ttrain-rmse:1.94939\n",
      "[28802]\teval-rmse:3.7836\ttrain-rmse:1.94932\n",
      "[28803]\teval-rmse:3.78441\ttrain-rmse:1.94928\n",
      "[28804]\teval-rmse:3.78441\ttrain-rmse:1.94928\n",
      "[28805]\teval-rmse:3.78425\ttrain-rmse:1.94924\n",
      "[28806]\teval-rmse:3.78409\ttrain-rmse:1.9492\n",
      "[28807]\teval-rmse:3.78362\ttrain-rmse:1.94922\n",
      "[28808]\teval-rmse:3.78269\ttrain-rmse:1.94926\n",
      "[28809]\teval-rmse:3.78124\ttrain-rmse:1.94934\n",
      "[28810]\teval-rmse:3.77959\ttrain-rmse:1.94943\n",
      "[28811]\teval-rmse:3.77948\ttrain-rmse:1.94944\n",
      "[28812]\teval-rmse:3.77803\ttrain-rmse:1.94953\n",
      "[28813]\teval-rmse:3.77679\ttrain-rmse:1.94962\n",
      "[28814]\teval-rmse:3.77661\ttrain-rmse:1.94963\n",
      "[28815]\teval-rmse:3.77696\ttrain-rmse:1.94961\n",
      "[28816]\teval-rmse:3.77826\ttrain-rmse:1.94952\n",
      "[28817]\teval-rmse:3.77863\ttrain-rmse:1.9495\n",
      "[28818]\teval-rmse:3.77773\ttrain-rmse:1.94955\n",
      "[28819]\teval-rmse:3.7782\ttrain-rmse:1.94952\n",
      "[28820]\teval-rmse:3.77807\ttrain-rmse:1.94953\n",
      "[28821]\teval-rmse:3.77958\ttrain-rmse:1.94944\n",
      "[28822]\teval-rmse:3.77833\ttrain-rmse:1.94952\n",
      "[28823]\teval-rmse:3.77766\ttrain-rmse:1.94956\n",
      "[28824]\teval-rmse:3.77871\ttrain-rmse:1.94949\n",
      "[28825]\teval-rmse:3.77781\ttrain-rmse:1.94955\n",
      "[28826]\teval-rmse:3.77836\ttrain-rmse:1.94951\n",
      "[28827]\teval-rmse:3.77823\ttrain-rmse:1.94952\n",
      "[28828]\teval-rmse:3.77708\ttrain-rmse:1.9496\n",
      "[28829]\teval-rmse:3.77843\ttrain-rmse:1.94951\n",
      "[28830]\teval-rmse:3.77996\ttrain-rmse:1.94941\n",
      "[28831]\teval-rmse:3.78025\ttrain-rmse:1.9494\n",
      "[28832]\teval-rmse:3.77934\ttrain-rmse:1.94945\n",
      "[28833]\teval-rmse:3.77991\ttrain-rmse:1.94941\n",
      "[28834]\teval-rmse:3.77977\ttrain-rmse:1.94942\n",
      "[28835]\teval-rmse:3.77963\ttrain-rmse:1.94943\n",
      "[28836]\teval-rmse:3.77918\ttrain-rmse:1.94945\n",
      "[28837]\teval-rmse:3.77975\ttrain-rmse:1.94942\n",
      "[28838]\teval-rmse:3.78038\ttrain-rmse:1.94939\n",
      "[28839]\teval-rmse:3.78189\ttrain-rmse:1.94931\n",
      "[28840]\teval-rmse:3.78177\ttrain-rmse:1.94932\n",
      "[28841]\teval-rmse:3.7806\ttrain-rmse:1.94938\n",
      "[28842]\teval-rmse:3.77939\ttrain-rmse:1.94945\n",
      "[28843]\teval-rmse:3.77903\ttrain-rmse:1.94947\n",
      "[28844]\teval-rmse:3.77764\ttrain-rmse:1.94956\n",
      "[28845]\teval-rmse:3.7762\ttrain-rmse:1.94966\n",
      "[28846]\teval-rmse:3.77611\ttrain-rmse:1.94967\n",
      "[28847]\teval-rmse:3.77522\ttrain-rmse:1.94972\n",
      "[28848]\teval-rmse:3.7751\ttrain-rmse:1.94973\n",
      "[28849]\teval-rmse:3.77654\ttrain-rmse:1.94964\n",
      "[28850]\teval-rmse:3.77609\ttrain-rmse:1.94968\n",
      "[28851]\teval-rmse:3.77737\ttrain-rmse:1.94959\n",
      "[28852]\teval-rmse:3.77569\ttrain-rmse:1.94972\n",
      "[28853]\teval-rmse:3.7756\ttrain-rmse:1.94968\n",
      "[28854]\teval-rmse:3.77524\ttrain-rmse:1.9497\n",
      "[28855]\teval-rmse:3.77512\ttrain-rmse:1.94971\n",
      "[28856]\teval-rmse:3.77445\ttrain-rmse:1.94976\n",
      "[28857]\teval-rmse:3.77495\ttrain-rmse:1.94972\n",
      "[28858]\teval-rmse:3.7738\ttrain-rmse:1.94981\n",
      "[28859]\teval-rmse:3.77516\ttrain-rmse:1.9497\n",
      "[28860]\teval-rmse:3.77571\ttrain-rmse:1.94967\n",
      "[28861]\teval-rmse:3.77621\ttrain-rmse:1.94963\n",
      "[28862]\teval-rmse:3.77579\ttrain-rmse:1.94966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28863]\teval-rmse:3.77664\ttrain-rmse:1.9496\n",
      "[28864]\teval-rmse:3.7772\ttrain-rmse:1.94956\n",
      "[28865]\teval-rmse:3.77579\ttrain-rmse:1.94966\n",
      "[28866]\teval-rmse:3.77633\ttrain-rmse:1.94963\n",
      "[28867]\teval-rmse:3.77661\ttrain-rmse:1.94961\n",
      "[28868]\teval-rmse:3.77643\ttrain-rmse:1.94962\n",
      "[28869]\teval-rmse:3.77634\ttrain-rmse:1.94963\n",
      "[28870]\teval-rmse:3.77498\ttrain-rmse:1.94973\n",
      "[28871]\teval-rmse:3.77464\ttrain-rmse:1.94975\n",
      "[28872]\teval-rmse:3.77545\ttrain-rmse:1.94969\n",
      "[28873]\teval-rmse:3.77704\ttrain-rmse:1.94959\n",
      "[28874]\teval-rmse:3.77888\ttrain-rmse:1.94948\n",
      "[28875]\teval-rmse:3.77969\ttrain-rmse:1.94943\n",
      "[28876]\teval-rmse:3.78095\ttrain-rmse:1.94936\n",
      "[28877]\teval-rmse:3.78143\ttrain-rmse:1.94933\n",
      "[28878]\teval-rmse:3.77949\ttrain-rmse:1.94942\n",
      "[28879]\teval-rmse:3.78003\ttrain-rmse:1.94939\n",
      "[28880]\teval-rmse:3.78186\ttrain-rmse:1.94929\n",
      "[28881]\teval-rmse:3.78369\ttrain-rmse:1.94921\n",
      "[28882]\teval-rmse:3.78356\ttrain-rmse:1.94917\n",
      "[28883]\teval-rmse:3.78461\ttrain-rmse:1.94912\n",
      "[28884]\teval-rmse:3.78494\ttrain-rmse:1.9491\n",
      "[28885]\teval-rmse:3.7835\ttrain-rmse:1.94917\n",
      "[28886]\teval-rmse:3.78182\ttrain-rmse:1.94925\n",
      "[28887]\teval-rmse:3.78065\ttrain-rmse:1.94932\n",
      "[28888]\teval-rmse:3.78191\ttrain-rmse:1.94925\n",
      "[28889]\teval-rmse:3.78042\ttrain-rmse:1.94933\n",
      "[28890]\teval-rmse:3.78169\ttrain-rmse:1.94926\n",
      "[28891]\teval-rmse:3.78029\ttrain-rmse:1.94934\n",
      "[28892]\teval-rmse:3.77987\ttrain-rmse:1.94937\n",
      "[28893]\teval-rmse:3.78113\ttrain-rmse:1.94929\n",
      "[28894]\teval-rmse:3.78078\ttrain-rmse:1.94931\n",
      "[28895]\teval-rmse:3.78063\ttrain-rmse:1.94927\n",
      "[28896]\teval-rmse:3.78121\ttrain-rmse:1.94923\n",
      "[28897]\teval-rmse:3.78076\ttrain-rmse:1.94926\n",
      "[28898]\teval-rmse:3.77905\ttrain-rmse:1.94937\n",
      "[28899]\teval-rmse:3.7804\ttrain-rmse:1.94928\n",
      "[28900]\teval-rmse:3.77925\ttrain-rmse:1.94934\n",
      "[28901]\teval-rmse:3.77756\ttrain-rmse:1.94946\n",
      "[28902]\teval-rmse:3.77642\ttrain-rmse:1.94954\n",
      "[28903]\teval-rmse:3.77725\ttrain-rmse:1.94949\n",
      "[28904]\teval-rmse:3.77684\ttrain-rmse:1.94951\n",
      "[28905]\teval-rmse:3.77642\ttrain-rmse:1.94955\n",
      "[28906]\teval-rmse:3.77804\ttrain-rmse:1.94944\n",
      "[28907]\teval-rmse:3.77737\ttrain-rmse:1.94948\n",
      "[28908]\teval-rmse:3.77774\ttrain-rmse:1.94946\n",
      "[28909]\teval-rmse:3.7766\ttrain-rmse:1.94954\n",
      "[28910]\teval-rmse:3.77844\ttrain-rmse:1.94943\n",
      "[28911]\teval-rmse:3.77825\ttrain-rmse:1.94944\n",
      "[28912]\teval-rmse:3.77978\ttrain-rmse:1.94935\n",
      "[28913]\teval-rmse:3.77934\ttrain-rmse:1.94938\n",
      "[28914]\teval-rmse:3.77967\ttrain-rmse:1.94936\n",
      "[28915]\teval-rmse:3.77923\ttrain-rmse:1.94939\n",
      "[28916]\teval-rmse:3.77909\ttrain-rmse:1.9494\n",
      "[28917]\teval-rmse:3.77896\ttrain-rmse:1.9494\n",
      "[28918]\teval-rmse:3.78025\ttrain-rmse:1.94933\n",
      "[28919]\teval-rmse:3.78159\ttrain-rmse:1.94924\n",
      "[28920]\teval-rmse:3.78184\ttrain-rmse:1.94923\n",
      "[28921]\teval-rmse:3.78042\ttrain-rmse:1.94932\n",
      "[28922]\teval-rmse:3.78007\ttrain-rmse:1.94934\n",
      "[28923]\teval-rmse:3.78113\ttrain-rmse:1.94927\n",
      "[28924]\teval-rmse:3.78266\ttrain-rmse:1.94919\n",
      "[28925]\teval-rmse:3.78425\ttrain-rmse:1.94912\n",
      "[28926]\teval-rmse:3.78352\ttrain-rmse:1.94915\n",
      "[28927]\teval-rmse:3.78202\ttrain-rmse:1.94925\n",
      "[28928]\teval-rmse:3.78181\ttrain-rmse:1.94926\n",
      "[28929]\teval-rmse:3.7824\ttrain-rmse:1.94922\n",
      "[28930]\teval-rmse:3.78228\ttrain-rmse:1.94922\n",
      "[28931]\teval-rmse:3.78136\ttrain-rmse:1.94927\n",
      "[28932]\teval-rmse:3.78044\ttrain-rmse:1.94932\n",
      "[28933]\teval-rmse:3.78179\ttrain-rmse:1.94923\n",
      "[28934]\teval-rmse:3.78284\ttrain-rmse:1.94917\n",
      "[28935]\teval-rmse:3.78159\ttrain-rmse:1.94925\n",
      "[28936]\teval-rmse:3.78147\ttrain-rmse:1.94925\n",
      "[28937]\teval-rmse:3.77999\ttrain-rmse:1.94935\n",
      "[28938]\teval-rmse:3.77883\ttrain-rmse:1.94944\n",
      "[28939]\teval-rmse:3.77964\ttrain-rmse:1.94938\n",
      "[28940]\teval-rmse:3.77922\ttrain-rmse:1.94941\n",
      "[28941]\teval-rmse:3.77924\ttrain-rmse:1.94941\n",
      "[28942]\teval-rmse:3.78108\ttrain-rmse:1.94931\n",
      "[28943]\teval-rmse:3.78136\ttrain-rmse:1.94929\n",
      "[28944]\teval-rmse:3.78183\ttrain-rmse:1.94926\n",
      "[28945]\teval-rmse:3.78208\ttrain-rmse:1.94925\n",
      "[28946]\teval-rmse:3.78339\ttrain-rmse:1.94917\n",
      "[28947]\teval-rmse:3.7842\ttrain-rmse:1.94913\n",
      "[28948]\teval-rmse:3.7835\ttrain-rmse:1.94917\n",
      "[28949]\teval-rmse:3.78335\ttrain-rmse:1.94917\n",
      "[28950]\teval-rmse:3.78218\ttrain-rmse:1.94923\n",
      "[28951]\teval-rmse:3.78104\ttrain-rmse:1.94928\n",
      "[28952]\teval-rmse:3.77991\ttrain-rmse:1.94935\n",
      "[28953]\teval-rmse:3.78174\ttrain-rmse:1.94926\n",
      "[28954]\teval-rmse:3.78333\ttrain-rmse:1.94917\n",
      "[28955]\teval-rmse:3.78237\ttrain-rmse:1.94922\n",
      "[28956]\teval-rmse:3.78045\ttrain-rmse:1.94934\n",
      "[28957]\teval-rmse:3.78228\ttrain-rmse:1.94925\n",
      "[28958]\teval-rmse:3.78207\ttrain-rmse:1.94926\n",
      "[28959]\teval-rmse:3.78082\ttrain-rmse:1.94934\n",
      "[28960]\teval-rmse:3.77943\ttrain-rmse:1.94942\n",
      "[28961]\teval-rmse:3.77929\ttrain-rmse:1.94942\n",
      "[28962]\teval-rmse:3.77862\ttrain-rmse:1.94946\n",
      "[28963]\teval-rmse:3.78022\ttrain-rmse:1.94935\n",
      "[28964]\teval-rmse:3.7816\ttrain-rmse:1.94926\n",
      "[28965]\teval-rmse:3.78313\ttrain-rmse:1.94918\n",
      "[28966]\teval-rmse:3.783\ttrain-rmse:1.94918\n",
      "[28967]\teval-rmse:3.78255\ttrain-rmse:1.94921\n",
      "[28968]\teval-rmse:3.78385\ttrain-rmse:1.94914\n",
      "[28969]\teval-rmse:3.78235\ttrain-rmse:1.94922\n",
      "[28970]\teval-rmse:3.7822\ttrain-rmse:1.94922\n",
      "[28971]\teval-rmse:3.78347\ttrain-rmse:1.94915\n",
      "[28972]\teval-rmse:3.78403\ttrain-rmse:1.94912\n",
      "[28973]\teval-rmse:3.78484\ttrain-rmse:1.94908\n",
      "[28974]\teval-rmse:3.78612\ttrain-rmse:1.94902\n",
      "[28975]\teval-rmse:3.7864\ttrain-rmse:1.94901\n",
      "[28976]\teval-rmse:3.78666\ttrain-rmse:1.949\n",
      "[28977]\teval-rmse:3.78649\ttrain-rmse:1.949\n",
      "[28978]\teval-rmse:3.78775\ttrain-rmse:1.94895\n",
      "[28979]\teval-rmse:3.78758\ttrain-rmse:1.9489\n",
      "[28980]\teval-rmse:3.78637\ttrain-rmse:1.94895\n",
      "[28981]\teval-rmse:3.78686\ttrain-rmse:1.94893\n",
      "[28982]\teval-rmse:3.78613\ttrain-rmse:1.94896\n",
      "[28983]\teval-rmse:3.78728\ttrain-rmse:1.94891\n",
      "[28984]\teval-rmse:3.7875\ttrain-rmse:1.94891\n",
      "[28985]\teval-rmse:3.78802\ttrain-rmse:1.94889\n",
      "[28986]\teval-rmse:3.78964\ttrain-rmse:1.94884\n",
      "[28987]\teval-rmse:3.79092\ttrain-rmse:1.9488\n",
      "[28988]\teval-rmse:3.7925\ttrain-rmse:1.94876\n",
      "[28989]\teval-rmse:3.7923\ttrain-rmse:1.94877\n",
      "[28990]\teval-rmse:3.79132\ttrain-rmse:1.94879\n",
      "[28991]\teval-rmse:3.78935\ttrain-rmse:1.94884\n",
      "[28992]\teval-rmse:3.79074\ttrain-rmse:1.9488\n",
      "[28993]\teval-rmse:3.79161\ttrain-rmse:1.94879\n",
      "[28994]\teval-rmse:3.79288\ttrain-rmse:1.94876\n",
      "[28995]\teval-rmse:3.79214\ttrain-rmse:1.94877\n",
      "[28996]\teval-rmse:3.79084\ttrain-rmse:1.9488\n",
      "[28997]\teval-rmse:3.79245\ttrain-rmse:1.94877\n",
      "[28998]\teval-rmse:3.79282\ttrain-rmse:1.94876\n",
      "[28999]\teval-rmse:3.7928\ttrain-rmse:1.94876\n",
      "[29000]\teval-rmse:3.79278\ttrain-rmse:1.94876\n",
      "[29001]\teval-rmse:3.79304\ttrain-rmse:1.94876\n",
      "[29002]\teval-rmse:3.79262\ttrain-rmse:1.94877\n",
      "[29003]\teval-rmse:3.79163\ttrain-rmse:1.94879\n",
      "[29004]\teval-rmse:3.791\ttrain-rmse:1.9488\n",
      "[29005]\teval-rmse:3.78956\ttrain-rmse:1.94884\n",
      "[29006]\teval-rmse:3.79115\ttrain-rmse:1.9488\n",
      "[29007]\teval-rmse:3.79096\ttrain-rmse:1.94876\n",
      "[29008]\teval-rmse:3.79207\ttrain-rmse:1.94873\n",
      "[29009]\teval-rmse:3.79242\ttrain-rmse:1.94873\n",
      "[29010]\teval-rmse:3.79119\ttrain-rmse:1.94876\n",
      "[29011]\teval-rmse:3.7927\ttrain-rmse:1.94873\n",
      "[29012]\teval-rmse:3.79421\ttrain-rmse:1.9487\n",
      "[29013]\teval-rmse:3.79296\ttrain-rmse:1.94872\n",
      "[29014]\teval-rmse:3.79457\ttrain-rmse:1.94869\n",
      "[29015]\teval-rmse:3.79357\ttrain-rmse:1.94871\n",
      "[29016]\teval-rmse:3.79337\ttrain-rmse:1.94867\n",
      "[29017]\teval-rmse:3.79356\ttrain-rmse:1.94866\n",
      "[29018]\teval-rmse:3.7949\ttrain-rmse:1.94865\n",
      "[29019]\teval-rmse:3.79491\ttrain-rmse:1.94865\n",
      "[29020]\teval-rmse:3.79336\ttrain-rmse:1.94866\n",
      "[29021]\teval-rmse:3.79309\ttrain-rmse:1.94867\n",
      "[29022]\teval-rmse:3.79289\ttrain-rmse:1.94863\n",
      "[29023]\teval-rmse:3.79449\ttrain-rmse:1.94861\n",
      "[29024]\teval-rmse:3.79325\ttrain-rmse:1.94862\n",
      "[29025]\teval-rmse:3.79305\ttrain-rmse:1.94859\n",
      "[29026]\teval-rmse:3.79254\ttrain-rmse:1.9486\n",
      "[29027]\teval-rmse:3.79378\ttrain-rmse:1.94859\n",
      "[29028]\teval-rmse:3.7936\ttrain-rmse:1.94859\n",
      "[29029]\teval-rmse:3.79236\ttrain-rmse:1.9486\n",
      "[29030]\teval-rmse:3.79363\ttrain-rmse:1.94859\n",
      "[29031]\teval-rmse:3.79495\ttrain-rmse:1.94859\n",
      "[29032]\teval-rmse:3.79371\ttrain-rmse:1.94859\n",
      "[29033]\teval-rmse:3.7935\ttrain-rmse:1.9486\n",
      "[29034]\teval-rmse:3.79429\ttrain-rmse:1.94858\n",
      "[29035]\teval-rmse:3.79255\ttrain-rmse:1.94859\n",
      "[29036]\teval-rmse:3.79098\ttrain-rmse:1.94861\n",
      "[29037]\teval-rmse:3.79079\ttrain-rmse:1.94857\n",
      "[29038]\teval-rmse:3.79133\ttrain-rmse:1.94856\n",
      "[29039]\teval-rmse:3.7901\ttrain-rmse:1.9486\n",
      "[29040]\teval-rmse:3.78881\ttrain-rmse:1.94863\n",
      "[29041]\teval-rmse:3.78863\ttrain-rmse:1.9486\n",
      "[29042]\teval-rmse:3.78917\ttrain-rmse:1.94859\n",
      "[29043]\teval-rmse:3.7894\ttrain-rmse:1.94858\n",
      "[29044]\teval-rmse:3.78937\ttrain-rmse:1.94858\n",
      "[29045]\teval-rmse:3.79015\ttrain-rmse:1.94857\n",
      "[29046]\teval-rmse:3.79069\ttrain-rmse:1.94857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29047]\teval-rmse:3.79195\ttrain-rmse:1.94856\n",
      "[29048]\teval-rmse:3.79245\ttrain-rmse:1.94855\n",
      "[29049]\teval-rmse:3.79402\ttrain-rmse:1.94854\n",
      "[29050]\teval-rmse:3.79401\ttrain-rmse:1.94854\n",
      "[29051]\teval-rmse:3.79438\ttrain-rmse:1.94854\n",
      "[29052]\teval-rmse:3.79563\ttrain-rmse:1.94854\n",
      "[29053]\teval-rmse:3.79462\ttrain-rmse:1.94856\n",
      "[29054]\teval-rmse:3.79596\ttrain-rmse:1.94857\n",
      "[29055]\teval-rmse:3.79468\ttrain-rmse:1.94857\n",
      "[29056]\teval-rmse:3.79624\ttrain-rmse:1.94857\n",
      "[29057]\teval-rmse:3.79571\ttrain-rmse:1.94857\n",
      "[29058]\teval-rmse:3.79699\ttrain-rmse:1.94859\n",
      "[29059]\teval-rmse:3.79697\ttrain-rmse:1.94859\n",
      "[29060]\teval-rmse:3.7973\ttrain-rmse:1.9486\n",
      "[29061]\teval-rmse:3.79711\ttrain-rmse:1.9486\n",
      "[29062]\teval-rmse:3.7955\ttrain-rmse:1.94859\n",
      "[29063]\teval-rmse:3.79377\ttrain-rmse:1.94857\n",
      "[29064]\teval-rmse:3.79479\ttrain-rmse:1.94858\n",
      "[29065]\teval-rmse:3.79478\ttrain-rmse:1.94858\n",
      "[29066]\teval-rmse:3.7966\ttrain-rmse:1.94855\n",
      "[29067]\teval-rmse:3.79714\ttrain-rmse:1.94856\n",
      "[29068]\teval-rmse:3.79695\ttrain-rmse:1.94852\n",
      "[29069]\teval-rmse:3.79746\ttrain-rmse:1.94853\n",
      "[29070]\teval-rmse:3.79595\ttrain-rmse:1.9485\n",
      "[29071]\teval-rmse:3.79519\ttrain-rmse:1.9485\n",
      "[29072]\teval-rmse:3.79501\ttrain-rmse:1.94846\n",
      "[29073]\teval-rmse:3.79482\ttrain-rmse:1.94843\n",
      "[29074]\teval-rmse:3.79585\ttrain-rmse:1.94844\n",
      "[29075]\teval-rmse:3.79564\ttrain-rmse:1.94844\n",
      "[29076]\teval-rmse:3.79441\ttrain-rmse:1.94845\n",
      "[29077]\teval-rmse:3.79386\ttrain-rmse:1.94846\n",
      "[29078]\teval-rmse:3.79261\ttrain-rmse:1.94846\n",
      "[29079]\teval-rmse:3.79418\ttrain-rmse:1.94845\n",
      "[29080]\teval-rmse:3.79463\ttrain-rmse:1.94846\n",
      "[29081]\teval-rmse:3.79645\ttrain-rmse:1.94843\n",
      "[29082]\teval-rmse:3.79602\ttrain-rmse:1.94843\n",
      "[29083]\teval-rmse:3.79477\ttrain-rmse:1.94841\n",
      "[29084]\teval-rmse:3.79605\ttrain-rmse:1.94842\n",
      "[29085]\teval-rmse:3.7956\ttrain-rmse:1.94841\n",
      "[29086]\teval-rmse:3.79508\ttrain-rmse:1.94841\n",
      "[29087]\teval-rmse:3.79489\ttrain-rmse:1.94841\n",
      "[29088]\teval-rmse:3.79648\ttrain-rmse:1.94839\n",
      "[29089]\teval-rmse:3.79807\ttrain-rmse:1.9484\n",
      "[29090]\teval-rmse:3.79683\ttrain-rmse:1.94841\n",
      "[29091]\teval-rmse:3.79737\ttrain-rmse:1.94842\n",
      "[29092]\teval-rmse:3.79715\ttrain-rmse:1.94838\n",
      "[29093]\teval-rmse:3.79671\ttrain-rmse:1.94837\n",
      "[29094]\teval-rmse:3.79796\ttrain-rmse:1.94838\n",
      "[29095]\teval-rmse:3.79815\ttrain-rmse:1.94839\n",
      "[29096]\teval-rmse:3.79794\ttrain-rmse:1.94838\n",
      "[29097]\teval-rmse:3.79616\ttrain-rmse:1.94836\n",
      "[29098]\teval-rmse:3.79492\ttrain-rmse:1.94836\n",
      "[29099]\teval-rmse:3.79651\ttrain-rmse:1.94834\n",
      "[29100]\teval-rmse:3.79598\ttrain-rmse:1.94834\n",
      "[29101]\teval-rmse:3.79472\ttrain-rmse:1.94834\n",
      "[29102]\teval-rmse:3.79502\ttrain-rmse:1.94834\n",
      "[29103]\teval-rmse:3.79605\ttrain-rmse:1.94835\n",
      "[29104]\teval-rmse:3.79528\ttrain-rmse:1.94835\n",
      "[29105]\teval-rmse:3.79628\ttrain-rmse:1.94836\n",
      "[29106]\teval-rmse:3.79445\ttrain-rmse:1.94834\n",
      "[29107]\teval-rmse:3.79286\ttrain-rmse:1.94834\n",
      "[29108]\teval-rmse:3.79266\ttrain-rmse:1.94834\n",
      "[29109]\teval-rmse:3.79416\ttrain-rmse:1.94834\n",
      "[29110]\teval-rmse:3.79493\ttrain-rmse:1.94832\n",
      "[29111]\teval-rmse:3.79516\ttrain-rmse:1.94833\n",
      "[29112]\teval-rmse:3.79566\ttrain-rmse:1.94833\n",
      "[29113]\teval-rmse:3.79723\ttrain-rmse:1.94833\n",
      "[29114]\teval-rmse:3.79598\ttrain-rmse:1.94833\n",
      "[29115]\teval-rmse:3.79597\ttrain-rmse:1.94833\n",
      "[29116]\teval-rmse:3.79578\ttrain-rmse:1.94833\n",
      "[29117]\teval-rmse:3.79704\ttrain-rmse:1.94834\n",
      "[29118]\teval-rmse:3.79552\ttrain-rmse:1.94833\n",
      "[29119]\teval-rmse:3.79372\ttrain-rmse:1.94833\n",
      "[29120]\teval-rmse:3.7933\ttrain-rmse:1.94833\n",
      "[29121]\teval-rmse:3.79373\ttrain-rmse:1.94833\n",
      "[29122]\teval-rmse:3.79369\ttrain-rmse:1.94833\n",
      "[29123]\teval-rmse:3.79511\ttrain-rmse:1.94834\n",
      "[29124]\teval-rmse:3.79492\ttrain-rmse:1.9483\n",
      "[29125]\teval-rmse:3.79437\ttrain-rmse:1.9483\n",
      "[29126]\teval-rmse:3.79258\ttrain-rmse:1.9483\n",
      "[29127]\teval-rmse:3.7944\ttrain-rmse:1.94826\n",
      "[29128]\teval-rmse:3.79313\ttrain-rmse:1.94827\n",
      "[29129]\teval-rmse:3.79366\ttrain-rmse:1.94827\n",
      "[29130]\teval-rmse:3.79468\ttrain-rmse:1.94827\n",
      "[29131]\teval-rmse:3.79443\ttrain-rmse:1.94827\n",
      "[29132]\teval-rmse:3.79497\ttrain-rmse:1.94827\n",
      "[29133]\teval-rmse:3.79477\ttrain-rmse:1.94824\n",
      "[29134]\teval-rmse:3.79422\ttrain-rmse:1.94824\n",
      "[29135]\teval-rmse:3.79478\ttrain-rmse:1.94824\n",
      "[29136]\teval-rmse:3.79403\ttrain-rmse:1.94824\n",
      "[29137]\teval-rmse:3.79553\ttrain-rmse:1.94825\n",
      "[29138]\teval-rmse:3.79534\ttrain-rmse:1.94822\n",
      "[29139]\teval-rmse:3.79353\ttrain-rmse:1.94821\n",
      "[29140]\teval-rmse:3.7923\ttrain-rmse:1.94823\n",
      "[29141]\teval-rmse:3.79179\ttrain-rmse:1.94824\n",
      "[29142]\teval-rmse:3.79207\ttrain-rmse:1.94824\n",
      "[29143]\teval-rmse:3.79389\ttrain-rmse:1.9482\n",
      "[29144]\teval-rmse:3.79434\ttrain-rmse:1.9482\n",
      "[29145]\teval-rmse:3.79562\ttrain-rmse:1.94821\n",
      "[29146]\teval-rmse:3.79405\ttrain-rmse:1.94822\n",
      "[29147]\teval-rmse:3.79282\ttrain-rmse:1.94821\n",
      "[29148]\teval-rmse:3.79439\ttrain-rmse:1.94822\n",
      "[29149]\teval-rmse:3.79412\ttrain-rmse:1.94822\n",
      "[29150]\teval-rmse:3.79386\ttrain-rmse:1.94822\n",
      "[29151]\teval-rmse:3.79519\ttrain-rmse:1.94822\n",
      "[29152]\teval-rmse:3.79391\ttrain-rmse:1.94822\n",
      "[29153]\teval-rmse:3.79371\ttrain-rmse:1.94823\n",
      "[29154]\teval-rmse:3.79398\ttrain-rmse:1.94823\n",
      "[29155]\teval-rmse:3.79453\ttrain-rmse:1.94823\n",
      "[29156]\teval-rmse:3.79507\ttrain-rmse:1.94823\n",
      "[29157]\teval-rmse:3.79464\ttrain-rmse:1.94823\n",
      "[29158]\teval-rmse:3.79363\ttrain-rmse:1.94825\n",
      "[29159]\teval-rmse:3.79288\ttrain-rmse:1.94825\n",
      "[29160]\teval-rmse:3.7947\ttrain-rmse:1.94821\n",
      "[29161]\teval-rmse:3.79393\ttrain-rmse:1.94822\n",
      "[29162]\teval-rmse:3.79211\ttrain-rmse:1.94822\n",
      "[29163]\teval-rmse:3.79265\ttrain-rmse:1.94821\n",
      "[29164]\teval-rmse:3.79221\ttrain-rmse:1.94822\n",
      "[29165]\teval-rmse:3.79274\ttrain-rmse:1.94821\n",
      "[29166]\teval-rmse:3.79297\ttrain-rmse:1.94821\n",
      "[29167]\teval-rmse:3.7942\ttrain-rmse:1.9482\n",
      "[29168]\teval-rmse:3.79546\ttrain-rmse:1.9482\n",
      "[29169]\teval-rmse:3.79671\ttrain-rmse:1.9482\n",
      "[29170]\teval-rmse:3.79853\ttrain-rmse:1.94819\n",
      "[29171]\teval-rmse:3.7977\ttrain-rmse:1.94818\n",
      "[29172]\teval-rmse:3.79591\ttrain-rmse:1.94817\n",
      "[29173]\teval-rmse:3.79389\ttrain-rmse:1.94817\n",
      "[29174]\teval-rmse:3.7954\ttrain-rmse:1.94816\n",
      "[29175]\teval-rmse:3.79439\ttrain-rmse:1.94818\n",
      "[29176]\teval-rmse:3.79282\ttrain-rmse:1.94819\n",
      "[29177]\teval-rmse:3.79306\ttrain-rmse:1.94819\n",
      "[29178]\teval-rmse:3.79288\ttrain-rmse:1.94819\n",
      "[29179]\teval-rmse:3.79111\ttrain-rmse:1.94821\n",
      "[29180]\teval-rmse:3.79135\ttrain-rmse:1.94821\n",
      "[29181]\teval-rmse:3.79109\ttrain-rmse:1.94821\n",
      "[29182]\teval-rmse:3.79235\ttrain-rmse:1.9482\n",
      "[29183]\teval-rmse:3.79257\ttrain-rmse:1.94819\n",
      "[29184]\teval-rmse:3.79134\ttrain-rmse:1.94821\n",
      "[29185]\teval-rmse:3.79114\ttrain-rmse:1.94817\n",
      "[29186]\teval-rmse:3.78958\ttrain-rmse:1.94819\n",
      "[29187]\teval-rmse:3.79007\ttrain-rmse:1.94819\n",
      "[29188]\teval-rmse:3.78973\ttrain-rmse:1.94819\n",
      "[29189]\teval-rmse:3.78851\ttrain-rmse:1.94823\n",
      "[29190]\teval-rmse:3.78732\ttrain-rmse:1.94826\n",
      "[29191]\teval-rmse:3.78861\ttrain-rmse:1.94822\n",
      "[29192]\teval-rmse:3.79008\ttrain-rmse:1.9482\n",
      "[29193]\teval-rmse:3.79143\ttrain-rmse:1.94818\n",
      "[29194]\teval-rmse:3.79196\ttrain-rmse:1.94818\n",
      "[29195]\teval-rmse:3.79239\ttrain-rmse:1.94818\n",
      "[29196]\teval-rmse:3.79317\ttrain-rmse:1.94816\n",
      "[29197]\teval-rmse:3.79391\ttrain-rmse:1.94816\n",
      "[29198]\teval-rmse:3.7934\ttrain-rmse:1.94816\n",
      "[29199]\teval-rmse:3.79143\ttrain-rmse:1.94817\n",
      "[29200]\teval-rmse:3.79124\ttrain-rmse:1.94813\n",
      "[29201]\teval-rmse:3.79105\ttrain-rmse:1.9481\n",
      "[29202]\teval-rmse:3.79131\ttrain-rmse:1.9481\n",
      "[29203]\teval-rmse:3.79162\ttrain-rmse:1.9481\n",
      "[29204]\teval-rmse:3.79145\ttrain-rmse:1.9481\n",
      "[29205]\teval-rmse:3.79169\ttrain-rmse:1.9481\n",
      "[29206]\teval-rmse:3.79214\ttrain-rmse:1.9481\n",
      "[29207]\teval-rmse:3.79165\ttrain-rmse:1.94811\n",
      "[29208]\teval-rmse:3.79089\ttrain-rmse:1.94812\n",
      "[29209]\teval-rmse:3.79086\ttrain-rmse:1.94812\n",
      "[29210]\teval-rmse:3.7919\ttrain-rmse:1.9481\n",
      "[29211]\teval-rmse:3.79146\ttrain-rmse:1.94811\n",
      "[29212]\teval-rmse:3.79262\ttrain-rmse:1.94811\n",
      "[29213]\teval-rmse:3.79104\ttrain-rmse:1.94812\n",
      "[29214]\teval-rmse:3.79005\ttrain-rmse:1.94815\n",
      "[29215]\teval-rmse:3.78922\ttrain-rmse:1.94815\n",
      "[29216]\teval-rmse:3.78802\ttrain-rmse:1.94817\n",
      "[29217]\teval-rmse:3.78962\ttrain-rmse:1.94814\n",
      "[29218]\teval-rmse:3.78985\ttrain-rmse:1.94814\n",
      "[29219]\teval-rmse:3.78865\ttrain-rmse:1.94816\n",
      "[29220]\teval-rmse:3.78723\ttrain-rmse:1.94818\n",
      "[29221]\teval-rmse:3.7865\ttrain-rmse:1.9482\n",
      "[29222]\teval-rmse:3.78529\ttrain-rmse:1.94823\n",
      "[29223]\teval-rmse:3.7845\ttrain-rmse:1.94825\n",
      "[29224]\teval-rmse:3.78436\ttrain-rmse:1.94826\n",
      "[29225]\teval-rmse:3.78412\ttrain-rmse:1.94826\n",
      "[29226]\teval-rmse:3.78468\ttrain-rmse:1.94825\n",
      "[29227]\teval-rmse:3.78342\ttrain-rmse:1.94829\n",
      "[29228]\teval-rmse:3.78366\ttrain-rmse:1.94828\n",
      "[29229]\teval-rmse:3.78238\ttrain-rmse:1.94833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29230]\teval-rmse:3.78166\ttrain-rmse:1.94836\n",
      "[29231]\teval-rmse:3.78018\ttrain-rmse:1.94842\n",
      "[29232]\teval-rmse:3.77846\ttrain-rmse:1.9485\n",
      "[29233]\teval-rmse:3.78029\ttrain-rmse:1.94841\n",
      "[29234]\teval-rmse:3.78156\ttrain-rmse:1.94835\n",
      "[29235]\teval-rmse:3.78338\ttrain-rmse:1.94828\n",
      "[29236]\teval-rmse:3.78292\ttrain-rmse:1.9483\n",
      "[29237]\teval-rmse:3.7828\ttrain-rmse:1.94826\n",
      "[29238]\teval-rmse:3.78121\ttrain-rmse:1.94832\n",
      "[29239]\teval-rmse:3.78007\ttrain-rmse:1.94837\n",
      "[29240]\teval-rmse:3.78189\ttrain-rmse:1.94829\n",
      "[29241]\teval-rmse:3.78293\ttrain-rmse:1.94824\n",
      "[29242]\teval-rmse:3.78445\ttrain-rmse:1.94819\n",
      "[29243]\teval-rmse:3.78325\ttrain-rmse:1.94823\n",
      "[29244]\teval-rmse:3.78205\ttrain-rmse:1.94828\n",
      "[29245]\teval-rmse:3.78111\ttrain-rmse:1.94833\n",
      "[29246]\teval-rmse:3.78068\ttrain-rmse:1.94835\n",
      "[29247]\teval-rmse:3.78047\ttrain-rmse:1.94836\n",
      "[29248]\teval-rmse:3.78229\ttrain-rmse:1.94828\n",
      "[29249]\teval-rmse:3.78088\ttrain-rmse:1.94835\n",
      "[29250]\teval-rmse:3.78145\ttrain-rmse:1.94832\n",
      "[29251]\teval-rmse:3.782\ttrain-rmse:1.94829\n",
      "[29252]\teval-rmse:3.78103\ttrain-rmse:1.94834\n",
      "[29253]\teval-rmse:3.78052\ttrain-rmse:1.94836\n",
      "[29254]\teval-rmse:3.7803\ttrain-rmse:1.94837\n",
      "[29255]\teval-rmse:3.78187\ttrain-rmse:1.9483\n",
      "[29256]\teval-rmse:3.78346\ttrain-rmse:1.94822\n",
      "[29257]\teval-rmse:3.78432\ttrain-rmse:1.94818\n",
      "[29258]\teval-rmse:3.78466\ttrain-rmse:1.94817\n",
      "[29259]\teval-rmse:3.78426\ttrain-rmse:1.94819\n",
      "[29260]\teval-rmse:3.78403\ttrain-rmse:1.9482\n",
      "[29261]\teval-rmse:3.78532\ttrain-rmse:1.94815\n",
      "[29262]\teval-rmse:3.78516\ttrain-rmse:1.94816\n",
      "[29263]\teval-rmse:3.78632\ttrain-rmse:1.94812\n",
      "[29264]\teval-rmse:3.78767\ttrain-rmse:1.94808\n",
      "[29265]\teval-rmse:3.78639\ttrain-rmse:1.94812\n",
      "[29266]\teval-rmse:3.78589\ttrain-rmse:1.94813\n",
      "[29267]\teval-rmse:3.78624\ttrain-rmse:1.94812\n",
      "[29268]\teval-rmse:3.78583\ttrain-rmse:1.94813\n",
      "[29269]\teval-rmse:3.78716\ttrain-rmse:1.9481\n",
      "[29270]\teval-rmse:3.78598\ttrain-rmse:1.94813\n",
      "[29271]\teval-rmse:3.78619\ttrain-rmse:1.94813\n",
      "[29272]\teval-rmse:3.78574\ttrain-rmse:1.94814\n",
      "[29273]\teval-rmse:3.78698\ttrain-rmse:1.94811\n",
      "[29274]\teval-rmse:3.78652\ttrain-rmse:1.94813\n",
      "[29275]\teval-rmse:3.78678\ttrain-rmse:1.94812\n",
      "[29276]\teval-rmse:3.78837\ttrain-rmse:1.94806\n",
      "[29277]\teval-rmse:3.78997\ttrain-rmse:1.94802\n",
      "[29278]\teval-rmse:3.79178\ttrain-rmse:1.94797\n",
      "[29279]\teval-rmse:3.79224\ttrain-rmse:1.94797\n",
      "[29280]\teval-rmse:3.79248\ttrain-rmse:1.94797\n",
      "[29281]\teval-rmse:3.79229\ttrain-rmse:1.94797\n",
      "[29282]\teval-rmse:3.7941\ttrain-rmse:1.94794\n",
      "[29283]\teval-rmse:3.79278\ttrain-rmse:1.94796\n",
      "[29284]\teval-rmse:3.79155\ttrain-rmse:1.94798\n",
      "[29285]\teval-rmse:3.79233\ttrain-rmse:1.94797\n",
      "[29286]\teval-rmse:3.79133\ttrain-rmse:1.94799\n",
      "[29287]\teval-rmse:3.79059\ttrain-rmse:1.948\n",
      "[29288]\teval-rmse:3.79079\ttrain-rmse:1.948\n",
      "[29289]\teval-rmse:3.79216\ttrain-rmse:1.94798\n",
      "[29290]\teval-rmse:3.79163\ttrain-rmse:1.94799\n",
      "[29291]\teval-rmse:3.79241\ttrain-rmse:1.94798\n",
      "[29292]\teval-rmse:3.79298\ttrain-rmse:1.94797\n",
      "[29293]\teval-rmse:3.79142\ttrain-rmse:1.94799\n",
      "[29294]\teval-rmse:3.78989\ttrain-rmse:1.94801\n",
      "[29295]\teval-rmse:3.78971\ttrain-rmse:1.94802\n",
      "[29296]\teval-rmse:3.78945\ttrain-rmse:1.94802\n",
      "[29297]\teval-rmse:3.78971\ttrain-rmse:1.94802\n",
      "[29298]\teval-rmse:3.78996\ttrain-rmse:1.94801\n",
      "[29299]\teval-rmse:3.78868\ttrain-rmse:1.94805\n",
      "[29300]\teval-rmse:3.78852\ttrain-rmse:1.94806\n",
      "[29301]\teval-rmse:3.7889\ttrain-rmse:1.94805\n",
      "[29302]\teval-rmse:3.78766\ttrain-rmse:1.94808\n",
      "[29303]\teval-rmse:3.78613\ttrain-rmse:1.94813\n",
      "[29304]\teval-rmse:3.78598\ttrain-rmse:1.94813\n",
      "[29305]\teval-rmse:3.7878\ttrain-rmse:1.94807\n",
      "[29306]\teval-rmse:3.78782\ttrain-rmse:1.94807\n",
      "[29307]\teval-rmse:3.78685\ttrain-rmse:1.9481\n",
      "[29308]\teval-rmse:3.78762\ttrain-rmse:1.94808\n",
      "[29309]\teval-rmse:3.7892\ttrain-rmse:1.94804\n",
      "[29310]\teval-rmse:3.78799\ttrain-rmse:1.94807\n",
      "[29311]\teval-rmse:3.78784\ttrain-rmse:1.94803\n",
      "[29312]\teval-rmse:3.78817\ttrain-rmse:1.94802\n",
      "[29313]\teval-rmse:3.78944\ttrain-rmse:1.94799\n",
      "[29314]\teval-rmse:3.79068\ttrain-rmse:1.94797\n",
      "[29315]\teval-rmse:3.79104\ttrain-rmse:1.94797\n",
      "[29316]\teval-rmse:3.79264\ttrain-rmse:1.94793\n",
      "[29317]\teval-rmse:3.79117\ttrain-rmse:1.94795\n",
      "[29318]\teval-rmse:3.79168\ttrain-rmse:1.94795\n",
      "[29319]\teval-rmse:3.79293\ttrain-rmse:1.94794\n",
      "[29320]\teval-rmse:3.79162\ttrain-rmse:1.94795\n",
      "[29321]\teval-rmse:3.79033\ttrain-rmse:1.94797\n",
      "[29322]\teval-rmse:3.79016\ttrain-rmse:1.94798\n",
      "[29323]\teval-rmse:3.79043\ttrain-rmse:1.94797\n",
      "[29324]\teval-rmse:3.79193\ttrain-rmse:1.94796\n",
      "[29325]\teval-rmse:3.79143\ttrain-rmse:1.94797\n",
      "[29326]\teval-rmse:3.79273\ttrain-rmse:1.94796\n",
      "[29327]\teval-rmse:3.79407\ttrain-rmse:1.94797\n",
      "[29328]\teval-rmse:3.79424\ttrain-rmse:1.94797\n",
      "[29329]\teval-rmse:3.79547\ttrain-rmse:1.94798\n",
      "[29330]\teval-rmse:3.79389\ttrain-rmse:1.94798\n",
      "[29331]\teval-rmse:3.79513\ttrain-rmse:1.94798\n",
      "[29332]\teval-rmse:3.79645\ttrain-rmse:1.94797\n",
      "[29333]\teval-rmse:3.79511\ttrain-rmse:1.94798\n",
      "[29334]\teval-rmse:3.79362\ttrain-rmse:1.94799\n",
      "[29335]\teval-rmse:3.79214\ttrain-rmse:1.948\n",
      "[29336]\teval-rmse:3.79292\ttrain-rmse:1.94801\n",
      "[29337]\teval-rmse:3.79272\ttrain-rmse:1.94798\n",
      "[29338]\teval-rmse:3.79092\ttrain-rmse:1.94798\n",
      "[29339]\teval-rmse:3.79145\ttrain-rmse:1.94798\n",
      "[29340]\teval-rmse:3.79165\ttrain-rmse:1.94798\n",
      "[29341]\teval-rmse:3.79115\ttrain-rmse:1.94798\n",
      "[29342]\teval-rmse:3.7924\ttrain-rmse:1.94797\n",
      "[29343]\teval-rmse:3.79198\ttrain-rmse:1.94797\n",
      "[29344]\teval-rmse:3.79379\ttrain-rmse:1.94794\n",
      "[29345]\teval-rmse:3.7953\ttrain-rmse:1.94791\n",
      "[29346]\teval-rmse:3.79679\ttrain-rmse:1.94793\n",
      "[29347]\teval-rmse:3.79555\ttrain-rmse:1.94794\n",
      "[29348]\teval-rmse:3.79583\ttrain-rmse:1.94794\n",
      "[29349]\teval-rmse:3.79764\ttrain-rmse:1.94797\n",
      "[29350]\teval-rmse:3.79914\ttrain-rmse:1.94798\n",
      "[29351]\teval-rmse:3.79862\ttrain-rmse:1.94797\n",
      "[29352]\teval-rmse:3.79963\ttrain-rmse:1.948\n",
      "[29353]\teval-rmse:3.80007\ttrain-rmse:1.94801\n",
      "[29354]\teval-rmse:3.79872\ttrain-rmse:1.94799\n",
      "[29355]\teval-rmse:3.79747\ttrain-rmse:1.94799\n",
      "[29356]\teval-rmse:3.79798\ttrain-rmse:1.94799\n",
      "[29357]\teval-rmse:3.79979\ttrain-rmse:1.94798\n",
      "[29358]\teval-rmse:3.8008\ttrain-rmse:1.94801\n",
      "[29359]\teval-rmse:3.8023\ttrain-rmse:1.94806\n",
      "[29360]\teval-rmse:3.80063\ttrain-rmse:1.94801\n",
      "[29361]\teval-rmse:3.79903\ttrain-rmse:1.94799\n",
      "[29362]\teval-rmse:3.79778\ttrain-rmse:1.94799\n",
      "[29363]\teval-rmse:3.79938\ttrain-rmse:1.948\n",
      "[29364]\teval-rmse:3.79958\ttrain-rmse:1.948\n",
      "[29365]\teval-rmse:3.80115\ttrain-rmse:1.94801\n",
      "[29366]\teval-rmse:3.80239\ttrain-rmse:1.94806\n",
      "[29367]\teval-rmse:3.80395\ttrain-rmse:1.94809\n",
      "[29368]\teval-rmse:3.80576\ttrain-rmse:1.9481\n",
      "[29369]\teval-rmse:3.80446\ttrain-rmse:1.94804\n",
      "[29370]\teval-rmse:3.80487\ttrain-rmse:1.94806\n",
      "[29371]\teval-rmse:3.80323\ttrain-rmse:1.94802\n",
      "[29372]\teval-rmse:3.80457\ttrain-rmse:1.94808\n",
      "[29373]\teval-rmse:3.80292\ttrain-rmse:1.94804\n",
      "[29374]\teval-rmse:3.80268\ttrain-rmse:1.94804\n",
      "[29375]\teval-rmse:3.80401\ttrain-rmse:1.94809\n",
      "[29376]\teval-rmse:3.80262\ttrain-rmse:1.94804\n",
      "[29377]\teval-rmse:3.80338\ttrain-rmse:1.94807\n",
      "[29378]\teval-rmse:3.80307\ttrain-rmse:1.94806\n",
      "[29379]\teval-rmse:3.80325\ttrain-rmse:1.94807\n",
      "[29380]\teval-rmse:3.80483\ttrain-rmse:1.94811\n",
      "[29381]\teval-rmse:3.80586\ttrain-rmse:1.94816\n",
      "[29382]\teval-rmse:3.80456\ttrain-rmse:1.94814\n",
      "[29383]\teval-rmse:3.80473\ttrain-rmse:1.94815\n",
      "[29384]\teval-rmse:3.80393\ttrain-rmse:1.94813\n",
      "[29385]\teval-rmse:3.80444\ttrain-rmse:1.94814\n",
      "[29386]\teval-rmse:3.80304\ttrain-rmse:1.94812\n",
      "[29387]\teval-rmse:3.80377\ttrain-rmse:1.94813\n",
      "[29388]\teval-rmse:3.80457\ttrain-rmse:1.94817\n",
      "[29389]\teval-rmse:3.80325\ttrain-rmse:1.94814\n",
      "[29390]\teval-rmse:3.8027\ttrain-rmse:1.94812\n",
      "[29391]\teval-rmse:3.80133\ttrain-rmse:1.94811\n",
      "[29392]\teval-rmse:3.79973\ttrain-rmse:1.94806\n",
      "[29393]\teval-rmse:3.80132\ttrain-rmse:1.94805\n",
      "[29394]\teval-rmse:3.80236\ttrain-rmse:1.94809\n",
      "[29395]\teval-rmse:3.8019\ttrain-rmse:1.94808\n",
      "[29396]\teval-rmse:3.80061\ttrain-rmse:1.94808\n",
      "[29397]\teval-rmse:3.80073\ttrain-rmse:1.94809\n",
      "[29398]\teval-rmse:3.79921\ttrain-rmse:1.94808\n",
      "[29399]\teval-rmse:3.79915\ttrain-rmse:1.94808\n",
      "[29400]\teval-rmse:3.79956\ttrain-rmse:1.94809\n",
      "[29401]\teval-rmse:3.79955\ttrain-rmse:1.94809\n",
      "[29402]\teval-rmse:3.80103\ttrain-rmse:1.9481\n",
      "[29403]\teval-rmse:3.80079\ttrain-rmse:1.9481\n",
      "[29404]\teval-rmse:3.80034\ttrain-rmse:1.9481\n",
      "[29405]\teval-rmse:3.80054\ttrain-rmse:1.94811\n",
      "[29406]\teval-rmse:3.80008\ttrain-rmse:1.94809\n",
      "[29407]\teval-rmse:3.79978\ttrain-rmse:1.94809\n",
      "[29408]\teval-rmse:3.80135\ttrain-rmse:1.94815\n",
      "[29409]\teval-rmse:3.80083\ttrain-rmse:1.94814\n",
      "[29410]\teval-rmse:3.79972\ttrain-rmse:1.9481\n",
      "[29411]\teval-rmse:3.80024\ttrain-rmse:1.94812\n",
      "[29412]\teval-rmse:3.79894\ttrain-rmse:1.94811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29413]\teval-rmse:3.79948\ttrain-rmse:1.94812\n",
      "[29414]\teval-rmse:3.80074\ttrain-rmse:1.94812\n",
      "[29415]\teval-rmse:3.79913\ttrain-rmse:1.94807\n",
      "[29416]\teval-rmse:3.79778\ttrain-rmse:1.94804\n",
      "[29417]\teval-rmse:3.79618\ttrain-rmse:1.94802\n",
      "[29418]\teval-rmse:3.79597\ttrain-rmse:1.94799\n",
      "[29419]\teval-rmse:3.79617\ttrain-rmse:1.94799\n",
      "[29420]\teval-rmse:3.79598\ttrain-rmse:1.94795\n",
      "[29421]\teval-rmse:3.7944\ttrain-rmse:1.94793\n",
      "[29422]\teval-rmse:3.79598\ttrain-rmse:1.94792\n",
      "[29423]\teval-rmse:3.79758\ttrain-rmse:1.94792\n",
      "[29424]\teval-rmse:3.79751\ttrain-rmse:1.94792\n",
      "[29425]\teval-rmse:3.79675\ttrain-rmse:1.9479\n",
      "[29426]\teval-rmse:3.79706\ttrain-rmse:1.94791\n",
      "[29427]\teval-rmse:3.79808\ttrain-rmse:1.94793\n",
      "[29428]\teval-rmse:3.79753\ttrain-rmse:1.94792\n",
      "[29429]\teval-rmse:3.79733\ttrain-rmse:1.94793\n",
      "[29430]\teval-rmse:3.79666\ttrain-rmse:1.94791\n",
      "[29431]\teval-rmse:3.79548\ttrain-rmse:1.94791\n",
      "[29432]\teval-rmse:3.79697\ttrain-rmse:1.94792\n",
      "[29433]\teval-rmse:3.79642\ttrain-rmse:1.94791\n",
      "[29434]\teval-rmse:3.79694\ttrain-rmse:1.94791\n",
      "[29435]\teval-rmse:3.79569\ttrain-rmse:1.94792\n",
      "[29436]\teval-rmse:3.79517\ttrain-rmse:1.94792\n",
      "[29437]\teval-rmse:3.79537\ttrain-rmse:1.94792\n",
      "[29438]\teval-rmse:3.79588\ttrain-rmse:1.94792\n",
      "[29439]\teval-rmse:3.79623\ttrain-rmse:1.94792\n",
      "[29440]\teval-rmse:3.79748\ttrain-rmse:1.94795\n",
      "[29441]\teval-rmse:3.79729\ttrain-rmse:1.94791\n",
      "[29442]\teval-rmse:3.79577\ttrain-rmse:1.94788\n",
      "[29443]\teval-rmse:3.79476\ttrain-rmse:1.9479\n",
      "[29444]\teval-rmse:3.79455\ttrain-rmse:1.9479\n",
      "[29445]\teval-rmse:3.79475\ttrain-rmse:1.9479\n",
      "[29446]\teval-rmse:3.79318\ttrain-rmse:1.94789\n",
      "[29447]\teval-rmse:3.79137\ttrain-rmse:1.94789\n",
      "[29448]\teval-rmse:3.79251\ttrain-rmse:1.94789\n",
      "[29449]\teval-rmse:3.79199\ttrain-rmse:1.94789\n",
      "[29450]\teval-rmse:3.79038\ttrain-rmse:1.9479\n",
      "[29451]\teval-rmse:3.79219\ttrain-rmse:1.94786\n",
      "[29452]\teval-rmse:3.79089\ttrain-rmse:1.94789\n",
      "[29453]\teval-rmse:3.79134\ttrain-rmse:1.94787\n",
      "[29454]\teval-rmse:3.79035\ttrain-rmse:1.9479\n",
      "[29455]\teval-rmse:3.79174\ttrain-rmse:1.94789\n",
      "[29456]\teval-rmse:3.79134\ttrain-rmse:1.94789\n",
      "[29457]\teval-rmse:3.79261\ttrain-rmse:1.94789\n",
      "[29458]\teval-rmse:3.79233\ttrain-rmse:1.9479\n",
      "[29459]\teval-rmse:3.79286\ttrain-rmse:1.9479\n",
      "[29460]\teval-rmse:3.79266\ttrain-rmse:1.94786\n",
      "[29461]\teval-rmse:3.79381\ttrain-rmse:1.94786\n",
      "[29462]\teval-rmse:3.79249\ttrain-rmse:1.94787\n",
      "[29463]\teval-rmse:3.79094\ttrain-rmse:1.9479\n",
      "[29464]\teval-rmse:3.79124\ttrain-rmse:1.94789\n",
      "[29465]\teval-rmse:3.79177\ttrain-rmse:1.94788\n",
      "[29466]\teval-rmse:3.79021\ttrain-rmse:1.94789\n",
      "[29467]\teval-rmse:3.78948\ttrain-rmse:1.9479\n",
      "[29468]\teval-rmse:3.78994\ttrain-rmse:1.9479\n",
      "[29469]\teval-rmse:3.7898\ttrain-rmse:1.9479\n",
      "[29470]\teval-rmse:3.79107\ttrain-rmse:1.94787\n",
      "[29471]\teval-rmse:3.79265\ttrain-rmse:1.94783\n",
      "[29472]\teval-rmse:3.79247\ttrain-rmse:1.94783\n",
      "[29473]\teval-rmse:3.79395\ttrain-rmse:1.94782\n",
      "[29474]\teval-rmse:3.79415\ttrain-rmse:1.94782\n",
      "[29475]\teval-rmse:3.79463\ttrain-rmse:1.94782\n",
      "[29476]\teval-rmse:3.79588\ttrain-rmse:1.94783\n",
      "[29477]\teval-rmse:3.79536\ttrain-rmse:1.94784\n",
      "[29478]\teval-rmse:3.79693\ttrain-rmse:1.94783\n",
      "[29479]\teval-rmse:3.79689\ttrain-rmse:1.94783\n",
      "[29480]\teval-rmse:3.79613\ttrain-rmse:1.94784\n",
      "[29481]\teval-rmse:3.79478\ttrain-rmse:1.94784\n",
      "[29482]\teval-rmse:3.79426\ttrain-rmse:1.94785\n",
      "[29483]\teval-rmse:3.79278\ttrain-rmse:1.94786\n",
      "[29484]\teval-rmse:3.79157\ttrain-rmse:1.94788\n",
      "[29485]\teval-rmse:3.79285\ttrain-rmse:1.94786\n",
      "[29486]\teval-rmse:3.79441\ttrain-rmse:1.94785\n",
      "[29487]\teval-rmse:3.79484\ttrain-rmse:1.94785\n",
      "[29488]\teval-rmse:3.79352\ttrain-rmse:1.94788\n",
      "[29489]\teval-rmse:3.79206\ttrain-rmse:1.9479\n",
      "[29490]\teval-rmse:3.79355\ttrain-rmse:1.94788\n",
      "[29491]\teval-rmse:3.7921\ttrain-rmse:1.9479\n",
      "[29492]\teval-rmse:3.79182\ttrain-rmse:1.9479\n",
      "[29493]\teval-rmse:3.79363\ttrain-rmse:1.94787\n",
      "[29494]\teval-rmse:3.79214\ttrain-rmse:1.94788\n",
      "[29495]\teval-rmse:3.79141\ttrain-rmse:1.9479\n",
      "[29496]\teval-rmse:3.79266\ttrain-rmse:1.9479\n",
      "[29497]\teval-rmse:3.79423\ttrain-rmse:1.94787\n",
      "[29498]\teval-rmse:3.79323\ttrain-rmse:1.94789\n",
      "[29499]\teval-rmse:3.79483\ttrain-rmse:1.94787\n",
      "[29500]\teval-rmse:3.79438\ttrain-rmse:1.94787\n",
      "[29501]\teval-rmse:3.79516\ttrain-rmse:1.94787\n",
      "[29502]\teval-rmse:3.79629\ttrain-rmse:1.94789\n",
      "[29503]\teval-rmse:3.79671\ttrain-rmse:1.94789\n",
      "[29504]\teval-rmse:3.79724\ttrain-rmse:1.94789\n",
      "[29505]\teval-rmse:3.79565\ttrain-rmse:1.9479\n",
      "[29506]\teval-rmse:3.79585\ttrain-rmse:1.9479\n",
      "[29507]\teval-rmse:3.79508\ttrain-rmse:1.94789\n",
      "[29508]\teval-rmse:3.79407\ttrain-rmse:1.94791\n",
      "[29509]\teval-rmse:3.79259\ttrain-rmse:1.94793\n",
      "[29510]\teval-rmse:3.79302\ttrain-rmse:1.94793\n",
      "[29511]\teval-rmse:3.79449\ttrain-rmse:1.94791\n",
      "[29512]\teval-rmse:3.79407\ttrain-rmse:1.9479\n",
      "[29513]\teval-rmse:3.79257\ttrain-rmse:1.94792\n",
      "[29514]\teval-rmse:3.79102\ttrain-rmse:1.94795\n",
      "[29515]\teval-rmse:3.7918\ttrain-rmse:1.94792\n",
      "[29516]\teval-rmse:3.79055\ttrain-rmse:1.94792\n",
      "[29517]\teval-rmse:3.79205\ttrain-rmse:1.94789\n",
      "[29518]\teval-rmse:3.79226\ttrain-rmse:1.94789\n",
      "[29519]\teval-rmse:3.79178\ttrain-rmse:1.9479\n",
      "[29520]\teval-rmse:3.79329\ttrain-rmse:1.94786\n",
      "[29521]\teval-rmse:3.7931\ttrain-rmse:1.94787\n",
      "[29522]\teval-rmse:3.79309\ttrain-rmse:1.94787\n",
      "[29523]\teval-rmse:3.79137\ttrain-rmse:1.94786\n",
      "[29524]\teval-rmse:3.7927\ttrain-rmse:1.94784\n",
      "[29525]\teval-rmse:3.7925\ttrain-rmse:1.94781\n",
      "[29526]\teval-rmse:3.79209\ttrain-rmse:1.94782\n",
      "[29527]\teval-rmse:3.79251\ttrain-rmse:1.94782\n",
      "[29528]\teval-rmse:3.79093\ttrain-rmse:1.94782\n",
      "[29529]\teval-rmse:3.7909\ttrain-rmse:1.94782\n",
      "[29530]\teval-rmse:3.78966\ttrain-rmse:1.94784\n",
      "[29531]\teval-rmse:3.79124\ttrain-rmse:1.94781\n",
      "[29532]\teval-rmse:3.78952\ttrain-rmse:1.94782\n",
      "[29533]\teval-rmse:3.78831\ttrain-rmse:1.94786\n",
      "[29534]\teval-rmse:3.78861\ttrain-rmse:1.94785\n",
      "[29535]\teval-rmse:3.78939\ttrain-rmse:1.94784\n",
      "[29536]\teval-rmse:3.78818\ttrain-rmse:1.94788\n",
      "[29537]\teval-rmse:3.78771\ttrain-rmse:1.94789\n",
      "[29538]\teval-rmse:3.78756\ttrain-rmse:1.94789\n",
      "[29539]\teval-rmse:3.78659\ttrain-rmse:1.94792\n",
      "[29540]\teval-rmse:3.78646\ttrain-rmse:1.94792\n",
      "[29541]\teval-rmse:3.78517\ttrain-rmse:1.94795\n",
      "[29542]\teval-rmse:3.78503\ttrain-rmse:1.94792\n",
      "[29543]\teval-rmse:3.78629\ttrain-rmse:1.94787\n",
      "[29544]\teval-rmse:3.7865\ttrain-rmse:1.94787\n",
      "[29545]\teval-rmse:3.78633\ttrain-rmse:1.94783\n",
      "[29546]\teval-rmse:3.78685\ttrain-rmse:1.94783\n",
      "[29547]\teval-rmse:3.78647\ttrain-rmse:1.94784\n",
      "[29548]\teval-rmse:3.78676\ttrain-rmse:1.94783\n",
      "[29549]\teval-rmse:3.7863\ttrain-rmse:1.94785\n",
      "[29550]\teval-rmse:3.78613\ttrain-rmse:1.94781\n",
      "[29551]\teval-rmse:3.78492\ttrain-rmse:1.94783\n",
      "[29552]\teval-rmse:3.7865\ttrain-rmse:1.94777\n",
      "[29553]\teval-rmse:3.7868\ttrain-rmse:1.94777\n",
      "[29554]\teval-rmse:3.78839\ttrain-rmse:1.94772\n",
      "[29555]\teval-rmse:3.78823\ttrain-rmse:1.94773\n",
      "[29556]\teval-rmse:3.78922\ttrain-rmse:1.94772\n",
      "[29557]\teval-rmse:3.78905\ttrain-rmse:1.94772\n",
      "[29558]\teval-rmse:3.78856\ttrain-rmse:1.94773\n",
      "[29559]\teval-rmse:3.78679\ttrain-rmse:1.94775\n",
      "[29560]\teval-rmse:3.78678\ttrain-rmse:1.94775\n",
      "[29561]\teval-rmse:3.78755\ttrain-rmse:1.94774\n",
      "[29562]\teval-rmse:3.78915\ttrain-rmse:1.94771\n",
      "[29563]\teval-rmse:3.78897\ttrain-rmse:1.94767\n",
      "[29564]\teval-rmse:3.78775\ttrain-rmse:1.9477\n",
      "[29565]\teval-rmse:3.78887\ttrain-rmse:1.94769\n",
      "[29566]\teval-rmse:3.78789\ttrain-rmse:1.94772\n",
      "[29567]\teval-rmse:3.78844\ttrain-rmse:1.9477\n",
      "[29568]\teval-rmse:3.78826\ttrain-rmse:1.94771\n",
      "[29569]\teval-rmse:3.78705\ttrain-rmse:1.94774\n",
      "[29570]\teval-rmse:3.78608\ttrain-rmse:1.94777\n",
      "[29571]\teval-rmse:3.7879\ttrain-rmse:1.94771\n",
      "[29572]\teval-rmse:3.78891\ttrain-rmse:1.94769\n",
      "[29573]\teval-rmse:3.78991\ttrain-rmse:1.94769\n",
      "[29574]\teval-rmse:3.78861\ttrain-rmse:1.94771\n",
      "[29575]\teval-rmse:3.78915\ttrain-rmse:1.9477\n",
      "[29576]\teval-rmse:3.78897\ttrain-rmse:1.94767\n",
      "[29577]\teval-rmse:3.7895\ttrain-rmse:1.94766\n",
      "[29578]\teval-rmse:3.78779\ttrain-rmse:1.94766\n",
      "[29579]\teval-rmse:3.78921\ttrain-rmse:1.94765\n",
      "[29580]\teval-rmse:3.78902\ttrain-rmse:1.94766\n",
      "[29581]\teval-rmse:3.7883\ttrain-rmse:1.94766\n",
      "[29582]\teval-rmse:3.79011\ttrain-rmse:1.94761\n",
      "[29583]\teval-rmse:3.78815\ttrain-rmse:1.94763\n",
      "[29584]\teval-rmse:3.78693\ttrain-rmse:1.94766\n",
      "[29585]\teval-rmse:3.78668\ttrain-rmse:1.94767\n",
      "[29586]\teval-rmse:3.78597\ttrain-rmse:1.94769\n",
      "[29587]\teval-rmse:3.78676\ttrain-rmse:1.94767\n",
      "[29588]\teval-rmse:3.78834\ttrain-rmse:1.94765\n",
      "[29589]\teval-rmse:3.78704\ttrain-rmse:1.94768\n",
      "[29590]\teval-rmse:3.78781\ttrain-rmse:1.94767\n",
      "[29591]\teval-rmse:3.78808\ttrain-rmse:1.94767\n",
      "[29592]\teval-rmse:3.78782\ttrain-rmse:1.94768\n",
      "[29593]\teval-rmse:3.78709\ttrain-rmse:1.94769\n",
      "[29594]\teval-rmse:3.78581\ttrain-rmse:1.94774\n",
      "[29595]\teval-rmse:3.78612\ttrain-rmse:1.94773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29596]\teval-rmse:3.78569\ttrain-rmse:1.94774\n",
      "[29597]\teval-rmse:3.78506\ttrain-rmse:1.94775\n",
      "[29598]\teval-rmse:3.7863\ttrain-rmse:1.94771\n",
      "[29599]\teval-rmse:3.78709\ttrain-rmse:1.94769\n",
      "[29600]\teval-rmse:3.78733\ttrain-rmse:1.94769\n",
      "[29601]\teval-rmse:3.78891\ttrain-rmse:1.94765\n",
      "[29602]\teval-rmse:3.78992\ttrain-rmse:1.94764\n",
      "[29603]\teval-rmse:3.78966\ttrain-rmse:1.94765\n",
      "[29604]\teval-rmse:3.7895\ttrain-rmse:1.94765\n",
      "[29605]\teval-rmse:3.78964\ttrain-rmse:1.94765\n",
      "[29606]\teval-rmse:3.78945\ttrain-rmse:1.94765\n",
      "[29607]\teval-rmse:3.78994\ttrain-rmse:1.94765\n",
      "[29608]\teval-rmse:3.78874\ttrain-rmse:1.94767\n",
      "[29609]\teval-rmse:3.7889\ttrain-rmse:1.94767\n",
      "[29610]\teval-rmse:3.79071\ttrain-rmse:1.94763\n",
      "[29611]\teval-rmse:3.79222\ttrain-rmse:1.94759\n",
      "[29612]\teval-rmse:3.7935\ttrain-rmse:1.9476\n",
      "[29613]\teval-rmse:3.79226\ttrain-rmse:1.94762\n",
      "[29614]\teval-rmse:3.79104\ttrain-rmse:1.94765\n",
      "[29615]\teval-rmse:3.79054\ttrain-rmse:1.94765\n",
      "[29616]\teval-rmse:3.78897\ttrain-rmse:1.94766\n",
      "[29617]\teval-rmse:3.78871\ttrain-rmse:1.94766\n",
      "[29618]\teval-rmse:3.78902\ttrain-rmse:1.94766\n",
      "[29619]\teval-rmse:3.78938\ttrain-rmse:1.94765\n",
      "[29620]\teval-rmse:3.78898\ttrain-rmse:1.94766\n",
      "[29621]\teval-rmse:3.78751\ttrain-rmse:1.9477\n",
      "[29622]\teval-rmse:3.78907\ttrain-rmse:1.94765\n",
      "[29623]\teval-rmse:3.78777\ttrain-rmse:1.94768\n",
      "[29624]\teval-rmse:3.78853\ttrain-rmse:1.94768\n",
      "[29625]\teval-rmse:3.79003\ttrain-rmse:1.94763\n",
      "[29626]\teval-rmse:3.79129\ttrain-rmse:1.94763\n",
      "[29627]\teval-rmse:3.79261\ttrain-rmse:1.94764\n",
      "[29628]\teval-rmse:3.79284\ttrain-rmse:1.94764\n",
      "[29629]\teval-rmse:3.79242\ttrain-rmse:1.94765\n",
      "[29630]\teval-rmse:3.79088\ttrain-rmse:1.94764\n",
      "[29631]\teval-rmse:3.79211\ttrain-rmse:1.94764\n",
      "[29632]\teval-rmse:3.79237\ttrain-rmse:1.94765\n",
      "[29633]\teval-rmse:3.79388\ttrain-rmse:1.94761\n",
      "[29634]\teval-rmse:3.7937\ttrain-rmse:1.94761\n",
      "[29635]\teval-rmse:3.79214\ttrain-rmse:1.94763\n",
      "[29636]\teval-rmse:3.79234\ttrain-rmse:1.94763\n",
      "[29637]\teval-rmse:3.79113\ttrain-rmse:1.94765\n",
      "[29638]\teval-rmse:3.79063\ttrain-rmse:1.94766\n",
      "[29639]\teval-rmse:3.79209\ttrain-rmse:1.94766\n",
      "[29640]\teval-rmse:3.79109\ttrain-rmse:1.94768\n",
      "[29641]\teval-rmse:3.79129\ttrain-rmse:1.94769\n",
      "[29642]\teval-rmse:3.79111\ttrain-rmse:1.94769\n",
      "[29643]\teval-rmse:3.78933\ttrain-rmse:1.94772\n",
      "[29644]\teval-rmse:3.79091\ttrain-rmse:1.94768\n",
      "[29645]\teval-rmse:3.78961\ttrain-rmse:1.94772\n",
      "[29646]\teval-rmse:3.78935\ttrain-rmse:1.94772\n",
      "[29647]\teval-rmse:3.78959\ttrain-rmse:1.94772\n",
      "[29648]\teval-rmse:3.79118\ttrain-rmse:1.94767\n",
      "[29649]\teval-rmse:3.78919\ttrain-rmse:1.94767\n",
      "[29650]\teval-rmse:3.78939\ttrain-rmse:1.94767\n",
      "[29651]\teval-rmse:3.78784\ttrain-rmse:1.94768\n",
      "[29652]\teval-rmse:3.78887\ttrain-rmse:1.94767\n",
      "[29653]\teval-rmse:3.78693\ttrain-rmse:1.94769\n",
      "[29654]\teval-rmse:3.78808\ttrain-rmse:1.94768\n",
      "[29655]\teval-rmse:3.78944\ttrain-rmse:1.94765\n",
      "[29656]\teval-rmse:3.78774\ttrain-rmse:1.94767\n",
      "[29657]\teval-rmse:3.78756\ttrain-rmse:1.94763\n",
      "[29658]\teval-rmse:3.78777\ttrain-rmse:1.94763\n",
      "[29659]\teval-rmse:3.78647\ttrain-rmse:1.94766\n",
      "[29660]\teval-rmse:3.78805\ttrain-rmse:1.94762\n",
      "[29661]\teval-rmse:3.78954\ttrain-rmse:1.94758\n",
      "[29662]\teval-rmse:3.78797\ttrain-rmse:1.94759\n",
      "[29663]\teval-rmse:3.78779\ttrain-rmse:1.9476\n",
      "[29664]\teval-rmse:3.78763\ttrain-rmse:1.9476\n",
      "[29665]\teval-rmse:3.78747\ttrain-rmse:1.94761\n",
      "[29666]\teval-rmse:3.78675\ttrain-rmse:1.94762\n",
      "[29667]\teval-rmse:3.78833\ttrain-rmse:1.94758\n",
      "[29668]\teval-rmse:3.78888\ttrain-rmse:1.94756\n",
      "[29669]\teval-rmse:3.7887\ttrain-rmse:1.94753\n",
      "[29670]\teval-rmse:3.79026\ttrain-rmse:1.9475\n",
      "[29671]\teval-rmse:3.78903\ttrain-rmse:1.9475\n",
      "[29672]\teval-rmse:3.78749\ttrain-rmse:1.94754\n",
      "[29673]\teval-rmse:3.78804\ttrain-rmse:1.94753\n",
      "[29674]\teval-rmse:3.7886\ttrain-rmse:1.94751\n",
      "[29675]\teval-rmse:3.78971\ttrain-rmse:1.9475\n",
      "[29676]\teval-rmse:3.78952\ttrain-rmse:1.94748\n",
      "[29677]\teval-rmse:3.78935\ttrain-rmse:1.94748\n",
      "[29678]\teval-rmse:3.78909\ttrain-rmse:1.94748\n",
      "[29679]\teval-rmse:3.78779\ttrain-rmse:1.94751\n",
      "[29680]\teval-rmse:3.78583\ttrain-rmse:1.94755\n",
      "[29681]\teval-rmse:3.78634\ttrain-rmse:1.94753\n",
      "[29682]\teval-rmse:3.78481\ttrain-rmse:1.94756\n",
      "[29683]\teval-rmse:3.78385\ttrain-rmse:1.9476\n",
      "[29684]\teval-rmse:3.78266\ttrain-rmse:1.94763\n",
      "[29685]\teval-rmse:3.78402\ttrain-rmse:1.94758\n",
      "[29686]\teval-rmse:3.78284\ttrain-rmse:1.94762\n",
      "[29687]\teval-rmse:3.78387\ttrain-rmse:1.94759\n",
      "[29688]\teval-rmse:3.78349\ttrain-rmse:1.94761\n",
      "[29689]\teval-rmse:3.78379\ttrain-rmse:1.9476\n",
      "[29690]\teval-rmse:3.78259\ttrain-rmse:1.94765\n",
      "[29691]\teval-rmse:3.7828\ttrain-rmse:1.94764\n",
      "[29692]\teval-rmse:3.78462\ttrain-rmse:1.94757\n",
      "[29693]\teval-rmse:3.78516\ttrain-rmse:1.94756\n",
      "[29694]\teval-rmse:3.78539\ttrain-rmse:1.94755\n",
      "[29695]\teval-rmse:3.78573\ttrain-rmse:1.94754\n",
      "[29696]\teval-rmse:3.78732\ttrain-rmse:1.94749\n",
      "[29697]\teval-rmse:3.78565\ttrain-rmse:1.94753\n",
      "[29698]\teval-rmse:3.78596\ttrain-rmse:1.94752\n",
      "[29699]\teval-rmse:3.78548\ttrain-rmse:1.94754\n",
      "[29700]\teval-rmse:3.7842\ttrain-rmse:1.94757\n",
      "[29701]\teval-rmse:3.78474\ttrain-rmse:1.94755\n",
      "[29702]\teval-rmse:3.78601\ttrain-rmse:1.94752\n",
      "[29703]\teval-rmse:3.78645\ttrain-rmse:1.94751\n",
      "[29704]\teval-rmse:3.78777\ttrain-rmse:1.94749\n",
      "[29705]\teval-rmse:3.78658\ttrain-rmse:1.94753\n",
      "[29706]\teval-rmse:3.78643\ttrain-rmse:1.94749\n",
      "[29707]\teval-rmse:3.78719\ttrain-rmse:1.94747\n",
      "[29708]\teval-rmse:3.78859\ttrain-rmse:1.94745\n",
      "[29709]\teval-rmse:3.78819\ttrain-rmse:1.94747\n",
      "[29710]\teval-rmse:3.78953\ttrain-rmse:1.94746\n",
      "[29711]\teval-rmse:3.79078\ttrain-rmse:1.94746\n",
      "[29712]\teval-rmse:3.79236\ttrain-rmse:1.94744\n",
      "[29713]\teval-rmse:3.79418\ttrain-rmse:1.94741\n",
      "[29714]\teval-rmse:3.79442\ttrain-rmse:1.94742\n",
      "[29715]\teval-rmse:3.7934\ttrain-rmse:1.94743\n",
      "[29716]\teval-rmse:3.79319\ttrain-rmse:1.94743\n",
      "[29717]\teval-rmse:3.79316\ttrain-rmse:1.94743\n",
      "[29718]\teval-rmse:3.79344\ttrain-rmse:1.94744\n",
      "[29719]\teval-rmse:3.79302\ttrain-rmse:1.94744\n",
      "[29720]\teval-rmse:3.79331\ttrain-rmse:1.94744\n",
      "[29721]\teval-rmse:3.79255\ttrain-rmse:1.94744\n",
      "[29722]\teval-rmse:3.79059\ttrain-rmse:1.94743\n",
      "[29723]\teval-rmse:3.79207\ttrain-rmse:1.94742\n",
      "[29724]\teval-rmse:3.79355\ttrain-rmse:1.9474\n",
      "[29725]\teval-rmse:3.79479\ttrain-rmse:1.9474\n",
      "[29726]\teval-rmse:3.79428\ttrain-rmse:1.9474\n",
      "[29727]\teval-rmse:3.79409\ttrain-rmse:1.94736\n",
      "[29728]\teval-rmse:3.79284\ttrain-rmse:1.94737\n",
      "[29729]\teval-rmse:3.79266\ttrain-rmse:1.94733\n",
      "[29730]\teval-rmse:3.79319\ttrain-rmse:1.94734\n",
      "[29731]\teval-rmse:3.79275\ttrain-rmse:1.94734\n",
      "[29732]\teval-rmse:3.79255\ttrain-rmse:1.94731\n",
      "[29733]\teval-rmse:3.79131\ttrain-rmse:1.94733\n",
      "[29734]\teval-rmse:3.79208\ttrain-rmse:1.94731\n",
      "[29735]\teval-rmse:3.79156\ttrain-rmse:1.94732\n",
      "[29736]\teval-rmse:3.79284\ttrain-rmse:1.94733\n",
      "[29737]\teval-rmse:3.79234\ttrain-rmse:1.94733\n",
      "[29738]\teval-rmse:3.79367\ttrain-rmse:1.94735\n",
      "[29739]\teval-rmse:3.79265\ttrain-rmse:1.94736\n",
      "[29740]\teval-rmse:3.79133\ttrain-rmse:1.94738\n",
      "[29741]\teval-rmse:3.79191\ttrain-rmse:1.94738\n",
      "[29742]\teval-rmse:3.7914\ttrain-rmse:1.94738\n",
      "[29743]\teval-rmse:3.79193\ttrain-rmse:1.94739\n",
      "[29744]\teval-rmse:3.79173\ttrain-rmse:1.94739\n",
      "[29745]\teval-rmse:3.7904\ttrain-rmse:1.94738\n",
      "[29746]\teval-rmse:3.78907\ttrain-rmse:1.94737\n",
      "[29747]\teval-rmse:3.78881\ttrain-rmse:1.94738\n",
      "[29748]\teval-rmse:3.78902\ttrain-rmse:1.94738\n",
      "[29749]\teval-rmse:3.78933\ttrain-rmse:1.94738\n",
      "[29750]\teval-rmse:3.78884\ttrain-rmse:1.94738\n",
      "[29751]\teval-rmse:3.78962\ttrain-rmse:1.94736\n",
      "[29752]\teval-rmse:3.78914\ttrain-rmse:1.94737\n",
      "[29753]\teval-rmse:3.78763\ttrain-rmse:1.9474\n",
      "[29754]\teval-rmse:3.78807\ttrain-rmse:1.94739\n",
      "[29755]\teval-rmse:3.78735\ttrain-rmse:1.94739\n",
      "[29756]\teval-rmse:3.78686\ttrain-rmse:1.94741\n",
      "[29757]\teval-rmse:3.7867\ttrain-rmse:1.94741\n",
      "[29758]\teval-rmse:3.78722\ttrain-rmse:1.94741\n",
      "[29759]\teval-rmse:3.78592\ttrain-rmse:1.94742\n",
      "[29760]\teval-rmse:3.78546\ttrain-rmse:1.94743\n",
      "[29761]\teval-rmse:3.78573\ttrain-rmse:1.94743\n",
      "[29762]\teval-rmse:3.78533\ttrain-rmse:1.94744\n",
      "[29763]\teval-rmse:3.78355\ttrain-rmse:1.94748\n",
      "[29764]\teval-rmse:3.78431\ttrain-rmse:1.94746\n",
      "[29765]\teval-rmse:3.78534\ttrain-rmse:1.94744\n",
      "[29766]\teval-rmse:3.78407\ttrain-rmse:1.94746\n",
      "[29767]\teval-rmse:3.78383\ttrain-rmse:1.94747\n",
      "[29768]\teval-rmse:3.78367\ttrain-rmse:1.94744\n",
      "[29769]\teval-rmse:3.785\ttrain-rmse:1.94742\n",
      "[29770]\teval-rmse:3.78616\ttrain-rmse:1.9474\n",
      "[29771]\teval-rmse:3.78553\ttrain-rmse:1.94741\n",
      "[29772]\teval-rmse:3.78528\ttrain-rmse:1.94741\n",
      "[29773]\teval-rmse:3.7861\ttrain-rmse:1.94741\n",
      "[29774]\teval-rmse:3.78744\ttrain-rmse:1.94741\n",
      "[29775]\teval-rmse:3.78726\ttrain-rmse:1.94741\n",
      "[29776]\teval-rmse:3.78575\ttrain-rmse:1.94745\n",
      "[29777]\teval-rmse:3.78421\ttrain-rmse:1.94746\n",
      "[29778]\teval-rmse:3.785\ttrain-rmse:1.94744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29779]\teval-rmse:3.78462\ttrain-rmse:1.94745\n",
      "[29780]\teval-rmse:3.78317\ttrain-rmse:1.9475\n",
      "[29781]\teval-rmse:3.78395\ttrain-rmse:1.94747\n",
      "[29782]\teval-rmse:3.78205\ttrain-rmse:1.94751\n",
      "[29783]\teval-rmse:3.78136\ttrain-rmse:1.94754\n",
      "[29784]\teval-rmse:3.78269\ttrain-rmse:1.94748\n",
      "[29785]\teval-rmse:3.78254\ttrain-rmse:1.94749\n",
      "[29786]\teval-rmse:3.78104\ttrain-rmse:1.94755\n",
      "[29787]\teval-rmse:3.78228\ttrain-rmse:1.94752\n",
      "[29788]\teval-rmse:3.78393\ttrain-rmse:1.94749\n",
      "[29789]\teval-rmse:3.78265\ttrain-rmse:1.94754\n",
      "[29790]\teval-rmse:3.78423\ttrain-rmse:1.94748\n",
      "[29791]\teval-rmse:3.78399\ttrain-rmse:1.94749\n",
      "[29792]\teval-rmse:3.7827\ttrain-rmse:1.94752\n",
      "[29793]\teval-rmse:3.78121\ttrain-rmse:1.94757\n",
      "[29794]\teval-rmse:3.78138\ttrain-rmse:1.94757\n",
      "[29795]\teval-rmse:3.78191\ttrain-rmse:1.94756\n",
      "[29796]\teval-rmse:3.78143\ttrain-rmse:1.94758\n",
      "[29797]\teval-rmse:3.78247\ttrain-rmse:1.94756\n",
      "[29798]\teval-rmse:3.78098\ttrain-rmse:1.94762\n",
      "[29799]\teval-rmse:3.78144\ttrain-rmse:1.9476\n",
      "[29800]\teval-rmse:3.78143\ttrain-rmse:1.94761\n",
      "[29801]\teval-rmse:3.78179\ttrain-rmse:1.9476\n",
      "[29802]\teval-rmse:3.78132\ttrain-rmse:1.94762\n",
      "[29803]\teval-rmse:3.78062\ttrain-rmse:1.94765\n",
      "[29804]\teval-rmse:3.77946\ttrain-rmse:1.9477\n",
      "[29805]\teval-rmse:3.7783\ttrain-rmse:1.94776\n",
      "[29806]\teval-rmse:3.77965\ttrain-rmse:1.94769\n",
      "[29807]\teval-rmse:3.78092\ttrain-rmse:1.94764\n",
      "[29808]\teval-rmse:3.78274\ttrain-rmse:1.94756\n",
      "[29809]\teval-rmse:3.78293\ttrain-rmse:1.94756\n",
      "[29810]\teval-rmse:3.7837\ttrain-rmse:1.94753\n",
      "[29811]\teval-rmse:3.78357\ttrain-rmse:1.94753\n",
      "[29812]\teval-rmse:3.78483\ttrain-rmse:1.94752\n",
      "[29813]\teval-rmse:3.78478\ttrain-rmse:1.94752\n",
      "[29814]\teval-rmse:3.78383\ttrain-rmse:1.94755\n",
      "[29815]\teval-rmse:3.78359\ttrain-rmse:1.94756\n",
      "[29816]\teval-rmse:3.7823\ttrain-rmse:1.94761\n",
      "[29817]\teval-rmse:3.78253\ttrain-rmse:1.9476\n",
      "[29818]\teval-rmse:3.78206\ttrain-rmse:1.94762\n",
      "[29819]\teval-rmse:3.78331\ttrain-rmse:1.9476\n",
      "[29820]\teval-rmse:3.78384\ttrain-rmse:1.94759\n",
      "[29821]\teval-rmse:3.78508\ttrain-rmse:1.94759\n",
      "[29822]\teval-rmse:3.78617\ttrain-rmse:1.94758\n",
      "[29823]\teval-rmse:3.78671\ttrain-rmse:1.94759\n",
      "[29824]\teval-rmse:3.78598\ttrain-rmse:1.94761\n",
      "[29825]\teval-rmse:3.78695\ttrain-rmse:1.94761\n",
      "[29826]\teval-rmse:3.78824\ttrain-rmse:1.94762\n",
      "[29827]\teval-rmse:3.78954\ttrain-rmse:1.94763\n",
      "[29828]\teval-rmse:3.78824\ttrain-rmse:1.94766\n",
      "[29829]\teval-rmse:3.78983\ttrain-rmse:1.94762\n",
      "[29830]\teval-rmse:3.79002\ttrain-rmse:1.94762\n",
      "[29831]\teval-rmse:3.79161\ttrain-rmse:1.94759\n",
      "[29832]\teval-rmse:3.79039\ttrain-rmse:1.9476\n",
      "[29833]\teval-rmse:3.79113\ttrain-rmse:1.94759\n",
      "[29834]\teval-rmse:3.78991\ttrain-rmse:1.9476\n",
      "[29835]\teval-rmse:3.78868\ttrain-rmse:1.94761\n",
      "[29836]\teval-rmse:3.78893\ttrain-rmse:1.94762\n",
      "[29837]\teval-rmse:3.7904\ttrain-rmse:1.9476\n",
      "[29838]\teval-rmse:3.78884\ttrain-rmse:1.94757\n",
      "[29839]\teval-rmse:3.78927\ttrain-rmse:1.94757\n",
      "[29840]\teval-rmse:3.789\ttrain-rmse:1.94758\n",
      "[29841]\teval-rmse:3.7877\ttrain-rmse:1.94761\n",
      "[29842]\teval-rmse:3.78802\ttrain-rmse:1.94761\n",
      "[29843]\teval-rmse:3.78856\ttrain-rmse:1.9476\n",
      "[29844]\teval-rmse:3.78808\ttrain-rmse:1.94761\n",
      "[29845]\teval-rmse:3.78842\ttrain-rmse:1.94762\n",
      "[29846]\teval-rmse:3.78868\ttrain-rmse:1.94762\n",
      "[29847]\teval-rmse:3.79025\ttrain-rmse:1.94759\n",
      "[29848]\teval-rmse:3.78973\ttrain-rmse:1.9476\n",
      "[29849]\teval-rmse:3.79097\ttrain-rmse:1.94758\n",
      "[29850]\teval-rmse:3.79118\ttrain-rmse:1.94758\n",
      "[29851]\teval-rmse:3.7925\ttrain-rmse:1.94762\n",
      "[29852]\teval-rmse:3.7943\ttrain-rmse:1.94759\n",
      "[29853]\teval-rmse:3.79329\ttrain-rmse:1.9476\n",
      "[29854]\teval-rmse:3.79409\ttrain-rmse:1.94763\n",
      "[29855]\teval-rmse:3.79388\ttrain-rmse:1.94763\n",
      "[29856]\teval-rmse:3.79438\ttrain-rmse:1.94765\n",
      "[29857]\teval-rmse:3.79386\ttrain-rmse:1.94764\n",
      "[29858]\teval-rmse:3.79253\ttrain-rmse:1.94765\n",
      "[29859]\teval-rmse:3.79097\ttrain-rmse:1.94766\n",
      "[29860]\teval-rmse:3.79246\ttrain-rmse:1.94764\n",
      "[29861]\teval-rmse:3.79295\ttrain-rmse:1.94766\n",
      "[29862]\teval-rmse:3.79135\ttrain-rmse:1.94761\n",
      "[29863]\teval-rmse:3.79292\ttrain-rmse:1.9476\n",
      "[29864]\teval-rmse:3.79238\ttrain-rmse:1.9476\n",
      "[29865]\teval-rmse:3.79219\ttrain-rmse:1.94758\n",
      "[29866]\teval-rmse:3.79199\ttrain-rmse:1.94758\n",
      "[29867]\teval-rmse:3.79051\ttrain-rmse:1.94759\n",
      "[29868]\teval-rmse:3.79032\ttrain-rmse:1.94756\n",
      "[29869]\teval-rmse:3.7919\ttrain-rmse:1.94753\n",
      "[29870]\teval-rmse:3.79162\ttrain-rmse:1.94753\n",
      "[29871]\teval-rmse:3.79121\ttrain-rmse:1.94754\n",
      "[29872]\teval-rmse:3.79174\ttrain-rmse:1.94753\n",
      "[29873]\teval-rmse:3.79156\ttrain-rmse:1.94754\n",
      "[29874]\teval-rmse:3.79033\ttrain-rmse:1.94755\n",
      "[29875]\teval-rmse:3.79147\ttrain-rmse:1.94757\n",
      "[29876]\teval-rmse:3.79023\ttrain-rmse:1.94758\n",
      "[29877]\teval-rmse:3.79143\ttrain-rmse:1.9476\n",
      "[29878]\teval-rmse:3.79068\ttrain-rmse:1.94759\n",
      "[29879]\teval-rmse:3.79201\ttrain-rmse:1.94763\n",
      "[29880]\teval-rmse:3.79382\ttrain-rmse:1.9476\n",
      "[29881]\teval-rmse:3.79362\ttrain-rmse:1.94757\n",
      "[29882]\teval-rmse:3.79469\ttrain-rmse:1.9476\n",
      "[29883]\teval-rmse:3.79593\ttrain-rmse:1.9476\n",
      "[29884]\teval-rmse:3.79624\ttrain-rmse:1.94761\n",
      "[29885]\teval-rmse:3.79619\ttrain-rmse:1.94761\n",
      "[29886]\teval-rmse:3.79567\ttrain-rmse:1.94761\n",
      "[29887]\teval-rmse:3.79465\ttrain-rmse:1.94762\n",
      "[29888]\teval-rmse:3.79444\ttrain-rmse:1.94761\n",
      "[29889]\teval-rmse:3.79244\ttrain-rmse:1.94756\n",
      "[29890]\teval-rmse:3.79226\ttrain-rmse:1.94756\n",
      "[29891]\teval-rmse:3.79102\ttrain-rmse:1.94753\n",
      "[29892]\teval-rmse:3.78969\ttrain-rmse:1.9475\n",
      "[29893]\teval-rmse:3.78896\ttrain-rmse:1.94751\n",
      "[29894]\teval-rmse:3.78741\ttrain-rmse:1.94754\n",
      "[29895]\teval-rmse:3.78761\ttrain-rmse:1.94754\n",
      "[29896]\teval-rmse:3.78663\ttrain-rmse:1.94756\n",
      "[29897]\teval-rmse:3.78794\ttrain-rmse:1.94758\n",
      "[29898]\teval-rmse:3.78745\ttrain-rmse:1.94759\n",
      "[29899]\teval-rmse:3.78742\ttrain-rmse:1.94759\n",
      "[29900]\teval-rmse:3.78866\ttrain-rmse:1.94757\n",
      "[29901]\teval-rmse:3.78824\ttrain-rmse:1.94757\n",
      "[29902]\teval-rmse:3.78853\ttrain-rmse:1.94757\n",
      "[29903]\teval-rmse:3.79012\ttrain-rmse:1.94755\n",
      "[29904]\teval-rmse:3.78962\ttrain-rmse:1.94755\n",
      "[29905]\teval-rmse:3.79013\ttrain-rmse:1.94756\n",
      "[29906]\teval-rmse:3.78963\ttrain-rmse:1.94757\n",
      "[29907]\teval-rmse:3.78814\ttrain-rmse:1.94754\n",
      "[29908]\teval-rmse:3.78668\ttrain-rmse:1.94757\n",
      "[29909]\teval-rmse:3.78722\ttrain-rmse:1.94756\n",
      "[29910]\teval-rmse:3.78567\ttrain-rmse:1.94754\n",
      "[29911]\teval-rmse:3.78619\ttrain-rmse:1.94753\n",
      "[29912]\teval-rmse:3.78602\ttrain-rmse:1.94753\n",
      "[29913]\teval-rmse:3.7871\ttrain-rmse:1.94754\n",
      "[29914]\teval-rmse:3.78579\ttrain-rmse:1.94753\n",
      "[29915]\teval-rmse:3.78434\ttrain-rmse:1.94757\n",
      "[29916]\teval-rmse:3.78288\ttrain-rmse:1.94758\n",
      "[29917]\teval-rmse:3.78413\ttrain-rmse:1.94754\n",
      "[29918]\teval-rmse:3.78367\ttrain-rmse:1.94756\n",
      "[29919]\teval-rmse:3.78272\ttrain-rmse:1.94757\n",
      "[29920]\teval-rmse:3.78177\ttrain-rmse:1.9476\n",
      "[29921]\teval-rmse:3.78302\ttrain-rmse:1.94756\n",
      "[29922]\teval-rmse:3.78404\ttrain-rmse:1.94755\n",
      "[29923]\teval-rmse:3.78505\ttrain-rmse:1.94752\n",
      "[29924]\teval-rmse:3.78565\ttrain-rmse:1.94752\n",
      "[29925]\teval-rmse:3.78551\ttrain-rmse:1.94752\n",
      "[29926]\teval-rmse:3.78711\ttrain-rmse:1.94748\n",
      "[29927]\teval-rmse:3.78891\ttrain-rmse:1.94744\n",
      "[29928]\teval-rmse:3.78923\ttrain-rmse:1.94744\n",
      "[29929]\teval-rmse:3.78851\ttrain-rmse:1.94745\n",
      "[29930]\teval-rmse:3.78834\ttrain-rmse:1.94742\n",
      "[29931]\teval-rmse:3.78853\ttrain-rmse:1.94742\n",
      "[29932]\teval-rmse:3.78953\ttrain-rmse:1.94744\n",
      "[29933]\teval-rmse:3.78823\ttrain-rmse:1.94746\n",
      "[29934]\teval-rmse:3.78979\ttrain-rmse:1.94743\n",
      "[29935]\teval-rmse:3.78858\ttrain-rmse:1.94746\n",
      "[29936]\teval-rmse:3.78726\ttrain-rmse:1.94748\n",
      "[29937]\teval-rmse:3.78686\ttrain-rmse:1.94749\n",
      "[29938]\teval-rmse:3.78822\ttrain-rmse:1.94747\n",
      "[29939]\teval-rmse:3.78774\ttrain-rmse:1.94748\n",
      "[29940]\teval-rmse:3.78733\ttrain-rmse:1.94748\n",
      "[29941]\teval-rmse:3.7879\ttrain-rmse:1.94748\n",
      "[29942]\teval-rmse:3.78928\ttrain-rmse:1.94751\n",
      "[29943]\teval-rmse:3.78888\ttrain-rmse:1.94751\n",
      "[29944]\teval-rmse:3.7884\ttrain-rmse:1.94752\n",
      "[29945]\teval-rmse:3.78716\ttrain-rmse:1.94754\n",
      "[29946]\teval-rmse:3.78701\ttrain-rmse:1.94751\n",
      "[29947]\teval-rmse:3.78506\ttrain-rmse:1.94751\n",
      "[29948]\teval-rmse:3.7849\ttrain-rmse:1.94748\n",
      "[29949]\teval-rmse:3.78441\ttrain-rmse:1.94749\n",
      "[29950]\teval-rmse:3.78314\ttrain-rmse:1.94754\n",
      "[29951]\teval-rmse:3.78367\ttrain-rmse:1.94752\n",
      "[29952]\teval-rmse:3.78548\ttrain-rmse:1.94746\n",
      "[29953]\teval-rmse:3.78569\ttrain-rmse:1.94747\n",
      "[29954]\teval-rmse:3.7862\ttrain-rmse:1.94747\n",
      "[29955]\teval-rmse:3.78664\ttrain-rmse:1.94747\n",
      "[29956]\teval-rmse:3.78845\ttrain-rmse:1.94742\n",
      "[29957]\teval-rmse:3.78827\ttrain-rmse:1.94742\n",
      "[29958]\teval-rmse:3.78879\ttrain-rmse:1.94743\n",
      "[29959]\teval-rmse:3.79037\ttrain-rmse:1.94741\n",
      "[29960]\teval-rmse:3.78904\ttrain-rmse:1.94739\n",
      "[29961]\teval-rmse:3.78831\ttrain-rmse:1.94741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29962]\teval-rmse:3.7899\ttrain-rmse:1.94737\n",
      "[29963]\teval-rmse:3.78859\ttrain-rmse:1.94739\n",
      "[29964]\teval-rmse:3.78761\ttrain-rmse:1.94742\n",
      "[29965]\teval-rmse:3.78686\ttrain-rmse:1.94741\n",
      "[29966]\teval-rmse:3.78643\ttrain-rmse:1.94741\n",
      "[29967]\teval-rmse:3.78463\ttrain-rmse:1.94741\n",
      "[29968]\teval-rmse:3.78612\ttrain-rmse:1.94737\n",
      "[29969]\teval-rmse:3.78792\ttrain-rmse:1.94732\n",
      "[29970]\teval-rmse:3.78915\ttrain-rmse:1.94732\n",
      "[29971]\teval-rmse:3.78792\ttrain-rmse:1.94735\n",
      "[29972]\teval-rmse:3.7884\ttrain-rmse:1.94735\n",
      "[29973]\teval-rmse:3.78972\ttrain-rmse:1.94737\n",
      "[29974]\teval-rmse:3.7885\ttrain-rmse:1.9474\n",
      "[29975]\teval-rmse:3.78725\ttrain-rmse:1.94739\n",
      "[29976]\teval-rmse:3.7877\ttrain-rmse:1.94738\n",
      "[29977]\teval-rmse:3.7873\ttrain-rmse:1.94739\n",
      "[29978]\teval-rmse:3.7883\ttrain-rmse:1.9474\n",
      "[29979]\teval-rmse:3.78955\ttrain-rmse:1.94742\n",
      "[29980]\teval-rmse:3.79112\ttrain-rmse:1.94741\n",
      "[29981]\teval-rmse:3.79093\ttrain-rmse:1.94741\n",
      "[29982]\teval-rmse:3.79052\ttrain-rmse:1.94741\n",
      "[29983]\teval-rmse:3.7921\ttrain-rmse:1.9474\n",
      "[29984]\teval-rmse:3.79338\ttrain-rmse:1.94743\n",
      "[29985]\teval-rmse:3.79309\ttrain-rmse:1.94743\n",
      "[29986]\teval-rmse:3.79176\ttrain-rmse:1.94743\n",
      "[29987]\teval-rmse:3.79149\ttrain-rmse:1.94744\n",
      "[29988]\teval-rmse:3.79283\ttrain-rmse:1.94743\n",
      "[29989]\teval-rmse:3.79148\ttrain-rmse:1.94744\n",
      "[29990]\teval-rmse:3.79222\ttrain-rmse:1.94743\n",
      "[29991]\teval-rmse:3.79087\ttrain-rmse:1.94744\n",
      "[29992]\teval-rmse:3.78963\ttrain-rmse:1.94745\n",
      "[29993]\teval-rmse:3.78816\ttrain-rmse:1.94747\n",
      "[29994]\teval-rmse:3.78717\ttrain-rmse:1.94749\n",
      "[29995]\teval-rmse:3.78826\ttrain-rmse:1.94751\n",
      "[29996]\teval-rmse:3.78853\ttrain-rmse:1.94752\n",
      "[29997]\teval-rmse:3.78699\ttrain-rmse:1.94754\n",
      "[29998]\teval-rmse:3.78825\ttrain-rmse:1.94752\n",
      "[29999]\teval-rmse:3.78975\ttrain-rmse:1.9475\n",
      "[30000]\teval-rmse:3.78851\ttrain-rmse:1.94751\n",
      "[30001]\teval-rmse:3.78836\ttrain-rmse:1.94751\n",
      "[30002]\teval-rmse:3.78678\ttrain-rmse:1.94749\n",
      "[30003]\teval-rmse:3.78597\ttrain-rmse:1.94749\n",
      "[30004]\teval-rmse:3.78583\ttrain-rmse:1.94749\n",
      "[30005]\teval-rmse:3.78741\ttrain-rmse:1.94745\n",
      "[30006]\teval-rmse:3.78891\ttrain-rmse:1.94741\n",
      "[30007]\teval-rmse:3.7877\ttrain-rmse:1.94743\n",
      "[30008]\teval-rmse:3.78903\ttrain-rmse:1.9474\n",
      "[30009]\teval-rmse:3.79061\ttrain-rmse:1.94738\n",
      "[30010]\teval-rmse:3.79138\ttrain-rmse:1.94737\n",
      "[30011]\teval-rmse:3.79013\ttrain-rmse:1.94739\n",
      "[30012]\teval-rmse:3.78841\ttrain-rmse:1.94736\n",
      "[30013]\teval-rmse:3.78967\ttrain-rmse:1.94735\n",
      "[30014]\teval-rmse:3.78893\ttrain-rmse:1.94735\n",
      "[30015]\teval-rmse:3.78876\ttrain-rmse:1.94736\n",
      "[30016]\teval-rmse:3.78858\ttrain-rmse:1.94736\n",
      "[30017]\teval-rmse:3.78981\ttrain-rmse:1.94735\n",
      "[30018]\teval-rmse:3.78858\ttrain-rmse:1.94737\n",
      "[30019]\teval-rmse:3.78727\ttrain-rmse:1.94739\n",
      "[30020]\teval-rmse:3.78629\ttrain-rmse:1.94741\n",
      "[30021]\teval-rmse:3.7881\ttrain-rmse:1.94737\n",
      "[30022]\teval-rmse:3.78662\ttrain-rmse:1.94736\n",
      "[30023]\teval-rmse:3.78739\ttrain-rmse:1.94735\n",
      "[30024]\teval-rmse:3.78783\ttrain-rmse:1.94734\n",
      "[30025]\teval-rmse:3.78941\ttrain-rmse:1.94731\n",
      "[30026]\teval-rmse:3.78994\ttrain-rmse:1.94731\n",
      "[30027]\teval-rmse:3.78836\ttrain-rmse:1.94728\n",
      "[30028]\teval-rmse:3.78857\ttrain-rmse:1.94728\n",
      "[30029]\teval-rmse:3.78783\ttrain-rmse:1.94727\n",
      "[30030]\teval-rmse:3.7878\ttrain-rmse:1.94727\n",
      "[30031]\teval-rmse:3.78841\ttrain-rmse:1.94728\n",
      "[30032]\teval-rmse:3.78963\ttrain-rmse:1.94729\n",
      "[30033]\teval-rmse:3.78945\ttrain-rmse:1.94725\n",
      "[30034]\teval-rmse:3.79024\ttrain-rmse:1.94723\n",
      "[30035]\teval-rmse:3.79147\ttrain-rmse:1.94726\n",
      "[30036]\teval-rmse:3.7927\ttrain-rmse:1.94729\n",
      "[30037]\teval-rmse:3.79408\ttrain-rmse:1.94733\n",
      "[30038]\teval-rmse:3.79588\ttrain-rmse:1.94732\n",
      "[30039]\teval-rmse:3.79405\ttrain-rmse:1.94725\n",
      "[30040]\teval-rmse:3.79396\ttrain-rmse:1.94725\n",
      "[30041]\teval-rmse:3.79424\ttrain-rmse:1.94726\n",
      "[30042]\teval-rmse:3.79404\ttrain-rmse:1.94726\n",
      "[30043]\teval-rmse:3.79458\ttrain-rmse:1.94726\n",
      "[30044]\teval-rmse:3.79322\ttrain-rmse:1.94726\n",
      "[30045]\teval-rmse:3.79346\ttrain-rmse:1.94727\n",
      "[30046]\teval-rmse:3.792\ttrain-rmse:1.94727\n",
      "[30047]\teval-rmse:3.79074\ttrain-rmse:1.94725\n",
      "[30048]\teval-rmse:3.79031\ttrain-rmse:1.94724\n",
      "[30049]\teval-rmse:3.79186\ttrain-rmse:1.94723\n",
      "[30050]\teval-rmse:3.79205\ttrain-rmse:1.94723\n",
      "[30051]\teval-rmse:3.79257\ttrain-rmse:1.94723\n",
      "[30052]\teval-rmse:3.79238\ttrain-rmse:1.9472\n",
      "[30053]\teval-rmse:3.79083\ttrain-rmse:1.94721\n",
      "[30054]\teval-rmse:3.79207\ttrain-rmse:1.9472\n",
      "[30055]\teval-rmse:3.79082\ttrain-rmse:1.94718\n",
      "[30056]\teval-rmse:3.79031\ttrain-rmse:1.94718\n",
      "[30057]\teval-rmse:3.79012\ttrain-rmse:1.94719\n",
      "[30058]\teval-rmse:3.78995\ttrain-rmse:1.94716\n",
      "[30059]\teval-rmse:3.78863\ttrain-rmse:1.94718\n",
      "[30060]\teval-rmse:3.78814\ttrain-rmse:1.94719\n",
      "[30061]\teval-rmse:3.78871\ttrain-rmse:1.94719\n",
      "[30062]\teval-rmse:3.78845\ttrain-rmse:1.94719\n",
      "[30063]\teval-rmse:3.78898\ttrain-rmse:1.94718\n",
      "[30064]\teval-rmse:3.78767\ttrain-rmse:1.94717\n",
      "[30065]\teval-rmse:3.78816\ttrain-rmse:1.94717\n",
      "[30066]\teval-rmse:3.78949\ttrain-rmse:1.94715\n",
      "[30067]\teval-rmse:3.7885\ttrain-rmse:1.94718\n",
      "[30068]\teval-rmse:3.78962\ttrain-rmse:1.94719\n",
      "[30069]\teval-rmse:3.78944\ttrain-rmse:1.94716\n",
      "[30070]\teval-rmse:3.79077\ttrain-rmse:1.94715\n",
      "[30071]\teval-rmse:3.79058\ttrain-rmse:1.94715\n",
      "[30072]\teval-rmse:3.79031\ttrain-rmse:1.94715\n",
      "[30073]\teval-rmse:3.79074\ttrain-rmse:1.94716\n",
      "[30074]\teval-rmse:3.79001\ttrain-rmse:1.94715\n",
      "[30075]\teval-rmse:3.79031\ttrain-rmse:1.94715\n",
      "[30076]\teval-rmse:3.7919\ttrain-rmse:1.94712\n",
      "[30077]\teval-rmse:3.79292\ttrain-rmse:1.94714\n",
      "[30078]\teval-rmse:3.79449\ttrain-rmse:1.9472\n",
      "[30079]\teval-rmse:3.79394\ttrain-rmse:1.94719\n",
      "[30080]\teval-rmse:3.79237\ttrain-rmse:1.94719\n",
      "[30081]\teval-rmse:3.79288\ttrain-rmse:1.9472\n",
      "[30082]\teval-rmse:3.79307\ttrain-rmse:1.9472\n",
      "[30083]\teval-rmse:3.79456\ttrain-rmse:1.94724\n",
      "[30084]\teval-rmse:3.79429\ttrain-rmse:1.94724\n",
      "[30085]\teval-rmse:3.79328\ttrain-rmse:1.94724\n",
      "[30086]\teval-rmse:3.7946\ttrain-rmse:1.94725\n",
      "[30087]\teval-rmse:3.79392\ttrain-rmse:1.94722\n",
      "[30088]\teval-rmse:3.79419\ttrain-rmse:1.94722\n",
      "[30089]\teval-rmse:3.79367\ttrain-rmse:1.94722\n",
      "[30090]\teval-rmse:3.79241\ttrain-rmse:1.94722\n",
      "[30091]\teval-rmse:3.79261\ttrain-rmse:1.94723\n",
      "[30092]\teval-rmse:3.79233\ttrain-rmse:1.94723\n",
      "[30093]\teval-rmse:3.79391\ttrain-rmse:1.94722\n",
      "[30094]\teval-rmse:3.7934\ttrain-rmse:1.94722\n",
      "[30095]\teval-rmse:3.79205\ttrain-rmse:1.94723\n",
      "[30096]\teval-rmse:3.79245\ttrain-rmse:1.94724\n",
      "[30097]\teval-rmse:3.7926\ttrain-rmse:1.94725\n",
      "[30098]\teval-rmse:3.79128\ttrain-rmse:1.94727\n",
      "[30099]\teval-rmse:3.79227\ttrain-rmse:1.94729\n",
      "[30100]\teval-rmse:3.79383\ttrain-rmse:1.9473\n",
      "[30101]\teval-rmse:3.79363\ttrain-rmse:1.94729\n",
      "[30102]\teval-rmse:3.79494\ttrain-rmse:1.94735\n",
      "[30103]\teval-rmse:3.7965\ttrain-rmse:1.94736\n",
      "[30104]\teval-rmse:3.79667\ttrain-rmse:1.94737\n",
      "[30105]\teval-rmse:3.79612\ttrain-rmse:1.94736\n",
      "[30106]\teval-rmse:3.79509\ttrain-rmse:1.94736\n",
      "[30107]\teval-rmse:3.79656\ttrain-rmse:1.94743\n",
      "[30108]\teval-rmse:3.79694\ttrain-rmse:1.94745\n",
      "[30109]\teval-rmse:3.79719\ttrain-rmse:1.94745\n",
      "[30110]\teval-rmse:3.79558\ttrain-rmse:1.94737\n",
      "[30111]\teval-rmse:3.79682\ttrain-rmse:1.94739\n",
      "[30112]\teval-rmse:3.79732\ttrain-rmse:1.94739\n",
      "[30113]\teval-rmse:3.79912\ttrain-rmse:1.94739\n",
      "[30114]\teval-rmse:3.80022\ttrain-rmse:1.94744\n",
      "[30115]\teval-rmse:3.80038\ttrain-rmse:1.94745\n",
      "[30116]\teval-rmse:3.80193\ttrain-rmse:1.94755\n",
      "[30117]\teval-rmse:3.80086\ttrain-rmse:1.94755\n",
      "[30118]\teval-rmse:3.80234\ttrain-rmse:1.94756\n",
      "[30119]\teval-rmse:3.80202\ttrain-rmse:1.94755\n",
      "[30120]\teval-rmse:3.80382\ttrain-rmse:1.94756\n",
      "[30121]\teval-rmse:3.80375\ttrain-rmse:1.94756\n",
      "[30122]\teval-rmse:3.8039\ttrain-rmse:1.94756\n",
      "[30123]\teval-rmse:3.80261\ttrain-rmse:1.94753\n",
      "[30124]\teval-rmse:3.80074\ttrain-rmse:1.94747\n",
      "[30125]\teval-rmse:3.79937\ttrain-rmse:1.94744\n",
      "[30126]\teval-rmse:3.79906\ttrain-rmse:1.94743\n",
      "[30127]\teval-rmse:3.79746\ttrain-rmse:1.94734\n",
      "[30128]\teval-rmse:3.79743\ttrain-rmse:1.94734\n",
      "[30129]\teval-rmse:3.7959\ttrain-rmse:1.94732\n",
      "[30130]\teval-rmse:3.79435\ttrain-rmse:1.94725\n",
      "[30131]\teval-rmse:3.7941\ttrain-rmse:1.94724\n",
      "[30132]\teval-rmse:3.79535\ttrain-rmse:1.94729\n",
      "[30133]\teval-rmse:3.79492\ttrain-rmse:1.94729\n",
      "[30134]\teval-rmse:3.7964\ttrain-rmse:1.94727\n",
      "[30135]\teval-rmse:3.79796\ttrain-rmse:1.94729\n",
      "[30136]\teval-rmse:3.79777\ttrain-rmse:1.94728\n",
      "[30137]\teval-rmse:3.79791\ttrain-rmse:1.94729\n",
      "[30138]\teval-rmse:3.79814\ttrain-rmse:1.94731\n",
      "[30139]\teval-rmse:3.79648\ttrain-rmse:1.94724\n",
      "[30140]\teval-rmse:3.79802\ttrain-rmse:1.94725\n",
      "[30141]\teval-rmse:3.79819\ttrain-rmse:1.94726\n",
      "[30142]\teval-rmse:3.79932\ttrain-rmse:1.94731\n",
      "[30143]\teval-rmse:3.79769\ttrain-rmse:1.94722\n",
      "[30144]\teval-rmse:3.79585\ttrain-rmse:1.9472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30145]\teval-rmse:3.79616\ttrain-rmse:1.94721\n",
      "[30146]\teval-rmse:3.79666\ttrain-rmse:1.94722\n",
      "[30147]\teval-rmse:3.79718\ttrain-rmse:1.94722\n",
      "[30148]\teval-rmse:3.79592\ttrain-rmse:1.94717\n",
      "[30149]\teval-rmse:3.79453\ttrain-rmse:1.94712\n",
      "[30150]\teval-rmse:3.79408\ttrain-rmse:1.94712\n",
      "[30151]\teval-rmse:3.79428\ttrain-rmse:1.94713\n",
      "[30152]\teval-rmse:3.79326\ttrain-rmse:1.94714\n",
      "[30153]\teval-rmse:3.79176\ttrain-rmse:1.94709\n",
      "[30154]\teval-rmse:3.79207\ttrain-rmse:1.9471\n",
      "[30155]\teval-rmse:3.79365\ttrain-rmse:1.94708\n",
      "[30156]\teval-rmse:3.79208\ttrain-rmse:1.94708\n",
      "[30157]\teval-rmse:3.79388\ttrain-rmse:1.94705\n",
      "[30158]\teval-rmse:3.79344\ttrain-rmse:1.94704\n",
      "[30159]\teval-rmse:3.79162\ttrain-rmse:1.947\n",
      "[30160]\teval-rmse:3.79198\ttrain-rmse:1.947\n",
      "[30161]\teval-rmse:3.79324\ttrain-rmse:1.947\n",
      "[30162]\teval-rmse:3.79191\ttrain-rmse:1.94701\n",
      "[30163]\teval-rmse:3.79043\ttrain-rmse:1.94702\n",
      "[30164]\teval-rmse:3.79175\ttrain-rmse:1.94704\n",
      "[30165]\teval-rmse:3.79018\ttrain-rmse:1.94702\n",
      "[30166]\teval-rmse:3.7907\ttrain-rmse:1.94701\n",
      "[30167]\teval-rmse:3.79251\ttrain-rmse:1.94698\n",
      "[30168]\teval-rmse:3.79431\ttrain-rmse:1.94696\n",
      "[30169]\teval-rmse:3.79545\ttrain-rmse:1.94699\n",
      "[30170]\teval-rmse:3.79387\ttrain-rmse:1.94699\n",
      "[30171]\teval-rmse:3.79384\ttrain-rmse:1.94699\n",
      "[30172]\teval-rmse:3.79506\ttrain-rmse:1.94702\n",
      "[30173]\teval-rmse:3.79582\ttrain-rmse:1.94702\n",
      "[30174]\teval-rmse:3.79529\ttrain-rmse:1.94701\n",
      "[30175]\teval-rmse:3.79476\ttrain-rmse:1.947\n",
      "[30176]\teval-rmse:3.79341\ttrain-rmse:1.94697\n",
      "[30177]\teval-rmse:3.79323\ttrain-rmse:1.94694\n",
      "[30178]\teval-rmse:3.79436\ttrain-rmse:1.94697\n",
      "[30179]\teval-rmse:3.79362\ttrain-rmse:1.94697\n",
      "[30180]\teval-rmse:3.79438\ttrain-rmse:1.94696\n",
      "[30181]\teval-rmse:3.79336\ttrain-rmse:1.94697\n",
      "[30182]\teval-rmse:3.79379\ttrain-rmse:1.94697\n",
      "[30183]\teval-rmse:3.79453\ttrain-rmse:1.94697\n",
      "[30184]\teval-rmse:3.79388\ttrain-rmse:1.94695\n",
      "[30185]\teval-rmse:3.79313\ttrain-rmse:1.94694\n",
      "[30186]\teval-rmse:3.79365\ttrain-rmse:1.94694\n",
      "[30187]\teval-rmse:3.79416\ttrain-rmse:1.94694\n",
      "[30188]\teval-rmse:3.79566\ttrain-rmse:1.94692\n",
      "[30189]\teval-rmse:3.79617\ttrain-rmse:1.94694\n",
      "[30190]\teval-rmse:3.79637\ttrain-rmse:1.94694\n",
      "[30191]\teval-rmse:3.79585\ttrain-rmse:1.94694\n",
      "[30192]\teval-rmse:3.79686\ttrain-rmse:1.94697\n",
      "[30193]\teval-rmse:3.79719\ttrain-rmse:1.94698\n",
      "[30194]\teval-rmse:3.79794\ttrain-rmse:1.94698\n",
      "[30195]\teval-rmse:3.79844\ttrain-rmse:1.947\n",
      "[30196]\teval-rmse:3.79684\ttrain-rmse:1.94695\n",
      "[30197]\teval-rmse:3.79831\ttrain-rmse:1.94696\n",
      "[30198]\teval-rmse:3.79722\ttrain-rmse:1.94693\n",
      "[30199]\teval-rmse:3.79774\ttrain-rmse:1.94693\n",
      "[30200]\teval-rmse:3.79615\ttrain-rmse:1.94692\n",
      "[30201]\teval-rmse:3.79656\ttrain-rmse:1.94693\n",
      "[30202]\teval-rmse:3.79805\ttrain-rmse:1.94698\n",
      "[30203]\teval-rmse:3.79701\ttrain-rmse:1.94698\n",
      "[30204]\teval-rmse:3.79825\ttrain-rmse:1.947\n",
      "[30205]\teval-rmse:3.79807\ttrain-rmse:1.94699\n",
      "[30206]\teval-rmse:3.79954\ttrain-rmse:1.94705\n",
      "[30207]\teval-rmse:3.79932\ttrain-rmse:1.94705\n",
      "[30208]\teval-rmse:3.79982\ttrain-rmse:1.94706\n",
      "[30209]\teval-rmse:3.79877\ttrain-rmse:1.94706\n",
      "[30210]\teval-rmse:3.79751\ttrain-rmse:1.94706\n",
      "[30211]\teval-rmse:3.79875\ttrain-rmse:1.94707\n",
      "[30212]\teval-rmse:3.79821\ttrain-rmse:1.94706\n",
      "[30213]\teval-rmse:3.80002\ttrain-rmse:1.94705\n",
      "[30214]\teval-rmse:3.80141\ttrain-rmse:1.94712\n",
      "[30215]\teval-rmse:3.7998\ttrain-rmse:1.94709\n",
      "[30216]\teval-rmse:3.80054\ttrain-rmse:1.9471\n",
      "[30217]\teval-rmse:3.79948\ttrain-rmse:1.9471\n",
      "[30218]\teval-rmse:3.79786\ttrain-rmse:1.94703\n",
      "[30219]\teval-rmse:3.79659\ttrain-rmse:1.94703\n",
      "[30220]\teval-rmse:3.79607\ttrain-rmse:1.94703\n",
      "[30221]\teval-rmse:3.79588\ttrain-rmse:1.94703\n",
      "[30222]\teval-rmse:3.79661\ttrain-rmse:1.94703\n",
      "[30223]\teval-rmse:3.79535\ttrain-rmse:1.94698\n",
      "[30224]\teval-rmse:3.79375\ttrain-rmse:1.94695\n",
      "[30225]\teval-rmse:3.79323\ttrain-rmse:1.94696\n",
      "[30226]\teval-rmse:3.79191\ttrain-rmse:1.94697\n",
      "[30227]\teval-rmse:3.79034\ttrain-rmse:1.94695\n",
      "[30228]\teval-rmse:3.7896\ttrain-rmse:1.94696\n",
      "[30229]\teval-rmse:3.79094\ttrain-rmse:1.94694\n",
      "[30230]\teval-rmse:3.79116\ttrain-rmse:1.94693\n",
      "[30231]\teval-rmse:3.79193\ttrain-rmse:1.94692\n",
      "[30232]\teval-rmse:3.79141\ttrain-rmse:1.94692\n",
      "[30233]\teval-rmse:3.79091\ttrain-rmse:1.94693\n",
      "[30234]\teval-rmse:3.79087\ttrain-rmse:1.94693\n",
      "[30235]\teval-rmse:3.79181\ttrain-rmse:1.94694\n",
      "[30236]\teval-rmse:3.79361\ttrain-rmse:1.94697\n",
      "[30237]\teval-rmse:3.79236\ttrain-rmse:1.94697\n",
      "[30238]\teval-rmse:3.79103\ttrain-rmse:1.94698\n",
      "[30239]\teval-rmse:3.79121\ttrain-rmse:1.94698\n",
      "[30240]\teval-rmse:3.78964\ttrain-rmse:1.94697\n",
      "[30241]\teval-rmse:3.79089\ttrain-rmse:1.94695\n",
      "[30242]\teval-rmse:3.78958\ttrain-rmse:1.94697\n",
      "[30243]\teval-rmse:3.78907\ttrain-rmse:1.94697\n",
      "[30244]\teval-rmse:3.78808\ttrain-rmse:1.947\n",
      "[30245]\teval-rmse:3.78965\ttrain-rmse:1.94697\n",
      "[30246]\teval-rmse:3.79067\ttrain-rmse:1.94697\n",
      "[30247]\teval-rmse:3.79048\ttrain-rmse:1.94697\n",
      "[30248]\teval-rmse:3.79078\ttrain-rmse:1.94698\n",
      "[30249]\teval-rmse:3.78947\ttrain-rmse:1.94701\n",
      "[30250]\teval-rmse:3.78824\ttrain-rmse:1.94702\n",
      "[30251]\teval-rmse:3.78982\ttrain-rmse:1.94704\n",
      "[30252]\teval-rmse:3.79015\ttrain-rmse:1.94704\n",
      "[30253]\teval-rmse:3.78999\ttrain-rmse:1.94704\n",
      "[30254]\teval-rmse:3.78984\ttrain-rmse:1.94701\n",
      "[30255]\teval-rmse:3.79002\ttrain-rmse:1.94701\n",
      "[30256]\teval-rmse:3.79138\ttrain-rmse:1.947\n",
      "[30257]\teval-rmse:3.79063\ttrain-rmse:1.94699\n",
      "[30258]\teval-rmse:3.79113\ttrain-rmse:1.94699\n",
      "[30259]\teval-rmse:3.7927\ttrain-rmse:1.94696\n",
      "[30260]\teval-rmse:3.79196\ttrain-rmse:1.94696\n",
      "[30261]\teval-rmse:3.79354\ttrain-rmse:1.94694\n",
      "[30262]\teval-rmse:3.79279\ttrain-rmse:1.94694\n",
      "[30263]\teval-rmse:3.7938\ttrain-rmse:1.94694\n",
      "[30264]\teval-rmse:3.79506\ttrain-rmse:1.94697\n",
      "[30265]\teval-rmse:3.79452\ttrain-rmse:1.94696\n",
      "[30266]\teval-rmse:3.79295\ttrain-rmse:1.94696\n",
      "[30267]\teval-rmse:3.79371\ttrain-rmse:1.94696\n",
      "[30268]\teval-rmse:3.79215\ttrain-rmse:1.94697\n",
      "[30269]\teval-rmse:3.7937\ttrain-rmse:1.94696\n",
      "[30270]\teval-rmse:3.79328\ttrain-rmse:1.94697\n",
      "[30271]\teval-rmse:3.79483\ttrain-rmse:1.94697\n",
      "[30272]\teval-rmse:3.79333\ttrain-rmse:1.94694\n",
      "[30273]\teval-rmse:3.7921\ttrain-rmse:1.94695\n",
      "[30274]\teval-rmse:3.79359\ttrain-rmse:1.94693\n",
      "[30275]\teval-rmse:3.79331\ttrain-rmse:1.94693\n",
      "[30276]\teval-rmse:3.79361\ttrain-rmse:1.94694\n",
      "[30277]\teval-rmse:3.79405\ttrain-rmse:1.94694\n",
      "[30278]\teval-rmse:3.79385\ttrain-rmse:1.94694\n",
      "[30279]\teval-rmse:3.79253\ttrain-rmse:1.94695\n",
      "[30280]\teval-rmse:3.7913\ttrain-rmse:1.94696\n",
      "[30281]\teval-rmse:3.78982\ttrain-rmse:1.94695\n",
      "[30282]\teval-rmse:3.78832\ttrain-rmse:1.94693\n",
      "[30283]\teval-rmse:3.7899\ttrain-rmse:1.94691\n",
      "[30284]\teval-rmse:3.78941\ttrain-rmse:1.94692\n",
      "[30285]\teval-rmse:3.78924\ttrain-rmse:1.94692\n",
      "[30286]\teval-rmse:3.78876\ttrain-rmse:1.94693\n",
      "[30287]\teval-rmse:3.78778\ttrain-rmse:1.94695\n",
      "[30288]\teval-rmse:3.7889\ttrain-rmse:1.94696\n",
      "[30289]\teval-rmse:3.78919\ttrain-rmse:1.94697\n",
      "[30290]\teval-rmse:3.78901\ttrain-rmse:1.94697\n",
      "[30291]\teval-rmse:3.78883\ttrain-rmse:1.94697\n",
      "[30292]\teval-rmse:3.79006\ttrain-rmse:1.94699\n",
      "[30293]\teval-rmse:3.78957\ttrain-rmse:1.94699\n",
      "[30294]\teval-rmse:3.79113\ttrain-rmse:1.94697\n",
      "[30295]\teval-rmse:3.79132\ttrain-rmse:1.94697\n",
      "[30296]\teval-rmse:3.79118\ttrain-rmse:1.94697\n",
      "[30297]\teval-rmse:3.79218\ttrain-rmse:1.94698\n",
      "[30298]\teval-rmse:3.79201\ttrain-rmse:1.94698\n",
      "[30299]\teval-rmse:3.79252\ttrain-rmse:1.94698\n",
      "[30300]\teval-rmse:3.793\ttrain-rmse:1.947\n",
      "[30301]\teval-rmse:3.7933\ttrain-rmse:1.947\n",
      "[30302]\teval-rmse:3.79147\ttrain-rmse:1.94696\n",
      "[30303]\teval-rmse:3.78967\ttrain-rmse:1.94693\n",
      "[30304]\teval-rmse:3.78925\ttrain-rmse:1.94693\n",
      "[30305]\teval-rmse:3.78796\ttrain-rmse:1.94697\n",
      "[30306]\teval-rmse:3.7881\ttrain-rmse:1.94697\n",
      "[30307]\teval-rmse:3.78792\ttrain-rmse:1.94697\n",
      "[30308]\teval-rmse:3.78818\ttrain-rmse:1.94697\n",
      "[30309]\teval-rmse:3.7892\ttrain-rmse:1.94697\n",
      "[30310]\teval-rmse:3.78871\ttrain-rmse:1.94698\n",
      "[30311]\teval-rmse:3.78691\ttrain-rmse:1.94697\n",
      "[30312]\teval-rmse:3.78742\ttrain-rmse:1.94696\n",
      "[30313]\teval-rmse:3.78817\ttrain-rmse:1.94694\n",
      "[30314]\teval-rmse:3.7885\ttrain-rmse:1.94694\n",
      "[30315]\teval-rmse:3.7903\ttrain-rmse:1.9469\n",
      "[30316]\teval-rmse:3.79153\ttrain-rmse:1.94692\n",
      "[30317]\teval-rmse:3.78998\ttrain-rmse:1.94694\n",
      "[30318]\teval-rmse:3.78826\ttrain-rmse:1.94693\n",
      "[30319]\teval-rmse:3.78673\ttrain-rmse:1.94695\n",
      "[30320]\teval-rmse:3.78798\ttrain-rmse:1.94693\n",
      "[30321]\teval-rmse:3.78749\ttrain-rmse:1.94694\n",
      "[30322]\teval-rmse:3.7862\ttrain-rmse:1.94694\n",
      "[30323]\teval-rmse:3.78581\ttrain-rmse:1.94695\n",
      "[30324]\teval-rmse:3.78541\ttrain-rmse:1.94696\n",
      "[30325]\teval-rmse:3.7839\ttrain-rmse:1.94697\n",
      "[30326]\teval-rmse:3.78195\ttrain-rmse:1.94701\n",
      "[30327]\teval-rmse:3.7815\ttrain-rmse:1.94702\n",
      "[30328]\teval-rmse:3.78003\ttrain-rmse:1.94709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30329]\teval-rmse:3.77959\ttrain-rmse:1.94711\n",
      "[30330]\teval-rmse:3.78108\ttrain-rmse:1.94704\n",
      "[30331]\teval-rmse:3.78093\ttrain-rmse:1.94705\n",
      "[30332]\teval-rmse:3.78196\ttrain-rmse:1.94702\n",
      "[30333]\teval-rmse:3.78353\ttrain-rmse:1.94696\n",
      "[30334]\teval-rmse:3.78305\ttrain-rmse:1.94698\n",
      "[30335]\teval-rmse:3.78188\ttrain-rmse:1.947\n",
      "[30336]\teval-rmse:3.78143\ttrain-rmse:1.94702\n",
      "[30337]\teval-rmse:3.78097\ttrain-rmse:1.94704\n",
      "[30338]\teval-rmse:3.78003\ttrain-rmse:1.94708\n",
      "[30339]\teval-rmse:3.77989\ttrain-rmse:1.94708\n",
      "[30340]\teval-rmse:3.77863\ttrain-rmse:1.94713\n",
      "[30341]\teval-rmse:3.78003\ttrain-rmse:1.94708\n",
      "[30342]\teval-rmse:3.7796\ttrain-rmse:1.94711\n",
      "[30343]\teval-rmse:3.78141\ttrain-rmse:1.94703\n",
      "[30344]\teval-rmse:3.78164\ttrain-rmse:1.94702\n",
      "[30345]\teval-rmse:3.78208\ttrain-rmse:1.94701\n",
      "[30346]\teval-rmse:3.78264\ttrain-rmse:1.94699\n",
      "[30347]\teval-rmse:3.78148\ttrain-rmse:1.94703\n",
      "[30348]\teval-rmse:3.78136\ttrain-rmse:1.947\n",
      "[30349]\teval-rmse:3.78097\ttrain-rmse:1.94701\n",
      "[30350]\teval-rmse:3.78095\ttrain-rmse:1.94701\n",
      "[30351]\teval-rmse:3.7823\ttrain-rmse:1.94696\n",
      "[30352]\teval-rmse:3.78215\ttrain-rmse:1.94693\n",
      "[30353]\teval-rmse:3.78176\ttrain-rmse:1.94694\n",
      "[30354]\teval-rmse:3.78194\ttrain-rmse:1.94694\n",
      "[30355]\teval-rmse:3.78229\ttrain-rmse:1.94693\n",
      "[30356]\teval-rmse:3.78359\ttrain-rmse:1.94691\n",
      "[30357]\teval-rmse:3.78312\ttrain-rmse:1.94692\n",
      "[30358]\teval-rmse:3.78388\ttrain-rmse:1.9469\n",
      "[30359]\teval-rmse:3.7849\ttrain-rmse:1.94687\n",
      "[30360]\teval-rmse:3.78394\ttrain-rmse:1.9469\n",
      "[30361]\teval-rmse:3.78422\ttrain-rmse:1.94689\n",
      "[30362]\teval-rmse:3.78352\ttrain-rmse:1.94691\n",
      "[30363]\teval-rmse:3.78257\ttrain-rmse:1.94695\n",
      "[30364]\teval-rmse:3.78278\ttrain-rmse:1.94694\n",
      "[30365]\teval-rmse:3.78265\ttrain-rmse:1.94691\n",
      "[30366]\teval-rmse:3.78414\ttrain-rmse:1.94687\n",
      "[30367]\teval-rmse:3.78262\ttrain-rmse:1.94692\n",
      "[30368]\teval-rmse:3.78167\ttrain-rmse:1.94695\n",
      "[30369]\teval-rmse:3.78043\ttrain-rmse:1.947\n",
      "[30370]\teval-rmse:3.78031\ttrain-rmse:1.947\n",
      "[30371]\teval-rmse:3.78017\ttrain-rmse:1.94701\n",
      "[30372]\teval-rmse:3.78052\ttrain-rmse:1.947\n",
      "[30373]\teval-rmse:3.78203\ttrain-rmse:1.94698\n",
      "[30374]\teval-rmse:3.78351\ttrain-rmse:1.94693\n",
      "[30375]\teval-rmse:3.78303\ttrain-rmse:1.94695\n",
      "[30376]\teval-rmse:3.78151\ttrain-rmse:1.94697\n",
      "[30377]\teval-rmse:3.7823\ttrain-rmse:1.94693\n",
      "[30378]\teval-rmse:3.78056\ttrain-rmse:1.94697\n",
      "[30379]\teval-rmse:3.78205\ttrain-rmse:1.94695\n",
      "[30380]\teval-rmse:3.78088\ttrain-rmse:1.947\n",
      "[30381]\teval-rmse:3.78214\ttrain-rmse:1.94696\n",
      "[30382]\teval-rmse:3.78064\ttrain-rmse:1.94698\n",
      "[30383]\teval-rmse:3.78215\ttrain-rmse:1.94693\n",
      "[30384]\teval-rmse:3.78089\ttrain-rmse:1.94696\n",
      "[30385]\teval-rmse:3.78237\ttrain-rmse:1.9469\n",
      "[30386]\teval-rmse:3.78222\ttrain-rmse:1.94691\n",
      "[30387]\teval-rmse:3.78364\ttrain-rmse:1.94689\n",
      "[30388]\teval-rmse:3.7835\ttrain-rmse:1.9469\n",
      "[30389]\teval-rmse:3.78507\ttrain-rmse:1.94686\n",
      "[30390]\teval-rmse:3.78505\ttrain-rmse:1.94686\n",
      "[30391]\teval-rmse:3.78409\ttrain-rmse:1.94689\n",
      "[30392]\teval-rmse:3.78438\ttrain-rmse:1.94688\n",
      "[30393]\teval-rmse:3.78423\ttrain-rmse:1.94688\n",
      "[30394]\teval-rmse:3.78578\ttrain-rmse:1.94684\n",
      "[30395]\teval-rmse:3.78553\ttrain-rmse:1.94685\n",
      "[30396]\teval-rmse:3.78676\ttrain-rmse:1.94682\n",
      "[30397]\teval-rmse:3.78808\ttrain-rmse:1.9468\n",
      "[30398]\teval-rmse:3.78685\ttrain-rmse:1.94683\n",
      "[30399]\teval-rmse:3.78842\ttrain-rmse:1.94681\n",
      "[30400]\teval-rmse:3.78801\ttrain-rmse:1.94681\n",
      "[30401]\teval-rmse:3.78784\ttrain-rmse:1.94681\n",
      "[30402]\teval-rmse:3.78628\ttrain-rmse:1.94681\n",
      "[30403]\teval-rmse:3.78681\ttrain-rmse:1.9468\n",
      "[30404]\teval-rmse:3.78816\ttrain-rmse:1.94681\n",
      "[30405]\teval-rmse:3.7879\ttrain-rmse:1.94681\n",
      "[30406]\teval-rmse:3.78764\ttrain-rmse:1.94682\n",
      "[30407]\teval-rmse:3.78611\ttrain-rmse:1.94683\n",
      "[30408]\teval-rmse:3.78513\ttrain-rmse:1.94685\n",
      "[30409]\teval-rmse:3.78386\ttrain-rmse:1.94687\n",
      "[30410]\teval-rmse:3.78339\ttrain-rmse:1.94688\n",
      "[30411]\teval-rmse:3.78219\ttrain-rmse:1.94692\n",
      "[30412]\teval-rmse:3.78343\ttrain-rmse:1.9469\n",
      "[30413]\teval-rmse:3.78499\ttrain-rmse:1.94687\n",
      "[30414]\teval-rmse:3.78552\ttrain-rmse:1.94687\n",
      "[30415]\teval-rmse:3.78535\ttrain-rmse:1.94687\n",
      "[30416]\teval-rmse:3.78554\ttrain-rmse:1.94687\n",
      "[30417]\teval-rmse:3.78379\ttrain-rmse:1.94689\n",
      "[30418]\teval-rmse:3.78329\ttrain-rmse:1.9469\n",
      "[30419]\teval-rmse:3.78486\ttrain-rmse:1.94686\n",
      "[30420]\teval-rmse:3.78446\ttrain-rmse:1.94687\n",
      "[30421]\teval-rmse:3.78604\ttrain-rmse:1.94682\n",
      "[30422]\teval-rmse:3.7876\ttrain-rmse:1.9468\n",
      "[30423]\teval-rmse:3.78788\ttrain-rmse:1.9468\n",
      "[30424]\teval-rmse:3.78762\ttrain-rmse:1.9468\n",
      "[30425]\teval-rmse:3.78585\ttrain-rmse:1.9468\n",
      "[30426]\teval-rmse:3.78609\ttrain-rmse:1.9468\n",
      "[30427]\teval-rmse:3.78584\ttrain-rmse:1.94681\n",
      "[30428]\teval-rmse:3.78456\ttrain-rmse:1.94684\n",
      "[30429]\teval-rmse:3.78579\ttrain-rmse:1.94682\n",
      "[30430]\teval-rmse:3.78654\ttrain-rmse:1.9468\n",
      "[30431]\teval-rmse:3.78675\ttrain-rmse:1.9468\n",
      "[30432]\teval-rmse:3.78479\ttrain-rmse:1.94681\n",
      "[30433]\teval-rmse:3.78463\ttrain-rmse:1.94678\n",
      "[30434]\teval-rmse:3.78319\ttrain-rmse:1.94682\n",
      "[30435]\teval-rmse:3.782\ttrain-rmse:1.94685\n",
      "[30436]\teval-rmse:3.78051\ttrain-rmse:1.94689\n",
      "[30437]\teval-rmse:3.78176\ttrain-rmse:1.94685\n",
      "[30438]\teval-rmse:3.78131\ttrain-rmse:1.94687\n",
      "[30439]\teval-rmse:3.78129\ttrain-rmse:1.94687\n",
      "[30440]\teval-rmse:3.77988\ttrain-rmse:1.94691\n",
      "[30441]\teval-rmse:3.77858\ttrain-rmse:1.94695\n",
      "[30442]\teval-rmse:3.77814\ttrain-rmse:1.94697\n",
      "[30443]\teval-rmse:3.77918\ttrain-rmse:1.94693\n",
      "[30444]\teval-rmse:3.77941\ttrain-rmse:1.94692\n",
      "[30445]\teval-rmse:3.78122\ttrain-rmse:1.94684\n",
      "[30446]\teval-rmse:3.78279\ttrain-rmse:1.9468\n",
      "[30447]\teval-rmse:3.78322\ttrain-rmse:1.94679\n",
      "[30448]\teval-rmse:3.78196\ttrain-rmse:1.94682\n",
      "[30449]\teval-rmse:3.78281\ttrain-rmse:1.9468\n",
      "[30450]\teval-rmse:3.7828\ttrain-rmse:1.9468\n",
      "[30451]\teval-rmse:3.78404\ttrain-rmse:1.94676\n",
      "[30452]\teval-rmse:3.78389\ttrain-rmse:1.94677\n",
      "[30453]\teval-rmse:3.78318\ttrain-rmse:1.94678\n",
      "[30454]\teval-rmse:3.78279\ttrain-rmse:1.94679\n",
      "[30455]\teval-rmse:3.78413\ttrain-rmse:1.94676\n",
      "[30456]\teval-rmse:3.78398\ttrain-rmse:1.94676\n",
      "[30457]\teval-rmse:3.78205\ttrain-rmse:1.9468\n",
      "[30458]\teval-rmse:3.78055\ttrain-rmse:1.94686\n",
      "[30459]\teval-rmse:3.78041\ttrain-rmse:1.94682\n",
      "[30460]\teval-rmse:3.78222\ttrain-rmse:1.94675\n",
      "[30461]\teval-rmse:3.78252\ttrain-rmse:1.94674\n",
      "[30462]\teval-rmse:3.78135\ttrain-rmse:1.94678\n",
      "[30463]\teval-rmse:3.78135\ttrain-rmse:1.94678\n",
      "[30464]\teval-rmse:3.78135\ttrain-rmse:1.94678\n",
      "[30465]\teval-rmse:3.78018\ttrain-rmse:1.94683\n",
      "[30466]\teval-rmse:3.782\ttrain-rmse:1.94676\n",
      "[30467]\teval-rmse:3.78381\ttrain-rmse:1.94669\n",
      "[30468]\teval-rmse:3.78562\ttrain-rmse:1.94664\n",
      "[30469]\teval-rmse:3.78546\ttrain-rmse:1.94664\n",
      "[30470]\teval-rmse:3.78449\ttrain-rmse:1.94667\n",
      "[30471]\teval-rmse:3.78331\ttrain-rmse:1.9467\n",
      "[30472]\teval-rmse:3.7849\ttrain-rmse:1.94664\n",
      "[30473]\teval-rmse:3.78516\ttrain-rmse:1.94663\n",
      "[30474]\teval-rmse:3.78675\ttrain-rmse:1.94658\n",
      "[30475]\teval-rmse:3.78658\ttrain-rmse:1.94658\n",
      "[30476]\teval-rmse:3.78498\ttrain-rmse:1.94661\n",
      "[30477]\teval-rmse:3.7838\ttrain-rmse:1.94666\n",
      "[30478]\teval-rmse:3.78207\ttrain-rmse:1.94671\n",
      "[30479]\teval-rmse:3.78332\ttrain-rmse:1.94667\n",
      "[30480]\teval-rmse:3.78215\ttrain-rmse:1.94671\n",
      "[30481]\teval-rmse:3.7817\ttrain-rmse:1.94673\n",
      "[30482]\teval-rmse:3.78247\ttrain-rmse:1.9467\n",
      "[30483]\teval-rmse:3.78404\ttrain-rmse:1.94666\n",
      "[30484]\teval-rmse:3.78455\ttrain-rmse:1.94664\n",
      "[30485]\teval-rmse:3.78567\ttrain-rmse:1.94663\n",
      "[30486]\teval-rmse:3.78446\ttrain-rmse:1.94666\n",
      "[30487]\teval-rmse:3.78602\ttrain-rmse:1.94661\n",
      "[30488]\teval-rmse:3.786\ttrain-rmse:1.94662\n",
      "[30489]\teval-rmse:3.78586\ttrain-rmse:1.94658\n",
      "[30490]\teval-rmse:3.78713\ttrain-rmse:1.94657\n",
      "[30491]\teval-rmse:3.78827\ttrain-rmse:1.94655\n",
      "[30492]\teval-rmse:3.78672\ttrain-rmse:1.94657\n",
      "[30493]\teval-rmse:3.78623\ttrain-rmse:1.94658\n",
      "[30494]\teval-rmse:3.78494\ttrain-rmse:1.9466\n",
      "[30495]\teval-rmse:3.78367\ttrain-rmse:1.94665\n",
      "[30496]\teval-rmse:3.78343\ttrain-rmse:1.94666\n",
      "[30497]\teval-rmse:3.78376\ttrain-rmse:1.94665\n",
      "[30498]\teval-rmse:3.78235\ttrain-rmse:1.9467\n",
      "[30499]\teval-rmse:3.78281\ttrain-rmse:1.94668\n",
      "[30500]\teval-rmse:3.78186\ttrain-rmse:1.94671\n",
      "[30501]\teval-rmse:3.78212\ttrain-rmse:1.94671\n",
      "[30502]\teval-rmse:3.78197\ttrain-rmse:1.94667\n",
      "[30503]\teval-rmse:3.7808\ttrain-rmse:1.94673\n",
      "[30504]\teval-rmse:3.78183\ttrain-rmse:1.94669\n",
      "[30505]\teval-rmse:3.78309\ttrain-rmse:1.94666\n",
      "[30506]\teval-rmse:3.78466\ttrain-rmse:1.94662\n",
      "[30507]\teval-rmse:3.78543\ttrain-rmse:1.9466\n",
      "[30508]\teval-rmse:3.78594\ttrain-rmse:1.94659\n",
      "[30509]\teval-rmse:3.78578\ttrain-rmse:1.94659\n",
      "[30510]\teval-rmse:3.78553\ttrain-rmse:1.9466\n",
      "[30511]\teval-rmse:3.78606\ttrain-rmse:1.94659\n",
      "[30512]\teval-rmse:3.78556\ttrain-rmse:1.9466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30513]\teval-rmse:3.7838\ttrain-rmse:1.94663\n",
      "[30514]\teval-rmse:3.78262\ttrain-rmse:1.94668\n",
      "[30515]\teval-rmse:3.78137\ttrain-rmse:1.94671\n",
      "[30516]\teval-rmse:3.78009\ttrain-rmse:1.94676\n",
      "[30517]\teval-rmse:3.77859\ttrain-rmse:1.94682\n",
      "[30518]\teval-rmse:3.77903\ttrain-rmse:1.9468\n",
      "[30519]\teval-rmse:3.77948\ttrain-rmse:1.94679\n",
      "[30520]\teval-rmse:3.77757\ttrain-rmse:1.94686\n",
      "[30521]\teval-rmse:3.77744\ttrain-rmse:1.94686\n",
      "[30522]\teval-rmse:3.77598\ttrain-rmse:1.94693\n",
      "[30523]\teval-rmse:3.77618\ttrain-rmse:1.94692\n",
      "[30524]\teval-rmse:3.77743\ttrain-rmse:1.94687\n",
      "[30525]\teval-rmse:3.77923\ttrain-rmse:1.94678\n",
      "[30526]\teval-rmse:3.77922\ttrain-rmse:1.94678\n",
      "[30527]\teval-rmse:3.77878\ttrain-rmse:1.9468\n",
      "[30528]\teval-rmse:3.78003\ttrain-rmse:1.94675\n",
      "[30529]\teval-rmse:3.77958\ttrain-rmse:1.94677\n",
      "[30530]\teval-rmse:3.77957\ttrain-rmse:1.94677\n",
      "[30531]\teval-rmse:3.78083\ttrain-rmse:1.94672\n",
      "[30532]\teval-rmse:3.78082\ttrain-rmse:1.94672\n",
      "[30533]\teval-rmse:3.78103\ttrain-rmse:1.94671\n",
      "[30534]\teval-rmse:3.77987\ttrain-rmse:1.94677\n",
      "[30535]\teval-rmse:3.77951\ttrain-rmse:1.94678\n",
      "[30536]\teval-rmse:3.78099\ttrain-rmse:1.94673\n",
      "[30537]\teval-rmse:3.78121\ttrain-rmse:1.94672\n",
      "[30538]\teval-rmse:3.78233\ttrain-rmse:1.9467\n",
      "[30539]\teval-rmse:3.78117\ttrain-rmse:1.94673\n",
      "[30540]\teval-rmse:3.78151\ttrain-rmse:1.94672\n",
      "[30541]\teval-rmse:3.78148\ttrain-rmse:1.94672\n",
      "[30542]\teval-rmse:3.78134\ttrain-rmse:1.94669\n",
      "[30543]\teval-rmse:3.77961\ttrain-rmse:1.94675\n",
      "[30544]\teval-rmse:3.78118\ttrain-rmse:1.94669\n",
      "[30545]\teval-rmse:3.77969\ttrain-rmse:1.94674\n",
      "[30546]\teval-rmse:3.78093\ttrain-rmse:1.9467\n",
      "[30547]\teval-rmse:3.7807\ttrain-rmse:1.94671\n",
      "[30548]\teval-rmse:3.78123\ttrain-rmse:1.94669\n",
      "[30549]\teval-rmse:3.77998\ttrain-rmse:1.94673\n",
      "[30550]\teval-rmse:3.77998\ttrain-rmse:1.94673\n",
      "[30551]\teval-rmse:3.78051\ttrain-rmse:1.94671\n",
      "[30552]\teval-rmse:3.78051\ttrain-rmse:1.94671\n",
      "[30553]\teval-rmse:3.77932\ttrain-rmse:1.94677\n",
      "[30554]\teval-rmse:3.78009\ttrain-rmse:1.94674\n",
      "[30555]\teval-rmse:3.77868\ttrain-rmse:1.94679\n",
      "[30556]\teval-rmse:3.77908\ttrain-rmse:1.94677\n",
      "[30557]\teval-rmse:3.77935\ttrain-rmse:1.94676\n",
      "[30558]\teval-rmse:3.77935\ttrain-rmse:1.94676\n",
      "[30559]\teval-rmse:3.77937\ttrain-rmse:1.94676\n",
      "[30560]\teval-rmse:3.77789\ttrain-rmse:1.94683\n",
      "[30561]\teval-rmse:3.77697\ttrain-rmse:1.94687\n",
      "[30562]\teval-rmse:3.77685\ttrain-rmse:1.94688\n",
      "[30563]\teval-rmse:3.7774\ttrain-rmse:1.94685\n",
      "[30564]\teval-rmse:3.7776\ttrain-rmse:1.94684\n",
      "[30565]\teval-rmse:3.77822\ttrain-rmse:1.94682\n",
      "[30566]\teval-rmse:3.77752\ttrain-rmse:1.94685\n",
      "[30567]\teval-rmse:3.77739\ttrain-rmse:1.94686\n",
      "[30568]\teval-rmse:3.77647\ttrain-rmse:1.9469\n",
      "[30569]\teval-rmse:3.7767\ttrain-rmse:1.94689\n",
      "[30570]\teval-rmse:3.77731\ttrain-rmse:1.94687\n",
      "[30571]\teval-rmse:3.77857\ttrain-rmse:1.94681\n",
      "[30572]\teval-rmse:3.78016\ttrain-rmse:1.94673\n",
      "[30573]\teval-rmse:3.77866\ttrain-rmse:1.94678\n",
      "[30574]\teval-rmse:3.7789\ttrain-rmse:1.94677\n",
      "[30575]\teval-rmse:3.78014\ttrain-rmse:1.94673\n",
      "[30576]\teval-rmse:3.77866\ttrain-rmse:1.94679\n",
      "[30577]\teval-rmse:3.77905\ttrain-rmse:1.94678\n",
      "[30578]\teval-rmse:3.7779\ttrain-rmse:1.94684\n",
      "[30579]\teval-rmse:3.77814\ttrain-rmse:1.94683\n",
      "[30580]\teval-rmse:3.77859\ttrain-rmse:1.94681\n",
      "[30581]\teval-rmse:3.78039\ttrain-rmse:1.94673\n",
      "[30582]\teval-rmse:3.78025\ttrain-rmse:1.94674\n",
      "[30583]\teval-rmse:3.78026\ttrain-rmse:1.94674\n",
      "[30584]\teval-rmse:3.77878\ttrain-rmse:1.9468\n",
      "[30585]\teval-rmse:3.77954\ttrain-rmse:1.94677\n",
      "[30586]\teval-rmse:3.78055\ttrain-rmse:1.94673\n",
      "[30587]\teval-rmse:3.77887\ttrain-rmse:1.94678\n",
      "[30588]\teval-rmse:3.77913\ttrain-rmse:1.94677\n",
      "[30589]\teval-rmse:3.77878\ttrain-rmse:1.94679\n",
      "[30590]\teval-rmse:3.77764\ttrain-rmse:1.94685\n",
      "[30591]\teval-rmse:3.77903\ttrain-rmse:1.9468\n",
      "[30592]\teval-rmse:3.78062\ttrain-rmse:1.94674\n",
      "[30593]\teval-rmse:3.78139\ttrain-rmse:1.94672\n",
      "[30594]\teval-rmse:3.78215\ttrain-rmse:1.94669\n",
      "[30595]\teval-rmse:3.78354\ttrain-rmse:1.94667\n",
      "[30596]\teval-rmse:3.78308\ttrain-rmse:1.94669\n",
      "[30597]\teval-rmse:3.78466\ttrain-rmse:1.94662\n",
      "[30598]\teval-rmse:3.78625\ttrain-rmse:1.94657\n",
      "[30599]\teval-rmse:3.78805\ttrain-rmse:1.94652\n",
      "[30600]\teval-rmse:3.78676\ttrain-rmse:1.94655\n",
      "[30601]\teval-rmse:3.78546\ttrain-rmse:1.94658\n",
      "[30602]\teval-rmse:3.78508\ttrain-rmse:1.94659\n",
      "[30603]\teval-rmse:3.78632\ttrain-rmse:1.94657\n",
      "[30604]\teval-rmse:3.78633\ttrain-rmse:1.94657\n",
      "[30605]\teval-rmse:3.78479\ttrain-rmse:1.94659\n",
      "[30606]\teval-rmse:3.78627\ttrain-rmse:1.94656\n",
      "[30607]\teval-rmse:3.78742\ttrain-rmse:1.94655\n",
      "[30608]\teval-rmse:3.78757\ttrain-rmse:1.94655\n",
      "[30609]\teval-rmse:3.78906\ttrain-rmse:1.94651\n",
      "[30610]\teval-rmse:3.7888\ttrain-rmse:1.94651\n",
      "[30611]\teval-rmse:3.78749\ttrain-rmse:1.94653\n",
      "[30612]\teval-rmse:3.78618\ttrain-rmse:1.94656\n",
      "[30613]\teval-rmse:3.78488\ttrain-rmse:1.94658\n",
      "[30614]\teval-rmse:3.78543\ttrain-rmse:1.94658\n",
      "[30615]\teval-rmse:3.78678\ttrain-rmse:1.94656\n",
      "[30616]\teval-rmse:3.78782\ttrain-rmse:1.94656\n",
      "[30617]\teval-rmse:3.78939\ttrain-rmse:1.94656\n",
      "[30618]\teval-rmse:3.7884\ttrain-rmse:1.94658\n",
      "[30619]\teval-rmse:3.7872\ttrain-rmse:1.94658\n",
      "[30620]\teval-rmse:3.78869\ttrain-rmse:1.94654\n",
      "[30621]\teval-rmse:3.78995\ttrain-rmse:1.94654\n",
      "[30622]\teval-rmse:3.79071\ttrain-rmse:1.94654\n",
      "[30623]\teval-rmse:3.79202\ttrain-rmse:1.94654\n",
      "[30624]\teval-rmse:3.79183\ttrain-rmse:1.94651\n",
      "[30625]\teval-rmse:3.79309\ttrain-rmse:1.94654\n",
      "[30626]\teval-rmse:3.79489\ttrain-rmse:1.94652\n",
      "[30627]\teval-rmse:3.79365\ttrain-rmse:1.94649\n",
      "[30628]\teval-rmse:3.79312\ttrain-rmse:1.94649\n",
      "[30629]\teval-rmse:3.79354\ttrain-rmse:1.9465\n",
      "[30630]\teval-rmse:3.79174\ttrain-rmse:1.94647\n",
      "[30631]\teval-rmse:3.79308\ttrain-rmse:1.94646\n",
      "[30632]\teval-rmse:3.79128\ttrain-rmse:1.94644\n",
      "[30633]\teval-rmse:3.79085\ttrain-rmse:1.94644\n",
      "[30634]\teval-rmse:3.78937\ttrain-rmse:1.94645\n",
      "[30635]\teval-rmse:3.78972\ttrain-rmse:1.94645\n",
      "[30636]\teval-rmse:3.79025\ttrain-rmse:1.94645\n",
      "[30637]\teval-rmse:3.79181\ttrain-rmse:1.94643\n",
      "[30638]\teval-rmse:3.79132\ttrain-rmse:1.94643\n",
      "[30639]\teval-rmse:3.78954\ttrain-rmse:1.94643\n",
      "[30640]\teval-rmse:3.78927\ttrain-rmse:1.94643\n",
      "[30641]\teval-rmse:3.78773\ttrain-rmse:1.94646\n",
      "[30642]\teval-rmse:3.78923\ttrain-rmse:1.94642\n",
      "[30643]\teval-rmse:3.79103\ttrain-rmse:1.94639\n",
      "[30644]\teval-rmse:3.78906\ttrain-rmse:1.9464\n",
      "[30645]\teval-rmse:3.78776\ttrain-rmse:1.94643\n",
      "[30646]\teval-rmse:3.78624\ttrain-rmse:1.94647\n",
      "[30647]\teval-rmse:3.78505\ttrain-rmse:1.94651\n",
      "[30648]\teval-rmse:3.78685\ttrain-rmse:1.94646\n",
      "[30649]\teval-rmse:3.78789\ttrain-rmse:1.94644\n",
      "[30650]\teval-rmse:3.78811\ttrain-rmse:1.94643\n",
      "[30651]\teval-rmse:3.78689\ttrain-rmse:1.94645\n",
      "[30652]\teval-rmse:3.7883\ttrain-rmse:1.94643\n",
      "[30653]\teval-rmse:3.78883\ttrain-rmse:1.94642\n",
      "[30654]\teval-rmse:3.78752\ttrain-rmse:1.94644\n",
      "[30655]\teval-rmse:3.78576\ttrain-rmse:1.94648\n",
      "[30656]\teval-rmse:3.78703\ttrain-rmse:1.94645\n",
      "[30657]\teval-rmse:3.78584\ttrain-rmse:1.94649\n",
      "[30658]\teval-rmse:3.78568\ttrain-rmse:1.94645\n",
      "[30659]\teval-rmse:3.78702\ttrain-rmse:1.94643\n",
      "[30660]\teval-rmse:3.78756\ttrain-rmse:1.94642\n",
      "[30661]\teval-rmse:3.78915\ttrain-rmse:1.94638\n",
      "[30662]\teval-rmse:3.79038\ttrain-rmse:1.94636\n",
      "[30663]\teval-rmse:3.78997\ttrain-rmse:1.94637\n",
      "[30664]\teval-rmse:3.79154\ttrain-rmse:1.94635\n",
      "[30665]\teval-rmse:3.79091\ttrain-rmse:1.94635\n",
      "[30666]\teval-rmse:3.79223\ttrain-rmse:1.94634\n",
      "[30667]\teval-rmse:3.79101\ttrain-rmse:1.94636\n",
      "[30668]\teval-rmse:3.79082\ttrain-rmse:1.94637\n",
      "[30669]\teval-rmse:3.78958\ttrain-rmse:1.94638\n",
      "[30670]\teval-rmse:3.79003\ttrain-rmse:1.94637\n",
      "[30671]\teval-rmse:3.78823\ttrain-rmse:1.9464\n",
      "[30672]\teval-rmse:3.78972\ttrain-rmse:1.94636\n",
      "[30673]\teval-rmse:3.78779\ttrain-rmse:1.94639\n",
      "[30674]\teval-rmse:3.78855\ttrain-rmse:1.94637\n",
      "[30675]\teval-rmse:3.78854\ttrain-rmse:1.94637\n",
      "[30676]\teval-rmse:3.78732\ttrain-rmse:1.94639\n",
      "[30677]\teval-rmse:3.7889\ttrain-rmse:1.94637\n",
      "[30678]\teval-rmse:3.78872\ttrain-rmse:1.94637\n",
      "[30679]\teval-rmse:3.78916\ttrain-rmse:1.94637\n",
      "[30680]\teval-rmse:3.79041\ttrain-rmse:1.94636\n",
      "[30681]\teval-rmse:3.79092\ttrain-rmse:1.94636\n",
      "[30682]\teval-rmse:3.79144\ttrain-rmse:1.94636\n",
      "[30683]\teval-rmse:3.79257\ttrain-rmse:1.94636\n",
      "[30684]\teval-rmse:3.79238\ttrain-rmse:1.94636\n",
      "[30685]\teval-rmse:3.79371\ttrain-rmse:1.94638\n",
      "[30686]\teval-rmse:3.79371\ttrain-rmse:1.94638\n",
      "[30687]\teval-rmse:3.79517\ttrain-rmse:1.94637\n",
      "[30688]\teval-rmse:3.79453\ttrain-rmse:1.94636\n",
      "[30689]\teval-rmse:3.79424\ttrain-rmse:1.94637\n",
      "[30690]\teval-rmse:3.79405\ttrain-rmse:1.94633\n",
      "[30691]\teval-rmse:3.79304\ttrain-rmse:1.94634\n",
      "[30692]\teval-rmse:3.7941\ttrain-rmse:1.94635\n",
      "[30693]\teval-rmse:3.79286\ttrain-rmse:1.94636\n",
      "[30694]\teval-rmse:3.7931\ttrain-rmse:1.94636\n",
      "[30695]\teval-rmse:3.79112\ttrain-rmse:1.94635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30696]\teval-rmse:3.79112\ttrain-rmse:1.94635\n",
      "[30697]\teval-rmse:3.7917\ttrain-rmse:1.94636\n",
      "[30698]\teval-rmse:3.79167\ttrain-rmse:1.94636\n",
      "[30699]\teval-rmse:3.79186\ttrain-rmse:1.94636\n",
      "[30700]\teval-rmse:3.79239\ttrain-rmse:1.94635\n",
      "[30701]\teval-rmse:3.79396\ttrain-rmse:1.94638\n",
      "[30702]\teval-rmse:3.79343\ttrain-rmse:1.94638\n",
      "[30703]\teval-rmse:3.79443\ttrain-rmse:1.94639\n",
      "[30704]\teval-rmse:3.79392\ttrain-rmse:1.94639\n",
      "[30705]\teval-rmse:3.7954\ttrain-rmse:1.94642\n",
      "[30706]\teval-rmse:3.79589\ttrain-rmse:1.94643\n",
      "[30707]\teval-rmse:3.79769\ttrain-rmse:1.94642\n",
      "[30708]\teval-rmse:3.79714\ttrain-rmse:1.94641\n",
      "[30709]\teval-rmse:3.79839\ttrain-rmse:1.94642\n",
      "[30710]\teval-rmse:3.79833\ttrain-rmse:1.94642\n",
      "[30711]\teval-rmse:3.79944\ttrain-rmse:1.94645\n",
      "[30712]\teval-rmse:3.79994\ttrain-rmse:1.94646\n",
      "[30713]\teval-rmse:3.79889\ttrain-rmse:1.94646\n",
      "[30714]\teval-rmse:3.79906\ttrain-rmse:1.94646\n",
      "[30715]\teval-rmse:3.80052\ttrain-rmse:1.94648\n",
      "[30716]\teval-rmse:3.79975\ttrain-rmse:1.94646\n",
      "[30717]\teval-rmse:3.80086\ttrain-rmse:1.9465\n",
      "[30718]\teval-rmse:3.80115\ttrain-rmse:1.94652\n",
      "[30719]\teval-rmse:3.80156\ttrain-rmse:1.94652\n",
      "[30720]\teval-rmse:3.80303\ttrain-rmse:1.94654\n",
      "[30721]\teval-rmse:3.80174\ttrain-rmse:1.94652\n",
      "[30722]\teval-rmse:3.80037\ttrain-rmse:1.9465\n",
      "[30723]\teval-rmse:3.80177\ttrain-rmse:1.94655\n",
      "[30724]\teval-rmse:3.80249\ttrain-rmse:1.94659\n",
      "[30725]\teval-rmse:3.80087\ttrain-rmse:1.94654\n",
      "[30726]\teval-rmse:3.80065\ttrain-rmse:1.94653\n",
      "[30727]\teval-rmse:3.79882\ttrain-rmse:1.94646\n",
      "[30728]\teval-rmse:3.79778\ttrain-rmse:1.94646\n",
      "[30729]\teval-rmse:3.79626\ttrain-rmse:1.94641\n",
      "[30730]\teval-rmse:3.79468\ttrain-rmse:1.9464\n",
      "[30731]\teval-rmse:3.79486\ttrain-rmse:1.9464\n",
      "[30732]\teval-rmse:3.79304\ttrain-rmse:1.94637\n",
      "[30733]\teval-rmse:3.79325\ttrain-rmse:1.94637\n",
      "[30734]\teval-rmse:3.79401\ttrain-rmse:1.94636\n",
      "[30735]\teval-rmse:3.79356\ttrain-rmse:1.94635\n",
      "[30736]\teval-rmse:3.79199\ttrain-rmse:1.94633\n",
      "[30737]\teval-rmse:3.79052\ttrain-rmse:1.94633\n",
      "[30738]\teval-rmse:3.79211\ttrain-rmse:1.94631\n",
      "[30739]\teval-rmse:3.79191\ttrain-rmse:1.94632\n",
      "[30740]\teval-rmse:3.79045\ttrain-rmse:1.94631\n",
      "[30741]\teval-rmse:3.79077\ttrain-rmse:1.94631\n",
      "[30742]\teval-rmse:3.79235\ttrain-rmse:1.94629\n",
      "[30743]\teval-rmse:3.79079\ttrain-rmse:1.94629\n",
      "[30744]\teval-rmse:3.7911\ttrain-rmse:1.94629\n",
      "[30745]\teval-rmse:3.79036\ttrain-rmse:1.94629\n",
      "[30746]\teval-rmse:3.78986\ttrain-rmse:1.9463\n",
      "[30747]\teval-rmse:3.78817\ttrain-rmse:1.94632\n",
      "[30748]\teval-rmse:3.78778\ttrain-rmse:1.94633\n",
      "[30749]\teval-rmse:3.78821\ttrain-rmse:1.94633\n",
      "[30750]\teval-rmse:3.78881\ttrain-rmse:1.94632\n",
      "[30751]\teval-rmse:3.78864\ttrain-rmse:1.94632\n",
      "[30752]\teval-rmse:3.78882\ttrain-rmse:1.94632\n",
      "[30753]\teval-rmse:3.79017\ttrain-rmse:1.9463\n",
      "[30754]\teval-rmse:3.78999\ttrain-rmse:1.9463\n",
      "[30755]\teval-rmse:3.78878\ttrain-rmse:1.94633\n",
      "[30756]\teval-rmse:3.78852\ttrain-rmse:1.94633\n",
      "[30757]\teval-rmse:3.78779\ttrain-rmse:1.94634\n",
      "[30758]\teval-rmse:3.78648\ttrain-rmse:1.94637\n",
      "[30759]\teval-rmse:3.7867\ttrain-rmse:1.94637\n",
      "[30760]\teval-rmse:3.78527\ttrain-rmse:1.9464\n",
      "[30761]\teval-rmse:3.78586\ttrain-rmse:1.94639\n",
      "[30762]\teval-rmse:3.78641\ttrain-rmse:1.94637\n",
      "[30763]\teval-rmse:3.7852\ttrain-rmse:1.9464\n",
      "[30764]\teval-rmse:3.78573\ttrain-rmse:1.94639\n",
      "[30765]\teval-rmse:3.78596\ttrain-rmse:1.94639\n",
      "[30766]\teval-rmse:3.78453\ttrain-rmse:1.94642\n",
      "[30767]\teval-rmse:3.78476\ttrain-rmse:1.94641\n",
      "[30768]\teval-rmse:3.78356\ttrain-rmse:1.94645\n",
      "[30769]\teval-rmse:3.78206\ttrain-rmse:1.9465\n",
      "[30770]\teval-rmse:3.78191\ttrain-rmse:1.94651\n",
      "[30771]\teval-rmse:3.78146\ttrain-rmse:1.94653\n",
      "[30772]\teval-rmse:3.78273\ttrain-rmse:1.94648\n",
      "[30773]\teval-rmse:3.78424\ttrain-rmse:1.94642\n",
      "[30774]\teval-rmse:3.78549\ttrain-rmse:1.94638\n",
      "[30775]\teval-rmse:3.78605\ttrain-rmse:1.94637\n",
      "[30776]\teval-rmse:3.78484\ttrain-rmse:1.9464\n",
      "[30777]\teval-rmse:3.78388\ttrain-rmse:1.94644\n",
      "[30778]\teval-rmse:3.78269\ttrain-rmse:1.94648\n",
      "[30779]\teval-rmse:3.78232\ttrain-rmse:1.94649\n",
      "[30780]\teval-rmse:3.78357\ttrain-rmse:1.94645\n",
      "[30781]\teval-rmse:3.78434\ttrain-rmse:1.94643\n",
      "[30782]\teval-rmse:3.78292\ttrain-rmse:1.94647\n",
      "[30783]\teval-rmse:3.78423\ttrain-rmse:1.94643\n",
      "[30784]\teval-rmse:3.78537\ttrain-rmse:1.94641\n",
      "[30785]\teval-rmse:3.78419\ttrain-rmse:1.94645\n",
      "[30786]\teval-rmse:3.78381\ttrain-rmse:1.94646\n",
      "[30787]\teval-rmse:3.78232\ttrain-rmse:1.94651\n",
      "[30788]\teval-rmse:3.78195\ttrain-rmse:1.94653\n",
      "[30789]\teval-rmse:3.78064\ttrain-rmse:1.94657\n",
      "[30790]\teval-rmse:3.78096\ttrain-rmse:1.94656\n",
      "[30791]\teval-rmse:3.78221\ttrain-rmse:1.94651\n",
      "[30792]\teval-rmse:3.78402\ttrain-rmse:1.94644\n",
      "[30793]\teval-rmse:3.78551\ttrain-rmse:1.9464\n",
      "[30794]\teval-rmse:3.78525\ttrain-rmse:1.9464\n",
      "[30795]\teval-rmse:3.78399\ttrain-rmse:1.94644\n",
      "[30796]\teval-rmse:3.7825\ttrain-rmse:1.94649\n",
      "[30797]\teval-rmse:3.78234\ttrain-rmse:1.9465\n",
      "[30798]\teval-rmse:3.78293\ttrain-rmse:1.94648\n",
      "[30799]\teval-rmse:3.78451\ttrain-rmse:1.94644\n",
      "[30800]\teval-rmse:3.78301\ttrain-rmse:1.94649\n",
      "[30801]\teval-rmse:3.78451\ttrain-rmse:1.94643\n",
      "[30802]\teval-rmse:3.78578\ttrain-rmse:1.94639\n",
      "[30803]\teval-rmse:3.78704\ttrain-rmse:1.94635\n",
      "[30804]\teval-rmse:3.78757\ttrain-rmse:1.94634\n",
      "[30805]\teval-rmse:3.78882\ttrain-rmse:1.94633\n",
      "[30806]\teval-rmse:3.78751\ttrain-rmse:1.94636\n",
      "[30807]\teval-rmse:3.78796\ttrain-rmse:1.94635\n",
      "[30808]\teval-rmse:3.78748\ttrain-rmse:1.94636\n",
      "[30809]\teval-rmse:3.78669\ttrain-rmse:1.94637\n",
      "[30810]\teval-rmse:3.78516\ttrain-rmse:1.94642\n",
      "[30811]\teval-rmse:3.78641\ttrain-rmse:1.94639\n",
      "[30812]\teval-rmse:3.78624\ttrain-rmse:1.9464\n",
      "[30813]\teval-rmse:3.78701\ttrain-rmse:1.94639\n",
      "[30814]\teval-rmse:3.78722\ttrain-rmse:1.94638\n",
      "[30815]\teval-rmse:3.78848\ttrain-rmse:1.94636\n",
      "[30816]\teval-rmse:3.78979\ttrain-rmse:1.94635\n",
      "[30817]\teval-rmse:3.78961\ttrain-rmse:1.94635\n",
      "[30818]\teval-rmse:3.78829\ttrain-rmse:1.94638\n",
      "[30819]\teval-rmse:3.78701\ttrain-rmse:1.94639\n",
      "[30820]\teval-rmse:3.78815\ttrain-rmse:1.94638\n",
      "[30821]\teval-rmse:3.78684\ttrain-rmse:1.9464\n",
      "[30822]\teval-rmse:3.78645\ttrain-rmse:1.9464\n",
      "[30823]\teval-rmse:3.78526\ttrain-rmse:1.94644\n",
      "[30824]\teval-rmse:3.7851\ttrain-rmse:1.9464\n",
      "[30825]\teval-rmse:3.78547\ttrain-rmse:1.9464\n",
      "[30826]\teval-rmse:3.78531\ttrain-rmse:1.9464\n",
      "[30827]\teval-rmse:3.78386\ttrain-rmse:1.94643\n",
      "[30828]\teval-rmse:3.78462\ttrain-rmse:1.9464\n",
      "[30829]\teval-rmse:3.78517\ttrain-rmse:1.94639\n",
      "[30830]\teval-rmse:3.78641\ttrain-rmse:1.94636\n",
      "[30831]\teval-rmse:3.7852\ttrain-rmse:1.9464\n",
      "[30832]\teval-rmse:3.78543\ttrain-rmse:1.9464\n",
      "[30833]\teval-rmse:3.78423\ttrain-rmse:1.94642\n",
      "[30834]\teval-rmse:3.78549\ttrain-rmse:1.94638\n",
      "[30835]\teval-rmse:3.78571\ttrain-rmse:1.94637\n",
      "[30836]\teval-rmse:3.78453\ttrain-rmse:1.94641\n",
      "[30837]\teval-rmse:3.78406\ttrain-rmse:1.94643\n",
      "[30838]\teval-rmse:3.7836\ttrain-rmse:1.94645\n",
      "[30839]\teval-rmse:3.78511\ttrain-rmse:1.94639\n",
      "[30840]\teval-rmse:3.78464\ttrain-rmse:1.94641\n",
      "[30841]\teval-rmse:3.78518\ttrain-rmse:1.94639\n",
      "[30842]\teval-rmse:3.78458\ttrain-rmse:1.9464\n",
      "[30843]\teval-rmse:3.78419\ttrain-rmse:1.94642\n",
      "[30844]\teval-rmse:3.78244\ttrain-rmse:1.94646\n",
      "[30845]\teval-rmse:3.78371\ttrain-rmse:1.94642\n",
      "[30846]\teval-rmse:3.78254\ttrain-rmse:1.94646\n",
      "[30847]\teval-rmse:3.7838\ttrain-rmse:1.94642\n",
      "[30848]\teval-rmse:3.78333\ttrain-rmse:1.94644\n",
      "[30849]\teval-rmse:3.78411\ttrain-rmse:1.94641\n",
      "[30850]\teval-rmse:3.78464\ttrain-rmse:1.94639\n",
      "[30851]\teval-rmse:3.78598\ttrain-rmse:1.94637\n",
      "[30852]\teval-rmse:3.78471\ttrain-rmse:1.94639\n",
      "[30853]\teval-rmse:3.78455\ttrain-rmse:1.9464\n",
      "[30854]\teval-rmse:3.78439\ttrain-rmse:1.9464\n",
      "[30855]\teval-rmse:3.78312\ttrain-rmse:1.94644\n",
      "[30856]\teval-rmse:3.78118\ttrain-rmse:1.9465\n",
      "[30857]\teval-rmse:3.78171\ttrain-rmse:1.94648\n",
      "[30858]\teval-rmse:3.78227\ttrain-rmse:1.94646\n",
      "[30859]\teval-rmse:3.78384\ttrain-rmse:1.94641\n",
      "[30860]\teval-rmse:3.78511\ttrain-rmse:1.94637\n",
      "[30861]\teval-rmse:3.78542\ttrain-rmse:1.94636\n",
      "[30862]\teval-rmse:3.78422\ttrain-rmse:1.9464\n",
      "[30863]\teval-rmse:3.78409\ttrain-rmse:1.94636\n",
      "[30864]\teval-rmse:3.78462\ttrain-rmse:1.94635\n",
      "[30865]\teval-rmse:3.78319\ttrain-rmse:1.94639\n",
      "[30866]\teval-rmse:3.78374\ttrain-rmse:1.94637\n",
      "[30867]\teval-rmse:3.78362\ttrain-rmse:1.94634\n",
      "[30868]\teval-rmse:3.78346\ttrain-rmse:1.94634\n",
      "[30869]\teval-rmse:3.78221\ttrain-rmse:1.94638\n",
      "[30870]\teval-rmse:3.78335\ttrain-rmse:1.94636\n",
      "[30871]\teval-rmse:3.78292\ttrain-rmse:1.94637\n",
      "[30872]\teval-rmse:3.78244\ttrain-rmse:1.94639\n",
      "[30873]\teval-rmse:3.78149\ttrain-rmse:1.94642\n",
      "[30874]\teval-rmse:3.78196\ttrain-rmse:1.9464\n",
      "[30875]\teval-rmse:3.78228\ttrain-rmse:1.9464\n",
      "[30876]\teval-rmse:3.78158\ttrain-rmse:1.94642\n",
      "[30877]\teval-rmse:3.78293\ttrain-rmse:1.94637\n",
      "[30878]\teval-rmse:3.78151\ttrain-rmse:1.94641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30879]\teval-rmse:3.78115\ttrain-rmse:1.94643\n",
      "[30880]\teval-rmse:3.78141\ttrain-rmse:1.94642\n",
      "[30881]\teval-rmse:3.78268\ttrain-rmse:1.94637\n",
      "[30882]\teval-rmse:3.78118\ttrain-rmse:1.94642\n",
      "[30883]\teval-rmse:3.78141\ttrain-rmse:1.94642\n",
      "[30884]\teval-rmse:3.78127\ttrain-rmse:1.94638\n",
      "[30885]\teval-rmse:3.7826\ttrain-rmse:1.94634\n",
      "[30886]\teval-rmse:3.78236\ttrain-rmse:1.94635\n",
      "[30887]\teval-rmse:3.78314\ttrain-rmse:1.94632\n",
      "[30888]\teval-rmse:3.7834\ttrain-rmse:1.94632\n",
      "[30889]\teval-rmse:3.7852\ttrain-rmse:1.94626\n",
      "[30890]\teval-rmse:3.78677\ttrain-rmse:1.94622\n",
      "[30891]\teval-rmse:3.78532\ttrain-rmse:1.94625\n",
      "[30892]\teval-rmse:3.78507\ttrain-rmse:1.94626\n",
      "[30893]\teval-rmse:3.78491\ttrain-rmse:1.94626\n",
      "[30894]\teval-rmse:3.78626\ttrain-rmse:1.94623\n",
      "[30895]\teval-rmse:3.78579\ttrain-rmse:1.94624\n",
      "[30896]\teval-rmse:3.78562\ttrain-rmse:1.94625\n",
      "[30897]\teval-rmse:3.78584\ttrain-rmse:1.94624\n",
      "[30898]\teval-rmse:3.78431\ttrain-rmse:1.94628\n",
      "[30899]\teval-rmse:3.78288\ttrain-rmse:1.94632\n",
      "[30900]\teval-rmse:3.78149\ttrain-rmse:1.94637\n",
      "[30901]\teval-rmse:3.7815\ttrain-rmse:1.94637\n",
      "[30902]\teval-rmse:3.78009\ttrain-rmse:1.94643\n",
      "[30903]\teval-rmse:3.78009\ttrain-rmse:1.94643\n",
      "[30904]\teval-rmse:3.78149\ttrain-rmse:1.94637\n",
      "[30905]\teval-rmse:3.78024\ttrain-rmse:1.94643\n",
      "[30906]\teval-rmse:3.78079\ttrain-rmse:1.94641\n",
      "[30907]\teval-rmse:3.78181\ttrain-rmse:1.94637\n",
      "[30908]\teval-rmse:3.78179\ttrain-rmse:1.94637\n",
      "[30909]\teval-rmse:3.78306\ttrain-rmse:1.94633\n",
      "[30910]\teval-rmse:3.78237\ttrain-rmse:1.94635\n",
      "[30911]\teval-rmse:3.78191\ttrain-rmse:1.94637\n",
      "[30912]\teval-rmse:3.78223\ttrain-rmse:1.94636\n",
      "[30913]\teval-rmse:3.78209\ttrain-rmse:1.94636\n",
      "[30914]\teval-rmse:3.78232\ttrain-rmse:1.94635\n",
      "[30915]\teval-rmse:3.7823\ttrain-rmse:1.94635\n",
      "[30916]\teval-rmse:3.78194\ttrain-rmse:1.94637\n",
      "[30917]\teval-rmse:3.78099\ttrain-rmse:1.9464\n",
      "[30918]\teval-rmse:3.78226\ttrain-rmse:1.94636\n",
      "[30919]\teval-rmse:3.78279\ttrain-rmse:1.94634\n",
      "[30920]\teval-rmse:3.78267\ttrain-rmse:1.94631\n",
      "[30921]\teval-rmse:3.78243\ttrain-rmse:1.94632\n",
      "[30922]\teval-rmse:3.78148\ttrain-rmse:1.94635\n",
      "[30923]\teval-rmse:3.7825\ttrain-rmse:1.94632\n",
      "[30924]\teval-rmse:3.78409\ttrain-rmse:1.94627\n",
      "[30925]\teval-rmse:3.78393\ttrain-rmse:1.94627\n",
      "[30926]\teval-rmse:3.78574\ttrain-rmse:1.94621\n",
      "[30927]\teval-rmse:3.78731\ttrain-rmse:1.94618\n",
      "[30928]\teval-rmse:3.78714\ttrain-rmse:1.94619\n",
      "[30929]\teval-rmse:3.78664\ttrain-rmse:1.9462\n",
      "[30930]\teval-rmse:3.78495\ttrain-rmse:1.94623\n",
      "[30931]\teval-rmse:3.78626\ttrain-rmse:1.9462\n",
      "[30932]\teval-rmse:3.78651\ttrain-rmse:1.9462\n",
      "[30933]\teval-rmse:3.7861\ttrain-rmse:1.94621\n",
      "[30934]\teval-rmse:3.78745\ttrain-rmse:1.94619\n",
      "[30935]\teval-rmse:3.78798\ttrain-rmse:1.94618\n",
      "[30936]\teval-rmse:3.78772\ttrain-rmse:1.94619\n",
      "[30937]\teval-rmse:3.78824\ttrain-rmse:1.94618\n",
      "[30938]\teval-rmse:3.78949\ttrain-rmse:1.94616\n",
      "[30939]\teval-rmse:3.78876\ttrain-rmse:1.94617\n",
      "[30940]\teval-rmse:3.78978\ttrain-rmse:1.94617\n",
      "[30941]\teval-rmse:3.79136\ttrain-rmse:1.94614\n",
      "[30942]\teval-rmse:3.7912\ttrain-rmse:1.94611\n",
      "[30943]\teval-rmse:3.79101\ttrain-rmse:1.94611\n",
      "[30944]\teval-rmse:3.78946\ttrain-rmse:1.94611\n",
      "[30945]\teval-rmse:3.79079\ttrain-rmse:1.94611\n",
      "[30946]\teval-rmse:3.78925\ttrain-rmse:1.94612\n",
      "[30947]\teval-rmse:3.78876\ttrain-rmse:1.94613\n",
      "[30948]\teval-rmse:3.79001\ttrain-rmse:1.94612\n",
      "[30949]\teval-rmse:3.78983\ttrain-rmse:1.94612\n",
      "[30950]\teval-rmse:3.79115\ttrain-rmse:1.94611\n",
      "[30951]\teval-rmse:3.78941\ttrain-rmse:1.94611\n",
      "[30952]\teval-rmse:3.79121\ttrain-rmse:1.94608\n",
      "[30953]\teval-rmse:3.7908\ttrain-rmse:1.94608\n",
      "[30954]\teval-rmse:3.79006\ttrain-rmse:1.94608\n",
      "[30955]\teval-rmse:3.78851\ttrain-rmse:1.94609\n",
      "[30956]\teval-rmse:3.78872\ttrain-rmse:1.94609\n",
      "[30957]\teval-rmse:3.7903\ttrain-rmse:1.94607\n",
      "[30958]\teval-rmse:3.7906\ttrain-rmse:1.94606\n",
      "[30959]\teval-rmse:3.79082\ttrain-rmse:1.94606\n",
      "[30960]\teval-rmse:3.79103\ttrain-rmse:1.94606\n",
      "[30961]\teval-rmse:3.78981\ttrain-rmse:1.94608\n",
      "[30962]\teval-rmse:3.79139\ttrain-rmse:1.94605\n",
      "[30963]\teval-rmse:3.79263\ttrain-rmse:1.94605\n",
      "[30964]\teval-rmse:3.7914\ttrain-rmse:1.94607\n",
      "[30965]\teval-rmse:3.79274\ttrain-rmse:1.94606\n",
      "[30966]\teval-rmse:3.79398\ttrain-rmse:1.94607\n",
      "[30967]\teval-rmse:3.79395\ttrain-rmse:1.94607\n",
      "[30968]\teval-rmse:3.79447\ttrain-rmse:1.94607\n",
      "[30969]\teval-rmse:3.79627\ttrain-rmse:1.94606\n",
      "[30970]\teval-rmse:3.79523\ttrain-rmse:1.94606\n",
      "[30971]\teval-rmse:3.79393\ttrain-rmse:1.94605\n",
      "[30972]\teval-rmse:3.79469\ttrain-rmse:1.94604\n",
      "[30973]\teval-rmse:3.79594\ttrain-rmse:1.94605\n",
      "[30974]\teval-rmse:3.79636\ttrain-rmse:1.94606\n",
      "[30975]\teval-rmse:3.79593\ttrain-rmse:1.94605\n",
      "[30976]\teval-rmse:3.79541\ttrain-rmse:1.94605\n",
      "[30977]\teval-rmse:3.79464\ttrain-rmse:1.94604\n",
      "[30978]\teval-rmse:3.79506\ttrain-rmse:1.94605\n",
      "[30979]\teval-rmse:3.7958\ttrain-rmse:1.94605\n",
      "[30980]\teval-rmse:3.79455\ttrain-rmse:1.94605\n",
      "[30981]\teval-rmse:3.79403\ttrain-rmse:1.94605\n",
      "[30982]\teval-rmse:3.79386\ttrain-rmse:1.94601\n",
      "[30983]\teval-rmse:3.7955\ttrain-rmse:1.94603\n",
      "[30984]\teval-rmse:3.7953\ttrain-rmse:1.94603\n",
      "[30985]\teval-rmse:3.79579\ttrain-rmse:1.94604\n",
      "[30986]\teval-rmse:3.79535\ttrain-rmse:1.94604\n",
      "[30987]\teval-rmse:3.79354\ttrain-rmse:1.94602\n",
      "[30988]\teval-rmse:3.79534\ttrain-rmse:1.946\n",
      "[30989]\teval-rmse:3.79377\ttrain-rmse:1.94599\n",
      "[30990]\teval-rmse:3.79204\ttrain-rmse:1.94599\n",
      "[30991]\teval-rmse:3.79203\ttrain-rmse:1.94599\n",
      "[30992]\teval-rmse:3.79175\ttrain-rmse:1.94599\n",
      "[30993]\teval-rmse:3.79201\ttrain-rmse:1.94599\n",
      "[30994]\teval-rmse:3.79326\ttrain-rmse:1.94599\n",
      "[30995]\teval-rmse:3.79225\ttrain-rmse:1.946\n",
      "[30996]\teval-rmse:3.79221\ttrain-rmse:1.946\n",
      "[30997]\teval-rmse:3.79338\ttrain-rmse:1.946\n",
      "[30998]\teval-rmse:3.79413\ttrain-rmse:1.94599\n",
      "[30999]\teval-rmse:3.79257\ttrain-rmse:1.94599\n",
      "[31000]\teval-rmse:3.79133\ttrain-rmse:1.946\n",
      "[31001]\teval-rmse:3.79176\ttrain-rmse:1.94599\n",
      "[31002]\teval-rmse:3.79357\ttrain-rmse:1.94597\n",
      "[31003]\teval-rmse:3.79185\ttrain-rmse:1.94598\n",
      "[31004]\teval-rmse:3.79143\ttrain-rmse:1.94598\n",
      "[31005]\teval-rmse:3.79124\ttrain-rmse:1.94598\n",
      "[31006]\teval-rmse:3.79025\ttrain-rmse:1.946\n",
      "[31007]\teval-rmse:3.79069\ttrain-rmse:1.94599\n",
      "[31008]\teval-rmse:3.7902\ttrain-rmse:1.946\n",
      "[31009]\teval-rmse:3.792\ttrain-rmse:1.94597\n",
      "[31010]\teval-rmse:3.79076\ttrain-rmse:1.94598\n",
      "[31011]\teval-rmse:3.78906\ttrain-rmse:1.94601\n",
      "[31012]\teval-rmse:3.79041\ttrain-rmse:1.94599\n",
      "[31013]\teval-rmse:3.79167\ttrain-rmse:1.94598\n",
      "[31014]\teval-rmse:3.79127\ttrain-rmse:1.94598\n",
      "[31015]\teval-rmse:3.79203\ttrain-rmse:1.94597\n",
      "[31016]\teval-rmse:3.79102\ttrain-rmse:1.94599\n",
      "[31017]\teval-rmse:3.7926\ttrain-rmse:1.94596\n",
      "[31018]\teval-rmse:3.79261\ttrain-rmse:1.94596\n",
      "[31019]\teval-rmse:3.79187\ttrain-rmse:1.94597\n",
      "[31020]\teval-rmse:3.79362\ttrain-rmse:1.94596\n",
      "[31021]\teval-rmse:3.79311\ttrain-rmse:1.94597\n",
      "[31022]\teval-rmse:3.79439\ttrain-rmse:1.94596\n",
      "[31023]\teval-rmse:3.79409\ttrain-rmse:1.94597\n",
      "[31024]\teval-rmse:3.7944\ttrain-rmse:1.94597\n",
      "[31025]\teval-rmse:3.79597\ttrain-rmse:1.94598\n",
      "[31026]\teval-rmse:3.79399\ttrain-rmse:1.94598\n",
      "[31027]\teval-rmse:3.79274\ttrain-rmse:1.94598\n",
      "[31028]\teval-rmse:3.79318\ttrain-rmse:1.94598\n",
      "[31029]\teval-rmse:3.79275\ttrain-rmse:1.94598\n",
      "[31030]\teval-rmse:3.79351\ttrain-rmse:1.94597\n",
      "[31031]\teval-rmse:3.79299\ttrain-rmse:1.94597\n",
      "[31032]\teval-rmse:3.79447\ttrain-rmse:1.94598\n",
      "[31033]\teval-rmse:3.79582\ttrain-rmse:1.94598\n",
      "[31034]\teval-rmse:3.79606\ttrain-rmse:1.94598\n",
      "[31035]\teval-rmse:3.79786\ttrain-rmse:1.94598\n",
      "[31036]\teval-rmse:3.79733\ttrain-rmse:1.94597\n",
      "[31037]\teval-rmse:3.79769\ttrain-rmse:1.94598\n",
      "[31038]\teval-rmse:3.79843\ttrain-rmse:1.94598\n",
      "[31039]\teval-rmse:3.79967\ttrain-rmse:1.946\n",
      "[31040]\teval-rmse:3.80124\ttrain-rmse:1.94601\n",
      "[31041]\teval-rmse:3.80282\ttrain-rmse:1.94605\n",
      "[31042]\teval-rmse:3.80396\ttrain-rmse:1.94609\n",
      "[31043]\teval-rmse:3.80469\ttrain-rmse:1.9461\n",
      "[31044]\teval-rmse:3.80594\ttrain-rmse:1.94615\n",
      "[31045]\teval-rmse:3.80463\ttrain-rmse:1.94611\n",
      "[31046]\teval-rmse:3.80323\ttrain-rmse:1.94608\n",
      "[31047]\teval-rmse:3.80366\ttrain-rmse:1.9461\n",
      "[31048]\teval-rmse:3.8018\ttrain-rmse:1.94605\n",
      "[31049]\teval-rmse:3.80147\ttrain-rmse:1.94605\n",
      "[31050]\teval-rmse:3.80199\ttrain-rmse:1.94606\n",
      "[31051]\teval-rmse:3.80044\ttrain-rmse:1.94602\n",
      "[31052]\teval-rmse:3.80202\ttrain-rmse:1.94606\n",
      "[31053]\teval-rmse:3.80305\ttrain-rmse:1.9461\n",
      "[31054]\teval-rmse:3.80484\ttrain-rmse:1.94612\n",
      "[31055]\teval-rmse:3.80356\ttrain-rmse:1.94607\n",
      "[31056]\teval-rmse:3.80291\ttrain-rmse:1.94605\n",
      "[31057]\teval-rmse:3.80236\ttrain-rmse:1.94604\n",
      "[31058]\teval-rmse:3.80076\ttrain-rmse:1.94599\n",
      "[31059]\teval-rmse:3.79917\ttrain-rmse:1.94596\n",
      "[31060]\teval-rmse:3.79789\ttrain-rmse:1.94595\n",
      "[31061]\teval-rmse:3.7984\ttrain-rmse:1.94596\n",
      "[31062]\teval-rmse:3.79818\ttrain-rmse:1.94592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31063]\teval-rmse:3.7984\ttrain-rmse:1.94592\n",
      "[31064]\teval-rmse:3.79998\ttrain-rmse:1.94593\n",
      "[31065]\teval-rmse:3.80155\ttrain-rmse:1.94595\n",
      "[31066]\teval-rmse:3.80131\ttrain-rmse:1.94594\n",
      "[31067]\teval-rmse:3.80165\ttrain-rmse:1.94595\n",
      "[31068]\teval-rmse:3.80305\ttrain-rmse:1.94598\n",
      "[31069]\teval-rmse:3.80323\ttrain-rmse:1.94598\n",
      "[31070]\teval-rmse:3.80501\ttrain-rmse:1.946\n",
      "[31071]\teval-rmse:3.80467\ttrain-rmse:1.946\n",
      "[31072]\teval-rmse:3.80614\ttrain-rmse:1.94604\n",
      "[31073]\teval-rmse:3.80445\ttrain-rmse:1.94599\n",
      "[31074]\teval-rmse:3.80466\ttrain-rmse:1.946\n",
      "[31075]\teval-rmse:3.80305\ttrain-rmse:1.94596\n",
      "[31076]\teval-rmse:3.80123\ttrain-rmse:1.94591\n",
      "[31077]\teval-rmse:3.80302\ttrain-rmse:1.94595\n",
      "[31078]\teval-rmse:3.80449\ttrain-rmse:1.94599\n",
      "[31079]\teval-rmse:3.80392\ttrain-rmse:1.94597\n",
      "[31080]\teval-rmse:3.80571\ttrain-rmse:1.946\n",
      "[31081]\teval-rmse:3.8075\ttrain-rmse:1.94603\n",
      "[31082]\teval-rmse:3.80769\ttrain-rmse:1.94604\n",
      "[31083]\teval-rmse:3.80636\ttrain-rmse:1.94599\n",
      "[31084]\teval-rmse:3.80482\ttrain-rmse:1.94596\n",
      "[31085]\teval-rmse:3.80555\ttrain-rmse:1.94598\n",
      "[31086]\teval-rmse:3.80402\ttrain-rmse:1.94594\n",
      "[31087]\teval-rmse:3.80377\ttrain-rmse:1.94589\n",
      "[31088]\teval-rmse:3.80398\ttrain-rmse:1.9459\n",
      "[31089]\teval-rmse:3.80576\ttrain-rmse:1.94593\n",
      "[31090]\teval-rmse:3.80607\ttrain-rmse:1.94593\n",
      "[31091]\teval-rmse:3.80658\ttrain-rmse:1.94595\n",
      "[31092]\teval-rmse:3.80836\ttrain-rmse:1.94598\n",
      "[31093]\teval-rmse:3.80962\ttrain-rmse:1.94603\n",
      "[31094]\teval-rmse:3.81011\ttrain-rmse:1.94605\n",
      "[31095]\teval-rmse:3.80878\ttrain-rmse:1.94601\n",
      "[31096]\teval-rmse:3.80876\ttrain-rmse:1.94601\n",
      "[31097]\teval-rmse:3.80926\ttrain-rmse:1.94603\n",
      "[31098]\teval-rmse:3.80761\ttrain-rmse:1.94598\n",
      "[31099]\teval-rmse:3.80888\ttrain-rmse:1.94603\n",
      "[31100]\teval-rmse:3.80861\ttrain-rmse:1.94599\n",
      "[31101]\teval-rmse:3.80964\ttrain-rmse:1.94603\n",
      "[31102]\teval-rmse:3.81112\ttrain-rmse:1.94607\n",
      "[31103]\teval-rmse:3.81236\ttrain-rmse:1.94613\n",
      "[31104]\teval-rmse:3.81101\ttrain-rmse:1.94608\n",
      "[31105]\teval-rmse:3.81041\ttrain-rmse:1.94606\n",
      "[31106]\teval-rmse:3.81061\ttrain-rmse:1.94607\n",
      "[31107]\teval-rmse:3.81239\ttrain-rmse:1.94612\n",
      "[31108]\teval-rmse:3.81159\ttrain-rmse:1.94609\n",
      "[31109]\teval-rmse:3.81046\ttrain-rmse:1.94606\n",
      "[31110]\teval-rmse:3.81094\ttrain-rmse:1.94608\n",
      "[31111]\teval-rmse:3.81014\ttrain-rmse:1.94604\n",
      "[31112]\teval-rmse:3.8085\ttrain-rmse:1.94598\n",
      "[31113]\teval-rmse:3.80791\ttrain-rmse:1.94596\n",
      "[31114]\teval-rmse:3.80651\ttrain-rmse:1.94593\n",
      "[31115]\teval-rmse:3.80737\ttrain-rmse:1.94596\n",
      "[31116]\teval-rmse:3.80787\ttrain-rmse:1.94598\n",
      "[31117]\teval-rmse:3.8074\ttrain-rmse:1.94597\n",
      "[31118]\teval-rmse:3.80604\ttrain-rmse:1.94592\n",
      "[31119]\teval-rmse:3.80601\ttrain-rmse:1.94592\n",
      "[31120]\teval-rmse:3.80624\ttrain-rmse:1.94592\n",
      "[31121]\teval-rmse:3.8078\ttrain-rmse:1.94597\n",
      "[31122]\teval-rmse:3.80652\ttrain-rmse:1.94592\n",
      "[31123]\teval-rmse:3.80497\ttrain-rmse:1.94588\n",
      "[31124]\teval-rmse:3.80368\ttrain-rmse:1.94587\n",
      "[31125]\teval-rmse:3.80343\ttrain-rmse:1.94586\n",
      "[31126]\teval-rmse:3.80394\ttrain-rmse:1.94588\n",
      "[31127]\teval-rmse:3.80529\ttrain-rmse:1.9459\n",
      "[31128]\teval-rmse:3.80473\ttrain-rmse:1.94588\n",
      "[31129]\teval-rmse:3.80525\ttrain-rmse:1.9459\n",
      "[31130]\teval-rmse:3.80363\ttrain-rmse:1.94587\n",
      "[31131]\teval-rmse:3.80361\ttrain-rmse:1.94587\n",
      "[31132]\teval-rmse:3.80383\ttrain-rmse:1.94587\n",
      "[31133]\teval-rmse:3.80541\ttrain-rmse:1.9459\n",
      "[31134]\teval-rmse:3.80378\ttrain-rmse:1.94586\n",
      "[31135]\teval-rmse:3.80353\ttrain-rmse:1.94586\n",
      "[31136]\teval-rmse:3.80501\ttrain-rmse:1.94588\n",
      "[31137]\teval-rmse:3.80627\ttrain-rmse:1.94591\n",
      "[31138]\teval-rmse:3.80752\ttrain-rmse:1.94595\n",
      "[31139]\teval-rmse:3.80696\ttrain-rmse:1.94594\n",
      "[31140]\teval-rmse:3.8067\ttrain-rmse:1.94593\n",
      "[31141]\teval-rmse:3.80515\ttrain-rmse:1.94589\n",
      "[31142]\teval-rmse:3.8049\ttrain-rmse:1.94585\n",
      "[31143]\teval-rmse:3.80488\ttrain-rmse:1.94585\n",
      "[31144]\teval-rmse:3.80464\ttrain-rmse:1.94581\n",
      "[31145]\teval-rmse:3.80482\ttrain-rmse:1.94582\n",
      "[31146]\teval-rmse:3.80661\ttrain-rmse:1.94585\n",
      "[31147]\teval-rmse:3.8052\ttrain-rmse:1.94582\n",
      "[31148]\teval-rmse:3.80581\ttrain-rmse:1.94584\n",
      "[31149]\teval-rmse:3.80525\ttrain-rmse:1.94582\n",
      "[31150]\teval-rmse:3.80599\ttrain-rmse:1.94585\n",
      "[31151]\teval-rmse:3.80574\ttrain-rmse:1.94581\n",
      "[31152]\teval-rmse:3.80517\ttrain-rmse:1.9458\n",
      "[31153]\teval-rmse:3.80673\ttrain-rmse:1.94585\n",
      "[31154]\teval-rmse:3.80563\ttrain-rmse:1.94583\n",
      "[31155]\teval-rmse:3.80528\ttrain-rmse:1.94583\n",
      "[31156]\teval-rmse:3.80506\ttrain-rmse:1.94579\n",
      "[31157]\teval-rmse:3.80684\ttrain-rmse:1.94582\n",
      "[31158]\teval-rmse:3.80649\ttrain-rmse:1.94581\n",
      "[31159]\teval-rmse:3.80777\ttrain-rmse:1.94586\n",
      "[31160]\teval-rmse:3.80645\ttrain-rmse:1.94583\n",
      "[31161]\teval-rmse:3.80619\ttrain-rmse:1.94583\n",
      "[31162]\teval-rmse:3.80466\ttrain-rmse:1.94576\n",
      "[31163]\teval-rmse:3.80516\ttrain-rmse:1.94578\n",
      "[31164]\teval-rmse:3.80618\ttrain-rmse:1.94582\n",
      "[31165]\teval-rmse:3.80465\ttrain-rmse:1.94578\n",
      "[31166]\teval-rmse:3.80505\ttrain-rmse:1.94579\n",
      "[31167]\teval-rmse:3.8048\ttrain-rmse:1.94575\n",
      "[31168]\teval-rmse:3.80372\ttrain-rmse:1.94574\n",
      "[31169]\teval-rmse:3.80338\ttrain-rmse:1.94573\n",
      "[31170]\teval-rmse:3.80361\ttrain-rmse:1.94574\n",
      "[31171]\teval-rmse:3.80495\ttrain-rmse:1.94579\n",
      "[31172]\teval-rmse:3.80553\ttrain-rmse:1.94581\n",
      "[31173]\teval-rmse:3.80495\ttrain-rmse:1.9458\n",
      "[31174]\teval-rmse:3.80415\ttrain-rmse:1.94577\n",
      "[31175]\teval-rmse:3.80412\ttrain-rmse:1.94577\n",
      "[31176]\teval-rmse:3.80283\ttrain-rmse:1.94576\n",
      "[31177]\teval-rmse:3.8025\ttrain-rmse:1.94575\n",
      "[31178]\teval-rmse:3.80226\ttrain-rmse:1.94575\n",
      "[31179]\teval-rmse:3.8035\ttrain-rmse:1.94577\n",
      "[31180]\teval-rmse:3.80316\ttrain-rmse:1.94577\n",
      "[31181]\teval-rmse:3.80401\ttrain-rmse:1.9458\n",
      "[31182]\teval-rmse:3.80472\ttrain-rmse:1.94582\n",
      "[31183]\teval-rmse:3.8045\ttrain-rmse:1.94578\n",
      "[31184]\teval-rmse:3.80627\ttrain-rmse:1.94581\n",
      "[31185]\teval-rmse:3.80571\ttrain-rmse:1.9458\n",
      "[31186]\teval-rmse:3.80515\ttrain-rmse:1.94579\n",
      "[31187]\teval-rmse:3.8049\ttrain-rmse:1.94578\n",
      "[31188]\teval-rmse:3.80506\ttrain-rmse:1.94579\n",
      "[31189]\teval-rmse:3.80527\ttrain-rmse:1.9458\n",
      "[31190]\teval-rmse:3.80598\ttrain-rmse:1.94582\n",
      "[31191]\teval-rmse:3.80638\ttrain-rmse:1.94584\n",
      "[31192]\teval-rmse:3.80772\ttrain-rmse:1.94588\n",
      "[31193]\teval-rmse:3.80629\ttrain-rmse:1.94582\n",
      "[31194]\teval-rmse:3.80474\ttrain-rmse:1.94577\n",
      "[31195]\teval-rmse:3.805\ttrain-rmse:1.94579\n",
      "[31196]\teval-rmse:3.80338\ttrain-rmse:1.94574\n",
      "[31197]\teval-rmse:3.80282\ttrain-rmse:1.94573\n",
      "[31198]\teval-rmse:3.80148\ttrain-rmse:1.94568\n",
      "[31199]\teval-rmse:3.80252\ttrain-rmse:1.94571\n",
      "[31200]\teval-rmse:3.80173\ttrain-rmse:1.94569\n",
      "[31201]\teval-rmse:3.8033\ttrain-rmse:1.94572\n",
      "[31202]\teval-rmse:3.80297\ttrain-rmse:1.94572\n",
      "[31203]\teval-rmse:3.80348\ttrain-rmse:1.94574\n",
      "[31204]\teval-rmse:3.80499\ttrain-rmse:1.9458\n",
      "[31205]\teval-rmse:3.8039\ttrain-rmse:1.94579\n",
      "[31206]\teval-rmse:3.80408\ttrain-rmse:1.94579\n",
      "[31207]\teval-rmse:3.80457\ttrain-rmse:1.94581\n",
      "[31208]\teval-rmse:3.80328\ttrain-rmse:1.94579\n",
      "[31209]\teval-rmse:3.80451\ttrain-rmse:1.94584\n",
      "[31210]\teval-rmse:3.80445\ttrain-rmse:1.94583\n",
      "[31211]\teval-rmse:3.80602\ttrain-rmse:1.94587\n",
      "[31212]\teval-rmse:3.80448\ttrain-rmse:1.94582\n",
      "[31213]\teval-rmse:3.80424\ttrain-rmse:1.94579\n",
      "[31214]\teval-rmse:3.80602\ttrain-rmse:1.94581\n",
      "[31215]\teval-rmse:3.80554\ttrain-rmse:1.9458\n",
      "[31216]\teval-rmse:3.80567\ttrain-rmse:1.9458\n",
      "[31217]\teval-rmse:3.80724\ttrain-rmse:1.94585\n",
      "[31218]\teval-rmse:3.80746\ttrain-rmse:1.94586\n",
      "[31219]\teval-rmse:3.80869\ttrain-rmse:1.94593\n",
      "[31220]\teval-rmse:3.81025\ttrain-rmse:1.946\n",
      "[31221]\teval-rmse:3.80997\ttrain-rmse:1.94599\n",
      "[31222]\teval-rmse:3.80816\ttrain-rmse:1.94589\n",
      "[31223]\teval-rmse:3.80947\ttrain-rmse:1.94595\n",
      "[31224]\teval-rmse:3.81047\ttrain-rmse:1.94602\n",
      "[31225]\teval-rmse:3.80904\ttrain-rmse:1.94598\n",
      "[31226]\teval-rmse:3.81049\ttrain-rmse:1.94604\n",
      "[31227]\teval-rmse:3.81066\ttrain-rmse:1.94606\n",
      "[31228]\teval-rmse:3.81105\ttrain-rmse:1.94608\n",
      "[31229]\teval-rmse:3.81261\ttrain-rmse:1.9462\n",
      "[31230]\teval-rmse:3.81384\ttrain-rmse:1.9463\n",
      "[31231]\teval-rmse:3.81397\ttrain-rmse:1.94631\n",
      "[31232]\teval-rmse:3.81466\ttrain-rmse:1.94635\n",
      "[31233]\teval-rmse:3.81298\ttrain-rmse:1.94625\n",
      "[31234]\teval-rmse:3.81356\ttrain-rmse:1.94629\n",
      "[31235]\teval-rmse:3.81479\ttrain-rmse:1.94636\n",
      "[31236]\teval-rmse:3.81331\ttrain-rmse:1.94627\n",
      "[31237]\teval-rmse:3.81121\ttrain-rmse:1.94614\n",
      "[31238]\teval-rmse:3.81267\ttrain-rmse:1.94622\n",
      "[31239]\teval-rmse:3.81184\ttrain-rmse:1.94618\n",
      "[31240]\teval-rmse:3.81209\ttrain-rmse:1.9462\n",
      "[31241]\teval-rmse:3.81073\ttrain-rmse:1.94612\n",
      "[31242]\teval-rmse:3.81219\ttrain-rmse:1.94617\n",
      "[31243]\teval-rmse:3.81039\ttrain-rmse:1.94606\n",
      "[31244]\teval-rmse:3.81012\ttrain-rmse:1.94602\n",
      "[31245]\teval-rmse:3.81027\ttrain-rmse:1.94602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31246]\teval-rmse:3.81042\ttrain-rmse:1.94603\n",
      "[31247]\teval-rmse:3.8096\ttrain-rmse:1.94598\n",
      "[31248]\teval-rmse:3.80803\ttrain-rmse:1.94589\n",
      "[31249]\teval-rmse:3.80828\ttrain-rmse:1.9459\n",
      "[31250]\teval-rmse:3.80977\ttrain-rmse:1.94594\n",
      "[31251]\teval-rmse:3.80832\ttrain-rmse:1.94588\n",
      "[31252]\teval-rmse:3.80977\ttrain-rmse:1.94593\n",
      "[31253]\teval-rmse:3.81155\ttrain-rmse:1.94598\n",
      "[31254]\teval-rmse:3.81175\ttrain-rmse:1.94599\n",
      "[31255]\teval-rmse:3.81114\ttrain-rmse:1.94596\n",
      "[31256]\teval-rmse:3.81065\ttrain-rmse:1.94594\n",
      "[31257]\teval-rmse:3.81063\ttrain-rmse:1.94594\n",
      "[31258]\teval-rmse:3.81112\ttrain-rmse:1.94597\n",
      "[31259]\teval-rmse:3.81074\ttrain-rmse:1.94596\n",
      "[31260]\teval-rmse:3.81075\ttrain-rmse:1.94596\n",
      "[31261]\teval-rmse:3.81124\ttrain-rmse:1.94599\n",
      "[31262]\teval-rmse:3.81281\ttrain-rmse:1.94604\n",
      "[31263]\teval-rmse:3.81198\ttrain-rmse:1.94598\n",
      "[31264]\teval-rmse:3.81353\ttrain-rmse:1.94606\n",
      "[31265]\teval-rmse:3.81218\ttrain-rmse:1.94602\n",
      "[31266]\teval-rmse:3.81061\ttrain-rmse:1.94591\n",
      "[31267]\teval-rmse:3.80918\ttrain-rmse:1.94583\n",
      "[31268]\teval-rmse:3.81064\ttrain-rmse:1.94587\n",
      "[31269]\teval-rmse:3.81027\ttrain-rmse:1.94586\n",
      "[31270]\teval-rmse:3.81022\ttrain-rmse:1.94586\n",
      "[31271]\teval-rmse:3.81168\ttrain-rmse:1.94594\n",
      "[31272]\teval-rmse:3.81139\ttrain-rmse:1.94593\n",
      "[31273]\teval-rmse:3.8095\ttrain-rmse:1.94585\n",
      "[31274]\teval-rmse:3.80762\ttrain-rmse:1.94575\n",
      "[31275]\teval-rmse:3.80651\ttrain-rmse:1.94572\n",
      "[31276]\teval-rmse:3.80625\ttrain-rmse:1.94572\n",
      "[31277]\teval-rmse:3.8047\ttrain-rmse:1.94567\n",
      "[31278]\teval-rmse:3.80361\ttrain-rmse:1.94565\n",
      "[31279]\teval-rmse:3.80518\ttrain-rmse:1.9457\n",
      "[31280]\teval-rmse:3.80643\ttrain-rmse:1.94575\n",
      "[31281]\teval-rmse:3.80798\ttrain-rmse:1.94582\n",
      "[31282]\teval-rmse:3.80838\ttrain-rmse:1.94584\n",
      "[31283]\teval-rmse:3.80995\ttrain-rmse:1.9459\n",
      "[31284]\teval-rmse:3.80838\ttrain-rmse:1.94584\n",
      "[31285]\teval-rmse:3.80657\ttrain-rmse:1.94575\n",
      "[31286]\teval-rmse:3.80495\ttrain-rmse:1.94568\n",
      "[31287]\teval-rmse:3.80385\ttrain-rmse:1.94566\n",
      "[31288]\teval-rmse:3.80224\ttrain-rmse:1.94561\n",
      "[31289]\teval-rmse:3.80349\ttrain-rmse:1.94565\n",
      "[31290]\teval-rmse:3.8024\ttrain-rmse:1.94563\n",
      "[31291]\teval-rmse:3.80291\ttrain-rmse:1.94565\n",
      "[31292]\teval-rmse:3.8033\ttrain-rmse:1.94566\n",
      "[31293]\teval-rmse:3.80353\ttrain-rmse:1.94567\n",
      "[31294]\teval-rmse:3.80276\ttrain-rmse:1.94564\n",
      "[31295]\teval-rmse:3.80333\ttrain-rmse:1.94566\n",
      "[31296]\teval-rmse:3.8048\ttrain-rmse:1.9457\n",
      "[31297]\teval-rmse:3.80433\ttrain-rmse:1.94569\n",
      "[31298]\teval-rmse:3.80541\ttrain-rmse:1.94573\n",
      "[31299]\teval-rmse:3.80687\ttrain-rmse:1.94578\n",
      "[31300]\teval-rmse:3.80546\ttrain-rmse:1.94575\n",
      "[31301]\teval-rmse:3.8039\ttrain-rmse:1.9457\n",
      "[31302]\teval-rmse:3.80463\ttrain-rmse:1.94572\n",
      "[31303]\teval-rmse:3.80484\ttrain-rmse:1.94572\n",
      "[31304]\teval-rmse:3.80485\ttrain-rmse:1.94572\n",
      "[31305]\teval-rmse:3.80407\ttrain-rmse:1.94569\n",
      "[31306]\teval-rmse:3.80447\ttrain-rmse:1.9457\n",
      "[31307]\teval-rmse:3.80413\ttrain-rmse:1.9457\n",
      "[31308]\teval-rmse:3.80389\ttrain-rmse:1.94566\n",
      "[31309]\teval-rmse:3.8028\ttrain-rmse:1.94565\n",
      "[31310]\teval-rmse:3.80299\ttrain-rmse:1.94565\n",
      "[31311]\teval-rmse:3.80169\ttrain-rmse:1.94562\n",
      "[31312]\teval-rmse:3.80202\ttrain-rmse:1.94563\n",
      "[31313]\teval-rmse:3.80198\ttrain-rmse:1.94562\n",
      "[31314]\teval-rmse:3.80174\ttrain-rmse:1.94562\n",
      "[31315]\teval-rmse:3.80036\ttrain-rmse:1.94561\n",
      "[31316]\teval-rmse:3.79876\ttrain-rmse:1.94557\n",
      "[31317]\teval-rmse:3.79895\ttrain-rmse:1.94558\n",
      "[31318]\teval-rmse:3.80052\ttrain-rmse:1.9456\n",
      "[31319]\teval-rmse:3.80178\ttrain-rmse:1.94565\n",
      "[31320]\teval-rmse:3.80334\ttrain-rmse:1.94569\n",
      "[31321]\teval-rmse:3.80491\ttrain-rmse:1.94572\n",
      "[31322]\teval-rmse:3.80363\ttrain-rmse:1.94566\n",
      "[31323]\teval-rmse:3.80223\ttrain-rmse:1.94564\n",
      "[31324]\teval-rmse:3.80084\ttrain-rmse:1.94561\n",
      "[31325]\teval-rmse:3.80185\ttrain-rmse:1.94564\n",
      "[31326]\teval-rmse:3.79982\ttrain-rmse:1.94558\n",
      "[31327]\teval-rmse:3.79926\ttrain-rmse:1.94556\n",
      "[31328]\teval-rmse:3.79799\ttrain-rmse:1.94556\n",
      "[31329]\teval-rmse:3.79639\ttrain-rmse:1.94554\n",
      "[31330]\teval-rmse:3.79772\ttrain-rmse:1.94556\n",
      "[31331]\teval-rmse:3.79896\ttrain-rmse:1.94558\n",
      "[31332]\teval-rmse:3.79819\ttrain-rmse:1.94557\n",
      "[31333]\teval-rmse:3.79816\ttrain-rmse:1.94557\n",
      "[31334]\teval-rmse:3.79917\ttrain-rmse:1.94559\n",
      "[31335]\teval-rmse:3.8005\ttrain-rmse:1.94562\n",
      "[31336]\teval-rmse:3.80187\ttrain-rmse:1.94565\n",
      "[31337]\teval-rmse:3.8008\ttrain-rmse:1.94564\n",
      "[31338]\teval-rmse:3.80121\ttrain-rmse:1.94566\n",
      "[31339]\teval-rmse:3.80118\ttrain-rmse:1.94566\n",
      "[31340]\teval-rmse:3.80158\ttrain-rmse:1.94566\n",
      "[31341]\teval-rmse:3.80336\ttrain-rmse:1.94569\n",
      "[31342]\teval-rmse:3.80134\ttrain-rmse:1.94561\n",
      "[31343]\teval-rmse:3.80151\ttrain-rmse:1.94562\n",
      "[31344]\teval-rmse:3.80224\ttrain-rmse:1.94565\n",
      "[31345]\teval-rmse:3.80169\ttrain-rmse:1.94563\n",
      "[31346]\teval-rmse:3.80146\ttrain-rmse:1.94563\n",
      "[31347]\teval-rmse:3.80016\ttrain-rmse:1.9456\n",
      "[31348]\teval-rmse:3.8015\ttrain-rmse:1.94563\n",
      "[31349]\teval-rmse:3.80129\ttrain-rmse:1.94563\n",
      "[31350]\teval-rmse:3.79998\ttrain-rmse:1.94559\n",
      "[31351]\teval-rmse:3.7987\ttrain-rmse:1.94558\n",
      "[31352]\teval-rmse:3.79765\ttrain-rmse:1.94558\n",
      "[31353]\teval-rmse:3.79738\ttrain-rmse:1.94555\n",
      "[31354]\teval-rmse:3.79611\ttrain-rmse:1.94553\n",
      "[31355]\teval-rmse:3.79686\ttrain-rmse:1.94554\n",
      "[31356]\teval-rmse:3.79666\ttrain-rmse:1.94554\n",
      "[31357]\teval-rmse:3.79508\ttrain-rmse:1.9455\n",
      "[31358]\teval-rmse:3.79374\ttrain-rmse:1.94549\n",
      "[31359]\teval-rmse:3.79424\ttrain-rmse:1.9455\n",
      "[31360]\teval-rmse:3.7929\ttrain-rmse:1.94551\n",
      "[31361]\teval-rmse:3.7943\ttrain-rmse:1.94552\n",
      "[31362]\teval-rmse:3.79554\ttrain-rmse:1.94553\n",
      "[31363]\teval-rmse:3.79688\ttrain-rmse:1.94554\n",
      "[31364]\teval-rmse:3.7961\ttrain-rmse:1.94552\n",
      "[31365]\teval-rmse:3.79484\ttrain-rmse:1.9455\n",
      "[31366]\teval-rmse:3.79535\ttrain-rmse:1.9455\n",
      "[31367]\teval-rmse:3.79692\ttrain-rmse:1.9455\n",
      "[31368]\teval-rmse:3.79817\ttrain-rmse:1.94552\n",
      "[31369]\teval-rmse:3.7989\ttrain-rmse:1.94554\n",
      "[31370]\teval-rmse:3.7993\ttrain-rmse:1.94555\n",
      "[31371]\teval-rmse:3.7997\ttrain-rmse:1.94555\n",
      "[31372]\teval-rmse:3.79809\ttrain-rmse:1.94553\n",
      "[31373]\teval-rmse:3.79883\ttrain-rmse:1.94553\n",
      "[31374]\teval-rmse:3.79756\ttrain-rmse:1.94553\n",
      "[31375]\teval-rmse:3.79751\ttrain-rmse:1.94552\n",
      "[31376]\teval-rmse:3.7975\ttrain-rmse:1.94552\n",
      "[31377]\teval-rmse:3.79851\ttrain-rmse:1.94555\n",
      "[31378]\teval-rmse:3.79819\ttrain-rmse:1.94555\n",
      "[31379]\teval-rmse:3.79816\ttrain-rmse:1.94555\n",
      "[31380]\teval-rmse:3.79963\ttrain-rmse:1.94556\n",
      "[31381]\teval-rmse:3.79804\ttrain-rmse:1.94551\n",
      "[31382]\teval-rmse:3.79727\ttrain-rmse:1.9455\n",
      "[31383]\teval-rmse:3.79622\ttrain-rmse:1.9455\n",
      "[31384]\teval-rmse:3.79569\ttrain-rmse:1.94549\n",
      "[31385]\teval-rmse:3.79547\ttrain-rmse:1.94549\n",
      "[31386]\teval-rmse:3.79726\ttrain-rmse:1.94549\n",
      "[31387]\teval-rmse:3.79874\ttrain-rmse:1.94553\n",
      "[31388]\teval-rmse:3.79818\ttrain-rmse:1.94552\n",
      "[31389]\teval-rmse:3.79798\ttrain-rmse:1.94551\n",
      "[31390]\teval-rmse:3.79639\ttrain-rmse:1.94549\n",
      "[31391]\teval-rmse:3.79594\ttrain-rmse:1.94548\n",
      "[31392]\teval-rmse:3.7972\ttrain-rmse:1.9455\n",
      "[31393]\teval-rmse:3.79698\ttrain-rmse:1.94547\n",
      "[31394]\teval-rmse:3.79677\ttrain-rmse:1.94544\n",
      "[31395]\teval-rmse:3.79833\ttrain-rmse:1.94546\n",
      "[31396]\teval-rmse:3.7999\ttrain-rmse:1.9455\n",
      "[31397]\teval-rmse:3.79967\ttrain-rmse:1.9455\n",
      "[31398]\teval-rmse:3.79934\ttrain-rmse:1.94549\n",
      "[31399]\teval-rmse:3.79807\ttrain-rmse:1.94547\n",
      "[31400]\teval-rmse:3.79826\ttrain-rmse:1.94548\n",
      "[31401]\teval-rmse:3.79699\ttrain-rmse:1.94547\n",
      "[31402]\teval-rmse:3.79812\ttrain-rmse:1.9455\n",
      "[31403]\teval-rmse:3.79945\ttrain-rmse:1.94555\n",
      "[31404]\teval-rmse:3.8009\ttrain-rmse:1.94557\n",
      "[31405]\teval-rmse:3.80043\ttrain-rmse:1.94556\n",
      "[31406]\teval-rmse:3.79905\ttrain-rmse:1.94554\n",
      "[31407]\teval-rmse:3.79943\ttrain-rmse:1.94555\n",
      "[31408]\teval-rmse:3.80121\ttrain-rmse:1.94556\n",
      "[31409]\teval-rmse:3.79958\ttrain-rmse:1.94552\n",
      "[31410]\teval-rmse:3.7992\ttrain-rmse:1.9455\n",
      "[31411]\teval-rmse:3.7997\ttrain-rmse:1.94551\n",
      "[31412]\teval-rmse:3.79914\ttrain-rmse:1.94549\n",
      "[31413]\teval-rmse:3.79947\ttrain-rmse:1.9455\n",
      "[31414]\teval-rmse:3.79924\ttrain-rmse:1.9455\n",
      "[31415]\teval-rmse:3.79974\ttrain-rmse:1.94551\n",
      "[31416]\teval-rmse:3.80014\ttrain-rmse:1.94552\n",
      "[31417]\teval-rmse:3.79863\ttrain-rmse:1.94547\n",
      "[31418]\teval-rmse:3.8001\ttrain-rmse:1.94549\n",
      "[31419]\teval-rmse:3.7999\ttrain-rmse:1.94549\n",
      "[31420]\teval-rmse:3.79862\ttrain-rmse:1.94547\n",
      "[31421]\teval-rmse:3.79913\ttrain-rmse:1.94547\n",
      "[31422]\teval-rmse:3.80015\ttrain-rmse:1.94551\n",
      "[31423]\teval-rmse:3.80172\ttrain-rmse:1.94552\n",
      "[31424]\teval-rmse:3.80042\ttrain-rmse:1.94549\n",
      "[31425]\teval-rmse:3.8006\ttrain-rmse:1.94549\n",
      "[31426]\teval-rmse:3.80215\ttrain-rmse:1.94552\n",
      "[31427]\teval-rmse:3.80169\ttrain-rmse:1.94552\n",
      "[31428]\teval-rmse:3.80302\ttrain-rmse:1.94555\n",
      "[31429]\teval-rmse:3.80173\ttrain-rmse:1.94553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31430]\teval-rmse:3.80351\ttrain-rmse:1.94555\n",
      "[31431]\teval-rmse:3.80305\ttrain-rmse:1.94554\n",
      "[31432]\teval-rmse:3.80429\ttrain-rmse:1.94559\n",
      "[31433]\teval-rmse:3.80426\ttrain-rmse:1.94559\n",
      "[31434]\teval-rmse:3.8058\ttrain-rmse:1.94564\n",
      "[31435]\teval-rmse:3.8044\ttrain-rmse:1.94561\n",
      "[31436]\teval-rmse:3.80358\ttrain-rmse:1.94558\n",
      "[31437]\teval-rmse:3.80302\ttrain-rmse:1.94556\n",
      "[31438]\teval-rmse:3.8048\ttrain-rmse:1.94559\n",
      "[31439]\teval-rmse:3.80327\ttrain-rmse:1.94554\n",
      "[31440]\teval-rmse:3.80144\ttrain-rmse:1.94547\n",
      "[31441]\teval-rmse:3.80013\ttrain-rmse:1.94544\n",
      "[31442]\teval-rmse:3.79885\ttrain-rmse:1.94542\n",
      "[31443]\teval-rmse:3.80009\ttrain-rmse:1.94545\n",
      "[31444]\teval-rmse:3.80134\ttrain-rmse:1.94548\n",
      "[31445]\teval-rmse:3.80206\ttrain-rmse:1.94549\n",
      "[31446]\teval-rmse:3.80321\ttrain-rmse:1.94553\n",
      "[31447]\teval-rmse:3.80444\ttrain-rmse:1.94557\n",
      "[31448]\teval-rmse:3.80376\ttrain-rmse:1.94554\n",
      "[31449]\teval-rmse:3.80555\ttrain-rmse:1.94557\n",
      "[31450]\teval-rmse:3.80422\ttrain-rmse:1.94553\n",
      "[31451]\teval-rmse:3.80557\ttrain-rmse:1.94559\n",
      "[31452]\teval-rmse:3.80597\ttrain-rmse:1.9456\n",
      "[31453]\teval-rmse:3.80653\ttrain-rmse:1.94563\n",
      "[31454]\teval-rmse:3.80776\ttrain-rmse:1.94569\n",
      "[31455]\teval-rmse:3.80609\ttrain-rmse:1.94563\n",
      "[31456]\teval-rmse:3.80586\ttrain-rmse:1.94562\n",
      "[31457]\teval-rmse:3.8056\ttrain-rmse:1.94558\n",
      "[31458]\teval-rmse:3.80502\ttrain-rmse:1.94556\n",
      "[31459]\teval-rmse:3.80421\ttrain-rmse:1.94553\n",
      "[31460]\teval-rmse:3.8046\ttrain-rmse:1.94554\n",
      "[31461]\teval-rmse:3.805\ttrain-rmse:1.94556\n",
      "[31462]\teval-rmse:3.80678\ttrain-rmse:1.94559\n",
      "[31463]\teval-rmse:3.80833\ttrain-rmse:1.94566\n",
      "[31464]\teval-rmse:3.80701\ttrain-rmse:1.9456\n",
      "[31465]\teval-rmse:3.80675\ttrain-rmse:1.94556\n",
      "[31466]\teval-rmse:3.80713\ttrain-rmse:1.94558\n",
      "[31467]\teval-rmse:3.80663\ttrain-rmse:1.94556\n",
      "[31468]\teval-rmse:3.80657\ttrain-rmse:1.94556\n",
      "[31469]\teval-rmse:3.80781\ttrain-rmse:1.94561\n",
      "[31470]\teval-rmse:3.80903\ttrain-rmse:1.94566\n",
      "[31471]\teval-rmse:3.80747\ttrain-rmse:1.9456\n",
      "[31472]\teval-rmse:3.8072\ttrain-rmse:1.94559\n",
      "[31473]\teval-rmse:3.80876\ttrain-rmse:1.94563\n",
      "[31474]\teval-rmse:3.81032\ttrain-rmse:1.94567\n",
      "[31475]\teval-rmse:3.81005\ttrain-rmse:1.94566\n",
      "[31476]\teval-rmse:3.81182\ttrain-rmse:1.94572\n",
      "[31477]\teval-rmse:3.81069\ttrain-rmse:1.94568\n",
      "[31478]\teval-rmse:3.81193\ttrain-rmse:1.94575\n",
      "[31479]\teval-rmse:3.81166\ttrain-rmse:1.94574\n",
      "[31480]\teval-rmse:3.81312\ttrain-rmse:1.94581\n",
      "[31481]\teval-rmse:3.81175\ttrain-rmse:1.94574\n",
      "[31482]\teval-rmse:3.81283\ttrain-rmse:1.94581\n",
      "[31483]\teval-rmse:3.8146\ttrain-rmse:1.94587\n",
      "[31484]\teval-rmse:3.81292\ttrain-rmse:1.94575\n",
      "[31485]\teval-rmse:3.81124\ttrain-rmse:1.94564\n",
      "[31486]\teval-rmse:3.80937\ttrain-rmse:1.94555\n",
      "[31487]\teval-rmse:3.80972\ttrain-rmse:1.94556\n",
      "[31488]\teval-rmse:3.80914\ttrain-rmse:1.94554\n",
      "[31489]\teval-rmse:3.80962\ttrain-rmse:1.94557\n",
      "[31490]\teval-rmse:3.81011\ttrain-rmse:1.94559\n",
      "[31491]\teval-rmse:3.81008\ttrain-rmse:1.94559\n",
      "[31492]\teval-rmse:3.81029\ttrain-rmse:1.9456\n",
      "[31493]\teval-rmse:3.8097\ttrain-rmse:1.94557\n",
      "[31494]\teval-rmse:3.80835\ttrain-rmse:1.94552\n",
      "[31495]\teval-rmse:3.80853\ttrain-rmse:1.94553\n",
      "[31496]\teval-rmse:3.80773\ttrain-rmse:1.94549\n",
      "[31497]\teval-rmse:3.80907\ttrain-rmse:1.94554\n",
      "[31498]\teval-rmse:3.80742\ttrain-rmse:1.94548\n",
      "[31499]\teval-rmse:3.80601\ttrain-rmse:1.94543\n",
      "[31500]\teval-rmse:3.80758\ttrain-rmse:1.94546\n",
      "[31501]\teval-rmse:3.8083\ttrain-rmse:1.94548\n",
      "[31502]\teval-rmse:3.80947\ttrain-rmse:1.94553\n",
      "[31503]\teval-rmse:3.80944\ttrain-rmse:1.94553\n",
      "[31504]\teval-rmse:3.81079\ttrain-rmse:1.94559\n",
      "[31505]\teval-rmse:3.81053\ttrain-rmse:1.94555\n",
      "[31506]\teval-rmse:3.81071\ttrain-rmse:1.94556\n",
      "[31507]\teval-rmse:3.81013\ttrain-rmse:1.94553\n",
      "[31508]\teval-rmse:3.80975\ttrain-rmse:1.94552\n",
      "[31509]\teval-rmse:3.80972\ttrain-rmse:1.94552\n",
      "[31510]\teval-rmse:3.81098\ttrain-rmse:1.94559\n",
      "[31511]\teval-rmse:3.80962\ttrain-rmse:1.94553\n",
      "[31512]\teval-rmse:3.80829\ttrain-rmse:1.94547\n",
      "[31513]\teval-rmse:3.80877\ttrain-rmse:1.94549\n",
      "[31514]\teval-rmse:3.81033\ttrain-rmse:1.94556\n",
      "[31515]\teval-rmse:3.80995\ttrain-rmse:1.94555\n",
      "[31516]\teval-rmse:3.81011\ttrain-rmse:1.94555\n",
      "[31517]\teval-rmse:3.81167\ttrain-rmse:1.94562\n",
      "[31518]\teval-rmse:3.81139\ttrain-rmse:1.94561\n",
      "[31519]\teval-rmse:3.81089\ttrain-rmse:1.94559\n",
      "[31520]\teval-rmse:3.81245\ttrain-rmse:1.94564\n",
      "[31521]\teval-rmse:3.81282\ttrain-rmse:1.94566\n",
      "[31522]\teval-rmse:3.81428\ttrain-rmse:1.94573\n",
      "[31523]\teval-rmse:3.81313\ttrain-rmse:1.94569\n",
      "[31524]\teval-rmse:3.81459\ttrain-rmse:1.94577\n",
      "[31525]\teval-rmse:3.81321\ttrain-rmse:1.9457\n",
      "[31526]\teval-rmse:3.81339\ttrain-rmse:1.94571\n",
      "[31527]\teval-rmse:3.81286\ttrain-rmse:1.94569\n",
      "[31528]\teval-rmse:3.81304\ttrain-rmse:1.9457\n",
      "[31529]\teval-rmse:3.81275\ttrain-rmse:1.94569\n",
      "[31530]\teval-rmse:3.81213\ttrain-rmse:1.94565\n",
      "[31531]\teval-rmse:3.81054\ttrain-rmse:1.94558\n",
      "[31532]\teval-rmse:3.81113\ttrain-rmse:1.94561\n",
      "[31533]\teval-rmse:3.80924\ttrain-rmse:1.94552\n",
      "[31534]\teval-rmse:3.80919\ttrain-rmse:1.94552\n",
      "[31535]\teval-rmse:3.80763\ttrain-rmse:1.94546\n",
      "[31536]\teval-rmse:3.80584\ttrain-rmse:1.94539\n",
      "[31537]\teval-rmse:3.80604\ttrain-rmse:1.9454\n",
      "[31538]\teval-rmse:3.80728\ttrain-rmse:1.94544\n",
      "[31539]\teval-rmse:3.80862\ttrain-rmse:1.94551\n",
      "[31540]\teval-rmse:3.80706\ttrain-rmse:1.94543\n",
      "[31541]\teval-rmse:3.80553\ttrain-rmse:1.94536\n",
      "[31542]\teval-rmse:3.80586\ttrain-rmse:1.94537\n",
      "[31543]\teval-rmse:3.80732\ttrain-rmse:1.94543\n",
      "[31544]\teval-rmse:3.8091\ttrain-rmse:1.94548\n",
      "[31545]\teval-rmse:3.81087\ttrain-rmse:1.94552\n",
      "[31546]\teval-rmse:3.81243\ttrain-rmse:1.9456\n",
      "[31547]\teval-rmse:3.81314\ttrain-rmse:1.94564\n",
      "[31548]\teval-rmse:3.81353\ttrain-rmse:1.94566\n",
      "[31549]\teval-rmse:3.81475\ttrain-rmse:1.94572\n",
      "[31550]\teval-rmse:3.81339\ttrain-rmse:1.94567\n",
      "[31551]\teval-rmse:3.81372\ttrain-rmse:1.94569\n",
      "[31552]\teval-rmse:3.81227\ttrain-rmse:1.94563\n",
      "[31553]\teval-rmse:3.81221\ttrain-rmse:1.94563\n",
      "[31554]\teval-rmse:3.81249\ttrain-rmse:1.94565\n",
      "[31555]\teval-rmse:3.81105\ttrain-rmse:1.9456\n",
      "[31556]\teval-rmse:3.81024\ttrain-rmse:1.94556\n",
      "[31557]\teval-rmse:3.81071\ttrain-rmse:1.94558\n",
      "[31558]\teval-rmse:3.80991\ttrain-rmse:1.94554\n",
      "[31559]\teval-rmse:3.80953\ttrain-rmse:1.94553\n",
      "[31560]\teval-rmse:3.81076\ttrain-rmse:1.94558\n",
      "[31561]\teval-rmse:3.81221\ttrain-rmse:1.94565\n",
      "[31562]\teval-rmse:3.81161\ttrain-rmse:1.94562\n",
      "[31563]\teval-rmse:3.81078\ttrain-rmse:1.94558\n",
      "[31564]\teval-rmse:3.81149\ttrain-rmse:1.94562\n",
      "[31565]\teval-rmse:3.81274\ttrain-rmse:1.9457\n",
      "[31566]\teval-rmse:3.81286\ttrain-rmse:1.94571\n",
      "[31567]\teval-rmse:3.81227\ttrain-rmse:1.94567\n",
      "[31568]\teval-rmse:3.81261\ttrain-rmse:1.94569\n",
      "[31569]\teval-rmse:3.81393\ttrain-rmse:1.94576\n",
      "[31570]\teval-rmse:3.81515\ttrain-rmse:1.94585\n",
      "[31571]\teval-rmse:3.8143\ttrain-rmse:1.94579\n",
      "[31572]\teval-rmse:3.81545\ttrain-rmse:1.94586\n",
      "[31573]\teval-rmse:3.81614\ttrain-rmse:1.9459\n",
      "[31574]\teval-rmse:3.81652\ttrain-rmse:1.94593\n",
      "[31575]\teval-rmse:3.81518\ttrain-rmse:1.94583\n",
      "[31576]\teval-rmse:3.81674\ttrain-rmse:1.9459\n",
      "[31577]\teval-rmse:3.81731\ttrain-rmse:1.94594\n",
      "[31578]\teval-rmse:3.81756\ttrain-rmse:1.94596\n",
      "[31579]\teval-rmse:3.81801\ttrain-rmse:1.94599\n",
      "[31580]\teval-rmse:3.81917\ttrain-rmse:1.94608\n",
      "[31581]\teval-rmse:3.81724\ttrain-rmse:1.94592\n",
      "[31582]\teval-rmse:3.81858\ttrain-rmse:1.94602\n",
      "[31583]\teval-rmse:3.82035\ttrain-rmse:1.9461\n",
      "[31584]\teval-rmse:3.81824\ttrain-rmse:1.94595\n",
      "[31585]\teval-rmse:3.81676\ttrain-rmse:1.94586\n",
      "[31586]\teval-rmse:3.81786\ttrain-rmse:1.94594\n",
      "[31587]\teval-rmse:3.81624\ttrain-rmse:1.94582\n",
      "[31588]\teval-rmse:3.81573\ttrain-rmse:1.94579\n",
      "[31589]\teval-rmse:3.81641\ttrain-rmse:1.94583\n",
      "[31590]\teval-rmse:3.81667\ttrain-rmse:1.94585\n",
      "[31591]\teval-rmse:3.81498\ttrain-rmse:1.94575\n",
      "[31592]\teval-rmse:3.81644\ttrain-rmse:1.94581\n",
      "[31593]\teval-rmse:3.81497\ttrain-rmse:1.94573\n",
      "[31594]\teval-rmse:3.81337\ttrain-rmse:1.94564\n",
      "[31595]\teval-rmse:3.81223\ttrain-rmse:1.9456\n",
      "[31596]\teval-rmse:3.81379\ttrain-rmse:1.94568\n",
      "[31597]\teval-rmse:3.81221\ttrain-rmse:1.94561\n",
      "[31598]\teval-rmse:3.81377\ttrain-rmse:1.94566\n",
      "[31599]\teval-rmse:3.81349\ttrain-rmse:1.94565\n",
      "[31600]\teval-rmse:3.81419\ttrain-rmse:1.94568\n",
      "[31601]\teval-rmse:3.81368\ttrain-rmse:1.94565\n",
      "[31602]\teval-rmse:3.81417\ttrain-rmse:1.94568\n",
      "[31603]\teval-rmse:3.81227\ttrain-rmse:1.94558\n",
      "[31604]\teval-rmse:3.81166\ttrain-rmse:1.94556\n",
      "[31605]\teval-rmse:3.81237\ttrain-rmse:1.94559\n",
      "[31606]\teval-rmse:3.81236\ttrain-rmse:1.94559\n",
      "[31607]\teval-rmse:3.81392\ttrain-rmse:1.94566\n",
      "[31608]\teval-rmse:3.81331\ttrain-rmse:1.94563\n",
      "[31609]\teval-rmse:3.81173\ttrain-rmse:1.94556\n",
      "[31610]\teval-rmse:3.81038\ttrain-rmse:1.94551\n",
      "[31611]\teval-rmse:3.81215\ttrain-rmse:1.94556\n",
      "[31612]\teval-rmse:3.81164\ttrain-rmse:1.94554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31613]\teval-rmse:3.81185\ttrain-rmse:1.94555\n",
      "[31614]\teval-rmse:3.8131\ttrain-rmse:1.94562\n",
      "[31615]\teval-rmse:3.81174\ttrain-rmse:1.94556\n",
      "[31616]\teval-rmse:3.81093\ttrain-rmse:1.94551\n",
      "[31617]\teval-rmse:3.80936\ttrain-rmse:1.94545\n",
      "[31618]\teval-rmse:3.80882\ttrain-rmse:1.94542\n",
      "[31619]\teval-rmse:3.81059\ttrain-rmse:1.94547\n",
      "[31620]\teval-rmse:3.81077\ttrain-rmse:1.94548\n",
      "[31621]\teval-rmse:3.81254\ttrain-rmse:1.94554\n",
      "[31622]\teval-rmse:3.81193\ttrain-rmse:1.94551\n",
      "[31623]\teval-rmse:3.81165\ttrain-rmse:1.9455\n",
      "[31624]\teval-rmse:3.80973\ttrain-rmse:1.94542\n",
      "[31625]\teval-rmse:3.81107\ttrain-rmse:1.94547\n",
      "[31626]\teval-rmse:3.8094\ttrain-rmse:1.9454\n",
      "[31627]\teval-rmse:3.80806\ttrain-rmse:1.94536\n",
      "[31628]\teval-rmse:3.80664\ttrain-rmse:1.94532\n",
      "[31629]\teval-rmse:3.80638\ttrain-rmse:1.94531\n",
      "[31630]\teval-rmse:3.80612\ttrain-rmse:1.94531\n",
      "[31631]\teval-rmse:3.80759\ttrain-rmse:1.94535\n",
      "[31632]\teval-rmse:3.80884\ttrain-rmse:1.94539\n",
      "[31633]\teval-rmse:3.80751\ttrain-rmse:1.94535\n",
      "[31634]\teval-rmse:3.80587\ttrain-rmse:1.94531\n",
      "[31635]\teval-rmse:3.80618\ttrain-rmse:1.94532\n",
      "[31636]\teval-rmse:3.80507\ttrain-rmse:1.94529\n",
      "[31637]\teval-rmse:3.80367\ttrain-rmse:1.94527\n",
      "[31638]\teval-rmse:3.80258\ttrain-rmse:1.94525\n",
      "[31639]\teval-rmse:3.80234\ttrain-rmse:1.94525\n",
      "[31640]\teval-rmse:3.80095\ttrain-rmse:1.94523\n",
      "[31641]\teval-rmse:3.80136\ttrain-rmse:1.94524\n",
      "[31642]\teval-rmse:3.79987\ttrain-rmse:1.94522\n",
      "[31643]\teval-rmse:3.79881\ttrain-rmse:1.94522\n",
      "[31644]\teval-rmse:3.79776\ttrain-rmse:1.94521\n",
      "[31645]\teval-rmse:3.79628\ttrain-rmse:1.94521\n",
      "[31646]\teval-rmse:3.79576\ttrain-rmse:1.94522\n",
      "[31647]\teval-rmse:3.79755\ttrain-rmse:1.94522\n",
      "[31648]\teval-rmse:3.79628\ttrain-rmse:1.94521\n",
      "[31649]\teval-rmse:3.79575\ttrain-rmse:1.94521\n",
      "[31650]\teval-rmse:3.79577\ttrain-rmse:1.94521\n",
      "[31651]\teval-rmse:3.79555\ttrain-rmse:1.94521\n",
      "[31652]\teval-rmse:3.79399\ttrain-rmse:1.94522\n",
      "[31653]\teval-rmse:3.79222\ttrain-rmse:1.94524\n",
      "[31654]\teval-rmse:3.79121\ttrain-rmse:1.94525\n",
      "[31655]\teval-rmse:3.79101\ttrain-rmse:1.94526\n",
      "[31656]\teval-rmse:3.79051\ttrain-rmse:1.94527\n",
      "[31657]\teval-rmse:3.79012\ttrain-rmse:1.94528\n",
      "[31658]\teval-rmse:3.79012\ttrain-rmse:1.94528\n",
      "[31659]\teval-rmse:3.78963\ttrain-rmse:1.94529\n",
      "[31660]\teval-rmse:3.78923\ttrain-rmse:1.9453\n",
      "[31661]\teval-rmse:3.78905\ttrain-rmse:1.9453\n",
      "[31662]\teval-rmse:3.78956\ttrain-rmse:1.94529\n",
      "[31663]\teval-rmse:3.79081\ttrain-rmse:1.94526\n",
      "[31664]\teval-rmse:3.79105\ttrain-rmse:1.94526\n",
      "[31665]\teval-rmse:3.78961\ttrain-rmse:1.94529\n",
      "[31666]\teval-rmse:3.7914\ttrain-rmse:1.94527\n",
      "[31667]\teval-rmse:3.7908\ttrain-rmse:1.94528\n",
      "[31668]\teval-rmse:3.78937\ttrain-rmse:1.94532\n",
      "[31669]\teval-rmse:3.78838\ttrain-rmse:1.94533\n",
      "[31670]\teval-rmse:3.78865\ttrain-rmse:1.94532\n",
      "[31671]\teval-rmse:3.7899\ttrain-rmse:1.94529\n",
      "[31672]\teval-rmse:3.79127\ttrain-rmse:1.94527\n",
      "[31673]\teval-rmse:3.79005\ttrain-rmse:1.9453\n",
      "[31674]\teval-rmse:3.79163\ttrain-rmse:1.94526\n",
      "[31675]\teval-rmse:3.79312\ttrain-rmse:1.94525\n",
      "[31676]\teval-rmse:3.79159\ttrain-rmse:1.94528\n",
      "[31677]\teval-rmse:3.79006\ttrain-rmse:1.9453\n",
      "[31678]\teval-rmse:3.79135\ttrain-rmse:1.94527\n",
      "[31679]\teval-rmse:3.79014\ttrain-rmse:1.9453\n",
      "[31680]\teval-rmse:3.79172\ttrain-rmse:1.94527\n",
      "[31681]\teval-rmse:3.79303\ttrain-rmse:1.94525\n",
      "[31682]\teval-rmse:3.7943\ttrain-rmse:1.94524\n",
      "[31683]\teval-rmse:3.79273\ttrain-rmse:1.94525\n",
      "[31684]\teval-rmse:3.79354\ttrain-rmse:1.94525\n",
      "[31685]\teval-rmse:3.79379\ttrain-rmse:1.94524\n",
      "[31686]\teval-rmse:3.79245\ttrain-rmse:1.94527\n",
      "[31687]\teval-rmse:3.79357\ttrain-rmse:1.94526\n",
      "[31688]\teval-rmse:3.79381\ttrain-rmse:1.94526\n",
      "[31689]\teval-rmse:3.79379\ttrain-rmse:1.94526\n",
      "[31690]\teval-rmse:3.79329\ttrain-rmse:1.94526\n",
      "[31691]\teval-rmse:3.79256\ttrain-rmse:1.94528\n",
      "[31692]\teval-rmse:3.79215\ttrain-rmse:1.94528\n",
      "[31693]\teval-rmse:3.79319\ttrain-rmse:1.94527\n",
      "[31694]\teval-rmse:3.7932\ttrain-rmse:1.94527\n",
      "[31695]\teval-rmse:3.79478\ttrain-rmse:1.94525\n",
      "[31696]\teval-rmse:3.79354\ttrain-rmse:1.94527\n",
      "[31697]\teval-rmse:3.79533\ttrain-rmse:1.94526\n",
      "[31698]\teval-rmse:3.7965\ttrain-rmse:1.94526\n",
      "[31699]\teval-rmse:3.79651\ttrain-rmse:1.94526\n",
      "[31700]\teval-rmse:3.79609\ttrain-rmse:1.94526\n",
      "[31701]\teval-rmse:3.79765\ttrain-rmse:1.94527\n",
      "[31702]\teval-rmse:3.79713\ttrain-rmse:1.94528\n",
      "[31703]\teval-rmse:3.79692\ttrain-rmse:1.94528\n",
      "[31704]\teval-rmse:3.7974\ttrain-rmse:1.94528\n",
      "[31705]\teval-rmse:3.7976\ttrain-rmse:1.94528\n",
      "[31706]\teval-rmse:3.79624\ttrain-rmse:1.94529\n",
      "[31707]\teval-rmse:3.79549\ttrain-rmse:1.94528\n",
      "[31708]\teval-rmse:3.79528\ttrain-rmse:1.94528\n",
      "[31709]\teval-rmse:3.79484\ttrain-rmse:1.94528\n",
      "[31710]\teval-rmse:3.79529\ttrain-rmse:1.94528\n",
      "[31711]\teval-rmse:3.79663\ttrain-rmse:1.94528\n",
      "[31712]\teval-rmse:3.79721\ttrain-rmse:1.94529\n",
      "[31713]\teval-rmse:3.79858\ttrain-rmse:1.94528\n",
      "[31714]\teval-rmse:3.79901\ttrain-rmse:1.94528\n",
      "[31715]\teval-rmse:3.79959\ttrain-rmse:1.94529\n",
      "[31716]\teval-rmse:3.79958\ttrain-rmse:1.94529\n",
      "[31717]\teval-rmse:3.80083\ttrain-rmse:1.94532\n",
      "[31718]\teval-rmse:3.80098\ttrain-rmse:1.94533\n",
      "[31719]\teval-rmse:3.7994\ttrain-rmse:1.94532\n",
      "[31720]\teval-rmse:3.79961\ttrain-rmse:1.94532\n",
      "[31721]\teval-rmse:3.80036\ttrain-rmse:1.94532\n",
      "[31722]\teval-rmse:3.8016\ttrain-rmse:1.94536\n",
      "[31723]\teval-rmse:3.80179\ttrain-rmse:1.94536\n",
      "[31724]\teval-rmse:3.80156\ttrain-rmse:1.94536\n",
      "[31725]\teval-rmse:3.80239\ttrain-rmse:1.94538\n",
      "[31726]\teval-rmse:3.80258\ttrain-rmse:1.94539\n",
      "[31727]\teval-rmse:3.80151\ttrain-rmse:1.94538\n",
      "[31728]\teval-rmse:3.80329\ttrain-rmse:1.9454\n",
      "[31729]\teval-rmse:3.80304\ttrain-rmse:1.94539\n",
      "[31730]\teval-rmse:3.80143\ttrain-rmse:1.94535\n",
      "[31731]\teval-rmse:3.80014\ttrain-rmse:1.94534\n",
      "[31732]\teval-rmse:3.79812\ttrain-rmse:1.9453\n",
      "[31733]\teval-rmse:3.79854\ttrain-rmse:1.9453\n",
      "[31734]\teval-rmse:3.80013\ttrain-rmse:1.9453\n",
      "[31735]\teval-rmse:3.79831\ttrain-rmse:1.94527\n",
      "[31736]\teval-rmse:3.79978\ttrain-rmse:1.94527\n",
      "[31737]\teval-rmse:3.79925\ttrain-rmse:1.94527\n",
      "[31738]\teval-rmse:3.80081\ttrain-rmse:1.94528\n",
      "[31739]\teval-rmse:3.80059\ttrain-rmse:1.94528\n",
      "[31740]\teval-rmse:3.7991\ttrain-rmse:1.94527\n",
      "[31741]\teval-rmse:3.79777\ttrain-rmse:1.94526\n",
      "[31742]\teval-rmse:3.79754\ttrain-rmse:1.94526\n",
      "[31743]\teval-rmse:3.79732\ttrain-rmse:1.94525\n",
      "[31744]\teval-rmse:3.79807\ttrain-rmse:1.94525\n",
      "[31745]\teval-rmse:3.79881\ttrain-rmse:1.94525\n",
      "[31746]\teval-rmse:3.79986\ttrain-rmse:1.94527\n",
      "[31747]\teval-rmse:3.79933\ttrain-rmse:1.94526\n",
      "[31748]\teval-rmse:3.79774\ttrain-rmse:1.94524\n",
      "[31749]\teval-rmse:3.79952\ttrain-rmse:1.94525\n",
      "[31750]\teval-rmse:3.7993\ttrain-rmse:1.94525\n",
      "[31751]\teval-rmse:3.79887\ttrain-rmse:1.94525\n",
      "[31752]\teval-rmse:3.80044\ttrain-rmse:1.94525\n",
      "[31753]\teval-rmse:3.80079\ttrain-rmse:1.94526\n",
      "[31754]\teval-rmse:3.79952\ttrain-rmse:1.94525\n",
      "[31755]\teval-rmse:3.80131\ttrain-rmse:1.94527\n",
      "[31756]\teval-rmse:3.80164\ttrain-rmse:1.94527\n",
      "[31757]\teval-rmse:3.80268\ttrain-rmse:1.94529\n",
      "[31758]\teval-rmse:3.80309\ttrain-rmse:1.94531\n",
      "[31759]\teval-rmse:3.80444\ttrain-rmse:1.94532\n",
      "[31760]\teval-rmse:3.80568\ttrain-rmse:1.94537\n",
      "[31761]\teval-rmse:3.80522\ttrain-rmse:1.94536\n",
      "[31762]\teval-rmse:3.80497\ttrain-rmse:1.94532\n",
      "[31763]\teval-rmse:3.80636\ttrain-rmse:1.94537\n",
      "[31764]\teval-rmse:3.80636\ttrain-rmse:1.94537\n",
      "[31765]\teval-rmse:3.80579\ttrain-rmse:1.94536\n",
      "[31766]\teval-rmse:3.80469\ttrain-rmse:1.94534\n",
      "[31767]\teval-rmse:3.80503\ttrain-rmse:1.94535\n",
      "[31768]\teval-rmse:3.80503\ttrain-rmse:1.94535\n",
      "[31769]\teval-rmse:3.80342\ttrain-rmse:1.94529\n",
      "[31770]\teval-rmse:3.80444\ttrain-rmse:1.94532\n",
      "[31771]\teval-rmse:3.80419\ttrain-rmse:1.94532\n",
      "[31772]\teval-rmse:3.8031\ttrain-rmse:1.94531\n",
      "[31773]\teval-rmse:3.80264\ttrain-rmse:1.94529\n",
      "[31774]\teval-rmse:3.80188\ttrain-rmse:1.94528\n",
      "[31775]\teval-rmse:3.8026\ttrain-rmse:1.94529\n",
      "[31776]\teval-rmse:3.80332\ttrain-rmse:1.9453\n",
      "[31777]\teval-rmse:3.80182\ttrain-rmse:1.94528\n",
      "[31778]\teval-rmse:3.80053\ttrain-rmse:1.94527\n",
      "[31779]\teval-rmse:3.8001\ttrain-rmse:1.94527\n",
      "[31780]\teval-rmse:3.79988\ttrain-rmse:1.94527\n",
      "[31781]\teval-rmse:3.79987\ttrain-rmse:1.94527\n",
      "[31782]\teval-rmse:3.80028\ttrain-rmse:1.94528\n",
      "[31783]\teval-rmse:3.79869\ttrain-rmse:1.94527\n",
      "[31784]\teval-rmse:3.79743\ttrain-rmse:1.94527\n",
      "[31785]\teval-rmse:3.79721\ttrain-rmse:1.94527\n",
      "[31786]\teval-rmse:3.79587\ttrain-rmse:1.94525\n",
      "[31787]\teval-rmse:3.79536\ttrain-rmse:1.94526\n",
      "[31788]\teval-rmse:3.79518\ttrain-rmse:1.94522\n",
      "[31789]\teval-rmse:3.79497\ttrain-rmse:1.94522\n",
      "[31790]\teval-rmse:3.79364\ttrain-rmse:1.94524\n",
      "[31791]\teval-rmse:3.79521\ttrain-rmse:1.94522\n",
      "[31792]\teval-rmse:3.79679\ttrain-rmse:1.94521\n",
      "[31793]\teval-rmse:3.79752\ttrain-rmse:1.94522\n",
      "[31794]\teval-rmse:3.79877\ttrain-rmse:1.94522\n",
      "[31795]\teval-rmse:3.79906\ttrain-rmse:1.94522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31796]\teval-rmse:3.79874\ttrain-rmse:1.94522\n",
      "[31797]\teval-rmse:3.79749\ttrain-rmse:1.94522\n",
      "[31798]\teval-rmse:3.79885\ttrain-rmse:1.94524\n",
      "[31799]\teval-rmse:3.79908\ttrain-rmse:1.94525\n",
      "[31800]\teval-rmse:3.79783\ttrain-rmse:1.94524\n",
      "[31801]\teval-rmse:3.79625\ttrain-rmse:1.94525\n",
      "[31802]\teval-rmse:3.79573\ttrain-rmse:1.94525\n",
      "[31803]\teval-rmse:3.79427\ttrain-rmse:1.94527\n",
      "[31804]\teval-rmse:3.79583\ttrain-rmse:1.94525\n",
      "[31805]\teval-rmse:3.79542\ttrain-rmse:1.94525\n",
      "[31806]\teval-rmse:3.79563\ttrain-rmse:1.94526\n",
      "[31807]\teval-rmse:3.79488\ttrain-rmse:1.94525\n",
      "[31808]\teval-rmse:3.79666\ttrain-rmse:1.94525\n",
      "[31809]\teval-rmse:3.79614\ttrain-rmse:1.94525\n",
      "[31810]\teval-rmse:3.79466\ttrain-rmse:1.94524\n",
      "[31811]\teval-rmse:3.79334\ttrain-rmse:1.94526\n",
      "[31812]\teval-rmse:3.79492\ttrain-rmse:1.94524\n",
      "[31813]\teval-rmse:3.79595\ttrain-rmse:1.94524\n",
      "[31814]\teval-rmse:3.79732\ttrain-rmse:1.94523\n",
      "[31815]\teval-rmse:3.79576\ttrain-rmse:1.94524\n",
      "[31816]\teval-rmse:3.79452\ttrain-rmse:1.94525\n",
      "[31817]\teval-rmse:3.79473\ttrain-rmse:1.94525\n",
      "[31818]\teval-rmse:3.79631\ttrain-rmse:1.94524\n",
      "[31819]\teval-rmse:3.79486\ttrain-rmse:1.94525\n",
      "[31820]\teval-rmse:3.79644\ttrain-rmse:1.94524\n",
      "[31821]\teval-rmse:3.7952\ttrain-rmse:1.94525\n",
      "[31822]\teval-rmse:3.79479\ttrain-rmse:1.94525\n",
      "[31823]\teval-rmse:3.79304\ttrain-rmse:1.94525\n",
      "[31824]\teval-rmse:3.79439\ttrain-rmse:1.94523\n",
      "[31825]\teval-rmse:3.79455\ttrain-rmse:1.94523\n",
      "[31826]\teval-rmse:3.79583\ttrain-rmse:1.94522\n",
      "[31827]\teval-rmse:3.79542\ttrain-rmse:1.94522\n",
      "[31828]\teval-rmse:3.79501\ttrain-rmse:1.94522\n",
      "[31829]\teval-rmse:3.79603\ttrain-rmse:1.94523\n",
      "[31830]\teval-rmse:3.79426\ttrain-rmse:1.94522\n",
      "[31831]\teval-rmse:3.79301\ttrain-rmse:1.94523\n",
      "[31832]\teval-rmse:3.79128\ttrain-rmse:1.94525\n",
      "[31833]\teval-rmse:3.79231\ttrain-rmse:1.94523\n",
      "[31834]\teval-rmse:3.7941\ttrain-rmse:1.94522\n",
      "[31835]\teval-rmse:3.79255\ttrain-rmse:1.94523\n",
      "[31836]\teval-rmse:3.7936\ttrain-rmse:1.94522\n",
      "[31837]\teval-rmse:3.79258\ttrain-rmse:1.94523\n",
      "[31838]\teval-rmse:3.79282\ttrain-rmse:1.94523\n",
      "[31839]\teval-rmse:3.79262\ttrain-rmse:1.94523\n",
      "[31840]\teval-rmse:3.79367\ttrain-rmse:1.94522\n",
      "[31841]\teval-rmse:3.79494\ttrain-rmse:1.94521\n",
      "[31842]\teval-rmse:3.79497\ttrain-rmse:1.94521\n",
      "[31843]\teval-rmse:3.79475\ttrain-rmse:1.94521\n",
      "[31844]\teval-rmse:3.79372\ttrain-rmse:1.94521\n",
      "[31845]\teval-rmse:3.79551\ttrain-rmse:1.94521\n",
      "[31846]\teval-rmse:3.79426\ttrain-rmse:1.94522\n",
      "[31847]\teval-rmse:3.79408\ttrain-rmse:1.94519\n",
      "[31848]\teval-rmse:3.79458\ttrain-rmse:1.94519\n",
      "[31849]\teval-rmse:3.79637\ttrain-rmse:1.94518\n",
      "[31850]\teval-rmse:3.79616\ttrain-rmse:1.94515\n",
      "[31851]\teval-rmse:3.79795\ttrain-rmse:1.94515\n",
      "[31852]\teval-rmse:3.799\ttrain-rmse:1.94516\n",
      "[31853]\teval-rmse:3.79744\ttrain-rmse:1.94516\n",
      "[31854]\teval-rmse:3.7989\ttrain-rmse:1.94518\n",
      "[31855]\teval-rmse:3.79764\ttrain-rmse:1.94518\n",
      "[31856]\teval-rmse:3.79712\ttrain-rmse:1.94518\n",
      "[31857]\teval-rmse:3.79869\ttrain-rmse:1.94518\n",
      "[31858]\teval-rmse:3.79713\ttrain-rmse:1.94518\n",
      "[31859]\teval-rmse:3.79641\ttrain-rmse:1.94518\n",
      "[31860]\teval-rmse:3.79589\ttrain-rmse:1.94518\n",
      "[31861]\teval-rmse:3.79738\ttrain-rmse:1.94517\n",
      "[31862]\teval-rmse:3.79716\ttrain-rmse:1.94513\n",
      "[31863]\teval-rmse:3.79698\ttrain-rmse:1.94509\n",
      "[31864]\teval-rmse:3.79645\ttrain-rmse:1.9451\n",
      "[31865]\teval-rmse:3.79803\ttrain-rmse:1.94509\n",
      "[31866]\teval-rmse:3.79909\ttrain-rmse:1.94509\n",
      "[31867]\teval-rmse:3.79753\ttrain-rmse:1.94509\n",
      "[31868]\teval-rmse:3.79722\ttrain-rmse:1.94509\n",
      "[31869]\teval-rmse:3.79557\ttrain-rmse:1.94508\n",
      "[31870]\teval-rmse:3.79602\ttrain-rmse:1.94508\n",
      "[31871]\teval-rmse:3.79706\ttrain-rmse:1.94509\n",
      "[31872]\teval-rmse:3.79708\ttrain-rmse:1.94509\n",
      "[31873]\teval-rmse:3.79848\ttrain-rmse:1.94511\n",
      "[31874]\teval-rmse:3.79691\ttrain-rmse:1.94511\n",
      "[31875]\teval-rmse:3.79587\ttrain-rmse:1.94511\n",
      "[31876]\teval-rmse:3.79428\ttrain-rmse:1.9451\n",
      "[31877]\teval-rmse:3.79409\ttrain-rmse:1.9451\n",
      "[31878]\teval-rmse:3.79306\ttrain-rmse:1.94511\n",
      "[31879]\teval-rmse:3.79339\ttrain-rmse:1.94511\n",
      "[31880]\teval-rmse:3.79358\ttrain-rmse:1.94511\n",
      "[31881]\teval-rmse:3.79328\ttrain-rmse:1.94511\n",
      "[31882]\teval-rmse:3.79278\ttrain-rmse:1.94511\n",
      "[31883]\teval-rmse:3.79333\ttrain-rmse:1.94511\n",
      "[31884]\teval-rmse:3.79512\ttrain-rmse:1.9451\n",
      "[31885]\teval-rmse:3.79647\ttrain-rmse:1.94511\n",
      "[31886]\teval-rmse:3.79625\ttrain-rmse:1.94511\n",
      "[31887]\teval-rmse:3.7949\ttrain-rmse:1.94512\n",
      "[31888]\teval-rmse:3.79336\ttrain-rmse:1.94514\n",
      "[31889]\teval-rmse:3.79315\ttrain-rmse:1.94514\n",
      "[31890]\teval-rmse:3.79294\ttrain-rmse:1.94514\n",
      "[31891]\teval-rmse:3.79169\ttrain-rmse:1.94515\n",
      "[31892]\teval-rmse:3.79325\ttrain-rmse:1.94512\n",
      "[31893]\teval-rmse:3.79484\ttrain-rmse:1.9451\n",
      "[31894]\teval-rmse:3.79508\ttrain-rmse:1.9451\n",
      "[31895]\teval-rmse:3.79559\ttrain-rmse:1.9451\n",
      "[31896]\teval-rmse:3.79601\ttrain-rmse:1.9451\n",
      "[31897]\teval-rmse:3.79738\ttrain-rmse:1.9451\n",
      "[31898]\teval-rmse:3.79684\ttrain-rmse:1.9451\n",
      "[31899]\teval-rmse:3.79529\ttrain-rmse:1.94511\n",
      "[31900]\teval-rmse:3.79551\ttrain-rmse:1.94511\n",
      "[31901]\teval-rmse:3.79531\ttrain-rmse:1.94511\n",
      "[31902]\teval-rmse:3.79655\ttrain-rmse:1.94512\n",
      "[31903]\teval-rmse:3.79692\ttrain-rmse:1.94513\n",
      "[31904]\teval-rmse:3.79849\ttrain-rmse:1.94513\n",
      "[31905]\teval-rmse:3.79883\ttrain-rmse:1.94513\n",
      "[31906]\teval-rmse:3.79956\ttrain-rmse:1.94514\n",
      "[31907]\teval-rmse:3.79819\ttrain-rmse:1.94511\n",
      "[31908]\teval-rmse:3.79655\ttrain-rmse:1.94509\n",
      "[31909]\teval-rmse:3.79604\ttrain-rmse:1.9451\n",
      "[31910]\teval-rmse:3.79664\ttrain-rmse:1.9451\n",
      "[31911]\teval-rmse:3.79737\ttrain-rmse:1.9451\n",
      "[31912]\teval-rmse:3.79761\ttrain-rmse:1.9451\n",
      "[31913]\teval-rmse:3.79894\ttrain-rmse:1.94512\n",
      "[31914]\teval-rmse:3.79714\ttrain-rmse:1.9451\n",
      "[31915]\teval-rmse:3.79736\ttrain-rmse:1.9451\n",
      "[31916]\teval-rmse:3.79876\ttrain-rmse:1.94512\n",
      "[31917]\teval-rmse:3.798\ttrain-rmse:1.9451\n",
      "[31918]\teval-rmse:3.79603\ttrain-rmse:1.9451\n",
      "[31919]\teval-rmse:3.79499\ttrain-rmse:1.9451\n",
      "[31920]\teval-rmse:3.79344\ttrain-rmse:1.94509\n",
      "[31921]\teval-rmse:3.7919\ttrain-rmse:1.94512\n",
      "[31922]\teval-rmse:3.79316\ttrain-rmse:1.94511\n",
      "[31923]\teval-rmse:3.79458\ttrain-rmse:1.94511\n",
      "[31924]\teval-rmse:3.79428\ttrain-rmse:1.94511\n",
      "[31925]\teval-rmse:3.79512\ttrain-rmse:1.94512\n",
      "[31926]\teval-rmse:3.79638\ttrain-rmse:1.94513\n",
      "[31927]\teval-rmse:3.79504\ttrain-rmse:1.94514\n",
      "[31928]\teval-rmse:3.79537\ttrain-rmse:1.94514\n",
      "[31929]\teval-rmse:3.7961\ttrain-rmse:1.94514\n",
      "[31930]\teval-rmse:3.79432\ttrain-rmse:1.94515\n",
      "[31931]\teval-rmse:3.79611\ttrain-rmse:1.94514\n",
      "[31932]\teval-rmse:3.79507\ttrain-rmse:1.94514\n",
      "[31933]\teval-rmse:3.79685\ttrain-rmse:1.94514\n",
      "[31934]\teval-rmse:3.79526\ttrain-rmse:1.94513\n",
      "[31935]\teval-rmse:3.79581\ttrain-rmse:1.94512\n",
      "[31936]\teval-rmse:3.7974\ttrain-rmse:1.94511\n",
      "[31937]\teval-rmse:3.79625\ttrain-rmse:1.9451\n",
      "[31938]\teval-rmse:3.79783\ttrain-rmse:1.94509\n",
      "[31939]\teval-rmse:3.79885\ttrain-rmse:1.94511\n",
      "[31940]\teval-rmse:3.79779\ttrain-rmse:1.9451\n",
      "[31941]\teval-rmse:3.79837\ttrain-rmse:1.94511\n",
      "[31942]\teval-rmse:3.79889\ttrain-rmse:1.94511\n",
      "[31943]\teval-rmse:3.79844\ttrain-rmse:1.9451\n",
      "[31944]\teval-rmse:3.79792\ttrain-rmse:1.9451\n",
      "[31945]\teval-rmse:3.79656\ttrain-rmse:1.94511\n",
      "[31946]\teval-rmse:3.79793\ttrain-rmse:1.94511\n",
      "[31947]\teval-rmse:3.79824\ttrain-rmse:1.94511\n",
      "[31948]\teval-rmse:3.79957\ttrain-rmse:1.94514\n",
      "[31949]\teval-rmse:3.79954\ttrain-rmse:1.94513\n",
      "[31950]\teval-rmse:3.80101\ttrain-rmse:1.94517\n",
      "[31951]\teval-rmse:3.80175\ttrain-rmse:1.94518\n",
      "[31952]\teval-rmse:3.80013\ttrain-rmse:1.94514\n",
      "[31953]\teval-rmse:3.80031\ttrain-rmse:1.94514\n",
      "[31954]\teval-rmse:3.79976\ttrain-rmse:1.94513\n",
      "[31955]\teval-rmse:3.79921\ttrain-rmse:1.94513\n",
      "[31956]\teval-rmse:3.79899\ttrain-rmse:1.94509\n",
      "[31957]\teval-rmse:3.79877\ttrain-rmse:1.94509\n",
      "[31958]\teval-rmse:3.79721\ttrain-rmse:1.94509\n",
      "[31959]\teval-rmse:3.79736\ttrain-rmse:1.94509\n",
      "[31960]\teval-rmse:3.79557\ttrain-rmse:1.94507\n",
      "[31961]\teval-rmse:3.7961\ttrain-rmse:1.94507\n",
      "[31962]\teval-rmse:3.79757\ttrain-rmse:1.94506\n",
      "[31963]\teval-rmse:3.79736\ttrain-rmse:1.94502\n",
      "[31964]\teval-rmse:3.79883\ttrain-rmse:1.94505\n",
      "[31965]\teval-rmse:3.79755\ttrain-rmse:1.94505\n",
      "[31966]\teval-rmse:3.79723\ttrain-rmse:1.94505\n",
      "[31967]\teval-rmse:3.79847\ttrain-rmse:1.94507\n",
      "[31968]\teval-rmse:3.79972\ttrain-rmse:1.94508\n",
      "[31969]\teval-rmse:3.80107\ttrain-rmse:1.94509\n",
      "[31970]\teval-rmse:3.80234\ttrain-rmse:1.9451\n",
      "[31971]\teval-rmse:3.80357\ttrain-rmse:1.94514\n",
      "[31972]\teval-rmse:3.80227\ttrain-rmse:1.94513\n",
      "[31973]\teval-rmse:3.80051\ttrain-rmse:1.94509\n",
      "[31974]\teval-rmse:3.79912\ttrain-rmse:1.94505\n",
      "[31975]\teval-rmse:3.80068\ttrain-rmse:1.94506\n",
      "[31976]\teval-rmse:3.79909\ttrain-rmse:1.94506\n",
      "[31977]\teval-rmse:3.80087\ttrain-rmse:1.94507\n",
      "[31978]\teval-rmse:3.80065\ttrain-rmse:1.94503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31979]\teval-rmse:3.80125\ttrain-rmse:1.94504\n",
      "[31980]\teval-rmse:3.801\ttrain-rmse:1.94504\n",
      "[31981]\teval-rmse:3.80077\ttrain-rmse:1.94504\n",
      "[31982]\teval-rmse:3.79917\ttrain-rmse:1.94503\n",
      "[31983]\teval-rmse:3.80034\ttrain-rmse:1.94505\n",
      "[31984]\teval-rmse:3.80012\ttrain-rmse:1.94505\n",
      "[31985]\teval-rmse:3.8019\ttrain-rmse:1.94506\n",
      "[31986]\teval-rmse:3.80031\ttrain-rmse:1.94505\n",
      "[31987]\teval-rmse:3.80105\ttrain-rmse:1.94505\n",
      "[31988]\teval-rmse:3.80242\ttrain-rmse:1.94506\n",
      "[31989]\teval-rmse:3.8039\ttrain-rmse:1.94507\n",
      "[31990]\teval-rmse:3.80462\ttrain-rmse:1.94508\n",
      "[31991]\teval-rmse:3.80323\ttrain-rmse:1.94507\n",
      "[31992]\teval-rmse:3.80183\ttrain-rmse:1.94505\n",
      "[31993]\teval-rmse:3.80204\ttrain-rmse:1.94505\n",
      "[31994]\teval-rmse:3.80383\ttrain-rmse:1.94507\n",
      "[31995]\teval-rmse:3.80509\ttrain-rmse:1.9451\n",
      "[31996]\teval-rmse:3.80532\ttrain-rmse:1.9451\n",
      "[31997]\teval-rmse:3.804\ttrain-rmse:1.94508\n",
      "[31998]\teval-rmse:3.80324\ttrain-rmse:1.94507\n",
      "[31999]\teval-rmse:3.80377\ttrain-rmse:1.94508\n",
      "[32000]\teval-rmse:3.80522\ttrain-rmse:1.94512\n",
      "[32001]\teval-rmse:3.8065\ttrain-rmse:1.94517\n",
      "[32002]\teval-rmse:3.80443\ttrain-rmse:1.94509\n",
      "[32003]\teval-rmse:3.80282\ttrain-rmse:1.94507\n",
      "[32004]\teval-rmse:3.80459\ttrain-rmse:1.9451\n",
      "[32005]\teval-rmse:3.80615\ttrain-rmse:1.94512\n",
      "[32006]\teval-rmse:3.80792\ttrain-rmse:1.94516\n",
      "[32007]\teval-rmse:3.80737\ttrain-rmse:1.94515\n",
      "[32008]\teval-rmse:3.80895\ttrain-rmse:1.94518\n",
      "[32009]\teval-rmse:3.80762\ttrain-rmse:1.94514\n",
      "[32010]\teval-rmse:3.80736\ttrain-rmse:1.94514\n",
      "[32011]\teval-rmse:3.807\ttrain-rmse:1.94513\n",
      "[32012]\teval-rmse:3.80877\ttrain-rmse:1.94517\n",
      "[32013]\teval-rmse:3.80982\ttrain-rmse:1.94522\n",
      "[32014]\teval-rmse:3.81104\ttrain-rmse:1.94527\n",
      "[32015]\teval-rmse:3.80991\ttrain-rmse:1.94524\n",
      "[32016]\teval-rmse:3.81094\ttrain-rmse:1.94529\n",
      "[32017]\teval-rmse:3.81065\ttrain-rmse:1.94528\n",
      "[32018]\teval-rmse:3.81007\ttrain-rmse:1.94526\n",
      "[32019]\teval-rmse:3.81162\ttrain-rmse:1.94531\n",
      "[32020]\teval-rmse:3.81266\ttrain-rmse:1.94537\n",
      "[32021]\teval-rmse:3.81227\ttrain-rmse:1.94535\n",
      "[32022]\teval-rmse:3.81061\ttrain-rmse:1.9453\n",
      "[32023]\teval-rmse:3.81166\ttrain-rmse:1.94533\n",
      "[32024]\teval-rmse:3.81213\ttrain-rmse:1.94536\n",
      "[32025]\teval-rmse:3.81315\ttrain-rmse:1.94542\n",
      "[32026]\teval-rmse:3.81415\ttrain-rmse:1.94548\n",
      "[32027]\teval-rmse:3.81388\ttrain-rmse:1.94544\n",
      "[32028]\teval-rmse:3.81238\ttrain-rmse:1.94536\n",
      "[32029]\teval-rmse:3.81034\ttrain-rmse:1.94527\n",
      "[32030]\teval-rmse:3.80901\ttrain-rmse:1.94522\n",
      "[32031]\teval-rmse:3.8076\ttrain-rmse:1.94519\n",
      "[32032]\teval-rmse:3.8086\ttrain-rmse:1.94524\n",
      "[32033]\teval-rmse:3.81007\ttrain-rmse:1.94528\n",
      "[32034]\teval-rmse:3.8095\ttrain-rmse:1.94526\n",
      "[32035]\teval-rmse:3.80897\ttrain-rmse:1.94524\n",
      "[32036]\teval-rmse:3.81013\ttrain-rmse:1.9453\n",
      "[32037]\teval-rmse:3.81189\ttrain-rmse:1.94535\n",
      "[32038]\teval-rmse:3.81238\ttrain-rmse:1.94538\n",
      "[32039]\teval-rmse:3.81083\ttrain-rmse:1.94532\n",
      "[32040]\teval-rmse:3.81131\ttrain-rmse:1.94535\n",
      "[32041]\teval-rmse:3.81092\ttrain-rmse:1.94533\n",
      "[32042]\teval-rmse:3.81133\ttrain-rmse:1.94536\n",
      "[32043]\teval-rmse:3.81257\ttrain-rmse:1.94543\n",
      "[32044]\teval-rmse:3.81372\ttrain-rmse:1.94549\n",
      "[32045]\teval-rmse:3.8137\ttrain-rmse:1.94549\n",
      "[32046]\teval-rmse:3.81234\ttrain-rmse:1.94543\n",
      "[32047]\teval-rmse:3.81101\ttrain-rmse:1.94538\n",
      "[32048]\teval-rmse:3.81217\ttrain-rmse:1.94544\n",
      "[32049]\teval-rmse:3.81211\ttrain-rmse:1.94544\n",
      "[32050]\teval-rmse:3.81098\ttrain-rmse:1.9454\n",
      "[32051]\teval-rmse:3.81169\ttrain-rmse:1.94542\n",
      "[32052]\teval-rmse:3.81004\ttrain-rmse:1.94537\n",
      "[32053]\teval-rmse:3.8115\ttrain-rmse:1.94541\n",
      "[32054]\teval-rmse:3.81124\ttrain-rmse:1.94537\n",
      "[32055]\teval-rmse:3.81073\ttrain-rmse:1.94534\n",
      "[32056]\teval-rmse:3.81124\ttrain-rmse:1.94536\n",
      "[32057]\teval-rmse:3.81249\ttrain-rmse:1.9454\n",
      "[32058]\teval-rmse:3.81094\ttrain-rmse:1.94535\n",
      "[32059]\teval-rmse:3.81036\ttrain-rmse:1.94533\n",
      "[32060]\teval-rmse:3.81159\ttrain-rmse:1.9454\n",
      "[32061]\teval-rmse:3.81296\ttrain-rmse:1.94548\n",
      "[32062]\teval-rmse:3.81431\ttrain-rmse:1.94554\n",
      "[32063]\teval-rmse:3.81239\ttrain-rmse:1.94541\n",
      "[32064]\teval-rmse:3.81092\ttrain-rmse:1.94532\n",
      "[32065]\teval-rmse:3.81164\ttrain-rmse:1.94534\n",
      "[32066]\teval-rmse:3.81021\ttrain-rmse:1.94529\n",
      "[32067]\teval-rmse:3.81169\ttrain-rmse:1.94534\n",
      "[32068]\teval-rmse:3.81141\ttrain-rmse:1.94533\n",
      "[32069]\teval-rmse:3.80987\ttrain-rmse:1.94524\n",
      "[32070]\teval-rmse:3.80798\ttrain-rmse:1.94515\n",
      "[32071]\teval-rmse:3.80954\ttrain-rmse:1.94519\n",
      "[32072]\teval-rmse:3.8108\ttrain-rmse:1.94523\n",
      "[32073]\teval-rmse:3.81211\ttrain-rmse:1.9453\n",
      "[32074]\teval-rmse:3.81047\ttrain-rmse:1.94525\n",
      "[32075]\teval-rmse:3.80914\ttrain-rmse:1.94521\n",
      "[32076]\teval-rmse:3.80771\ttrain-rmse:1.94517\n",
      "[32077]\teval-rmse:3.8077\ttrain-rmse:1.94517\n",
      "[32078]\teval-rmse:3.80615\ttrain-rmse:1.94511\n",
      "[32079]\teval-rmse:3.80657\ttrain-rmse:1.94511\n",
      "[32080]\teval-rmse:3.80803\ttrain-rmse:1.94514\n",
      "[32081]\teval-rmse:3.8064\ttrain-rmse:1.94508\n",
      "[32082]\teval-rmse:3.80764\ttrain-rmse:1.9451\n",
      "[32083]\teval-rmse:3.80741\ttrain-rmse:1.94506\n",
      "[32084]\teval-rmse:3.80695\ttrain-rmse:1.94505\n",
      "[32085]\teval-rmse:3.80798\ttrain-rmse:1.9451\n",
      "[32086]\teval-rmse:3.8084\ttrain-rmse:1.94511\n",
      "[32087]\teval-rmse:3.80803\ttrain-rmse:1.9451\n",
      "[32088]\teval-rmse:3.80726\ttrain-rmse:1.94508\n",
      "[32089]\teval-rmse:3.80689\ttrain-rmse:1.94507\n",
      "[32090]\teval-rmse:3.80664\ttrain-rmse:1.94503\n",
      "[32091]\teval-rmse:3.80532\ttrain-rmse:1.94498\n",
      "[32092]\teval-rmse:3.80346\ttrain-rmse:1.94492\n",
      "[32093]\teval-rmse:3.80311\ttrain-rmse:1.94492\n",
      "[32094]\teval-rmse:3.80343\ttrain-rmse:1.94492\n",
      "[32095]\teval-rmse:3.80318\ttrain-rmse:1.94492\n",
      "[32096]\teval-rmse:3.80209\ttrain-rmse:1.9449\n",
      "[32097]\teval-rmse:3.80165\ttrain-rmse:1.9449\n",
      "[32098]\teval-rmse:3.79965\ttrain-rmse:1.94487\n",
      "[32099]\teval-rmse:3.80105\ttrain-rmse:1.94489\n",
      "[32100]\teval-rmse:3.80137\ttrain-rmse:1.94489\n",
      "[32101]\teval-rmse:3.80054\ttrain-rmse:1.94488\n",
      "[32102]\teval-rmse:3.80098\ttrain-rmse:1.94488\n",
      "[32103]\teval-rmse:3.80135\ttrain-rmse:1.94488\n",
      "[32104]\teval-rmse:3.80208\ttrain-rmse:1.94489\n",
      "[32105]\teval-rmse:3.80077\ttrain-rmse:1.94486\n",
      "[32106]\teval-rmse:3.80151\ttrain-rmse:1.94487\n",
      "[32107]\teval-rmse:3.80254\ttrain-rmse:1.94489\n",
      "[32108]\teval-rmse:3.80326\ttrain-rmse:1.9449\n",
      "[32109]\teval-rmse:3.80186\ttrain-rmse:1.94488\n",
      "[32110]\teval-rmse:3.8013\ttrain-rmse:1.94488\n",
      "[32111]\teval-rmse:3.80287\ttrain-rmse:1.94489\n",
      "[32112]\teval-rmse:3.80414\ttrain-rmse:1.94491\n",
      "[32113]\teval-rmse:3.80358\ttrain-rmse:1.9449\n",
      "[32114]\teval-rmse:3.80302\ttrain-rmse:1.94488\n",
      "[32115]\teval-rmse:3.80279\ttrain-rmse:1.94488\n",
      "[32116]\teval-rmse:3.80149\ttrain-rmse:1.94487\n",
      "[32117]\teval-rmse:3.80022\ttrain-rmse:1.94485\n",
      "[32118]\teval-rmse:3.79872\ttrain-rmse:1.94483\n",
      "[32119]\teval-rmse:3.79839\ttrain-rmse:1.94483\n",
      "[32120]\teval-rmse:3.79767\ttrain-rmse:1.94483\n",
      "[32121]\teval-rmse:3.79691\ttrain-rmse:1.94483\n",
      "[32122]\teval-rmse:3.79537\ttrain-rmse:1.94484\n",
      "[32123]\teval-rmse:3.79517\ttrain-rmse:1.94481\n",
      "[32124]\teval-rmse:3.79519\ttrain-rmse:1.94481\n",
      "[32125]\teval-rmse:3.79542\ttrain-rmse:1.94481\n",
      "[32126]\teval-rmse:3.79511\ttrain-rmse:1.94481\n",
      "[32127]\teval-rmse:3.79439\ttrain-rmse:1.94482\n",
      "[32128]\teval-rmse:3.79495\ttrain-rmse:1.94481\n",
      "[32129]\teval-rmse:3.79571\ttrain-rmse:1.9448\n",
      "[32130]\teval-rmse:3.79682\ttrain-rmse:1.9448\n",
      "[32131]\teval-rmse:3.79638\ttrain-rmse:1.9448\n",
      "[32132]\teval-rmse:3.79566\ttrain-rmse:1.9448\n",
      "[32133]\teval-rmse:3.79569\ttrain-rmse:1.9448\n",
      "[32134]\teval-rmse:3.79725\ttrain-rmse:1.94478\n",
      "[32135]\teval-rmse:3.79673\ttrain-rmse:1.94479\n",
      "[32136]\teval-rmse:3.7962\ttrain-rmse:1.94479\n",
      "[32137]\teval-rmse:3.79747\ttrain-rmse:1.94478\n",
      "[32138]\teval-rmse:3.79781\ttrain-rmse:1.94478\n",
      "[32139]\teval-rmse:3.79811\ttrain-rmse:1.94478\n",
      "[32140]\teval-rmse:3.7966\ttrain-rmse:1.94478\n",
      "[32141]\teval-rmse:3.79629\ttrain-rmse:1.94477\n",
      "[32142]\teval-rmse:3.79745\ttrain-rmse:1.94478\n",
      "[32143]\teval-rmse:3.79702\ttrain-rmse:1.94477\n",
      "[32144]\teval-rmse:3.797\ttrain-rmse:1.94477\n",
      "[32145]\teval-rmse:3.79574\ttrain-rmse:1.94478\n",
      "[32146]\teval-rmse:3.79411\ttrain-rmse:1.94479\n",
      "[32147]\teval-rmse:3.79216\ttrain-rmse:1.94481\n",
      "[32148]\teval-rmse:3.79114\ttrain-rmse:1.94482\n",
      "[32149]\teval-rmse:3.79043\ttrain-rmse:1.94484\n",
      "[32150]\teval-rmse:3.78994\ttrain-rmse:1.94485\n",
      "[32151]\teval-rmse:3.78976\ttrain-rmse:1.94481\n",
      "[32152]\teval-rmse:3.78855\ttrain-rmse:1.94485\n",
      "[32153]\teval-rmse:3.78837\ttrain-rmse:1.94485\n",
      "[32154]\teval-rmse:3.78872\ttrain-rmse:1.94484\n",
      "[32155]\teval-rmse:3.78732\ttrain-rmse:1.94488\n",
      "[32156]\teval-rmse:3.78611\ttrain-rmse:1.94492\n",
      "[32157]\teval-rmse:3.78648\ttrain-rmse:1.94491\n",
      "[32158]\teval-rmse:3.785\ttrain-rmse:1.94497\n",
      "[32159]\teval-rmse:3.78452\ttrain-rmse:1.94499\n",
      "[32160]\teval-rmse:3.78631\ttrain-rmse:1.94495\n",
      "[32161]\teval-rmse:3.78653\ttrain-rmse:1.94494\n",
      "[32162]\teval-rmse:3.78637\ttrain-rmse:1.94495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32163]\teval-rmse:3.78498\ttrain-rmse:1.94501\n",
      "[32164]\teval-rmse:3.78648\ttrain-rmse:1.94495\n",
      "[32165]\teval-rmse:3.78797\ttrain-rmse:1.94489\n",
      "[32166]\teval-rmse:3.78956\ttrain-rmse:1.94485\n",
      "[32167]\teval-rmse:3.79033\ttrain-rmse:1.94483\n",
      "[32168]\teval-rmse:3.79181\ttrain-rmse:1.94479\n",
      "[32169]\teval-rmse:3.79133\ttrain-rmse:1.9448\n",
      "[32170]\teval-rmse:3.79154\ttrain-rmse:1.94479\n",
      "[32171]\teval-rmse:3.79208\ttrain-rmse:1.94478\n",
      "[32172]\teval-rmse:3.79363\ttrain-rmse:1.94476\n",
      "[32173]\teval-rmse:3.79512\ttrain-rmse:1.94475\n",
      "[32174]\teval-rmse:3.79691\ttrain-rmse:1.94475\n",
      "[32175]\teval-rmse:3.79743\ttrain-rmse:1.94475\n",
      "[32176]\teval-rmse:3.79638\ttrain-rmse:1.94475\n",
      "[32177]\teval-rmse:3.79597\ttrain-rmse:1.94475\n",
      "[32178]\teval-rmse:3.79461\ttrain-rmse:1.94477\n",
      "[32179]\teval-rmse:3.79379\ttrain-rmse:1.94477\n",
      "[32180]\teval-rmse:3.79256\ttrain-rmse:1.9448\n",
      "[32181]\teval-rmse:3.79309\ttrain-rmse:1.94479\n",
      "[32182]\teval-rmse:3.79133\ttrain-rmse:1.94481\n",
      "[32183]\teval-rmse:3.79115\ttrain-rmse:1.94478\n",
      "[32184]\teval-rmse:3.79064\ttrain-rmse:1.94479\n",
      "[32185]\teval-rmse:3.78943\ttrain-rmse:1.94482\n",
      "[32186]\teval-rmse:3.78823\ttrain-rmse:1.94486\n",
      "[32187]\teval-rmse:3.78843\ttrain-rmse:1.94485\n",
      "[32188]\teval-rmse:3.79022\ttrain-rmse:1.94483\n",
      "[32189]\teval-rmse:3.7888\ttrain-rmse:1.94487\n",
      "[32190]\teval-rmse:3.78812\ttrain-rmse:1.9449\n",
      "[32191]\teval-rmse:3.7866\ttrain-rmse:1.94495\n",
      "[32192]\teval-rmse:3.78712\ttrain-rmse:1.94493\n",
      "[32193]\teval-rmse:3.78756\ttrain-rmse:1.94492\n",
      "[32194]\teval-rmse:3.78812\ttrain-rmse:1.9449\n",
      "[32195]\teval-rmse:3.78939\ttrain-rmse:1.94486\n",
      "[32196]\teval-rmse:3.78967\ttrain-rmse:1.94485\n",
      "[32197]\teval-rmse:3.78848\ttrain-rmse:1.9449\n",
      "[32198]\teval-rmse:3.78872\ttrain-rmse:1.94489\n",
      "[32199]\teval-rmse:3.78872\ttrain-rmse:1.94489\n",
      "[32200]\teval-rmse:3.78854\ttrain-rmse:1.94489\n",
      "[32201]\teval-rmse:3.78817\ttrain-rmse:1.9449\n",
      "[32202]\teval-rmse:3.78869\ttrain-rmse:1.94488\n",
      "[32203]\teval-rmse:3.79048\ttrain-rmse:1.94486\n",
      "[32204]\teval-rmse:3.78896\ttrain-rmse:1.94491\n",
      "[32205]\teval-rmse:3.78745\ttrain-rmse:1.94496\n",
      "[32206]\teval-rmse:3.78678\ttrain-rmse:1.94499\n",
      "[32207]\teval-rmse:3.78808\ttrain-rmse:1.94493\n",
      "[32208]\teval-rmse:3.78689\ttrain-rmse:1.94497\n",
      "[32209]\teval-rmse:3.78671\ttrain-rmse:1.94497\n",
      "[32210]\teval-rmse:3.78633\ttrain-rmse:1.94498\n",
      "[32211]\teval-rmse:3.78738\ttrain-rmse:1.94495\n",
      "[32212]\teval-rmse:3.78711\ttrain-rmse:1.94495\n",
      "[32213]\teval-rmse:3.7876\ttrain-rmse:1.94493\n",
      "[32214]\teval-rmse:3.78605\ttrain-rmse:1.945\n",
      "[32215]\teval-rmse:3.78588\ttrain-rmse:1.94496\n",
      "[32216]\teval-rmse:3.78562\ttrain-rmse:1.94496\n",
      "[32217]\teval-rmse:3.78617\ttrain-rmse:1.94494\n",
      "[32218]\teval-rmse:3.78639\ttrain-rmse:1.94493\n",
      "[32219]\teval-rmse:3.78717\ttrain-rmse:1.9449\n",
      "[32220]\teval-rmse:3.78822\ttrain-rmse:1.94487\n",
      "[32221]\teval-rmse:3.78826\ttrain-rmse:1.94487\n",
      "[32222]\teval-rmse:3.78862\ttrain-rmse:1.94486\n",
      "[32223]\teval-rmse:3.78845\ttrain-rmse:1.94481\n",
      "[32224]\teval-rmse:3.78777\ttrain-rmse:1.94483\n",
      "[32225]\teval-rmse:3.78886\ttrain-rmse:1.94479\n",
      "[32226]\teval-rmse:3.78867\ttrain-rmse:1.9448\n",
      "[32227]\teval-rmse:3.78786\ttrain-rmse:1.94481\n",
      "[32228]\teval-rmse:3.78642\ttrain-rmse:1.94486\n",
      "[32229]\teval-rmse:3.78695\ttrain-rmse:1.94484\n",
      "[32230]\teval-rmse:3.78547\ttrain-rmse:1.94491\n",
      "[32231]\teval-rmse:3.78726\ttrain-rmse:1.94487\n",
      "[32232]\teval-rmse:3.78648\ttrain-rmse:1.9449\n",
      "[32233]\teval-rmse:3.78809\ttrain-rmse:1.94485\n",
      "[32234]\teval-rmse:3.78679\ttrain-rmse:1.9449\n",
      "[32235]\teval-rmse:3.78714\ttrain-rmse:1.94489\n",
      "[32236]\teval-rmse:3.78667\ttrain-rmse:1.94491\n",
      "[32237]\teval-rmse:3.78791\ttrain-rmse:1.94486\n",
      "[32238]\teval-rmse:3.78851\ttrain-rmse:1.94485\n",
      "[32239]\teval-rmse:3.78912\ttrain-rmse:1.94483\n",
      "[32240]\teval-rmse:3.79062\ttrain-rmse:1.94479\n",
      "[32241]\teval-rmse:3.79087\ttrain-rmse:1.94478\n",
      "[32242]\teval-rmse:3.79266\ttrain-rmse:1.94476\n",
      "[32243]\teval-rmse:3.79295\ttrain-rmse:1.94476\n",
      "[32244]\teval-rmse:3.79265\ttrain-rmse:1.94476\n",
      "[32245]\teval-rmse:3.79318\ttrain-rmse:1.94475\n",
      "[32246]\teval-rmse:3.79341\ttrain-rmse:1.94475\n",
      "[32247]\teval-rmse:3.79189\ttrain-rmse:1.94479\n",
      "[32248]\teval-rmse:3.79242\ttrain-rmse:1.94478\n",
      "[32249]\teval-rmse:3.79111\ttrain-rmse:1.94481\n",
      "[32250]\teval-rmse:3.79062\ttrain-rmse:1.94482\n",
      "[32251]\teval-rmse:3.79175\ttrain-rmse:1.9448\n",
      "[32252]\teval-rmse:3.79126\ttrain-rmse:1.94481\n",
      "[32253]\teval-rmse:3.7923\ttrain-rmse:1.94479\n",
      "[32254]\teval-rmse:3.79098\ttrain-rmse:1.94483\n",
      "[32255]\teval-rmse:3.79101\ttrain-rmse:1.94483\n",
      "[32256]\teval-rmse:3.78982\ttrain-rmse:1.94486\n",
      "[32257]\teval-rmse:3.7911\ttrain-rmse:1.94484\n",
      "[32258]\teval-rmse:3.79081\ttrain-rmse:1.94484\n",
      "[32259]\teval-rmse:3.79061\ttrain-rmse:1.94484\n",
      "[32260]\teval-rmse:3.7901\ttrain-rmse:1.94485\n",
      "[32261]\teval-rmse:3.78881\ttrain-rmse:1.94488\n",
      "[32262]\teval-rmse:3.78811\ttrain-rmse:1.94491\n",
      "[32263]\teval-rmse:3.78792\ttrain-rmse:1.94491\n",
      "[32264]\teval-rmse:3.78849\ttrain-rmse:1.94489\n",
      "[32265]\teval-rmse:3.78974\ttrain-rmse:1.94487\n",
      "[32266]\teval-rmse:3.78825\ttrain-rmse:1.94492\n",
      "[32267]\teval-rmse:3.78665\ttrain-rmse:1.94497\n",
      "[32268]\teval-rmse:3.78647\ttrain-rmse:1.94497\n",
      "[32269]\teval-rmse:3.7862\ttrain-rmse:1.94497\n",
      "[32270]\teval-rmse:3.78657\ttrain-rmse:1.94496\n",
      "[32271]\teval-rmse:3.78717\ttrain-rmse:1.94494\n",
      "[32272]\teval-rmse:3.78718\ttrain-rmse:1.94494\n",
      "[32273]\teval-rmse:3.78699\ttrain-rmse:1.94494\n",
      "[32274]\teval-rmse:3.7855\ttrain-rmse:1.94501\n",
      "[32275]\teval-rmse:3.78503\ttrain-rmse:1.94503\n",
      "[32276]\teval-rmse:3.78463\ttrain-rmse:1.94505\n",
      "[32277]\teval-rmse:3.78566\ttrain-rmse:1.94501\n",
      "[32278]\teval-rmse:3.78692\ttrain-rmse:1.94498\n",
      "[32279]\teval-rmse:3.78821\ttrain-rmse:1.94492\n",
      "[32280]\teval-rmse:3.78693\ttrain-rmse:1.94496\n",
      "[32281]\teval-rmse:3.78523\ttrain-rmse:1.94504\n",
      "[32282]\teval-rmse:3.78627\ttrain-rmse:1.94501\n",
      "[32283]\teval-rmse:3.7861\ttrain-rmse:1.94501\n",
      "[32284]\teval-rmse:3.78767\ttrain-rmse:1.94495\n",
      "[32285]\teval-rmse:3.78647\ttrain-rmse:1.94499\n",
      "[32286]\teval-rmse:3.7863\ttrain-rmse:1.94499\n",
      "[32287]\teval-rmse:3.7876\ttrain-rmse:1.94494\n",
      "[32288]\teval-rmse:3.7859\ttrain-rmse:1.94499\n",
      "[32289]\teval-rmse:3.78592\ttrain-rmse:1.94499\n",
      "[32290]\teval-rmse:3.78574\ttrain-rmse:1.94499\n",
      "[32291]\teval-rmse:3.78446\ttrain-rmse:1.94505\n",
      "[32292]\teval-rmse:3.78625\ttrain-rmse:1.94501\n",
      "[32293]\teval-rmse:3.78496\ttrain-rmse:1.94505\n",
      "[32294]\teval-rmse:3.78575\ttrain-rmse:1.94502\n",
      "[32295]\teval-rmse:3.78726\ttrain-rmse:1.94497\n",
      "[32296]\teval-rmse:3.78753\ttrain-rmse:1.94496\n",
      "[32297]\teval-rmse:3.78739\ttrain-rmse:1.94493\n",
      "[32298]\teval-rmse:3.78869\ttrain-rmse:1.94487\n",
      "[32299]\teval-rmse:3.78675\ttrain-rmse:1.94494\n",
      "[32300]\teval-rmse:3.78557\ttrain-rmse:1.94498\n",
      "[32301]\teval-rmse:3.78604\ttrain-rmse:1.94496\n",
      "[32302]\teval-rmse:3.78429\ttrain-rmse:1.94504\n",
      "[32303]\teval-rmse:3.78331\ttrain-rmse:1.94507\n",
      "[32304]\teval-rmse:3.78435\ttrain-rmse:1.94502\n",
      "[32305]\teval-rmse:3.78409\ttrain-rmse:1.94503\n",
      "[32306]\teval-rmse:3.78263\ttrain-rmse:1.94511\n",
      "[32307]\teval-rmse:3.78163\ttrain-rmse:1.94515\n",
      "[32308]\teval-rmse:3.78038\ttrain-rmse:1.94523\n",
      "[32309]\teval-rmse:3.77892\ttrain-rmse:1.94532\n",
      "[32310]\teval-rmse:3.77754\ttrain-rmse:1.9454\n",
      "[32311]\teval-rmse:3.77607\ttrain-rmse:1.9455\n",
      "[32312]\teval-rmse:3.77493\ttrain-rmse:1.9456\n",
      "[32313]\teval-rmse:3.77673\ttrain-rmse:1.94552\n",
      "[32314]\teval-rmse:3.77608\ttrain-rmse:1.94556\n",
      "[32315]\teval-rmse:3.77689\ttrain-rmse:1.94552\n",
      "[32316]\teval-rmse:3.77566\ttrain-rmse:1.94562\n",
      "[32317]\teval-rmse:3.77456\ttrain-rmse:1.94569\n",
      "[32318]\teval-rmse:3.77412\ttrain-rmse:1.94573\n",
      "[32319]\teval-rmse:3.77553\ttrain-rmse:1.94562\n",
      "[32320]\teval-rmse:3.77668\ttrain-rmse:1.94552\n",
      "[32321]\teval-rmse:3.77821\ttrain-rmse:1.94541\n",
      "[32322]\teval-rmse:3.77753\ttrain-rmse:1.94546\n",
      "[32323]\teval-rmse:3.77719\ttrain-rmse:1.94548\n",
      "[32324]\teval-rmse:3.77858\ttrain-rmse:1.94538\n",
      "[32325]\teval-rmse:3.77845\ttrain-rmse:1.94533\n",
      "[32326]\teval-rmse:3.77874\ttrain-rmse:1.94531\n",
      "[32327]\teval-rmse:3.77906\ttrain-rmse:1.94529\n",
      "[32328]\teval-rmse:3.7801\ttrain-rmse:1.94522\n",
      "[32329]\teval-rmse:3.77978\ttrain-rmse:1.94524\n",
      "[32330]\teval-rmse:3.78028\ttrain-rmse:1.9452\n",
      "[32331]\teval-rmse:3.77933\ttrain-rmse:1.94524\n",
      "[32332]\teval-rmse:3.77987\ttrain-rmse:1.9452\n",
      "[32333]\teval-rmse:3.77862\ttrain-rmse:1.94529\n",
      "[32334]\teval-rmse:3.77737\ttrain-rmse:1.94537\n",
      "[32335]\teval-rmse:3.77878\ttrain-rmse:1.94527\n",
      "[32336]\teval-rmse:3.77917\ttrain-rmse:1.94524\n",
      "[32337]\teval-rmse:3.77823\ttrain-rmse:1.94528\n",
      "[32338]\teval-rmse:3.77855\ttrain-rmse:1.94526\n",
      "[32339]\teval-rmse:3.77894\ttrain-rmse:1.94524\n",
      "[32340]\teval-rmse:3.77974\ttrain-rmse:1.94519\n",
      "[32341]\teval-rmse:3.77861\ttrain-rmse:1.94525\n",
      "[32342]\teval-rmse:3.77828\ttrain-rmse:1.94527\n",
      "[32343]\teval-rmse:3.77876\ttrain-rmse:1.94524\n",
      "[32344]\teval-rmse:3.78035\ttrain-rmse:1.94513\n",
      "[32345]\teval-rmse:3.77967\ttrain-rmse:1.94517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32346]\teval-rmse:3.78122\ttrain-rmse:1.94509\n",
      "[32347]\teval-rmse:3.78279\ttrain-rmse:1.945\n",
      "[32348]\teval-rmse:3.78278\ttrain-rmse:1.945\n",
      "[32349]\teval-rmse:3.78457\ttrain-rmse:1.94495\n",
      "[32350]\teval-rmse:3.78586\ttrain-rmse:1.94489\n",
      "[32351]\teval-rmse:3.78568\ttrain-rmse:1.94489\n",
      "[32352]\teval-rmse:3.78533\ttrain-rmse:1.94491\n",
      "[32353]\teval-rmse:3.78694\ttrain-rmse:1.94484\n",
      "[32354]\teval-rmse:3.78566\ttrain-rmse:1.94488\n",
      "[32355]\teval-rmse:3.78592\ttrain-rmse:1.94487\n",
      "[32356]\teval-rmse:3.78751\ttrain-rmse:1.94481\n",
      "[32357]\teval-rmse:3.78703\ttrain-rmse:1.94483\n",
      "[32358]\teval-rmse:3.78706\ttrain-rmse:1.94483\n",
      "[32359]\teval-rmse:3.78811\ttrain-rmse:1.9448\n",
      "[32360]\teval-rmse:3.78867\ttrain-rmse:1.94478\n",
      "[32361]\teval-rmse:3.78848\ttrain-rmse:1.94479\n",
      "[32362]\teval-rmse:3.78708\ttrain-rmse:1.94483\n",
      "[32363]\teval-rmse:3.78764\ttrain-rmse:1.94481\n",
      "[32364]\teval-rmse:3.78943\ttrain-rmse:1.94478\n",
      "[32365]\teval-rmse:3.78968\ttrain-rmse:1.94477\n",
      "[32366]\teval-rmse:3.7895\ttrain-rmse:1.94478\n",
      "[32367]\teval-rmse:3.78801\ttrain-rmse:1.94481\n",
      "[32368]\teval-rmse:3.78821\ttrain-rmse:1.9448\n",
      "[32369]\teval-rmse:3.78899\ttrain-rmse:1.94478\n",
      "[32370]\teval-rmse:3.78778\ttrain-rmse:1.94482\n",
      "[32371]\teval-rmse:3.78908\ttrain-rmse:1.94477\n",
      "[32372]\teval-rmse:3.79034\ttrain-rmse:1.94474\n",
      "[32373]\teval-rmse:3.78972\ttrain-rmse:1.94476\n",
      "[32374]\teval-rmse:3.78954\ttrain-rmse:1.94476\n",
      "[32375]\teval-rmse:3.7891\ttrain-rmse:1.94477\n",
      "[32376]\teval-rmse:3.79061\ttrain-rmse:1.94474\n",
      "[32377]\teval-rmse:3.79032\ttrain-rmse:1.94474\n",
      "[32378]\teval-rmse:3.79079\ttrain-rmse:1.94473\n",
      "[32379]\teval-rmse:3.79154\ttrain-rmse:1.9447\n",
      "[32380]\teval-rmse:3.79174\ttrain-rmse:1.9447\n",
      "[32381]\teval-rmse:3.79302\ttrain-rmse:1.94469\n",
      "[32382]\teval-rmse:3.7941\ttrain-rmse:1.94468\n",
      "[32383]\teval-rmse:3.79265\ttrain-rmse:1.94471\n",
      "[32384]\teval-rmse:3.79339\ttrain-rmse:1.9447\n",
      "[32385]\teval-rmse:3.79393\ttrain-rmse:1.94469\n",
      "[32386]\teval-rmse:3.79317\ttrain-rmse:1.94469\n",
      "[32387]\teval-rmse:3.79425\ttrain-rmse:1.94469\n",
      "[32388]\teval-rmse:3.79272\ttrain-rmse:1.94469\n",
      "[32389]\teval-rmse:3.79274\ttrain-rmse:1.94469\n",
      "[32390]\teval-rmse:3.79403\ttrain-rmse:1.94467\n",
      "[32391]\teval-rmse:3.79426\ttrain-rmse:1.94467\n",
      "[32392]\teval-rmse:3.79303\ttrain-rmse:1.94468\n",
      "[32393]\teval-rmse:3.79201\ttrain-rmse:1.94469\n",
      "[32394]\teval-rmse:3.79047\ttrain-rmse:1.94471\n",
      "[32395]\teval-rmse:3.79049\ttrain-rmse:1.94471\n",
      "[32396]\teval-rmse:3.79228\ttrain-rmse:1.94469\n",
      "[32397]\teval-rmse:3.7925\ttrain-rmse:1.94469\n",
      "[32398]\teval-rmse:3.79399\ttrain-rmse:1.94467\n",
      "[32399]\teval-rmse:3.79248\ttrain-rmse:1.94469\n",
      "[32400]\teval-rmse:3.79353\ttrain-rmse:1.94468\n",
      "[32401]\teval-rmse:3.79509\ttrain-rmse:1.94466\n",
      "[32402]\teval-rmse:3.79542\ttrain-rmse:1.94466\n",
      "[32403]\teval-rmse:3.79721\ttrain-rmse:1.94466\n",
      "[32404]\teval-rmse:3.79846\ttrain-rmse:1.94467\n",
      "[32405]\teval-rmse:3.79709\ttrain-rmse:1.94466\n",
      "[32406]\teval-rmse:3.7975\ttrain-rmse:1.94467\n",
      "[32407]\teval-rmse:3.79624\ttrain-rmse:1.94467\n",
      "[32408]\teval-rmse:3.79604\ttrain-rmse:1.94467\n",
      "[32409]\teval-rmse:3.795\ttrain-rmse:1.94467\n",
      "[32410]\teval-rmse:3.79326\ttrain-rmse:1.94471\n",
      "[32411]\teval-rmse:3.79386\ttrain-rmse:1.94471\n",
      "[32412]\teval-rmse:3.79432\ttrain-rmse:1.9447\n",
      "[32413]\teval-rmse:3.79433\ttrain-rmse:1.9447\n",
      "[32414]\teval-rmse:3.79591\ttrain-rmse:1.94468\n",
      "[32415]\teval-rmse:3.79588\ttrain-rmse:1.94468\n",
      "[32416]\teval-rmse:3.79482\ttrain-rmse:1.94468\n",
      "[32417]\teval-rmse:3.79593\ttrain-rmse:1.94468\n",
      "[32418]\teval-rmse:3.7977\ttrain-rmse:1.94468\n",
      "[32419]\teval-rmse:3.79805\ttrain-rmse:1.94468\n",
      "[32420]\teval-rmse:3.79839\ttrain-rmse:1.94468\n",
      "[32421]\teval-rmse:3.79977\ttrain-rmse:1.9447\n",
      "[32422]\teval-rmse:3.79871\ttrain-rmse:1.94469\n",
      "[32423]\teval-rmse:3.79973\ttrain-rmse:1.9447\n",
      "[32424]\teval-rmse:3.79867\ttrain-rmse:1.9447\n",
      "[32425]\teval-rmse:3.79993\ttrain-rmse:1.94469\n",
      "[32426]\teval-rmse:3.79939\ttrain-rmse:1.94469\n",
      "[32427]\teval-rmse:3.79804\ttrain-rmse:1.94469\n",
      "[32428]\teval-rmse:3.79644\ttrain-rmse:1.94468\n",
      "[32429]\teval-rmse:3.79804\ttrain-rmse:1.94467\n",
      "[32430]\teval-rmse:3.79754\ttrain-rmse:1.94467\n",
      "[32431]\teval-rmse:3.79722\ttrain-rmse:1.94467\n",
      "[32432]\teval-rmse:3.79744\ttrain-rmse:1.94467\n",
      "[32433]\teval-rmse:3.79776\ttrain-rmse:1.94468\n",
      "[32434]\teval-rmse:3.79796\ttrain-rmse:1.94468\n",
      "[32435]\teval-rmse:3.79746\ttrain-rmse:1.94468\n",
      "[32436]\teval-rmse:3.79904\ttrain-rmse:1.94467\n",
      "[32437]\teval-rmse:3.80054\ttrain-rmse:1.9447\n",
      "[32438]\teval-rmse:3.79997\ttrain-rmse:1.94469\n",
      "[32439]\teval-rmse:3.7987\ttrain-rmse:1.94469\n",
      "[32440]\teval-rmse:3.79744\ttrain-rmse:1.94469\n",
      "[32441]\teval-rmse:3.79689\ttrain-rmse:1.94469\n",
      "[32442]\teval-rmse:3.79705\ttrain-rmse:1.94469\n",
      "[32443]\teval-rmse:3.7981\ttrain-rmse:1.9447\n",
      "[32444]\teval-rmse:3.79791\ttrain-rmse:1.94467\n",
      "[32445]\teval-rmse:3.79929\ttrain-rmse:1.94466\n",
      "[32446]\teval-rmse:3.79895\ttrain-rmse:1.94466\n",
      "[32447]\teval-rmse:3.80042\ttrain-rmse:1.94466\n",
      "[32448]\teval-rmse:3.8019\ttrain-rmse:1.94467\n",
      "[32449]\teval-rmse:3.80344\ttrain-rmse:1.94472\n",
      "[32450]\teval-rmse:3.80191\ttrain-rmse:1.94467\n",
      "[32451]\teval-rmse:3.80327\ttrain-rmse:1.94469\n",
      "[32452]\teval-rmse:3.80475\ttrain-rmse:1.94471\n",
      "[32453]\teval-rmse:3.80594\ttrain-rmse:1.94474\n",
      "[32454]\teval-rmse:3.80433\ttrain-rmse:1.94472\n",
      "[32455]\teval-rmse:3.80282\ttrain-rmse:1.9447\n",
      "[32456]\teval-rmse:3.80077\ttrain-rmse:1.94464\n",
      "[32457]\teval-rmse:3.80118\ttrain-rmse:1.94465\n",
      "[32458]\teval-rmse:3.8014\ttrain-rmse:1.94466\n",
      "[32459]\teval-rmse:3.80086\ttrain-rmse:1.94466\n",
      "[32460]\teval-rmse:3.80187\ttrain-rmse:1.94468\n",
      "[32461]\teval-rmse:3.801\ttrain-rmse:1.94466\n",
      "[32462]\teval-rmse:3.801\ttrain-rmse:1.94466\n",
      "[32463]\teval-rmse:3.80048\ttrain-rmse:1.94465\n",
      "[32464]\teval-rmse:3.8016\ttrain-rmse:1.94468\n",
      "[32465]\teval-rmse:3.80208\ttrain-rmse:1.9447\n",
      "[32466]\teval-rmse:3.80334\ttrain-rmse:1.94474\n",
      "[32467]\teval-rmse:3.80174\ttrain-rmse:1.94469\n",
      "[32468]\teval-rmse:3.80149\ttrain-rmse:1.94468\n",
      "[32469]\teval-rmse:3.80115\ttrain-rmse:1.94468\n",
      "[32470]\teval-rmse:3.80059\ttrain-rmse:1.94468\n",
      "[32471]\teval-rmse:3.80005\ttrain-rmse:1.94467\n",
      "[32472]\teval-rmse:3.79982\ttrain-rmse:1.94467\n",
      "[32473]\teval-rmse:3.79797\ttrain-rmse:1.94463\n",
      "[32474]\teval-rmse:3.79924\ttrain-rmse:1.94463\n",
      "[32475]\teval-rmse:3.80079\ttrain-rmse:1.94464\n",
      "[32476]\teval-rmse:3.80098\ttrain-rmse:1.94464\n",
      "[32477]\teval-rmse:3.80053\ttrain-rmse:1.94464\n",
      "[32478]\teval-rmse:3.80199\ttrain-rmse:1.94468\n",
      "[32479]\teval-rmse:3.80221\ttrain-rmse:1.94469\n",
      "[32480]\teval-rmse:3.8024\ttrain-rmse:1.94469\n",
      "[32481]\teval-rmse:3.80235\ttrain-rmse:1.94469\n",
      "[32482]\teval-rmse:3.80182\ttrain-rmse:1.94469\n",
      "[32483]\teval-rmse:3.80234\ttrain-rmse:1.94469\n",
      "[32484]\teval-rmse:3.8021\ttrain-rmse:1.94469\n",
      "[32485]\teval-rmse:3.80187\ttrain-rmse:1.94468\n",
      "[32486]\teval-rmse:3.80186\ttrain-rmse:1.94468\n",
      "[32487]\teval-rmse:3.80184\ttrain-rmse:1.94468\n",
      "[32488]\teval-rmse:3.80223\ttrain-rmse:1.9447\n",
      "[32489]\teval-rmse:3.80282\ttrain-rmse:1.94471\n",
      "[32490]\teval-rmse:3.80152\ttrain-rmse:1.9447\n",
      "[32491]\teval-rmse:3.79999\ttrain-rmse:1.94466\n",
      "[32492]\teval-rmse:3.80122\ttrain-rmse:1.94468\n",
      "[32493]\teval-rmse:3.80099\ttrain-rmse:1.94464\n",
      "[32494]\teval-rmse:3.8014\ttrain-rmse:1.94465\n",
      "[32495]\teval-rmse:3.80241\ttrain-rmse:1.94468\n",
      "[32496]\teval-rmse:3.8036\ttrain-rmse:1.94472\n",
      "[32497]\teval-rmse:3.80537\ttrain-rmse:1.94475\n",
      "[32498]\teval-rmse:3.80475\ttrain-rmse:1.94473\n",
      "[32499]\teval-rmse:3.80336\ttrain-rmse:1.94467\n",
      "[32500]\teval-rmse:3.8017\ttrain-rmse:1.94463\n",
      "[32501]\teval-rmse:3.80294\ttrain-rmse:1.94467\n",
      "[32502]\teval-rmse:3.80217\ttrain-rmse:1.94464\n",
      "[32503]\teval-rmse:3.80192\ttrain-rmse:1.94464\n",
      "[32504]\teval-rmse:3.80158\ttrain-rmse:1.94463\n",
      "[32505]\teval-rmse:3.80178\ttrain-rmse:1.94464\n",
      "[32506]\teval-rmse:3.80019\ttrain-rmse:1.94463\n",
      "[32507]\teval-rmse:3.79818\ttrain-rmse:1.9446\n",
      "[32508]\teval-rmse:3.79763\ttrain-rmse:1.94459\n",
      "[32509]\teval-rmse:3.79711\ttrain-rmse:1.9446\n",
      "[32510]\teval-rmse:3.79859\ttrain-rmse:1.94459\n",
      "[32511]\teval-rmse:3.79807\ttrain-rmse:1.94459\n",
      "[32512]\teval-rmse:3.79964\ttrain-rmse:1.94459\n",
      "[32513]\teval-rmse:3.801\ttrain-rmse:1.94459\n",
      "[32514]\teval-rmse:3.80222\ttrain-rmse:1.94462\n",
      "[32515]\teval-rmse:3.80168\ttrain-rmse:1.94461\n",
      "[32516]\teval-rmse:3.8022\ttrain-rmse:1.94461\n",
      "[32517]\teval-rmse:3.80397\ttrain-rmse:1.94464\n",
      "[32518]\teval-rmse:3.80399\ttrain-rmse:1.94464\n",
      "[32519]\teval-rmse:3.80499\ttrain-rmse:1.94467\n",
      "[32520]\teval-rmse:3.80368\ttrain-rmse:1.94466\n",
      "[32521]\teval-rmse:3.80344\ttrain-rmse:1.94465\n",
      "[32522]\teval-rmse:3.80346\ttrain-rmse:1.94465\n",
      "[32523]\teval-rmse:3.80479\ttrain-rmse:1.9447\n",
      "[32524]\teval-rmse:3.80605\ttrain-rmse:1.94472\n",
      "[32525]\teval-rmse:3.80764\ttrain-rmse:1.94476\n",
      "[32526]\teval-rmse:3.80585\ttrain-rmse:1.9447\n",
      "[32527]\teval-rmse:3.80763\ttrain-rmse:1.94474\n",
      "[32528]\teval-rmse:3.80921\ttrain-rmse:1.94478\n",
      "[32529]\teval-rmse:3.80895\ttrain-rmse:1.94473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32530]\teval-rmse:3.80925\ttrain-rmse:1.94474\n",
      "[32531]\teval-rmse:3.80791\ttrain-rmse:1.9447\n",
      "[32532]\teval-rmse:3.80735\ttrain-rmse:1.94469\n",
      "[32533]\teval-rmse:3.80689\ttrain-rmse:1.94468\n",
      "[32534]\teval-rmse:3.80526\ttrain-rmse:1.94462\n",
      "[32535]\teval-rmse:3.80416\ttrain-rmse:1.9446\n",
      "[32536]\teval-rmse:3.80392\ttrain-rmse:1.9446\n",
      "[32537]\teval-rmse:3.80368\ttrain-rmse:1.94456\n",
      "[32538]\teval-rmse:3.80515\ttrain-rmse:1.94458\n",
      "[32539]\teval-rmse:3.80692\ttrain-rmse:1.94462\n",
      "[32540]\teval-rmse:3.80743\ttrain-rmse:1.94463\n",
      "[32541]\teval-rmse:3.80763\ttrain-rmse:1.94463\n",
      "[32542]\teval-rmse:3.8063\ttrain-rmse:1.9446\n",
      "[32543]\teval-rmse:3.80469\ttrain-rmse:1.94455\n",
      "[32544]\teval-rmse:3.80447\ttrain-rmse:1.94451\n",
      "[32545]\teval-rmse:3.80498\ttrain-rmse:1.94453\n",
      "[32546]\teval-rmse:3.80451\ttrain-rmse:1.94451\n",
      "[32547]\teval-rmse:3.80396\ttrain-rmse:1.9445\n",
      "[32548]\teval-rmse:3.80268\ttrain-rmse:1.94448\n",
      "[32549]\teval-rmse:3.80223\ttrain-rmse:1.94448\n",
      "[32550]\teval-rmse:3.80202\ttrain-rmse:1.94444\n",
      "[32551]\teval-rmse:3.80248\ttrain-rmse:1.94444\n",
      "[32552]\teval-rmse:3.80088\ttrain-rmse:1.94443\n",
      "[32553]\teval-rmse:3.80011\ttrain-rmse:1.94442\n",
      "[32554]\teval-rmse:3.80013\ttrain-rmse:1.94442\n",
      "[32555]\teval-rmse:3.80099\ttrain-rmse:1.94443\n",
      "[32556]\teval-rmse:3.80202\ttrain-rmse:1.94446\n",
      "[32557]\teval-rmse:3.80259\ttrain-rmse:1.94447\n",
      "[32558]\teval-rmse:3.80236\ttrain-rmse:1.94447\n",
      "[32559]\teval-rmse:3.80088\ttrain-rmse:1.94446\n",
      "[32560]\teval-rmse:3.7989\ttrain-rmse:1.94443\n",
      "[32561]\teval-rmse:3.79716\ttrain-rmse:1.94443\n",
      "[32562]\teval-rmse:3.79761\ttrain-rmse:1.94443\n",
      "[32563]\teval-rmse:3.79819\ttrain-rmse:1.94443\n",
      "[32564]\teval-rmse:3.7984\ttrain-rmse:1.94443\n",
      "[32565]\teval-rmse:3.79716\ttrain-rmse:1.94443\n",
      "[32566]\teval-rmse:3.79848\ttrain-rmse:1.94445\n",
      "[32567]\teval-rmse:3.80025\ttrain-rmse:1.94447\n",
      "[32568]\teval-rmse:3.79992\ttrain-rmse:1.94446\n",
      "[32569]\teval-rmse:3.80066\ttrain-rmse:1.94446\n",
      "[32570]\teval-rmse:3.80214\ttrain-rmse:1.94449\n",
      "[32571]\teval-rmse:3.80358\ttrain-rmse:1.94453\n",
      "[32572]\teval-rmse:3.80459\ttrain-rmse:1.94457\n",
      "[32573]\teval-rmse:3.80432\ttrain-rmse:1.94456\n",
      "[32574]\teval-rmse:3.80482\ttrain-rmse:1.94458\n",
      "[32575]\teval-rmse:3.8028\ttrain-rmse:1.94452\n",
      "[32576]\teval-rmse:3.80151\ttrain-rmse:1.9445\n",
      "[32577]\teval-rmse:3.80273\ttrain-rmse:1.94454\n",
      "[32578]\teval-rmse:3.80419\ttrain-rmse:1.94456\n",
      "[32579]\teval-rmse:3.8042\ttrain-rmse:1.94456\n",
      "[32580]\teval-rmse:3.80394\ttrain-rmse:1.94455\n",
      "[32581]\teval-rmse:3.80436\ttrain-rmse:1.94456\n",
      "[32582]\teval-rmse:3.80378\ttrain-rmse:1.94455\n",
      "[32583]\teval-rmse:3.80268\ttrain-rmse:1.94453\n",
      "[32584]\teval-rmse:3.80139\ttrain-rmse:1.94451\n",
      "[32585]\teval-rmse:3.79981\ttrain-rmse:1.9445\n",
      "[32586]\teval-rmse:3.79956\ttrain-rmse:1.9445\n",
      "[32587]\teval-rmse:3.79975\ttrain-rmse:1.9445\n",
      "[32588]\teval-rmse:3.79846\ttrain-rmse:1.9445\n",
      "[32589]\teval-rmse:3.79824\ttrain-rmse:1.9445\n",
      "[32590]\teval-rmse:3.79688\ttrain-rmse:1.94448\n",
      "[32591]\teval-rmse:3.79761\ttrain-rmse:1.94448\n",
      "[32592]\teval-rmse:3.79803\ttrain-rmse:1.94448\n",
      "[32593]\teval-rmse:3.79667\ttrain-rmse:1.94446\n",
      "[32594]\teval-rmse:3.79511\ttrain-rmse:1.94447\n",
      "[32595]\teval-rmse:3.79387\ttrain-rmse:1.94449\n",
      "[32596]\teval-rmse:3.79337\ttrain-rmse:1.94449\n",
      "[32597]\teval-rmse:3.79233\ttrain-rmse:1.9445\n",
      "[32598]\teval-rmse:3.79362\ttrain-rmse:1.94448\n",
      "[32599]\teval-rmse:3.79464\ttrain-rmse:1.94448\n",
      "[32600]\teval-rmse:3.79578\ttrain-rmse:1.94448\n",
      "[32601]\teval-rmse:3.79424\ttrain-rmse:1.9445\n",
      "[32602]\teval-rmse:3.79384\ttrain-rmse:1.9445\n",
      "[32603]\teval-rmse:3.79309\ttrain-rmse:1.9445\n",
      "[32604]\teval-rmse:3.79334\ttrain-rmse:1.9445\n",
      "[32605]\teval-rmse:3.79454\ttrain-rmse:1.9445\n",
      "[32606]\teval-rmse:3.79632\ttrain-rmse:1.94451\n",
      "[32607]\teval-rmse:3.79487\ttrain-rmse:1.94452\n",
      "[32608]\teval-rmse:3.79488\ttrain-rmse:1.94452\n",
      "[32609]\teval-rmse:3.79533\ttrain-rmse:1.94451\n",
      "[32610]\teval-rmse:3.79577\ttrain-rmse:1.94451\n",
      "[32611]\teval-rmse:3.79423\ttrain-rmse:1.94453\n",
      "[32612]\teval-rmse:3.79525\ttrain-rmse:1.94453\n",
      "[32613]\teval-rmse:3.7946\ttrain-rmse:1.94453\n",
      "[32614]\teval-rmse:3.79605\ttrain-rmse:1.94454\n",
      "[32615]\teval-rmse:3.795\ttrain-rmse:1.94454\n",
      "[32616]\teval-rmse:3.79366\ttrain-rmse:1.94456\n",
      "[32617]\teval-rmse:3.79349\ttrain-rmse:1.94452\n",
      "[32618]\teval-rmse:3.79318\ttrain-rmse:1.94452\n",
      "[32619]\teval-rmse:3.79195\ttrain-rmse:1.94451\n",
      "[32620]\teval-rmse:3.79345\ttrain-rmse:1.94451\n",
      "[32621]\teval-rmse:3.79325\ttrain-rmse:1.94451\n",
      "[32622]\teval-rmse:3.79503\ttrain-rmse:1.94451\n",
      "[32623]\teval-rmse:3.79451\ttrain-rmse:1.94452\n",
      "[32624]\teval-rmse:3.79609\ttrain-rmse:1.94453\n",
      "[32625]\teval-rmse:3.79475\ttrain-rmse:1.94452\n",
      "[32626]\teval-rmse:3.79599\ttrain-rmse:1.94453\n",
      "[32627]\teval-rmse:3.79625\ttrain-rmse:1.94454\n",
      "[32628]\teval-rmse:3.79802\ttrain-rmse:1.94455\n",
      "[32629]\teval-rmse:3.79948\ttrain-rmse:1.94454\n",
      "[32630]\teval-rmse:3.79903\ttrain-rmse:1.94454\n",
      "[32631]\teval-rmse:3.79958\ttrain-rmse:1.94456\n",
      "[32632]\teval-rmse:3.79916\ttrain-rmse:1.94455\n",
      "[32633]\teval-rmse:3.80072\ttrain-rmse:1.94456\n",
      "[32634]\teval-rmse:3.80131\ttrain-rmse:1.94457\n",
      "[32635]\teval-rmse:3.7999\ttrain-rmse:1.94453\n",
      "[32636]\teval-rmse:3.79883\ttrain-rmse:1.94452\n",
      "[32637]\teval-rmse:3.79907\ttrain-rmse:1.94453\n",
      "[32638]\teval-rmse:3.80009\ttrain-rmse:1.94455\n",
      "[32639]\teval-rmse:3.79953\ttrain-rmse:1.94455\n",
      "[32640]\teval-rmse:3.798\ttrain-rmse:1.94451\n",
      "[32641]\teval-rmse:3.79822\ttrain-rmse:1.94452\n",
      "[32642]\teval-rmse:3.79978\ttrain-rmse:1.94452\n",
      "[32643]\teval-rmse:3.80155\ttrain-rmse:1.94454\n",
      "[32644]\teval-rmse:3.80209\ttrain-rmse:1.94454\n",
      "[32645]\teval-rmse:3.80207\ttrain-rmse:1.94454\n",
      "[32646]\teval-rmse:3.80133\ttrain-rmse:1.94454\n",
      "[32647]\teval-rmse:3.80003\ttrain-rmse:1.94453\n",
      "[32648]\teval-rmse:3.80129\ttrain-rmse:1.94454\n",
      "[32649]\teval-rmse:3.80204\ttrain-rmse:1.94454\n",
      "[32650]\teval-rmse:3.80354\ttrain-rmse:1.94459\n",
      "[32651]\teval-rmse:3.80328\ttrain-rmse:1.94458\n",
      "[32652]\teval-rmse:3.80262\ttrain-rmse:1.94456\n",
      "[32653]\teval-rmse:3.80188\ttrain-rmse:1.94455\n",
      "[32654]\teval-rmse:3.80038\ttrain-rmse:1.94455\n",
      "[32655]\teval-rmse:3.80091\ttrain-rmse:1.94455\n",
      "[32656]\teval-rmse:3.80145\ttrain-rmse:1.94455\n",
      "[32657]\teval-rmse:3.80267\ttrain-rmse:1.94459\n",
      "[32658]\teval-rmse:3.80233\ttrain-rmse:1.94458\n",
      "[32659]\teval-rmse:3.80095\ttrain-rmse:1.94457\n",
      "[32660]\teval-rmse:3.80071\ttrain-rmse:1.94457\n",
      "[32661]\teval-rmse:3.80092\ttrain-rmse:1.94457\n",
      "[32662]\teval-rmse:3.79943\ttrain-rmse:1.94456\n",
      "[32663]\teval-rmse:3.79891\ttrain-rmse:1.94457\n",
      "[32664]\teval-rmse:3.7991\ttrain-rmse:1.94457\n",
      "[32665]\teval-rmse:3.80068\ttrain-rmse:1.94457\n",
      "[32666]\teval-rmse:3.80194\ttrain-rmse:1.94458\n",
      "[32667]\teval-rmse:3.80068\ttrain-rmse:1.94457\n",
      "[32668]\teval-rmse:3.79994\ttrain-rmse:1.94457\n",
      "[32669]\teval-rmse:3.79992\ttrain-rmse:1.94457\n",
      "[32670]\teval-rmse:3.79861\ttrain-rmse:1.94454\n",
      "[32671]\teval-rmse:3.79839\ttrain-rmse:1.94453\n",
      "[32672]\teval-rmse:3.79788\ttrain-rmse:1.94454\n",
      "[32673]\teval-rmse:3.79631\ttrain-rmse:1.94455\n",
      "[32674]\teval-rmse:3.79527\ttrain-rmse:1.94455\n",
      "[32675]\teval-rmse:3.79348\ttrain-rmse:1.94454\n",
      "[32676]\teval-rmse:3.79506\ttrain-rmse:1.94452\n",
      "[32677]\teval-rmse:3.7964\ttrain-rmse:1.94453\n",
      "[32678]\teval-rmse:3.79683\ttrain-rmse:1.94452\n",
      "[32679]\teval-rmse:3.79841\ttrain-rmse:1.94451\n",
      "[32680]\teval-rmse:3.79706\ttrain-rmse:1.94452\n",
      "[32681]\teval-rmse:3.79827\ttrain-rmse:1.94454\n",
      "[32682]\teval-rmse:3.79965\ttrain-rmse:1.94454\n",
      "[32683]\teval-rmse:3.80037\ttrain-rmse:1.94454\n",
      "[32684]\teval-rmse:3.80186\ttrain-rmse:1.94457\n",
      "[32685]\teval-rmse:3.80212\ttrain-rmse:1.94458\n",
      "[32686]\teval-rmse:3.80208\ttrain-rmse:1.94458\n",
      "[32687]\teval-rmse:3.80367\ttrain-rmse:1.94459\n",
      "[32688]\teval-rmse:3.80162\ttrain-rmse:1.94453\n",
      "[32689]\teval-rmse:3.80127\ttrain-rmse:1.94452\n",
      "[32690]\teval-rmse:3.80152\ttrain-rmse:1.94453\n",
      "[32691]\teval-rmse:3.80128\ttrain-rmse:1.94452\n",
      "[32692]\teval-rmse:3.80198\ttrain-rmse:1.94454\n",
      "[32693]\teval-rmse:3.80175\ttrain-rmse:1.94454\n",
      "[32694]\teval-rmse:3.80328\ttrain-rmse:1.94459\n",
      "[32695]\teval-rmse:3.80357\ttrain-rmse:1.9446\n",
      "[32696]\teval-rmse:3.8041\ttrain-rmse:1.94461\n",
      "[32697]\teval-rmse:3.80462\ttrain-rmse:1.94463\n",
      "[32698]\teval-rmse:3.80437\ttrain-rmse:1.94463\n",
      "[32699]\teval-rmse:3.80491\ttrain-rmse:1.94464\n",
      "[32700]\teval-rmse:3.80515\ttrain-rmse:1.94464\n",
      "[32701]\teval-rmse:3.80566\ttrain-rmse:1.94467\n",
      "[32702]\teval-rmse:3.80619\ttrain-rmse:1.9447\n",
      "[32703]\teval-rmse:3.80747\ttrain-rmse:1.94473\n",
      "[32704]\teval-rmse:3.80601\ttrain-rmse:1.94466\n",
      "[32705]\teval-rmse:3.80446\ttrain-rmse:1.94459\n",
      "[32706]\teval-rmse:3.80585\ttrain-rmse:1.94464\n",
      "[32707]\teval-rmse:3.80534\ttrain-rmse:1.94462\n",
      "[32708]\teval-rmse:3.80393\ttrain-rmse:1.9446\n",
      "[32709]\teval-rmse:3.80233\ttrain-rmse:1.94457\n",
      "[32710]\teval-rmse:3.80232\ttrain-rmse:1.94457\n",
      "[32711]\teval-rmse:3.80358\ttrain-rmse:1.94463\n",
      "[32712]\teval-rmse:3.8031\ttrain-rmse:1.94461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32713]\teval-rmse:3.8035\ttrain-rmse:1.94461\n",
      "[32714]\teval-rmse:3.80211\ttrain-rmse:1.9446\n",
      "[32715]\teval-rmse:3.80137\ttrain-rmse:1.94457\n",
      "[32716]\teval-rmse:3.80063\ttrain-rmse:1.94456\n",
      "[32717]\teval-rmse:3.7988\ttrain-rmse:1.94451\n",
      "[32718]\teval-rmse:3.79858\ttrain-rmse:1.94451\n",
      "[32719]\teval-rmse:3.799\ttrain-rmse:1.94451\n",
      "[32720]\teval-rmse:3.80055\ttrain-rmse:1.94452\n",
      "[32721]\teval-rmse:3.7985\ttrain-rmse:1.94448\n",
      "[32722]\teval-rmse:3.79905\ttrain-rmse:1.94448\n",
      "[32723]\teval-rmse:3.7977\ttrain-rmse:1.94445\n",
      "[32724]\teval-rmse:3.79812\ttrain-rmse:1.94446\n",
      "[32725]\teval-rmse:3.79865\ttrain-rmse:1.94447\n",
      "[32726]\teval-rmse:3.79988\ttrain-rmse:1.9445\n",
      "[32727]\teval-rmse:3.79861\ttrain-rmse:1.9445\n",
      "[32728]\teval-rmse:3.79754\ttrain-rmse:1.94449\n",
      "[32729]\teval-rmse:3.79722\ttrain-rmse:1.94449\n",
      "[32730]\teval-rmse:3.79656\ttrain-rmse:1.94447\n",
      "[32731]\teval-rmse:3.79636\ttrain-rmse:1.94444\n",
      "[32732]\teval-rmse:3.79792\ttrain-rmse:1.94444\n",
      "[32733]\teval-rmse:3.79646\ttrain-rmse:1.94444\n",
      "[32734]\teval-rmse:3.79594\ttrain-rmse:1.94444\n",
      "[32735]\teval-rmse:3.79571\ttrain-rmse:1.94444\n",
      "[32736]\teval-rmse:3.79539\ttrain-rmse:1.94444\n",
      "[32737]\teval-rmse:3.79392\ttrain-rmse:1.94443\n",
      "[32738]\teval-rmse:3.79415\ttrain-rmse:1.94442\n",
      "[32739]\teval-rmse:3.79364\ttrain-rmse:1.94442\n",
      "[32740]\teval-rmse:3.79419\ttrain-rmse:1.94443\n",
      "[32741]\teval-rmse:3.79543\ttrain-rmse:1.94444\n",
      "[32742]\teval-rmse:3.79522\ttrain-rmse:1.94444\n",
      "[32743]\teval-rmse:3.79482\ttrain-rmse:1.94444\n",
      "[32744]\teval-rmse:3.79503\ttrain-rmse:1.94444\n",
      "[32745]\teval-rmse:3.79631\ttrain-rmse:1.94443\n",
      "[32746]\teval-rmse:3.79674\ttrain-rmse:1.94443\n",
      "[32747]\teval-rmse:3.79749\ttrain-rmse:1.94443\n",
      "[32748]\teval-rmse:3.79779\ttrain-rmse:1.94443\n",
      "[32749]\teval-rmse:3.79738\ttrain-rmse:1.94443\n",
      "[32750]\teval-rmse:3.79591\ttrain-rmse:1.94444\n",
      "[32751]\teval-rmse:3.79537\ttrain-rmse:1.94443\n",
      "[32752]\teval-rmse:3.79684\ttrain-rmse:1.94442\n",
      "[32753]\teval-rmse:3.79549\ttrain-rmse:1.94443\n",
      "[32754]\teval-rmse:3.79587\ttrain-rmse:1.94443\n",
      "[32755]\teval-rmse:3.79631\ttrain-rmse:1.94443\n",
      "[32756]\teval-rmse:3.79481\ttrain-rmse:1.94441\n",
      "[32757]\teval-rmse:3.79328\ttrain-rmse:1.94443\n",
      "[32758]\teval-rmse:3.79179\ttrain-rmse:1.94443\n",
      "[32759]\teval-rmse:3.79059\ttrain-rmse:1.94445\n",
      "[32760]\teval-rmse:3.78986\ttrain-rmse:1.94446\n",
      "[32761]\teval-rmse:3.78935\ttrain-rmse:1.94447\n",
      "[32762]\teval-rmse:3.7874\ttrain-rmse:1.94449\n",
      "[32763]\teval-rmse:3.78793\ttrain-rmse:1.94448\n",
      "[32764]\teval-rmse:3.78754\ttrain-rmse:1.94449\n",
      "[32765]\teval-rmse:3.78912\ttrain-rmse:1.94444\n",
      "[32766]\teval-rmse:3.78989\ttrain-rmse:1.94442\n",
      "[32767]\teval-rmse:3.79116\ttrain-rmse:1.94439\n",
      "[32768]\teval-rmse:3.79138\ttrain-rmse:1.94439\n",
      "[32769]\teval-rmse:3.78985\ttrain-rmse:1.94443\n",
      "[32770]\teval-rmse:3.79149\ttrain-rmse:1.94441\n",
      "[32771]\teval-rmse:3.79118\ttrain-rmse:1.94441\n",
      "[32772]\teval-rmse:3.79142\ttrain-rmse:1.94441\n",
      "[32773]\teval-rmse:3.78972\ttrain-rmse:1.94443\n",
      "[32774]\teval-rmse:3.78831\ttrain-rmse:1.94447\n",
      "[32775]\teval-rmse:3.78874\ttrain-rmse:1.94445\n",
      "[32776]\teval-rmse:3.78834\ttrain-rmse:1.94446\n",
      "[32777]\teval-rmse:3.78979\ttrain-rmse:1.94445\n",
      "[32778]\teval-rmse:3.78846\ttrain-rmse:1.94449\n",
      "[32779]\teval-rmse:3.78807\ttrain-rmse:1.9445\n",
      "[32780]\teval-rmse:3.78828\ttrain-rmse:1.9445\n",
      "[32781]\teval-rmse:3.78881\ttrain-rmse:1.94449\n",
      "[32782]\teval-rmse:3.78751\ttrain-rmse:1.94453\n",
      "[32783]\teval-rmse:3.78734\ttrain-rmse:1.94453\n",
      "[32784]\teval-rmse:3.78886\ttrain-rmse:1.94451\n",
      "[32785]\teval-rmse:3.78837\ttrain-rmse:1.94452\n",
      "[32786]\teval-rmse:3.78954\ttrain-rmse:1.94451\n",
      "[32787]\teval-rmse:3.78853\ttrain-rmse:1.94453\n",
      "[32788]\teval-rmse:3.78658\ttrain-rmse:1.94455\n",
      "[32789]\teval-rmse:3.78514\ttrain-rmse:1.94457\n",
      "[32790]\teval-rmse:3.78397\ttrain-rmse:1.94462\n",
      "[32791]\teval-rmse:3.78349\ttrain-rmse:1.94463\n",
      "[32792]\teval-rmse:3.78347\ttrain-rmse:1.94463\n",
      "[32793]\teval-rmse:3.78364\ttrain-rmse:1.94463\n",
      "[32794]\teval-rmse:3.78492\ttrain-rmse:1.94457\n",
      "[32795]\teval-rmse:3.78346\ttrain-rmse:1.94461\n",
      "[32796]\teval-rmse:3.78228\ttrain-rmse:1.94466\n",
      "[32797]\teval-rmse:3.7815\ttrain-rmse:1.94468\n",
      "[32798]\teval-rmse:3.78033\ttrain-rmse:1.94474\n",
      "[32799]\teval-rmse:3.77889\ttrain-rmse:1.94482\n",
      "[32800]\teval-rmse:3.77946\ttrain-rmse:1.94479\n",
      "[32801]\teval-rmse:3.77761\ttrain-rmse:1.94488\n",
      "[32802]\teval-rmse:3.77819\ttrain-rmse:1.94484\n",
      "[32803]\teval-rmse:3.77775\ttrain-rmse:1.94487\n",
      "[32804]\teval-rmse:3.77912\ttrain-rmse:1.9448\n",
      "[32805]\teval-rmse:3.77794\ttrain-rmse:1.94488\n",
      "[32806]\teval-rmse:3.77647\ttrain-rmse:1.94495\n",
      "[32807]\teval-rmse:3.77554\ttrain-rmse:1.94499\n",
      "[32808]\teval-rmse:3.77693\ttrain-rmse:1.94492\n",
      "[32809]\teval-rmse:3.77852\ttrain-rmse:1.94481\n",
      "[32810]\teval-rmse:3.77737\ttrain-rmse:1.94488\n",
      "[32811]\teval-rmse:3.77875\ttrain-rmse:1.94482\n",
      "[32812]\teval-rmse:3.77706\ttrain-rmse:1.9449\n",
      "[32813]\teval-rmse:3.77541\ttrain-rmse:1.94501\n",
      "[32814]\teval-rmse:3.7757\ttrain-rmse:1.94499\n",
      "[32815]\teval-rmse:3.77592\ttrain-rmse:1.94498\n",
      "[32816]\teval-rmse:3.7772\ttrain-rmse:1.94489\n",
      "[32817]\teval-rmse:3.77707\ttrain-rmse:1.9449\n",
      "[32818]\teval-rmse:3.77662\ttrain-rmse:1.94492\n",
      "[32819]\teval-rmse:3.77763\ttrain-rmse:1.94487\n",
      "[32820]\teval-rmse:3.77627\ttrain-rmse:1.94494\n",
      "[32821]\teval-rmse:3.77705\ttrain-rmse:1.94489\n",
      "[32822]\teval-rmse:3.7776\ttrain-rmse:1.94486\n",
      "[32823]\teval-rmse:3.77719\ttrain-rmse:1.94488\n",
      "[32824]\teval-rmse:3.77625\ttrain-rmse:1.94492\n",
      "[32825]\teval-rmse:3.77656\ttrain-rmse:1.94491\n",
      "[32826]\teval-rmse:3.77519\ttrain-rmse:1.94497\n",
      "[32827]\teval-rmse:3.77426\ttrain-rmse:1.94502\n",
      "[32828]\teval-rmse:3.77574\ttrain-rmse:1.94491\n",
      "[32829]\teval-rmse:3.77574\ttrain-rmse:1.94491\n",
      "[32830]\teval-rmse:3.77432\ttrain-rmse:1.94499\n",
      "[32831]\teval-rmse:3.77392\ttrain-rmse:1.94502\n",
      "[32832]\teval-rmse:3.77551\ttrain-rmse:1.94491\n",
      "[32833]\teval-rmse:3.77519\ttrain-rmse:1.94493\n",
      "[32834]\teval-rmse:3.77474\ttrain-rmse:1.94495\n",
      "[32835]\teval-rmse:3.77342\ttrain-rmse:1.94504\n",
      "[32836]\teval-rmse:3.77501\ttrain-rmse:1.94493\n",
      "[32837]\teval-rmse:3.77546\ttrain-rmse:1.94491\n",
      "[32838]\teval-rmse:3.77434\ttrain-rmse:1.94498\n",
      "[32839]\teval-rmse:3.77568\ttrain-rmse:1.94491\n",
      "[32840]\teval-rmse:3.77623\ttrain-rmse:1.94488\n",
      "[32841]\teval-rmse:3.77478\ttrain-rmse:1.94496\n",
      "[32842]\teval-rmse:3.77657\ttrain-rmse:1.94488\n",
      "[32843]\teval-rmse:3.77647\ttrain-rmse:1.94485\n",
      "[32844]\teval-rmse:3.77633\ttrain-rmse:1.94486\n",
      "[32845]\teval-rmse:3.77638\ttrain-rmse:1.94485\n",
      "[32846]\teval-rmse:3.77573\ttrain-rmse:1.94489\n",
      "[32847]\teval-rmse:3.77694\ttrain-rmse:1.94483\n",
      "[32848]\teval-rmse:3.77681\ttrain-rmse:1.94483\n",
      "[32849]\teval-rmse:3.77806\ttrain-rmse:1.94476\n",
      "[32850]\teval-rmse:3.77743\ttrain-rmse:1.94479\n",
      "[32851]\teval-rmse:3.77627\ttrain-rmse:1.94487\n",
      "[32852]\teval-rmse:3.77741\ttrain-rmse:1.94481\n",
      "[32853]\teval-rmse:3.777\ttrain-rmse:1.94484\n",
      "[32854]\teval-rmse:3.77726\ttrain-rmse:1.94483\n",
      "[32855]\teval-rmse:3.77578\ttrain-rmse:1.94492\n",
      "[32856]\teval-rmse:3.77534\ttrain-rmse:1.94495\n",
      "[32857]\teval-rmse:3.77502\ttrain-rmse:1.94497\n",
      "[32858]\teval-rmse:3.77526\ttrain-rmse:1.94496\n",
      "[32859]\teval-rmse:3.77685\ttrain-rmse:1.94486\n",
      "[32860]\teval-rmse:3.77673\ttrain-rmse:1.94487\n",
      "[32861]\teval-rmse:3.77801\ttrain-rmse:1.94479\n",
      "[32862]\teval-rmse:3.77651\ttrain-rmse:1.94486\n",
      "[32863]\teval-rmse:3.77535\ttrain-rmse:1.94492\n",
      "[32864]\teval-rmse:3.77615\ttrain-rmse:1.94487\n",
      "[32865]\teval-rmse:3.77618\ttrain-rmse:1.94487\n",
      "[32866]\teval-rmse:3.77761\ttrain-rmse:1.94481\n",
      "[32867]\teval-rmse:3.77817\ttrain-rmse:1.94478\n",
      "[32868]\teval-rmse:3.7784\ttrain-rmse:1.94477\n",
      "[32869]\teval-rmse:3.77827\ttrain-rmse:1.94474\n",
      "[32870]\teval-rmse:3.77813\ttrain-rmse:1.94475\n",
      "[32871]\teval-rmse:3.77917\ttrain-rmse:1.94471\n",
      "[32872]\teval-rmse:3.77777\ttrain-rmse:1.94476\n",
      "[32873]\teval-rmse:3.77956\ttrain-rmse:1.9447\n",
      "[32874]\teval-rmse:3.78035\ttrain-rmse:1.94467\n",
      "[32875]\teval-rmse:3.7817\ttrain-rmse:1.94463\n",
      "[32876]\teval-rmse:3.78299\ttrain-rmse:1.94457\n",
      "[32877]\teval-rmse:3.78168\ttrain-rmse:1.9446\n",
      "[32878]\teval-rmse:3.78206\ttrain-rmse:1.94459\n",
      "[32879]\teval-rmse:3.78263\ttrain-rmse:1.94457\n",
      "[32880]\teval-rmse:3.78238\ttrain-rmse:1.94458\n",
      "[32881]\teval-rmse:3.78123\ttrain-rmse:1.94464\n",
      "[32882]\teval-rmse:3.78098\ttrain-rmse:1.94465\n",
      "[32883]\teval-rmse:3.78276\ttrain-rmse:1.94459\n",
      "[32884]\teval-rmse:3.78406\ttrain-rmse:1.94453\n",
      "[32885]\teval-rmse:3.78213\ttrain-rmse:1.94458\n",
      "[32886]\teval-rmse:3.78196\ttrain-rmse:1.94459\n",
      "[32887]\teval-rmse:3.78068\ttrain-rmse:1.94465\n",
      "[32888]\teval-rmse:3.78191\ttrain-rmse:1.94461\n",
      "[32889]\teval-rmse:3.78266\ttrain-rmse:1.94457\n",
      "[32890]\teval-rmse:3.78319\ttrain-rmse:1.94455\n",
      "[32891]\teval-rmse:3.78339\ttrain-rmse:1.94454\n",
      "[32892]\teval-rmse:3.78364\ttrain-rmse:1.94453\n",
      "[32893]\teval-rmse:3.78468\ttrain-rmse:1.94451\n",
      "[32894]\teval-rmse:3.78324\ttrain-rmse:1.94454\n",
      "[32895]\teval-rmse:3.78378\ttrain-rmse:1.94453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32896]\teval-rmse:3.78232\ttrain-rmse:1.94457\n",
      "[32897]\teval-rmse:3.78264\ttrain-rmse:1.94456\n",
      "[32898]\teval-rmse:3.78323\ttrain-rmse:1.94453\n",
      "[32899]\teval-rmse:3.78196\ttrain-rmse:1.94457\n",
      "[32900]\teval-rmse:3.78051\ttrain-rmse:1.94465\n",
      "[32901]\teval-rmse:3.78108\ttrain-rmse:1.94462\n",
      "[32902]\teval-rmse:3.78167\ttrain-rmse:1.94459\n",
      "[32903]\teval-rmse:3.78274\ttrain-rmse:1.94453\n",
      "[32904]\teval-rmse:3.78297\ttrain-rmse:1.94453\n",
      "[32905]\teval-rmse:3.78333\ttrain-rmse:1.94451\n",
      "[32906]\teval-rmse:3.78389\ttrain-rmse:1.94449\n",
      "[32907]\teval-rmse:3.7855\ttrain-rmse:1.94442\n",
      "[32908]\teval-rmse:3.78625\ttrain-rmse:1.9444\n",
      "[32909]\teval-rmse:3.78507\ttrain-rmse:1.94442\n",
      "[32910]\teval-rmse:3.7856\ttrain-rmse:1.94441\n",
      "[32911]\teval-rmse:3.78514\ttrain-rmse:1.94442\n",
      "[32912]\teval-rmse:3.78569\ttrain-rmse:1.9444\n",
      "[32913]\teval-rmse:3.78676\ttrain-rmse:1.94438\n",
      "[32914]\teval-rmse:3.78649\ttrain-rmse:1.94439\n",
      "[32915]\teval-rmse:3.78476\ttrain-rmse:1.94442\n",
      "[32916]\teval-rmse:3.7852\ttrain-rmse:1.9444\n",
      "[32917]\teval-rmse:3.78581\ttrain-rmse:1.94439\n",
      "[32918]\teval-rmse:3.78463\ttrain-rmse:1.94443\n",
      "[32919]\teval-rmse:3.78515\ttrain-rmse:1.94442\n",
      "[32920]\teval-rmse:3.78445\ttrain-rmse:1.94445\n",
      "[32921]\teval-rmse:3.78429\ttrain-rmse:1.94442\n",
      "[32922]\teval-rmse:3.78383\ttrain-rmse:1.94444\n",
      "[32923]\teval-rmse:3.78401\ttrain-rmse:1.94444\n",
      "[32924]\teval-rmse:3.78281\ttrain-rmse:1.94447\n",
      "[32925]\teval-rmse:3.78336\ttrain-rmse:1.94446\n",
      "[32926]\teval-rmse:3.78185\ttrain-rmse:1.94451\n",
      "[32927]\teval-rmse:3.78171\ttrain-rmse:1.94451\n",
      "[32928]\teval-rmse:3.78137\ttrain-rmse:1.94453\n",
      "[32929]\teval-rmse:3.77986\ttrain-rmse:1.9446\n",
      "[32930]\teval-rmse:3.77862\ttrain-rmse:1.94466\n",
      "[32931]\teval-rmse:3.78012\ttrain-rmse:1.94458\n",
      "[32932]\teval-rmse:3.77998\ttrain-rmse:1.94459\n",
      "[32933]\teval-rmse:3.77962\ttrain-rmse:1.94461\n",
      "[32934]\teval-rmse:3.7792\ttrain-rmse:1.94463\n",
      "[32935]\teval-rmse:3.77973\ttrain-rmse:1.9446\n",
      "[32936]\teval-rmse:3.78\ttrain-rmse:1.94459\n",
      "[32937]\teval-rmse:3.77986\ttrain-rmse:1.94456\n",
      "[32938]\teval-rmse:3.77951\ttrain-rmse:1.94458\n",
      "[32939]\teval-rmse:3.77935\ttrain-rmse:1.94458\n",
      "[32940]\teval-rmse:3.7782\ttrain-rmse:1.94464\n",
      "[32941]\teval-rmse:3.77806\ttrain-rmse:1.94465\n",
      "[32942]\teval-rmse:3.77984\ttrain-rmse:1.94459\n",
      "[32943]\teval-rmse:3.77856\ttrain-rmse:1.94464\n",
      "[32944]\teval-rmse:3.78013\ttrain-rmse:1.94455\n",
      "[32945]\teval-rmse:3.77895\ttrain-rmse:1.94462\n",
      "[32946]\teval-rmse:3.7784\ttrain-rmse:1.94465\n",
      "[32947]\teval-rmse:3.77715\ttrain-rmse:1.94473\n",
      "[32948]\teval-rmse:3.77818\ttrain-rmse:1.94467\n",
      "[32949]\teval-rmse:3.7782\ttrain-rmse:1.94467\n",
      "[32950]\teval-rmse:3.7765\ttrain-rmse:1.94476\n",
      "[32951]\teval-rmse:3.77637\ttrain-rmse:1.94473\n",
      "[32952]\teval-rmse:3.77696\ttrain-rmse:1.94469\n",
      "[32953]\teval-rmse:3.77684\ttrain-rmse:1.9447\n",
      "[32954]\teval-rmse:3.77787\ttrain-rmse:1.94464\n",
      "[32955]\teval-rmse:3.77809\ttrain-rmse:1.94463\n",
      "[32956]\teval-rmse:3.77845\ttrain-rmse:1.94461\n",
      "[32957]\teval-rmse:3.77947\ttrain-rmse:1.94457\n",
      "[32958]\teval-rmse:3.78001\ttrain-rmse:1.94454\n",
      "[32959]\teval-rmse:3.78161\ttrain-rmse:1.94445\n",
      "[32960]\teval-rmse:3.78065\ttrain-rmse:1.94448\n",
      "[32961]\teval-rmse:3.7822\ttrain-rmse:1.94443\n",
      "[32962]\teval-rmse:3.78172\ttrain-rmse:1.94445\n",
      "[32963]\teval-rmse:3.7833\ttrain-rmse:1.94439\n",
      "[32964]\teval-rmse:3.78161\ttrain-rmse:1.94444\n",
      "[32965]\teval-rmse:3.7832\ttrain-rmse:1.94437\n",
      "[32966]\teval-rmse:3.78194\ttrain-rmse:1.94442\n",
      "[32967]\teval-rmse:3.78241\ttrain-rmse:1.9444\n",
      "[32968]\teval-rmse:3.78238\ttrain-rmse:1.9444\n",
      "[32969]\teval-rmse:3.782\ttrain-rmse:1.94442\n",
      "[32970]\teval-rmse:3.78186\ttrain-rmse:1.94442\n",
      "[32971]\teval-rmse:3.78066\ttrain-rmse:1.94447\n",
      "[32972]\teval-rmse:3.78212\ttrain-rmse:1.9444\n",
      "[32973]\teval-rmse:3.78195\ttrain-rmse:1.9444\n",
      "[32974]\teval-rmse:3.78099\ttrain-rmse:1.94443\n",
      "[32975]\teval-rmse:3.78119\ttrain-rmse:1.94443\n",
      "[32976]\teval-rmse:3.78241\ttrain-rmse:1.94439\n",
      "[32977]\teval-rmse:3.78122\ttrain-rmse:1.94443\n",
      "[32978]\teval-rmse:3.77977\ttrain-rmse:1.9445\n",
      "[32979]\teval-rmse:3.78156\ttrain-rmse:1.94444\n",
      "[32980]\teval-rmse:3.78111\ttrain-rmse:1.94447\n",
      "[32981]\teval-rmse:3.78269\ttrain-rmse:1.9444\n",
      "[32982]\teval-rmse:3.78128\ttrain-rmse:1.94445\n",
      "[32983]\teval-rmse:3.78012\ttrain-rmse:1.9445\n",
      "[32984]\teval-rmse:3.7801\ttrain-rmse:1.9445\n",
      "[32985]\teval-rmse:3.78143\ttrain-rmse:1.94444\n",
      "[32986]\teval-rmse:3.78118\ttrain-rmse:1.94445\n",
      "[32987]\teval-rmse:3.78073\ttrain-rmse:1.94447\n",
      "[32988]\teval-rmse:3.78252\ttrain-rmse:1.94442\n",
      "[32989]\teval-rmse:3.78209\ttrain-rmse:1.94443\n",
      "[32990]\teval-rmse:3.78166\ttrain-rmse:1.94445\n",
      "[32991]\teval-rmse:3.7827\ttrain-rmse:1.94441\n",
      "[32992]\teval-rmse:3.78102\ttrain-rmse:1.94448\n",
      "[32993]\teval-rmse:3.78259\ttrain-rmse:1.94442\n",
      "[32994]\teval-rmse:3.782\ttrain-rmse:1.94444\n",
      "[32995]\teval-rmse:3.78083\ttrain-rmse:1.9445\n",
      "[32996]\teval-rmse:3.78119\ttrain-rmse:1.94448\n",
      "[32997]\teval-rmse:3.78274\ttrain-rmse:1.9444\n",
      "[32998]\teval-rmse:3.7842\ttrain-rmse:1.94436\n",
      "[32999]\teval-rmse:3.7837\ttrain-rmse:1.94437\n",
      "[33000]\teval-rmse:3.78525\ttrain-rmse:1.94433\n",
      "[33001]\teval-rmse:3.78551\ttrain-rmse:1.94432\n",
      "[33002]\teval-rmse:3.78513\ttrain-rmse:1.94433\n",
      "[33003]\teval-rmse:3.78384\ttrain-rmse:1.94438\n",
      "[33004]\teval-rmse:3.78213\ttrain-rmse:1.94443\n",
      "[33005]\teval-rmse:3.78142\ttrain-rmse:1.94446\n",
      "[33006]\teval-rmse:3.78273\ttrain-rmse:1.9444\n",
      "[33007]\teval-rmse:3.78319\ttrain-rmse:1.94438\n",
      "[33008]\teval-rmse:3.78222\ttrain-rmse:1.94441\n",
      "[33009]\teval-rmse:3.78377\ttrain-rmse:1.94434\n",
      "[33010]\teval-rmse:3.78351\ttrain-rmse:1.94434\n",
      "[33011]\teval-rmse:3.78334\ttrain-rmse:1.94435\n",
      "[33012]\teval-rmse:3.78308\ttrain-rmse:1.94436\n",
      "[33013]\teval-rmse:3.78328\ttrain-rmse:1.94435\n",
      "[33014]\teval-rmse:3.78346\ttrain-rmse:1.94434\n",
      "[33015]\teval-rmse:3.7837\ttrain-rmse:1.94433\n",
      "[33016]\teval-rmse:3.78428\ttrain-rmse:1.94432\n",
      "[33017]\teval-rmse:3.78358\ttrain-rmse:1.94434\n",
      "[33018]\teval-rmse:3.78414\ttrain-rmse:1.94432\n",
      "[33019]\teval-rmse:3.78449\ttrain-rmse:1.9443\n",
      "[33020]\teval-rmse:3.78422\ttrain-rmse:1.94431\n",
      "[33021]\teval-rmse:3.78407\ttrain-rmse:1.94428\n",
      "[33022]\teval-rmse:3.78585\ttrain-rmse:1.94424\n",
      "[33023]\teval-rmse:3.78628\ttrain-rmse:1.94423\n",
      "[33024]\teval-rmse:3.78769\ttrain-rmse:1.94421\n",
      "[33025]\teval-rmse:3.78791\ttrain-rmse:1.9442\n",
      "[33026]\teval-rmse:3.78898\ttrain-rmse:1.94419\n",
      "[33027]\teval-rmse:3.78851\ttrain-rmse:1.9442\n",
      "[33028]\teval-rmse:3.78783\ttrain-rmse:1.94422\n",
      "[33029]\teval-rmse:3.78817\ttrain-rmse:1.94421\n",
      "[33030]\teval-rmse:3.78945\ttrain-rmse:1.94418\n",
      "[33031]\teval-rmse:3.78966\ttrain-rmse:1.94418\n",
      "[33032]\teval-rmse:3.78968\ttrain-rmse:1.94418\n",
      "[33033]\teval-rmse:3.79104\ttrain-rmse:1.94415\n",
      "[33034]\teval-rmse:3.79232\ttrain-rmse:1.94416\n",
      "[33035]\teval-rmse:3.79285\ttrain-rmse:1.94416\n",
      "[33036]\teval-rmse:3.79316\ttrain-rmse:1.94416\n",
      "[33037]\teval-rmse:3.79493\ttrain-rmse:1.94416\n",
      "[33038]\teval-rmse:3.79542\ttrain-rmse:1.94416\n",
      "[33039]\teval-rmse:3.79678\ttrain-rmse:1.94419\n",
      "[33040]\teval-rmse:3.79533\ttrain-rmse:1.94419\n",
      "[33041]\teval-rmse:3.79397\ttrain-rmse:1.9442\n",
      "[33042]\teval-rmse:3.79343\ttrain-rmse:1.94421\n",
      "[33043]\teval-rmse:3.79168\ttrain-rmse:1.94421\n",
      "[33044]\teval-rmse:3.79096\ttrain-rmse:1.94422\n",
      "[33045]\teval-rmse:3.79045\ttrain-rmse:1.94423\n",
      "[33046]\teval-rmse:3.79025\ttrain-rmse:1.94423\n",
      "[33047]\teval-rmse:3.79067\ttrain-rmse:1.94423\n",
      "[33048]\teval-rmse:3.79192\ttrain-rmse:1.94423\n",
      "[33049]\teval-rmse:3.79227\ttrain-rmse:1.94423\n",
      "[33050]\teval-rmse:3.79084\ttrain-rmse:1.94426\n",
      "[33051]\teval-rmse:3.78961\ttrain-rmse:1.94429\n",
      "[33052]\teval-rmse:3.78985\ttrain-rmse:1.94429\n",
      "[33053]\teval-rmse:3.79027\ttrain-rmse:1.94429\n",
      "[33054]\teval-rmse:3.79176\ttrain-rmse:1.9443\n",
      "[33055]\teval-rmse:3.7903\ttrain-rmse:1.94432\n",
      "[33056]\teval-rmse:3.79102\ttrain-rmse:1.94431\n",
      "[33057]\teval-rmse:3.79135\ttrain-rmse:1.9443\n",
      "[33058]\teval-rmse:3.79085\ttrain-rmse:1.94431\n",
      "[33059]\teval-rmse:3.78913\ttrain-rmse:1.9443\n",
      "[33060]\teval-rmse:3.78884\ttrain-rmse:1.94431\n",
      "[33061]\teval-rmse:3.79013\ttrain-rmse:1.9443\n",
      "[33062]\teval-rmse:3.79037\ttrain-rmse:1.9443\n",
      "[33063]\teval-rmse:3.78907\ttrain-rmse:1.94433\n",
      "[33064]\teval-rmse:3.79082\ttrain-rmse:1.94435\n",
      "[33065]\teval-rmse:3.79114\ttrain-rmse:1.94435\n",
      "[33066]\teval-rmse:3.79268\ttrain-rmse:1.94436\n",
      "[33067]\teval-rmse:3.79229\ttrain-rmse:1.94436\n",
      "[33068]\teval-rmse:3.79033\ttrain-rmse:1.94434\n",
      "[33069]\teval-rmse:3.78913\ttrain-rmse:1.94437\n",
      "[33070]\teval-rmse:3.78952\ttrain-rmse:1.94437\n",
      "[33071]\teval-rmse:3.7895\ttrain-rmse:1.94437\n",
      "[33072]\teval-rmse:3.79009\ttrain-rmse:1.94437\n",
      "[33073]\teval-rmse:3.78962\ttrain-rmse:1.94438\n",
      "[33074]\teval-rmse:3.78817\ttrain-rmse:1.94441\n",
      "[33075]\teval-rmse:3.78688\ttrain-rmse:1.94444\n",
      "[33076]\teval-rmse:3.78765\ttrain-rmse:1.94441\n",
      "[33077]\teval-rmse:3.78647\ttrain-rmse:1.94445\n",
      "[33078]\teval-rmse:3.78575\ttrain-rmse:1.94446\n",
      "[33079]\teval-rmse:3.78548\ttrain-rmse:1.94446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33080]\teval-rmse:3.78428\ttrain-rmse:1.9445\n",
      "[33081]\teval-rmse:3.78401\ttrain-rmse:1.94451\n",
      "[33082]\teval-rmse:3.78303\ttrain-rmse:1.94453\n",
      "[33083]\teval-rmse:3.78481\ttrain-rmse:1.94449\n",
      "[33084]\teval-rmse:3.78537\ttrain-rmse:1.94447\n",
      "[33085]\teval-rmse:3.78658\ttrain-rmse:1.94446\n",
      "[33086]\teval-rmse:3.78613\ttrain-rmse:1.94447\n",
      "[33087]\teval-rmse:3.7849\ttrain-rmse:1.94451\n",
      "[33088]\teval-rmse:3.78363\ttrain-rmse:1.94456\n",
      "[33089]\teval-rmse:3.78348\ttrain-rmse:1.94453\n",
      "[33090]\teval-rmse:3.78372\ttrain-rmse:1.94452\n",
      "[33091]\teval-rmse:3.7824\ttrain-rmse:1.94455\n",
      "[33092]\teval-rmse:3.78319\ttrain-rmse:1.94451\n",
      "[33093]\teval-rmse:3.78395\ttrain-rmse:1.94448\n",
      "[33094]\teval-rmse:3.78556\ttrain-rmse:1.94442\n",
      "[33095]\teval-rmse:3.78701\ttrain-rmse:1.94438\n",
      "[33096]\teval-rmse:3.78682\ttrain-rmse:1.94438\n",
      "[33097]\teval-rmse:3.78654\ttrain-rmse:1.94439\n",
      "[33098]\teval-rmse:3.78811\ttrain-rmse:1.94434\n",
      "[33099]\teval-rmse:3.78969\ttrain-rmse:1.94431\n",
      "[33100]\teval-rmse:3.791\ttrain-rmse:1.94431\n",
      "[33101]\teval-rmse:3.79225\ttrain-rmse:1.94429\n",
      "[33102]\teval-rmse:3.79206\ttrain-rmse:1.94426\n",
      "[33103]\teval-rmse:3.79235\ttrain-rmse:1.94427\n",
      "[33104]\teval-rmse:3.79083\ttrain-rmse:1.94429\n",
      "[33105]\teval-rmse:3.78961\ttrain-rmse:1.94432\n",
      "[33106]\teval-rmse:3.78859\ttrain-rmse:1.94433\n",
      "[33107]\teval-rmse:3.7873\ttrain-rmse:1.94436\n",
      "[33108]\teval-rmse:3.78783\ttrain-rmse:1.94436\n",
      "[33109]\teval-rmse:3.78936\ttrain-rmse:1.94433\n",
      "[33110]\teval-rmse:3.79092\ttrain-rmse:1.94435\n",
      "[33111]\teval-rmse:3.78959\ttrain-rmse:1.94434\n",
      "[33112]\teval-rmse:3.79119\ttrain-rmse:1.94432\n",
      "[33113]\teval-rmse:3.79296\ttrain-rmse:1.94431\n",
      "[33114]\teval-rmse:3.79174\ttrain-rmse:1.94433\n",
      "[33115]\teval-rmse:3.79153\ttrain-rmse:1.94433\n",
      "[33116]\teval-rmse:3.79103\ttrain-rmse:1.94433\n",
      "[33117]\teval-rmse:3.79155\ttrain-rmse:1.94434\n",
      "[33118]\teval-rmse:3.78999\ttrain-rmse:1.94436\n",
      "[33119]\teval-rmse:3.78801\ttrain-rmse:1.94435\n",
      "[33120]\teval-rmse:3.78831\ttrain-rmse:1.94435\n",
      "[33121]\teval-rmse:3.79009\ttrain-rmse:1.94433\n",
      "[33122]\teval-rmse:3.79048\ttrain-rmse:1.94433\n",
      "[33123]\teval-rmse:3.79173\ttrain-rmse:1.94432\n",
      "[33124]\teval-rmse:3.79317\ttrain-rmse:1.9443\n",
      "[33125]\teval-rmse:3.79262\ttrain-rmse:1.94431\n",
      "[33126]\teval-rmse:3.79391\ttrain-rmse:1.94433\n",
      "[33127]\teval-rmse:3.79568\ttrain-rmse:1.94433\n",
      "[33128]\teval-rmse:3.79445\ttrain-rmse:1.94434\n",
      "[33129]\teval-rmse:3.79623\ttrain-rmse:1.94435\n",
      "[33130]\teval-rmse:3.7978\ttrain-rmse:1.94434\n",
      "[33131]\teval-rmse:3.79759\ttrain-rmse:1.94433\n",
      "[33132]\teval-rmse:3.79682\ttrain-rmse:1.94433\n",
      "[33133]\teval-rmse:3.79577\ttrain-rmse:1.94432\n",
      "[33134]\teval-rmse:3.79555\ttrain-rmse:1.94432\n",
      "[33135]\teval-rmse:3.79638\ttrain-rmse:1.94434\n",
      "[33136]\teval-rmse:3.79699\ttrain-rmse:1.94436\n",
      "[33137]\teval-rmse:3.79835\ttrain-rmse:1.94437\n",
      "[33138]\teval-rmse:3.79889\ttrain-rmse:1.94437\n",
      "[33139]\teval-rmse:3.7992\ttrain-rmse:1.94438\n",
      "[33140]\teval-rmse:3.79963\ttrain-rmse:1.9444\n",
      "[33141]\teval-rmse:3.80091\ttrain-rmse:1.94442\n",
      "[33142]\teval-rmse:3.80041\ttrain-rmse:1.9444\n",
      "[33143]\teval-rmse:3.80076\ttrain-rmse:1.94441\n",
      "[33144]\teval-rmse:3.79939\ttrain-rmse:1.9444\n",
      "[33145]\teval-rmse:3.79933\ttrain-rmse:1.9444\n",
      "[33146]\teval-rmse:3.79972\ttrain-rmse:1.94442\n",
      "[33147]\teval-rmse:3.80098\ttrain-rmse:1.94444\n",
      "[33148]\teval-rmse:3.80246\ttrain-rmse:1.94445\n",
      "[33149]\teval-rmse:3.8008\ttrain-rmse:1.94438\n",
      "[33150]\teval-rmse:3.7997\ttrain-rmse:1.94436\n",
      "[33151]\teval-rmse:3.80124\ttrain-rmse:1.94443\n",
      "[33152]\teval-rmse:3.79995\ttrain-rmse:1.9444\n",
      "[33153]\teval-rmse:3.79973\ttrain-rmse:1.9444\n",
      "[33154]\teval-rmse:3.8015\ttrain-rmse:1.94442\n",
      "[33155]\teval-rmse:3.80163\ttrain-rmse:1.94443\n",
      "[33156]\teval-rmse:3.7999\ttrain-rmse:1.94437\n",
      "[33157]\teval-rmse:3.79883\ttrain-rmse:1.94435\n",
      "[33158]\teval-rmse:3.79907\ttrain-rmse:1.94436\n",
      "[33159]\teval-rmse:3.79948\ttrain-rmse:1.94438\n",
      "[33160]\teval-rmse:3.80073\ttrain-rmse:1.94438\n",
      "[33161]\teval-rmse:3.80124\ttrain-rmse:1.94438\n",
      "[33162]\teval-rmse:3.80279\ttrain-rmse:1.94442\n",
      "[33163]\teval-rmse:3.8029\ttrain-rmse:1.94443\n",
      "[33164]\teval-rmse:3.80391\ttrain-rmse:1.94448\n",
      "[33165]\teval-rmse:3.80355\ttrain-rmse:1.94447\n",
      "[33166]\teval-rmse:3.80476\ttrain-rmse:1.94451\n",
      "[33167]\teval-rmse:3.80603\ttrain-rmse:1.94453\n",
      "[33168]\teval-rmse:3.80534\ttrain-rmse:1.9445\n",
      "[33169]\teval-rmse:3.80686\ttrain-rmse:1.94455\n",
      "[33170]\teval-rmse:3.80574\ttrain-rmse:1.94452\n",
      "[33171]\teval-rmse:3.80432\ttrain-rmse:1.94449\n",
      "[33172]\teval-rmse:3.80249\ttrain-rmse:1.94439\n",
      "[33173]\teval-rmse:3.80111\ttrain-rmse:1.94437\n",
      "[33174]\teval-rmse:3.80236\ttrain-rmse:1.94443\n",
      "[33175]\teval-rmse:3.80235\ttrain-rmse:1.94443\n",
      "[33176]\teval-rmse:3.80108\ttrain-rmse:1.9444\n",
      "[33177]\teval-rmse:3.80262\ttrain-rmse:1.94444\n",
      "[33178]\teval-rmse:3.80239\ttrain-rmse:1.94441\n",
      "[33179]\teval-rmse:3.80276\ttrain-rmse:1.94442\n",
      "[33180]\teval-rmse:3.80415\ttrain-rmse:1.94449\n",
      "[33181]\teval-rmse:3.80281\ttrain-rmse:1.94443\n",
      "[33182]\teval-rmse:3.80204\ttrain-rmse:1.9444\n",
      "[33183]\teval-rmse:3.80043\ttrain-rmse:1.94437\n",
      "[33184]\teval-rmse:3.79917\ttrain-rmse:1.94435\n",
      "[33185]\teval-rmse:3.8005\ttrain-rmse:1.94441\n",
      "[33186]\teval-rmse:3.80207\ttrain-rmse:1.94443\n",
      "[33187]\teval-rmse:3.80276\ttrain-rmse:1.94446\n",
      "[33188]\teval-rmse:3.80313\ttrain-rmse:1.94448\n",
      "[33189]\teval-rmse:3.80363\ttrain-rmse:1.94451\n",
      "[33190]\teval-rmse:3.8034\ttrain-rmse:1.9445\n",
      "[33191]\teval-rmse:3.80388\ttrain-rmse:1.94451\n",
      "[33192]\teval-rmse:3.80363\ttrain-rmse:1.94451\n",
      "[33193]\teval-rmse:3.80508\ttrain-rmse:1.94456\n",
      "[33194]\teval-rmse:3.80484\ttrain-rmse:1.94452\n",
      "[33195]\teval-rmse:3.80514\ttrain-rmse:1.94454\n",
      "[33196]\teval-rmse:3.80347\ttrain-rmse:1.94449\n",
      "[33197]\teval-rmse:3.80396\ttrain-rmse:1.94451\n",
      "[33198]\teval-rmse:3.80252\ttrain-rmse:1.94447\n",
      "[33199]\teval-rmse:3.80125\ttrain-rmse:1.94445\n",
      "[33200]\teval-rmse:3.80079\ttrain-rmse:1.94443\n",
      "[33201]\teval-rmse:3.80238\ttrain-rmse:1.94447\n",
      "[33202]\teval-rmse:3.80214\ttrain-rmse:1.94444\n",
      "[33203]\teval-rmse:3.80193\ttrain-rmse:1.94443\n",
      "[33204]\teval-rmse:3.80149\ttrain-rmse:1.94442\n",
      "[33205]\teval-rmse:3.80123\ttrain-rmse:1.94441\n",
      "[33206]\teval-rmse:3.80247\ttrain-rmse:1.94445\n",
      "[33207]\teval-rmse:3.80224\ttrain-rmse:1.94442\n",
      "[33208]\teval-rmse:3.80171\ttrain-rmse:1.94441\n",
      "[33209]\teval-rmse:3.80021\ttrain-rmse:1.94437\n",
      "[33210]\teval-rmse:3.80169\ttrain-rmse:1.94438\n",
      "[33211]\teval-rmse:3.80291\ttrain-rmse:1.94442\n",
      "[33212]\teval-rmse:3.80161\ttrain-rmse:1.9444\n",
      "[33213]\teval-rmse:3.80262\ttrain-rmse:1.94446\n",
      "[33214]\teval-rmse:3.80082\ttrain-rmse:1.94437\n",
      "[33215]\teval-rmse:3.80224\ttrain-rmse:1.94445\n",
      "[33216]\teval-rmse:3.80248\ttrain-rmse:1.94446\n",
      "[33217]\teval-rmse:3.80371\ttrain-rmse:1.94454\n",
      "[33218]\teval-rmse:3.80233\ttrain-rmse:1.94445\n",
      "[33219]\teval-rmse:3.80198\ttrain-rmse:1.94444\n",
      "[33220]\teval-rmse:3.80328\ttrain-rmse:1.94449\n",
      "[33221]\teval-rmse:3.80364\ttrain-rmse:1.94451\n",
      "[33222]\teval-rmse:3.80508\ttrain-rmse:1.94456\n",
      "[33223]\teval-rmse:3.80523\ttrain-rmse:1.94457\n",
      "[33224]\teval-rmse:3.80674\ttrain-rmse:1.94464\n",
      "[33225]\teval-rmse:3.80518\ttrain-rmse:1.94454\n",
      "[33226]\teval-rmse:3.80674\ttrain-rmse:1.94461\n",
      "[33227]\teval-rmse:3.80746\ttrain-rmse:1.94462\n",
      "[33228]\teval-rmse:3.8072\ttrain-rmse:1.94461\n",
      "[33229]\teval-rmse:3.80763\ttrain-rmse:1.94464\n",
      "[33230]\teval-rmse:3.80705\ttrain-rmse:1.94462\n",
      "[33231]\teval-rmse:3.80805\ttrain-rmse:1.94469\n",
      "[33232]\teval-rmse:3.80823\ttrain-rmse:1.94471\n",
      "[33233]\teval-rmse:3.8071\ttrain-rmse:1.94467\n",
      "[33234]\teval-rmse:3.80579\ttrain-rmse:1.94464\n",
      "[33235]\teval-rmse:3.80522\ttrain-rmse:1.94463\n",
      "[33236]\teval-rmse:3.8036\ttrain-rmse:1.94452\n",
      "[33237]\teval-rmse:3.80335\ttrain-rmse:1.94449\n",
      "[33238]\teval-rmse:3.80359\ttrain-rmse:1.94451\n",
      "[33239]\teval-rmse:3.80415\ttrain-rmse:1.94454\n",
      "[33240]\teval-rmse:3.80391\ttrain-rmse:1.94453\n",
      "[33241]\teval-rmse:3.80354\ttrain-rmse:1.94452\n",
      "[33242]\teval-rmse:3.80489\ttrain-rmse:1.94457\n",
      "[33243]\teval-rmse:3.80544\ttrain-rmse:1.94461\n",
      "[33244]\teval-rmse:3.807\ttrain-rmse:1.94469\n",
      "[33245]\teval-rmse:3.8057\ttrain-rmse:1.94465\n",
      "[33246]\teval-rmse:3.80507\ttrain-rmse:1.9446\n",
      "[33247]\teval-rmse:3.80343\ttrain-rmse:1.94449\n",
      "[33248]\teval-rmse:3.80142\ttrain-rmse:1.94437\n",
      "[33249]\teval-rmse:3.80063\ttrain-rmse:1.94434\n",
      "[33250]\teval-rmse:3.80216\ttrain-rmse:1.94437\n",
      "[33251]\teval-rmse:3.80054\ttrain-rmse:1.94431\n",
      "[33252]\teval-rmse:3.79925\ttrain-rmse:1.9443\n",
      "[33253]\teval-rmse:3.79818\ttrain-rmse:1.94429\n",
      "[33254]\teval-rmse:3.79636\ttrain-rmse:1.9442\n",
      "[33255]\teval-rmse:3.79775\ttrain-rmse:1.94425\n",
      "[33256]\teval-rmse:3.79612\ttrain-rmse:1.94418\n",
      "[33257]\teval-rmse:3.79559\ttrain-rmse:1.94418\n",
      "[33258]\teval-rmse:3.79703\ttrain-rmse:1.94421\n",
      "[33259]\teval-rmse:3.79682\ttrain-rmse:1.94418\n",
      "[33260]\teval-rmse:3.79859\ttrain-rmse:1.94419\n",
      "[33261]\teval-rmse:3.80006\ttrain-rmse:1.9442\n",
      "[33262]\teval-rmse:3.79985\ttrain-rmse:1.94417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33263]\teval-rmse:3.80058\ttrain-rmse:1.94417\n",
      "[33264]\teval-rmse:3.80111\ttrain-rmse:1.94418\n",
      "[33265]\teval-rmse:3.80032\ttrain-rmse:1.94416\n",
      "[33266]\teval-rmse:3.80135\ttrain-rmse:1.9442\n",
      "[33267]\teval-rmse:3.79953\ttrain-rmse:1.94411\n",
      "[33268]\teval-rmse:3.79933\ttrain-rmse:1.94408\n",
      "[33269]\teval-rmse:3.80056\ttrain-rmse:1.94412\n",
      "[33270]\teval-rmse:3.80033\ttrain-rmse:1.94409\n",
      "[33271]\teval-rmse:3.80209\ttrain-rmse:1.94412\n",
      "[33272]\teval-rmse:3.80279\ttrain-rmse:1.94414\n",
      "[33273]\teval-rmse:3.80435\ttrain-rmse:1.94423\n",
      "[33274]\teval-rmse:3.80455\ttrain-rmse:1.94424\n",
      "[33275]\teval-rmse:3.80407\ttrain-rmse:1.94422\n",
      "[33276]\teval-rmse:3.80427\ttrain-rmse:1.94423\n",
      "[33277]\teval-rmse:3.8039\ttrain-rmse:1.94422\n",
      "[33278]\teval-rmse:3.80354\ttrain-rmse:1.94421\n",
      "[33279]\teval-rmse:3.80201\ttrain-rmse:1.94415\n",
      "[33280]\teval-rmse:3.80196\ttrain-rmse:1.94415\n",
      "[33281]\teval-rmse:3.80254\ttrain-rmse:1.94418\n",
      "[33282]\teval-rmse:3.80227\ttrain-rmse:1.94417\n",
      "[33283]\teval-rmse:3.80404\ttrain-rmse:1.94421\n",
      "[33284]\teval-rmse:3.80243\ttrain-rmse:1.94415\n",
      "[33285]\teval-rmse:3.8039\ttrain-rmse:1.94418\n",
      "[33286]\teval-rmse:3.80525\ttrain-rmse:1.94423\n",
      "[33287]\teval-rmse:3.8056\ttrain-rmse:1.94425\n",
      "[33288]\teval-rmse:3.80419\ttrain-rmse:1.94422\n",
      "[33289]\teval-rmse:3.80375\ttrain-rmse:1.94421\n",
      "[33290]\teval-rmse:3.80297\ttrain-rmse:1.94419\n",
      "[33291]\teval-rmse:3.80295\ttrain-rmse:1.94419\n",
      "[33292]\teval-rmse:3.80442\ttrain-rmse:1.94424\n",
      "[33293]\teval-rmse:3.80463\ttrain-rmse:1.94425\n",
      "[33294]\teval-rmse:3.80617\ttrain-rmse:1.94432\n",
      "[33295]\teval-rmse:3.8058\ttrain-rmse:1.94431\n",
      "[33296]\teval-rmse:3.80552\ttrain-rmse:1.9443\n",
      "[33297]\teval-rmse:3.80566\ttrain-rmse:1.94431\n",
      "[33298]\teval-rmse:3.80595\ttrain-rmse:1.94433\n",
      "[33299]\teval-rmse:3.80667\ttrain-rmse:1.94436\n",
      "[33300]\teval-rmse:3.80505\ttrain-rmse:1.94429\n",
      "[33301]\teval-rmse:3.80623\ttrain-rmse:1.94434\n",
      "[33302]\teval-rmse:3.80565\ttrain-rmse:1.94433\n",
      "[33303]\teval-rmse:3.80604\ttrain-rmse:1.94434\n",
      "[33304]\teval-rmse:3.80422\ttrain-rmse:1.94424\n",
      "[33305]\teval-rmse:3.80398\ttrain-rmse:1.94423\n",
      "[33306]\teval-rmse:3.80447\ttrain-rmse:1.94425\n",
      "[33307]\teval-rmse:3.80417\ttrain-rmse:1.94422\n",
      "[33308]\teval-rmse:3.80347\ttrain-rmse:1.94418\n",
      "[33309]\teval-rmse:3.80418\ttrain-rmse:1.94419\n",
      "[33310]\teval-rmse:3.80256\ttrain-rmse:1.94413\n",
      "[33311]\teval-rmse:3.80124\ttrain-rmse:1.94408\n",
      "[33312]\teval-rmse:3.80163\ttrain-rmse:1.9441\n",
      "[33313]\teval-rmse:3.80014\ttrain-rmse:1.94406\n",
      "[33314]\teval-rmse:3.80056\ttrain-rmse:1.94407\n",
      "[33315]\teval-rmse:3.80092\ttrain-rmse:1.94409\n",
      "[33316]\teval-rmse:3.80142\ttrain-rmse:1.9441\n",
      "[33317]\teval-rmse:3.8016\ttrain-rmse:1.94411\n",
      "[33318]\teval-rmse:3.80102\ttrain-rmse:1.9441\n",
      "[33319]\teval-rmse:3.80247\ttrain-rmse:1.94412\n",
      "[33320]\teval-rmse:3.80212\ttrain-rmse:1.94411\n",
      "[33321]\teval-rmse:3.80313\ttrain-rmse:1.94415\n",
      "[33322]\teval-rmse:3.80153\ttrain-rmse:1.94406\n",
      "[33323]\teval-rmse:3.80262\ttrain-rmse:1.94412\n",
      "[33324]\teval-rmse:3.80084\ttrain-rmse:1.94404\n",
      "[33325]\teval-rmse:3.79946\ttrain-rmse:1.94398\n",
      "[33326]\teval-rmse:3.80071\ttrain-rmse:1.94404\n",
      "[33327]\teval-rmse:3.80247\ttrain-rmse:1.94407\n",
      "[33328]\teval-rmse:3.80105\ttrain-rmse:1.94404\n",
      "[33329]\teval-rmse:3.80081\ttrain-rmse:1.94403\n",
      "[33330]\teval-rmse:3.79928\ttrain-rmse:1.94396\n",
      "[33331]\teval-rmse:3.79969\ttrain-rmse:1.94398\n",
      "[33332]\teval-rmse:3.80072\ttrain-rmse:1.944\n",
      "[33333]\teval-rmse:3.80172\ttrain-rmse:1.94405\n",
      "[33334]\teval-rmse:3.80043\ttrain-rmse:1.94403\n",
      "[33335]\teval-rmse:3.80084\ttrain-rmse:1.94403\n",
      "[33336]\teval-rmse:3.8014\ttrain-rmse:1.94406\n",
      "[33337]\teval-rmse:3.80021\ttrain-rmse:1.944\n",
      "[33338]\teval-rmse:3.80175\ttrain-rmse:1.94405\n",
      "[33339]\teval-rmse:3.80009\ttrain-rmse:1.944\n",
      "[33340]\teval-rmse:3.80025\ttrain-rmse:1.94401\n",
      "[33341]\teval-rmse:3.7999\ttrain-rmse:1.944\n",
      "[33342]\teval-rmse:3.79827\ttrain-rmse:1.94393\n",
      "[33343]\teval-rmse:3.79699\ttrain-rmse:1.94393\n",
      "[33344]\teval-rmse:3.79515\ttrain-rmse:1.94388\n",
      "[33345]\teval-rmse:3.7938\ttrain-rmse:1.94388\n",
      "[33346]\teval-rmse:3.79276\ttrain-rmse:1.94388\n",
      "[33347]\teval-rmse:3.79331\ttrain-rmse:1.94389\n",
      "[33348]\teval-rmse:3.79468\ttrain-rmse:1.9439\n",
      "[33349]\teval-rmse:3.7952\ttrain-rmse:1.94391\n",
      "[33350]\teval-rmse:3.79467\ttrain-rmse:1.9439\n",
      "[33351]\teval-rmse:3.7934\ttrain-rmse:1.94389\n",
      "[33352]\teval-rmse:3.7934\ttrain-rmse:1.94389\n",
      "[33353]\teval-rmse:3.79499\ttrain-rmse:1.94388\n",
      "[33354]\teval-rmse:3.79517\ttrain-rmse:1.94388\n",
      "[33355]\teval-rmse:3.79465\ttrain-rmse:1.94388\n",
      "[33356]\teval-rmse:3.79308\ttrain-rmse:1.94386\n",
      "[33357]\teval-rmse:3.79159\ttrain-rmse:1.94384\n",
      "[33358]\teval-rmse:3.79157\ttrain-rmse:1.94384\n",
      "[33359]\teval-rmse:3.79113\ttrain-rmse:1.94384\n",
      "[33360]\teval-rmse:3.79261\ttrain-rmse:1.94384\n",
      "[33361]\teval-rmse:3.79208\ttrain-rmse:1.94384\n",
      "[33362]\teval-rmse:3.79356\ttrain-rmse:1.94382\n",
      "[33363]\teval-rmse:3.79338\ttrain-rmse:1.94379\n",
      "[33364]\teval-rmse:3.79462\ttrain-rmse:1.94379\n",
      "[33365]\teval-rmse:3.79519\ttrain-rmse:1.9438\n",
      "[33366]\teval-rmse:3.79413\ttrain-rmse:1.94379\n",
      "[33367]\teval-rmse:3.79488\ttrain-rmse:1.94379\n",
      "[33368]\teval-rmse:3.79562\ttrain-rmse:1.94379\n",
      "[33369]\teval-rmse:3.79665\ttrain-rmse:1.9438\n",
      "[33370]\teval-rmse:3.79558\ttrain-rmse:1.9438\n",
      "[33371]\teval-rmse:3.79598\ttrain-rmse:1.94381\n",
      "[33372]\teval-rmse:3.79614\ttrain-rmse:1.94381\n",
      "[33373]\teval-rmse:3.79645\ttrain-rmse:1.94382\n",
      "[33374]\teval-rmse:3.79761\ttrain-rmse:1.94385\n",
      "[33375]\teval-rmse:3.79704\ttrain-rmse:1.94384\n",
      "[33376]\teval-rmse:3.79806\ttrain-rmse:1.94387\n",
      "[33377]\teval-rmse:3.79953\ttrain-rmse:1.94388\n",
      "[33378]\teval-rmse:3.79805\ttrain-rmse:1.94386\n",
      "[33379]\teval-rmse:3.79949\ttrain-rmse:1.94391\n",
      "[33380]\teval-rmse:3.79927\ttrain-rmse:1.94388\n",
      "[33381]\teval-rmse:3.80071\ttrain-rmse:1.9439\n",
      "[33382]\teval-rmse:3.80111\ttrain-rmse:1.94392\n",
      "[33383]\teval-rmse:3.79928\ttrain-rmse:1.94384\n",
      "[33384]\teval-rmse:3.798\ttrain-rmse:1.94381\n",
      "[33385]\teval-rmse:3.79754\ttrain-rmse:1.9438\n",
      "[33386]\teval-rmse:3.7973\ttrain-rmse:1.9438\n",
      "[33387]\teval-rmse:3.79697\ttrain-rmse:1.9438\n",
      "[33388]\teval-rmse:3.79675\ttrain-rmse:1.94377\n",
      "[33389]\teval-rmse:3.79601\ttrain-rmse:1.94375\n",
      "[33390]\teval-rmse:3.79749\ttrain-rmse:1.94378\n",
      "[33391]\teval-rmse:3.79904\ttrain-rmse:1.94379\n",
      "[33392]\teval-rmse:3.79922\ttrain-rmse:1.9438\n",
      "[33393]\teval-rmse:3.79963\ttrain-rmse:1.94381\n",
      "[33394]\teval-rmse:3.79982\ttrain-rmse:1.94382\n",
      "[33395]\teval-rmse:3.80086\ttrain-rmse:1.94386\n",
      "[33396]\teval-rmse:3.80262\ttrain-rmse:1.9439\n",
      "[33397]\teval-rmse:3.8037\ttrain-rmse:1.94395\n",
      "[33398]\teval-rmse:3.80503\ttrain-rmse:1.94402\n",
      "[33399]\teval-rmse:3.80501\ttrain-rmse:1.94402\n",
      "[33400]\teval-rmse:3.80369\ttrain-rmse:1.94397\n",
      "[33401]\teval-rmse:3.80207\ttrain-rmse:1.94393\n",
      "[33402]\teval-rmse:3.80079\ttrain-rmse:1.94387\n",
      "[33403]\teval-rmse:3.79939\ttrain-rmse:1.94383\n",
      "[33404]\teval-rmse:3.79987\ttrain-rmse:1.94385\n",
      "[33405]\teval-rmse:3.80109\ttrain-rmse:1.9439\n",
      "[33406]\teval-rmse:3.80083\ttrain-rmse:1.9439\n",
      "[33407]\teval-rmse:3.79947\ttrain-rmse:1.94384\n",
      "[33408]\teval-rmse:3.7989\ttrain-rmse:1.94383\n",
      "[33409]\teval-rmse:3.79865\ttrain-rmse:1.94383\n",
      "[33410]\teval-rmse:3.79813\ttrain-rmse:1.94383\n",
      "[33411]\teval-rmse:3.79769\ttrain-rmse:1.94382\n",
      "[33412]\teval-rmse:3.79819\ttrain-rmse:1.94384\n",
      "[33413]\teval-rmse:3.79975\ttrain-rmse:1.94385\n",
      "[33414]\teval-rmse:3.79923\ttrain-rmse:1.94384\n",
      "[33415]\teval-rmse:3.80099\ttrain-rmse:1.94387\n",
      "[33416]\teval-rmse:3.80064\ttrain-rmse:1.94386\n",
      "[33417]\teval-rmse:3.8024\ttrain-rmse:1.9439\n",
      "[33418]\teval-rmse:3.80258\ttrain-rmse:1.9439\n",
      "[33419]\teval-rmse:3.80128\ttrain-rmse:1.94388\n",
      "[33420]\teval-rmse:3.79965\ttrain-rmse:1.94382\n",
      "[33421]\teval-rmse:3.80084\ttrain-rmse:1.94386\n",
      "[33422]\teval-rmse:3.80115\ttrain-rmse:1.94387\n",
      "[33423]\teval-rmse:3.80137\ttrain-rmse:1.94388\n",
      "[33424]\teval-rmse:3.80058\ttrain-rmse:1.94386\n",
      "[33425]\teval-rmse:3.80204\ttrain-rmse:1.94387\n",
      "[33426]\teval-rmse:3.80177\ttrain-rmse:1.94386\n",
      "[33427]\teval-rmse:3.80198\ttrain-rmse:1.94387\n",
      "[33428]\teval-rmse:3.80215\ttrain-rmse:1.94388\n",
      "[33429]\teval-rmse:3.80236\ttrain-rmse:1.94389\n",
      "[33430]\teval-rmse:3.80107\ttrain-rmse:1.94387\n",
      "[33431]\teval-rmse:3.8024\ttrain-rmse:1.94393\n",
      "[33432]\teval-rmse:3.80111\ttrain-rmse:1.9439\n",
      "[33433]\teval-rmse:3.8014\ttrain-rmse:1.9439\n",
      "[33434]\teval-rmse:3.79962\ttrain-rmse:1.94385\n",
      "[33435]\teval-rmse:3.79885\ttrain-rmse:1.94382\n",
      "[33436]\teval-rmse:3.79704\ttrain-rmse:1.94379\n",
      "[33437]\teval-rmse:3.79577\ttrain-rmse:1.94377\n",
      "[33438]\teval-rmse:3.79556\ttrain-rmse:1.94377\n",
      "[33439]\teval-rmse:3.79432\ttrain-rmse:1.94376\n",
      "[33440]\teval-rmse:3.7957\ttrain-rmse:1.94377\n",
      "[33441]\teval-rmse:3.79584\ttrain-rmse:1.94377\n",
      "[33442]\teval-rmse:3.79706\ttrain-rmse:1.94381\n",
      "[33443]\teval-rmse:3.79727\ttrain-rmse:1.94382\n",
      "[33444]\teval-rmse:3.79707\ttrain-rmse:1.94378\n",
      "[33445]\teval-rmse:3.79745\ttrain-rmse:1.9438\n",
      "[33446]\teval-rmse:3.79922\ttrain-rmse:1.94382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33447]\teval-rmse:3.79955\ttrain-rmse:1.94383\n",
      "[33448]\teval-rmse:3.79972\ttrain-rmse:1.94383\n",
      "[33449]\teval-rmse:3.7999\ttrain-rmse:1.94384\n",
      "[33450]\teval-rmse:3.79862\ttrain-rmse:1.94383\n",
      "[33451]\teval-rmse:3.79981\ttrain-rmse:1.94388\n",
      "[33452]\teval-rmse:3.80135\ttrain-rmse:1.94389\n",
      "[33453]\teval-rmse:3.80268\ttrain-rmse:1.94396\n",
      "[33454]\teval-rmse:3.80232\ttrain-rmse:1.94395\n",
      "[33455]\teval-rmse:3.80176\ttrain-rmse:1.94394\n",
      "[33456]\teval-rmse:3.80025\ttrain-rmse:1.94387\n",
      "[33457]\teval-rmse:3.7997\ttrain-rmse:1.94386\n",
      "[33458]\teval-rmse:3.79964\ttrain-rmse:1.94386\n",
      "[33459]\teval-rmse:3.79961\ttrain-rmse:1.94386\n",
      "[33460]\teval-rmse:3.79977\ttrain-rmse:1.94386\n",
      "[33461]\teval-rmse:3.80109\ttrain-rmse:1.9439\n",
      "[33462]\teval-rmse:3.80084\ttrain-rmse:1.94389\n",
      "[33463]\teval-rmse:3.80078\ttrain-rmse:1.94389\n",
      "[33464]\teval-rmse:3.80149\ttrain-rmse:1.9439\n",
      "[33465]\teval-rmse:3.80093\ttrain-rmse:1.94389\n",
      "[33466]\teval-rmse:3.79964\ttrain-rmse:1.94386\n",
      "[33467]\teval-rmse:3.80087\ttrain-rmse:1.94392\n",
      "[33468]\teval-rmse:3.79978\ttrain-rmse:1.9439\n",
      "[33469]\teval-rmse:3.79812\ttrain-rmse:1.94384\n",
      "[33470]\teval-rmse:3.79738\ttrain-rmse:1.94383\n",
      "[33471]\teval-rmse:3.79559\ttrain-rmse:1.94377\n",
      "[33472]\teval-rmse:3.79694\ttrain-rmse:1.94382\n",
      "[33473]\teval-rmse:3.79721\ttrain-rmse:1.94382\n",
      "[33474]\teval-rmse:3.79846\ttrain-rmse:1.94383\n",
      "[33475]\teval-rmse:3.79885\ttrain-rmse:1.94385\n",
      "[33476]\teval-rmse:3.79748\ttrain-rmse:1.94384\n",
      "[33477]\teval-rmse:3.79794\ttrain-rmse:1.94385\n",
      "[33478]\teval-rmse:3.79844\ttrain-rmse:1.94387\n",
      "[33479]\teval-rmse:3.79822\ttrain-rmse:1.94386\n",
      "[33480]\teval-rmse:3.79858\ttrain-rmse:1.94388\n",
      "[33481]\teval-rmse:3.80035\ttrain-rmse:1.9439\n",
      "[33482]\teval-rmse:3.80081\ttrain-rmse:1.94392\n",
      "[33483]\teval-rmse:3.79921\ttrain-rmse:1.94388\n",
      "[33484]\teval-rmse:3.80067\ttrain-rmse:1.94389\n",
      "[33485]\teval-rmse:3.80031\ttrain-rmse:1.94389\n",
      "[33486]\teval-rmse:3.79882\ttrain-rmse:1.94383\n",
      "[33487]\teval-rmse:3.79954\ttrain-rmse:1.94384\n",
      "[33488]\teval-rmse:3.79845\ttrain-rmse:1.94383\n",
      "[33489]\teval-rmse:3.80022\ttrain-rmse:1.94386\n",
      "[33490]\teval-rmse:3.80148\ttrain-rmse:1.94389\n",
      "[33491]\teval-rmse:3.79987\ttrain-rmse:1.94382\n",
      "[33492]\teval-rmse:3.79862\ttrain-rmse:1.94381\n",
      "[33493]\teval-rmse:3.80006\ttrain-rmse:1.94386\n",
      "[33494]\teval-rmse:3.7988\ttrain-rmse:1.94385\n",
      "[33495]\teval-rmse:3.80057\ttrain-rmse:1.94387\n",
      "[33496]\teval-rmse:3.79893\ttrain-rmse:1.94383\n",
      "[33497]\teval-rmse:3.79935\ttrain-rmse:1.94384\n",
      "[33498]\teval-rmse:3.8004\ttrain-rmse:1.94389\n",
      "[33499]\teval-rmse:3.79992\ttrain-rmse:1.94388\n",
      "[33500]\teval-rmse:3.79913\ttrain-rmse:1.94386\n",
      "[33501]\teval-rmse:3.79776\ttrain-rmse:1.94383\n",
      "[33502]\teval-rmse:3.79803\ttrain-rmse:1.94384\n",
      "[33503]\teval-rmse:3.79696\ttrain-rmse:1.94383\n",
      "[33504]\teval-rmse:3.79714\ttrain-rmse:1.94384\n",
      "[33505]\teval-rmse:3.79745\ttrain-rmse:1.94385\n",
      "[33506]\teval-rmse:3.79819\ttrain-rmse:1.94385\n",
      "[33507]\teval-rmse:3.79692\ttrain-rmse:1.94385\n",
      "[33508]\teval-rmse:3.79568\ttrain-rmse:1.94384\n",
      "[33509]\teval-rmse:3.79406\ttrain-rmse:1.94383\n",
      "[33510]\teval-rmse:3.79246\ttrain-rmse:1.94383\n",
      "[33511]\teval-rmse:3.79174\ttrain-rmse:1.94381\n",
      "[33512]\teval-rmse:3.79048\ttrain-rmse:1.94379\n",
      "[33513]\teval-rmse:3.78941\ttrain-rmse:1.94379\n",
      "[33514]\teval-rmse:3.78975\ttrain-rmse:1.94379\n",
      "[33515]\teval-rmse:3.78921\ttrain-rmse:1.94379\n",
      "[33516]\teval-rmse:3.78971\ttrain-rmse:1.94379\n",
      "[33517]\teval-rmse:3.79086\ttrain-rmse:1.94379\n",
      "[33518]\teval-rmse:3.79129\ttrain-rmse:1.94379\n",
      "[33519]\teval-rmse:3.79082\ttrain-rmse:1.94379\n",
      "[33520]\teval-rmse:3.7919\ttrain-rmse:1.9438\n",
      "[33521]\teval-rmse:3.79042\ttrain-rmse:1.94379\n",
      "[33522]\teval-rmse:3.79024\ttrain-rmse:1.94375\n",
      "[33523]\teval-rmse:3.79045\ttrain-rmse:1.94376\n",
      "[33524]\teval-rmse:3.79065\ttrain-rmse:1.94375\n",
      "[33525]\teval-rmse:3.79046\ttrain-rmse:1.94376\n",
      "[33526]\teval-rmse:3.78996\ttrain-rmse:1.94376\n",
      "[33527]\teval-rmse:3.78966\ttrain-rmse:1.94376\n",
      "[33528]\teval-rmse:3.78948\ttrain-rmse:1.94376\n",
      "[33529]\teval-rmse:3.79105\ttrain-rmse:1.94374\n",
      "[33530]\teval-rmse:3.79283\ttrain-rmse:1.94373\n",
      "[33531]\teval-rmse:3.7923\ttrain-rmse:1.94373\n",
      "[33532]\teval-rmse:3.79179\ttrain-rmse:1.94374\n",
      "[33533]\teval-rmse:3.79108\ttrain-rmse:1.94373\n",
      "[33534]\teval-rmse:3.79141\ttrain-rmse:1.94373\n",
      "[33535]\teval-rmse:3.79197\ttrain-rmse:1.94372\n",
      "[33536]\teval-rmse:3.79374\ttrain-rmse:1.94372\n",
      "[33537]\teval-rmse:3.79551\ttrain-rmse:1.94373\n",
      "[33538]\teval-rmse:3.79429\ttrain-rmse:1.94374\n",
      "[33539]\teval-rmse:3.79409\ttrain-rmse:1.94374\n",
      "[33540]\teval-rmse:3.79386\ttrain-rmse:1.94374\n",
      "[33541]\teval-rmse:3.79333\ttrain-rmse:1.94374\n",
      "[33542]\teval-rmse:3.79371\ttrain-rmse:1.94374\n",
      "[33543]\teval-rmse:3.79548\ttrain-rmse:1.94375\n",
      "[33544]\teval-rmse:3.79543\ttrain-rmse:1.94375\n",
      "[33545]\teval-rmse:3.79563\ttrain-rmse:1.94375\n",
      "[33546]\teval-rmse:3.7949\ttrain-rmse:1.94374\n",
      "[33547]\teval-rmse:3.79408\ttrain-rmse:1.94372\n",
      "[33548]\teval-rmse:3.79227\ttrain-rmse:1.94371\n",
      "[33549]\teval-rmse:3.79176\ttrain-rmse:1.94372\n",
      "[33550]\teval-rmse:3.79331\ttrain-rmse:1.94369\n",
      "[33551]\teval-rmse:3.79311\ttrain-rmse:1.94369\n",
      "[33552]\teval-rmse:3.79489\ttrain-rmse:1.9437\n",
      "[33553]\teval-rmse:3.79576\ttrain-rmse:1.94371\n",
      "[33554]\teval-rmse:3.79521\ttrain-rmse:1.94372\n",
      "[33555]\teval-rmse:3.79669\ttrain-rmse:1.94371\n",
      "[33556]\teval-rmse:3.79788\ttrain-rmse:1.94373\n",
      "[33557]\teval-rmse:3.79735\ttrain-rmse:1.94373\n",
      "[33558]\teval-rmse:3.79716\ttrain-rmse:1.9437\n",
      "[33559]\teval-rmse:3.79517\ttrain-rmse:1.94368\n",
      "[33560]\teval-rmse:3.79663\ttrain-rmse:1.94367\n",
      "[33561]\teval-rmse:3.79609\ttrain-rmse:1.94367\n",
      "[33562]\teval-rmse:3.79757\ttrain-rmse:1.94368\n",
      "[33563]\teval-rmse:3.79891\ttrain-rmse:1.94369\n",
      "[33564]\teval-rmse:3.80045\ttrain-rmse:1.94372\n",
      "[33565]\teval-rmse:3.79898\ttrain-rmse:1.9437\n",
      "[33566]\teval-rmse:3.79739\ttrain-rmse:1.94366\n",
      "[33567]\teval-rmse:3.79684\ttrain-rmse:1.94366\n",
      "[33568]\teval-rmse:3.79526\ttrain-rmse:1.94366\n",
      "[33569]\teval-rmse:3.79546\ttrain-rmse:1.94366\n",
      "[33570]\teval-rmse:3.79421\ttrain-rmse:1.94366\n",
      "[33571]\teval-rmse:3.79459\ttrain-rmse:1.94366\n",
      "[33572]\teval-rmse:3.79306\ttrain-rmse:1.94366\n",
      "[33573]\teval-rmse:3.79464\ttrain-rmse:1.94366\n",
      "[33574]\teval-rmse:3.79592\ttrain-rmse:1.94366\n",
      "[33575]\teval-rmse:3.79589\ttrain-rmse:1.94366\n",
      "[33576]\teval-rmse:3.79727\ttrain-rmse:1.94366\n",
      "[33577]\teval-rmse:3.79799\ttrain-rmse:1.94367\n",
      "[33578]\teval-rmse:3.79648\ttrain-rmse:1.94365\n",
      "[33579]\teval-rmse:3.79801\ttrain-rmse:1.94366\n",
      "[33580]\teval-rmse:3.79643\ttrain-rmse:1.94366\n",
      "[33581]\teval-rmse:3.7957\ttrain-rmse:1.94365\n",
      "[33582]\teval-rmse:3.79547\ttrain-rmse:1.94365\n",
      "[33583]\teval-rmse:3.79416\ttrain-rmse:1.94364\n",
      "[33584]\teval-rmse:3.79549\ttrain-rmse:1.94365\n",
      "[33585]\teval-rmse:3.79421\ttrain-rmse:1.94365\n",
      "[33586]\teval-rmse:3.79575\ttrain-rmse:1.94365\n",
      "[33587]\teval-rmse:3.79398\ttrain-rmse:1.94364\n",
      "[33588]\teval-rmse:3.79537\ttrain-rmse:1.94364\n",
      "[33589]\teval-rmse:3.79685\ttrain-rmse:1.94363\n",
      "[33590]\teval-rmse:3.79738\ttrain-rmse:1.94363\n",
      "[33591]\teval-rmse:3.79884\ttrain-rmse:1.94365\n",
      "[33592]\teval-rmse:3.79777\ttrain-rmse:1.94364\n",
      "[33593]\teval-rmse:3.79773\ttrain-rmse:1.94363\n",
      "[33594]\teval-rmse:3.79639\ttrain-rmse:1.94362\n",
      "[33595]\teval-rmse:3.79514\ttrain-rmse:1.94361\n",
      "[33596]\teval-rmse:3.79337\ttrain-rmse:1.94361\n",
      "[33597]\teval-rmse:3.79315\ttrain-rmse:1.94361\n",
      "[33598]\teval-rmse:3.79473\ttrain-rmse:1.9436\n",
      "[33599]\teval-rmse:3.7944\ttrain-rmse:1.9436\n",
      "[33600]\teval-rmse:3.79496\ttrain-rmse:1.9436\n",
      "[33601]\teval-rmse:3.79614\ttrain-rmse:1.94362\n",
      "[33602]\teval-rmse:3.79766\ttrain-rmse:1.94363\n",
      "[33603]\teval-rmse:3.79639\ttrain-rmse:1.94361\n",
      "[33604]\teval-rmse:3.79659\ttrain-rmse:1.94361\n",
      "[33605]\teval-rmse:3.79639\ttrain-rmse:1.94358\n",
      "[33606]\teval-rmse:3.79777\ttrain-rmse:1.94359\n",
      "[33607]\teval-rmse:3.7965\ttrain-rmse:1.94358\n",
      "[33608]\teval-rmse:3.7961\ttrain-rmse:1.94358\n",
      "[33609]\teval-rmse:3.79607\ttrain-rmse:1.94358\n",
      "[33610]\teval-rmse:3.7947\ttrain-rmse:1.94359\n",
      "[33611]\teval-rmse:3.7949\ttrain-rmse:1.94359\n",
      "[33612]\teval-rmse:3.79334\ttrain-rmse:1.94358\n",
      "[33613]\teval-rmse:3.79311\ttrain-rmse:1.94358\n",
      "[33614]\teval-rmse:3.79471\ttrain-rmse:1.94358\n",
      "[33615]\teval-rmse:3.7947\ttrain-rmse:1.94358\n",
      "[33616]\teval-rmse:3.79522\ttrain-rmse:1.94358\n",
      "[33617]\teval-rmse:3.7955\ttrain-rmse:1.94358\n",
      "[33618]\teval-rmse:3.79393\ttrain-rmse:1.94357\n",
      "[33619]\teval-rmse:3.7926\ttrain-rmse:1.94358\n",
      "[33620]\teval-rmse:3.79105\ttrain-rmse:1.94359\n",
      "[33621]\teval-rmse:3.79068\ttrain-rmse:1.94359\n",
      "[33622]\teval-rmse:3.79174\ttrain-rmse:1.94358\n",
      "[33623]\teval-rmse:3.79099\ttrain-rmse:1.94358\n",
      "[33624]\teval-rmse:3.79078\ttrain-rmse:1.94358\n",
      "[33625]\teval-rmse:3.79057\ttrain-rmse:1.94359\n",
      "[33626]\teval-rmse:3.79039\ttrain-rmse:1.94359\n",
      "[33627]\teval-rmse:3.79035\ttrain-rmse:1.94359\n",
      "[33628]\teval-rmse:3.79017\ttrain-rmse:1.94359\n",
      "[33629]\teval-rmse:3.79134\ttrain-rmse:1.94358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33630]\teval-rmse:3.79065\ttrain-rmse:1.94359\n",
      "[33631]\teval-rmse:3.79044\ttrain-rmse:1.94359\n",
      "[33632]\teval-rmse:3.7919\ttrain-rmse:1.94357\n",
      "[33633]\teval-rmse:3.79148\ttrain-rmse:1.94357\n",
      "[33634]\teval-rmse:3.7913\ttrain-rmse:1.94357\n",
      "[33635]\teval-rmse:3.79098\ttrain-rmse:1.94357\n",
      "[33636]\teval-rmse:3.79252\ttrain-rmse:1.94356\n",
      "[33637]\teval-rmse:3.79399\ttrain-rmse:1.94354\n",
      "[33638]\teval-rmse:3.79441\ttrain-rmse:1.94354\n",
      "[33639]\teval-rmse:3.79466\ttrain-rmse:1.94354\n",
      "[33640]\teval-rmse:3.79643\ttrain-rmse:1.94355\n",
      "[33641]\teval-rmse:3.79661\ttrain-rmse:1.94356\n",
      "[33642]\teval-rmse:3.79709\ttrain-rmse:1.94356\n",
      "[33643]\teval-rmse:3.7965\ttrain-rmse:1.94356\n",
      "[33644]\teval-rmse:3.79629\ttrain-rmse:1.94355\n",
      "[33645]\teval-rmse:3.79782\ttrain-rmse:1.94357\n",
      "[33646]\teval-rmse:3.79761\ttrain-rmse:1.94356\n",
      "[33647]\teval-rmse:3.79794\ttrain-rmse:1.94357\n",
      "[33648]\teval-rmse:3.79845\ttrain-rmse:1.94357\n",
      "[33649]\teval-rmse:3.79951\ttrain-rmse:1.94359\n",
      "[33650]\teval-rmse:3.79811\ttrain-rmse:1.94358\n",
      "[33651]\teval-rmse:3.79786\ttrain-rmse:1.94357\n",
      "[33652]\teval-rmse:3.79734\ttrain-rmse:1.94357\n",
      "[33653]\teval-rmse:3.79734\ttrain-rmse:1.94357\n",
      "[33654]\teval-rmse:3.79753\ttrain-rmse:1.94357\n",
      "[33655]\teval-rmse:3.79729\ttrain-rmse:1.94357\n",
      "[33656]\teval-rmse:3.79623\ttrain-rmse:1.94356\n",
      "[33657]\teval-rmse:3.79497\ttrain-rmse:1.94355\n",
      "[33658]\teval-rmse:3.79368\ttrain-rmse:1.94355\n",
      "[33659]\teval-rmse:3.79409\ttrain-rmse:1.94356\n",
      "[33660]\teval-rmse:3.79389\ttrain-rmse:1.94353\n",
      "[33661]\teval-rmse:3.79318\ttrain-rmse:1.94353\n",
      "[33662]\teval-rmse:3.79197\ttrain-rmse:1.94355\n",
      "[33663]\teval-rmse:3.79176\ttrain-rmse:1.94355\n",
      "[33664]\teval-rmse:3.79305\ttrain-rmse:1.94356\n",
      "[33665]\teval-rmse:3.79175\ttrain-rmse:1.94355\n",
      "[33666]\teval-rmse:3.79016\ttrain-rmse:1.94355\n",
      "[33667]\teval-rmse:3.79164\ttrain-rmse:1.94353\n",
      "[33668]\teval-rmse:3.79207\ttrain-rmse:1.94352\n",
      "[33669]\teval-rmse:3.79165\ttrain-rmse:1.94352\n",
      "[33670]\teval-rmse:3.79134\ttrain-rmse:1.94352\n",
      "[33671]\teval-rmse:3.79239\ttrain-rmse:1.94353\n",
      "[33672]\teval-rmse:3.79396\ttrain-rmse:1.94353\n",
      "[33673]\teval-rmse:3.7926\ttrain-rmse:1.94355\n",
      "[33674]\teval-rmse:3.79228\ttrain-rmse:1.94355\n",
      "[33675]\teval-rmse:3.79077\ttrain-rmse:1.94356\n",
      "[33676]\teval-rmse:3.79101\ttrain-rmse:1.94355\n",
      "[33677]\teval-rmse:3.78959\ttrain-rmse:1.94357\n",
      "[33678]\teval-rmse:3.78959\ttrain-rmse:1.94357\n",
      "[33679]\teval-rmse:3.78826\ttrain-rmse:1.9436\n",
      "[33680]\teval-rmse:3.79004\ttrain-rmse:1.94359\n",
      "[33681]\teval-rmse:3.78962\ttrain-rmse:1.94359\n",
      "[33682]\teval-rmse:3.79106\ttrain-rmse:1.94359\n",
      "[33683]\teval-rmse:3.78982\ttrain-rmse:1.94361\n",
      "[33684]\teval-rmse:3.79141\ttrain-rmse:1.94358\n",
      "[33685]\teval-rmse:3.79268\ttrain-rmse:1.94358\n",
      "[33686]\teval-rmse:3.79124\ttrain-rmse:1.94357\n",
      "[33687]\teval-rmse:3.79022\ttrain-rmse:1.94358\n",
      "[33688]\teval-rmse:3.7916\ttrain-rmse:1.94356\n",
      "[33689]\teval-rmse:3.79219\ttrain-rmse:1.94356\n",
      "[33690]\teval-rmse:3.79068\ttrain-rmse:1.94358\n",
      "[33691]\teval-rmse:3.78966\ttrain-rmse:1.94358\n",
      "[33692]\teval-rmse:3.78948\ttrain-rmse:1.94358\n",
      "[33693]\teval-rmse:3.7893\ttrain-rmse:1.94355\n",
      "[33694]\teval-rmse:3.78878\ttrain-rmse:1.94356\n",
      "[33695]\teval-rmse:3.78726\ttrain-rmse:1.9436\n",
      "[33696]\teval-rmse:3.78648\ttrain-rmse:1.94361\n",
      "[33697]\teval-rmse:3.78634\ttrain-rmse:1.94358\n",
      "[33698]\teval-rmse:3.78683\ttrain-rmse:1.94357\n",
      "[33699]\teval-rmse:3.78821\ttrain-rmse:1.94354\n",
      "[33700]\teval-rmse:3.78849\ttrain-rmse:1.94354\n",
      "[33701]\teval-rmse:3.79026\ttrain-rmse:1.94353\n",
      "[33702]\teval-rmse:3.78829\ttrain-rmse:1.94354\n",
      "[33703]\teval-rmse:3.78792\ttrain-rmse:1.94355\n",
      "[33704]\teval-rmse:3.78931\ttrain-rmse:1.94352\n",
      "[33705]\teval-rmse:3.79003\ttrain-rmse:1.94351\n",
      "[33706]\teval-rmse:3.79055\ttrain-rmse:1.94351\n",
      "[33707]\teval-rmse:3.78914\ttrain-rmse:1.94352\n",
      "[33708]\teval-rmse:3.79074\ttrain-rmse:1.9435\n",
      "[33709]\teval-rmse:3.79056\ttrain-rmse:1.9435\n",
      "[33710]\teval-rmse:3.79058\ttrain-rmse:1.9435\n",
      "[33711]\teval-rmse:3.78936\ttrain-rmse:1.94352\n",
      "[33712]\teval-rmse:3.79052\ttrain-rmse:1.94351\n",
      "[33713]\teval-rmse:3.78905\ttrain-rmse:1.94351\n",
      "[33714]\teval-rmse:3.7906\ttrain-rmse:1.94349\n",
      "[33715]\teval-rmse:3.78937\ttrain-rmse:1.94349\n",
      "[33716]\teval-rmse:3.78959\ttrain-rmse:1.94349\n",
      "[33717]\teval-rmse:3.79006\ttrain-rmse:1.94349\n",
      "[33718]\teval-rmse:3.78852\ttrain-rmse:1.9435\n",
      "[33719]\teval-rmse:3.7868\ttrain-rmse:1.94352\n",
      "[33720]\teval-rmse:3.78632\ttrain-rmse:1.94354\n",
      "[33721]\teval-rmse:3.78604\ttrain-rmse:1.94354\n",
      "[33722]\teval-rmse:3.78762\ttrain-rmse:1.94349\n",
      "[33723]\teval-rmse:3.78786\ttrain-rmse:1.94349\n",
      "[33724]\teval-rmse:3.78767\ttrain-rmse:1.94349\n",
      "[33725]\teval-rmse:3.78715\ttrain-rmse:1.94351\n",
      "[33726]\teval-rmse:3.7867\ttrain-rmse:1.94352\n",
      "[33727]\teval-rmse:3.78746\ttrain-rmse:1.9435\n",
      "[33728]\teval-rmse:3.78801\ttrain-rmse:1.94348\n",
      "[33729]\teval-rmse:3.78956\ttrain-rmse:1.94346\n",
      "[33730]\teval-rmse:3.78926\ttrain-rmse:1.94346\n",
      "[33731]\teval-rmse:3.78998\ttrain-rmse:1.94345\n",
      "[33732]\teval-rmse:3.79136\ttrain-rmse:1.94343\n",
      "[33733]\teval-rmse:3.79273\ttrain-rmse:1.94343\n",
      "[33734]\teval-rmse:3.79305\ttrain-rmse:1.94342\n",
      "[33735]\teval-rmse:3.79171\ttrain-rmse:1.94344\n",
      "[33736]\teval-rmse:3.79213\ttrain-rmse:1.94344\n",
      "[33737]\teval-rmse:3.79109\ttrain-rmse:1.94344\n",
      "[33738]\teval-rmse:3.79108\ttrain-rmse:1.94344\n",
      "[33739]\teval-rmse:3.7916\ttrain-rmse:1.94344\n",
      "[33740]\teval-rmse:3.79308\ttrain-rmse:1.94344\n",
      "[33741]\teval-rmse:3.79277\ttrain-rmse:1.94344\n",
      "[33742]\teval-rmse:3.79305\ttrain-rmse:1.94344\n",
      "[33743]\teval-rmse:3.79324\ttrain-rmse:1.94344\n",
      "[33744]\teval-rmse:3.79163\ttrain-rmse:1.94344\n",
      "[33745]\teval-rmse:3.7934\ttrain-rmse:1.94344\n",
      "[33746]\teval-rmse:3.79292\ttrain-rmse:1.94344\n",
      "[33747]\teval-rmse:3.79469\ttrain-rmse:1.94345\n",
      "[33748]\teval-rmse:3.79449\ttrain-rmse:1.94345\n",
      "[33749]\teval-rmse:3.79625\ttrain-rmse:1.94346\n",
      "[33750]\teval-rmse:3.79552\ttrain-rmse:1.94345\n",
      "[33751]\teval-rmse:3.79713\ttrain-rmse:1.94345\n",
      "[33752]\teval-rmse:3.79558\ttrain-rmse:1.94345\n",
      "[33753]\teval-rmse:3.79509\ttrain-rmse:1.94345\n",
      "[33754]\teval-rmse:3.79352\ttrain-rmse:1.94345\n",
      "[33755]\teval-rmse:3.79301\ttrain-rmse:1.94345\n",
      "[33756]\teval-rmse:3.79109\ttrain-rmse:1.94347\n",
      "[33757]\teval-rmse:3.79078\ttrain-rmse:1.94347\n",
      "[33758]\teval-rmse:3.79132\ttrain-rmse:1.94346\n",
      "[33759]\teval-rmse:3.79186\ttrain-rmse:1.94345\n",
      "[33760]\teval-rmse:3.79342\ttrain-rmse:1.94345\n",
      "[33761]\teval-rmse:3.79187\ttrain-rmse:1.94345\n",
      "[33762]\teval-rmse:3.79345\ttrain-rmse:1.94345\n",
      "[33763]\teval-rmse:3.7919\ttrain-rmse:1.94347\n",
      "[33764]\teval-rmse:3.79045\ttrain-rmse:1.94348\n",
      "[33765]\teval-rmse:3.78942\ttrain-rmse:1.94348\n",
      "[33766]\teval-rmse:3.79119\ttrain-rmse:1.94348\n",
      "[33767]\teval-rmse:3.79049\ttrain-rmse:1.94348\n",
      "[33768]\teval-rmse:3.78996\ttrain-rmse:1.94349\n",
      "[33769]\teval-rmse:3.78947\ttrain-rmse:1.9435\n",
      "[33770]\teval-rmse:3.78771\ttrain-rmse:1.94354\n",
      "[33771]\teval-rmse:3.78754\ttrain-rmse:1.94354\n",
      "[33772]\teval-rmse:3.78882\ttrain-rmse:1.94351\n",
      "[33773]\teval-rmse:3.78959\ttrain-rmse:1.9435\n",
      "[33774]\teval-rmse:3.78782\ttrain-rmse:1.94354\n",
      "[33775]\teval-rmse:3.78804\ttrain-rmse:1.94353\n",
      "[33776]\teval-rmse:3.78829\ttrain-rmse:1.94352\n",
      "[33777]\teval-rmse:3.78978\ttrain-rmse:1.94349\n",
      "[33778]\teval-rmse:3.7891\ttrain-rmse:1.9435\n",
      "[33779]\teval-rmse:3.79017\ttrain-rmse:1.94348\n",
      "[33780]\teval-rmse:3.7889\ttrain-rmse:1.94351\n",
      "[33781]\teval-rmse:3.78941\ttrain-rmse:1.9435\n",
      "[33782]\teval-rmse:3.79096\ttrain-rmse:1.94347\n",
      "[33783]\teval-rmse:3.78922\ttrain-rmse:1.9435\n",
      "[33784]\teval-rmse:3.78798\ttrain-rmse:1.94353\n",
      "[33785]\teval-rmse:3.78753\ttrain-rmse:1.94354\n",
      "[33786]\teval-rmse:3.78733\ttrain-rmse:1.94354\n",
      "[33787]\teval-rmse:3.78691\ttrain-rmse:1.94355\n",
      "[33788]\teval-rmse:3.7859\ttrain-rmse:1.94357\n",
      "[33789]\teval-rmse:3.78749\ttrain-rmse:1.94352\n",
      "[33790]\teval-rmse:3.78699\ttrain-rmse:1.94353\n",
      "[33791]\teval-rmse:3.7875\ttrain-rmse:1.94352\n",
      "[33792]\teval-rmse:3.78855\ttrain-rmse:1.94349\n",
      "[33793]\teval-rmse:3.78927\ttrain-rmse:1.94348\n",
      "[33794]\teval-rmse:3.79104\ttrain-rmse:1.94347\n",
      "[33795]\teval-rmse:3.79234\ttrain-rmse:1.94345\n",
      "[33796]\teval-rmse:3.79088\ttrain-rmse:1.94347\n",
      "[33797]\teval-rmse:3.79164\ttrain-rmse:1.94346\n",
      "[33798]\teval-rmse:3.79341\ttrain-rmse:1.94346\n",
      "[33799]\teval-rmse:3.79497\ttrain-rmse:1.94345\n",
      "[33800]\teval-rmse:3.7935\ttrain-rmse:1.94346\n",
      "[33801]\teval-rmse:3.79222\ttrain-rmse:1.94348\n",
      "[33802]\teval-rmse:3.79224\ttrain-rmse:1.94348\n",
      "[33803]\teval-rmse:3.79401\ttrain-rmse:1.94346\n",
      "[33804]\teval-rmse:3.79276\ttrain-rmse:1.94347\n",
      "[33805]\teval-rmse:3.79326\ttrain-rmse:1.94347\n",
      "[33806]\teval-rmse:3.79327\ttrain-rmse:1.94347\n",
      "[33807]\teval-rmse:3.79454\ttrain-rmse:1.94346\n",
      "[33808]\teval-rmse:3.79329\ttrain-rmse:1.94347\n",
      "[33809]\teval-rmse:3.79185\ttrain-rmse:1.94348\n",
      "[33810]\teval-rmse:3.79164\ttrain-rmse:1.94348\n",
      "[33811]\teval-rmse:3.79271\ttrain-rmse:1.94347\n",
      "[33812]\teval-rmse:3.79221\ttrain-rmse:1.94348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33813]\teval-rmse:3.7915\ttrain-rmse:1.94349\n",
      "[33814]\teval-rmse:3.79119\ttrain-rmse:1.94349\n",
      "[33815]\teval-rmse:3.78988\ttrain-rmse:1.94351\n",
      "[33816]\teval-rmse:3.79024\ttrain-rmse:1.9435\n",
      "[33817]\teval-rmse:3.78952\ttrain-rmse:1.94352\n",
      "[33818]\teval-rmse:3.78827\ttrain-rmse:1.94355\n",
      "[33819]\teval-rmse:3.78791\ttrain-rmse:1.94356\n",
      "[33820]\teval-rmse:3.7895\ttrain-rmse:1.94353\n",
      "[33821]\teval-rmse:3.78831\ttrain-rmse:1.94355\n",
      "[33822]\teval-rmse:3.78966\ttrain-rmse:1.94352\n",
      "[33823]\teval-rmse:3.78988\ttrain-rmse:1.94352\n",
      "[33824]\teval-rmse:3.78842\ttrain-rmse:1.94355\n",
      "[33825]\teval-rmse:3.78917\ttrain-rmse:1.94354\n",
      "[33826]\teval-rmse:3.7899\ttrain-rmse:1.94352\n",
      "[33827]\teval-rmse:3.79126\ttrain-rmse:1.9435\n",
      "[33828]\teval-rmse:3.79231\ttrain-rmse:1.94348\n",
      "[33829]\teval-rmse:3.79212\ttrain-rmse:1.94348\n",
      "[33830]\teval-rmse:3.79056\ttrain-rmse:1.9435\n",
      "[33831]\teval-rmse:3.79214\ttrain-rmse:1.94348\n",
      "[33832]\teval-rmse:3.79083\ttrain-rmse:1.94349\n",
      "[33833]\teval-rmse:3.78979\ttrain-rmse:1.9435\n",
      "[33834]\teval-rmse:3.79156\ttrain-rmse:1.94349\n",
      "[33835]\teval-rmse:3.79318\ttrain-rmse:1.94347\n",
      "[33836]\teval-rmse:3.79193\ttrain-rmse:1.94348\n",
      "[33837]\teval-rmse:3.79227\ttrain-rmse:1.94348\n",
      "[33838]\teval-rmse:3.79208\ttrain-rmse:1.94344\n",
      "[33839]\teval-rmse:3.79283\ttrain-rmse:1.94344\n",
      "[33840]\teval-rmse:3.79252\ttrain-rmse:1.94344\n",
      "[33841]\teval-rmse:3.79059\ttrain-rmse:1.94345\n",
      "[33842]\teval-rmse:3.7922\ttrain-rmse:1.94343\n",
      "[33843]\teval-rmse:3.79359\ttrain-rmse:1.94342\n",
      "[33844]\teval-rmse:3.79487\ttrain-rmse:1.94342\n",
      "[33845]\teval-rmse:3.7934\ttrain-rmse:1.94343\n",
      "[33846]\teval-rmse:3.79214\ttrain-rmse:1.94344\n",
      "[33847]\teval-rmse:3.7937\ttrain-rmse:1.94343\n",
      "[33848]\teval-rmse:3.7935\ttrain-rmse:1.94343\n",
      "[33849]\teval-rmse:3.79371\ttrain-rmse:1.94343\n",
      "[33850]\teval-rmse:3.79351\ttrain-rmse:1.94343\n",
      "[33851]\teval-rmse:3.79479\ttrain-rmse:1.94343\n",
      "[33852]\teval-rmse:3.79352\ttrain-rmse:1.94343\n",
      "[33853]\teval-rmse:3.79228\ttrain-rmse:1.94344\n",
      "[33854]\teval-rmse:3.79358\ttrain-rmse:1.94343\n",
      "[33855]\teval-rmse:3.79464\ttrain-rmse:1.94343\n",
      "[33856]\teval-rmse:3.79421\ttrain-rmse:1.94343\n",
      "[33857]\teval-rmse:3.79492\ttrain-rmse:1.94343\n",
      "[33858]\teval-rmse:3.79441\ttrain-rmse:1.94343\n",
      "[33859]\teval-rmse:3.79461\ttrain-rmse:1.94343\n",
      "[33860]\teval-rmse:3.7959\ttrain-rmse:1.94343\n",
      "[33861]\teval-rmse:3.79663\ttrain-rmse:1.94344\n",
      "[33862]\teval-rmse:3.79506\ttrain-rmse:1.94344\n",
      "[33863]\teval-rmse:3.79664\ttrain-rmse:1.94343\n",
      "[33864]\teval-rmse:3.79526\ttrain-rmse:1.94342\n",
      "[33865]\teval-rmse:3.79401\ttrain-rmse:1.94343\n",
      "[33866]\teval-rmse:3.79545\ttrain-rmse:1.94344\n",
      "[33867]\teval-rmse:3.79423\ttrain-rmse:1.94343\n",
      "[33868]\teval-rmse:3.79467\ttrain-rmse:1.94343\n",
      "[33869]\teval-rmse:3.79395\ttrain-rmse:1.94343\n",
      "[33870]\teval-rmse:3.79467\ttrain-rmse:1.94342\n",
      "[33871]\teval-rmse:3.79363\ttrain-rmse:1.94342\n",
      "[33872]\teval-rmse:3.79292\ttrain-rmse:1.94343\n",
      "[33873]\teval-rmse:3.79169\ttrain-rmse:1.94344\n",
      "[33874]\teval-rmse:3.79202\ttrain-rmse:1.94344\n",
      "[33875]\teval-rmse:3.79203\ttrain-rmse:1.94344\n",
      "[33876]\teval-rmse:3.7933\ttrain-rmse:1.94342\n",
      "[33877]\teval-rmse:3.79458\ttrain-rmse:1.94342\n",
      "[33878]\teval-rmse:3.79329\ttrain-rmse:1.94342\n",
      "[33879]\teval-rmse:3.79153\ttrain-rmse:1.94344\n",
      "[33880]\teval-rmse:3.79002\ttrain-rmse:1.94346\n",
      "[33881]\teval-rmse:3.79029\ttrain-rmse:1.94345\n",
      "[33882]\teval-rmse:3.7901\ttrain-rmse:1.94345\n",
      "[33883]\teval-rmse:3.78907\ttrain-rmse:1.94346\n",
      "[33884]\teval-rmse:3.78777\ttrain-rmse:1.94349\n",
      "[33885]\teval-rmse:3.7876\ttrain-rmse:1.94349\n",
      "[33886]\teval-rmse:3.78786\ttrain-rmse:1.94348\n",
      "[33887]\teval-rmse:3.78652\ttrain-rmse:1.94351\n",
      "[33888]\teval-rmse:3.78633\ttrain-rmse:1.94352\n",
      "[33889]\teval-rmse:3.78616\ttrain-rmse:1.94348\n",
      "[33890]\teval-rmse:3.78762\ttrain-rmse:1.94344\n",
      "[33891]\teval-rmse:3.7857\ttrain-rmse:1.94351\n",
      "[33892]\teval-rmse:3.7866\ttrain-rmse:1.94348\n",
      "[33893]\teval-rmse:3.78612\ttrain-rmse:1.94349\n",
      "[33894]\teval-rmse:3.7846\ttrain-rmse:1.94355\n",
      "[33895]\teval-rmse:3.78516\ttrain-rmse:1.94353\n",
      "[33896]\teval-rmse:3.78589\ttrain-rmse:1.9435\n",
      "[33897]\teval-rmse:3.78726\ttrain-rmse:1.94346\n",
      "[33898]\teval-rmse:3.78677\ttrain-rmse:1.94347\n",
      "[33899]\teval-rmse:3.7861\ttrain-rmse:1.94349\n",
      "[33900]\teval-rmse:3.78655\ttrain-rmse:1.94347\n",
      "[33901]\teval-rmse:3.7861\ttrain-rmse:1.94348\n",
      "[33902]\teval-rmse:3.7863\ttrain-rmse:1.94348\n",
      "[33903]\teval-rmse:3.78791\ttrain-rmse:1.94344\n",
      "[33904]\teval-rmse:3.78845\ttrain-rmse:1.94342\n",
      "[33905]\teval-rmse:3.78773\ttrain-rmse:1.94344\n",
      "[33906]\teval-rmse:3.78847\ttrain-rmse:1.94342\n",
      "[33907]\teval-rmse:3.7883\ttrain-rmse:1.94342\n",
      "[33908]\teval-rmse:3.78932\ttrain-rmse:1.9434\n",
      "[33909]\teval-rmse:3.78936\ttrain-rmse:1.9434\n",
      "[33910]\teval-rmse:3.7901\ttrain-rmse:1.94339\n",
      "[33911]\teval-rmse:3.78968\ttrain-rmse:1.94339\n",
      "[33912]\teval-rmse:3.79129\ttrain-rmse:1.94337\n",
      "[33913]\teval-rmse:3.7911\ttrain-rmse:1.94337\n",
      "[33914]\teval-rmse:3.79091\ttrain-rmse:1.94337\n",
      "[33915]\teval-rmse:3.79116\ttrain-rmse:1.94336\n",
      "[33916]\teval-rmse:3.79244\ttrain-rmse:1.94335\n",
      "[33917]\teval-rmse:3.79286\ttrain-rmse:1.94335\n",
      "[33918]\teval-rmse:3.79319\ttrain-rmse:1.94335\n",
      "[33919]\teval-rmse:3.79248\ttrain-rmse:1.94335\n",
      "[33920]\teval-rmse:3.79374\ttrain-rmse:1.94335\n",
      "[33921]\teval-rmse:3.79396\ttrain-rmse:1.94335\n",
      "[33922]\teval-rmse:3.79347\ttrain-rmse:1.94336\n",
      "[33923]\teval-rmse:3.79296\ttrain-rmse:1.94336\n",
      "[33924]\teval-rmse:3.79346\ttrain-rmse:1.94336\n",
      "[33925]\teval-rmse:3.79398\ttrain-rmse:1.94336\n",
      "[33926]\teval-rmse:3.79265\ttrain-rmse:1.94337\n",
      "[33927]\teval-rmse:3.79289\ttrain-rmse:1.94336\n",
      "[33928]\teval-rmse:3.79423\ttrain-rmse:1.94337\n",
      "[33929]\teval-rmse:3.79348\ttrain-rmse:1.94337\n",
      "[33930]\teval-rmse:3.79475\ttrain-rmse:1.94337\n",
      "[33931]\teval-rmse:3.79455\ttrain-rmse:1.94337\n",
      "[33932]\teval-rmse:3.79477\ttrain-rmse:1.94337\n",
      "[33933]\teval-rmse:3.79613\ttrain-rmse:1.94338\n",
      "[33934]\teval-rmse:3.79616\ttrain-rmse:1.94338\n",
      "[33935]\teval-rmse:3.79458\ttrain-rmse:1.94337\n",
      "[33936]\teval-rmse:3.79481\ttrain-rmse:1.94337\n",
      "[33937]\teval-rmse:3.79588\ttrain-rmse:1.94338\n",
      "[33938]\teval-rmse:3.79604\ttrain-rmse:1.94338\n",
      "[33939]\teval-rmse:3.79678\ttrain-rmse:1.94338\n",
      "[33940]\teval-rmse:3.79835\ttrain-rmse:1.94341\n",
      "[33941]\teval-rmse:3.79858\ttrain-rmse:1.94341\n",
      "[33942]\teval-rmse:3.79993\ttrain-rmse:1.94345\n",
      "[33943]\teval-rmse:3.80043\ttrain-rmse:1.94346\n",
      "[33944]\teval-rmse:3.79866\ttrain-rmse:1.94344\n",
      "[33945]\teval-rmse:3.79741\ttrain-rmse:1.94341\n",
      "[33946]\teval-rmse:3.79615\ttrain-rmse:1.9434\n",
      "[33947]\teval-rmse:3.79671\ttrain-rmse:1.9434\n",
      "[33948]\teval-rmse:3.79848\ttrain-rmse:1.94342\n",
      "[33949]\teval-rmse:3.79919\ttrain-rmse:1.94344\n",
      "[33950]\teval-rmse:3.79896\ttrain-rmse:1.94343\n",
      "[33951]\teval-rmse:3.79739\ttrain-rmse:1.94342\n",
      "[33952]\teval-rmse:3.79894\ttrain-rmse:1.94345\n",
      "[33953]\teval-rmse:3.8005\ttrain-rmse:1.94346\n",
      "[33954]\teval-rmse:3.80099\ttrain-rmse:1.94348\n",
      "[33955]\teval-rmse:3.80139\ttrain-rmse:1.94349\n",
      "[33956]\teval-rmse:3.80284\ttrain-rmse:1.94353\n",
      "[33957]\teval-rmse:3.80437\ttrain-rmse:1.94357\n",
      "[33958]\teval-rmse:3.80583\ttrain-rmse:1.94361\n",
      "[33959]\teval-rmse:3.80612\ttrain-rmse:1.94362\n",
      "[33960]\teval-rmse:3.80479\ttrain-rmse:1.94359\n",
      "[33961]\teval-rmse:3.80497\ttrain-rmse:1.9436\n",
      "[33962]\teval-rmse:3.80347\ttrain-rmse:1.94354\n",
      "[33963]\teval-rmse:3.80523\ttrain-rmse:1.94361\n",
      "[33964]\teval-rmse:3.80549\ttrain-rmse:1.94361\n",
      "[33965]\teval-rmse:3.80695\ttrain-rmse:1.94365\n",
      "[33966]\teval-rmse:3.80767\ttrain-rmse:1.94368\n",
      "[33967]\teval-rmse:3.80785\ttrain-rmse:1.94369\n",
      "[33968]\teval-rmse:3.8096\ttrain-rmse:1.94378\n",
      "[33969]\teval-rmse:3.81094\ttrain-rmse:1.94385\n",
      "[33970]\teval-rmse:3.81042\ttrain-rmse:1.94382\n",
      "[33971]\teval-rmse:3.81015\ttrain-rmse:1.94381\n",
      "[33972]\teval-rmse:3.80851\ttrain-rmse:1.94372\n",
      "[33973]\teval-rmse:3.80977\ttrain-rmse:1.94379\n",
      "[33974]\teval-rmse:3.811\ttrain-rmse:1.94386\n",
      "[33975]\teval-rmse:3.81146\ttrain-rmse:1.94389\n",
      "[33976]\teval-rmse:3.81248\ttrain-rmse:1.94396\n",
      "[33977]\teval-rmse:3.81132\ttrain-rmse:1.94391\n",
      "[33978]\teval-rmse:3.81074\ttrain-rmse:1.94389\n",
      "[33979]\teval-rmse:3.81232\ttrain-rmse:1.94396\n",
      "[33980]\teval-rmse:3.81242\ttrain-rmse:1.94397\n",
      "[33981]\teval-rmse:3.81366\ttrain-rmse:1.94406\n",
      "[33982]\teval-rmse:3.81365\ttrain-rmse:1.94406\n",
      "[33983]\teval-rmse:3.8123\ttrain-rmse:1.944\n",
      "[33984]\teval-rmse:3.81172\ttrain-rmse:1.94396\n",
      "[33985]\teval-rmse:3.81146\ttrain-rmse:1.94392\n",
      "[33986]\teval-rmse:3.81122\ttrain-rmse:1.94391\n",
      "[33987]\teval-rmse:3.81224\ttrain-rmse:1.94398\n",
      "[33988]\teval-rmse:3.81341\ttrain-rmse:1.94406\n",
      "[33989]\teval-rmse:3.81473\ttrain-rmse:1.94416\n",
      "[33990]\teval-rmse:3.81356\ttrain-rmse:1.94411\n",
      "[33991]\teval-rmse:3.81424\ttrain-rmse:1.94416\n",
      "[33992]\teval-rmse:3.8156\ttrain-rmse:1.94426\n",
      "[33993]\teval-rmse:3.81604\ttrain-rmse:1.94429\n",
      "[33994]\teval-rmse:3.81669\ttrain-rmse:1.94433\n",
      "[33995]\teval-rmse:3.8153\ttrain-rmse:1.94422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33996]\teval-rmse:3.81629\ttrain-rmse:1.94431\n",
      "[33997]\teval-rmse:3.8166\ttrain-rmse:1.94433\n",
      "[33998]\teval-rmse:3.81817\ttrain-rmse:1.94441\n",
      "[33999]\teval-rmse:3.81884\ttrain-rmse:1.94447\n",
      "[34000]\teval-rmse:3.8171\ttrain-rmse:1.94431\n",
      "[34001]\teval-rmse:3.81625\ttrain-rmse:1.94426\n",
      "[34002]\teval-rmse:3.81745\ttrain-rmse:1.94437\n",
      "[34003]\teval-rmse:3.81919\ttrain-rmse:1.94446\n",
      "[34004]\teval-rmse:3.81888\ttrain-rmse:1.94442\n",
      "[34005]\teval-rmse:3.81844\ttrain-rmse:1.94439\n",
      "[34006]\teval-rmse:3.81691\ttrain-rmse:1.94427\n",
      "[34007]\teval-rmse:3.81637\ttrain-rmse:1.94423\n",
      "[34008]\teval-rmse:3.8176\ttrain-rmse:1.94433\n",
      "[34009]\teval-rmse:3.81599\ttrain-rmse:1.94421\n",
      "[34010]\teval-rmse:3.81744\ttrain-rmse:1.94428\n",
      "[34011]\teval-rmse:3.81713\ttrain-rmse:1.94424\n",
      "[34012]\teval-rmse:3.81814\ttrain-rmse:1.94433\n",
      "[34013]\teval-rmse:3.81664\ttrain-rmse:1.94425\n",
      "[34014]\teval-rmse:3.81521\ttrain-rmse:1.94416\n",
      "[34015]\teval-rmse:3.81676\ttrain-rmse:1.94423\n",
      "[34016]\teval-rmse:3.81724\ttrain-rmse:1.94428\n",
      "[34017]\teval-rmse:3.81555\ttrain-rmse:1.94412\n",
      "[34018]\teval-rmse:3.81623\ttrain-rmse:1.94416\n",
      "[34019]\teval-rmse:3.81462\ttrain-rmse:1.94403\n",
      "[34020]\teval-rmse:3.81379\ttrain-rmse:1.94398\n",
      "[34021]\teval-rmse:3.81262\ttrain-rmse:1.94393\n",
      "[34022]\teval-rmse:3.81192\ttrain-rmse:1.94388\n",
      "[34023]\teval-rmse:3.81243\ttrain-rmse:1.94392\n",
      "[34024]\teval-rmse:3.81074\ttrain-rmse:1.9438\n",
      "[34025]\teval-rmse:3.81248\ttrain-rmse:1.94387\n",
      "[34026]\teval-rmse:3.81249\ttrain-rmse:1.94387\n",
      "[34027]\teval-rmse:3.81382\ttrain-rmse:1.94396\n",
      "[34028]\teval-rmse:3.81418\ttrain-rmse:1.94399\n",
      "[34029]\teval-rmse:3.81432\ttrain-rmse:1.944\n",
      "[34030]\teval-rmse:3.8139\ttrain-rmse:1.94398\n",
      "[34031]\teval-rmse:3.81325\ttrain-rmse:1.94394\n",
      "[34032]\teval-rmse:3.81243\ttrain-rmse:1.94388\n",
      "[34033]\teval-rmse:3.81312\ttrain-rmse:1.94391\n",
      "[34034]\teval-rmse:3.81345\ttrain-rmse:1.94393\n",
      "[34035]\teval-rmse:3.81175\ttrain-rmse:1.94383\n",
      "[34036]\teval-rmse:3.81191\ttrain-rmse:1.94384\n",
      "[34037]\teval-rmse:3.81344\ttrain-rmse:1.94394\n",
      "[34038]\teval-rmse:3.8138\ttrain-rmse:1.94397\n",
      "[34039]\teval-rmse:3.81221\ttrain-rmse:1.94384\n",
      "[34040]\teval-rmse:3.81376\ttrain-rmse:1.94392\n",
      "[34041]\teval-rmse:3.81388\ttrain-rmse:1.94393\n",
      "[34042]\teval-rmse:3.81272\ttrain-rmse:1.94384\n",
      "[34043]\teval-rmse:3.81285\ttrain-rmse:1.94385\n",
      "[34044]\teval-rmse:3.81436\ttrain-rmse:1.94395\n",
      "[34045]\teval-rmse:3.81266\ttrain-rmse:1.94384\n",
      "[34046]\teval-rmse:3.81393\ttrain-rmse:1.94393\n",
      "[34047]\teval-rmse:3.81517\ttrain-rmse:1.94401\n",
      "[34048]\teval-rmse:3.81358\ttrain-rmse:1.9439\n",
      "[34049]\teval-rmse:3.81404\ttrain-rmse:1.94393\n",
      "[34050]\teval-rmse:3.81553\ttrain-rmse:1.94405\n",
      "[34051]\teval-rmse:3.81621\ttrain-rmse:1.94409\n",
      "[34052]\teval-rmse:3.81742\ttrain-rmse:1.94417\n",
      "[34053]\teval-rmse:3.81883\ttrain-rmse:1.94426\n",
      "[34054]\teval-rmse:3.82057\ttrain-rmse:1.94436\n",
      "[34055]\teval-rmse:3.82081\ttrain-rmse:1.94438\n",
      "[34056]\teval-rmse:3.81939\ttrain-rmse:1.94428\n",
      "[34057]\teval-rmse:3.81875\ttrain-rmse:1.94424\n",
      "[34058]\teval-rmse:3.81899\ttrain-rmse:1.94426\n",
      "[34059]\teval-rmse:3.81935\ttrain-rmse:1.94429\n",
      "[34060]\teval-rmse:3.81975\ttrain-rmse:1.94433\n",
      "[34061]\teval-rmse:3.8191\ttrain-rmse:1.94428\n",
      "[34062]\teval-rmse:3.82085\ttrain-rmse:1.94438\n",
      "[34063]\teval-rmse:3.82129\ttrain-rmse:1.94442\n",
      "[34064]\teval-rmse:3.82302\ttrain-rmse:1.94453\n",
      "[34065]\teval-rmse:3.82422\ttrain-rmse:1.94464\n",
      "[34066]\teval-rmse:3.82333\ttrain-rmse:1.94456\n",
      "[34067]\teval-rmse:3.82399\ttrain-rmse:1.9446\n",
      "[34068]\teval-rmse:3.82415\ttrain-rmse:1.94462\n",
      "[34069]\teval-rmse:3.8243\ttrain-rmse:1.94464\n",
      "[34070]\teval-rmse:3.82396\ttrain-rmse:1.94461\n",
      "[34071]\teval-rmse:3.82407\ttrain-rmse:1.94462\n",
      "[34072]\teval-rmse:3.82373\ttrain-rmse:1.9446\n",
      "[34073]\teval-rmse:3.822\ttrain-rmse:1.94443\n",
      "[34074]\teval-rmse:3.82167\ttrain-rmse:1.94439\n",
      "[34075]\teval-rmse:3.82104\ttrain-rmse:1.94433\n",
      "[34076]\teval-rmse:3.82115\ttrain-rmse:1.94434\n",
      "[34077]\teval-rmse:3.81977\ttrain-rmse:1.94424\n",
      "[34078]\teval-rmse:3.81914\ttrain-rmse:1.94419\n",
      "[34079]\teval-rmse:3.82068\ttrain-rmse:1.94428\n",
      "[34080]\teval-rmse:3.82012\ttrain-rmse:1.94423\n",
      "[34081]\teval-rmse:3.82181\ttrain-rmse:1.94437\n",
      "[34082]\teval-rmse:3.82282\ttrain-rmse:1.94447\n",
      "[34083]\teval-rmse:3.82405\ttrain-rmse:1.94459\n",
      "[34084]\teval-rmse:3.82342\ttrain-rmse:1.94455\n",
      "[34085]\teval-rmse:3.82163\ttrain-rmse:1.94439\n",
      "[34086]\teval-rmse:3.82318\ttrain-rmse:1.94454\n",
      "[34087]\teval-rmse:3.82252\ttrain-rmse:1.94449\n",
      "[34088]\teval-rmse:3.82098\ttrain-rmse:1.94436\n",
      "[34089]\teval-rmse:3.82222\ttrain-rmse:1.94446\n",
      "[34090]\teval-rmse:3.82133\ttrain-rmse:1.94438\n",
      "[34091]\teval-rmse:3.82101\ttrain-rmse:1.94433\n",
      "[34092]\teval-rmse:3.82124\ttrain-rmse:1.94435\n",
      "[34093]\teval-rmse:3.82071\ttrain-rmse:1.94431\n",
      "[34094]\teval-rmse:3.82172\ttrain-rmse:1.94441\n",
      "[34095]\teval-rmse:3.82103\ttrain-rmse:1.94435\n",
      "[34096]\teval-rmse:3.82236\ttrain-rmse:1.94448\n",
      "[34097]\teval-rmse:3.82364\ttrain-rmse:1.94462\n",
      "[34098]\teval-rmse:3.82224\ttrain-rmse:1.94453\n",
      "[34099]\teval-rmse:3.82237\ttrain-rmse:1.94454\n",
      "[34100]\teval-rmse:3.822\ttrain-rmse:1.94452\n",
      "[34101]\teval-rmse:3.82352\ttrain-rmse:1.94468\n",
      "[34102]\teval-rmse:3.82177\ttrain-rmse:1.94453\n",
      "[34103]\teval-rmse:3.82176\ttrain-rmse:1.94453\n",
      "[34104]\teval-rmse:3.82147\ttrain-rmse:1.9445\n",
      "[34105]\teval-rmse:3.82268\ttrain-rmse:1.94463\n",
      "[34106]\teval-rmse:3.82129\ttrain-rmse:1.94454\n",
      "[34107]\teval-rmse:3.81935\ttrain-rmse:1.94434\n",
      "[34108]\teval-rmse:3.8197\ttrain-rmse:1.94437\n",
      "[34109]\teval-rmse:3.82026\ttrain-rmse:1.94442\n",
      "[34110]\teval-rmse:3.8185\ttrain-rmse:1.94425\n",
      "[34111]\teval-rmse:3.81934\ttrain-rmse:1.94433\n",
      "[34112]\teval-rmse:3.81998\ttrain-rmse:1.94438\n",
      "[34113]\teval-rmse:3.82172\ttrain-rmse:1.94448\n",
      "[34114]\teval-rmse:3.82051\ttrain-rmse:1.9444\n",
      "[34115]\teval-rmse:3.81913\ttrain-rmse:1.94427\n",
      "[34116]\teval-rmse:3.81926\ttrain-rmse:1.94428\n",
      "[34117]\teval-rmse:3.81835\ttrain-rmse:1.9442\n",
      "[34118]\teval-rmse:3.81785\ttrain-rmse:1.94417\n",
      "[34119]\teval-rmse:3.81917\ttrain-rmse:1.94429\n",
      "[34120]\teval-rmse:3.81968\ttrain-rmse:1.94434\n",
      "[34121]\teval-rmse:3.81937\ttrain-rmse:1.94432\n",
      "[34122]\teval-rmse:3.81946\ttrain-rmse:1.94432\n",
      "[34123]\teval-rmse:3.82096\ttrain-rmse:1.94445\n",
      "[34124]\teval-rmse:3.82245\ttrain-rmse:1.94458\n",
      "[34125]\teval-rmse:3.82398\ttrain-rmse:1.94472\n",
      "[34126]\teval-rmse:3.82422\ttrain-rmse:1.94474\n",
      "[34127]\teval-rmse:3.82246\ttrain-rmse:1.94458\n",
      "[34128]\teval-rmse:3.82074\ttrain-rmse:1.94446\n",
      "[34129]\teval-rmse:3.8203\ttrain-rmse:1.94443\n",
      "[34130]\teval-rmse:3.82203\ttrain-rmse:1.94453\n",
      "[34131]\teval-rmse:3.82149\ttrain-rmse:1.94448\n",
      "[34132]\teval-rmse:3.82247\ttrain-rmse:1.94458\n",
      "[34133]\teval-rmse:3.82403\ttrain-rmse:1.94468\n",
      "[34134]\teval-rmse:3.82249\ttrain-rmse:1.94451\n",
      "[34135]\teval-rmse:3.82401\ttrain-rmse:1.94468\n",
      "[34136]\teval-rmse:3.82315\ttrain-rmse:1.94459\n",
      "[34137]\teval-rmse:3.82446\ttrain-rmse:1.94472\n",
      "[34138]\teval-rmse:3.82468\ttrain-rmse:1.94475\n",
      "[34139]\teval-rmse:3.82402\ttrain-rmse:1.9447\n",
      "[34140]\teval-rmse:3.82523\ttrain-rmse:1.94484\n",
      "[34141]\teval-rmse:3.82466\ttrain-rmse:1.94479\n",
      "[34142]\teval-rmse:3.82419\ttrain-rmse:1.94475\n",
      "[34143]\teval-rmse:3.82541\ttrain-rmse:1.94487\n",
      "[34144]\teval-rmse:3.8267\ttrain-rmse:1.945\n",
      "[34145]\teval-rmse:3.82733\ttrain-rmse:1.94506\n",
      "[34146]\teval-rmse:3.82799\ttrain-rmse:1.94511\n",
      "[34147]\teval-rmse:3.82727\ttrain-rmse:1.94504\n",
      "[34148]\teval-rmse:3.82582\ttrain-rmse:1.94493\n",
      "[34149]\teval-rmse:3.82407\ttrain-rmse:1.94477\n",
      "[34150]\teval-rmse:3.8223\ttrain-rmse:1.9446\n",
      "[34151]\teval-rmse:3.82269\ttrain-rmse:1.94464\n",
      "[34152]\teval-rmse:3.8241\ttrain-rmse:1.94477\n",
      "[34153]\teval-rmse:3.82379\ttrain-rmse:1.94474\n",
      "[34154]\teval-rmse:3.82202\ttrain-rmse:1.94458\n",
      "[34155]\teval-rmse:3.8217\ttrain-rmse:1.94456\n",
      "[34156]\teval-rmse:3.81992\ttrain-rmse:1.94438\n",
      "[34157]\teval-rmse:3.81992\ttrain-rmse:1.94438\n",
      "[34158]\teval-rmse:3.81957\ttrain-rmse:1.94436\n",
      "[34159]\teval-rmse:3.81808\ttrain-rmse:1.94425\n",
      "[34160]\teval-rmse:3.81854\ttrain-rmse:1.94429\n",
      "[34161]\teval-rmse:3.81884\ttrain-rmse:1.94432\n",
      "[34162]\teval-rmse:3.81918\ttrain-rmse:1.94435\n",
      "[34163]\teval-rmse:3.82063\ttrain-rmse:1.94442\n",
      "[34164]\teval-rmse:3.82182\ttrain-rmse:1.94452\n",
      "[34165]\teval-rmse:3.8209\ttrain-rmse:1.94443\n",
      "[34166]\teval-rmse:3.82084\ttrain-rmse:1.94443\n",
      "[34167]\teval-rmse:3.82097\ttrain-rmse:1.94444\n",
      "[34168]\teval-rmse:3.81926\ttrain-rmse:1.9443\n",
      "[34169]\teval-rmse:3.81971\ttrain-rmse:1.94435\n",
      "[34170]\teval-rmse:3.81907\ttrain-rmse:1.94431\n",
      "[34171]\teval-rmse:3.82081\ttrain-rmse:1.94441\n",
      "[34172]\teval-rmse:3.8196\ttrain-rmse:1.94434\n",
      "[34173]\teval-rmse:3.82085\ttrain-rmse:1.94446\n",
      "[34174]\teval-rmse:3.82149\ttrain-rmse:1.94451\n",
      "[34175]\teval-rmse:3.82163\ttrain-rmse:1.94452\n",
      "[34176]\teval-rmse:3.82117\ttrain-rmse:1.94449\n",
      "[34177]\teval-rmse:3.82051\ttrain-rmse:1.94444\n",
      "[34178]\teval-rmse:3.82204\ttrain-rmse:1.94454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34179]\teval-rmse:3.82268\ttrain-rmse:1.9446\n",
      "[34180]\teval-rmse:3.82122\ttrain-rmse:1.94447\n",
      "[34181]\teval-rmse:3.82029\ttrain-rmse:1.94439\n",
      "[34182]\teval-rmse:3.81857\ttrain-rmse:1.94425\n",
      "[34183]\teval-rmse:3.81903\ttrain-rmse:1.9443\n",
      "[34184]\teval-rmse:3.82077\ttrain-rmse:1.9444\n",
      "[34185]\teval-rmse:3.82015\ttrain-rmse:1.94436\n",
      "[34186]\teval-rmse:3.81877\ttrain-rmse:1.94428\n",
      "[34187]\teval-rmse:3.81902\ttrain-rmse:1.9443\n",
      "[34188]\teval-rmse:3.8192\ttrain-rmse:1.94432\n",
      "[34189]\teval-rmse:3.81747\ttrain-rmse:1.94419\n",
      "[34190]\teval-rmse:3.8177\ttrain-rmse:1.94421\n",
      "[34191]\teval-rmse:3.81904\ttrain-rmse:1.94431\n",
      "[34192]\teval-rmse:3.82049\ttrain-rmse:1.94439\n",
      "[34193]\teval-rmse:3.82094\ttrain-rmse:1.94442\n",
      "[34194]\teval-rmse:3.82009\ttrain-rmse:1.94435\n",
      "[34195]\teval-rmse:3.82041\ttrain-rmse:1.94438\n",
      "[34196]\teval-rmse:3.82176\ttrain-rmse:1.94451\n",
      "[34197]\teval-rmse:3.82275\ttrain-rmse:1.94462\n",
      "[34198]\teval-rmse:3.82213\ttrain-rmse:1.94455\n",
      "[34199]\teval-rmse:3.8207\ttrain-rmse:1.94446\n",
      "[34200]\teval-rmse:3.82224\ttrain-rmse:1.94459\n",
      "[34201]\teval-rmse:3.82031\ttrain-rmse:1.9444\n",
      "[34202]\teval-rmse:3.8206\ttrain-rmse:1.94443\n",
      "[34203]\teval-rmse:3.81922\ttrain-rmse:1.94432\n",
      "[34204]\teval-rmse:3.82076\ttrain-rmse:1.94441\n",
      "[34205]\teval-rmse:3.81884\ttrain-rmse:1.94423\n",
      "[34206]\teval-rmse:3.81902\ttrain-rmse:1.94425\n",
      "[34207]\teval-rmse:3.82047\ttrain-rmse:1.94433\n",
      "[34208]\teval-rmse:3.81835\ttrain-rmse:1.94414\n",
      "[34209]\teval-rmse:3.81768\ttrain-rmse:1.94409\n",
      "[34210]\teval-rmse:3.81628\ttrain-rmse:1.944\n",
      "[34211]\teval-rmse:3.81772\ttrain-rmse:1.94408\n",
      "[34212]\teval-rmse:3.81742\ttrain-rmse:1.94406\n",
      "[34213]\teval-rmse:3.8179\ttrain-rmse:1.94409\n",
      "[34214]\teval-rmse:3.81805\ttrain-rmse:1.9441\n",
      "[34215]\teval-rmse:3.81633\ttrain-rmse:1.94398\n",
      "[34216]\teval-rmse:3.81755\ttrain-rmse:1.94405\n",
      "[34217]\teval-rmse:3.81712\ttrain-rmse:1.94403\n",
      "[34218]\teval-rmse:3.81682\ttrain-rmse:1.94399\n",
      "[34219]\teval-rmse:3.81834\ttrain-rmse:1.94408\n",
      "[34220]\teval-rmse:3.81641\ttrain-rmse:1.94391\n",
      "[34221]\teval-rmse:3.81658\ttrain-rmse:1.94393\n",
      "[34222]\teval-rmse:3.81519\ttrain-rmse:1.94384\n",
      "[34223]\teval-rmse:3.81602\ttrain-rmse:1.9439\n",
      "[34224]\teval-rmse:3.81756\ttrain-rmse:1.94399\n",
      "[34225]\teval-rmse:3.81618\ttrain-rmse:1.94387\n",
      "[34226]\teval-rmse:3.81614\ttrain-rmse:1.94387\n",
      "[34227]\teval-rmse:3.8165\ttrain-rmse:1.9439\n",
      "[34228]\teval-rmse:3.81482\ttrain-rmse:1.9438\n",
      "[34229]\teval-rmse:3.81548\ttrain-rmse:1.94385\n",
      "[34230]\teval-rmse:3.81413\ttrain-rmse:1.94378\n",
      "[34231]\teval-rmse:3.81568\ttrain-rmse:1.94387\n",
      "[34232]\teval-rmse:3.81526\ttrain-rmse:1.94385\n",
      "[34233]\teval-rmse:3.81563\ttrain-rmse:1.94387\n",
      "[34234]\teval-rmse:3.81609\ttrain-rmse:1.9439\n",
      "[34235]\teval-rmse:3.81526\ttrain-rmse:1.94384\n",
      "[34236]\teval-rmse:3.81496\ttrain-rmse:1.9438\n",
      "[34237]\teval-rmse:3.81648\ttrain-rmse:1.9439\n",
      "[34238]\teval-rmse:3.81496\ttrain-rmse:1.9438\n",
      "[34239]\teval-rmse:3.81361\ttrain-rmse:1.94372\n",
      "[34240]\teval-rmse:3.81359\ttrain-rmse:1.94372\n",
      "[34241]\teval-rmse:3.81276\ttrain-rmse:1.94366\n",
      "[34242]\teval-rmse:3.81299\ttrain-rmse:1.94367\n",
      "[34243]\teval-rmse:3.81257\ttrain-rmse:1.94365\n",
      "[34244]\teval-rmse:3.81193\ttrain-rmse:1.94361\n",
      "[34245]\teval-rmse:3.81368\ttrain-rmse:1.94369\n",
      "[34246]\teval-rmse:3.81335\ttrain-rmse:1.94367\n",
      "[34247]\teval-rmse:3.81179\ttrain-rmse:1.94357\n",
      "[34248]\teval-rmse:3.8123\ttrain-rmse:1.9436\n",
      "[34249]\teval-rmse:3.81076\ttrain-rmse:1.9435\n",
      "[34250]\teval-rmse:3.81035\ttrain-rmse:1.94349\n",
      "[34251]\teval-rmse:3.80878\ttrain-rmse:1.94341\n",
      "[34252]\teval-rmse:3.80698\ttrain-rmse:1.94333\n",
      "[34253]\teval-rmse:3.80653\ttrain-rmse:1.94332\n",
      "[34254]\teval-rmse:3.80489\ttrain-rmse:1.94325\n",
      "[34255]\teval-rmse:3.80617\ttrain-rmse:1.9433\n",
      "[34256]\teval-rmse:3.80615\ttrain-rmse:1.9433\n",
      "[34257]\teval-rmse:3.80742\ttrain-rmse:1.94335\n",
      "[34258]\teval-rmse:3.80761\ttrain-rmse:1.94335\n",
      "[34259]\teval-rmse:3.80557\ttrain-rmse:1.94328\n",
      "[34260]\teval-rmse:3.80555\ttrain-rmse:1.94328\n",
      "[34261]\teval-rmse:3.80679\ttrain-rmse:1.94332\n",
      "[34262]\teval-rmse:3.80549\ttrain-rmse:1.94328\n",
      "[34263]\teval-rmse:3.80586\ttrain-rmse:1.94329\n",
      "[34264]\teval-rmse:3.80454\ttrain-rmse:1.94326\n",
      "[34265]\teval-rmse:3.80291\ttrain-rmse:1.94322\n",
      "[34266]\teval-rmse:3.8018\ttrain-rmse:1.94319\n",
      "[34267]\teval-rmse:3.80319\ttrain-rmse:1.94322\n",
      "[34268]\teval-rmse:3.80495\ttrain-rmse:1.94327\n",
      "[34269]\teval-rmse:3.8047\ttrain-rmse:1.94326\n",
      "[34270]\teval-rmse:3.80447\ttrain-rmse:1.94322\n",
      "[34271]\teval-rmse:3.80422\ttrain-rmse:1.94318\n",
      "[34272]\teval-rmse:3.8031\ttrain-rmse:1.94315\n",
      "[34273]\teval-rmse:3.80183\ttrain-rmse:1.94312\n",
      "[34274]\teval-rmse:3.80051\ttrain-rmse:1.94309\n",
      "[34275]\teval-rmse:3.80064\ttrain-rmse:1.94309\n",
      "[34276]\teval-rmse:3.80202\ttrain-rmse:1.94311\n",
      "[34277]\teval-rmse:3.80072\ttrain-rmse:1.94309\n",
      "[34278]\teval-rmse:3.80087\ttrain-rmse:1.9431\n",
      "[34279]\teval-rmse:3.80234\ttrain-rmse:1.94312\n",
      "[34280]\teval-rmse:3.80358\ttrain-rmse:1.94315\n",
      "[34281]\teval-rmse:3.80382\ttrain-rmse:1.94316\n",
      "[34282]\teval-rmse:3.80354\ttrain-rmse:1.94315\n",
      "[34283]\teval-rmse:3.8031\ttrain-rmse:1.94314\n",
      "[34284]\teval-rmse:3.80351\ttrain-rmse:1.94315\n",
      "[34285]\teval-rmse:3.80314\ttrain-rmse:1.94314\n",
      "[34286]\teval-rmse:3.80461\ttrain-rmse:1.94319\n",
      "[34287]\teval-rmse:3.80491\ttrain-rmse:1.9432\n",
      "[34288]\teval-rmse:3.80289\ttrain-rmse:1.94315\n",
      "[34289]\teval-rmse:3.80445\ttrain-rmse:1.94318\n",
      "[34290]\teval-rmse:3.80289\ttrain-rmse:1.94315\n",
      "[34291]\teval-rmse:3.80261\ttrain-rmse:1.94314\n",
      "[34292]\teval-rmse:3.80134\ttrain-rmse:1.94312\n",
      "[34293]\teval-rmse:3.80271\ttrain-rmse:1.94315\n",
      "[34294]\teval-rmse:3.80322\ttrain-rmse:1.94317\n",
      "[34295]\teval-rmse:3.8048\ttrain-rmse:1.94322\n",
      "[34296]\teval-rmse:3.80529\ttrain-rmse:1.94323\n",
      "[34297]\teval-rmse:3.80468\ttrain-rmse:1.94321\n",
      "[34298]\teval-rmse:3.80592\ttrain-rmse:1.94325\n",
      "[34299]\teval-rmse:3.80514\ttrain-rmse:1.94322\n",
      "[34300]\teval-rmse:3.80352\ttrain-rmse:1.94317\n",
      "[34301]\teval-rmse:3.80476\ttrain-rmse:1.9432\n",
      "[34302]\teval-rmse:3.80529\ttrain-rmse:1.94322\n",
      "[34303]\teval-rmse:3.80503\ttrain-rmse:1.94321\n",
      "[34304]\teval-rmse:3.80537\ttrain-rmse:1.94322\n",
      "[34305]\teval-rmse:3.80608\ttrain-rmse:1.94325\n",
      "[34306]\teval-rmse:3.80765\ttrain-rmse:1.9433\n",
      "[34307]\teval-rmse:3.80631\ttrain-rmse:1.94325\n",
      "[34308]\teval-rmse:3.80759\ttrain-rmse:1.94331\n",
      "[34309]\teval-rmse:3.80779\ttrain-rmse:1.94332\n",
      "[34310]\teval-rmse:3.80634\ttrain-rmse:1.94325\n",
      "[34311]\teval-rmse:3.80751\ttrain-rmse:1.94329\n",
      "[34312]\teval-rmse:3.80887\ttrain-rmse:1.94336\n",
      "[34313]\teval-rmse:3.80886\ttrain-rmse:1.94336\n",
      "[34314]\teval-rmse:3.80846\ttrain-rmse:1.94334\n",
      "[34315]\teval-rmse:3.80806\ttrain-rmse:1.94333\n",
      "[34316]\teval-rmse:3.80653\ttrain-rmse:1.94325\n",
      "[34317]\teval-rmse:3.80703\ttrain-rmse:1.94328\n",
      "[34318]\teval-rmse:3.80862\ttrain-rmse:1.94333\n",
      "[34319]\teval-rmse:3.80696\ttrain-rmse:1.94325\n",
      "[34320]\teval-rmse:3.80551\ttrain-rmse:1.94321\n",
      "[34321]\teval-rmse:3.80665\ttrain-rmse:1.94325\n",
      "[34322]\teval-rmse:3.8075\ttrain-rmse:1.94329\n",
      "[34323]\teval-rmse:3.80819\ttrain-rmse:1.94332\n",
      "[34324]\teval-rmse:3.80705\ttrain-rmse:1.94328\n",
      "[34325]\teval-rmse:3.80562\ttrain-rmse:1.94323\n",
      "[34326]\teval-rmse:3.806\ttrain-rmse:1.94325\n",
      "[34327]\teval-rmse:3.80775\ttrain-rmse:1.94331\n",
      "[34328]\teval-rmse:3.80902\ttrain-rmse:1.94336\n",
      "[34329]\teval-rmse:3.80872\ttrain-rmse:1.94335\n",
      "[34330]\teval-rmse:3.80687\ttrain-rmse:1.94326\n",
      "[34331]\teval-rmse:3.80745\ttrain-rmse:1.94328\n",
      "[34332]\teval-rmse:3.80746\ttrain-rmse:1.94328\n",
      "[34333]\teval-rmse:3.80873\ttrain-rmse:1.94334\n",
      "[34334]\teval-rmse:3.80759\ttrain-rmse:1.9433\n",
      "[34335]\teval-rmse:3.80575\ttrain-rmse:1.94321\n",
      "[34336]\teval-rmse:3.80496\ttrain-rmse:1.94319\n",
      "[34337]\teval-rmse:3.80543\ttrain-rmse:1.9432\n",
      "[34338]\teval-rmse:3.80584\ttrain-rmse:1.94322\n",
      "[34339]\teval-rmse:3.80712\ttrain-rmse:1.94328\n",
      "[34340]\teval-rmse:3.80548\ttrain-rmse:1.94321\n",
      "[34341]\teval-rmse:3.80487\ttrain-rmse:1.94318\n",
      "[34342]\teval-rmse:3.80559\ttrain-rmse:1.94321\n",
      "[34343]\teval-rmse:3.80662\ttrain-rmse:1.94325\n",
      "[34344]\teval-rmse:3.80529\ttrain-rmse:1.9432\n",
      "[34345]\teval-rmse:3.80563\ttrain-rmse:1.94321\n",
      "[34346]\teval-rmse:3.80602\ttrain-rmse:1.94322\n",
      "[34347]\teval-rmse:3.80649\ttrain-rmse:1.94324\n",
      "[34348]\teval-rmse:3.80504\ttrain-rmse:1.94319\n",
      "[34349]\teval-rmse:3.80679\ttrain-rmse:1.94324\n",
      "[34350]\teval-rmse:3.80537\ttrain-rmse:1.9432\n",
      "[34351]\teval-rmse:3.80557\ttrain-rmse:1.94321\n",
      "[34352]\teval-rmse:3.80531\ttrain-rmse:1.9432\n",
      "[34353]\teval-rmse:3.80532\ttrain-rmse:1.9432\n",
      "[34354]\teval-rmse:3.80507\ttrain-rmse:1.94319\n",
      "[34355]\teval-rmse:3.80547\ttrain-rmse:1.94321\n",
      "[34356]\teval-rmse:3.80586\ttrain-rmse:1.94322\n",
      "[34357]\teval-rmse:3.8063\ttrain-rmse:1.94324\n",
      "[34358]\teval-rmse:3.80679\ttrain-rmse:1.94326\n",
      "[34359]\teval-rmse:3.80631\ttrain-rmse:1.94324\n",
      "[34360]\teval-rmse:3.80767\ttrain-rmse:1.9433\n",
      "[34361]\teval-rmse:3.80835\ttrain-rmse:1.94333\n",
      "[34362]\teval-rmse:3.80774\ttrain-rmse:1.9433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34363]\teval-rmse:3.8082\ttrain-rmse:1.94332\n",
      "[34364]\teval-rmse:3.8079\ttrain-rmse:1.94331\n",
      "[34365]\teval-rmse:3.80731\ttrain-rmse:1.94328\n",
      "[34366]\teval-rmse:3.80589\ttrain-rmse:1.94324\n",
      "[34367]\teval-rmse:3.80605\ttrain-rmse:1.94325\n",
      "[34368]\teval-rmse:3.8058\ttrain-rmse:1.94324\n",
      "[34369]\teval-rmse:3.80447\ttrain-rmse:1.94319\n",
      "[34370]\teval-rmse:3.80284\ttrain-rmse:1.94314\n",
      "[34371]\teval-rmse:3.80155\ttrain-rmse:1.94311\n",
      "[34372]\teval-rmse:3.80308\ttrain-rmse:1.94314\n",
      "[34373]\teval-rmse:3.80264\ttrain-rmse:1.94313\n",
      "[34374]\teval-rmse:3.80292\ttrain-rmse:1.94314\n",
      "[34375]\teval-rmse:3.80408\ttrain-rmse:1.94318\n",
      "[34376]\teval-rmse:3.80274\ttrain-rmse:1.94314\n",
      "[34377]\teval-rmse:3.80091\ttrain-rmse:1.94308\n",
      "[34378]\teval-rmse:3.79953\ttrain-rmse:1.94305\n",
      "[34379]\teval-rmse:3.79844\ttrain-rmse:1.94303\n",
      "[34380]\teval-rmse:3.7995\ttrain-rmse:1.94305\n",
      "[34381]\teval-rmse:3.79928\ttrain-rmse:1.94302\n",
      "[34382]\teval-rmse:3.7979\ttrain-rmse:1.94301\n",
      "[34383]\teval-rmse:3.79863\ttrain-rmse:1.94302\n",
      "[34384]\teval-rmse:3.8001\ttrain-rmse:1.94303\n",
      "[34385]\teval-rmse:3.80166\ttrain-rmse:1.94306\n",
      "[34386]\teval-rmse:3.80182\ttrain-rmse:1.94307\n",
      "[34387]\teval-rmse:3.80145\ttrain-rmse:1.94306\n",
      "[34388]\teval-rmse:3.80118\ttrain-rmse:1.94305\n",
      "[34389]\teval-rmse:3.79989\ttrain-rmse:1.94303\n",
      "[34390]\teval-rmse:3.80035\ttrain-rmse:1.94304\n",
      "[34391]\teval-rmse:3.80159\ttrain-rmse:1.94308\n",
      "[34392]\teval-rmse:3.8003\ttrain-rmse:1.94305\n",
      "[34393]\teval-rmse:3.80077\ttrain-rmse:1.94307\n",
      "[34394]\teval-rmse:3.80034\ttrain-rmse:1.94306\n",
      "[34395]\teval-rmse:3.79895\ttrain-rmse:1.94304\n",
      "[34396]\teval-rmse:3.79841\ttrain-rmse:1.94303\n",
      "[34397]\teval-rmse:3.79819\ttrain-rmse:1.94303\n",
      "[34398]\teval-rmse:3.79962\ttrain-rmse:1.94306\n",
      "[34399]\teval-rmse:3.79828\ttrain-rmse:1.94303\n",
      "[34400]\teval-rmse:3.79828\ttrain-rmse:1.94302\n",
      "[34401]\teval-rmse:3.79754\ttrain-rmse:1.94301\n",
      "[34402]\teval-rmse:3.79733\ttrain-rmse:1.94298\n",
      "[34403]\teval-rmse:3.79867\ttrain-rmse:1.94301\n",
      "[34404]\teval-rmse:3.80023\ttrain-rmse:1.94305\n",
      "[34405]\teval-rmse:3.79996\ttrain-rmse:1.94304\n",
      "[34406]\teval-rmse:3.80043\ttrain-rmse:1.94306\n",
      "[34407]\teval-rmse:3.79914\ttrain-rmse:1.94302\n",
      "[34408]\teval-rmse:3.80048\ttrain-rmse:1.94307\n",
      "[34409]\teval-rmse:3.80013\ttrain-rmse:1.94306\n",
      "[34410]\teval-rmse:3.80149\ttrain-rmse:1.9431\n",
      "[34411]\teval-rmse:3.80126\ttrain-rmse:1.94307\n",
      "[34412]\teval-rmse:3.79986\ttrain-rmse:1.94305\n",
      "[34413]\teval-rmse:3.79861\ttrain-rmse:1.94303\n",
      "[34414]\teval-rmse:3.80037\ttrain-rmse:1.94306\n",
      "[34415]\teval-rmse:3.80141\ttrain-rmse:1.9431\n",
      "[34416]\teval-rmse:3.8019\ttrain-rmse:1.94312\n",
      "[34417]\teval-rmse:3.80239\ttrain-rmse:1.94313\n",
      "[34418]\teval-rmse:3.80191\ttrain-rmse:1.94312\n",
      "[34419]\teval-rmse:3.80311\ttrain-rmse:1.94317\n",
      "[34420]\teval-rmse:3.80363\ttrain-rmse:1.94319\n",
      "[34421]\teval-rmse:3.8034\ttrain-rmse:1.94315\n",
      "[34422]\teval-rmse:3.80412\ttrain-rmse:1.94318\n",
      "[34423]\teval-rmse:3.80364\ttrain-rmse:1.94317\n",
      "[34424]\teval-rmse:3.80307\ttrain-rmse:1.94315\n",
      "[34425]\teval-rmse:3.80263\ttrain-rmse:1.94313\n",
      "[34426]\teval-rmse:3.80239\ttrain-rmse:1.94312\n",
      "[34427]\teval-rmse:3.80391\ttrain-rmse:1.94317\n",
      "[34428]\teval-rmse:3.80324\ttrain-rmse:1.94314\n",
      "[34429]\teval-rmse:3.80483\ttrain-rmse:1.94317\n",
      "[34430]\teval-rmse:3.80477\ttrain-rmse:1.94317\n",
      "[34431]\teval-rmse:3.80599\ttrain-rmse:1.94321\n",
      "[34432]\teval-rmse:3.80716\ttrain-rmse:1.94327\n",
      "[34433]\teval-rmse:3.80559\ttrain-rmse:1.94318\n",
      "[34434]\teval-rmse:3.80663\ttrain-rmse:1.94324\n",
      "[34435]\teval-rmse:3.80501\ttrain-rmse:1.94317\n",
      "[34436]\teval-rmse:3.80502\ttrain-rmse:1.94317\n",
      "[34437]\teval-rmse:3.80369\ttrain-rmse:1.94313\n",
      "[34438]\teval-rmse:3.80501\ttrain-rmse:1.94318\n",
      "[34439]\teval-rmse:3.80627\ttrain-rmse:1.94324\n",
      "[34440]\teval-rmse:3.80485\ttrain-rmse:1.9432\n",
      "[34441]\teval-rmse:3.80345\ttrain-rmse:1.94313\n",
      "[34442]\teval-rmse:3.80212\ttrain-rmse:1.94307\n",
      "[34443]\teval-rmse:3.80058\ttrain-rmse:1.94302\n",
      "[34444]\teval-rmse:3.80035\ttrain-rmse:1.94301\n",
      "[34445]\teval-rmse:3.80012\ttrain-rmse:1.94298\n",
      "[34446]\teval-rmse:3.80034\ttrain-rmse:1.94299\n",
      "[34447]\teval-rmse:3.7987\ttrain-rmse:1.94293\n",
      "[34448]\teval-rmse:3.79733\ttrain-rmse:1.94292\n",
      "[34449]\teval-rmse:3.79745\ttrain-rmse:1.94292\n",
      "[34450]\teval-rmse:3.79828\ttrain-rmse:1.94295\n",
      "[34451]\teval-rmse:3.7985\ttrain-rmse:1.94295\n",
      "[34452]\teval-rmse:3.79953\ttrain-rmse:1.94299\n",
      "[34453]\teval-rmse:3.79989\ttrain-rmse:1.943\n",
      "[34454]\teval-rmse:3.79938\ttrain-rmse:1.94299\n",
      "[34455]\teval-rmse:3.79759\ttrain-rmse:1.94295\n",
      "[34456]\teval-rmse:3.79642\ttrain-rmse:1.94292\n",
      "[34457]\teval-rmse:3.79598\ttrain-rmse:1.94291\n",
      "[34458]\teval-rmse:3.79758\ttrain-rmse:1.94292\n",
      "[34459]\teval-rmse:3.79579\ttrain-rmse:1.94288\n",
      "[34460]\teval-rmse:3.79751\ttrain-rmse:1.94291\n",
      "[34461]\teval-rmse:3.7955\ttrain-rmse:1.94288\n",
      "[34462]\teval-rmse:3.7962\ttrain-rmse:1.94289\n",
      "[34463]\teval-rmse:3.79643\ttrain-rmse:1.94289\n",
      "[34464]\teval-rmse:3.79766\ttrain-rmse:1.94291\n",
      "[34465]\teval-rmse:3.79926\ttrain-rmse:1.94293\n",
      "[34466]\teval-rmse:3.79946\ttrain-rmse:1.94293\n",
      "[34467]\teval-rmse:3.79997\ttrain-rmse:1.94295\n",
      "[34468]\teval-rmse:3.80144\ttrain-rmse:1.94297\n",
      "[34469]\teval-rmse:3.80183\ttrain-rmse:1.94298\n",
      "[34470]\teval-rmse:3.80338\ttrain-rmse:1.94304\n",
      "[34471]\teval-rmse:3.80451\ttrain-rmse:1.94308\n",
      "[34472]\teval-rmse:3.80422\ttrain-rmse:1.94307\n",
      "[34473]\teval-rmse:3.80281\ttrain-rmse:1.94304\n",
      "[34474]\teval-rmse:3.80404\ttrain-rmse:1.94308\n",
      "[34475]\teval-rmse:3.80292\ttrain-rmse:1.94305\n",
      "[34476]\teval-rmse:3.80445\ttrain-rmse:1.94312\n",
      "[34477]\teval-rmse:3.80568\ttrain-rmse:1.94319\n",
      "[34478]\teval-rmse:3.80723\ttrain-rmse:1.94324\n",
      "[34479]\teval-rmse:3.80693\ttrain-rmse:1.94322\n",
      "[34480]\teval-rmse:3.80705\ttrain-rmse:1.94323\n",
      "[34481]\teval-rmse:3.80826\ttrain-rmse:1.9433\n",
      "[34482]\teval-rmse:3.80663\ttrain-rmse:1.9432\n",
      "[34483]\teval-rmse:3.80479\ttrain-rmse:1.9431\n",
      "[34484]\teval-rmse:3.8053\ttrain-rmse:1.94312\n",
      "[34485]\teval-rmse:3.80565\ttrain-rmse:1.94314\n",
      "[34486]\teval-rmse:3.80508\ttrain-rmse:1.94311\n",
      "[34487]\teval-rmse:3.80355\ttrain-rmse:1.94304\n",
      "[34488]\teval-rmse:3.80191\ttrain-rmse:1.94298\n",
      "[34489]\teval-rmse:3.80231\ttrain-rmse:1.94299\n",
      "[34490]\teval-rmse:3.80352\ttrain-rmse:1.94304\n",
      "[34491]\teval-rmse:3.80351\ttrain-rmse:1.94304\n",
      "[34492]\teval-rmse:3.80497\ttrain-rmse:1.94307\n",
      "[34493]\teval-rmse:3.80331\ttrain-rmse:1.94301\n",
      "[34494]\teval-rmse:3.80507\ttrain-rmse:1.94308\n",
      "[34495]\teval-rmse:3.80346\ttrain-rmse:1.94303\n",
      "[34496]\teval-rmse:3.80501\ttrain-rmse:1.94308\n",
      "[34497]\teval-rmse:3.80633\ttrain-rmse:1.94313\n",
      "[34498]\teval-rmse:3.80679\ttrain-rmse:1.94316\n",
      "[34499]\teval-rmse:3.80536\ttrain-rmse:1.94309\n",
      "[34500]\teval-rmse:3.8035\ttrain-rmse:1.94301\n",
      "[34501]\teval-rmse:3.80326\ttrain-rmse:1.943\n",
      "[34502]\teval-rmse:3.80502\ttrain-rmse:1.94305\n",
      "[34503]\teval-rmse:3.80369\ttrain-rmse:1.943\n",
      "[34504]\teval-rmse:3.80227\ttrain-rmse:1.94295\n",
      "[34505]\teval-rmse:3.8025\ttrain-rmse:1.94296\n",
      "[34506]\teval-rmse:3.80384\ttrain-rmse:1.94301\n",
      "[34507]\teval-rmse:3.80399\ttrain-rmse:1.94302\n",
      "[34508]\teval-rmse:3.80362\ttrain-rmse:1.94301\n",
      "[34509]\teval-rmse:3.80507\ttrain-rmse:1.94307\n",
      "[34510]\teval-rmse:3.8047\ttrain-rmse:1.94305\n",
      "[34511]\teval-rmse:3.8051\ttrain-rmse:1.94307\n",
      "[34512]\teval-rmse:3.80537\ttrain-rmse:1.94308\n",
      "[34513]\teval-rmse:3.80606\ttrain-rmse:1.94312\n",
      "[34514]\teval-rmse:3.80781\ttrain-rmse:1.94318\n",
      "[34515]\teval-rmse:3.80782\ttrain-rmse:1.94318\n",
      "[34516]\teval-rmse:3.8078\ttrain-rmse:1.94318\n",
      "[34517]\teval-rmse:3.80753\ttrain-rmse:1.94314\n",
      "[34518]\teval-rmse:3.80908\ttrain-rmse:1.94322\n",
      "[34519]\teval-rmse:3.80882\ttrain-rmse:1.94321\n",
      "[34520]\teval-rmse:3.80929\ttrain-rmse:1.94324\n",
      "[34521]\teval-rmse:3.81048\ttrain-rmse:1.94331\n",
      "[34522]\teval-rmse:3.8084\ttrain-rmse:1.9432\n",
      "[34523]\teval-rmse:3.80676\ttrain-rmse:1.94313\n",
      "[34524]\teval-rmse:3.80835\ttrain-rmse:1.94318\n",
      "[34525]\teval-rmse:3.80867\ttrain-rmse:1.9432\n",
      "[34526]\teval-rmse:3.80808\ttrain-rmse:1.94317\n",
      "[34527]\teval-rmse:3.80622\ttrain-rmse:1.94308\n",
      "[34528]\teval-rmse:3.80596\ttrain-rmse:1.94307\n",
      "[34529]\teval-rmse:3.80539\ttrain-rmse:1.94305\n",
      "[34530]\teval-rmse:3.80714\ttrain-rmse:1.94311\n",
      "[34531]\teval-rmse:3.80675\ttrain-rmse:1.94309\n",
      "[34532]\teval-rmse:3.80733\ttrain-rmse:1.94312\n",
      "[34533]\teval-rmse:3.80885\ttrain-rmse:1.94319\n",
      "[34534]\teval-rmse:3.81018\ttrain-rmse:1.94327\n",
      "[34535]\teval-rmse:3.80852\ttrain-rmse:1.94317\n",
      "[34536]\teval-rmse:3.80853\ttrain-rmse:1.94317\n",
      "[34537]\teval-rmse:3.80878\ttrain-rmse:1.94318\n",
      "[34538]\teval-rmse:3.80799\ttrain-rmse:1.94315\n",
      "[34539]\teval-rmse:3.8072\ttrain-rmse:1.94311\n",
      "[34540]\teval-rmse:3.80822\ttrain-rmse:1.94316\n",
      "[34541]\teval-rmse:3.80775\ttrain-rmse:1.94314\n",
      "[34542]\teval-rmse:3.80814\ttrain-rmse:1.94316\n",
      "[34543]\teval-rmse:3.80753\ttrain-rmse:1.94313\n",
      "[34544]\teval-rmse:3.80786\ttrain-rmse:1.94315\n",
      "[34545]\teval-rmse:3.80759\ttrain-rmse:1.94314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34546]\teval-rmse:3.80734\ttrain-rmse:1.9431\n",
      "[34547]\teval-rmse:3.80857\ttrain-rmse:1.94315\n",
      "[34548]\teval-rmse:3.80709\ttrain-rmse:1.94307\n",
      "[34549]\teval-rmse:3.80663\ttrain-rmse:1.94305\n",
      "[34550]\teval-rmse:3.80701\ttrain-rmse:1.94307\n",
      "[34551]\teval-rmse:3.80639\ttrain-rmse:1.94304\n",
      "[34552]\teval-rmse:3.80486\ttrain-rmse:1.94298\n",
      "[34553]\teval-rmse:3.80629\ttrain-rmse:1.94304\n",
      "[34554]\teval-rmse:3.80647\ttrain-rmse:1.94304\n",
      "[34555]\teval-rmse:3.80679\ttrain-rmse:1.94306\n",
      "[34556]\teval-rmse:3.80546\ttrain-rmse:1.94301\n",
      "[34557]\teval-rmse:3.80575\ttrain-rmse:1.94303\n",
      "[34558]\teval-rmse:3.80598\ttrain-rmse:1.94304\n",
      "[34559]\teval-rmse:3.80446\ttrain-rmse:1.94298\n",
      "[34560]\teval-rmse:3.80369\ttrain-rmse:1.94296\n",
      "[34561]\teval-rmse:3.80241\ttrain-rmse:1.94294\n",
      "[34562]\teval-rmse:3.80185\ttrain-rmse:1.94292\n",
      "[34563]\teval-rmse:3.80054\ttrain-rmse:1.94287\n",
      "[34564]\teval-rmse:3.79914\ttrain-rmse:1.94284\n",
      "[34565]\teval-rmse:3.8006\ttrain-rmse:1.94286\n",
      "[34566]\teval-rmse:3.79931\ttrain-rmse:1.94283\n",
      "[34567]\teval-rmse:3.80051\ttrain-rmse:1.94286\n",
      "[34568]\teval-rmse:3.80015\ttrain-rmse:1.94285\n",
      "[34569]\teval-rmse:3.80152\ttrain-rmse:1.94289\n",
      "[34570]\teval-rmse:3.80327\ttrain-rmse:1.94294\n",
      "[34571]\teval-rmse:3.80162\ttrain-rmse:1.94289\n",
      "[34572]\teval-rmse:3.80139\ttrain-rmse:1.94285\n",
      "[34573]\teval-rmse:3.80228\ttrain-rmse:1.94288\n",
      "[34574]\teval-rmse:3.8015\ttrain-rmse:1.94286\n",
      "[34575]\teval-rmse:3.80011\ttrain-rmse:1.94283\n",
      "[34576]\teval-rmse:3.79881\ttrain-rmse:1.94281\n",
      "[34577]\teval-rmse:3.79951\ttrain-rmse:1.94282\n",
      "[34578]\teval-rmse:3.79792\ttrain-rmse:1.9428\n",
      "[34579]\teval-rmse:3.79767\ttrain-rmse:1.94279\n",
      "[34580]\teval-rmse:3.79627\ttrain-rmse:1.94278\n",
      "[34581]\teval-rmse:3.7952\ttrain-rmse:1.94277\n",
      "[34582]\teval-rmse:3.79392\ttrain-rmse:1.94277\n",
      "[34583]\teval-rmse:3.7944\ttrain-rmse:1.94277\n",
      "[34584]\teval-rmse:3.79491\ttrain-rmse:1.94277\n",
      "[34585]\teval-rmse:3.7953\ttrain-rmse:1.94277\n",
      "[34586]\teval-rmse:3.79585\ttrain-rmse:1.94277\n",
      "[34587]\teval-rmse:3.7944\ttrain-rmse:1.94276\n",
      "[34588]\teval-rmse:3.79438\ttrain-rmse:1.94276\n",
      "[34589]\teval-rmse:3.79333\ttrain-rmse:1.94276\n",
      "[34590]\teval-rmse:3.79454\ttrain-rmse:1.94277\n",
      "[34591]\teval-rmse:3.79348\ttrain-rmse:1.94276\n",
      "[34592]\teval-rmse:3.79476\ttrain-rmse:1.94276\n",
      "[34593]\teval-rmse:3.79436\ttrain-rmse:1.94276\n",
      "[34594]\teval-rmse:3.79485\ttrain-rmse:1.94276\n",
      "[34595]\teval-rmse:3.79518\ttrain-rmse:1.94276\n",
      "[34596]\teval-rmse:3.79465\ttrain-rmse:1.94276\n",
      "[34597]\teval-rmse:3.79327\ttrain-rmse:1.94276\n",
      "[34598]\teval-rmse:3.79452\ttrain-rmse:1.94276\n",
      "[34599]\teval-rmse:3.79576\ttrain-rmse:1.94277\n",
      "[34600]\teval-rmse:3.79418\ttrain-rmse:1.94276\n",
      "[34601]\teval-rmse:3.79394\ttrain-rmse:1.94275\n",
      "[34602]\teval-rmse:3.79242\ttrain-rmse:1.94276\n",
      "[34603]\teval-rmse:3.79263\ttrain-rmse:1.94276\n",
      "[34604]\teval-rmse:3.79087\ttrain-rmse:1.94276\n",
      "[34605]\teval-rmse:3.79212\ttrain-rmse:1.94275\n",
      "[34606]\teval-rmse:3.79371\ttrain-rmse:1.94274\n",
      "[34607]\teval-rmse:3.79515\ttrain-rmse:1.94274\n",
      "[34608]\teval-rmse:3.79387\ttrain-rmse:1.94274\n",
      "[34609]\teval-rmse:3.79494\ttrain-rmse:1.94274\n",
      "[34610]\teval-rmse:3.79474\ttrain-rmse:1.94274\n",
      "[34611]\teval-rmse:3.79455\ttrain-rmse:1.94271\n",
      "[34612]\teval-rmse:3.7935\ttrain-rmse:1.9427\n",
      "[34613]\teval-rmse:3.79376\ttrain-rmse:1.9427\n",
      "[34614]\teval-rmse:3.79322\ttrain-rmse:1.9427\n",
      "[34615]\teval-rmse:3.79373\ttrain-rmse:1.9427\n",
      "[34616]\teval-rmse:3.79229\ttrain-rmse:1.9427\n",
      "[34617]\teval-rmse:3.79406\ttrain-rmse:1.94271\n",
      "[34618]\teval-rmse:3.79249\ttrain-rmse:1.9427\n",
      "[34619]\teval-rmse:3.79226\ttrain-rmse:1.9427\n",
      "[34620]\teval-rmse:3.79266\ttrain-rmse:1.9427\n",
      "[34621]\teval-rmse:3.79214\ttrain-rmse:1.9427\n",
      "[34622]\teval-rmse:3.79138\ttrain-rmse:1.94271\n",
      "[34623]\teval-rmse:3.7926\ttrain-rmse:1.94271\n",
      "[34624]\teval-rmse:3.79081\ttrain-rmse:1.94272\n",
      "[34625]\teval-rmse:3.78978\ttrain-rmse:1.94274\n",
      "[34626]\teval-rmse:3.78997\ttrain-rmse:1.94274\n",
      "[34627]\teval-rmse:3.78967\ttrain-rmse:1.94274\n",
      "[34628]\teval-rmse:3.78864\ttrain-rmse:1.94274\n",
      "[34629]\teval-rmse:3.78884\ttrain-rmse:1.94273\n",
      "[34630]\teval-rmse:3.78815\ttrain-rmse:1.94274\n",
      "[34631]\teval-rmse:3.78664\ttrain-rmse:1.94276\n",
      "[34632]\teval-rmse:3.78715\ttrain-rmse:1.94275\n",
      "[34633]\teval-rmse:3.78566\ttrain-rmse:1.94278\n",
      "[34634]\teval-rmse:3.78537\ttrain-rmse:1.94279\n",
      "[34635]\teval-rmse:3.78562\ttrain-rmse:1.94278\n",
      "[34636]\teval-rmse:3.78422\ttrain-rmse:1.94283\n",
      "[34637]\teval-rmse:3.78551\ttrain-rmse:1.94279\n",
      "[34638]\teval-rmse:3.78674\ttrain-rmse:1.94276\n",
      "[34639]\teval-rmse:3.78633\ttrain-rmse:1.94277\n",
      "[34640]\teval-rmse:3.78667\ttrain-rmse:1.94276\n",
      "[34641]\teval-rmse:3.78687\ttrain-rmse:1.94276\n",
      "[34642]\teval-rmse:3.7884\ttrain-rmse:1.94273\n",
      "[34643]\teval-rmse:3.78979\ttrain-rmse:1.94271\n",
      "[34644]\teval-rmse:3.78829\ttrain-rmse:1.94273\n",
      "[34645]\teval-rmse:3.78854\ttrain-rmse:1.94273\n",
      "[34646]\teval-rmse:3.78911\ttrain-rmse:1.94272\n",
      "[34647]\teval-rmse:3.79028\ttrain-rmse:1.9427\n",
      "[34648]\teval-rmse:3.79186\ttrain-rmse:1.94269\n",
      "[34649]\teval-rmse:3.79007\ttrain-rmse:1.9427\n",
      "[34650]\teval-rmse:3.79046\ttrain-rmse:1.9427\n",
      "[34651]\teval-rmse:3.79108\ttrain-rmse:1.9427\n",
      "[34652]\teval-rmse:3.79182\ttrain-rmse:1.94269\n",
      "[34653]\teval-rmse:3.79182\ttrain-rmse:1.94269\n",
      "[34654]\teval-rmse:3.79058\ttrain-rmse:1.9427\n",
      "[34655]\teval-rmse:3.79215\ttrain-rmse:1.94268\n",
      "[34656]\teval-rmse:3.79192\ttrain-rmse:1.94268\n",
      "[34657]\teval-rmse:3.79346\ttrain-rmse:1.94269\n",
      "[34658]\teval-rmse:3.7919\ttrain-rmse:1.9427\n",
      "[34659]\teval-rmse:3.79142\ttrain-rmse:1.9427\n",
      "[34660]\teval-rmse:3.79123\ttrain-rmse:1.94266\n",
      "[34661]\teval-rmse:3.79139\ttrain-rmse:1.94266\n",
      "[34662]\teval-rmse:3.79292\ttrain-rmse:1.94266\n",
      "[34663]\teval-rmse:3.79158\ttrain-rmse:1.94266\n",
      "[34664]\teval-rmse:3.79286\ttrain-rmse:1.94267\n",
      "[34665]\teval-rmse:3.79308\ttrain-rmse:1.94267\n",
      "[34666]\teval-rmse:3.79433\ttrain-rmse:1.94267\n",
      "[34667]\teval-rmse:3.79551\ttrain-rmse:1.94268\n",
      "[34668]\teval-rmse:3.79666\ttrain-rmse:1.94269\n",
      "[34669]\teval-rmse:3.79699\ttrain-rmse:1.9427\n",
      "[34670]\teval-rmse:3.79625\ttrain-rmse:1.94269\n",
      "[34671]\teval-rmse:3.79668\ttrain-rmse:1.94269\n",
      "[34672]\teval-rmse:3.79725\ttrain-rmse:1.9427\n",
      "[34673]\teval-rmse:3.7969\ttrain-rmse:1.9427\n",
      "[34674]\teval-rmse:3.79646\ttrain-rmse:1.94269\n",
      "[34675]\teval-rmse:3.79752\ttrain-rmse:1.94271\n",
      "[34676]\teval-rmse:3.79874\ttrain-rmse:1.94273\n",
      "[34677]\teval-rmse:3.79887\ttrain-rmse:1.94274\n",
      "[34678]\teval-rmse:3.80019\ttrain-rmse:1.94277\n",
      "[34679]\teval-rmse:3.79961\ttrain-rmse:1.94276\n",
      "[34680]\teval-rmse:3.79796\ttrain-rmse:1.94272\n",
      "[34681]\teval-rmse:3.79899\ttrain-rmse:1.94274\n",
      "[34682]\teval-rmse:3.80033\ttrain-rmse:1.94278\n",
      "[34683]\teval-rmse:3.80168\ttrain-rmse:1.94283\n",
      "[34684]\teval-rmse:3.80182\ttrain-rmse:1.94283\n",
      "[34685]\teval-rmse:3.80197\ttrain-rmse:1.94284\n",
      "[34686]\teval-rmse:3.80068\ttrain-rmse:1.94279\n",
      "[34687]\teval-rmse:3.8014\ttrain-rmse:1.9428\n",
      "[34688]\teval-rmse:3.80014\ttrain-rmse:1.94278\n",
      "[34689]\teval-rmse:3.79957\ttrain-rmse:1.94278\n",
      "[34690]\teval-rmse:3.79833\ttrain-rmse:1.94275\n",
      "[34691]\teval-rmse:3.79868\ttrain-rmse:1.94276\n",
      "[34692]\teval-rmse:3.79886\ttrain-rmse:1.94276\n",
      "[34693]\teval-rmse:3.80041\ttrain-rmse:1.94279\n",
      "[34694]\teval-rmse:3.79916\ttrain-rmse:1.94277\n",
      "[34695]\teval-rmse:3.79783\ttrain-rmse:1.94274\n",
      "[34696]\teval-rmse:3.79676\ttrain-rmse:1.94273\n",
      "[34697]\teval-rmse:3.79818\ttrain-rmse:1.94276\n",
      "[34698]\teval-rmse:3.79961\ttrain-rmse:1.9428\n",
      "[34699]\teval-rmse:3.80106\ttrain-rmse:1.94284\n",
      "[34700]\teval-rmse:3.80241\ttrain-rmse:1.94289\n",
      "[34701]\teval-rmse:3.80081\ttrain-rmse:1.94285\n",
      "[34702]\teval-rmse:3.80038\ttrain-rmse:1.94284\n",
      "[34703]\teval-rmse:3.79995\ttrain-rmse:1.94283\n",
      "[34704]\teval-rmse:3.80129\ttrain-rmse:1.94288\n",
      "[34705]\teval-rmse:3.80233\ttrain-rmse:1.94293\n",
      "[34706]\teval-rmse:3.80212\ttrain-rmse:1.9429\n",
      "[34707]\teval-rmse:3.80188\ttrain-rmse:1.94289\n",
      "[34708]\teval-rmse:3.80207\ttrain-rmse:1.9429\n",
      "[34709]\teval-rmse:3.80142\ttrain-rmse:1.94287\n",
      "[34710]\teval-rmse:3.80266\ttrain-rmse:1.94292\n",
      "[34711]\teval-rmse:3.80282\ttrain-rmse:1.94293\n",
      "[34712]\teval-rmse:3.80132\ttrain-rmse:1.94287\n",
      "[34713]\teval-rmse:3.80001\ttrain-rmse:1.94285\n",
      "[34714]\teval-rmse:3.79953\ttrain-rmse:1.94283\n",
      "[34715]\teval-rmse:3.79931\ttrain-rmse:1.94283\n",
      "[34716]\teval-rmse:3.79822\ttrain-rmse:1.94281\n",
      "[34717]\teval-rmse:3.79684\ttrain-rmse:1.94278\n",
      "[34718]\teval-rmse:3.79705\ttrain-rmse:1.94279\n",
      "[34719]\teval-rmse:3.79826\ttrain-rmse:1.94283\n",
      "[34720]\teval-rmse:3.7972\ttrain-rmse:1.94279\n",
      "[34721]\teval-rmse:3.79752\ttrain-rmse:1.9428\n",
      "[34722]\teval-rmse:3.79874\ttrain-rmse:1.94284\n",
      "[34723]\teval-rmse:3.79852\ttrain-rmse:1.94284\n",
      "[34724]\teval-rmse:3.79797\ttrain-rmse:1.94283\n",
      "[34725]\teval-rmse:3.79669\ttrain-rmse:1.94281\n",
      "[34726]\teval-rmse:3.79647\ttrain-rmse:1.94281\n",
      "[34727]\teval-rmse:3.795\ttrain-rmse:1.94279\n",
      "[34728]\teval-rmse:3.79553\ttrain-rmse:1.94279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34729]\teval-rmse:3.79509\ttrain-rmse:1.94278\n",
      "[34730]\teval-rmse:3.79631\ttrain-rmse:1.94282\n",
      "[34731]\teval-rmse:3.79493\ttrain-rmse:1.94278\n",
      "[34732]\teval-rmse:3.79364\ttrain-rmse:1.94276\n",
      "[34733]\teval-rmse:3.79434\ttrain-rmse:1.94277\n",
      "[34734]\teval-rmse:3.7941\ttrain-rmse:1.94277\n",
      "[34735]\teval-rmse:3.79483\ttrain-rmse:1.94277\n",
      "[34736]\teval-rmse:3.79523\ttrain-rmse:1.94277\n",
      "[34737]\teval-rmse:3.79449\ttrain-rmse:1.94275\n",
      "[34738]\teval-rmse:3.79522\ttrain-rmse:1.94275\n",
      "[34739]\teval-rmse:3.79574\ttrain-rmse:1.94277\n",
      "[34740]\teval-rmse:3.79533\ttrain-rmse:1.94276\n",
      "[34741]\teval-rmse:3.79637\ttrain-rmse:1.94278\n",
      "[34742]\teval-rmse:3.79514\ttrain-rmse:1.94277\n",
      "[34743]\teval-rmse:3.79367\ttrain-rmse:1.94273\n",
      "[34744]\teval-rmse:3.7935\ttrain-rmse:1.9427\n",
      "[34745]\teval-rmse:3.79273\ttrain-rmse:1.94269\n",
      "[34746]\teval-rmse:3.79346\ttrain-rmse:1.94269\n",
      "[34747]\teval-rmse:3.79384\ttrain-rmse:1.9427\n",
      "[34748]\teval-rmse:3.79365\ttrain-rmse:1.9427\n",
      "[34749]\teval-rmse:3.79425\ttrain-rmse:1.94271\n",
      "[34750]\teval-rmse:3.79405\ttrain-rmse:1.9427\n",
      "[34751]\teval-rmse:3.79277\ttrain-rmse:1.94268\n",
      "[34752]\teval-rmse:3.79276\ttrain-rmse:1.94268\n",
      "[34753]\teval-rmse:3.79308\ttrain-rmse:1.94268\n",
      "[34754]\teval-rmse:3.79436\ttrain-rmse:1.94271\n",
      "[34755]\teval-rmse:3.79588\ttrain-rmse:1.94272\n",
      "[34756]\teval-rmse:3.79406\ttrain-rmse:1.94268\n",
      "[34757]\teval-rmse:3.79456\ttrain-rmse:1.94269\n",
      "[34758]\teval-rmse:3.79382\ttrain-rmse:1.94268\n",
      "[34759]\teval-rmse:3.7935\ttrain-rmse:1.94267\n",
      "[34760]\teval-rmse:3.79223\ttrain-rmse:1.94267\n",
      "[34761]\teval-rmse:3.79181\ttrain-rmse:1.94267\n",
      "[34762]\teval-rmse:3.79199\ttrain-rmse:1.94267\n",
      "[34763]\teval-rmse:3.79313\ttrain-rmse:1.94269\n",
      "[34764]\teval-rmse:3.79366\ttrain-rmse:1.9427\n",
      "[34765]\teval-rmse:3.79418\ttrain-rmse:1.94271\n",
      "[34766]\teval-rmse:3.79463\ttrain-rmse:1.94272\n",
      "[34767]\teval-rmse:3.79597\ttrain-rmse:1.94275\n",
      "[34768]\teval-rmse:3.7963\ttrain-rmse:1.94276\n",
      "[34769]\teval-rmse:3.79623\ttrain-rmse:1.94276\n",
      "[34770]\teval-rmse:3.79696\ttrain-rmse:1.94276\n",
      "[34771]\teval-rmse:3.79516\ttrain-rmse:1.94271\n",
      "[34772]\teval-rmse:3.7938\ttrain-rmse:1.94268\n",
      "[34773]\teval-rmse:3.79499\ttrain-rmse:1.94271\n",
      "[34774]\teval-rmse:3.79442\ttrain-rmse:1.9427\n",
      "[34775]\teval-rmse:3.79319\ttrain-rmse:1.9427\n",
      "[34776]\teval-rmse:3.79349\ttrain-rmse:1.9427\n",
      "[34777]\teval-rmse:3.79267\ttrain-rmse:1.94268\n",
      "[34778]\teval-rmse:3.79286\ttrain-rmse:1.94269\n",
      "[34779]\teval-rmse:3.79429\ttrain-rmse:1.94269\n",
      "[34780]\teval-rmse:3.79553\ttrain-rmse:1.94272\n",
      "[34781]\teval-rmse:3.79549\ttrain-rmse:1.94272\n",
      "[34782]\teval-rmse:3.79397\ttrain-rmse:1.94268\n",
      "[34783]\teval-rmse:3.79251\ttrain-rmse:1.94266\n",
      "[34784]\teval-rmse:3.7922\ttrain-rmse:1.94266\n",
      "[34785]\teval-rmse:3.79396\ttrain-rmse:1.94267\n",
      "[34786]\teval-rmse:3.79372\ttrain-rmse:1.94266\n",
      "[34787]\teval-rmse:3.79504\ttrain-rmse:1.94268\n",
      "[34788]\teval-rmse:3.79367\ttrain-rmse:1.94266\n",
      "[34789]\teval-rmse:3.79347\ttrain-rmse:1.94266\n",
      "[34790]\teval-rmse:3.79388\ttrain-rmse:1.94266\n",
      "[34791]\teval-rmse:3.79226\ttrain-rmse:1.94264\n",
      "[34792]\teval-rmse:3.79242\ttrain-rmse:1.94265\n",
      "[34793]\teval-rmse:3.79224\ttrain-rmse:1.94262\n",
      "[34794]\teval-rmse:3.79224\ttrain-rmse:1.94262\n",
      "[34795]\teval-rmse:3.79261\ttrain-rmse:1.94262\n",
      "[34796]\teval-rmse:3.7906\ttrain-rmse:1.94261\n",
      "[34797]\teval-rmse:3.79177\ttrain-rmse:1.94261\n",
      "[34798]\teval-rmse:3.793\ttrain-rmse:1.94263\n",
      "[34799]\teval-rmse:3.79178\ttrain-rmse:1.94263\n",
      "[34800]\teval-rmse:3.79097\ttrain-rmse:1.94262\n",
      "[34801]\teval-rmse:3.79273\ttrain-rmse:1.94263\n",
      "[34802]\teval-rmse:3.79323\ttrain-rmse:1.94263\n",
      "[34803]\teval-rmse:3.79189\ttrain-rmse:1.94264\n",
      "[34804]\teval-rmse:3.79014\ttrain-rmse:1.94263\n",
      "[34805]\teval-rmse:3.78965\ttrain-rmse:1.94263\n",
      "[34806]\teval-rmse:3.78942\ttrain-rmse:1.94263\n",
      "[34807]\teval-rmse:3.789\ttrain-rmse:1.94263\n",
      "[34808]\teval-rmse:3.78725\ttrain-rmse:1.94264\n",
      "[34809]\teval-rmse:3.78872\ttrain-rmse:1.94263\n",
      "[34810]\teval-rmse:3.78834\ttrain-rmse:1.94263\n",
      "[34811]\teval-rmse:3.78814\ttrain-rmse:1.94263\n",
      "[34812]\teval-rmse:3.78763\ttrain-rmse:1.94264\n",
      "[34813]\teval-rmse:3.78622\ttrain-rmse:1.94267\n",
      "[34814]\teval-rmse:3.78778\ttrain-rmse:1.94265\n",
      "[34815]\teval-rmse:3.7882\ttrain-rmse:1.94265\n",
      "[34816]\teval-rmse:3.7898\ttrain-rmse:1.94263\n",
      "[34817]\teval-rmse:3.7893\ttrain-rmse:1.94263\n",
      "[34818]\teval-rmse:3.79074\ttrain-rmse:1.94261\n",
      "[34819]\teval-rmse:3.7895\ttrain-rmse:1.94262\n",
      "[34820]\teval-rmse:3.78933\ttrain-rmse:1.94262\n",
      "[34821]\teval-rmse:3.79058\ttrain-rmse:1.94262\n",
      "[34822]\teval-rmse:3.79075\ttrain-rmse:1.94262\n",
      "[34823]\teval-rmse:3.7923\ttrain-rmse:1.94261\n",
      "[34824]\teval-rmse:3.79363\ttrain-rmse:1.94263\n",
      "[34825]\teval-rmse:3.79321\ttrain-rmse:1.94262\n",
      "[34826]\teval-rmse:3.79272\ttrain-rmse:1.94262\n",
      "[34827]\teval-rmse:3.79113\ttrain-rmse:1.94261\n",
      "[34828]\teval-rmse:3.79257\ttrain-rmse:1.94262\n",
      "[34829]\teval-rmse:3.79297\ttrain-rmse:1.94262\n",
      "[34830]\teval-rmse:3.7932\ttrain-rmse:1.94263\n",
      "[34831]\teval-rmse:3.79194\ttrain-rmse:1.94263\n",
      "[34832]\teval-rmse:3.79153\ttrain-rmse:1.94263\n",
      "[34833]\teval-rmse:3.79196\ttrain-rmse:1.94263\n",
      "[34834]\teval-rmse:3.79351\ttrain-rmse:1.94264\n",
      "[34835]\teval-rmse:3.7942\ttrain-rmse:1.94265\n",
      "[34836]\teval-rmse:3.79401\ttrain-rmse:1.94265\n",
      "[34837]\teval-rmse:3.794\ttrain-rmse:1.94265\n",
      "[34838]\teval-rmse:3.79274\ttrain-rmse:1.94265\n",
      "[34839]\teval-rmse:3.79099\ttrain-rmse:1.94264\n",
      "[34840]\teval-rmse:3.79255\ttrain-rmse:1.94265\n",
      "[34841]\teval-rmse:3.79059\ttrain-rmse:1.94265\n",
      "[34842]\teval-rmse:3.79007\ttrain-rmse:1.94265\n",
      "[34843]\teval-rmse:3.79112\ttrain-rmse:1.94265\n",
      "[34844]\teval-rmse:3.79185\ttrain-rmse:1.94266\n",
      "[34845]\teval-rmse:3.79154\ttrain-rmse:1.94266\n",
      "[34846]\teval-rmse:3.79135\ttrain-rmse:1.94263\n",
      "[34847]\teval-rmse:3.79269\ttrain-rmse:1.94265\n",
      "[34848]\teval-rmse:3.79148\ttrain-rmse:1.94263\n",
      "[34849]\teval-rmse:3.79198\ttrain-rmse:1.94264\n",
      "[34850]\teval-rmse:3.79248\ttrain-rmse:1.94264\n",
      "[34851]\teval-rmse:3.79231\ttrain-rmse:1.94261\n",
      "[34852]\teval-rmse:3.79391\ttrain-rmse:1.94262\n",
      "[34853]\teval-rmse:3.79334\ttrain-rmse:1.94262\n",
      "[34854]\teval-rmse:3.79189\ttrain-rmse:1.9426\n",
      "[34855]\teval-rmse:3.79166\ttrain-rmse:1.9426\n",
      "[34856]\teval-rmse:3.79118\ttrain-rmse:1.9426\n",
      "[34857]\teval-rmse:3.79113\ttrain-rmse:1.9426\n",
      "[34858]\teval-rmse:3.79185\ttrain-rmse:1.94261\n",
      "[34859]\teval-rmse:3.79129\ttrain-rmse:1.94261\n",
      "[34860]\teval-rmse:3.79161\ttrain-rmse:1.94261\n",
      "[34861]\teval-rmse:3.79296\ttrain-rmse:1.94263\n",
      "[34862]\teval-rmse:3.79398\ttrain-rmse:1.94266\n",
      "[34863]\teval-rmse:3.79514\ttrain-rmse:1.94268\n",
      "[34864]\teval-rmse:3.79552\ttrain-rmse:1.94269\n",
      "[34865]\teval-rmse:3.79657\ttrain-rmse:1.94273\n",
      "[34866]\teval-rmse:3.79655\ttrain-rmse:1.94273\n",
      "[34867]\teval-rmse:3.79477\ttrain-rmse:1.94268\n",
      "[34868]\teval-rmse:3.79623\ttrain-rmse:1.94268\n",
      "[34869]\teval-rmse:3.79754\ttrain-rmse:1.94272\n",
      "[34870]\teval-rmse:3.79732\ttrain-rmse:1.94272\n",
      "[34871]\teval-rmse:3.79786\ttrain-rmse:1.94274\n",
      "[34872]\teval-rmse:3.79638\ttrain-rmse:1.94271\n",
      "[34873]\teval-rmse:3.79531\ttrain-rmse:1.9427\n",
      "[34874]\teval-rmse:3.7958\ttrain-rmse:1.94271\n",
      "[34875]\teval-rmse:3.79616\ttrain-rmse:1.94272\n",
      "[34876]\teval-rmse:3.7948\ttrain-rmse:1.94269\n",
      "[34877]\teval-rmse:3.79612\ttrain-rmse:1.94273\n",
      "[34878]\teval-rmse:3.79608\ttrain-rmse:1.94273\n",
      "[34879]\teval-rmse:3.79525\ttrain-rmse:1.94271\n",
      "[34880]\teval-rmse:3.7966\ttrain-rmse:1.94275\n",
      "[34881]\teval-rmse:3.79498\ttrain-rmse:1.94269\n",
      "[34882]\teval-rmse:3.79518\ttrain-rmse:1.9427\n",
      "[34883]\teval-rmse:3.79672\ttrain-rmse:1.94272\n",
      "[34884]\teval-rmse:3.79494\ttrain-rmse:1.94266\n",
      "[34885]\teval-rmse:3.79648\ttrain-rmse:1.9427\n",
      "[34886]\teval-rmse:3.79541\ttrain-rmse:1.94268\n",
      "[34887]\teval-rmse:3.79482\ttrain-rmse:1.94267\n",
      "[34888]\teval-rmse:3.79463\ttrain-rmse:1.94264\n",
      "[34889]\teval-rmse:3.79618\ttrain-rmse:1.94265\n",
      "[34890]\teval-rmse:3.7977\ttrain-rmse:1.9427\n",
      "[34891]\teval-rmse:3.79903\ttrain-rmse:1.94274\n",
      "[34892]\teval-rmse:3.7978\ttrain-rmse:1.94269\n",
      "[34893]\teval-rmse:3.79672\ttrain-rmse:1.94268\n",
      "[34894]\teval-rmse:3.79671\ttrain-rmse:1.94267\n",
      "[34895]\teval-rmse:3.7962\ttrain-rmse:1.94267\n",
      "[34896]\teval-rmse:3.79459\ttrain-rmse:1.94265\n",
      "[34897]\teval-rmse:3.79635\ttrain-rmse:1.94267\n",
      "[34898]\teval-rmse:3.79811\ttrain-rmse:1.94269\n",
      "[34899]\teval-rmse:3.7967\ttrain-rmse:1.94267\n",
      "[34900]\teval-rmse:3.79531\ttrain-rmse:1.94263\n",
      "[34901]\teval-rmse:3.79553\ttrain-rmse:1.94263\n",
      "[34902]\teval-rmse:3.79512\ttrain-rmse:1.94263\n",
      "[34903]\teval-rmse:3.79635\ttrain-rmse:1.94264\n",
      "[34904]\teval-rmse:3.79527\ttrain-rmse:1.94263\n",
      "[34905]\teval-rmse:3.79379\ttrain-rmse:1.94259\n",
      "[34906]\teval-rmse:3.79329\ttrain-rmse:1.94259\n",
      "[34907]\teval-rmse:3.79488\ttrain-rmse:1.94259\n",
      "[34908]\teval-rmse:3.79606\ttrain-rmse:1.94262\n",
      "[34909]\teval-rmse:3.79424\ttrain-rmse:1.94258\n",
      "[34910]\teval-rmse:3.79527\ttrain-rmse:1.9426\n",
      "[34911]\teval-rmse:3.79364\ttrain-rmse:1.94257\n",
      "[34912]\teval-rmse:3.79235\ttrain-rmse:1.94257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34913]\teval-rmse:3.79203\ttrain-rmse:1.94257\n",
      "[34914]\teval-rmse:3.79229\ttrain-rmse:1.94257\n",
      "[34915]\teval-rmse:3.79284\ttrain-rmse:1.94258\n",
      "[34916]\teval-rmse:3.7923\ttrain-rmse:1.94257\n",
      "[34917]\teval-rmse:3.79159\ttrain-rmse:1.94256\n",
      "[34918]\teval-rmse:3.79032\ttrain-rmse:1.94257\n",
      "[34919]\teval-rmse:3.78928\ttrain-rmse:1.94257\n",
      "[34920]\teval-rmse:3.7897\ttrain-rmse:1.94257\n",
      "[34921]\teval-rmse:3.78931\ttrain-rmse:1.94257\n",
      "[34922]\teval-rmse:3.79074\ttrain-rmse:1.94256\n",
      "[34923]\teval-rmse:3.79074\ttrain-rmse:1.94256\n",
      "[34924]\teval-rmse:3.7893\ttrain-rmse:1.94257\n",
      "[34925]\teval-rmse:3.78779\ttrain-rmse:1.94257\n",
      "[34926]\teval-rmse:3.78925\ttrain-rmse:1.94257\n",
      "[34927]\teval-rmse:3.79026\ttrain-rmse:1.94257\n",
      "[34928]\teval-rmse:3.79071\ttrain-rmse:1.94258\n",
      "[34929]\teval-rmse:3.79071\ttrain-rmse:1.94258\n",
      "[34930]\teval-rmse:3.79207\ttrain-rmse:1.94259\n",
      "[34931]\teval-rmse:3.7906\ttrain-rmse:1.94258\n",
      "[34932]\teval-rmse:3.79235\ttrain-rmse:1.94258\n",
      "[34933]\teval-rmse:3.79214\ttrain-rmse:1.94258\n",
      "[34934]\teval-rmse:3.79238\ttrain-rmse:1.94258\n",
      "[34935]\teval-rmse:3.79185\ttrain-rmse:1.94258\n",
      "[34936]\teval-rmse:3.79361\ttrain-rmse:1.94259\n",
      "[34937]\teval-rmse:3.79507\ttrain-rmse:1.94259\n",
      "[34938]\teval-rmse:3.79384\ttrain-rmse:1.94259\n",
      "[34939]\teval-rmse:3.79255\ttrain-rmse:1.94257\n",
      "[34940]\teval-rmse:3.79255\ttrain-rmse:1.94257\n",
      "[34941]\teval-rmse:3.79309\ttrain-rmse:1.94257\n",
      "[34942]\teval-rmse:3.79277\ttrain-rmse:1.94257\n",
      "[34943]\teval-rmse:3.79151\ttrain-rmse:1.94256\n",
      "[34944]\teval-rmse:3.79099\ttrain-rmse:1.94255\n",
      "[34945]\teval-rmse:3.78947\ttrain-rmse:1.94255\n",
      "[34946]\teval-rmse:3.79104\ttrain-rmse:1.94255\n",
      "[34947]\teval-rmse:3.7916\ttrain-rmse:1.94256\n",
      "[34948]\teval-rmse:3.79287\ttrain-rmse:1.94255\n",
      "[34949]\teval-rmse:3.7941\ttrain-rmse:1.94257\n",
      "[34950]\teval-rmse:3.79483\ttrain-rmse:1.94257\n",
      "[34951]\teval-rmse:3.79525\ttrain-rmse:1.94257\n",
      "[34952]\teval-rmse:3.79419\ttrain-rmse:1.94256\n",
      "[34953]\teval-rmse:3.79399\ttrain-rmse:1.94253\n",
      "[34954]\teval-rmse:3.79545\ttrain-rmse:1.94256\n",
      "[34955]\teval-rmse:3.79699\ttrain-rmse:1.94257\n",
      "[34956]\teval-rmse:3.79674\ttrain-rmse:1.94257\n",
      "[34957]\teval-rmse:3.79525\ttrain-rmse:1.94253\n",
      "[34958]\teval-rmse:3.79492\ttrain-rmse:1.94253\n",
      "[34959]\teval-rmse:3.79629\ttrain-rmse:1.94256\n",
      "[34960]\teval-rmse:3.79779\ttrain-rmse:1.9426\n",
      "[34961]\teval-rmse:3.79648\ttrain-rmse:1.94259\n",
      "[34962]\teval-rmse:3.79771\ttrain-rmse:1.9426\n",
      "[34963]\teval-rmse:3.79892\ttrain-rmse:1.94264\n",
      "[34964]\teval-rmse:3.79925\ttrain-rmse:1.94266\n",
      "[34965]\teval-rmse:3.80038\ttrain-rmse:1.9427\n",
      "[34966]\teval-rmse:3.80213\ttrain-rmse:1.94274\n",
      "[34967]\teval-rmse:3.80168\ttrain-rmse:1.94271\n",
      "[34968]\teval-rmse:3.80324\ttrain-rmse:1.94276\n",
      "[34969]\teval-rmse:3.80278\ttrain-rmse:1.94274\n",
      "[34970]\teval-rmse:3.8022\ttrain-rmse:1.94271\n",
      "[34971]\teval-rmse:3.80363\ttrain-rmse:1.94275\n",
      "[34972]\teval-rmse:3.80251\ttrain-rmse:1.94272\n",
      "[34973]\teval-rmse:3.80393\ttrain-rmse:1.94276\n",
      "[34974]\teval-rmse:3.80425\ttrain-rmse:1.94278\n",
      "[34975]\teval-rmse:3.80491\ttrain-rmse:1.94281\n",
      "[34976]\teval-rmse:3.80362\ttrain-rmse:1.94275\n",
      "[34977]\teval-rmse:3.80199\ttrain-rmse:1.94267\n",
      "[34978]\teval-rmse:3.80374\ttrain-rmse:1.94272\n",
      "[34979]\teval-rmse:3.80525\ttrain-rmse:1.94277\n",
      "[34980]\teval-rmse:3.80383\ttrain-rmse:1.9427\n",
      "[34981]\teval-rmse:3.80416\ttrain-rmse:1.94272\n",
      "[34982]\teval-rmse:3.80536\ttrain-rmse:1.94277\n",
      "[34983]\teval-rmse:3.8057\ttrain-rmse:1.94279\n",
      "[34984]\teval-rmse:3.80609\ttrain-rmse:1.94281\n",
      "[34985]\teval-rmse:3.80497\ttrain-rmse:1.94277\n",
      "[34986]\teval-rmse:3.80641\ttrain-rmse:1.94282\n",
      "[34987]\teval-rmse:3.80686\ttrain-rmse:1.94284\n",
      "[34988]\teval-rmse:3.80502\ttrain-rmse:1.94275\n",
      "[34989]\teval-rmse:3.80658\ttrain-rmse:1.9428\n",
      "[34990]\teval-rmse:3.80792\ttrain-rmse:1.94288\n",
      "[34991]\teval-rmse:3.80876\ttrain-rmse:1.94293\n",
      "[34992]\teval-rmse:3.81001\ttrain-rmse:1.94298\n",
      "[34993]\teval-rmse:3.81124\ttrain-rmse:1.94307\n",
      "[34994]\teval-rmse:3.81169\ttrain-rmse:1.94309\n",
      "[34995]\teval-rmse:3.81141\ttrain-rmse:1.94305\n",
      "[34996]\teval-rmse:3.811\ttrain-rmse:1.94303\n",
      "[34997]\teval-rmse:3.80913\ttrain-rmse:1.94291\n",
      "[34998]\teval-rmse:3.80854\ttrain-rmse:1.94288\n",
      "[34999]\teval-rmse:3.80806\ttrain-rmse:1.94286\n",
      "[35000]\teval-rmse:3.80674\ttrain-rmse:1.94279\n",
      "[35001]\teval-rmse:3.8072\ttrain-rmse:1.94281\n",
      "[35002]\teval-rmse:3.80664\ttrain-rmse:1.94279\n",
      "[35003]\teval-rmse:3.80461\ttrain-rmse:1.9427\n",
      "[35004]\teval-rmse:3.80295\ttrain-rmse:1.94263\n",
      "[35005]\teval-rmse:3.80165\ttrain-rmse:1.94259\n",
      "[35006]\teval-rmse:3.80289\ttrain-rmse:1.94264\n",
      "[35007]\teval-rmse:3.80178\ttrain-rmse:1.94261\n",
      "[35008]\teval-rmse:3.80328\ttrain-rmse:1.94267\n",
      "[35009]\teval-rmse:3.80464\ttrain-rmse:1.94274\n",
      "[35010]\teval-rmse:3.80511\ttrain-rmse:1.94276\n",
      "[35011]\teval-rmse:3.80377\ttrain-rmse:1.9427\n",
      "[35012]\teval-rmse:3.80478\ttrain-rmse:1.94275\n",
      "[35013]\teval-rmse:3.80419\ttrain-rmse:1.94272\n",
      "[35014]\teval-rmse:3.80242\ttrain-rmse:1.94265\n",
      "[35015]\teval-rmse:3.80091\ttrain-rmse:1.9426\n",
      "[35016]\teval-rmse:3.79942\ttrain-rmse:1.94255\n",
      "[35017]\teval-rmse:3.7994\ttrain-rmse:1.94255\n",
      "[35018]\teval-rmse:3.79893\ttrain-rmse:1.94254\n",
      "[35019]\teval-rmse:3.79869\ttrain-rmse:1.94253\n",
      "[35020]\teval-rmse:3.79826\ttrain-rmse:1.94252\n",
      "[35021]\teval-rmse:3.79801\ttrain-rmse:1.94252\n",
      "[35022]\teval-rmse:3.7964\ttrain-rmse:1.94249\n",
      "[35023]\teval-rmse:3.79605\ttrain-rmse:1.94249\n",
      "[35024]\teval-rmse:3.79533\ttrain-rmse:1.94247\n",
      "[35025]\teval-rmse:3.79581\ttrain-rmse:1.94248\n",
      "[35026]\teval-rmse:3.79725\ttrain-rmse:1.94252\n",
      "[35027]\teval-rmse:3.79587\ttrain-rmse:1.9425\n",
      "[35028]\teval-rmse:3.79423\ttrain-rmse:1.94247\n",
      "[35029]\teval-rmse:3.79599\ttrain-rmse:1.94249\n",
      "[35030]\teval-rmse:3.79643\ttrain-rmse:1.9425\n",
      "[35031]\teval-rmse:3.79494\ttrain-rmse:1.94247\n",
      "[35032]\teval-rmse:3.79615\ttrain-rmse:1.94249\n",
      "[35033]\teval-rmse:3.79487\ttrain-rmse:1.94249\n",
      "[35034]\teval-rmse:3.79589\ttrain-rmse:1.94251\n",
      "[35035]\teval-rmse:3.79454\ttrain-rmse:1.94248\n",
      "[35036]\teval-rmse:3.7933\ttrain-rmse:1.94248\n",
      "[35037]\teval-rmse:3.79487\ttrain-rmse:1.94248\n",
      "[35038]\teval-rmse:3.79539\ttrain-rmse:1.94249\n",
      "[35039]\teval-rmse:3.79698\ttrain-rmse:1.94253\n",
      "[35040]\teval-rmse:3.79834\ttrain-rmse:1.94257\n",
      "[35041]\teval-rmse:3.79957\ttrain-rmse:1.9426\n",
      "[35042]\teval-rmse:3.79913\ttrain-rmse:1.94259\n",
      "[35043]\teval-rmse:3.79804\ttrain-rmse:1.94257\n",
      "[35044]\teval-rmse:3.79758\ttrain-rmse:1.94256\n",
      "[35045]\teval-rmse:3.79723\ttrain-rmse:1.94255\n",
      "[35046]\teval-rmse:3.79595\ttrain-rmse:1.94254\n",
      "[35047]\teval-rmse:3.79417\ttrain-rmse:1.9425\n",
      "[35048]\teval-rmse:3.79245\ttrain-rmse:1.94249\n",
      "[35049]\teval-rmse:3.79213\ttrain-rmse:1.94248\n",
      "[35050]\teval-rmse:3.79015\ttrain-rmse:1.94249\n",
      "[35051]\teval-rmse:3.78941\ttrain-rmse:1.94248\n",
      "[35052]\teval-rmse:3.78899\ttrain-rmse:1.94248\n",
      "[35053]\teval-rmse:3.78855\ttrain-rmse:1.94249\n",
      "[35054]\teval-rmse:3.78713\ttrain-rmse:1.94249\n",
      "[35055]\teval-rmse:3.788\ttrain-rmse:1.94248\n",
      "[35056]\teval-rmse:3.78927\ttrain-rmse:1.94248\n",
      "[35057]\teval-rmse:3.78801\ttrain-rmse:1.94249\n",
      "[35058]\teval-rmse:3.78836\ttrain-rmse:1.94248\n",
      "[35059]\teval-rmse:3.78785\ttrain-rmse:1.94249\n",
      "[35060]\teval-rmse:3.78806\ttrain-rmse:1.94249\n",
      "[35061]\teval-rmse:3.78939\ttrain-rmse:1.94248\n",
      "[35062]\teval-rmse:3.78989\ttrain-rmse:1.94248\n",
      "[35063]\teval-rmse:3.79112\ttrain-rmse:1.94247\n",
      "[35064]\teval-rmse:3.79081\ttrain-rmse:1.94247\n",
      "[35065]\teval-rmse:3.79049\ttrain-rmse:1.94247\n",
      "[35066]\teval-rmse:3.79169\ttrain-rmse:1.94248\n",
      "[35067]\teval-rmse:3.79272\ttrain-rmse:1.94249\n",
      "[35068]\teval-rmse:3.79097\ttrain-rmse:1.94247\n",
      "[35069]\teval-rmse:3.79096\ttrain-rmse:1.94247\n",
      "[35070]\teval-rmse:3.79272\ttrain-rmse:1.94248\n",
      "[35071]\teval-rmse:3.79231\ttrain-rmse:1.94248\n",
      "[35072]\teval-rmse:3.79353\ttrain-rmse:1.94249\n",
      "[35073]\teval-rmse:3.79489\ttrain-rmse:1.9425\n",
      "[35074]\teval-rmse:3.79361\ttrain-rmse:1.94248\n",
      "[35075]\teval-rmse:3.7952\ttrain-rmse:1.94249\n",
      "[35076]\teval-rmse:3.79673\ttrain-rmse:1.94252\n",
      "[35077]\teval-rmse:3.79799\ttrain-rmse:1.94254\n",
      "[35078]\teval-rmse:3.79871\ttrain-rmse:1.94255\n",
      "[35079]\teval-rmse:3.79924\ttrain-rmse:1.94257\n",
      "[35080]\teval-rmse:3.80041\ttrain-rmse:1.9426\n",
      "[35081]\teval-rmse:3.79874\ttrain-rmse:1.94255\n",
      "[35082]\teval-rmse:3.8003\ttrain-rmse:1.94258\n",
      "[35083]\teval-rmse:3.80191\ttrain-rmse:1.94263\n",
      "[35084]\teval-rmse:3.80085\ttrain-rmse:1.94259\n",
      "[35085]\teval-rmse:3.8003\ttrain-rmse:1.94257\n",
      "[35086]\teval-rmse:3.79975\ttrain-rmse:1.94256\n",
      "[35087]\teval-rmse:3.79953\ttrain-rmse:1.94252\n",
      "[35088]\teval-rmse:3.80128\ttrain-rmse:1.94256\n",
      "[35089]\teval-rmse:3.80303\ttrain-rmse:1.94261\n",
      "[35090]\teval-rmse:3.80245\ttrain-rmse:1.94259\n",
      "[35091]\teval-rmse:3.80276\ttrain-rmse:1.9426\n",
      "[35092]\teval-rmse:3.80229\ttrain-rmse:1.94259\n",
      "[35093]\teval-rmse:3.80079\ttrain-rmse:1.94255\n",
      "[35094]\teval-rmse:3.80196\ttrain-rmse:1.94258\n",
      "[35095]\teval-rmse:3.80068\ttrain-rmse:1.94255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35096]\teval-rmse:3.80107\ttrain-rmse:1.94256\n",
      "[35097]\teval-rmse:3.8007\ttrain-rmse:1.94256\n",
      "[35098]\teval-rmse:3.80139\ttrain-rmse:1.94257\n",
      "[35099]\teval-rmse:3.80063\ttrain-rmse:1.94255\n",
      "[35100]\teval-rmse:3.80004\ttrain-rmse:1.94253\n",
      "[35101]\teval-rmse:3.8005\ttrain-rmse:1.94255\n",
      "[35102]\teval-rmse:3.79924\ttrain-rmse:1.94251\n",
      "[35103]\teval-rmse:3.79868\ttrain-rmse:1.9425\n",
      "[35104]\teval-rmse:3.7973\ttrain-rmse:1.94247\n",
      "[35105]\teval-rmse:3.79754\ttrain-rmse:1.94248\n",
      "[35106]\teval-rmse:3.79887\ttrain-rmse:1.9425\n",
      "[35107]\teval-rmse:3.79937\ttrain-rmse:1.94251\n",
      "[35108]\teval-rmse:3.7996\ttrain-rmse:1.94252\n",
      "[35109]\teval-rmse:3.79902\ttrain-rmse:1.9425\n",
      "[35110]\teval-rmse:3.80061\ttrain-rmse:1.94253\n",
      "[35111]\teval-rmse:3.79986\ttrain-rmse:1.94251\n",
      "[35112]\teval-rmse:3.79985\ttrain-rmse:1.94251\n",
      "[35113]\teval-rmse:3.79855\ttrain-rmse:1.94248\n",
      "[35114]\teval-rmse:3.79714\ttrain-rmse:1.94246\n",
      "[35115]\teval-rmse:3.79852\ttrain-rmse:1.94249\n",
      "[35116]\teval-rmse:3.79712\ttrain-rmse:1.94246\n",
      "[35117]\teval-rmse:3.79653\ttrain-rmse:1.94245\n",
      "[35118]\teval-rmse:3.79772\ttrain-rmse:1.94247\n",
      "[35119]\teval-rmse:3.79929\ttrain-rmse:1.9425\n",
      "[35120]\teval-rmse:3.79798\ttrain-rmse:1.94246\n",
      "[35121]\teval-rmse:3.79953\ttrain-rmse:1.9425\n",
      "[35122]\teval-rmse:3.80057\ttrain-rmse:1.94253\n",
      "[35123]\teval-rmse:3.80184\ttrain-rmse:1.94256\n",
      "[35124]\teval-rmse:3.80336\ttrain-rmse:1.94261\n",
      "[35125]\teval-rmse:3.80403\ttrain-rmse:1.94264\n",
      "[35126]\teval-rmse:3.80578\ttrain-rmse:1.94269\n",
      "[35127]\teval-rmse:3.80646\ttrain-rmse:1.94272\n",
      "[35128]\teval-rmse:3.8082\ttrain-rmse:1.94278\n",
      "[35129]\teval-rmse:3.8076\ttrain-rmse:1.94276\n",
      "[35130]\teval-rmse:3.80615\ttrain-rmse:1.9427\n",
      "[35131]\teval-rmse:3.80479\ttrain-rmse:1.94266\n",
      "[35132]\teval-rmse:3.80513\ttrain-rmse:1.94267\n",
      "[35133]\teval-rmse:3.80485\ttrain-rmse:1.94266\n",
      "[35134]\teval-rmse:3.80513\ttrain-rmse:1.94268\n",
      "[35135]\teval-rmse:3.8049\ttrain-rmse:1.94264\n",
      "[35136]\teval-rmse:3.80602\ttrain-rmse:1.94269\n",
      "[35137]\teval-rmse:3.80645\ttrain-rmse:1.94271\n",
      "[35138]\teval-rmse:3.80489\ttrain-rmse:1.94264\n",
      "[35139]\teval-rmse:3.80444\ttrain-rmse:1.94263\n",
      "[35140]\teval-rmse:3.80515\ttrain-rmse:1.94266\n",
      "[35141]\teval-rmse:3.8035\ttrain-rmse:1.94259\n",
      "[35142]\teval-rmse:3.80216\ttrain-rmse:1.94255\n",
      "[35143]\teval-rmse:3.80159\ttrain-rmse:1.94254\n",
      "[35144]\teval-rmse:3.80262\ttrain-rmse:1.94258\n",
      "[35145]\teval-rmse:3.80119\ttrain-rmse:1.94255\n",
      "[35146]\teval-rmse:3.80168\ttrain-rmse:1.94256\n",
      "[35147]\teval-rmse:3.8011\ttrain-rmse:1.94254\n",
      "[35148]\teval-rmse:3.80087\ttrain-rmse:1.94251\n",
      "[35149]\teval-rmse:3.80224\ttrain-rmse:1.94256\n",
      "[35150]\teval-rmse:3.80382\ttrain-rmse:1.94263\n",
      "[35151]\teval-rmse:3.80354\ttrain-rmse:1.94262\n",
      "[35152]\teval-rmse:3.80203\ttrain-rmse:1.94255\n",
      "[35153]\teval-rmse:3.80166\ttrain-rmse:1.94254\n",
      "[35154]\teval-rmse:3.80103\ttrain-rmse:1.94252\n",
      "[35155]\teval-rmse:3.80278\ttrain-rmse:1.94257\n",
      "[35156]\teval-rmse:3.80256\ttrain-rmse:1.94253\n",
      "[35157]\teval-rmse:3.80233\ttrain-rmse:1.9425\n",
      "[35158]\teval-rmse:3.80157\ttrain-rmse:1.94248\n",
      "[35159]\teval-rmse:3.79979\ttrain-rmse:1.94243\n",
      "[35160]\teval-rmse:3.79958\ttrain-rmse:1.94242\n",
      "[35161]\teval-rmse:3.80085\ttrain-rmse:1.94244\n",
      "[35162]\teval-rmse:3.80243\ttrain-rmse:1.94249\n",
      "[35163]\teval-rmse:3.8022\ttrain-rmse:1.94246\n",
      "[35164]\teval-rmse:3.80216\ttrain-rmse:1.94246\n",
      "[35165]\teval-rmse:3.8027\ttrain-rmse:1.94248\n",
      "[35166]\teval-rmse:3.80129\ttrain-rmse:1.94245\n",
      "[35167]\teval-rmse:3.8015\ttrain-rmse:1.94246\n",
      "[35168]\teval-rmse:3.79985\ttrain-rmse:1.94241\n",
      "[35169]\teval-rmse:3.79828\ttrain-rmse:1.94237\n",
      "[35170]\teval-rmse:3.79969\ttrain-rmse:1.94241\n",
      "[35171]\teval-rmse:3.80123\ttrain-rmse:1.94243\n",
      "[35172]\teval-rmse:3.80264\ttrain-rmse:1.94248\n",
      "[35173]\teval-rmse:3.80131\ttrain-rmse:1.94243\n",
      "[35174]\teval-rmse:3.80076\ttrain-rmse:1.94242\n",
      "[35175]\teval-rmse:3.80095\ttrain-rmse:1.94243\n",
      "[35176]\teval-rmse:3.80238\ttrain-rmse:1.94248\n",
      "[35177]\teval-rmse:3.80036\ttrain-rmse:1.94242\n",
      "[35178]\teval-rmse:3.79927\ttrain-rmse:1.94239\n",
      "[35179]\teval-rmse:3.79975\ttrain-rmse:1.9424\n",
      "[35180]\teval-rmse:3.79923\ttrain-rmse:1.9424\n",
      "[35181]\teval-rmse:3.79847\ttrain-rmse:1.94238\n",
      "[35182]\teval-rmse:3.79975\ttrain-rmse:1.94241\n",
      "[35183]\teval-rmse:3.80101\ttrain-rmse:1.94243\n",
      "[35184]\teval-rmse:3.80064\ttrain-rmse:1.94243\n",
      "[35185]\teval-rmse:3.80042\ttrain-rmse:1.9424\n",
      "[35186]\teval-rmse:3.80019\ttrain-rmse:1.94236\n",
      "[35187]\teval-rmse:3.80056\ttrain-rmse:1.94238\n",
      "[35188]\teval-rmse:3.80075\ttrain-rmse:1.94238\n",
      "[35189]\teval-rmse:3.80038\ttrain-rmse:1.94237\n",
      "[35190]\teval-rmse:3.80084\ttrain-rmse:1.94239\n",
      "[35191]\teval-rmse:3.80062\ttrain-rmse:1.94236\n",
      "[35192]\teval-rmse:3.79881\ttrain-rmse:1.9423\n",
      "[35193]\teval-rmse:3.7992\ttrain-rmse:1.94231\n",
      "[35194]\teval-rmse:3.79805\ttrain-rmse:1.94228\n",
      "[35195]\teval-rmse:3.79769\ttrain-rmse:1.94228\n",
      "[35196]\teval-rmse:3.79746\ttrain-rmse:1.94227\n",
      "[35197]\teval-rmse:3.7985\ttrain-rmse:1.94229\n",
      "[35198]\teval-rmse:3.80007\ttrain-rmse:1.94235\n",
      "[35199]\teval-rmse:3.79963\ttrain-rmse:1.94233\n",
      "[35200]\teval-rmse:3.79937\ttrain-rmse:1.94233\n",
      "[35201]\teval-rmse:3.79951\ttrain-rmse:1.94233\n",
      "[35202]\teval-rmse:3.80105\ttrain-rmse:1.94239\n",
      "[35203]\teval-rmse:3.8028\ttrain-rmse:1.94243\n",
      "[35204]\teval-rmse:3.80169\ttrain-rmse:1.9424\n",
      "[35205]\teval-rmse:3.80303\ttrain-rmse:1.94245\n",
      "[35206]\teval-rmse:3.80321\ttrain-rmse:1.94246\n",
      "[35207]\teval-rmse:3.80295\ttrain-rmse:1.94244\n",
      "[35208]\teval-rmse:3.80295\ttrain-rmse:1.94244\n",
      "[35209]\teval-rmse:3.80335\ttrain-rmse:1.94246\n",
      "[35210]\teval-rmse:3.80458\ttrain-rmse:1.94251\n",
      "[35211]\teval-rmse:3.80599\ttrain-rmse:1.94258\n",
      "[35212]\teval-rmse:3.80699\ttrain-rmse:1.94264\n",
      "[35213]\teval-rmse:3.80636\ttrain-rmse:1.9426\n",
      "[35214]\teval-rmse:3.80598\ttrain-rmse:1.94258\n",
      "[35215]\teval-rmse:3.80597\ttrain-rmse:1.94258\n",
      "[35216]\teval-rmse:3.80597\ttrain-rmse:1.94258\n",
      "[35217]\teval-rmse:3.80538\ttrain-rmse:1.94256\n",
      "[35218]\teval-rmse:3.80493\ttrain-rmse:1.94255\n",
      "[35219]\teval-rmse:3.80651\ttrain-rmse:1.94263\n",
      "[35220]\teval-rmse:3.80589\ttrain-rmse:1.9426\n",
      "[35221]\teval-rmse:3.80587\ttrain-rmse:1.9426\n",
      "[35222]\teval-rmse:3.80549\ttrain-rmse:1.94257\n",
      "[35223]\teval-rmse:3.80685\ttrain-rmse:1.94265\n",
      "[35224]\teval-rmse:3.80639\ttrain-rmse:1.94262\n",
      "[35225]\teval-rmse:3.80677\ttrain-rmse:1.94264\n",
      "[35226]\teval-rmse:3.80631\ttrain-rmse:1.94263\n",
      "[35227]\teval-rmse:3.80485\ttrain-rmse:1.94257\n",
      "[35228]\teval-rmse:3.8044\ttrain-rmse:1.94255\n",
      "[35229]\teval-rmse:3.80294\ttrain-rmse:1.94248\n",
      "[35230]\teval-rmse:3.80413\ttrain-rmse:1.94253\n",
      "[35231]\teval-rmse:3.80411\ttrain-rmse:1.94253\n",
      "[35232]\teval-rmse:3.80424\ttrain-rmse:1.94254\n",
      "[35233]\teval-rmse:3.80577\ttrain-rmse:1.94258\n",
      "[35234]\teval-rmse:3.80517\ttrain-rmse:1.94257\n",
      "[35235]\teval-rmse:3.80534\ttrain-rmse:1.94257\n",
      "[35236]\teval-rmse:3.804\ttrain-rmse:1.94253\n",
      "[35237]\teval-rmse:3.80447\ttrain-rmse:1.94256\n",
      "[35238]\teval-rmse:3.80598\ttrain-rmse:1.94261\n",
      "[35239]\teval-rmse:3.80717\ttrain-rmse:1.94268\n",
      "[35240]\teval-rmse:3.80687\ttrain-rmse:1.94267\n",
      "[35241]\teval-rmse:3.8083\ttrain-rmse:1.94274\n",
      "[35242]\teval-rmse:3.80839\ttrain-rmse:1.94274\n",
      "[35243]\teval-rmse:3.80685\ttrain-rmse:1.94267\n",
      "[35244]\teval-rmse:3.80551\ttrain-rmse:1.94259\n",
      "[35245]\teval-rmse:3.80489\ttrain-rmse:1.94256\n",
      "[35246]\teval-rmse:3.80464\ttrain-rmse:1.94255\n",
      "[35247]\teval-rmse:3.80485\ttrain-rmse:1.94256\n",
      "[35248]\teval-rmse:3.80523\ttrain-rmse:1.94258\n",
      "[35249]\teval-rmse:3.80521\ttrain-rmse:1.94258\n",
      "[35250]\teval-rmse:3.80621\ttrain-rmse:1.94264\n",
      "[35251]\teval-rmse:3.80565\ttrain-rmse:1.94262\n",
      "[35252]\teval-rmse:3.80736\ttrain-rmse:1.94271\n",
      "[35253]\teval-rmse:3.80706\ttrain-rmse:1.9427\n",
      "[35254]\teval-rmse:3.80575\ttrain-rmse:1.94263\n",
      "[35255]\teval-rmse:3.80527\ttrain-rmse:1.94261\n",
      "[35256]\teval-rmse:3.80376\ttrain-rmse:1.94253\n",
      "[35257]\teval-rmse:3.80197\ttrain-rmse:1.94245\n",
      "[35258]\teval-rmse:3.80013\ttrain-rmse:1.94238\n",
      "[35259]\teval-rmse:3.80033\ttrain-rmse:1.94238\n",
      "[35260]\teval-rmse:3.79868\ttrain-rmse:1.94233\n",
      "[35261]\teval-rmse:3.79863\ttrain-rmse:1.94233\n",
      "[35262]\teval-rmse:3.79776\ttrain-rmse:1.94231\n",
      "[35263]\teval-rmse:3.7989\ttrain-rmse:1.94234\n",
      "[35264]\teval-rmse:3.79712\ttrain-rmse:1.9423\n",
      "[35265]\teval-rmse:3.79857\ttrain-rmse:1.94231\n",
      "[35266]\teval-rmse:3.79806\ttrain-rmse:1.9423\n",
      "[35267]\teval-rmse:3.79827\ttrain-rmse:1.9423\n",
      "[35268]\teval-rmse:3.79649\ttrain-rmse:1.94227\n",
      "[35269]\teval-rmse:3.79615\ttrain-rmse:1.94226\n",
      "[35270]\teval-rmse:3.79635\ttrain-rmse:1.94226\n",
      "[35271]\teval-rmse:3.79485\ttrain-rmse:1.94223\n",
      "[35272]\teval-rmse:3.79428\ttrain-rmse:1.94223\n",
      "[35273]\teval-rmse:3.79255\ttrain-rmse:1.94222\n",
      "[35274]\teval-rmse:3.7912\ttrain-rmse:1.94223\n",
      "[35275]\teval-rmse:3.79266\ttrain-rmse:1.94224\n",
      "[35276]\teval-rmse:3.793\ttrain-rmse:1.94224\n",
      "[35277]\teval-rmse:3.79228\ttrain-rmse:1.94224\n",
      "[35278]\teval-rmse:3.79211\ttrain-rmse:1.94221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35279]\teval-rmse:3.79347\ttrain-rmse:1.94222\n",
      "[35280]\teval-rmse:3.79302\ttrain-rmse:1.94222\n",
      "[35281]\teval-rmse:3.79284\ttrain-rmse:1.94222\n",
      "[35282]\teval-rmse:3.79146\ttrain-rmse:1.94222\n",
      "[35283]\teval-rmse:3.7909\ttrain-rmse:1.94222\n",
      "[35284]\teval-rmse:3.79038\ttrain-rmse:1.94221\n",
      "[35285]\teval-rmse:3.78862\ttrain-rmse:1.94221\n",
      "[35286]\teval-rmse:3.79038\ttrain-rmse:1.9422\n",
      "[35287]\teval-rmse:3.79198\ttrain-rmse:1.9422\n",
      "[35288]\teval-rmse:3.79322\ttrain-rmse:1.9422\n",
      "[35289]\teval-rmse:3.792\ttrain-rmse:1.9422\n",
      "[35290]\teval-rmse:3.79333\ttrain-rmse:1.94221\n",
      "[35291]\teval-rmse:3.79361\ttrain-rmse:1.94221\n",
      "[35292]\teval-rmse:3.7928\ttrain-rmse:1.94221\n",
      "[35293]\teval-rmse:3.79302\ttrain-rmse:1.94221\n",
      "[35294]\teval-rmse:3.79149\ttrain-rmse:1.94221\n",
      "[35295]\teval-rmse:3.79126\ttrain-rmse:1.94221\n",
      "[35296]\teval-rmse:3.79108\ttrain-rmse:1.94221\n",
      "[35297]\teval-rmse:3.78974\ttrain-rmse:1.94222\n",
      "[35298]\teval-rmse:3.79075\ttrain-rmse:1.94222\n",
      "[35299]\teval-rmse:3.78919\ttrain-rmse:1.94223\n",
      "[35300]\teval-rmse:3.79026\ttrain-rmse:1.94222\n",
      "[35301]\teval-rmse:3.7888\ttrain-rmse:1.94223\n",
      "[35302]\teval-rmse:3.78918\ttrain-rmse:1.94223\n",
      "[35303]\teval-rmse:3.78887\ttrain-rmse:1.94223\n",
      "[35304]\teval-rmse:3.79029\ttrain-rmse:1.94223\n",
      "[35305]\teval-rmse:3.78998\ttrain-rmse:1.94223\n",
      "[35306]\teval-rmse:3.79157\ttrain-rmse:1.94222\n",
      "[35307]\teval-rmse:3.79208\ttrain-rmse:1.94222\n",
      "[35308]\teval-rmse:3.79342\ttrain-rmse:1.94223\n",
      "[35309]\teval-rmse:3.79319\ttrain-rmse:1.94223\n",
      "[35310]\teval-rmse:3.79388\ttrain-rmse:1.94224\n",
      "[35311]\teval-rmse:3.79368\ttrain-rmse:1.94221\n",
      "[35312]\teval-rmse:3.79419\ttrain-rmse:1.94222\n",
      "[35313]\teval-rmse:3.79469\ttrain-rmse:1.94223\n",
      "[35314]\teval-rmse:3.79508\ttrain-rmse:1.94223\n",
      "[35315]\teval-rmse:3.79683\ttrain-rmse:1.94226\n",
      "[35316]\teval-rmse:3.79628\ttrain-rmse:1.94225\n",
      "[35317]\teval-rmse:3.79449\ttrain-rmse:1.94223\n",
      "[35318]\teval-rmse:3.7932\ttrain-rmse:1.94222\n",
      "[35319]\teval-rmse:3.79463\ttrain-rmse:1.94224\n",
      "[35320]\teval-rmse:3.79476\ttrain-rmse:1.94225\n",
      "[35321]\teval-rmse:3.79599\ttrain-rmse:1.94227\n",
      "[35322]\teval-rmse:3.79774\ttrain-rmse:1.9423\n",
      "[35323]\teval-rmse:3.79643\ttrain-rmse:1.94226\n",
      "[35324]\teval-rmse:3.79506\ttrain-rmse:1.94226\n",
      "[35325]\teval-rmse:3.79643\ttrain-rmse:1.94228\n",
      "[35326]\teval-rmse:3.79802\ttrain-rmse:1.9423\n",
      "[35327]\teval-rmse:3.79668\ttrain-rmse:1.94227\n",
      "[35328]\teval-rmse:3.79695\ttrain-rmse:1.94228\n",
      "[35329]\teval-rmse:3.7967\ttrain-rmse:1.94227\n",
      "[35330]\teval-rmse:3.79805\ttrain-rmse:1.9423\n",
      "[35331]\teval-rmse:3.79763\ttrain-rmse:1.94229\n",
      "[35332]\teval-rmse:3.79741\ttrain-rmse:1.94229\n",
      "[35333]\teval-rmse:3.79586\ttrain-rmse:1.94227\n",
      "[35334]\teval-rmse:3.79605\ttrain-rmse:1.94227\n",
      "[35335]\teval-rmse:3.79497\ttrain-rmse:1.94226\n",
      "[35336]\teval-rmse:3.79353\ttrain-rmse:1.94226\n",
      "[35337]\teval-rmse:3.79333\ttrain-rmse:1.94225\n",
      "[35338]\teval-rmse:3.79435\ttrain-rmse:1.94226\n",
      "[35339]\teval-rmse:3.79553\ttrain-rmse:1.94228\n",
      "[35340]\teval-rmse:3.79374\ttrain-rmse:1.94226\n",
      "[35341]\teval-rmse:3.79516\ttrain-rmse:1.94228\n",
      "[35342]\teval-rmse:3.79387\ttrain-rmse:1.94227\n",
      "[35343]\teval-rmse:3.79354\ttrain-rmse:1.94227\n",
      "[35344]\teval-rmse:3.79199\ttrain-rmse:1.94225\n",
      "[35345]\teval-rmse:3.79249\ttrain-rmse:1.94225\n",
      "[35346]\teval-rmse:3.7923\ttrain-rmse:1.94225\n",
      "[35347]\teval-rmse:3.79125\ttrain-rmse:1.94225\n",
      "[35348]\teval-rmse:3.79021\ttrain-rmse:1.94225\n",
      "[35349]\teval-rmse:3.78827\ttrain-rmse:1.94225\n",
      "[35350]\teval-rmse:3.78877\ttrain-rmse:1.94225\n",
      "[35351]\teval-rmse:3.78897\ttrain-rmse:1.94225\n",
      "[35352]\teval-rmse:3.78866\ttrain-rmse:1.94225\n",
      "[35353]\teval-rmse:3.79042\ttrain-rmse:1.94225\n",
      "[35354]\teval-rmse:3.79059\ttrain-rmse:1.94225\n",
      "[35355]\teval-rmse:3.79037\ttrain-rmse:1.94225\n",
      "[35356]\teval-rmse:3.78913\ttrain-rmse:1.94226\n",
      "[35357]\teval-rmse:3.78793\ttrain-rmse:1.94227\n",
      "[35358]\teval-rmse:3.78939\ttrain-rmse:1.94227\n",
      "[35359]\teval-rmse:3.78896\ttrain-rmse:1.94227\n",
      "[35360]\teval-rmse:3.78742\ttrain-rmse:1.94227\n",
      "[35361]\teval-rmse:3.78725\ttrain-rmse:1.94227\n",
      "[35362]\teval-rmse:3.78746\ttrain-rmse:1.94227\n",
      "[35363]\teval-rmse:3.78715\ttrain-rmse:1.94227\n",
      "[35364]\teval-rmse:3.78591\ttrain-rmse:1.9423\n",
      "[35365]\teval-rmse:3.78471\ttrain-rmse:1.94232\n",
      "[35366]\teval-rmse:3.78456\ttrain-rmse:1.94232\n",
      "[35367]\teval-rmse:3.78414\ttrain-rmse:1.94233\n",
      "[35368]\teval-rmse:3.78536\ttrain-rmse:1.94231\n",
      "[35369]\teval-rmse:3.78383\ttrain-rmse:1.94233\n",
      "[35370]\teval-rmse:3.78236\ttrain-rmse:1.94235\n",
      "[35371]\teval-rmse:3.78287\ttrain-rmse:1.94234\n",
      "[35372]\teval-rmse:3.78218\ttrain-rmse:1.94235\n",
      "[35373]\teval-rmse:3.78365\ttrain-rmse:1.94231\n",
      "[35374]\teval-rmse:3.78387\ttrain-rmse:1.9423\n",
      "[35375]\teval-rmse:3.78321\ttrain-rmse:1.94232\n",
      "[35376]\teval-rmse:3.78497\ttrain-rmse:1.94229\n",
      "[35377]\teval-rmse:3.78381\ttrain-rmse:1.94232\n",
      "[35378]\teval-rmse:3.78343\ttrain-rmse:1.94233\n",
      "[35379]\teval-rmse:3.78504\ttrain-rmse:1.94229\n",
      "[35380]\teval-rmse:3.78383\ttrain-rmse:1.94231\n",
      "[35381]\teval-rmse:3.78363\ttrain-rmse:1.94231\n",
      "[35382]\teval-rmse:3.78485\ttrain-rmse:1.94228\n",
      "[35383]\teval-rmse:3.7845\ttrain-rmse:1.94229\n",
      "[35384]\teval-rmse:3.78494\ttrain-rmse:1.94228\n",
      "[35385]\teval-rmse:3.78428\ttrain-rmse:1.94229\n",
      "[35386]\teval-rmse:3.78408\ttrain-rmse:1.94229\n",
      "[35387]\teval-rmse:3.78584\ttrain-rmse:1.94227\n",
      "[35388]\teval-rmse:3.78468\ttrain-rmse:1.94229\n",
      "[35389]\teval-rmse:3.7833\ttrain-rmse:1.94233\n",
      "[35390]\teval-rmse:3.78405\ttrain-rmse:1.94231\n",
      "[35391]\teval-rmse:3.7839\ttrain-rmse:1.94231\n",
      "[35392]\teval-rmse:3.78529\ttrain-rmse:1.94229\n",
      "[35393]\teval-rmse:3.78374\ttrain-rmse:1.94232\n",
      "[35394]\teval-rmse:3.78427\ttrain-rmse:1.9423\n",
      "[35395]\teval-rmse:3.78412\ttrain-rmse:1.9423\n",
      "[35396]\teval-rmse:3.78429\ttrain-rmse:1.9423\n",
      "[35397]\teval-rmse:3.78261\ttrain-rmse:1.94235\n",
      "[35398]\teval-rmse:3.78227\ttrain-rmse:1.94236\n",
      "[35399]\teval-rmse:3.78284\ttrain-rmse:1.94235\n",
      "[35400]\teval-rmse:3.78423\ttrain-rmse:1.9423\n",
      "[35401]\teval-rmse:3.7855\ttrain-rmse:1.94227\n",
      "[35402]\teval-rmse:3.78481\ttrain-rmse:1.94229\n",
      "[35403]\teval-rmse:3.78501\ttrain-rmse:1.94229\n",
      "[35404]\teval-rmse:3.78527\ttrain-rmse:1.94228\n",
      "[35405]\teval-rmse:3.78662\ttrain-rmse:1.94226\n",
      "[35406]\teval-rmse:3.78641\ttrain-rmse:1.94227\n",
      "[35407]\teval-rmse:3.78763\ttrain-rmse:1.94225\n",
      "[35408]\teval-rmse:3.78746\ttrain-rmse:1.94225\n",
      "[35409]\teval-rmse:3.78893\ttrain-rmse:1.94225\n",
      "[35410]\teval-rmse:3.79021\ttrain-rmse:1.94223\n",
      "[35411]\teval-rmse:3.79061\ttrain-rmse:1.94223\n",
      "[35412]\teval-rmse:3.79105\ttrain-rmse:1.94223\n",
      "[35413]\teval-rmse:3.79067\ttrain-rmse:1.94224\n",
      "[35414]\teval-rmse:3.79222\ttrain-rmse:1.94225\n",
      "[35415]\teval-rmse:3.79397\ttrain-rmse:1.94226\n",
      "[35416]\teval-rmse:3.79344\ttrain-rmse:1.94226\n",
      "[35417]\teval-rmse:3.79412\ttrain-rmse:1.94226\n",
      "[35418]\teval-rmse:3.79429\ttrain-rmse:1.94227\n",
      "[35419]\teval-rmse:3.79409\ttrain-rmse:1.94226\n",
      "[35420]\teval-rmse:3.79532\ttrain-rmse:1.94228\n",
      "[35421]\teval-rmse:3.79684\ttrain-rmse:1.94229\n",
      "[35422]\teval-rmse:3.7965\ttrain-rmse:1.94229\n",
      "[35423]\teval-rmse:3.79624\ttrain-rmse:1.94228\n",
      "[35424]\teval-rmse:3.79497\ttrain-rmse:1.94226\n",
      "[35425]\teval-rmse:3.79654\ttrain-rmse:1.94229\n",
      "[35426]\teval-rmse:3.79506\ttrain-rmse:1.94226\n",
      "[35427]\teval-rmse:3.79608\ttrain-rmse:1.94228\n",
      "[35428]\teval-rmse:3.79454\ttrain-rmse:1.94226\n",
      "[35429]\teval-rmse:3.79578\ttrain-rmse:1.94228\n",
      "[35430]\teval-rmse:3.79544\ttrain-rmse:1.94227\n",
      "[35431]\teval-rmse:3.7968\ttrain-rmse:1.94229\n",
      "[35432]\teval-rmse:3.79699\ttrain-rmse:1.94229\n",
      "[35433]\teval-rmse:3.79531\ttrain-rmse:1.94226\n",
      "[35434]\teval-rmse:3.79497\ttrain-rmse:1.94226\n",
      "[35435]\teval-rmse:3.79547\ttrain-rmse:1.94227\n",
      "[35436]\teval-rmse:3.79705\ttrain-rmse:1.9423\n",
      "[35437]\teval-rmse:3.79742\ttrain-rmse:1.9423\n",
      "[35438]\teval-rmse:3.79587\ttrain-rmse:1.94227\n",
      "[35439]\teval-rmse:3.7962\ttrain-rmse:1.94228\n",
      "[35440]\teval-rmse:3.796\ttrain-rmse:1.94227\n",
      "[35441]\teval-rmse:3.79602\ttrain-rmse:1.94228\n",
      "[35442]\teval-rmse:3.79547\ttrain-rmse:1.94227\n",
      "[35443]\teval-rmse:3.79495\ttrain-rmse:1.94226\n",
      "[35444]\teval-rmse:3.7942\ttrain-rmse:1.94225\n",
      "[35445]\teval-rmse:3.79577\ttrain-rmse:1.94228\n",
      "[35446]\teval-rmse:3.797\ttrain-rmse:1.94229\n",
      "[35447]\teval-rmse:3.79736\ttrain-rmse:1.9423\n",
      "[35448]\teval-rmse:3.79589\ttrain-rmse:1.94227\n",
      "[35449]\teval-rmse:3.79513\ttrain-rmse:1.94226\n",
      "[35450]\teval-rmse:3.79644\ttrain-rmse:1.94229\n",
      "[35451]\teval-rmse:3.79799\ttrain-rmse:1.9423\n",
      "[35452]\teval-rmse:3.79748\ttrain-rmse:1.94229\n",
      "[35453]\teval-rmse:3.7969\ttrain-rmse:1.94228\n",
      "[35454]\teval-rmse:3.79669\ttrain-rmse:1.94225\n",
      "[35455]\teval-rmse:3.7951\ttrain-rmse:1.94221\n",
      "[35456]\teval-rmse:3.79582\ttrain-rmse:1.94222\n",
      "[35457]\teval-rmse:3.79578\ttrain-rmse:1.94222\n",
      "[35458]\teval-rmse:3.79557\ttrain-rmse:1.94222\n",
      "[35459]\teval-rmse:3.79483\ttrain-rmse:1.9422\n",
      "[35460]\teval-rmse:3.79526\ttrain-rmse:1.94221\n",
      "[35461]\teval-rmse:3.79388\ttrain-rmse:1.94218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35462]\teval-rmse:3.79252\ttrain-rmse:1.94218\n",
      "[35463]\teval-rmse:3.79255\ttrain-rmse:1.94218\n",
      "[35464]\teval-rmse:3.79372\ttrain-rmse:1.94219\n",
      "[35465]\teval-rmse:3.79352\ttrain-rmse:1.94216\n",
      "[35466]\teval-rmse:3.79377\ttrain-rmse:1.94216\n",
      "[35467]\teval-rmse:3.79396\ttrain-rmse:1.94216\n",
      "[35468]\teval-rmse:3.79237\ttrain-rmse:1.94215\n",
      "[35469]\teval-rmse:3.7922\ttrain-rmse:1.94212\n",
      "[35470]\teval-rmse:3.79309\ttrain-rmse:1.94213\n",
      "[35471]\teval-rmse:3.7938\ttrain-rmse:1.94214\n",
      "[35472]\teval-rmse:3.79379\ttrain-rmse:1.94214\n",
      "[35473]\teval-rmse:3.79554\ttrain-rmse:1.94216\n",
      "[35474]\teval-rmse:3.79512\ttrain-rmse:1.94215\n",
      "[35475]\teval-rmse:3.7943\ttrain-rmse:1.94214\n",
      "[35476]\teval-rmse:3.79482\ttrain-rmse:1.94215\n",
      "[35477]\teval-rmse:3.79375\ttrain-rmse:1.94214\n",
      "[35478]\teval-rmse:3.79351\ttrain-rmse:1.94213\n",
      "[35479]\teval-rmse:3.79195\ttrain-rmse:1.94213\n",
      "[35480]\teval-rmse:3.79069\ttrain-rmse:1.94212\n",
      "[35481]\teval-rmse:3.79046\ttrain-rmse:1.94212\n",
      "[35482]\teval-rmse:3.7917\ttrain-rmse:1.94212\n",
      "[35483]\teval-rmse:3.79329\ttrain-rmse:1.94213\n",
      "[35484]\teval-rmse:3.79448\ttrain-rmse:1.94215\n",
      "[35485]\teval-rmse:3.79399\ttrain-rmse:1.94215\n",
      "[35486]\teval-rmse:3.79518\ttrain-rmse:1.94217\n",
      "[35487]\teval-rmse:3.7964\ttrain-rmse:1.9422\n",
      "[35488]\teval-rmse:3.79658\ttrain-rmse:1.9422\n",
      "[35489]\teval-rmse:3.79603\ttrain-rmse:1.94219\n",
      "[35490]\teval-rmse:3.79748\ttrain-rmse:1.9422\n",
      "[35491]\teval-rmse:3.79608\ttrain-rmse:1.94219\n",
      "[35492]\teval-rmse:3.7941\ttrain-rmse:1.94215\n",
      "[35493]\teval-rmse:3.79303\ttrain-rmse:1.94214\n",
      "[35494]\teval-rmse:3.79302\ttrain-rmse:1.94214\n",
      "[35495]\teval-rmse:3.79347\ttrain-rmse:1.94215\n",
      "[35496]\teval-rmse:3.79449\ttrain-rmse:1.94216\n",
      "[35497]\teval-rmse:3.79521\ttrain-rmse:1.94217\n",
      "[35498]\teval-rmse:3.79696\ttrain-rmse:1.94219\n",
      "[35499]\teval-rmse:3.79541\ttrain-rmse:1.94215\n",
      "[35500]\teval-rmse:3.79663\ttrain-rmse:1.94216\n",
      "[35501]\teval-rmse:3.79525\ttrain-rmse:1.94214\n",
      "[35502]\teval-rmse:3.79466\ttrain-rmse:1.94213\n",
      "[35503]\teval-rmse:3.79601\ttrain-rmse:1.94215\n",
      "[35504]\teval-rmse:3.7962\ttrain-rmse:1.94215\n",
      "[35505]\teval-rmse:3.79775\ttrain-rmse:1.94219\n",
      "[35506]\teval-rmse:3.79733\ttrain-rmse:1.94219\n",
      "[35507]\teval-rmse:3.79677\ttrain-rmse:1.94218\n",
      "[35508]\teval-rmse:3.79547\ttrain-rmse:1.94215\n",
      "[35509]\teval-rmse:3.79522\ttrain-rmse:1.94215\n",
      "[35510]\teval-rmse:3.7947\ttrain-rmse:1.94214\n",
      "[35511]\teval-rmse:3.79445\ttrain-rmse:1.94213\n",
      "[35512]\teval-rmse:3.79463\ttrain-rmse:1.94213\n",
      "[35513]\teval-rmse:3.79443\ttrain-rmse:1.94211\n",
      "[35514]\teval-rmse:3.79463\ttrain-rmse:1.94211\n",
      "[35515]\teval-rmse:3.79283\ttrain-rmse:1.94209\n",
      "[35516]\teval-rmse:3.79232\ttrain-rmse:1.94209\n",
      "[35517]\teval-rmse:3.79407\ttrain-rmse:1.94211\n",
      "[35518]\teval-rmse:3.79444\ttrain-rmse:1.94212\n",
      "[35519]\teval-rmse:3.7948\ttrain-rmse:1.94213\n",
      "[35520]\teval-rmse:3.79446\ttrain-rmse:1.94212\n",
      "[35521]\teval-rmse:3.79308\ttrain-rmse:1.9421\n",
      "[35522]\teval-rmse:3.79202\ttrain-rmse:1.94209\n",
      "[35523]\teval-rmse:3.79042\ttrain-rmse:1.94207\n",
      "[35524]\teval-rmse:3.79115\ttrain-rmse:1.94207\n",
      "[35525]\teval-rmse:3.79261\ttrain-rmse:1.94207\n",
      "[35526]\teval-rmse:3.79407\ttrain-rmse:1.94207\n",
      "[35527]\teval-rmse:3.79477\ttrain-rmse:1.94209\n",
      "[35528]\teval-rmse:3.79495\ttrain-rmse:1.94209\n",
      "[35529]\teval-rmse:3.7951\ttrain-rmse:1.94209\n",
      "[35530]\teval-rmse:3.79379\ttrain-rmse:1.94208\n",
      "[35531]\teval-rmse:3.79505\ttrain-rmse:1.9421\n",
      "[35532]\teval-rmse:3.79641\ttrain-rmse:1.94212\n",
      "[35533]\teval-rmse:3.79591\ttrain-rmse:1.94212\n",
      "[35534]\teval-rmse:3.79431\ttrain-rmse:1.94208\n",
      "[35535]\teval-rmse:3.79397\ttrain-rmse:1.94208\n",
      "[35536]\teval-rmse:3.79339\ttrain-rmse:1.94207\n",
      "[35537]\teval-rmse:3.79498\ttrain-rmse:1.94209\n",
      "[35538]\teval-rmse:3.79625\ttrain-rmse:1.94212\n",
      "[35539]\teval-rmse:3.79582\ttrain-rmse:1.94211\n",
      "[35540]\teval-rmse:3.79527\ttrain-rmse:1.9421\n",
      "[35541]\teval-rmse:3.7957\ttrain-rmse:1.94211\n",
      "[35542]\teval-rmse:3.79722\ttrain-rmse:1.94215\n",
      "[35543]\teval-rmse:3.79881\ttrain-rmse:1.94217\n",
      "[35544]\teval-rmse:3.79854\ttrain-rmse:1.94216\n",
      "[35545]\teval-rmse:3.7999\ttrain-rmse:1.94219\n",
      "[35546]\teval-rmse:3.7988\ttrain-rmse:1.94216\n",
      "[35547]\teval-rmse:3.79718\ttrain-rmse:1.94213\n",
      "[35548]\teval-rmse:3.79829\ttrain-rmse:1.94217\n",
      "[35549]\teval-rmse:3.79793\ttrain-rmse:1.94216\n",
      "[35550]\teval-rmse:3.79632\ttrain-rmse:1.94212\n",
      "[35551]\teval-rmse:3.79631\ttrain-rmse:1.94212\n",
      "[35552]\teval-rmse:3.79597\ttrain-rmse:1.94211\n",
      "[35553]\teval-rmse:3.79669\ttrain-rmse:1.94213\n",
      "[35554]\teval-rmse:3.79724\ttrain-rmse:1.94215\n",
      "[35555]\teval-rmse:3.79523\ttrain-rmse:1.94209\n",
      "[35556]\teval-rmse:3.79682\ttrain-rmse:1.9421\n",
      "[35557]\teval-rmse:3.79656\ttrain-rmse:1.9421\n",
      "[35558]\teval-rmse:3.79693\ttrain-rmse:1.94211\n",
      "[35559]\teval-rmse:3.79563\ttrain-rmse:1.94209\n",
      "[35560]\teval-rmse:3.79688\ttrain-rmse:1.94213\n",
      "[35561]\teval-rmse:3.79703\ttrain-rmse:1.94213\n",
      "[35562]\teval-rmse:3.79825\ttrain-rmse:1.94217\n",
      "[35563]\teval-rmse:3.79976\ttrain-rmse:1.9422\n",
      "[35564]\teval-rmse:3.79901\ttrain-rmse:1.94217\n",
      "[35565]\teval-rmse:3.79879\ttrain-rmse:1.94215\n",
      "[35566]\teval-rmse:3.79896\ttrain-rmse:1.94215\n",
      "[35567]\teval-rmse:3.79917\ttrain-rmse:1.94216\n",
      "[35568]\teval-rmse:3.80053\ttrain-rmse:1.94222\n",
      "[35569]\teval-rmse:3.79977\ttrain-rmse:1.94219\n",
      "[35570]\teval-rmse:3.80009\ttrain-rmse:1.9422\n",
      "[35571]\teval-rmse:3.79987\ttrain-rmse:1.94217\n",
      "[35572]\teval-rmse:3.79986\ttrain-rmse:1.94217\n",
      "[35573]\teval-rmse:3.80102\ttrain-rmse:1.94222\n",
      "[35574]\teval-rmse:3.80132\ttrain-rmse:1.94223\n",
      "[35575]\teval-rmse:3.8029\ttrain-rmse:1.94228\n",
      "[35576]\teval-rmse:3.80415\ttrain-rmse:1.94233\n",
      "[35577]\teval-rmse:3.80287\ttrain-rmse:1.94228\n",
      "[35578]\teval-rmse:3.80137\ttrain-rmse:1.9422\n",
      "[35579]\teval-rmse:3.80026\ttrain-rmse:1.94218\n",
      "[35580]\teval-rmse:3.80139\ttrain-rmse:1.94223\n",
      "[35581]\teval-rmse:3.80272\ttrain-rmse:1.94229\n",
      "[35582]\teval-rmse:3.80107\ttrain-rmse:1.94221\n",
      "[35583]\teval-rmse:3.80227\ttrain-rmse:1.94225\n",
      "[35584]\teval-rmse:3.80379\ttrain-rmse:1.9423\n",
      "[35585]\teval-rmse:3.80351\ttrain-rmse:1.94229\n",
      "[35586]\teval-rmse:3.80303\ttrain-rmse:1.94227\n",
      "[35587]\teval-rmse:3.80437\ttrain-rmse:1.94232\n",
      "[35588]\teval-rmse:3.80571\ttrain-rmse:1.94239\n",
      "[35589]\teval-rmse:3.80671\ttrain-rmse:1.94246\n",
      "[35590]\teval-rmse:3.80695\ttrain-rmse:1.94247\n",
      "[35591]\teval-rmse:3.80738\ttrain-rmse:1.9425\n",
      "[35592]\teval-rmse:3.80788\ttrain-rmse:1.94252\n",
      "[35593]\teval-rmse:3.80649\ttrain-rmse:1.94243\n",
      "[35594]\teval-rmse:3.80791\ttrain-rmse:1.94249\n",
      "[35595]\teval-rmse:3.80762\ttrain-rmse:1.94247\n",
      "[35596]\teval-rmse:3.80892\ttrain-rmse:1.94255\n",
      "[35597]\teval-rmse:3.80834\ttrain-rmse:1.94251\n",
      "[35598]\teval-rmse:3.80719\ttrain-rmse:1.94247\n",
      "[35599]\teval-rmse:3.80764\ttrain-rmse:1.94249\n",
      "[35600]\teval-rmse:3.80779\ttrain-rmse:1.9425\n",
      "[35601]\teval-rmse:3.8073\ttrain-rmse:1.94247\n",
      "[35602]\teval-rmse:3.80903\ttrain-rmse:1.94253\n",
      "[35603]\teval-rmse:3.80788\ttrain-rmse:1.94249\n",
      "[35604]\teval-rmse:3.80856\ttrain-rmse:1.94252\n",
      "[35605]\teval-rmse:3.80805\ttrain-rmse:1.94249\n",
      "[35606]\teval-rmse:3.8078\ttrain-rmse:1.94246\n",
      "[35607]\teval-rmse:3.80716\ttrain-rmse:1.94242\n",
      "[35608]\teval-rmse:3.80752\ttrain-rmse:1.94244\n",
      "[35609]\teval-rmse:3.80818\ttrain-rmse:1.94249\n",
      "[35610]\teval-rmse:3.80648\ttrain-rmse:1.94238\n",
      "[35611]\teval-rmse:3.80821\ttrain-rmse:1.94244\n",
      "[35612]\teval-rmse:3.80978\ttrain-rmse:1.94251\n",
      "[35613]\teval-rmse:3.80919\ttrain-rmse:1.94248\n",
      "[35614]\teval-rmse:3.80932\ttrain-rmse:1.94249\n",
      "[35615]\teval-rmse:3.81066\ttrain-rmse:1.94259\n",
      "[35616]\teval-rmse:3.81239\ttrain-rmse:1.94267\n",
      "[35617]\teval-rmse:3.8134\ttrain-rmse:1.94275\n",
      "[35618]\teval-rmse:3.81314\ttrain-rmse:1.94271\n",
      "[35619]\teval-rmse:3.81329\ttrain-rmse:1.94273\n",
      "[35620]\teval-rmse:3.81301\ttrain-rmse:1.94269\n",
      "[35621]\teval-rmse:3.81442\ttrain-rmse:1.94278\n",
      "[35622]\teval-rmse:3.81477\ttrain-rmse:1.94281\n",
      "[35623]\teval-rmse:3.81494\ttrain-rmse:1.94282\n",
      "[35624]\teval-rmse:3.8165\ttrain-rmse:1.94293\n",
      "[35625]\teval-rmse:3.81588\ttrain-rmse:1.94287\n",
      "[35626]\teval-rmse:3.81447\ttrain-rmse:1.94275\n",
      "[35627]\teval-rmse:3.81478\ttrain-rmse:1.94278\n",
      "[35628]\teval-rmse:3.81359\ttrain-rmse:1.94271\n",
      "[35629]\teval-rmse:3.81325\ttrain-rmse:1.9427\n",
      "[35630]\teval-rmse:3.81441\ttrain-rmse:1.94279\n",
      "[35631]\teval-rmse:3.8148\ttrain-rmse:1.94282\n",
      "[35632]\teval-rmse:3.8131\ttrain-rmse:1.94269\n",
      "[35633]\teval-rmse:3.81461\ttrain-rmse:1.94278\n",
      "[35634]\teval-rmse:3.81433\ttrain-rmse:1.94274\n",
      "[35635]\teval-rmse:3.81454\ttrain-rmse:1.94276\n",
      "[35636]\teval-rmse:3.8147\ttrain-rmse:1.94278\n",
      "[35637]\teval-rmse:3.81644\ttrain-rmse:1.94293\n",
      "[35638]\teval-rmse:3.81784\ttrain-rmse:1.94305\n",
      "[35639]\teval-rmse:3.81717\ttrain-rmse:1.94299\n",
      "[35640]\teval-rmse:3.8158\ttrain-rmse:1.94287\n",
      "[35641]\teval-rmse:3.81536\ttrain-rmse:1.94284\n",
      "[35642]\teval-rmse:3.81345\ttrain-rmse:1.94267\n",
      "[35643]\teval-rmse:3.81428\ttrain-rmse:1.94274\n",
      "[35644]\teval-rmse:3.81545\ttrain-rmse:1.94284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35645]\teval-rmse:3.81355\ttrain-rmse:1.94267\n",
      "[35646]\teval-rmse:3.81473\ttrain-rmse:1.94274\n",
      "[35647]\teval-rmse:3.813\ttrain-rmse:1.94263\n",
      "[35648]\teval-rmse:3.81182\ttrain-rmse:1.94258\n",
      "[35649]\teval-rmse:3.81281\ttrain-rmse:1.94265\n",
      "[35650]\teval-rmse:3.81297\ttrain-rmse:1.94267\n",
      "[35651]\teval-rmse:3.81313\ttrain-rmse:1.94268\n",
      "[35652]\teval-rmse:3.81411\ttrain-rmse:1.94277\n",
      "[35653]\teval-rmse:3.81383\ttrain-rmse:1.94273\n",
      "[35654]\teval-rmse:3.81323\ttrain-rmse:1.9427\n",
      "[35655]\teval-rmse:3.81407\ttrain-rmse:1.94277\n",
      "[35656]\teval-rmse:3.81272\ttrain-rmse:1.94269\n",
      "[35657]\teval-rmse:3.81323\ttrain-rmse:1.94273\n",
      "[35658]\teval-rmse:3.81182\ttrain-rmse:1.94264\n",
      "[35659]\teval-rmse:3.81329\ttrain-rmse:1.94276\n",
      "[35660]\teval-rmse:3.81301\ttrain-rmse:1.94272\n",
      "[35661]\teval-rmse:3.81258\ttrain-rmse:1.9427\n",
      "[35662]\teval-rmse:3.81102\ttrain-rmse:1.94256\n",
      "[35663]\teval-rmse:3.81094\ttrain-rmse:1.94256\n",
      "[35664]\teval-rmse:3.8103\ttrain-rmse:1.94252\n",
      "[35665]\teval-rmse:3.80874\ttrain-rmse:1.9424\n",
      "[35666]\teval-rmse:3.80812\ttrain-rmse:1.94235\n",
      "[35667]\teval-rmse:3.80753\ttrain-rmse:1.94232\n",
      "[35668]\teval-rmse:3.80723\ttrain-rmse:1.94231\n",
      "[35669]\teval-rmse:3.80585\ttrain-rmse:1.94225\n",
      "[35670]\teval-rmse:3.80441\ttrain-rmse:1.9422\n",
      "[35671]\teval-rmse:3.80583\ttrain-rmse:1.94226\n",
      "[35672]\teval-rmse:3.80704\ttrain-rmse:1.94233\n",
      "[35673]\teval-rmse:3.80624\ttrain-rmse:1.94229\n",
      "[35674]\teval-rmse:3.80599\ttrain-rmse:1.94227\n",
      "[35675]\teval-rmse:3.80616\ttrain-rmse:1.94229\n",
      "[35676]\teval-rmse:3.80591\ttrain-rmse:1.94228\n",
      "[35677]\teval-rmse:3.80657\ttrain-rmse:1.94232\n",
      "[35678]\teval-rmse:3.8052\ttrain-rmse:1.94223\n",
      "[35679]\teval-rmse:3.80407\ttrain-rmse:1.9422\n",
      "[35680]\teval-rmse:3.80351\ttrain-rmse:1.94218\n",
      "[35681]\teval-rmse:3.80385\ttrain-rmse:1.9422\n",
      "[35682]\teval-rmse:3.80252\ttrain-rmse:1.94216\n",
      "[35683]\teval-rmse:3.80275\ttrain-rmse:1.94217\n",
      "[35684]\teval-rmse:3.80114\ttrain-rmse:1.94211\n",
      "[35685]\teval-rmse:3.79949\ttrain-rmse:1.94204\n",
      "[35686]\teval-rmse:3.79943\ttrain-rmse:1.94203\n",
      "[35687]\teval-rmse:3.79977\ttrain-rmse:1.94205\n",
      "[35688]\teval-rmse:3.7994\ttrain-rmse:1.94204\n",
      "[35689]\teval-rmse:3.79798\ttrain-rmse:1.94198\n",
      "[35690]\teval-rmse:3.79868\ttrain-rmse:1.94201\n",
      "[35691]\teval-rmse:3.79841\ttrain-rmse:1.942\n",
      "[35692]\teval-rmse:3.79677\ttrain-rmse:1.94193\n",
      "[35693]\teval-rmse:3.79826\ttrain-rmse:1.94199\n",
      "[35694]\teval-rmse:3.79948\ttrain-rmse:1.94204\n",
      "[35695]\teval-rmse:3.8009\ttrain-rmse:1.94211\n",
      "[35696]\teval-rmse:3.80264\ttrain-rmse:1.94215\n",
      "[35697]\teval-rmse:3.80396\ttrain-rmse:1.94223\n",
      "[35698]\teval-rmse:3.80569\ttrain-rmse:1.94229\n",
      "[35699]\teval-rmse:3.80636\ttrain-rmse:1.94232\n",
      "[35700]\teval-rmse:3.80579\ttrain-rmse:1.94228\n",
      "[35701]\teval-rmse:3.8054\ttrain-rmse:1.94226\n",
      "[35702]\teval-rmse:3.80539\ttrain-rmse:1.94226\n",
      "[35703]\teval-rmse:3.80462\ttrain-rmse:1.94221\n",
      "[35704]\teval-rmse:3.80574\ttrain-rmse:1.94228\n",
      "[35705]\teval-rmse:3.80747\ttrain-rmse:1.94235\n",
      "[35706]\teval-rmse:3.80697\ttrain-rmse:1.94231\n",
      "[35707]\teval-rmse:3.80566\ttrain-rmse:1.94223\n",
      "[35708]\teval-rmse:3.80582\ttrain-rmse:1.94224\n",
      "[35709]\teval-rmse:3.80473\ttrain-rmse:1.94217\n",
      "[35710]\teval-rmse:3.80339\ttrain-rmse:1.94212\n",
      "[35711]\teval-rmse:3.80491\ttrain-rmse:1.94218\n",
      "[35712]\teval-rmse:3.80646\ttrain-rmse:1.94224\n",
      "[35713]\teval-rmse:3.80676\ttrain-rmse:1.94226\n",
      "[35714]\teval-rmse:3.80514\ttrain-rmse:1.94216\n",
      "[35715]\teval-rmse:3.80468\ttrain-rmse:1.94214\n",
      "[35716]\teval-rmse:3.80301\ttrain-rmse:1.94207\n",
      "[35717]\teval-rmse:3.80457\ttrain-rmse:1.94213\n",
      "[35718]\teval-rmse:3.80591\ttrain-rmse:1.94221\n",
      "[35719]\teval-rmse:3.80649\ttrain-rmse:1.94224\n",
      "[35720]\teval-rmse:3.80623\ttrain-rmse:1.94223\n",
      "[35721]\teval-rmse:3.80622\ttrain-rmse:1.94223\n",
      "[35722]\teval-rmse:3.80576\ttrain-rmse:1.94221\n",
      "[35723]\teval-rmse:3.80749\ttrain-rmse:1.94227\n",
      "[35724]\teval-rmse:3.8067\ttrain-rmse:1.94223\n",
      "[35725]\teval-rmse:3.80667\ttrain-rmse:1.94223\n",
      "[35726]\teval-rmse:3.80666\ttrain-rmse:1.94223\n",
      "[35727]\teval-rmse:3.80519\ttrain-rmse:1.94217\n",
      "[35728]\teval-rmse:3.80355\ttrain-rmse:1.94208\n",
      "[35729]\teval-rmse:3.80402\ttrain-rmse:1.9421\n",
      "[35730]\teval-rmse:3.80363\ttrain-rmse:1.94209\n",
      "[35731]\teval-rmse:3.80401\ttrain-rmse:1.9421\n",
      "[35732]\teval-rmse:3.80354\ttrain-rmse:1.94208\n",
      "[35733]\teval-rmse:3.8049\ttrain-rmse:1.94215\n",
      "[35734]\teval-rmse:3.80466\ttrain-rmse:1.94212\n",
      "[35735]\teval-rmse:3.80639\ttrain-rmse:1.94218\n",
      "[35736]\teval-rmse:3.80502\ttrain-rmse:1.94212\n",
      "[35737]\teval-rmse:3.80442\ttrain-rmse:1.9421\n",
      "[35738]\teval-rmse:3.80437\ttrain-rmse:1.9421\n",
      "[35739]\teval-rmse:3.80556\ttrain-rmse:1.94214\n",
      "[35740]\teval-rmse:3.80532\ttrain-rmse:1.94213\n",
      "[35741]\teval-rmse:3.80363\ttrain-rmse:1.94204\n",
      "[35742]\teval-rmse:3.80334\ttrain-rmse:1.94203\n",
      "[35743]\teval-rmse:3.8031\ttrain-rmse:1.942\n",
      "[35744]\teval-rmse:3.80327\ttrain-rmse:1.94201\n",
      "[35745]\teval-rmse:3.80461\ttrain-rmse:1.94206\n",
      "[35746]\teval-rmse:3.80563\ttrain-rmse:1.94212\n",
      "[35747]\teval-rmse:3.80608\ttrain-rmse:1.94213\n",
      "[35748]\teval-rmse:3.80725\ttrain-rmse:1.9422\n",
      "[35749]\teval-rmse:3.80846\ttrain-rmse:1.94228\n",
      "[35750]\teval-rmse:3.80968\ttrain-rmse:1.94237\n",
      "[35751]\teval-rmse:3.80936\ttrain-rmse:1.94236\n",
      "[35752]\teval-rmse:3.80911\ttrain-rmse:1.94234\n",
      "[35753]\teval-rmse:3.80704\ttrain-rmse:1.94221\n",
      "[35754]\teval-rmse:3.80837\ttrain-rmse:1.94227\n",
      "[35755]\teval-rmse:3.80957\ttrain-rmse:1.94235\n",
      "[35756]\teval-rmse:3.80899\ttrain-rmse:1.94232\n",
      "[35757]\teval-rmse:3.81049\ttrain-rmse:1.94243\n",
      "[35758]\teval-rmse:3.80895\ttrain-rmse:1.94232\n",
      "[35759]\teval-rmse:3.81044\ttrain-rmse:1.94242\n",
      "[35760]\teval-rmse:3.80986\ttrain-rmse:1.94239\n",
      "[35761]\teval-rmse:3.80814\ttrain-rmse:1.94227\n",
      "[35762]\teval-rmse:3.80668\ttrain-rmse:1.94222\n",
      "[35763]\teval-rmse:3.80612\ttrain-rmse:1.94219\n",
      "[35764]\teval-rmse:3.80681\ttrain-rmse:1.94222\n",
      "[35765]\teval-rmse:3.8083\ttrain-rmse:1.94229\n",
      "[35766]\teval-rmse:3.80846\ttrain-rmse:1.9423\n",
      "[35767]\teval-rmse:3.80861\ttrain-rmse:1.94231\n",
      "[35768]\teval-rmse:3.8083\ttrain-rmse:1.9423\n",
      "[35769]\teval-rmse:3.80842\ttrain-rmse:1.94231\n",
      "[35770]\teval-rmse:3.80975\ttrain-rmse:1.94238\n",
      "[35771]\teval-rmse:3.80912\ttrain-rmse:1.94234\n",
      "[35772]\teval-rmse:3.81047\ttrain-rmse:1.94243\n",
      "[35773]\teval-rmse:3.80968\ttrain-rmse:1.94237\n",
      "[35774]\teval-rmse:3.80836\ttrain-rmse:1.9423\n",
      "[35775]\teval-rmse:3.80875\ttrain-rmse:1.94233\n",
      "[35776]\teval-rmse:3.80885\ttrain-rmse:1.94234\n",
      "[35777]\teval-rmse:3.81027\ttrain-rmse:1.9424\n",
      "[35778]\teval-rmse:3.81042\ttrain-rmse:1.94241\n",
      "[35779]\teval-rmse:3.8087\ttrain-rmse:1.94229\n",
      "[35780]\teval-rmse:3.80701\ttrain-rmse:1.94221\n",
      "[35781]\teval-rmse:3.80521\ttrain-rmse:1.94211\n",
      "[35782]\teval-rmse:3.80483\ttrain-rmse:1.94209\n",
      "[35783]\teval-rmse:3.80529\ttrain-rmse:1.94211\n",
      "[35784]\teval-rmse:3.80677\ttrain-rmse:1.9422\n",
      "[35785]\teval-rmse:3.8083\ttrain-rmse:1.94226\n",
      "[35786]\teval-rmse:3.80663\ttrain-rmse:1.94215\n",
      "[35787]\teval-rmse:3.80549\ttrain-rmse:1.94211\n",
      "[35788]\teval-rmse:3.80414\ttrain-rmse:1.94206\n",
      "[35789]\teval-rmse:3.80415\ttrain-rmse:1.94206\n",
      "[35790]\teval-rmse:3.80413\ttrain-rmse:1.94206\n",
      "[35791]\teval-rmse:3.80556\ttrain-rmse:1.94215\n",
      "[35792]\teval-rmse:3.80494\ttrain-rmse:1.94211\n",
      "[35793]\teval-rmse:3.8054\ttrain-rmse:1.94214\n",
      "[35794]\teval-rmse:3.80478\ttrain-rmse:1.9421\n",
      "[35795]\teval-rmse:3.80633\ttrain-rmse:1.94217\n",
      "[35796]\teval-rmse:3.80495\ttrain-rmse:1.94209\n",
      "[35797]\teval-rmse:3.80331\ttrain-rmse:1.942\n",
      "[35798]\teval-rmse:3.80293\ttrain-rmse:1.94199\n",
      "[35799]\teval-rmse:3.80248\ttrain-rmse:1.94196\n",
      "[35800]\teval-rmse:3.80226\ttrain-rmse:1.94193\n",
      "[35801]\teval-rmse:3.80332\ttrain-rmse:1.94199\n",
      "[35802]\teval-rmse:3.80471\ttrain-rmse:1.94206\n",
      "[35803]\teval-rmse:3.80447\ttrain-rmse:1.94206\n",
      "[35804]\teval-rmse:3.80304\ttrain-rmse:1.94201\n",
      "[35805]\teval-rmse:3.80275\ttrain-rmse:1.942\n",
      "[35806]\teval-rmse:3.80237\ttrain-rmse:1.94199\n",
      "[35807]\teval-rmse:3.80342\ttrain-rmse:1.94205\n",
      "[35808]\teval-rmse:3.80282\ttrain-rmse:1.94203\n",
      "[35809]\teval-rmse:3.80259\ttrain-rmse:1.942\n",
      "[35810]\teval-rmse:3.8022\ttrain-rmse:1.94199\n",
      "[35811]\teval-rmse:3.80257\ttrain-rmse:1.942\n",
      "[35812]\teval-rmse:3.80179\ttrain-rmse:1.94198\n",
      "[35813]\teval-rmse:3.80067\ttrain-rmse:1.94194\n",
      "[35814]\teval-rmse:3.7994\ttrain-rmse:1.94191\n",
      "[35815]\teval-rmse:3.79758\ttrain-rmse:1.94184\n",
      "[35816]\teval-rmse:3.79599\ttrain-rmse:1.94178\n",
      "[35817]\teval-rmse:3.79578\ttrain-rmse:1.94176\n",
      "[35818]\teval-rmse:3.79685\ttrain-rmse:1.94179\n",
      "[35819]\teval-rmse:3.79664\ttrain-rmse:1.94176\n",
      "[35820]\teval-rmse:3.79698\ttrain-rmse:1.94178\n",
      "[35821]\teval-rmse:3.79559\ttrain-rmse:1.94175\n",
      "[35822]\teval-rmse:3.79592\ttrain-rmse:1.94176\n",
      "[35823]\teval-rmse:3.79702\ttrain-rmse:1.9418\n",
      "[35824]\teval-rmse:3.79772\ttrain-rmse:1.94183\n",
      "[35825]\teval-rmse:3.79643\ttrain-rmse:1.94178\n",
      "[35826]\teval-rmse:3.7946\ttrain-rmse:1.94172\n",
      "[35827]\teval-rmse:3.79478\ttrain-rmse:1.94172\n",
      "[35828]\teval-rmse:3.79636\ttrain-rmse:1.94174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35829]\teval-rmse:3.79769\ttrain-rmse:1.94179\n",
      "[35830]\teval-rmse:3.79691\ttrain-rmse:1.94176\n",
      "[35831]\teval-rmse:3.79665\ttrain-rmse:1.94175\n",
      "[35832]\teval-rmse:3.79736\ttrain-rmse:1.94178\n",
      "[35833]\teval-rmse:3.79855\ttrain-rmse:1.94181\n",
      "[35834]\teval-rmse:3.79797\ttrain-rmse:1.9418\n",
      "[35835]\teval-rmse:3.79776\ttrain-rmse:1.94177\n",
      "[35836]\teval-rmse:3.79819\ttrain-rmse:1.94179\n",
      "[35837]\teval-rmse:3.79691\ttrain-rmse:1.94174\n",
      "[35838]\teval-rmse:3.7967\ttrain-rmse:1.94173\n",
      "[35839]\teval-rmse:3.79696\ttrain-rmse:1.94174\n",
      "[35840]\teval-rmse:3.79796\ttrain-rmse:1.94179\n",
      "[35841]\teval-rmse:3.79855\ttrain-rmse:1.94181\n",
      "[35842]\teval-rmse:3.79851\ttrain-rmse:1.94181\n",
      "[35843]\teval-rmse:3.79953\ttrain-rmse:1.94186\n",
      "[35844]\teval-rmse:3.7993\ttrain-rmse:1.94185\n",
      "[35845]\teval-rmse:3.80031\ttrain-rmse:1.9419\n",
      "[35846]\teval-rmse:3.80009\ttrain-rmse:1.9419\n",
      "[35847]\teval-rmse:3.79953\ttrain-rmse:1.94188\n",
      "[35848]\teval-rmse:3.7979\ttrain-rmse:1.94181\n",
      "[35849]\teval-rmse:3.79902\ttrain-rmse:1.94186\n",
      "[35850]\teval-rmse:3.80028\ttrain-rmse:1.94193\n",
      "[35851]\teval-rmse:3.80147\ttrain-rmse:1.942\n",
      "[35852]\teval-rmse:3.80145\ttrain-rmse:1.942\n",
      "[35853]\teval-rmse:3.8018\ttrain-rmse:1.94201\n",
      "[35854]\teval-rmse:3.80337\ttrain-rmse:1.94205\n",
      "[35855]\teval-rmse:3.80352\ttrain-rmse:1.94206\n",
      "[35856]\teval-rmse:3.80477\ttrain-rmse:1.94215\n",
      "[35857]\teval-rmse:3.80342\ttrain-rmse:1.9421\n",
      "[35858]\teval-rmse:3.80297\ttrain-rmse:1.94208\n",
      "[35859]\teval-rmse:3.804\ttrain-rmse:1.94216\n",
      "[35860]\teval-rmse:3.80245\ttrain-rmse:1.94206\n",
      "[35861]\teval-rmse:3.80165\ttrain-rmse:1.94201\n",
      "[35862]\teval-rmse:3.80234\ttrain-rmse:1.94204\n",
      "[35863]\teval-rmse:3.80189\ttrain-rmse:1.94202\n",
      "[35864]\teval-rmse:3.80208\ttrain-rmse:1.94203\n",
      "[35865]\teval-rmse:3.80241\ttrain-rmse:1.94205\n",
      "[35866]\teval-rmse:3.80268\ttrain-rmse:1.94207\n",
      "[35867]\teval-rmse:3.80084\ttrain-rmse:1.94195\n",
      "[35868]\teval-rmse:3.80152\ttrain-rmse:1.94199\n",
      "[35869]\teval-rmse:3.80301\ttrain-rmse:1.94208\n",
      "[35870]\teval-rmse:3.80297\ttrain-rmse:1.94207\n",
      "[35871]\teval-rmse:3.80334\ttrain-rmse:1.9421\n",
      "[35872]\teval-rmse:3.80452\ttrain-rmse:1.94218\n",
      "[35873]\teval-rmse:3.80389\ttrain-rmse:1.94213\n",
      "[35874]\teval-rmse:3.80413\ttrain-rmse:1.94215\n",
      "[35875]\teval-rmse:3.80449\ttrain-rmse:1.94217\n",
      "[35876]\teval-rmse:3.80298\ttrain-rmse:1.94208\n",
      "[35877]\teval-rmse:3.80114\ttrain-rmse:1.94197\n",
      "[35878]\teval-rmse:3.80067\ttrain-rmse:1.94195\n",
      "[35879]\teval-rmse:3.79907\ttrain-rmse:1.94186\n",
      "[35880]\teval-rmse:3.80057\ttrain-rmse:1.94193\n",
      "[35881]\teval-rmse:3.79946\ttrain-rmse:1.9419\n",
      "[35882]\teval-rmse:3.79805\ttrain-rmse:1.94184\n",
      "[35883]\teval-rmse:3.79646\ttrain-rmse:1.94177\n",
      "[35884]\teval-rmse:3.79467\ttrain-rmse:1.9417\n",
      "[35885]\teval-rmse:3.79566\ttrain-rmse:1.94174\n",
      "[35886]\teval-rmse:3.79511\ttrain-rmse:1.94173\n",
      "[35887]\teval-rmse:3.79685\ttrain-rmse:1.94176\n",
      "[35888]\teval-rmse:3.79728\ttrain-rmse:1.94178\n",
      "[35889]\teval-rmse:3.79707\ttrain-rmse:1.94177\n",
      "[35890]\teval-rmse:3.7973\ttrain-rmse:1.94178\n",
      "[35891]\teval-rmse:3.79566\ttrain-rmse:1.94172\n",
      "[35892]\teval-rmse:3.79565\ttrain-rmse:1.94172\n",
      "[35893]\teval-rmse:3.79545\ttrain-rmse:1.94171\n",
      "[35894]\teval-rmse:3.79525\ttrain-rmse:1.94168\n",
      "[35895]\teval-rmse:3.79499\ttrain-rmse:1.94168\n",
      "[35896]\teval-rmse:3.79511\ttrain-rmse:1.94168\n",
      "[35897]\teval-rmse:3.79632\ttrain-rmse:1.94173\n",
      "[35898]\teval-rmse:3.79652\ttrain-rmse:1.94173\n",
      "[35899]\teval-rmse:3.79631\ttrain-rmse:1.94171\n",
      "[35900]\teval-rmse:3.79744\ttrain-rmse:1.94175\n",
      "[35901]\teval-rmse:3.79723\ttrain-rmse:1.94175\n",
      "[35902]\teval-rmse:3.79598\ttrain-rmse:1.9417\n",
      "[35903]\teval-rmse:3.79474\ttrain-rmse:1.94169\n",
      "[35904]\teval-rmse:3.79522\ttrain-rmse:1.94171\n",
      "[35905]\teval-rmse:3.79666\ttrain-rmse:1.94174\n",
      "[35906]\teval-rmse:3.7969\ttrain-rmse:1.94175\n",
      "[35907]\teval-rmse:3.79655\ttrain-rmse:1.94174\n",
      "[35908]\teval-rmse:3.79654\ttrain-rmse:1.94174\n",
      "[35909]\teval-rmse:3.79704\ttrain-rmse:1.94176\n",
      "[35910]\teval-rmse:3.79647\ttrain-rmse:1.94175\n",
      "[35911]\teval-rmse:3.79765\ttrain-rmse:1.9418\n",
      "[35912]\teval-rmse:3.79729\ttrain-rmse:1.94179\n",
      "[35913]\teval-rmse:3.7977\ttrain-rmse:1.94181\n",
      "[35914]\teval-rmse:3.79727\ttrain-rmse:1.9418\n",
      "[35915]\teval-rmse:3.79682\ttrain-rmse:1.94178\n",
      "[35916]\teval-rmse:3.79855\ttrain-rmse:1.94182\n",
      "[35917]\teval-rmse:3.80007\ttrain-rmse:1.94186\n",
      "[35918]\teval-rmse:3.79963\ttrain-rmse:1.94185\n",
      "[35919]\teval-rmse:3.79812\ttrain-rmse:1.94177\n",
      "[35920]\teval-rmse:3.79858\ttrain-rmse:1.94179\n",
      "[35921]\teval-rmse:3.79852\ttrain-rmse:1.94179\n",
      "[35922]\teval-rmse:3.79667\ttrain-rmse:1.9417\n",
      "[35923]\teval-rmse:3.79646\ttrain-rmse:1.94168\n",
      "[35924]\teval-rmse:3.79766\ttrain-rmse:1.94171\n",
      "[35925]\teval-rmse:3.79797\ttrain-rmse:1.94172\n",
      "[35926]\teval-rmse:3.79845\ttrain-rmse:1.94174\n",
      "[35927]\teval-rmse:3.79808\ttrain-rmse:1.94173\n",
      "[35928]\teval-rmse:3.79822\ttrain-rmse:1.94174\n",
      "[35929]\teval-rmse:3.79786\ttrain-rmse:1.94173\n",
      "[35930]\teval-rmse:3.79726\ttrain-rmse:1.94172\n",
      "[35931]\teval-rmse:3.79564\ttrain-rmse:1.94165\n",
      "[35932]\teval-rmse:3.79425\ttrain-rmse:1.94163\n",
      "[35933]\teval-rmse:3.79248\ttrain-rmse:1.94158\n",
      "[35934]\teval-rmse:3.79367\ttrain-rmse:1.9416\n",
      "[35935]\teval-rmse:3.79343\ttrain-rmse:1.94159\n",
      "[35936]\teval-rmse:3.79287\ttrain-rmse:1.94158\n",
      "[35937]\teval-rmse:3.79126\ttrain-rmse:1.94154\n",
      "[35938]\teval-rmse:3.79108\ttrain-rmse:1.94152\n",
      "[35939]\teval-rmse:3.78979\ttrain-rmse:1.94151\n",
      "[35940]\teval-rmse:3.78931\ttrain-rmse:1.94151\n",
      "[35941]\teval-rmse:3.7888\ttrain-rmse:1.9415\n",
      "[35942]\teval-rmse:3.78842\ttrain-rmse:1.9415\n",
      "[35943]\teval-rmse:3.79016\ttrain-rmse:1.94151\n",
      "[35944]\teval-rmse:3.79057\ttrain-rmse:1.94151\n",
      "[35945]\teval-rmse:3.78878\ttrain-rmse:1.94148\n",
      "[35946]\teval-rmse:3.79054\ttrain-rmse:1.94149\n",
      "[35947]\teval-rmse:3.78919\ttrain-rmse:1.94147\n",
      "[35948]\teval-rmse:3.78941\ttrain-rmse:1.94147\n",
      "[35949]\teval-rmse:3.78967\ttrain-rmse:1.94148\n",
      "[35950]\teval-rmse:3.79\ttrain-rmse:1.94148\n",
      "[35951]\teval-rmse:3.78961\ttrain-rmse:1.94148\n",
      "[35952]\teval-rmse:3.78911\ttrain-rmse:1.94147\n",
      "[35953]\teval-rmse:3.79045\ttrain-rmse:1.94149\n",
      "[35954]\teval-rmse:3.79027\ttrain-rmse:1.94149\n",
      "[35955]\teval-rmse:3.78904\ttrain-rmse:1.94147\n",
      "[35956]\teval-rmse:3.79079\ttrain-rmse:1.94148\n",
      "[35957]\teval-rmse:3.79132\ttrain-rmse:1.94149\n",
      "[35958]\teval-rmse:3.79308\ttrain-rmse:1.94153\n",
      "[35959]\teval-rmse:3.79289\ttrain-rmse:1.94152\n",
      "[35960]\teval-rmse:3.79264\ttrain-rmse:1.94152\n",
      "[35961]\teval-rmse:3.7924\ttrain-rmse:1.94152\n",
      "[35962]\teval-rmse:3.79197\ttrain-rmse:1.94151\n",
      "[35963]\teval-rmse:3.79214\ttrain-rmse:1.94152\n",
      "[35964]\teval-rmse:3.79257\ttrain-rmse:1.94152\n",
      "[35965]\teval-rmse:3.79204\ttrain-rmse:1.94151\n",
      "[35966]\teval-rmse:3.7917\ttrain-rmse:1.94151\n",
      "[35967]\teval-rmse:3.79215\ttrain-rmse:1.94152\n",
      "[35968]\teval-rmse:3.7925\ttrain-rmse:1.94153\n",
      "[35969]\teval-rmse:3.79285\ttrain-rmse:1.94154\n",
      "[35970]\teval-rmse:3.79318\ttrain-rmse:1.94155\n",
      "[35971]\teval-rmse:3.79261\ttrain-rmse:1.94153\n",
      "[35972]\teval-rmse:3.7922\ttrain-rmse:1.94152\n",
      "[35973]\teval-rmse:3.79231\ttrain-rmse:1.94152\n",
      "[35974]\teval-rmse:3.79277\ttrain-rmse:1.94154\n",
      "[35975]\teval-rmse:3.79329\ttrain-rmse:1.94155\n",
      "[35976]\teval-rmse:3.79192\ttrain-rmse:1.94152\n",
      "[35977]\teval-rmse:3.79348\ttrain-rmse:1.94155\n",
      "[35978]\teval-rmse:3.79329\ttrain-rmse:1.94153\n",
      "[35979]\teval-rmse:3.79374\ttrain-rmse:1.94154\n",
      "[35980]\teval-rmse:3.79516\ttrain-rmse:1.94159\n",
      "[35981]\teval-rmse:3.79568\ttrain-rmse:1.94161\n",
      "[35982]\teval-rmse:3.79616\ttrain-rmse:1.94163\n",
      "[35983]\teval-rmse:3.79478\ttrain-rmse:1.94157\n",
      "[35984]\teval-rmse:3.79526\ttrain-rmse:1.94159\n",
      "[35985]\teval-rmse:3.79642\ttrain-rmse:1.94163\n",
      "[35986]\teval-rmse:3.79616\ttrain-rmse:1.94162\n",
      "[35987]\teval-rmse:3.79581\ttrain-rmse:1.94162\n",
      "[35988]\teval-rmse:3.79432\ttrain-rmse:1.94157\n",
      "[35989]\teval-rmse:3.79445\ttrain-rmse:1.94157\n",
      "[35990]\teval-rmse:3.79318\ttrain-rmse:1.94154\n",
      "[35991]\teval-rmse:3.79331\ttrain-rmse:1.94154\n",
      "[35992]\teval-rmse:3.7938\ttrain-rmse:1.94156\n",
      "[35993]\teval-rmse:3.79337\ttrain-rmse:1.94155\n",
      "[35994]\teval-rmse:3.79385\ttrain-rmse:1.94156\n",
      "[35995]\teval-rmse:3.79226\ttrain-rmse:1.94152\n",
      "[35996]\teval-rmse:3.79203\ttrain-rmse:1.94152\n",
      "[35997]\teval-rmse:3.79078\ttrain-rmse:1.94151\n",
      "[35998]\teval-rmse:3.79037\ttrain-rmse:1.9415\n",
      "[35999]\teval-rmse:3.79156\ttrain-rmse:1.94152\n",
      "[36000]\teval-rmse:3.79153\ttrain-rmse:1.94152\n",
      "[36001]\teval-rmse:3.78999\ttrain-rmse:1.94149\n",
      "[36002]\teval-rmse:3.79158\ttrain-rmse:1.94152\n",
      "[36003]\teval-rmse:3.79155\ttrain-rmse:1.94152\n",
      "[36004]\teval-rmse:3.79199\ttrain-rmse:1.94154\n",
      "[36005]\teval-rmse:3.7927\ttrain-rmse:1.94154\n",
      "[36006]\teval-rmse:3.79246\ttrain-rmse:1.94153\n",
      "[36007]\teval-rmse:3.79345\ttrain-rmse:1.94156\n",
      "[36008]\teval-rmse:3.79325\ttrain-rmse:1.94156\n",
      "[36009]\teval-rmse:3.7937\ttrain-rmse:1.94158\n",
      "[36010]\teval-rmse:3.79246\ttrain-rmse:1.94154\n",
      "[36011]\teval-rmse:3.7942\ttrain-rmse:1.94156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36012]\teval-rmse:3.79489\ttrain-rmse:1.94156\n",
      "[36013]\teval-rmse:3.79623\ttrain-rmse:1.94159\n",
      "[36014]\teval-rmse:3.79569\ttrain-rmse:1.94158\n",
      "[36015]\teval-rmse:3.79713\ttrain-rmse:1.94163\n",
      "[36016]\teval-rmse:3.79677\ttrain-rmse:1.94162\n",
      "[36017]\teval-rmse:3.79651\ttrain-rmse:1.94162\n",
      "[36018]\teval-rmse:3.79625\ttrain-rmse:1.94161\n",
      "[36019]\teval-rmse:3.79775\ttrain-rmse:1.94168\n",
      "[36020]\teval-rmse:3.79754\ttrain-rmse:1.94165\n",
      "[36021]\teval-rmse:3.79804\ttrain-rmse:1.94168\n",
      "[36022]\teval-rmse:3.79855\ttrain-rmse:1.9417\n",
      "[36023]\teval-rmse:3.80007\ttrain-rmse:1.94173\n",
      "[36024]\teval-rmse:3.80052\ttrain-rmse:1.94175\n",
      "[36025]\teval-rmse:3.80087\ttrain-rmse:1.94176\n",
      "[36026]\teval-rmse:3.79922\ttrain-rmse:1.94168\n",
      "[36027]\teval-rmse:3.80096\ttrain-rmse:1.94172\n",
      "[36028]\teval-rmse:3.80068\ttrain-rmse:1.94171\n",
      "[36029]\teval-rmse:3.79927\ttrain-rmse:1.94165\n",
      "[36030]\teval-rmse:3.79941\ttrain-rmse:1.94166\n",
      "[36031]\teval-rmse:3.798\ttrain-rmse:1.94162\n",
      "[36032]\teval-rmse:3.79661\ttrain-rmse:1.94158\n",
      "[36033]\teval-rmse:3.79585\ttrain-rmse:1.94156\n",
      "[36034]\teval-rmse:3.79559\ttrain-rmse:1.94155\n",
      "[36035]\teval-rmse:3.79574\ttrain-rmse:1.94156\n",
      "[36036]\teval-rmse:3.79499\ttrain-rmse:1.94155\n",
      "[36037]\teval-rmse:3.79367\ttrain-rmse:1.94151\n",
      "[36038]\teval-rmse:3.79542\ttrain-rmse:1.94153\n",
      "[36039]\teval-rmse:3.79692\ttrain-rmse:1.94155\n",
      "[36040]\teval-rmse:3.7985\ttrain-rmse:1.94158\n",
      "[36041]\teval-rmse:3.79846\ttrain-rmse:1.94158\n",
      "[36042]\teval-rmse:3.79819\ttrain-rmse:1.94157\n",
      "[36043]\teval-rmse:3.79694\ttrain-rmse:1.94155\n",
      "[36044]\teval-rmse:3.79838\ttrain-rmse:1.94157\n",
      "[36045]\teval-rmse:3.79802\ttrain-rmse:1.94156\n",
      "[36046]\teval-rmse:3.79911\ttrain-rmse:1.94161\n",
      "[36047]\teval-rmse:3.79875\ttrain-rmse:1.9416\n",
      "[36048]\teval-rmse:3.79821\ttrain-rmse:1.94158\n",
      "[36049]\teval-rmse:3.7977\ttrain-rmse:1.94157\n",
      "[36050]\teval-rmse:3.79839\ttrain-rmse:1.94158\n",
      "[36051]\teval-rmse:3.79997\ttrain-rmse:1.94161\n",
      "[36052]\teval-rmse:3.80034\ttrain-rmse:1.94163\n",
      "[36053]\teval-rmse:3.80049\ttrain-rmse:1.94164\n",
      "[36054]\teval-rmse:3.79991\ttrain-rmse:1.94162\n",
      "[36055]\teval-rmse:3.79963\ttrain-rmse:1.94162\n",
      "[36056]\teval-rmse:3.79977\ttrain-rmse:1.94162\n",
      "[36057]\teval-rmse:3.80028\ttrain-rmse:1.94164\n",
      "[36058]\teval-rmse:3.79865\ttrain-rmse:1.94157\n",
      "[36059]\teval-rmse:3.80004\ttrain-rmse:1.94162\n",
      "[36060]\teval-rmse:3.79852\ttrain-rmse:1.94156\n",
      "[36061]\teval-rmse:3.79967\ttrain-rmse:1.94161\n",
      "[36062]\teval-rmse:3.80068\ttrain-rmse:1.94166\n",
      "[36063]\teval-rmse:3.80119\ttrain-rmse:1.94169\n",
      "[36064]\teval-rmse:3.79992\ttrain-rmse:1.94165\n",
      "[36065]\teval-rmse:3.80126\ttrain-rmse:1.94172\n",
      "[36066]\teval-rmse:3.79999\ttrain-rmse:1.94169\n",
      "[36067]\teval-rmse:3.80172\ttrain-rmse:1.94174\n",
      "[36068]\teval-rmse:3.80224\ttrain-rmse:1.94175\n",
      "[36069]\teval-rmse:3.80089\ttrain-rmse:1.94171\n",
      "[36070]\teval-rmse:3.79912\ttrain-rmse:1.94162\n",
      "[36071]\teval-rmse:3.79884\ttrain-rmse:1.94162\n",
      "[36072]\teval-rmse:3.79751\ttrain-rmse:1.94156\n",
      "[36073]\teval-rmse:3.79694\ttrain-rmse:1.94155\n",
      "[36074]\teval-rmse:3.7957\ttrain-rmse:1.94151\n",
      "[36075]\teval-rmse:3.79607\ttrain-rmse:1.94153\n",
      "[36076]\teval-rmse:3.79521\ttrain-rmse:1.9415\n",
      "[36077]\teval-rmse:3.79543\ttrain-rmse:1.94151\n",
      "[36078]\teval-rmse:3.79659\ttrain-rmse:1.94155\n",
      "[36079]\teval-rmse:3.79759\ttrain-rmse:1.94159\n",
      "[36080]\teval-rmse:3.79741\ttrain-rmse:1.94159\n",
      "[36081]\teval-rmse:3.79786\ttrain-rmse:1.9416\n",
      "[36082]\teval-rmse:3.7976\ttrain-rmse:1.9416\n",
      "[36083]\teval-rmse:3.79579\ttrain-rmse:1.94153\n",
      "[36084]\teval-rmse:3.79646\ttrain-rmse:1.94155\n",
      "[36085]\teval-rmse:3.79483\ttrain-rmse:1.94149\n",
      "[36086]\teval-rmse:3.79617\ttrain-rmse:1.94153\n",
      "[36087]\teval-rmse:3.79791\ttrain-rmse:1.94156\n",
      "[36088]\teval-rmse:3.79833\ttrain-rmse:1.94158\n",
      "[36089]\teval-rmse:3.79676\ttrain-rmse:1.94155\n",
      "[36090]\teval-rmse:3.79625\ttrain-rmse:1.94154\n",
      "[36091]\teval-rmse:3.79425\ttrain-rmse:1.94149\n",
      "[36092]\teval-rmse:3.794\ttrain-rmse:1.94149\n",
      "[36093]\teval-rmse:3.7924\ttrain-rmse:1.94145\n",
      "[36094]\teval-rmse:3.79288\ttrain-rmse:1.94146\n",
      "[36095]\teval-rmse:3.79312\ttrain-rmse:1.94147\n",
      "[36096]\teval-rmse:3.79135\ttrain-rmse:1.94144\n",
      "[36097]\teval-rmse:3.79187\ttrain-rmse:1.94144\n",
      "[36098]\teval-rmse:3.79226\ttrain-rmse:1.94145\n",
      "[36099]\teval-rmse:3.79397\ttrain-rmse:1.94148\n",
      "[36100]\teval-rmse:3.79417\ttrain-rmse:1.94149\n",
      "[36101]\teval-rmse:3.7943\ttrain-rmse:1.94149\n",
      "[36102]\teval-rmse:3.79589\ttrain-rmse:1.94153\n",
      "[36103]\teval-rmse:3.79715\ttrain-rmse:1.94157\n",
      "[36104]\teval-rmse:3.79587\ttrain-rmse:1.94153\n",
      "[36105]\teval-rmse:3.79431\ttrain-rmse:1.94149\n",
      "[36106]\teval-rmse:3.79406\ttrain-rmse:1.94149\n",
      "[36107]\teval-rmse:3.79546\ttrain-rmse:1.94152\n",
      "[36108]\teval-rmse:3.79487\ttrain-rmse:1.94151\n",
      "[36109]\teval-rmse:3.7938\ttrain-rmse:1.9415\n",
      "[36110]\teval-rmse:3.79362\ttrain-rmse:1.94147\n",
      "[36111]\teval-rmse:3.79343\ttrain-rmse:1.94145\n",
      "[36112]\teval-rmse:3.79388\ttrain-rmse:1.94146\n",
      "[36113]\teval-rmse:3.79281\ttrain-rmse:1.94145\n",
      "[36114]\teval-rmse:3.79398\ttrain-rmse:1.94147\n",
      "[36115]\teval-rmse:3.7952\ttrain-rmse:1.94151\n",
      "[36116]\teval-rmse:3.79464\ttrain-rmse:1.9415\n",
      "[36117]\teval-rmse:3.7931\ttrain-rmse:1.94145\n",
      "[36118]\teval-rmse:3.7938\ttrain-rmse:1.94146\n",
      "[36119]\teval-rmse:3.7934\ttrain-rmse:1.94145\n",
      "[36120]\teval-rmse:3.79492\ttrain-rmse:1.94149\n",
      "[36121]\teval-rmse:3.79385\ttrain-rmse:1.94148\n",
      "[36122]\teval-rmse:3.79365\ttrain-rmse:1.94148\n",
      "[36123]\teval-rmse:3.79362\ttrain-rmse:1.94148\n",
      "[36124]\teval-rmse:3.79337\ttrain-rmse:1.94147\n",
      "[36125]\teval-rmse:3.79511\ttrain-rmse:1.9415\n",
      "[36126]\teval-rmse:3.79613\ttrain-rmse:1.94153\n",
      "[36127]\teval-rmse:3.79769\ttrain-rmse:1.94158\n",
      "[36128]\teval-rmse:3.79718\ttrain-rmse:1.94156\n",
      "[36129]\teval-rmse:3.79661\ttrain-rmse:1.94155\n",
      "[36130]\teval-rmse:3.79719\ttrain-rmse:1.94158\n",
      "[36131]\teval-rmse:3.79772\ttrain-rmse:1.94159\n",
      "[36132]\teval-rmse:3.79647\ttrain-rmse:1.94157\n",
      "[36133]\teval-rmse:3.79691\ttrain-rmse:1.94159\n",
      "[36134]\teval-rmse:3.79688\ttrain-rmse:1.94159\n",
      "[36135]\teval-rmse:3.79615\ttrain-rmse:1.94156\n",
      "[36136]\teval-rmse:3.79788\ttrain-rmse:1.94159\n",
      "[36137]\teval-rmse:3.79723\ttrain-rmse:1.94156\n",
      "[36138]\teval-rmse:3.79859\ttrain-rmse:1.94162\n",
      "[36139]\teval-rmse:3.79732\ttrain-rmse:1.94157\n",
      "[36140]\teval-rmse:3.79906\ttrain-rmse:1.94161\n",
      "[36141]\teval-rmse:3.79852\ttrain-rmse:1.94159\n",
      "[36142]\teval-rmse:3.79652\ttrain-rmse:1.94152\n",
      "[36143]\teval-rmse:3.79608\ttrain-rmse:1.94151\n",
      "[36144]\teval-rmse:3.79657\ttrain-rmse:1.94152\n",
      "[36145]\teval-rmse:3.7967\ttrain-rmse:1.94153\n",
      "[36146]\teval-rmse:3.7982\ttrain-rmse:1.94158\n",
      "[36147]\teval-rmse:3.79842\ttrain-rmse:1.94159\n",
      "[36148]\teval-rmse:3.79789\ttrain-rmse:1.94156\n",
      "[36149]\teval-rmse:3.79859\ttrain-rmse:1.94157\n",
      "[36150]\teval-rmse:3.79822\ttrain-rmse:1.94156\n",
      "[36151]\teval-rmse:3.79834\ttrain-rmse:1.94157\n",
      "[36152]\teval-rmse:3.79724\ttrain-rmse:1.94155\n",
      "[36153]\teval-rmse:3.7956\ttrain-rmse:1.94149\n",
      "[36154]\teval-rmse:3.79357\ttrain-rmse:1.94144\n",
      "[36155]\teval-rmse:3.79339\ttrain-rmse:1.94141\n",
      "[36156]\teval-rmse:3.7932\ttrain-rmse:1.94141\n",
      "[36157]\teval-rmse:3.79454\ttrain-rmse:1.94145\n",
      "[36158]\teval-rmse:3.79434\ttrain-rmse:1.94142\n",
      "[36159]\teval-rmse:3.79327\ttrain-rmse:1.94141\n",
      "[36160]\teval-rmse:3.79469\ttrain-rmse:1.94145\n",
      "[36161]\teval-rmse:3.79434\ttrain-rmse:1.94144\n",
      "[36162]\teval-rmse:3.79391\ttrain-rmse:1.94143\n",
      "[36163]\teval-rmse:3.79417\ttrain-rmse:1.94144\n",
      "[36164]\teval-rmse:3.79272\ttrain-rmse:1.9414\n",
      "[36165]\teval-rmse:3.79148\ttrain-rmse:1.94139\n",
      "[36166]\teval-rmse:3.79322\ttrain-rmse:1.94141\n",
      "[36167]\teval-rmse:3.79143\ttrain-rmse:1.94137\n",
      "[36168]\teval-rmse:3.79302\ttrain-rmse:1.94138\n",
      "[36169]\teval-rmse:3.79195\ttrain-rmse:1.94137\n",
      "[36170]\teval-rmse:3.79337\ttrain-rmse:1.94138\n",
      "[36171]\teval-rmse:3.79369\ttrain-rmse:1.94139\n",
      "[36172]\teval-rmse:3.79384\ttrain-rmse:1.94139\n",
      "[36173]\teval-rmse:3.79326\ttrain-rmse:1.94139\n",
      "[36174]\teval-rmse:3.79327\ttrain-rmse:1.94139\n",
      "[36175]\teval-rmse:3.79342\ttrain-rmse:1.94139\n",
      "[36176]\teval-rmse:3.79199\ttrain-rmse:1.94137\n",
      "[36177]\teval-rmse:3.79237\ttrain-rmse:1.94138\n",
      "[36178]\teval-rmse:3.79203\ttrain-rmse:1.94137\n",
      "[36179]\teval-rmse:3.7917\ttrain-rmse:1.94137\n",
      "[36180]\teval-rmse:3.79319\ttrain-rmse:1.9414\n",
      "[36181]\teval-rmse:3.79285\ttrain-rmse:1.9414\n",
      "[36182]\teval-rmse:3.79426\ttrain-rmse:1.94144\n",
      "[36183]\teval-rmse:3.79423\ttrain-rmse:1.94144\n",
      "[36184]\teval-rmse:3.79469\ttrain-rmse:1.94145\n",
      "[36185]\teval-rmse:3.79388\ttrain-rmse:1.94143\n",
      "[36186]\teval-rmse:3.79257\ttrain-rmse:1.9414\n",
      "[36187]\teval-rmse:3.79217\ttrain-rmse:1.9414\n",
      "[36188]\teval-rmse:3.79111\ttrain-rmse:1.94139\n",
      "[36189]\teval-rmse:3.7915\ttrain-rmse:1.94139\n",
      "[36190]\teval-rmse:3.78957\ttrain-rmse:1.94137\n",
      "[36191]\teval-rmse:3.79097\ttrain-rmse:1.94139\n",
      "[36192]\teval-rmse:3.79096\ttrain-rmse:1.94139\n",
      "[36193]\teval-rmse:3.79213\ttrain-rmse:1.94142\n",
      "[36194]\teval-rmse:3.79179\ttrain-rmse:1.94142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36195]\teval-rmse:3.79323\ttrain-rmse:1.94145\n",
      "[36196]\teval-rmse:3.79425\ttrain-rmse:1.94148\n",
      "[36197]\teval-rmse:3.7926\ttrain-rmse:1.94144\n",
      "[36198]\teval-rmse:3.79216\ttrain-rmse:1.94143\n",
      "[36199]\teval-rmse:3.79302\ttrain-rmse:1.94145\n",
      "[36200]\teval-rmse:3.79315\ttrain-rmse:1.94145\n",
      "[36201]\teval-rmse:3.7929\ttrain-rmse:1.94145\n",
      "[36202]\teval-rmse:3.79414\ttrain-rmse:1.94149\n",
      "[36203]\teval-rmse:3.79391\ttrain-rmse:1.94148\n",
      "[36204]\teval-rmse:3.79413\ttrain-rmse:1.94148\n",
      "[36205]\teval-rmse:3.79357\ttrain-rmse:1.94148\n",
      "[36206]\teval-rmse:3.79226\ttrain-rmse:1.94144\n",
      "[36207]\teval-rmse:3.79089\ttrain-rmse:1.94141\n",
      "[36208]\teval-rmse:3.79041\ttrain-rmse:1.9414\n",
      "[36209]\teval-rmse:3.79074\ttrain-rmse:1.9414\n",
      "[36210]\teval-rmse:3.78969\ttrain-rmse:1.94139\n",
      "[36211]\teval-rmse:3.78947\ttrain-rmse:1.94139\n",
      "[36212]\teval-rmse:3.79071\ttrain-rmse:1.94141\n",
      "[36213]\teval-rmse:3.78925\ttrain-rmse:1.94139\n",
      "[36214]\teval-rmse:3.78757\ttrain-rmse:1.94138\n",
      "[36215]\teval-rmse:3.78798\ttrain-rmse:1.94139\n",
      "[36216]\teval-rmse:3.78766\ttrain-rmse:1.94138\n",
      "[36217]\teval-rmse:3.78745\ttrain-rmse:1.94138\n",
      "[36218]\teval-rmse:3.78773\ttrain-rmse:1.94139\n",
      "[36219]\teval-rmse:3.78804\ttrain-rmse:1.94139\n",
      "[36220]\teval-rmse:3.78873\ttrain-rmse:1.9414\n",
      "[36221]\teval-rmse:3.79023\ttrain-rmse:1.94143\n",
      "[36222]\teval-rmse:3.78871\ttrain-rmse:1.9414\n",
      "[36223]\teval-rmse:3.78856\ttrain-rmse:1.9414\n",
      "[36224]\teval-rmse:3.78678\ttrain-rmse:1.94138\n",
      "[36225]\teval-rmse:3.78501\ttrain-rmse:1.94137\n",
      "[36226]\teval-rmse:3.78538\ttrain-rmse:1.94138\n",
      "[36227]\teval-rmse:3.78393\ttrain-rmse:1.94137\n",
      "[36228]\teval-rmse:3.78203\ttrain-rmse:1.94141\n",
      "[36229]\teval-rmse:3.78085\ttrain-rmse:1.94144\n",
      "[36230]\teval-rmse:3.7826\ttrain-rmse:1.94141\n",
      "[36231]\teval-rmse:3.78262\ttrain-rmse:1.94141\n",
      "[36232]\teval-rmse:3.78233\ttrain-rmse:1.94142\n",
      "[36233]\teval-rmse:3.78161\ttrain-rmse:1.94142\n",
      "[36234]\teval-rmse:3.7821\ttrain-rmse:1.94142\n",
      "[36235]\teval-rmse:3.78191\ttrain-rmse:1.94142\n",
      "[36236]\teval-rmse:3.78155\ttrain-rmse:1.94142\n",
      "[36237]\teval-rmse:3.78208\ttrain-rmse:1.94142\n",
      "[36238]\teval-rmse:3.78261\ttrain-rmse:1.94141\n",
      "[36239]\teval-rmse:3.78246\ttrain-rmse:1.94141\n",
      "[36240]\teval-rmse:3.7825\ttrain-rmse:1.94141\n",
      "[36241]\teval-rmse:3.78299\ttrain-rmse:1.94141\n",
      "[36242]\teval-rmse:3.78246\ttrain-rmse:1.94142\n",
      "[36243]\teval-rmse:3.78125\ttrain-rmse:1.94144\n",
      "[36244]\teval-rmse:3.77969\ttrain-rmse:1.94146\n",
      "[36245]\teval-rmse:3.77941\ttrain-rmse:1.94147\n",
      "[36246]\teval-rmse:3.77914\ttrain-rmse:1.94147\n",
      "[36247]\teval-rmse:3.78065\ttrain-rmse:1.94143\n",
      "[36248]\teval-rmse:3.7809\ttrain-rmse:1.94143\n",
      "[36249]\teval-rmse:3.78191\ttrain-rmse:1.94141\n",
      "[36250]\teval-rmse:3.78231\ttrain-rmse:1.94141\n",
      "[36251]\teval-rmse:3.78285\ttrain-rmse:1.94141\n",
      "[36252]\teval-rmse:3.78166\ttrain-rmse:1.94141\n",
      "[36253]\teval-rmse:3.78198\ttrain-rmse:1.94141\n",
      "[36254]\teval-rmse:3.78272\ttrain-rmse:1.9414\n",
      "[36255]\teval-rmse:3.78123\ttrain-rmse:1.94141\n",
      "[36256]\teval-rmse:3.78246\ttrain-rmse:1.9414\n",
      "[36257]\teval-rmse:3.78231\ttrain-rmse:1.9414\n",
      "[36258]\teval-rmse:3.78366\ttrain-rmse:1.94139\n",
      "[36259]\teval-rmse:3.78345\ttrain-rmse:1.94139\n",
      "[36260]\teval-rmse:3.78501\ttrain-rmse:1.94139\n",
      "[36261]\teval-rmse:3.7866\ttrain-rmse:1.94138\n",
      "[36262]\teval-rmse:3.78773\ttrain-rmse:1.94139\n",
      "[36263]\teval-rmse:3.78648\ttrain-rmse:1.94139\n",
      "[36264]\teval-rmse:3.7879\ttrain-rmse:1.94139\n",
      "[36265]\teval-rmse:3.78618\ttrain-rmse:1.9414\n",
      "[36266]\teval-rmse:3.78459\ttrain-rmse:1.94142\n",
      "[36267]\teval-rmse:3.78357\ttrain-rmse:1.94143\n",
      "[36268]\teval-rmse:3.78511\ttrain-rmse:1.94143\n",
      "[36269]\teval-rmse:3.78552\ttrain-rmse:1.94143\n",
      "[36270]\teval-rmse:3.7843\ttrain-rmse:1.94143\n",
      "[36271]\teval-rmse:3.78588\ttrain-rmse:1.94143\n",
      "[36272]\teval-rmse:3.78602\ttrain-rmse:1.94143\n",
      "[36273]\teval-rmse:3.78483\ttrain-rmse:1.94143\n",
      "[36274]\teval-rmse:3.78381\ttrain-rmse:1.94143\n",
      "[36275]\teval-rmse:3.78429\ttrain-rmse:1.94143\n",
      "[36276]\teval-rmse:3.78469\ttrain-rmse:1.94143\n",
      "[36277]\teval-rmse:3.78324\ttrain-rmse:1.94143\n",
      "[36278]\teval-rmse:3.78199\ttrain-rmse:1.94143\n",
      "[36279]\teval-rmse:3.78374\ttrain-rmse:1.94141\n",
      "[36280]\teval-rmse:3.78447\ttrain-rmse:1.94141\n",
      "[36281]\teval-rmse:3.78575\ttrain-rmse:1.94141\n",
      "[36282]\teval-rmse:3.78501\ttrain-rmse:1.9414\n",
      "[36283]\teval-rmse:3.7839\ttrain-rmse:1.9414\n",
      "[36284]\teval-rmse:3.78418\ttrain-rmse:1.9414\n",
      "[36285]\teval-rmse:3.78397\ttrain-rmse:1.9414\n",
      "[36286]\teval-rmse:3.78556\ttrain-rmse:1.9414\n",
      "[36287]\teval-rmse:3.78574\ttrain-rmse:1.9414\n",
      "[36288]\teval-rmse:3.78543\ttrain-rmse:1.9414\n",
      "[36289]\teval-rmse:3.78583\ttrain-rmse:1.9414\n",
      "[36290]\teval-rmse:3.78438\ttrain-rmse:1.94139\n",
      "[36291]\teval-rmse:3.78592\ttrain-rmse:1.9414\n",
      "[36292]\teval-rmse:3.78561\ttrain-rmse:1.9414\n",
      "[36293]\teval-rmse:3.78593\ttrain-rmse:1.9414\n",
      "[36294]\teval-rmse:3.78436\ttrain-rmse:1.94141\n",
      "[36295]\teval-rmse:3.78465\ttrain-rmse:1.94141\n",
      "[36296]\teval-rmse:3.78484\ttrain-rmse:1.94141\n",
      "[36297]\teval-rmse:3.78628\ttrain-rmse:1.9414\n",
      "[36298]\teval-rmse:3.78597\ttrain-rmse:1.9414\n",
      "[36299]\teval-rmse:3.78756\ttrain-rmse:1.94139\n",
      "[36300]\teval-rmse:3.78633\ttrain-rmse:1.94139\n",
      "[36301]\teval-rmse:3.78787\ttrain-rmse:1.94138\n",
      "[36302]\teval-rmse:3.78909\ttrain-rmse:1.9414\n",
      "[36303]\teval-rmse:3.79066\ttrain-rmse:1.94144\n",
      "[36304]\teval-rmse:3.7893\ttrain-rmse:1.94143\n",
      "[36305]\teval-rmse:3.78925\ttrain-rmse:1.94142\n",
      "[36306]\teval-rmse:3.78997\ttrain-rmse:1.94142\n",
      "[36307]\teval-rmse:3.78964\ttrain-rmse:1.94142\n",
      "[36308]\teval-rmse:3.79063\ttrain-rmse:1.94145\n",
      "[36309]\teval-rmse:3.79132\ttrain-rmse:1.94146\n",
      "[36310]\teval-rmse:3.79077\ttrain-rmse:1.94145\n",
      "[36311]\teval-rmse:3.78941\ttrain-rmse:1.94145\n",
      "[36312]\teval-rmse:3.79061\ttrain-rmse:1.94148\n",
      "[36313]\teval-rmse:3.79097\ttrain-rmse:1.94149\n",
      "[36314]\teval-rmse:3.78941\ttrain-rmse:1.94145\n",
      "[36315]\teval-rmse:3.78836\ttrain-rmse:1.94145\n",
      "[36316]\teval-rmse:3.78973\ttrain-rmse:1.94148\n",
      "[36317]\teval-rmse:3.78814\ttrain-rmse:1.94145\n",
      "[36318]\teval-rmse:3.78797\ttrain-rmse:1.94143\n",
      "[36319]\teval-rmse:3.78829\ttrain-rmse:1.94143\n",
      "[36320]\teval-rmse:3.78901\ttrain-rmse:1.94143\n",
      "[36321]\teval-rmse:3.78934\ttrain-rmse:1.94144\n",
      "[36322]\teval-rmse:3.78933\ttrain-rmse:1.94144\n",
      "[36323]\teval-rmse:3.78983\ttrain-rmse:1.94145\n",
      "[36324]\teval-rmse:3.79157\ttrain-rmse:1.94151\n",
      "[36325]\teval-rmse:3.79308\ttrain-rmse:1.94153\n",
      "[36326]\teval-rmse:3.79326\ttrain-rmse:1.94154\n",
      "[36327]\teval-rmse:3.79273\ttrain-rmse:1.94152\n",
      "[36328]\teval-rmse:3.79299\ttrain-rmse:1.94153\n",
      "[36329]\teval-rmse:3.79173\ttrain-rmse:1.94149\n",
      "[36330]\teval-rmse:3.79347\ttrain-rmse:1.94152\n",
      "[36331]\teval-rmse:3.79223\ttrain-rmse:1.94149\n",
      "[36332]\teval-rmse:3.79374\ttrain-rmse:1.94155\n",
      "[36333]\teval-rmse:3.79212\ttrain-rmse:1.94152\n",
      "[36334]\teval-rmse:3.79231\ttrain-rmse:1.94153\n",
      "[36335]\teval-rmse:3.79101\ttrain-rmse:1.94148\n",
      "[36336]\teval-rmse:3.79084\ttrain-rmse:1.94146\n",
      "[36337]\teval-rmse:3.78978\ttrain-rmse:1.94145\n",
      "[36338]\teval-rmse:3.79129\ttrain-rmse:1.94146\n",
      "[36339]\teval-rmse:3.79023\ttrain-rmse:1.94145\n",
      "[36340]\teval-rmse:3.78967\ttrain-rmse:1.94144\n",
      "[36341]\teval-rmse:3.78845\ttrain-rmse:1.9414\n",
      "[36342]\teval-rmse:3.78898\ttrain-rmse:1.94141\n",
      "[36343]\teval-rmse:3.79015\ttrain-rmse:1.94145\n",
      "[36344]\teval-rmse:3.79011\ttrain-rmse:1.94145\n",
      "[36345]\teval-rmse:3.78936\ttrain-rmse:1.94143\n",
      "[36346]\teval-rmse:3.78938\ttrain-rmse:1.94143\n",
      "[36347]\teval-rmse:3.78887\ttrain-rmse:1.94143\n",
      "[36348]\teval-rmse:3.78869\ttrain-rmse:1.94141\n",
      "[36349]\teval-rmse:3.78749\ttrain-rmse:1.94139\n",
      "[36350]\teval-rmse:3.78898\ttrain-rmse:1.94139\n",
      "[36351]\teval-rmse:3.78937\ttrain-rmse:1.94139\n",
      "[36352]\teval-rmse:3.78904\ttrain-rmse:1.94139\n",
      "[36353]\teval-rmse:3.79079\ttrain-rmse:1.9414\n",
      "[36354]\teval-rmse:3.791\ttrain-rmse:1.94141\n",
      "[36355]\teval-rmse:3.78978\ttrain-rmse:1.9414\n",
      "[36356]\teval-rmse:3.78977\ttrain-rmse:1.9414\n",
      "[36357]\teval-rmse:3.79133\ttrain-rmse:1.94144\n",
      "[36358]\teval-rmse:3.79307\ttrain-rmse:1.94145\n",
      "[36359]\teval-rmse:3.79185\ttrain-rmse:1.94144\n",
      "[36360]\teval-rmse:3.79151\ttrain-rmse:1.94144\n",
      "[36361]\teval-rmse:3.79292\ttrain-rmse:1.94146\n",
      "[36362]\teval-rmse:3.79169\ttrain-rmse:1.94145\n",
      "[36363]\teval-rmse:3.79152\ttrain-rmse:1.94142\n",
      "[36364]\teval-rmse:3.79102\ttrain-rmse:1.94141\n",
      "[36365]\teval-rmse:3.79069\ttrain-rmse:1.94141\n",
      "[36366]\teval-rmse:3.78947\ttrain-rmse:1.94138\n",
      "[36367]\teval-rmse:3.78923\ttrain-rmse:1.94138\n",
      "[36368]\teval-rmse:3.79057\ttrain-rmse:1.94141\n",
      "[36369]\teval-rmse:3.78929\ttrain-rmse:1.9414\n",
      "[36370]\teval-rmse:3.78962\ttrain-rmse:1.94141\n",
      "[36371]\teval-rmse:3.78841\ttrain-rmse:1.94138\n",
      "[36372]\teval-rmse:3.78785\ttrain-rmse:1.94138\n",
      "[36373]\teval-rmse:3.78926\ttrain-rmse:1.9414\n",
      "[36374]\teval-rmse:3.78967\ttrain-rmse:1.94141\n",
      "[36375]\teval-rmse:3.78985\ttrain-rmse:1.94142\n",
      "[36376]\teval-rmse:3.79128\ttrain-rmse:1.94143\n",
      "[36377]\teval-rmse:3.79244\ttrain-rmse:1.94147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36378]\teval-rmse:3.79104\ttrain-rmse:1.94145\n",
      "[36379]\teval-rmse:3.79118\ttrain-rmse:1.94146\n",
      "[36380]\teval-rmse:3.7901\ttrain-rmse:1.94141\n",
      "[36381]\teval-rmse:3.78883\ttrain-rmse:1.94141\n",
      "[36382]\teval-rmse:3.78763\ttrain-rmse:1.94139\n",
      "[36383]\teval-rmse:3.78724\ttrain-rmse:1.94139\n",
      "[36384]\teval-rmse:3.78673\ttrain-rmse:1.94138\n",
      "[36385]\teval-rmse:3.78656\ttrain-rmse:1.94136\n",
      "[36386]\teval-rmse:3.78782\ttrain-rmse:1.94137\n",
      "[36387]\teval-rmse:3.78677\ttrain-rmse:1.94136\n",
      "[36388]\teval-rmse:3.78508\ttrain-rmse:1.94133\n",
      "[36389]\teval-rmse:3.78504\ttrain-rmse:1.94133\n",
      "[36390]\teval-rmse:3.78631\ttrain-rmse:1.94135\n",
      "[36391]\teval-rmse:3.78614\ttrain-rmse:1.94134\n",
      "[36392]\teval-rmse:3.78458\ttrain-rmse:1.94131\n",
      "[36393]\teval-rmse:3.78406\ttrain-rmse:1.94132\n",
      "[36394]\teval-rmse:3.78439\ttrain-rmse:1.94132\n",
      "[36395]\teval-rmse:3.78598\ttrain-rmse:1.9413\n",
      "[36396]\teval-rmse:3.78597\ttrain-rmse:1.9413\n",
      "[36397]\teval-rmse:3.7844\ttrain-rmse:1.94129\n",
      "[36398]\teval-rmse:3.7828\ttrain-rmse:1.94127\n",
      "[36399]\teval-rmse:3.78405\ttrain-rmse:1.94128\n",
      "[36400]\teval-rmse:3.78273\ttrain-rmse:1.9413\n",
      "[36401]\teval-rmse:3.78418\ttrain-rmse:1.94129\n",
      "[36402]\teval-rmse:3.78226\ttrain-rmse:1.94129\n",
      "[36403]\teval-rmse:3.78125\ttrain-rmse:1.94131\n",
      "[36404]\teval-rmse:3.78261\ttrain-rmse:1.94129\n",
      "[36405]\teval-rmse:3.78282\ttrain-rmse:1.94129\n",
      "[36406]\teval-rmse:3.78329\ttrain-rmse:1.94129\n",
      "[36407]\teval-rmse:3.7838\ttrain-rmse:1.9413\n",
      "[36408]\teval-rmse:3.78377\ttrain-rmse:1.9413\n",
      "[36409]\teval-rmse:3.78427\ttrain-rmse:1.94131\n",
      "[36410]\teval-rmse:3.78466\ttrain-rmse:1.9413\n",
      "[36411]\teval-rmse:3.7842\ttrain-rmse:1.94131\n",
      "[36412]\teval-rmse:3.78406\ttrain-rmse:1.94131\n",
      "[36413]\teval-rmse:3.78526\ttrain-rmse:1.94132\n",
      "[36414]\teval-rmse:3.78644\ttrain-rmse:1.94134\n",
      "[36415]\teval-rmse:3.78658\ttrain-rmse:1.94134\n",
      "[36416]\teval-rmse:3.78608\ttrain-rmse:1.94134\n",
      "[36417]\teval-rmse:3.78555\ttrain-rmse:1.94134\n",
      "[36418]\teval-rmse:3.78627\ttrain-rmse:1.94134\n",
      "[36419]\teval-rmse:3.78474\ttrain-rmse:1.94131\n",
      "[36420]\teval-rmse:3.78488\ttrain-rmse:1.94131\n",
      "[36421]\teval-rmse:3.78438\ttrain-rmse:1.94131\n",
      "[36422]\teval-rmse:3.78294\ttrain-rmse:1.94129\n",
      "[36423]\teval-rmse:3.78242\ttrain-rmse:1.9413\n",
      "[36424]\teval-rmse:3.78244\ttrain-rmse:1.9413\n",
      "[36425]\teval-rmse:3.78258\ttrain-rmse:1.9413\n",
      "[36426]\teval-rmse:3.78219\ttrain-rmse:1.9413\n",
      "[36427]\teval-rmse:3.78354\ttrain-rmse:1.94128\n",
      "[36428]\teval-rmse:3.78378\ttrain-rmse:1.94128\n",
      "[36429]\teval-rmse:3.78499\ttrain-rmse:1.9413\n",
      "[36430]\teval-rmse:3.78553\ttrain-rmse:1.9413\n",
      "[36431]\teval-rmse:3.78531\ttrain-rmse:1.9413\n",
      "[36432]\teval-rmse:3.7858\ttrain-rmse:1.94131\n",
      "[36433]\teval-rmse:3.78608\ttrain-rmse:1.94131\n",
      "[36434]\teval-rmse:3.78608\ttrain-rmse:1.94131\n",
      "[36435]\teval-rmse:3.78639\ttrain-rmse:1.94132\n",
      "[36436]\teval-rmse:3.78622\ttrain-rmse:1.94132\n",
      "[36437]\teval-rmse:3.78607\ttrain-rmse:1.9413\n",
      "[36438]\teval-rmse:3.78658\ttrain-rmse:1.94131\n",
      "[36439]\teval-rmse:3.78809\ttrain-rmse:1.94132\n",
      "[36440]\teval-rmse:3.78769\ttrain-rmse:1.94131\n",
      "[36441]\teval-rmse:3.78613\ttrain-rmse:1.94129\n",
      "[36442]\teval-rmse:3.7848\ttrain-rmse:1.94129\n",
      "[36443]\teval-rmse:3.78463\ttrain-rmse:1.94128\n",
      "[36444]\teval-rmse:3.78524\ttrain-rmse:1.94128\n",
      "[36445]\teval-rmse:3.78622\ttrain-rmse:1.94131\n",
      "[36446]\teval-rmse:3.78797\ttrain-rmse:1.94136\n",
      "[36447]\teval-rmse:3.78774\ttrain-rmse:1.94136\n",
      "[36448]\teval-rmse:3.78917\ttrain-rmse:1.94136\n",
      "[36449]\teval-rmse:3.78988\ttrain-rmse:1.94138\n",
      "[36450]\teval-rmse:3.78955\ttrain-rmse:1.94138\n",
      "[36451]\teval-rmse:3.79052\ttrain-rmse:1.94141\n",
      "[36452]\teval-rmse:3.79072\ttrain-rmse:1.94142\n",
      "[36453]\teval-rmse:3.79185\ttrain-rmse:1.94146\n",
      "[36454]\teval-rmse:3.79152\ttrain-rmse:1.94146\n",
      "[36455]\teval-rmse:3.79196\ttrain-rmse:1.94148\n",
      "[36456]\teval-rmse:3.79266\ttrain-rmse:1.94148\n",
      "[36457]\teval-rmse:3.79248\ttrain-rmse:1.94146\n",
      "[36458]\teval-rmse:3.79122\ttrain-rmse:1.94142\n",
      "[36459]\teval-rmse:3.78963\ttrain-rmse:1.94137\n",
      "[36460]\teval-rmse:3.79096\ttrain-rmse:1.94141\n",
      "[36461]\teval-rmse:3.78975\ttrain-rmse:1.9414\n",
      "[36462]\teval-rmse:3.79021\ttrain-rmse:1.94141\n",
      "[36463]\teval-rmse:3.79019\ttrain-rmse:1.94141\n",
      "[36464]\teval-rmse:3.79036\ttrain-rmse:1.94142\n",
      "[36465]\teval-rmse:3.7917\ttrain-rmse:1.94148\n",
      "[36466]\teval-rmse:3.79094\ttrain-rmse:1.94145\n",
      "[36467]\teval-rmse:3.78957\ttrain-rmse:1.94138\n",
      "[36468]\teval-rmse:3.79097\ttrain-rmse:1.9414\n",
      "[36469]\teval-rmse:3.79134\ttrain-rmse:1.94141\n",
      "[36470]\teval-rmse:3.79171\ttrain-rmse:1.94141\n",
      "[36471]\teval-rmse:3.79209\ttrain-rmse:1.94142\n",
      "[36472]\teval-rmse:3.7908\ttrain-rmse:1.94138\n",
      "[36473]\teval-rmse:3.79109\ttrain-rmse:1.94139\n",
      "[36474]\teval-rmse:3.78979\ttrain-rmse:1.94133\n",
      "[36475]\teval-rmse:3.78992\ttrain-rmse:1.94134\n",
      "[36476]\teval-rmse:3.79004\ttrain-rmse:1.94134\n",
      "[36477]\teval-rmse:3.78949\ttrain-rmse:1.94133\n",
      "[36478]\teval-rmse:3.79098\ttrain-rmse:1.94137\n",
      "[36479]\teval-rmse:3.7922\ttrain-rmse:1.94143\n",
      "[36480]\teval-rmse:3.79144\ttrain-rmse:1.94141\n",
      "[36481]\teval-rmse:3.79269\ttrain-rmse:1.94148\n",
      "[36482]\teval-rmse:3.79212\ttrain-rmse:1.94147\n",
      "[36483]\teval-rmse:3.79206\ttrain-rmse:1.94147\n",
      "[36484]\teval-rmse:3.79358\ttrain-rmse:1.94152\n",
      "[36485]\teval-rmse:3.79322\ttrain-rmse:1.94152\n",
      "[36486]\teval-rmse:3.79191\ttrain-rmse:1.94147\n",
      "[36487]\teval-rmse:3.79307\ttrain-rmse:1.94153\n",
      "[36488]\teval-rmse:3.79142\ttrain-rmse:1.94145\n",
      "[36489]\teval-rmse:3.79316\ttrain-rmse:1.94146\n",
      "[36490]\teval-rmse:3.79309\ttrain-rmse:1.94146\n",
      "[36491]\teval-rmse:3.79449\ttrain-rmse:1.94149\n",
      "[36492]\teval-rmse:3.79429\ttrain-rmse:1.94147\n",
      "[36493]\teval-rmse:3.79321\ttrain-rmse:1.94145\n",
      "[36494]\teval-rmse:3.79336\ttrain-rmse:1.94146\n",
      "[36495]\teval-rmse:3.79276\ttrain-rmse:1.94144\n",
      "[36496]\teval-rmse:3.79126\ttrain-rmse:1.94139\n",
      "[36497]\teval-rmse:3.79254\ttrain-rmse:1.94145\n",
      "[36498]\teval-rmse:3.79091\ttrain-rmse:1.94137\n",
      "[36499]\teval-rmse:3.79131\ttrain-rmse:1.94139\n",
      "[36500]\teval-rmse:3.79202\ttrain-rmse:1.94141\n",
      "[36501]\teval-rmse:3.79185\ttrain-rmse:1.94139\n",
      "[36502]\teval-rmse:3.79166\ttrain-rmse:1.94138\n",
      "[36503]\teval-rmse:3.79309\ttrain-rmse:1.94143\n",
      "[36504]\teval-rmse:3.7925\ttrain-rmse:1.94141\n",
      "[36505]\teval-rmse:3.79112\ttrain-rmse:1.94136\n",
      "[36506]\teval-rmse:3.79035\ttrain-rmse:1.94133\n",
      "[36507]\teval-rmse:3.79028\ttrain-rmse:1.94133\n",
      "[36508]\teval-rmse:3.79098\ttrain-rmse:1.94135\n",
      "[36509]\teval-rmse:3.79096\ttrain-rmse:1.94135\n",
      "[36510]\teval-rmse:3.79219\ttrain-rmse:1.94139\n",
      "[36511]\teval-rmse:3.79321\ttrain-rmse:1.94144\n",
      "[36512]\teval-rmse:3.7937\ttrain-rmse:1.94147\n",
      "[36513]\teval-rmse:3.79191\ttrain-rmse:1.94137\n",
      "[36514]\teval-rmse:3.79227\ttrain-rmse:1.94138\n",
      "[36515]\teval-rmse:3.79276\ttrain-rmse:1.94141\n",
      "[36516]\teval-rmse:3.79226\ttrain-rmse:1.9414\n",
      "[36517]\teval-rmse:3.794\ttrain-rmse:1.94142\n",
      "[36518]\teval-rmse:3.79555\ttrain-rmse:1.94146\n",
      "[36519]\teval-rmse:3.79596\ttrain-rmse:1.94148\n",
      "[36520]\teval-rmse:3.7952\ttrain-rmse:1.94146\n",
      "[36521]\teval-rmse:3.79532\ttrain-rmse:1.94146\n",
      "[36522]\teval-rmse:3.79533\ttrain-rmse:1.94147\n",
      "[36523]\teval-rmse:3.79558\ttrain-rmse:1.94148\n",
      "[36524]\teval-rmse:3.79732\ttrain-rmse:1.94151\n",
      "[36525]\teval-rmse:3.79832\ttrain-rmse:1.94158\n",
      "[36526]\teval-rmse:3.79672\ttrain-rmse:1.94152\n",
      "[36527]\teval-rmse:3.7969\ttrain-rmse:1.94153\n",
      "[36528]\teval-rmse:3.79863\ttrain-rmse:1.94157\n",
      "[36529]\teval-rmse:3.79844\ttrain-rmse:1.94156\n",
      "[36530]\teval-rmse:3.79677\ttrain-rmse:1.94149\n",
      "[36531]\teval-rmse:3.79799\ttrain-rmse:1.94154\n",
      "[36532]\teval-rmse:3.7974\ttrain-rmse:1.94152\n",
      "[36533]\teval-rmse:3.79683\ttrain-rmse:1.9415\n",
      "[36534]\teval-rmse:3.79543\ttrain-rmse:1.94147\n",
      "[36535]\teval-rmse:3.79698\ttrain-rmse:1.94152\n",
      "[36536]\teval-rmse:3.79531\ttrain-rmse:1.94142\n",
      "[36537]\teval-rmse:3.79582\ttrain-rmse:1.94145\n",
      "[36538]\teval-rmse:3.79503\ttrain-rmse:1.94141\n",
      "[36539]\teval-rmse:3.79343\ttrain-rmse:1.94133\n",
      "[36540]\teval-rmse:3.79486\ttrain-rmse:1.94136\n",
      "[36541]\teval-rmse:3.79629\ttrain-rmse:1.94139\n",
      "[36542]\teval-rmse:3.79639\ttrain-rmse:1.94139\n",
      "[36543]\teval-rmse:3.79481\ttrain-rmse:1.94133\n",
      "[36544]\teval-rmse:3.7955\ttrain-rmse:1.94135\n",
      "[36545]\teval-rmse:3.79724\ttrain-rmse:1.94139\n",
      "[36546]\teval-rmse:3.79867\ttrain-rmse:1.94142\n",
      "[36547]\teval-rmse:3.79896\ttrain-rmse:1.94144\n",
      "[36548]\teval-rmse:3.8003\ttrain-rmse:1.94152\n",
      "[36549]\teval-rmse:3.80148\ttrain-rmse:1.94158\n",
      "[36550]\teval-rmse:3.80192\ttrain-rmse:1.94162\n",
      "[36551]\teval-rmse:3.80048\ttrain-rmse:1.94157\n",
      "[36552]\teval-rmse:3.79921\ttrain-rmse:1.94153\n",
      "[36553]\teval-rmse:3.80038\ttrain-rmse:1.94161\n",
      "[36554]\teval-rmse:3.80082\ttrain-rmse:1.94164\n",
      "[36555]\teval-rmse:3.80109\ttrain-rmse:1.94166\n",
      "[36556]\teval-rmse:3.80041\ttrain-rmse:1.94161\n",
      "[36557]\teval-rmse:3.79889\ttrain-rmse:1.94153\n",
      "[36558]\teval-rmse:3.80013\ttrain-rmse:1.94159\n",
      "[36559]\teval-rmse:3.79868\ttrain-rmse:1.94152\n",
      "[36560]\teval-rmse:3.79904\ttrain-rmse:1.94154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36561]\teval-rmse:3.7976\ttrain-rmse:1.94145\n",
      "[36562]\teval-rmse:3.79777\ttrain-rmse:1.94146\n",
      "[36563]\teval-rmse:3.79857\ttrain-rmse:1.94151\n",
      "[36564]\teval-rmse:3.79982\ttrain-rmse:1.94156\n",
      "[36565]\teval-rmse:3.79806\ttrain-rmse:1.94147\n",
      "[36566]\teval-rmse:3.79674\ttrain-rmse:1.94139\n",
      "[36567]\teval-rmse:3.79548\ttrain-rmse:1.94137\n",
      "[36568]\teval-rmse:3.79424\ttrain-rmse:1.94135\n",
      "[36569]\teval-rmse:3.79491\ttrain-rmse:1.94137\n",
      "[36570]\teval-rmse:3.79624\ttrain-rmse:1.94144\n",
      "[36571]\teval-rmse:3.79499\ttrain-rmse:1.9414\n",
      "[36572]\teval-rmse:3.79569\ttrain-rmse:1.94143\n",
      "[36573]\teval-rmse:3.79721\ttrain-rmse:1.94148\n",
      "[36574]\teval-rmse:3.79854\ttrain-rmse:1.94154\n",
      "[36575]\teval-rmse:3.79817\ttrain-rmse:1.94153\n",
      "[36576]\teval-rmse:3.79707\ttrain-rmse:1.9415\n",
      "[36577]\teval-rmse:3.79739\ttrain-rmse:1.94151\n",
      "[36578]\teval-rmse:3.79888\ttrain-rmse:1.94159\n",
      "[36579]\teval-rmse:3.79844\ttrain-rmse:1.94158\n",
      "[36580]\teval-rmse:3.79998\ttrain-rmse:1.94164\n",
      "[36581]\teval-rmse:3.79959\ttrain-rmse:1.94162\n",
      "[36582]\teval-rmse:3.79986\ttrain-rmse:1.94164\n",
      "[36583]\teval-rmse:3.80023\ttrain-rmse:1.94167\n",
      "[36584]\teval-rmse:3.79961\ttrain-rmse:1.94164\n",
      "[36585]\teval-rmse:3.80069\ttrain-rmse:1.94172\n",
      "[36586]\teval-rmse:3.80023\ttrain-rmse:1.9417\n",
      "[36587]\teval-rmse:3.7996\ttrain-rmse:1.94166\n",
      "[36588]\teval-rmse:3.80117\ttrain-rmse:1.94175\n",
      "[36589]\teval-rmse:3.80166\ttrain-rmse:1.94178\n",
      "[36590]\teval-rmse:3.80305\ttrain-rmse:1.94187\n",
      "[36591]\teval-rmse:3.80101\ttrain-rmse:1.94173\n",
      "[36592]\teval-rmse:3.79966\ttrain-rmse:1.94169\n",
      "[36593]\teval-rmse:3.80013\ttrain-rmse:1.94172\n",
      "[36594]\teval-rmse:3.80138\ttrain-rmse:1.94181\n",
      "[36595]\teval-rmse:3.8022\ttrain-rmse:1.94188\n",
      "[36596]\teval-rmse:3.80174\ttrain-rmse:1.94186\n",
      "[36597]\teval-rmse:3.80273\ttrain-rmse:1.94193\n",
      "[36598]\teval-rmse:3.80127\ttrain-rmse:1.94182\n",
      "[36599]\teval-rmse:3.80169\ttrain-rmse:1.94185\n",
      "[36600]\teval-rmse:3.80146\ttrain-rmse:1.94183\n",
      "[36601]\teval-rmse:3.80101\ttrain-rmse:1.94182\n",
      "[36602]\teval-rmse:3.80125\ttrain-rmse:1.94184\n",
      "[36603]\teval-rmse:3.80087\ttrain-rmse:1.94182\n",
      "[36604]\teval-rmse:3.80027\ttrain-rmse:1.9418\n",
      "[36605]\teval-rmse:3.79893\ttrain-rmse:1.94172\n",
      "[36606]\teval-rmse:3.79849\ttrain-rmse:1.94169\n",
      "[36607]\teval-rmse:3.79766\ttrain-rmse:1.94164\n",
      "[36608]\teval-rmse:3.79624\ttrain-rmse:1.94161\n",
      "[36609]\teval-rmse:3.79656\ttrain-rmse:1.94162\n",
      "[36610]\teval-rmse:3.79516\ttrain-rmse:1.94154\n",
      "[36611]\teval-rmse:3.79566\ttrain-rmse:1.94156\n",
      "[36612]\teval-rmse:3.79543\ttrain-rmse:1.94155\n",
      "[36613]\teval-rmse:3.79559\ttrain-rmse:1.94156\n",
      "[36614]\teval-rmse:3.79701\ttrain-rmse:1.94161\n",
      "[36615]\teval-rmse:3.79738\ttrain-rmse:1.94163\n",
      "[36616]\teval-rmse:3.79798\ttrain-rmse:1.94166\n",
      "[36617]\teval-rmse:3.79656\ttrain-rmse:1.94162\n",
      "[36618]\teval-rmse:3.79778\ttrain-rmse:1.94171\n",
      "[36619]\teval-rmse:3.79647\ttrain-rmse:1.94167\n",
      "[36620]\teval-rmse:3.79779\ttrain-rmse:1.94174\n",
      "[36621]\teval-rmse:3.79825\ttrain-rmse:1.94177\n",
      "[36622]\teval-rmse:3.79855\ttrain-rmse:1.94179\n",
      "[36623]\teval-rmse:3.79863\ttrain-rmse:1.94179\n",
      "[36624]\teval-rmse:3.79804\ttrain-rmse:1.94176\n",
      "[36625]\teval-rmse:3.79653\ttrain-rmse:1.94168\n",
      "[36626]\teval-rmse:3.79499\ttrain-rmse:1.9416\n",
      "[36627]\teval-rmse:3.79438\ttrain-rmse:1.94157\n",
      "[36628]\teval-rmse:3.79286\ttrain-rmse:1.94151\n",
      "[36629]\teval-rmse:3.7923\ttrain-rmse:1.9415\n",
      "[36630]\teval-rmse:3.7934\ttrain-rmse:1.94155\n",
      "[36631]\teval-rmse:3.79211\ttrain-rmse:1.94152\n",
      "[36632]\teval-rmse:3.79186\ttrain-rmse:1.94151\n",
      "[36633]\teval-rmse:3.7913\ttrain-rmse:1.9415\n",
      "[36634]\teval-rmse:3.79186\ttrain-rmse:1.94153\n",
      "[36635]\teval-rmse:3.79337\ttrain-rmse:1.94157\n",
      "[36636]\teval-rmse:3.79283\ttrain-rmse:1.94154\n",
      "[36637]\teval-rmse:3.79309\ttrain-rmse:1.94155\n",
      "[36638]\teval-rmse:3.79461\ttrain-rmse:1.94157\n",
      "[36639]\teval-rmse:3.79435\ttrain-rmse:1.94157\n",
      "[36640]\teval-rmse:3.79501\ttrain-rmse:1.94159\n",
      "[36641]\teval-rmse:3.79522\ttrain-rmse:1.94161\n",
      "[36642]\teval-rmse:3.79665\ttrain-rmse:1.94163\n",
      "[36643]\teval-rmse:3.79613\ttrain-rmse:1.94162\n",
      "[36644]\teval-rmse:3.79487\ttrain-rmse:1.94159\n",
      "[36645]\teval-rmse:3.79337\ttrain-rmse:1.94155\n",
      "[36646]\teval-rmse:3.79318\ttrain-rmse:1.94152\n",
      "[36647]\teval-rmse:3.79188\ttrain-rmse:1.94151\n",
      "[36648]\teval-rmse:3.79362\ttrain-rmse:1.94153\n",
      "[36649]\teval-rmse:3.7946\ttrain-rmse:1.94157\n",
      "[36650]\teval-rmse:3.79619\ttrain-rmse:1.9416\n",
      "[36651]\teval-rmse:3.79469\ttrain-rmse:1.94153\n",
      "[36652]\teval-rmse:3.7939\ttrain-rmse:1.9415\n",
      "[36653]\teval-rmse:3.79434\ttrain-rmse:1.94151\n",
      "[36654]\teval-rmse:3.79603\ttrain-rmse:1.94158\n",
      "[36655]\teval-rmse:3.79602\ttrain-rmse:1.94158\n",
      "[36656]\teval-rmse:3.79637\ttrain-rmse:1.94159\n",
      "[36657]\teval-rmse:3.79795\ttrain-rmse:1.94162\n",
      "[36658]\teval-rmse:3.7966\ttrain-rmse:1.94156\n",
      "[36659]\teval-rmse:3.79694\ttrain-rmse:1.94158\n",
      "[36660]\teval-rmse:3.79567\ttrain-rmse:1.94155\n",
      "[36661]\teval-rmse:3.79458\ttrain-rmse:1.94153\n",
      "[36662]\teval-rmse:3.79279\ttrain-rmse:1.94143\n",
      "[36663]\teval-rmse:3.79225\ttrain-rmse:1.94141\n",
      "[36664]\teval-rmse:3.79222\ttrain-rmse:1.94141\n",
      "[36665]\teval-rmse:3.79178\ttrain-rmse:1.94139\n",
      "[36666]\teval-rmse:3.7933\ttrain-rmse:1.94143\n",
      "[36667]\teval-rmse:3.79148\ttrain-rmse:1.94137\n",
      "[36668]\teval-rmse:3.79287\ttrain-rmse:1.94141\n",
      "[36669]\teval-rmse:3.79336\ttrain-rmse:1.94144\n",
      "[36670]\teval-rmse:3.79494\ttrain-rmse:1.94151\n",
      "[36671]\teval-rmse:3.79468\ttrain-rmse:1.9415\n",
      "[36672]\teval-rmse:3.79534\ttrain-rmse:1.94153\n",
      "[36673]\teval-rmse:3.79515\ttrain-rmse:1.94152\n",
      "[36674]\teval-rmse:3.79479\ttrain-rmse:1.94151\n",
      "[36675]\teval-rmse:3.79491\ttrain-rmse:1.94152\n",
      "[36676]\teval-rmse:3.79415\ttrain-rmse:1.94149\n",
      "[36677]\teval-rmse:3.79426\ttrain-rmse:1.94149\n",
      "[36678]\teval-rmse:3.7946\ttrain-rmse:1.94151\n",
      "[36679]\teval-rmse:3.7944\ttrain-rmse:1.94151\n",
      "[36680]\teval-rmse:3.79592\ttrain-rmse:1.94155\n",
      "[36681]\teval-rmse:3.79657\ttrain-rmse:1.94158\n",
      "[36682]\teval-rmse:3.79636\ttrain-rmse:1.94155\n",
      "[36683]\teval-rmse:3.79558\ttrain-rmse:1.9415\n",
      "[36684]\teval-rmse:3.7936\ttrain-rmse:1.94142\n",
      "[36685]\teval-rmse:3.79161\ttrain-rmse:1.94133\n",
      "[36686]\teval-rmse:3.79285\ttrain-rmse:1.94136\n",
      "[36687]\teval-rmse:3.79316\ttrain-rmse:1.94138\n",
      "[36688]\teval-rmse:3.79265\ttrain-rmse:1.94136\n",
      "[36689]\teval-rmse:3.79284\ttrain-rmse:1.94137\n",
      "[36690]\teval-rmse:3.79136\ttrain-rmse:1.94131\n",
      "[36691]\teval-rmse:3.78976\ttrain-rmse:1.94127\n",
      "[36692]\teval-rmse:3.78936\ttrain-rmse:1.94127\n",
      "[36693]\teval-rmse:3.79037\ttrain-rmse:1.9413\n",
      "[36694]\teval-rmse:3.79181\ttrain-rmse:1.94131\n",
      "[36695]\teval-rmse:3.79216\ttrain-rmse:1.94133\n",
      "[36696]\teval-rmse:3.79241\ttrain-rmse:1.94134\n",
      "[36697]\teval-rmse:3.79254\ttrain-rmse:1.94135\n",
      "[36698]\teval-rmse:3.79095\ttrain-rmse:1.94127\n",
      "[36699]\teval-rmse:3.79133\ttrain-rmse:1.94128\n",
      "[36700]\teval-rmse:3.79274\ttrain-rmse:1.94135\n",
      "[36701]\teval-rmse:3.79408\ttrain-rmse:1.9414\n",
      "[36702]\teval-rmse:3.79425\ttrain-rmse:1.94141\n",
      "[36703]\teval-rmse:3.79283\ttrain-rmse:1.94135\n",
      "[36704]\teval-rmse:3.79156\ttrain-rmse:1.94132\n",
      "[36705]\teval-rmse:3.79049\ttrain-rmse:1.94131\n",
      "[36706]\teval-rmse:3.79189\ttrain-rmse:1.94134\n",
      "[36707]\teval-rmse:3.79304\ttrain-rmse:1.94138\n",
      "[36708]\teval-rmse:3.79446\ttrain-rmse:1.9414\n",
      "[36709]\teval-rmse:3.79395\ttrain-rmse:1.94139\n",
      "[36710]\teval-rmse:3.79437\ttrain-rmse:1.94141\n",
      "[36711]\teval-rmse:3.79482\ttrain-rmse:1.94143\n",
      "[36712]\teval-rmse:3.79373\ttrain-rmse:1.94141\n",
      "[36713]\teval-rmse:3.7939\ttrain-rmse:1.94141\n",
      "[36714]\teval-rmse:3.79336\ttrain-rmse:1.94139\n",
      "[36715]\teval-rmse:3.79475\ttrain-rmse:1.94143\n",
      "[36716]\teval-rmse:3.79615\ttrain-rmse:1.9415\n",
      "[36717]\teval-rmse:3.79588\ttrain-rmse:1.94149\n",
      "[36718]\teval-rmse:3.79511\ttrain-rmse:1.94145\n",
      "[36719]\teval-rmse:3.7938\ttrain-rmse:1.94143\n",
      "[36720]\teval-rmse:3.79409\ttrain-rmse:1.94145\n",
      "[36721]\teval-rmse:3.79582\ttrain-rmse:1.94148\n",
      "[36722]\teval-rmse:3.79401\ttrain-rmse:1.94138\n",
      "[36723]\teval-rmse:3.79202\ttrain-rmse:1.94132\n",
      "[36724]\teval-rmse:3.79143\ttrain-rmse:1.9413\n",
      "[36725]\teval-rmse:3.79184\ttrain-rmse:1.94132\n",
      "[36726]\teval-rmse:3.79135\ttrain-rmse:1.9413\n",
      "[36727]\teval-rmse:3.79213\ttrain-rmse:1.94132\n",
      "[36728]\teval-rmse:3.79237\ttrain-rmse:1.94133\n",
      "[36729]\teval-rmse:3.79354\ttrain-rmse:1.94136\n",
      "[36730]\teval-rmse:3.79246\ttrain-rmse:1.94134\n",
      "[36731]\teval-rmse:3.79227\ttrain-rmse:1.94132\n",
      "[36732]\teval-rmse:3.79192\ttrain-rmse:1.94131\n",
      "[36733]\teval-rmse:3.79234\ttrain-rmse:1.94133\n",
      "[36734]\teval-rmse:3.79209\ttrain-rmse:1.94132\n",
      "[36735]\teval-rmse:3.79246\ttrain-rmse:1.94134\n",
      "[36736]\teval-rmse:3.79287\ttrain-rmse:1.94136\n",
      "[36737]\teval-rmse:3.79442\ttrain-rmse:1.94142\n",
      "[36738]\teval-rmse:3.79243\ttrain-rmse:1.94134\n",
      "[36739]\teval-rmse:3.79383\ttrain-rmse:1.9414\n",
      "[36740]\teval-rmse:3.79363\ttrain-rmse:1.94139\n",
      "[36741]\teval-rmse:3.7939\ttrain-rmse:1.94141\n",
      "[36742]\teval-rmse:3.79533\ttrain-rmse:1.94143\n",
      "[36743]\teval-rmse:3.79497\ttrain-rmse:1.94143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36744]\teval-rmse:3.79369\ttrain-rmse:1.94137\n",
      "[36745]\teval-rmse:3.79484\ttrain-rmse:1.94142\n",
      "[36746]\teval-rmse:3.79627\ttrain-rmse:1.94145\n",
      "[36747]\teval-rmse:3.79745\ttrain-rmse:1.94152\n",
      "[36748]\teval-rmse:3.7979\ttrain-rmse:1.94155\n",
      "[36749]\teval-rmse:3.79915\ttrain-rmse:1.94163\n",
      "[36750]\teval-rmse:3.80065\ttrain-rmse:1.94168\n",
      "[36751]\teval-rmse:3.79953\ttrain-rmse:1.94164\n",
      "[36752]\teval-rmse:3.80021\ttrain-rmse:1.94169\n",
      "[36753]\teval-rmse:3.79942\ttrain-rmse:1.94164\n",
      "[36754]\teval-rmse:3.79922\ttrain-rmse:1.94163\n",
      "[36755]\teval-rmse:3.79901\ttrain-rmse:1.94162\n",
      "[36756]\teval-rmse:3.80049\ttrain-rmse:1.94171\n",
      "[36757]\teval-rmse:3.8018\ttrain-rmse:1.94181\n",
      "[36758]\teval-rmse:3.80017\ttrain-rmse:1.9417\n",
      "[36759]\teval-rmse:3.79886\ttrain-rmse:1.94162\n",
      "[36760]\teval-rmse:3.79757\ttrain-rmse:1.94155\n",
      "[36761]\teval-rmse:3.79879\ttrain-rmse:1.94161\n",
      "[36762]\teval-rmse:3.79876\ttrain-rmse:1.9416\n",
      "[36763]\teval-rmse:3.80031\ttrain-rmse:1.9417\n",
      "[36764]\teval-rmse:3.79919\ttrain-rmse:1.94166\n",
      "[36765]\teval-rmse:3.79898\ttrain-rmse:1.94163\n",
      "[36766]\teval-rmse:3.79906\ttrain-rmse:1.94164\n",
      "[36767]\teval-rmse:3.80037\ttrain-rmse:1.94172\n",
      "[36768]\teval-rmse:3.79875\ttrain-rmse:1.9416\n",
      "[36769]\teval-rmse:3.79894\ttrain-rmse:1.94161\n",
      "[36770]\teval-rmse:3.80066\ttrain-rmse:1.94166\n",
      "[36771]\teval-rmse:3.80117\ttrain-rmse:1.94169\n",
      "[36772]\teval-rmse:3.80055\ttrain-rmse:1.94166\n",
      "[36773]\teval-rmse:3.79903\ttrain-rmse:1.94157\n",
      "[36774]\teval-rmse:3.80017\ttrain-rmse:1.94166\n",
      "[36775]\teval-rmse:3.80133\ttrain-rmse:1.94173\n",
      "[36776]\teval-rmse:3.80171\ttrain-rmse:1.94176\n",
      "[36777]\teval-rmse:3.8032\ttrain-rmse:1.94186\n",
      "[36778]\teval-rmse:3.80135\ttrain-rmse:1.94171\n",
      "[36779]\teval-rmse:3.80155\ttrain-rmse:1.94172\n",
      "[36780]\teval-rmse:3.80125\ttrain-rmse:1.94171\n",
      "[36781]\teval-rmse:3.80067\ttrain-rmse:1.94168\n",
      "[36782]\teval-rmse:3.80012\ttrain-rmse:1.94165\n",
      "[36783]\teval-rmse:3.79952\ttrain-rmse:1.94161\n",
      "[36784]\teval-rmse:3.79985\ttrain-rmse:1.94163\n",
      "[36785]\teval-rmse:3.80018\ttrain-rmse:1.94165\n",
      "[36786]\teval-rmse:3.80034\ttrain-rmse:1.94166\n",
      "[36787]\teval-rmse:3.80184\ttrain-rmse:1.94176\n",
      "[36788]\teval-rmse:3.80162\ttrain-rmse:1.94173\n",
      "[36789]\teval-rmse:3.80033\ttrain-rmse:1.94166\n",
      "[36790]\teval-rmse:3.80046\ttrain-rmse:1.94168\n",
      "[36791]\teval-rmse:3.80023\ttrain-rmse:1.94165\n",
      "[36792]\teval-rmse:3.8003\ttrain-rmse:1.94165\n",
      "[36793]\teval-rmse:3.79877\ttrain-rmse:1.94156\n",
      "[36794]\teval-rmse:3.79833\ttrain-rmse:1.94154\n",
      "[36795]\teval-rmse:3.79879\ttrain-rmse:1.94156\n",
      "[36796]\teval-rmse:3.79851\ttrain-rmse:1.94155\n",
      "[36797]\teval-rmse:3.79718\ttrain-rmse:1.94151\n",
      "[36798]\teval-rmse:3.79742\ttrain-rmse:1.94152\n",
      "[36799]\teval-rmse:3.7968\ttrain-rmse:1.94149\n",
      "[36800]\teval-rmse:3.79526\ttrain-rmse:1.94139\n",
      "[36801]\teval-rmse:3.79605\ttrain-rmse:1.94144\n",
      "[36802]\teval-rmse:3.79553\ttrain-rmse:1.94142\n",
      "[36803]\teval-rmse:3.79704\ttrain-rmse:1.94145\n",
      "[36804]\teval-rmse:3.79666\ttrain-rmse:1.94145\n",
      "[36805]\teval-rmse:3.79629\ttrain-rmse:1.94143\n",
      "[36806]\teval-rmse:3.79685\ttrain-rmse:1.94147\n",
      "[36807]\teval-rmse:3.79826\ttrain-rmse:1.94153\n",
      "[36808]\teval-rmse:3.79663\ttrain-rmse:1.94144\n",
      "[36809]\teval-rmse:3.79619\ttrain-rmse:1.94142\n",
      "[36810]\teval-rmse:3.79485\ttrain-rmse:1.94134\n",
      "[36811]\teval-rmse:3.79607\ttrain-rmse:1.9414\n",
      "[36812]\teval-rmse:3.7957\ttrain-rmse:1.94139\n",
      "[36813]\teval-rmse:3.79719\ttrain-rmse:1.94145\n",
      "[36814]\teval-rmse:3.79698\ttrain-rmse:1.94143\n",
      "[36815]\teval-rmse:3.79677\ttrain-rmse:1.94141\n",
      "[36816]\teval-rmse:3.79702\ttrain-rmse:1.94142\n",
      "[36817]\teval-rmse:3.79823\ttrain-rmse:1.94151\n",
      "[36818]\teval-rmse:3.79891\ttrain-rmse:1.94153\n",
      "[36819]\teval-rmse:3.79918\ttrain-rmse:1.94155\n",
      "[36820]\teval-rmse:3.79807\ttrain-rmse:1.94151\n",
      "[36821]\teval-rmse:3.79962\ttrain-rmse:1.94161\n",
      "[36822]\teval-rmse:3.79933\ttrain-rmse:1.94159\n",
      "[36823]\teval-rmse:3.8\ttrain-rmse:1.94164\n",
      "[36824]\teval-rmse:3.79921\ttrain-rmse:1.94157\n",
      "[36825]\teval-rmse:3.79809\ttrain-rmse:1.94154\n",
      "[36826]\teval-rmse:3.79802\ttrain-rmse:1.94153\n",
      "[36827]\teval-rmse:3.79641\ttrain-rmse:1.94142\n",
      "[36828]\teval-rmse:3.79706\ttrain-rmse:1.94146\n",
      "[36829]\teval-rmse:3.79628\ttrain-rmse:1.94141\n",
      "[36830]\teval-rmse:3.79785\ttrain-rmse:1.94145\n",
      "[36831]\teval-rmse:3.79812\ttrain-rmse:1.94147\n",
      "[36832]\teval-rmse:3.79767\ttrain-rmse:1.94145\n",
      "[36833]\teval-rmse:3.79884\ttrain-rmse:1.94152\n",
      "[36834]\teval-rmse:3.7995\ttrain-rmse:1.94154\n",
      "[36835]\teval-rmse:3.79869\ttrain-rmse:1.94149\n",
      "[36836]\teval-rmse:3.79886\ttrain-rmse:1.9415\n",
      "[36837]\teval-rmse:3.79926\ttrain-rmse:1.94153\n",
      "[36838]\teval-rmse:3.79889\ttrain-rmse:1.94152\n",
      "[36839]\teval-rmse:3.79738\ttrain-rmse:1.94141\n",
      "[36840]\teval-rmse:3.7966\ttrain-rmse:1.94137\n",
      "[36841]\teval-rmse:3.79677\ttrain-rmse:1.94138\n",
      "[36842]\teval-rmse:3.79541\ttrain-rmse:1.94131\n",
      "[36843]\teval-rmse:3.79568\ttrain-rmse:1.94132\n",
      "[36844]\teval-rmse:3.79409\ttrain-rmse:1.94123\n",
      "[36845]\teval-rmse:3.79259\ttrain-rmse:1.94118\n",
      "[36846]\teval-rmse:3.79318\ttrain-rmse:1.94121\n",
      "[36847]\teval-rmse:3.79201\ttrain-rmse:1.94115\n",
      "[36848]\teval-rmse:3.79253\ttrain-rmse:1.94117\n",
      "[36849]\teval-rmse:3.79089\ttrain-rmse:1.94113\n",
      "[36850]\teval-rmse:3.79263\ttrain-rmse:1.94115\n",
      "[36851]\teval-rmse:3.79125\ttrain-rmse:1.94111\n",
      "[36852]\teval-rmse:3.7909\ttrain-rmse:1.94111\n",
      "[36853]\teval-rmse:3.79208\ttrain-rmse:1.94115\n",
      "[36854]\teval-rmse:3.79038\ttrain-rmse:1.94108\n",
      "[36855]\teval-rmse:3.78984\ttrain-rmse:1.94107\n",
      "[36856]\teval-rmse:3.78833\ttrain-rmse:1.94102\n",
      "[36857]\teval-rmse:3.78816\ttrain-rmse:1.94102\n",
      "[36858]\teval-rmse:3.78837\ttrain-rmse:1.94103\n",
      "[36859]\teval-rmse:3.78858\ttrain-rmse:1.94103\n",
      "[36860]\teval-rmse:3.78698\ttrain-rmse:1.941\n",
      "[36861]\teval-rmse:3.78593\ttrain-rmse:1.94099\n",
      "[36862]\teval-rmse:3.78726\ttrain-rmse:1.94101\n",
      "[36863]\teval-rmse:3.78901\ttrain-rmse:1.94102\n",
      "[36864]\teval-rmse:3.78755\ttrain-rmse:1.941\n",
      "[36865]\teval-rmse:3.78598\ttrain-rmse:1.94097\n",
      "[36866]\teval-rmse:3.78542\ttrain-rmse:1.94096\n",
      "[36867]\teval-rmse:3.78592\ttrain-rmse:1.94097\n",
      "[36868]\teval-rmse:3.78577\ttrain-rmse:1.94095\n",
      "[36869]\teval-rmse:3.78623\ttrain-rmse:1.94096\n",
      "[36870]\teval-rmse:3.78675\ttrain-rmse:1.94096\n",
      "[36871]\teval-rmse:3.78728\ttrain-rmse:1.94097\n",
      "[36872]\teval-rmse:3.78765\ttrain-rmse:1.94098\n",
      "[36873]\teval-rmse:3.78794\ttrain-rmse:1.94099\n",
      "[36874]\teval-rmse:3.78952\ttrain-rmse:1.94103\n",
      "[36875]\teval-rmse:3.78895\ttrain-rmse:1.94102\n",
      "[36876]\teval-rmse:3.7905\ttrain-rmse:1.94106\n",
      "[36877]\teval-rmse:3.79207\ttrain-rmse:1.94113\n",
      "[36878]\teval-rmse:3.79257\ttrain-rmse:1.94116\n",
      "[36879]\teval-rmse:3.79239\ttrain-rmse:1.94115\n",
      "[36880]\teval-rmse:3.79116\ttrain-rmse:1.94109\n",
      "[36881]\teval-rmse:3.79157\ttrain-rmse:1.94111\n",
      "[36882]\teval-rmse:3.7905\ttrain-rmse:1.9411\n",
      "[36883]\teval-rmse:3.79033\ttrain-rmse:1.94108\n",
      "[36884]\teval-rmse:3.79172\ttrain-rmse:1.94112\n",
      "[36885]\teval-rmse:3.79009\ttrain-rmse:1.94108\n",
      "[36886]\teval-rmse:3.78936\ttrain-rmse:1.94105\n",
      "[36887]\teval-rmse:3.78987\ttrain-rmse:1.94107\n",
      "[36888]\teval-rmse:3.78847\ttrain-rmse:1.94103\n",
      "[36889]\teval-rmse:3.78774\ttrain-rmse:1.94101\n",
      "[36890]\teval-rmse:3.78638\ttrain-rmse:1.94101\n",
      "[36891]\teval-rmse:3.78737\ttrain-rmse:1.94103\n",
      "[36892]\teval-rmse:3.78602\ttrain-rmse:1.94101\n",
      "[36893]\teval-rmse:3.78569\ttrain-rmse:1.94101\n",
      "[36894]\teval-rmse:3.78553\ttrain-rmse:1.94101\n",
      "[36895]\teval-rmse:3.78425\ttrain-rmse:1.94098\n",
      "[36896]\teval-rmse:3.78372\ttrain-rmse:1.94098\n",
      "[36897]\teval-rmse:3.7843\ttrain-rmse:1.94099\n",
      "[36898]\teval-rmse:3.7845\ttrain-rmse:1.941\n",
      "[36899]\teval-rmse:3.78462\ttrain-rmse:1.941\n",
      "[36900]\teval-rmse:3.78561\ttrain-rmse:1.94103\n",
      "[36901]\teval-rmse:3.78573\ttrain-rmse:1.94103\n",
      "[36902]\teval-rmse:3.78705\ttrain-rmse:1.94107\n",
      "[36903]\teval-rmse:3.7882\ttrain-rmse:1.9411\n",
      "[36904]\teval-rmse:3.78664\ttrain-rmse:1.94104\n",
      "[36905]\teval-rmse:3.78487\ttrain-rmse:1.94099\n",
      "[36906]\teval-rmse:3.78472\ttrain-rmse:1.94099\n",
      "[36907]\teval-rmse:3.78516\ttrain-rmse:1.941\n",
      "[36908]\teval-rmse:3.78445\ttrain-rmse:1.94098\n",
      "[36909]\teval-rmse:3.78429\ttrain-rmse:1.94096\n",
      "[36910]\teval-rmse:3.78413\ttrain-rmse:1.94096\n",
      "[36911]\teval-rmse:3.78426\ttrain-rmse:1.94097\n",
      "[36912]\teval-rmse:3.78444\ttrain-rmse:1.94097\n",
      "[36913]\teval-rmse:3.78292\ttrain-rmse:1.94096\n",
      "[36914]\teval-rmse:3.78166\ttrain-rmse:1.94095\n",
      "[36915]\teval-rmse:3.78065\ttrain-rmse:1.94096\n",
      "[36916]\teval-rmse:3.78119\ttrain-rmse:1.94096\n",
      "[36917]\teval-rmse:3.77962\ttrain-rmse:1.94096\n",
      "[36918]\teval-rmse:3.78137\ttrain-rmse:1.94094\n",
      "[36919]\teval-rmse:3.7798\ttrain-rmse:1.94095\n",
      "[36920]\teval-rmse:3.77944\ttrain-rmse:1.94095\n",
      "[36921]\teval-rmse:3.77826\ttrain-rmse:1.94096\n",
      "[36922]\teval-rmse:3.77806\ttrain-rmse:1.94096\n",
      "[36923]\teval-rmse:3.77908\ttrain-rmse:1.94096\n",
      "[36924]\teval-rmse:3.77939\ttrain-rmse:1.94096\n",
      "[36925]\teval-rmse:3.78072\ttrain-rmse:1.94097\n",
      "[36926]\teval-rmse:3.78222\ttrain-rmse:1.94098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36927]\teval-rmse:3.78371\ttrain-rmse:1.94101\n",
      "[36928]\teval-rmse:3.783\ttrain-rmse:1.941\n",
      "[36929]\teval-rmse:3.78158\ttrain-rmse:1.94099\n",
      "[36930]\teval-rmse:3.78128\ttrain-rmse:1.94099\n",
      "[36931]\teval-rmse:3.77936\ttrain-rmse:1.941\n",
      "[36932]\teval-rmse:3.77988\ttrain-rmse:1.94101\n",
      "[36933]\teval-rmse:3.78141\ttrain-rmse:1.94101\n",
      "[36934]\teval-rmse:3.78159\ttrain-rmse:1.94101\n",
      "[36935]\teval-rmse:3.78025\ttrain-rmse:1.94101\n",
      "[36936]\teval-rmse:3.77952\ttrain-rmse:1.94101\n",
      "[36937]\teval-rmse:3.77885\ttrain-rmse:1.941\n",
      "[36938]\teval-rmse:3.7791\ttrain-rmse:1.941\n",
      "[36939]\teval-rmse:3.77865\ttrain-rmse:1.94101\n",
      "[36940]\teval-rmse:3.7775\ttrain-rmse:1.94104\n",
      "[36941]\teval-rmse:3.77894\ttrain-rmse:1.94103\n",
      "[36942]\teval-rmse:3.77752\ttrain-rmse:1.94103\n",
      "[36943]\teval-rmse:3.77715\ttrain-rmse:1.94103\n",
      "[36944]\teval-rmse:3.77712\ttrain-rmse:1.94103\n",
      "[36945]\teval-rmse:3.77729\ttrain-rmse:1.94103\n",
      "[36946]\teval-rmse:3.77854\ttrain-rmse:1.94102\n",
      "[36947]\teval-rmse:3.77884\ttrain-rmse:1.94102\n",
      "[36948]\teval-rmse:3.77742\ttrain-rmse:1.94102\n",
      "[36949]\teval-rmse:3.77594\ttrain-rmse:1.94104\n",
      "[36950]\teval-rmse:3.77629\ttrain-rmse:1.94103\n",
      "[36951]\teval-rmse:3.77681\ttrain-rmse:1.94103\n",
      "[36952]\teval-rmse:3.77707\ttrain-rmse:1.94103\n",
      "[36953]\teval-rmse:3.77578\ttrain-rmse:1.94106\n",
      "[36954]\teval-rmse:3.77509\ttrain-rmse:1.94107\n",
      "[36955]\teval-rmse:3.7755\ttrain-rmse:1.94106\n",
      "[36956]\teval-rmse:3.77408\ttrain-rmse:1.9411\n",
      "[36957]\teval-rmse:3.77439\ttrain-rmse:1.94109\n",
      "[36958]\teval-rmse:3.77422\ttrain-rmse:1.9411\n",
      "[36959]\teval-rmse:3.77353\ttrain-rmse:1.94111\n",
      "[36960]\teval-rmse:3.77506\ttrain-rmse:1.94107\n",
      "[36961]\teval-rmse:3.7748\ttrain-rmse:1.94108\n",
      "[36962]\teval-rmse:3.77613\ttrain-rmse:1.94106\n",
      "[36963]\teval-rmse:3.77646\ttrain-rmse:1.94106\n",
      "[36964]\teval-rmse:3.77768\ttrain-rmse:1.94106\n",
      "[36965]\teval-rmse:3.77709\ttrain-rmse:1.94106\n",
      "[36966]\teval-rmse:3.77567\ttrain-rmse:1.94108\n",
      "[36967]\teval-rmse:3.77521\ttrain-rmse:1.94108\n",
      "[36968]\teval-rmse:3.7766\ttrain-rmse:1.94107\n",
      "[36969]\teval-rmse:3.77762\ttrain-rmse:1.94107\n",
      "[36970]\teval-rmse:3.77808\ttrain-rmse:1.94107\n",
      "[36971]\teval-rmse:3.77651\ttrain-rmse:1.94108\n",
      "[36972]\teval-rmse:3.77554\ttrain-rmse:1.94111\n",
      "[36973]\teval-rmse:3.77672\ttrain-rmse:1.94108\n",
      "[36974]\teval-rmse:3.77821\ttrain-rmse:1.94107\n",
      "[36975]\teval-rmse:3.77979\ttrain-rmse:1.94107\n",
      "[36976]\teval-rmse:3.78154\ttrain-rmse:1.94104\n",
      "[36977]\teval-rmse:3.78152\ttrain-rmse:1.94104\n",
      "[36978]\teval-rmse:3.78189\ttrain-rmse:1.94105\n",
      "[36979]\teval-rmse:3.78363\ttrain-rmse:1.94104\n",
      "[36980]\teval-rmse:3.78506\ttrain-rmse:1.94103\n",
      "[36981]\teval-rmse:3.78403\ttrain-rmse:1.94103\n",
      "[36982]\teval-rmse:3.7845\ttrain-rmse:1.94104\n",
      "[36983]\teval-rmse:3.78308\ttrain-rmse:1.941\n",
      "[36984]\teval-rmse:3.78289\ttrain-rmse:1.941\n",
      "[36985]\teval-rmse:3.783\ttrain-rmse:1.941\n",
      "[36986]\teval-rmse:3.78353\ttrain-rmse:1.94101\n",
      "[36987]\teval-rmse:3.78465\ttrain-rmse:1.94103\n",
      "[36988]\teval-rmse:3.78425\ttrain-rmse:1.94102\n",
      "[36989]\teval-rmse:3.78352\ttrain-rmse:1.941\n",
      "[36990]\teval-rmse:3.78194\ttrain-rmse:1.94099\n",
      "[36991]\teval-rmse:3.78093\ttrain-rmse:1.941\n",
      "[36992]\teval-rmse:3.78227\ttrain-rmse:1.94101\n",
      "[36993]\teval-rmse:3.7811\ttrain-rmse:1.94102\n",
      "[36994]\teval-rmse:3.7815\ttrain-rmse:1.94103\n",
      "[36995]\teval-rmse:3.78197\ttrain-rmse:1.94103\n",
      "[36996]\teval-rmse:3.78242\ttrain-rmse:1.94104\n",
      "[36997]\teval-rmse:3.78141\ttrain-rmse:1.94105\n",
      "[36998]\teval-rmse:3.78019\ttrain-rmse:1.94104\n",
      "[36999]\teval-rmse:3.78193\ttrain-rmse:1.94102\n",
      "[37000]\teval-rmse:3.78214\ttrain-rmse:1.94103\n",
      "[37001]\teval-rmse:3.78057\ttrain-rmse:1.94102\n",
      "[37002]\teval-rmse:3.78078\ttrain-rmse:1.94102\n",
      "[37003]\teval-rmse:3.78131\ttrain-rmse:1.94103\n",
      "[37004]\teval-rmse:3.77998\ttrain-rmse:1.94103\n",
      "[37005]\teval-rmse:3.78172\ttrain-rmse:1.941\n",
      "[37006]\teval-rmse:3.78125\ttrain-rmse:1.941\n",
      "[37007]\teval-rmse:3.77935\ttrain-rmse:1.94101\n",
      "[37008]\teval-rmse:3.77921\ttrain-rmse:1.94098\n",
      "[37009]\teval-rmse:3.77854\ttrain-rmse:1.94098\n",
      "[37010]\teval-rmse:3.78003\ttrain-rmse:1.94096\n",
      "[37011]\teval-rmse:3.77985\ttrain-rmse:1.94096\n",
      "[37012]\teval-rmse:3.78032\ttrain-rmse:1.94097\n",
      "[37013]\teval-rmse:3.78172\ttrain-rmse:1.94096\n",
      "[37014]\teval-rmse:3.77996\ttrain-rmse:1.94094\n",
      "[37015]\teval-rmse:3.78025\ttrain-rmse:1.94095\n",
      "[37016]\teval-rmse:3.78024\ttrain-rmse:1.94094\n",
      "[37017]\teval-rmse:3.77895\ttrain-rmse:1.94094\n",
      "[37018]\teval-rmse:3.77882\ttrain-rmse:1.94092\n",
      "[37019]\teval-rmse:3.78056\ttrain-rmse:1.9409\n",
      "[37020]\teval-rmse:3.78017\ttrain-rmse:1.9409\n",
      "[37021]\teval-rmse:3.78134\ttrain-rmse:1.94091\n",
      "[37022]\teval-rmse:3.78151\ttrain-rmse:1.94091\n",
      "[37023]\teval-rmse:3.78199\ttrain-rmse:1.94091\n",
      "[37024]\teval-rmse:3.78184\ttrain-rmse:1.94089\n",
      "[37025]\teval-rmse:3.78207\ttrain-rmse:1.94089\n",
      "[37026]\teval-rmse:3.78253\ttrain-rmse:1.94089\n",
      "[37027]\teval-rmse:3.78301\ttrain-rmse:1.9409\n",
      "[37028]\teval-rmse:3.78255\ttrain-rmse:1.94091\n",
      "[37029]\teval-rmse:3.78186\ttrain-rmse:1.9409\n",
      "[37030]\teval-rmse:3.78255\ttrain-rmse:1.94089\n",
      "[37031]\teval-rmse:3.78371\ttrain-rmse:1.9409\n",
      "[37032]\teval-rmse:3.78441\ttrain-rmse:1.94091\n",
      "[37033]\teval-rmse:3.78493\ttrain-rmse:1.94092\n",
      "[37034]\teval-rmse:3.78422\ttrain-rmse:1.9409\n",
      "[37035]\teval-rmse:3.78382\ttrain-rmse:1.94089\n",
      "[37036]\teval-rmse:3.78397\ttrain-rmse:1.94089\n",
      "[37037]\teval-rmse:3.7854\ttrain-rmse:1.94089\n",
      "[37038]\teval-rmse:3.78469\ttrain-rmse:1.94087\n",
      "[37039]\teval-rmse:3.78449\ttrain-rmse:1.94087\n",
      "[37040]\teval-rmse:3.78592\ttrain-rmse:1.94086\n",
      "[37041]\teval-rmse:3.78575\ttrain-rmse:1.94084\n",
      "[37042]\teval-rmse:3.78425\ttrain-rmse:1.94082\n",
      "[37043]\teval-rmse:3.78292\ttrain-rmse:1.9408\n",
      "[37044]\teval-rmse:3.78151\ttrain-rmse:1.94079\n",
      "[37045]\teval-rmse:3.78198\ttrain-rmse:1.94079\n",
      "[37046]\teval-rmse:3.78177\ttrain-rmse:1.94079\n",
      "[37047]\teval-rmse:3.7806\ttrain-rmse:1.94081\n",
      "[37048]\teval-rmse:3.7821\ttrain-rmse:1.94081\n",
      "[37049]\teval-rmse:3.78263\ttrain-rmse:1.94081\n",
      "[37050]\teval-rmse:3.78395\ttrain-rmse:1.94081\n",
      "[37051]\teval-rmse:3.7838\ttrain-rmse:1.9408\n",
      "[37052]\teval-rmse:3.78531\ttrain-rmse:1.94082\n",
      "[37053]\teval-rmse:3.78516\ttrain-rmse:1.9408\n",
      "[37054]\teval-rmse:3.78634\ttrain-rmse:1.94083\n",
      "[37055]\teval-rmse:3.78457\ttrain-rmse:1.9408\n",
      "[37056]\teval-rmse:3.78487\ttrain-rmse:1.94081\n",
      "[37057]\teval-rmse:3.78366\ttrain-rmse:1.94079\n",
      "[37058]\teval-rmse:3.78381\ttrain-rmse:1.94079\n",
      "[37059]\teval-rmse:3.78532\ttrain-rmse:1.94081\n",
      "[37060]\teval-rmse:3.78706\ttrain-rmse:1.94081\n",
      "[37061]\teval-rmse:3.78683\ttrain-rmse:1.94081\n",
      "[37062]\teval-rmse:3.78698\ttrain-rmse:1.94081\n",
      "[37063]\teval-rmse:3.78572\ttrain-rmse:1.94079\n",
      "[37064]\teval-rmse:3.78394\ttrain-rmse:1.94076\n",
      "[37065]\teval-rmse:3.7841\ttrain-rmse:1.94076\n",
      "[37066]\teval-rmse:3.78456\ttrain-rmse:1.94077\n",
      "[37067]\teval-rmse:3.78629\ttrain-rmse:1.94077\n",
      "[37068]\teval-rmse:3.78525\ttrain-rmse:1.94077\n",
      "[37069]\teval-rmse:3.78494\ttrain-rmse:1.94077\n",
      "[37070]\teval-rmse:3.78478\ttrain-rmse:1.94075\n",
      "[37071]\teval-rmse:3.78635\ttrain-rmse:1.94078\n",
      "[37072]\teval-rmse:3.78673\ttrain-rmse:1.94078\n",
      "[37073]\teval-rmse:3.78656\ttrain-rmse:1.94078\n",
      "[37074]\teval-rmse:3.78701\ttrain-rmse:1.9408\n",
      "[37075]\teval-rmse:3.78747\ttrain-rmse:1.9408\n",
      "[37076]\teval-rmse:3.78898\ttrain-rmse:1.94085\n",
      "[37077]\teval-rmse:3.78737\ttrain-rmse:1.94081\n",
      "[37078]\teval-rmse:3.78807\ttrain-rmse:1.94082\n",
      "[37079]\teval-rmse:3.78851\ttrain-rmse:1.94083\n",
      "[37080]\teval-rmse:3.78936\ttrain-rmse:1.94086\n",
      "[37081]\teval-rmse:3.78766\ttrain-rmse:1.94081\n",
      "[37082]\teval-rmse:3.78635\ttrain-rmse:1.9408\n",
      "[37083]\teval-rmse:3.78531\ttrain-rmse:1.9408\n",
      "[37084]\teval-rmse:3.7869\ttrain-rmse:1.94079\n",
      "[37085]\teval-rmse:3.78657\ttrain-rmse:1.94079\n",
      "[37086]\teval-rmse:3.78671\ttrain-rmse:1.94079\n",
      "[37087]\teval-rmse:3.78821\ttrain-rmse:1.94083\n",
      "[37088]\teval-rmse:3.78716\ttrain-rmse:1.94082\n",
      "[37089]\teval-rmse:3.78699\ttrain-rmse:1.9408\n",
      "[37090]\teval-rmse:3.78752\ttrain-rmse:1.94081\n",
      "[37091]\teval-rmse:3.78711\ttrain-rmse:1.9408\n",
      "[37092]\teval-rmse:3.78725\ttrain-rmse:1.9408\n",
      "[37093]\teval-rmse:3.78759\ttrain-rmse:1.94081\n",
      "[37094]\teval-rmse:3.78883\ttrain-rmse:1.94083\n",
      "[37095]\teval-rmse:3.79006\ttrain-rmse:1.94086\n",
      "[37096]\teval-rmse:3.78877\ttrain-rmse:1.94081\n",
      "[37097]\teval-rmse:3.78871\ttrain-rmse:1.94081\n",
      "[37098]\teval-rmse:3.78855\ttrain-rmse:1.94078\n",
      "[37099]\teval-rmse:3.78925\ttrain-rmse:1.94079\n",
      "[37100]\teval-rmse:3.78943\ttrain-rmse:1.9408\n",
      "[37101]\teval-rmse:3.79093\ttrain-rmse:1.94086\n",
      "[37102]\teval-rmse:3.79128\ttrain-rmse:1.94087\n",
      "[37103]\teval-rmse:3.78965\ttrain-rmse:1.94082\n",
      "[37104]\teval-rmse:3.78915\ttrain-rmse:1.94081\n",
      "[37105]\teval-rmse:3.78863\ttrain-rmse:1.9408\n",
      "[37106]\teval-rmse:3.78824\ttrain-rmse:1.94079\n",
      "[37107]\teval-rmse:3.78824\ttrain-rmse:1.94079\n",
      "[37108]\teval-rmse:3.78997\ttrain-rmse:1.94081\n",
      "[37109]\teval-rmse:3.79012\ttrain-rmse:1.94081\n",
      "[37110]\teval-rmse:3.79124\ttrain-rmse:1.94084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37111]\teval-rmse:3.79152\ttrain-rmse:1.94085\n",
      "[37112]\teval-rmse:3.79133\ttrain-rmse:1.94083\n",
      "[37113]\teval-rmse:3.79177\ttrain-rmse:1.94084\n",
      "[37114]\teval-rmse:3.79115\ttrain-rmse:1.94082\n",
      "[37115]\teval-rmse:3.79263\ttrain-rmse:1.94087\n",
      "[37116]\teval-rmse:3.79381\ttrain-rmse:1.94094\n",
      "[37117]\teval-rmse:3.7948\ttrain-rmse:1.94099\n",
      "[37118]\teval-rmse:3.79402\ttrain-rmse:1.94097\n",
      "[37119]\teval-rmse:3.79553\ttrain-rmse:1.941\n",
      "[37120]\teval-rmse:3.79389\ttrain-rmse:1.94091\n",
      "[37121]\teval-rmse:3.79264\ttrain-rmse:1.94088\n",
      "[37122]\teval-rmse:3.7938\ttrain-rmse:1.94093\n",
      "[37123]\teval-rmse:3.79538\ttrain-rmse:1.94096\n",
      "[37124]\teval-rmse:3.79517\ttrain-rmse:1.94095\n",
      "[37125]\teval-rmse:3.79462\ttrain-rmse:1.94094\n",
      "[37126]\teval-rmse:3.79319\ttrain-rmse:1.94089\n",
      "[37127]\teval-rmse:3.79211\ttrain-rmse:1.94087\n",
      "[37128]\teval-rmse:3.79052\ttrain-rmse:1.94081\n",
      "[37129]\teval-rmse:3.792\ttrain-rmse:1.94086\n",
      "[37130]\teval-rmse:3.79175\ttrain-rmse:1.94086\n",
      "[37131]\teval-rmse:3.7933\ttrain-rmse:1.9409\n",
      "[37132]\teval-rmse:3.79288\ttrain-rmse:1.94089\n",
      "[37133]\teval-rmse:3.7927\ttrain-rmse:1.94086\n",
      "[37134]\teval-rmse:3.79129\ttrain-rmse:1.94081\n",
      "[37135]\teval-rmse:3.79247\ttrain-rmse:1.94087\n",
      "[37136]\teval-rmse:3.79346\ttrain-rmse:1.94093\n",
      "[37137]\teval-rmse:3.79497\ttrain-rmse:1.94099\n",
      "[37138]\teval-rmse:3.79513\ttrain-rmse:1.941\n",
      "[37139]\teval-rmse:3.7947\ttrain-rmse:1.94098\n",
      "[37140]\teval-rmse:3.79361\ttrain-rmse:1.94096\n",
      "[37141]\teval-rmse:3.79335\ttrain-rmse:1.94095\n",
      "[37142]\teval-rmse:3.79227\ttrain-rmse:1.94093\n",
      "[37143]\teval-rmse:3.79063\ttrain-rmse:1.94084\n",
      "[37144]\teval-rmse:3.78907\ttrain-rmse:1.94077\n",
      "[37145]\teval-rmse:3.78744\ttrain-rmse:1.94073\n",
      "[37146]\teval-rmse:3.78623\ttrain-rmse:1.94072\n",
      "[37147]\teval-rmse:3.78774\ttrain-rmse:1.94075\n",
      "[37148]\teval-rmse:3.78647\ttrain-rmse:1.94072\n",
      "[37149]\teval-rmse:3.78527\ttrain-rmse:1.94071\n",
      "[37150]\teval-rmse:3.78505\ttrain-rmse:1.94071\n",
      "[37151]\teval-rmse:3.78654\ttrain-rmse:1.94074\n",
      "[37152]\teval-rmse:3.78597\ttrain-rmse:1.94073\n",
      "[37153]\teval-rmse:3.78558\ttrain-rmse:1.94072\n",
      "[37154]\teval-rmse:3.78709\ttrain-rmse:1.94074\n",
      "[37155]\teval-rmse:3.78547\ttrain-rmse:1.94071\n",
      "[37156]\teval-rmse:3.78589\ttrain-rmse:1.94072\n",
      "[37157]\teval-rmse:3.78659\ttrain-rmse:1.94072\n",
      "[37158]\teval-rmse:3.7853\ttrain-rmse:1.94069\n",
      "[37159]\teval-rmse:3.78583\ttrain-rmse:1.94071\n",
      "[37160]\teval-rmse:3.78462\ttrain-rmse:1.94069\n",
      "[37161]\teval-rmse:3.78446\ttrain-rmse:1.94069\n",
      "[37162]\teval-rmse:3.78529\ttrain-rmse:1.94071\n",
      "[37163]\teval-rmse:3.78596\ttrain-rmse:1.94071\n",
      "[37164]\teval-rmse:3.78493\ttrain-rmse:1.94071\n",
      "[37165]\teval-rmse:3.78535\ttrain-rmse:1.94073\n",
      "[37166]\teval-rmse:3.78709\ttrain-rmse:1.94073\n",
      "[37167]\teval-rmse:3.78686\ttrain-rmse:1.94073\n",
      "[37168]\teval-rmse:3.78532\ttrain-rmse:1.9407\n",
      "[37169]\teval-rmse:3.78602\ttrain-rmse:1.9407\n",
      "[37170]\teval-rmse:3.7876\ttrain-rmse:1.94073\n",
      "[37171]\teval-rmse:3.78603\ttrain-rmse:1.9407\n",
      "[37172]\teval-rmse:3.78467\ttrain-rmse:1.9407\n",
      "[37173]\teval-rmse:3.78598\ttrain-rmse:1.94073\n",
      "[37174]\teval-rmse:3.78566\ttrain-rmse:1.94073\n",
      "[37175]\teval-rmse:3.78626\ttrain-rmse:1.94074\n",
      "[37176]\teval-rmse:3.78594\ttrain-rmse:1.94074\n",
      "[37177]\teval-rmse:3.78457\ttrain-rmse:1.94071\n",
      "[37178]\teval-rmse:3.7841\ttrain-rmse:1.9407\n",
      "[37179]\teval-rmse:3.78457\ttrain-rmse:1.94072\n",
      "[37180]\teval-rmse:3.78263\ttrain-rmse:1.94068\n",
      "[37181]\teval-rmse:3.78395\ttrain-rmse:1.9407\n",
      "[37182]\teval-rmse:3.78392\ttrain-rmse:1.9407\n",
      "[37183]\teval-rmse:3.78431\ttrain-rmse:1.9407\n",
      "[37184]\teval-rmse:3.7858\ttrain-rmse:1.94073\n",
      "[37185]\teval-rmse:3.7846\ttrain-rmse:1.94073\n",
      "[37186]\teval-rmse:3.78427\ttrain-rmse:1.94072\n",
      "[37187]\teval-rmse:3.78423\ttrain-rmse:1.94072\n",
      "[37188]\teval-rmse:3.7858\ttrain-rmse:1.94076\n",
      "[37189]\teval-rmse:3.78387\ttrain-rmse:1.94073\n",
      "[37190]\teval-rmse:3.78536\ttrain-rmse:1.94074\n",
      "[37191]\teval-rmse:3.78574\ttrain-rmse:1.94076\n",
      "[37192]\teval-rmse:3.78726\ttrain-rmse:1.94079\n",
      "[37193]\teval-rmse:3.78709\ttrain-rmse:1.94079\n",
      "[37194]\teval-rmse:3.78809\ttrain-rmse:1.94083\n",
      "[37195]\teval-rmse:3.78958\ttrain-rmse:1.94087\n",
      "[37196]\teval-rmse:3.78917\ttrain-rmse:1.94087\n",
      "[37197]\teval-rmse:3.78779\ttrain-rmse:1.94085\n",
      "[37198]\teval-rmse:3.78723\ttrain-rmse:1.94084\n",
      "[37199]\teval-rmse:3.78667\ttrain-rmse:1.94082\n",
      "[37200]\teval-rmse:3.78592\ttrain-rmse:1.94081\n",
      "[37201]\teval-rmse:3.78733\ttrain-rmse:1.94085\n",
      "[37202]\teval-rmse:3.78906\ttrain-rmse:1.94086\n",
      "[37203]\teval-rmse:3.78918\ttrain-rmse:1.94086\n",
      "[37204]\teval-rmse:3.79039\ttrain-rmse:1.94091\n",
      "[37205]\teval-rmse:3.7919\ttrain-rmse:1.94095\n",
      "[37206]\teval-rmse:3.79226\ttrain-rmse:1.94097\n",
      "[37207]\teval-rmse:3.79281\ttrain-rmse:1.94099\n",
      "[37208]\teval-rmse:3.79156\ttrain-rmse:1.94093\n",
      "[37209]\teval-rmse:3.79152\ttrain-rmse:1.94092\n",
      "[37210]\teval-rmse:3.78957\ttrain-rmse:1.94084\n",
      "[37211]\teval-rmse:3.78939\ttrain-rmse:1.94084\n",
      "[37212]\teval-rmse:3.78832\ttrain-rmse:1.94083\n",
      "[37213]\teval-rmse:3.78817\ttrain-rmse:1.94083\n",
      "[37214]\teval-rmse:3.7869\ttrain-rmse:1.94079\n",
      "[37215]\teval-rmse:3.78685\ttrain-rmse:1.94079\n",
      "[37216]\teval-rmse:3.78735\ttrain-rmse:1.9408\n",
      "[37217]\teval-rmse:3.78706\ttrain-rmse:1.94079\n",
      "[37218]\teval-rmse:3.78585\ttrain-rmse:1.94077\n",
      "[37219]\teval-rmse:3.78459\ttrain-rmse:1.94075\n",
      "[37220]\teval-rmse:3.7842\ttrain-rmse:1.94075\n",
      "[37221]\teval-rmse:3.78246\ttrain-rmse:1.94072\n",
      "[37222]\teval-rmse:3.78244\ttrain-rmse:1.94072\n",
      "[37223]\teval-rmse:3.78367\ttrain-rmse:1.94073\n",
      "[37224]\teval-rmse:3.78317\ttrain-rmse:1.94073\n",
      "[37225]\teval-rmse:3.78331\ttrain-rmse:1.94073\n",
      "[37226]\teval-rmse:3.78329\ttrain-rmse:1.94073\n",
      "[37227]\teval-rmse:3.78373\ttrain-rmse:1.94074\n",
      "[37228]\teval-rmse:3.78531\ttrain-rmse:1.94074\n",
      "[37229]\teval-rmse:3.78396\ttrain-rmse:1.94071\n",
      "[37230]\teval-rmse:3.78243\ttrain-rmse:1.9407\n",
      "[37231]\teval-rmse:3.78125\ttrain-rmse:1.94068\n",
      "[37232]\teval-rmse:3.77968\ttrain-rmse:1.94069\n",
      "[37233]\teval-rmse:3.77827\ttrain-rmse:1.94068\n",
      "[37234]\teval-rmse:3.77882\ttrain-rmse:1.94068\n",
      "[37235]\teval-rmse:3.77845\ttrain-rmse:1.94068\n",
      "[37236]\teval-rmse:3.77745\ttrain-rmse:1.94069\n",
      "[37237]\teval-rmse:3.77717\ttrain-rmse:1.9407\n",
      "[37238]\teval-rmse:3.77851\ttrain-rmse:1.94068\n",
      "[37239]\teval-rmse:3.77664\ttrain-rmse:1.94072\n",
      "[37240]\teval-rmse:3.77719\ttrain-rmse:1.94071\n",
      "[37241]\teval-rmse:3.77878\ttrain-rmse:1.94068\n",
      "[37242]\teval-rmse:3.78052\ttrain-rmse:1.94067\n",
      "[37243]\teval-rmse:3.77882\ttrain-rmse:1.9407\n",
      "[37244]\teval-rmse:3.77751\ttrain-rmse:1.9407\n",
      "[37245]\teval-rmse:3.77635\ttrain-rmse:1.94072\n",
      "[37246]\teval-rmse:3.77623\ttrain-rmse:1.9407\n",
      "[37247]\teval-rmse:3.77573\ttrain-rmse:1.94071\n",
      "[37248]\teval-rmse:3.77475\ttrain-rmse:1.94073\n",
      "[37249]\teval-rmse:3.77448\ttrain-rmse:1.94073\n",
      "[37250]\teval-rmse:3.77435\ttrain-rmse:1.94074\n",
      "[37251]\teval-rmse:3.77463\ttrain-rmse:1.94073\n",
      "[37252]\teval-rmse:3.77638\ttrain-rmse:1.94069\n",
      "[37253]\teval-rmse:3.77518\ttrain-rmse:1.94071\n",
      "[37254]\teval-rmse:3.77505\ttrain-rmse:1.94069\n",
      "[37255]\teval-rmse:3.77462\ttrain-rmse:1.9407\n",
      "[37256]\teval-rmse:3.77596\ttrain-rmse:1.94068\n",
      "[37257]\teval-rmse:3.77498\ttrain-rmse:1.9407\n",
      "[37258]\teval-rmse:3.77639\ttrain-rmse:1.94068\n",
      "[37259]\teval-rmse:3.77595\ttrain-rmse:1.94068\n",
      "[37260]\teval-rmse:3.77729\ttrain-rmse:1.94067\n",
      "[37261]\teval-rmse:3.77678\ttrain-rmse:1.94067\n",
      "[37262]\teval-rmse:3.77782\ttrain-rmse:1.94066\n",
      "[37263]\teval-rmse:3.77805\ttrain-rmse:1.94066\n",
      "[37264]\teval-rmse:3.7784\ttrain-rmse:1.94065\n",
      "[37265]\teval-rmse:3.7786\ttrain-rmse:1.94065\n",
      "[37266]\teval-rmse:3.77996\ttrain-rmse:1.94065\n",
      "[37267]\teval-rmse:3.7784\ttrain-rmse:1.94065\n",
      "[37268]\teval-rmse:3.77954\ttrain-rmse:1.94065\n",
      "[37269]\teval-rmse:3.77813\ttrain-rmse:1.94066\n",
      "[37270]\teval-rmse:3.77945\ttrain-rmse:1.94066\n",
      "[37271]\teval-rmse:3.77875\ttrain-rmse:1.94066\n",
      "[37272]\teval-rmse:3.77831\ttrain-rmse:1.94066\n",
      "[37273]\teval-rmse:3.77853\ttrain-rmse:1.94066\n",
      "[37274]\teval-rmse:3.77814\ttrain-rmse:1.94066\n",
      "[37275]\teval-rmse:3.77898\ttrain-rmse:1.94066\n",
      "[37276]\teval-rmse:3.7778\ttrain-rmse:1.94067\n",
      "[37277]\teval-rmse:3.77818\ttrain-rmse:1.94066\n",
      "[37278]\teval-rmse:3.77789\ttrain-rmse:1.94067\n",
      "[37279]\teval-rmse:3.77922\ttrain-rmse:1.94066\n",
      "[37280]\teval-rmse:3.77887\ttrain-rmse:1.94066\n",
      "[37281]\teval-rmse:3.77901\ttrain-rmse:1.94066\n",
      "[37282]\teval-rmse:3.77715\ttrain-rmse:1.9407\n",
      "[37283]\teval-rmse:3.77582\ttrain-rmse:1.94071\n",
      "[37284]\teval-rmse:3.77462\ttrain-rmse:1.94073\n",
      "[37285]\teval-rmse:3.77278\ttrain-rmse:1.94078\n",
      "[37286]\teval-rmse:3.77318\ttrain-rmse:1.94077\n",
      "[37287]\teval-rmse:3.77191\ttrain-rmse:1.9408\n",
      "[37288]\teval-rmse:3.77317\ttrain-rmse:1.94075\n",
      "[37289]\teval-rmse:3.77291\ttrain-rmse:1.94075\n",
      "[37290]\teval-rmse:3.77315\ttrain-rmse:1.94074\n",
      "[37291]\teval-rmse:3.77219\ttrain-rmse:1.94077\n",
      "[37292]\teval-rmse:3.77067\ttrain-rmse:1.94081\n",
      "[37293]\teval-rmse:3.77003\ttrain-rmse:1.94083\n",
      "[37294]\teval-rmse:3.7702\ttrain-rmse:1.94082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37295]\teval-rmse:3.76994\ttrain-rmse:1.94083\n",
      "[37296]\teval-rmse:3.76929\ttrain-rmse:1.94086\n",
      "[37297]\teval-rmse:3.76957\ttrain-rmse:1.94084\n",
      "[37298]\teval-rmse:3.76909\ttrain-rmse:1.94086\n",
      "[37299]\teval-rmse:3.76783\ttrain-rmse:1.94091\n",
      "[37300]\teval-rmse:3.76657\ttrain-rmse:1.94096\n",
      "[37301]\teval-rmse:3.76649\ttrain-rmse:1.94097\n",
      "[37302]\teval-rmse:3.76609\ttrain-rmse:1.94098\n",
      "[37303]\teval-rmse:3.76613\ttrain-rmse:1.94098\n",
      "[37304]\teval-rmse:3.7666\ttrain-rmse:1.94096\n",
      "[37305]\teval-rmse:3.76482\ttrain-rmse:1.94108\n",
      "[37306]\teval-rmse:3.76499\ttrain-rmse:1.94106\n",
      "[37307]\teval-rmse:3.76351\ttrain-rmse:1.94115\n",
      "[37308]\teval-rmse:3.76308\ttrain-rmse:1.94117\n",
      "[37309]\teval-rmse:3.76245\ttrain-rmse:1.94122\n",
      "[37310]\teval-rmse:3.76265\ttrain-rmse:1.9412\n",
      "[37311]\teval-rmse:3.76425\ttrain-rmse:1.94111\n",
      "[37312]\teval-rmse:3.76394\ttrain-rmse:1.94112\n",
      "[37313]\teval-rmse:3.76509\ttrain-rmse:1.94104\n",
      "[37314]\teval-rmse:3.76551\ttrain-rmse:1.94101\n",
      "[37315]\teval-rmse:3.76426\ttrain-rmse:1.94108\n",
      "[37316]\teval-rmse:3.76383\ttrain-rmse:1.94111\n",
      "[37317]\teval-rmse:3.76527\ttrain-rmse:1.94103\n",
      "[37318]\teval-rmse:3.7649\ttrain-rmse:1.94105\n",
      "[37319]\teval-rmse:3.76539\ttrain-rmse:1.94102\n",
      "[37320]\teval-rmse:3.76583\ttrain-rmse:1.94099\n",
      "[37321]\teval-rmse:3.76575\ttrain-rmse:1.941\n",
      "[37322]\teval-rmse:3.76534\ttrain-rmse:1.94102\n",
      "[37323]\teval-rmse:3.76421\ttrain-rmse:1.94108\n",
      "[37324]\teval-rmse:3.76408\ttrain-rmse:1.94108\n",
      "[37325]\teval-rmse:3.76541\ttrain-rmse:1.94101\n",
      "[37326]\teval-rmse:3.76701\ttrain-rmse:1.94093\n",
      "[37327]\teval-rmse:3.76744\ttrain-rmse:1.94091\n",
      "[37328]\teval-rmse:3.76699\ttrain-rmse:1.94093\n",
      "[37329]\teval-rmse:3.76727\ttrain-rmse:1.94092\n",
      "[37330]\teval-rmse:3.76863\ttrain-rmse:1.94086\n",
      "[37331]\teval-rmse:3.76853\ttrain-rmse:1.94086\n",
      "[37332]\teval-rmse:3.76727\ttrain-rmse:1.94091\n",
      "[37333]\teval-rmse:3.76842\ttrain-rmse:1.94087\n",
      "[37334]\teval-rmse:3.76718\ttrain-rmse:1.94092\n",
      "[37335]\teval-rmse:3.76692\ttrain-rmse:1.94093\n",
      "[37336]\teval-rmse:3.76809\ttrain-rmse:1.94088\n",
      "[37337]\teval-rmse:3.76827\ttrain-rmse:1.94087\n",
      "[37338]\teval-rmse:3.76703\ttrain-rmse:1.94093\n",
      "[37339]\teval-rmse:3.76611\ttrain-rmse:1.94097\n",
      "[37340]\teval-rmse:3.76786\ttrain-rmse:1.9409\n",
      "[37341]\teval-rmse:3.76693\ttrain-rmse:1.94093\n",
      "[37342]\teval-rmse:3.76685\ttrain-rmse:1.94094\n",
      "[37343]\teval-rmse:3.76686\ttrain-rmse:1.94094\n",
      "[37344]\teval-rmse:3.76814\ttrain-rmse:1.94089\n",
      "[37345]\teval-rmse:3.7679\ttrain-rmse:1.9409\n",
      "[37346]\teval-rmse:3.76793\ttrain-rmse:1.9409\n",
      "[37347]\teval-rmse:3.76769\ttrain-rmse:1.94091\n",
      "[37348]\teval-rmse:3.76621\ttrain-rmse:1.94097\n",
      "[37349]\teval-rmse:3.76529\ttrain-rmse:1.94101\n",
      "[37350]\teval-rmse:3.76552\ttrain-rmse:1.941\n",
      "[37351]\teval-rmse:3.76403\ttrain-rmse:1.94107\n",
      "[37352]\teval-rmse:3.7638\ttrain-rmse:1.94108\n",
      "[37353]\teval-rmse:3.76215\ttrain-rmse:1.94117\n",
      "[37354]\teval-rmse:3.7639\ttrain-rmse:1.94108\n",
      "[37355]\teval-rmse:3.7654\ttrain-rmse:1.941\n",
      "[37356]\teval-rmse:3.76558\ttrain-rmse:1.94099\n",
      "[37357]\teval-rmse:3.76416\ttrain-rmse:1.94106\n",
      "[37358]\teval-rmse:3.76491\ttrain-rmse:1.94102\n",
      "[37359]\teval-rmse:3.7652\ttrain-rmse:1.94101\n",
      "[37360]\teval-rmse:3.76653\ttrain-rmse:1.94094\n",
      "[37361]\teval-rmse:3.76807\ttrain-rmse:1.94087\n",
      "[37362]\teval-rmse:3.76949\ttrain-rmse:1.94083\n",
      "[37363]\teval-rmse:3.77107\ttrain-rmse:1.94078\n",
      "[37364]\teval-rmse:3.77227\ttrain-rmse:1.94075\n",
      "[37365]\teval-rmse:3.77275\ttrain-rmse:1.94074\n",
      "[37366]\teval-rmse:3.77266\ttrain-rmse:1.94072\n",
      "[37367]\teval-rmse:3.77224\ttrain-rmse:1.94073\n",
      "[37368]\teval-rmse:3.77377\ttrain-rmse:1.9407\n",
      "[37369]\teval-rmse:3.77552\ttrain-rmse:1.94066\n",
      "[37370]\teval-rmse:3.77515\ttrain-rmse:1.94066\n",
      "[37371]\teval-rmse:3.77417\ttrain-rmse:1.94068\n",
      "[37372]\teval-rmse:3.7752\ttrain-rmse:1.94067\n",
      "[37373]\teval-rmse:3.77399\ttrain-rmse:1.94072\n",
      "[37374]\teval-rmse:3.77372\ttrain-rmse:1.94072\n",
      "[37375]\teval-rmse:3.77219\ttrain-rmse:1.94075\n",
      "[37376]\teval-rmse:3.77074\ttrain-rmse:1.9408\n",
      "[37377]\teval-rmse:3.76908\ttrain-rmse:1.94085\n",
      "[37378]\teval-rmse:3.76983\ttrain-rmse:1.94082\n",
      "[37379]\teval-rmse:3.77142\ttrain-rmse:1.94077\n",
      "[37380]\teval-rmse:3.77132\ttrain-rmse:1.94077\n",
      "[37381]\teval-rmse:3.77258\ttrain-rmse:1.94073\n",
      "[37382]\teval-rmse:3.77296\ttrain-rmse:1.94072\n",
      "[37383]\teval-rmse:3.77126\ttrain-rmse:1.94078\n",
      "[37384]\teval-rmse:3.77181\ttrain-rmse:1.94076\n",
      "[37385]\teval-rmse:3.77234\ttrain-rmse:1.94074\n",
      "[37386]\teval-rmse:3.77349\ttrain-rmse:1.94071\n",
      "[37387]\teval-rmse:3.77461\ttrain-rmse:1.94068\n",
      "[37388]\teval-rmse:3.77509\ttrain-rmse:1.94067\n",
      "[37389]\teval-rmse:3.77411\ttrain-rmse:1.94069\n",
      "[37390]\teval-rmse:3.77393\ttrain-rmse:1.9407\n",
      "[37391]\teval-rmse:3.77224\ttrain-rmse:1.94074\n",
      "[37392]\teval-rmse:3.77215\ttrain-rmse:1.94071\n",
      "[37393]\teval-rmse:3.77265\ttrain-rmse:1.9407\n",
      "[37394]\teval-rmse:3.77291\ttrain-rmse:1.94069\n",
      "[37395]\teval-rmse:3.77448\ttrain-rmse:1.94067\n",
      "[37396]\teval-rmse:3.77449\ttrain-rmse:1.94067\n",
      "[37397]\teval-rmse:3.77566\ttrain-rmse:1.94065\n",
      "[37398]\teval-rmse:3.77689\ttrain-rmse:1.94063\n",
      "[37399]\teval-rmse:3.77638\ttrain-rmse:1.94064\n",
      "[37400]\teval-rmse:3.77523\ttrain-rmse:1.94065\n",
      "[37401]\teval-rmse:3.77681\ttrain-rmse:1.94063\n",
      "[37402]\teval-rmse:3.77855\ttrain-rmse:1.9406\n",
      "[37403]\teval-rmse:3.77817\ttrain-rmse:1.9406\n",
      "[37404]\teval-rmse:3.77663\ttrain-rmse:1.94061\n",
      "[37405]\teval-rmse:3.77616\ttrain-rmse:1.94062\n",
      "[37406]\teval-rmse:3.77548\ttrain-rmse:1.94063\n",
      "[37407]\teval-rmse:3.77546\ttrain-rmse:1.94063\n",
      "[37408]\teval-rmse:3.77528\ttrain-rmse:1.94064\n",
      "[37409]\teval-rmse:3.7746\ttrain-rmse:1.94065\n",
      "[37410]\teval-rmse:3.77477\ttrain-rmse:1.94064\n",
      "[37411]\teval-rmse:3.77349\ttrain-rmse:1.94067\n",
      "[37412]\teval-rmse:3.77253\ttrain-rmse:1.9407\n",
      "[37413]\teval-rmse:3.77101\ttrain-rmse:1.94074\n",
      "[37414]\teval-rmse:3.77227\ttrain-rmse:1.9407\n",
      "[37415]\teval-rmse:3.77245\ttrain-rmse:1.9407\n",
      "[37416]\teval-rmse:3.77133\ttrain-rmse:1.94073\n",
      "[37417]\teval-rmse:3.77173\ttrain-rmse:1.94072\n",
      "[37418]\teval-rmse:3.77205\ttrain-rmse:1.94071\n",
      "[37419]\teval-rmse:3.77218\ttrain-rmse:1.9407\n",
      "[37420]\teval-rmse:3.77251\ttrain-rmse:1.9407\n",
      "[37421]\teval-rmse:3.77178\ttrain-rmse:1.94072\n",
      "[37422]\teval-rmse:3.77009\ttrain-rmse:1.94077\n",
      "[37423]\teval-rmse:3.76842\ttrain-rmse:1.94084\n",
      "[37424]\teval-rmse:3.7686\ttrain-rmse:1.94084\n",
      "[37425]\teval-rmse:3.77001\ttrain-rmse:1.94078\n",
      "[37426]\teval-rmse:3.77003\ttrain-rmse:1.94078\n",
      "[37427]\teval-rmse:3.76969\ttrain-rmse:1.94079\n",
      "[37428]\teval-rmse:3.76903\ttrain-rmse:1.94082\n",
      "[37429]\teval-rmse:3.77039\ttrain-rmse:1.94076\n",
      "[37430]\teval-rmse:3.76974\ttrain-rmse:1.94079\n",
      "[37431]\teval-rmse:3.7681\ttrain-rmse:1.94086\n",
      "[37432]\teval-rmse:3.76936\ttrain-rmse:1.94081\n",
      "[37433]\teval-rmse:3.77022\ttrain-rmse:1.94077\n",
      "[37434]\teval-rmse:3.77007\ttrain-rmse:1.94078\n",
      "[37435]\teval-rmse:3.7703\ttrain-rmse:1.94077\n",
      "[37436]\teval-rmse:3.77171\ttrain-rmse:1.94072\n",
      "[37437]\teval-rmse:3.77255\ttrain-rmse:1.9407\n",
      "[37438]\teval-rmse:3.77379\ttrain-rmse:1.94067\n",
      "[37439]\teval-rmse:3.77553\ttrain-rmse:1.94062\n",
      "[37440]\teval-rmse:3.77456\ttrain-rmse:1.94064\n",
      "[37441]\teval-rmse:3.77631\ttrain-rmse:1.94061\n",
      "[37442]\teval-rmse:3.77518\ttrain-rmse:1.94063\n",
      "[37443]\teval-rmse:3.77618\ttrain-rmse:1.94061\n",
      "[37444]\teval-rmse:3.77606\ttrain-rmse:1.94059\n",
      "[37445]\teval-rmse:3.7766\ttrain-rmse:1.94058\n",
      "[37446]\teval-rmse:3.77818\ttrain-rmse:1.94056\n",
      "[37447]\teval-rmse:3.77944\ttrain-rmse:1.94055\n",
      "[37448]\teval-rmse:3.77756\ttrain-rmse:1.94058\n",
      "[37449]\teval-rmse:3.77796\ttrain-rmse:1.94057\n",
      "[37450]\teval-rmse:3.77657\ttrain-rmse:1.94059\n",
      "[37451]\teval-rmse:3.77542\ttrain-rmse:1.94061\n",
      "[37452]\teval-rmse:3.77677\ttrain-rmse:1.94059\n",
      "[37453]\teval-rmse:3.77624\ttrain-rmse:1.9406\n",
      "[37454]\teval-rmse:3.77678\ttrain-rmse:1.94059\n",
      "[37455]\teval-rmse:3.77797\ttrain-rmse:1.94057\n",
      "[37456]\teval-rmse:3.77914\ttrain-rmse:1.94057\n",
      "[37457]\teval-rmse:3.77776\ttrain-rmse:1.94058\n",
      "[37458]\teval-rmse:3.77677\ttrain-rmse:1.94059\n",
      "[37459]\teval-rmse:3.77803\ttrain-rmse:1.94058\n",
      "[37460]\teval-rmse:3.77759\ttrain-rmse:1.94059\n",
      "[37461]\teval-rmse:3.77611\ttrain-rmse:1.9406\n",
      "[37462]\teval-rmse:3.77743\ttrain-rmse:1.94059\n",
      "[37463]\teval-rmse:3.77622\ttrain-rmse:1.94062\n",
      "[37464]\teval-rmse:3.7766\ttrain-rmse:1.94061\n",
      "[37465]\teval-rmse:3.77514\ttrain-rmse:1.94064\n",
      "[37466]\teval-rmse:3.77417\ttrain-rmse:1.94066\n",
      "[37467]\teval-rmse:3.77429\ttrain-rmse:1.94066\n",
      "[37468]\teval-rmse:3.77412\ttrain-rmse:1.94066\n",
      "[37469]\teval-rmse:3.77467\ttrain-rmse:1.94065\n",
      "[37470]\teval-rmse:3.77492\ttrain-rmse:1.94064\n",
      "[37471]\teval-rmse:3.77449\ttrain-rmse:1.94065\n",
      "[37472]\teval-rmse:3.77569\ttrain-rmse:1.94063\n",
      "[37473]\teval-rmse:3.77727\ttrain-rmse:1.94062\n",
      "[37474]\teval-rmse:3.77773\ttrain-rmse:1.94062\n",
      "[37475]\teval-rmse:3.77896\ttrain-rmse:1.94062\n",
      "[37476]\teval-rmse:3.77996\ttrain-rmse:1.94062\n",
      "[37477]\teval-rmse:3.77877\ttrain-rmse:1.94062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37478]\teval-rmse:3.77876\ttrain-rmse:1.94062\n",
      "[37479]\teval-rmse:3.77839\ttrain-rmse:1.94062\n",
      "[37480]\teval-rmse:3.77718\ttrain-rmse:1.94063\n",
      "[37481]\teval-rmse:3.77743\ttrain-rmse:1.94062\n",
      "[37482]\teval-rmse:3.77714\ttrain-rmse:1.94063\n",
      "[37483]\teval-rmse:3.77743\ttrain-rmse:1.94062\n",
      "[37484]\teval-rmse:3.77725\ttrain-rmse:1.94062\n",
      "[37485]\teval-rmse:3.77537\ttrain-rmse:1.94067\n",
      "[37486]\teval-rmse:3.7751\ttrain-rmse:1.94068\n",
      "[37487]\teval-rmse:3.77684\ttrain-rmse:1.94064\n",
      "[37488]\teval-rmse:3.7753\ttrain-rmse:1.94067\n",
      "[37489]\teval-rmse:3.77671\ttrain-rmse:1.94065\n",
      "[37490]\teval-rmse:3.77518\ttrain-rmse:1.94067\n",
      "[37491]\teval-rmse:3.77364\ttrain-rmse:1.9407\n",
      "[37492]\teval-rmse:3.77328\ttrain-rmse:1.9407\n",
      "[37493]\teval-rmse:3.77302\ttrain-rmse:1.94071\n",
      "[37494]\teval-rmse:3.77366\ttrain-rmse:1.94068\n",
      "[37495]\teval-rmse:3.77525\ttrain-rmse:1.94065\n",
      "[37496]\teval-rmse:3.77682\ttrain-rmse:1.94063\n",
      "[37497]\teval-rmse:3.77681\ttrain-rmse:1.94063\n",
      "[37498]\teval-rmse:3.77753\ttrain-rmse:1.94062\n",
      "[37499]\teval-rmse:3.77879\ttrain-rmse:1.94061\n",
      "[37500]\teval-rmse:3.77981\ttrain-rmse:1.94061\n",
      "[37501]\teval-rmse:3.77841\ttrain-rmse:1.94061\n",
      "[37502]\teval-rmse:3.77828\ttrain-rmse:1.94059\n",
      "[37503]\teval-rmse:3.77984\ttrain-rmse:1.94059\n",
      "[37504]\teval-rmse:3.78024\ttrain-rmse:1.94059\n",
      "[37505]\teval-rmse:3.77891\ttrain-rmse:1.94058\n",
      "[37506]\teval-rmse:3.78016\ttrain-rmse:1.94059\n",
      "[37507]\teval-rmse:3.78063\ttrain-rmse:1.94058\n",
      "[37508]\teval-rmse:3.78049\ttrain-rmse:1.94058\n",
      "[37509]\teval-rmse:3.78102\ttrain-rmse:1.94059\n",
      "[37510]\teval-rmse:3.78254\ttrain-rmse:1.9406\n",
      "[37511]\teval-rmse:3.78412\ttrain-rmse:1.94061\n",
      "[37512]\teval-rmse:3.78364\ttrain-rmse:1.94061\n",
      "[37513]\teval-rmse:3.78311\ttrain-rmse:1.94061\n",
      "[37514]\teval-rmse:3.78337\ttrain-rmse:1.94061\n",
      "[37515]\teval-rmse:3.78289\ttrain-rmse:1.9406\n",
      "[37516]\teval-rmse:3.78163\ttrain-rmse:1.94059\n",
      "[37517]\teval-rmse:3.7829\ttrain-rmse:1.9406\n",
      "[37518]\teval-rmse:3.78441\ttrain-rmse:1.94062\n",
      "[37519]\teval-rmse:3.78382\ttrain-rmse:1.94061\n",
      "[37520]\teval-rmse:3.785\ttrain-rmse:1.94063\n",
      "[37521]\teval-rmse:3.78536\ttrain-rmse:1.94063\n",
      "[37522]\teval-rmse:3.78602\ttrain-rmse:1.94065\n",
      "[37523]\teval-rmse:3.78702\ttrain-rmse:1.94067\n",
      "[37524]\teval-rmse:3.78581\ttrain-rmse:1.94067\n",
      "[37525]\teval-rmse:3.78565\ttrain-rmse:1.94065\n",
      "[37526]\teval-rmse:3.78462\ttrain-rmse:1.94064\n",
      "[37527]\teval-rmse:3.78335\ttrain-rmse:1.94065\n",
      "[37528]\teval-rmse:3.78405\ttrain-rmse:1.94066\n",
      "[37529]\teval-rmse:3.7827\ttrain-rmse:1.94064\n",
      "[37530]\teval-rmse:3.78145\ttrain-rmse:1.94065\n",
      "[37531]\teval-rmse:3.78028\ttrain-rmse:1.94064\n",
      "[37532]\teval-rmse:3.77991\ttrain-rmse:1.94064\n",
      "[37533]\teval-rmse:3.78141\ttrain-rmse:1.94065\n",
      "[37534]\teval-rmse:3.78103\ttrain-rmse:1.94065\n",
      "[37535]\teval-rmse:3.77957\ttrain-rmse:1.94064\n",
      "[37536]\teval-rmse:3.78059\ttrain-rmse:1.94065\n",
      "[37537]\teval-rmse:3.77984\ttrain-rmse:1.94065\n",
      "[37538]\teval-rmse:3.77824\ttrain-rmse:1.94064\n",
      "[37539]\teval-rmse:3.77813\ttrain-rmse:1.94062\n",
      "[37540]\teval-rmse:3.77881\ttrain-rmse:1.94062\n",
      "[37541]\teval-rmse:3.77813\ttrain-rmse:1.94062\n",
      "[37542]\teval-rmse:3.77865\ttrain-rmse:1.94062\n",
      "[37543]\teval-rmse:3.77812\ttrain-rmse:1.94062\n",
      "[37544]\teval-rmse:3.77761\ttrain-rmse:1.94062\n",
      "[37545]\teval-rmse:3.7782\ttrain-rmse:1.94062\n",
      "[37546]\teval-rmse:3.77702\ttrain-rmse:1.94062\n",
      "[37547]\teval-rmse:3.77604\ttrain-rmse:1.94064\n",
      "[37548]\teval-rmse:3.77747\ttrain-rmse:1.94063\n",
      "[37549]\teval-rmse:3.77617\ttrain-rmse:1.94064\n",
      "[37550]\teval-rmse:3.77605\ttrain-rmse:1.94062\n",
      "[37551]\teval-rmse:3.77609\ttrain-rmse:1.94062\n",
      "[37552]\teval-rmse:3.77731\ttrain-rmse:1.94062\n",
      "[37553]\teval-rmse:3.77854\ttrain-rmse:1.94062\n",
      "[37554]\teval-rmse:3.77974\ttrain-rmse:1.94063\n",
      "[37555]\teval-rmse:3.7809\ttrain-rmse:1.94064\n",
      "[37556]\teval-rmse:3.77948\ttrain-rmse:1.94063\n",
      "[37557]\teval-rmse:3.77927\ttrain-rmse:1.94063\n",
      "[37558]\teval-rmse:3.77957\ttrain-rmse:1.94063\n",
      "[37559]\teval-rmse:3.77994\ttrain-rmse:1.94063\n",
      "[37560]\teval-rmse:3.77867\ttrain-rmse:1.94063\n",
      "[37561]\teval-rmse:3.77693\ttrain-rmse:1.94063\n",
      "[37562]\teval-rmse:3.77544\ttrain-rmse:1.94063\n",
      "[37563]\teval-rmse:3.77388\ttrain-rmse:1.94065\n",
      "[37564]\teval-rmse:3.77515\ttrain-rmse:1.94063\n",
      "[37565]\teval-rmse:3.77515\ttrain-rmse:1.94063\n",
      "[37566]\teval-rmse:3.77689\ttrain-rmse:1.94059\n",
      "[37567]\teval-rmse:3.77727\ttrain-rmse:1.94059\n",
      "[37568]\teval-rmse:3.77612\ttrain-rmse:1.9406\n",
      "[37569]\teval-rmse:3.77594\ttrain-rmse:1.9406\n",
      "[37570]\teval-rmse:3.77429\ttrain-rmse:1.94063\n",
      "[37571]\teval-rmse:3.77412\ttrain-rmse:1.94063\n",
      "[37572]\teval-rmse:3.77379\ttrain-rmse:1.94063\n",
      "[37573]\teval-rmse:3.77514\ttrain-rmse:1.94061\n",
      "[37574]\teval-rmse:3.77471\ttrain-rmse:1.94062\n",
      "[37575]\teval-rmse:3.77619\ttrain-rmse:1.9406\n",
      "[37576]\teval-rmse:3.77584\ttrain-rmse:1.94061\n",
      "[37577]\teval-rmse:3.77759\ttrain-rmse:1.94058\n",
      "[37578]\teval-rmse:3.77641\ttrain-rmse:1.94058\n",
      "[37579]\teval-rmse:3.77639\ttrain-rmse:1.94058\n",
      "[37580]\teval-rmse:3.77813\ttrain-rmse:1.94058\n",
      "[37581]\teval-rmse:3.77799\ttrain-rmse:1.94056\n",
      "[37582]\teval-rmse:3.77661\ttrain-rmse:1.94057\n",
      "[37583]\teval-rmse:3.77794\ttrain-rmse:1.94056\n",
      "[37584]\teval-rmse:3.77664\ttrain-rmse:1.94057\n",
      "[37585]\teval-rmse:3.77617\ttrain-rmse:1.94057\n",
      "[37586]\teval-rmse:3.77574\ttrain-rmse:1.94058\n",
      "[37587]\teval-rmse:3.77699\ttrain-rmse:1.94057\n",
      "[37588]\teval-rmse:3.77704\ttrain-rmse:1.94057\n",
      "[37589]\teval-rmse:3.77684\ttrain-rmse:1.94057\n",
      "[37590]\teval-rmse:3.77569\ttrain-rmse:1.9406\n",
      "[37591]\teval-rmse:3.77616\ttrain-rmse:1.94059\n",
      "[37592]\teval-rmse:3.77492\ttrain-rmse:1.9406\n",
      "[37593]\teval-rmse:3.77481\ttrain-rmse:1.94058\n",
      "[37594]\teval-rmse:3.77428\ttrain-rmse:1.94059\n",
      "[37595]\teval-rmse:3.77282\ttrain-rmse:1.94061\n",
      "[37596]\teval-rmse:3.77185\ttrain-rmse:1.94064\n",
      "[37597]\teval-rmse:3.7706\ttrain-rmse:1.94068\n",
      "[37598]\teval-rmse:3.76931\ttrain-rmse:1.94071\n",
      "[37599]\teval-rmse:3.76861\ttrain-rmse:1.94075\n",
      "[37600]\teval-rmse:3.76694\ttrain-rmse:1.94081\n",
      "[37601]\teval-rmse:3.7668\ttrain-rmse:1.94081\n",
      "[37602]\teval-rmse:3.76588\ttrain-rmse:1.94085\n",
      "[37603]\teval-rmse:3.7674\ttrain-rmse:1.94078\n",
      "[37604]\teval-rmse:3.76647\ttrain-rmse:1.94081\n",
      "[37605]\teval-rmse:3.76806\ttrain-rmse:1.94074\n",
      "[37606]\teval-rmse:3.76798\ttrain-rmse:1.94074\n",
      "[37607]\teval-rmse:3.76856\ttrain-rmse:1.94072\n",
      "[37608]\teval-rmse:3.76897\ttrain-rmse:1.9407\n",
      "[37609]\teval-rmse:3.76887\ttrain-rmse:1.94069\n",
      "[37610]\teval-rmse:3.77007\ttrain-rmse:1.94064\n",
      "[37611]\teval-rmse:3.76975\ttrain-rmse:1.94065\n",
      "[37612]\teval-rmse:3.77014\ttrain-rmse:1.94064\n",
      "[37613]\teval-rmse:3.77035\ttrain-rmse:1.94064\n",
      "[37614]\teval-rmse:3.77187\ttrain-rmse:1.9406\n",
      "[37615]\teval-rmse:3.77057\ttrain-rmse:1.94063\n",
      "[37616]\teval-rmse:3.77078\ttrain-rmse:1.94062\n",
      "[37617]\teval-rmse:3.76949\ttrain-rmse:1.94066\n",
      "[37618]\teval-rmse:3.77068\ttrain-rmse:1.94062\n",
      "[37619]\teval-rmse:3.77202\ttrain-rmse:1.9406\n",
      "[37620]\teval-rmse:3.77156\ttrain-rmse:1.9406\n",
      "[37621]\teval-rmse:3.77256\ttrain-rmse:1.94059\n",
      "[37622]\teval-rmse:3.77126\ttrain-rmse:1.94061\n",
      "[37623]\teval-rmse:3.7699\ttrain-rmse:1.94064\n",
      "[37624]\teval-rmse:3.76838\ttrain-rmse:1.94069\n",
      "[37625]\teval-rmse:3.76787\ttrain-rmse:1.94071\n",
      "[37626]\teval-rmse:3.76962\ttrain-rmse:1.94065\n",
      "[37627]\teval-rmse:3.76826\ttrain-rmse:1.94069\n",
      "[37628]\teval-rmse:3.76777\ttrain-rmse:1.94071\n",
      "[37629]\teval-rmse:3.76896\ttrain-rmse:1.94067\n",
      "[37630]\teval-rmse:3.7707\ttrain-rmse:1.94061\n",
      "[37631]\teval-rmse:3.76929\ttrain-rmse:1.94065\n",
      "[37632]\teval-rmse:3.76801\ttrain-rmse:1.9407\n",
      "[37633]\teval-rmse:3.76669\ttrain-rmse:1.94075\n",
      "[37634]\teval-rmse:3.76674\ttrain-rmse:1.94075\n",
      "[37635]\teval-rmse:3.76731\ttrain-rmse:1.94072\n",
      "[37636]\teval-rmse:3.76696\ttrain-rmse:1.94073\n",
      "[37637]\teval-rmse:3.76666\ttrain-rmse:1.94074\n",
      "[37638]\teval-rmse:3.76792\ttrain-rmse:1.9407\n",
      "[37639]\teval-rmse:3.76744\ttrain-rmse:1.94072\n",
      "[37640]\teval-rmse:3.76846\ttrain-rmse:1.94067\n",
      "[37641]\teval-rmse:3.76701\ttrain-rmse:1.94073\n",
      "[37642]\teval-rmse:3.76775\ttrain-rmse:1.94069\n",
      "[37643]\teval-rmse:3.76919\ttrain-rmse:1.94064\n",
      "[37644]\teval-rmse:3.76918\ttrain-rmse:1.94064\n",
      "[37645]\teval-rmse:3.76783\ttrain-rmse:1.94069\n",
      "[37646]\teval-rmse:3.76884\ttrain-rmse:1.94065\n",
      "[37647]\teval-rmse:3.76868\ttrain-rmse:1.94066\n",
      "[37648]\teval-rmse:3.77026\ttrain-rmse:1.9406\n",
      "[37649]\teval-rmse:3.77016\ttrain-rmse:1.9406\n",
      "[37650]\teval-rmse:3.77089\ttrain-rmse:1.94058\n",
      "[37651]\teval-rmse:3.7716\ttrain-rmse:1.94056\n",
      "[37652]\teval-rmse:3.77017\ttrain-rmse:1.9406\n",
      "[37653]\teval-rmse:3.76968\ttrain-rmse:1.94061\n",
      "[37654]\teval-rmse:3.76936\ttrain-rmse:1.94063\n",
      "[37655]\teval-rmse:3.7701\ttrain-rmse:1.9406\n",
      "[37656]\teval-rmse:3.77001\ttrain-rmse:1.94059\n",
      "[37657]\teval-rmse:3.77153\ttrain-rmse:1.94054\n",
      "[37658]\teval-rmse:3.77169\ttrain-rmse:1.94054\n",
      "[37659]\teval-rmse:3.77295\ttrain-rmse:1.94052\n",
      "[37660]\teval-rmse:3.77262\ttrain-rmse:1.94052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37661]\teval-rmse:3.77335\ttrain-rmse:1.94051\n",
      "[37662]\teval-rmse:3.7722\ttrain-rmse:1.94053\n",
      "[37663]\teval-rmse:3.77244\ttrain-rmse:1.94052\n",
      "[37664]\teval-rmse:3.77227\ttrain-rmse:1.94053\n",
      "[37665]\teval-rmse:3.77282\ttrain-rmse:1.94052\n",
      "[37666]\teval-rmse:3.77233\ttrain-rmse:1.94053\n",
      "[37667]\teval-rmse:3.77186\ttrain-rmse:1.94054\n",
      "[37668]\teval-rmse:3.77189\ttrain-rmse:1.94054\n",
      "[37669]\teval-rmse:3.77178\ttrain-rmse:1.94055\n",
      "[37670]\teval-rmse:3.77039\ttrain-rmse:1.94058\n",
      "[37671]\teval-rmse:3.76992\ttrain-rmse:1.9406\n",
      "[37672]\teval-rmse:3.77166\ttrain-rmse:1.94054\n",
      "[37673]\teval-rmse:3.77117\ttrain-rmse:1.94055\n",
      "[37674]\teval-rmse:3.76999\ttrain-rmse:1.9406\n",
      "[37675]\teval-rmse:3.76933\ttrain-rmse:1.94062\n",
      "[37676]\teval-rmse:3.76893\ttrain-rmse:1.94064\n",
      "[37677]\teval-rmse:3.77016\ttrain-rmse:1.9406\n",
      "[37678]\teval-rmse:3.76984\ttrain-rmse:1.9406\n",
      "[37679]\teval-rmse:3.77033\ttrain-rmse:1.94059\n",
      "[37680]\teval-rmse:3.77062\ttrain-rmse:1.94058\n",
      "[37681]\teval-rmse:3.77037\ttrain-rmse:1.94059\n",
      "[37682]\teval-rmse:3.77054\ttrain-rmse:1.94058\n",
      "[37683]\teval-rmse:3.77172\ttrain-rmse:1.94056\n",
      "[37684]\teval-rmse:3.77195\ttrain-rmse:1.94055\n",
      "[37685]\teval-rmse:3.77312\ttrain-rmse:1.94053\n",
      "[37686]\teval-rmse:3.77358\ttrain-rmse:1.94052\n",
      "[37687]\teval-rmse:3.77261\ttrain-rmse:1.94054\n",
      "[37688]\teval-rmse:3.77413\ttrain-rmse:1.94052\n",
      "[37689]\teval-rmse:3.77432\ttrain-rmse:1.94052\n",
      "[37690]\teval-rmse:3.77545\ttrain-rmse:1.9405\n",
      "[37691]\teval-rmse:3.77692\ttrain-rmse:1.94049\n",
      "[37692]\teval-rmse:3.77804\ttrain-rmse:1.9405\n",
      "[37693]\teval-rmse:3.77937\ttrain-rmse:1.94051\n",
      "[37694]\teval-rmse:3.78111\ttrain-rmse:1.94049\n",
      "[37695]\teval-rmse:3.77936\ttrain-rmse:1.94048\n",
      "[37696]\teval-rmse:3.77792\ttrain-rmse:1.94047\n",
      "[37697]\teval-rmse:3.77764\ttrain-rmse:1.94048\n",
      "[37698]\teval-rmse:3.77751\ttrain-rmse:1.94046\n",
      "[37699]\teval-rmse:3.77892\ttrain-rmse:1.94047\n",
      "[37700]\teval-rmse:3.77844\ttrain-rmse:1.94047\n",
      "[37701]\teval-rmse:3.77961\ttrain-rmse:1.94048\n",
      "[37702]\teval-rmse:3.77908\ttrain-rmse:1.94047\n",
      "[37703]\teval-rmse:3.78008\ttrain-rmse:1.94049\n",
      "[37704]\teval-rmse:3.77889\ttrain-rmse:1.94049\n",
      "[37705]\teval-rmse:3.77739\ttrain-rmse:1.94048\n",
      "[37706]\teval-rmse:3.77775\ttrain-rmse:1.94047\n",
      "[37707]\teval-rmse:3.77817\ttrain-rmse:1.94047\n",
      "[37708]\teval-rmse:3.77838\ttrain-rmse:1.94048\n",
      "[37709]\teval-rmse:3.77986\ttrain-rmse:1.94047\n",
      "[37710]\teval-rmse:3.77947\ttrain-rmse:1.94047\n",
      "[37711]\teval-rmse:3.7812\ttrain-rmse:1.94046\n",
      "[37712]\teval-rmse:3.77946\ttrain-rmse:1.94046\n",
      "[37713]\teval-rmse:3.77975\ttrain-rmse:1.94046\n",
      "[37714]\teval-rmse:3.77787\ttrain-rmse:1.94047\n",
      "[37715]\teval-rmse:3.77662\ttrain-rmse:1.94047\n",
      "[37716]\teval-rmse:3.77643\ttrain-rmse:1.94047\n",
      "[37717]\teval-rmse:3.77683\ttrain-rmse:1.94047\n",
      "[37718]\teval-rmse:3.77526\ttrain-rmse:1.94048\n",
      "[37719]\teval-rmse:3.77492\ttrain-rmse:1.94049\n",
      "[37720]\teval-rmse:3.77394\ttrain-rmse:1.94051\n",
      "[37721]\teval-rmse:3.77493\ttrain-rmse:1.9405\n",
      "[37722]\teval-rmse:3.77523\ttrain-rmse:1.9405\n",
      "[37723]\teval-rmse:3.77486\ttrain-rmse:1.9405\n",
      "[37724]\teval-rmse:3.77467\ttrain-rmse:1.9405\n",
      "[37725]\teval-rmse:3.7744\ttrain-rmse:1.94051\n",
      "[37726]\teval-rmse:3.77321\ttrain-rmse:1.94053\n",
      "[37727]\teval-rmse:3.77136\ttrain-rmse:1.94056\n",
      "[37728]\teval-rmse:3.77175\ttrain-rmse:1.94055\n",
      "[37729]\teval-rmse:3.77158\ttrain-rmse:1.94056\n",
      "[37730]\teval-rmse:3.7715\ttrain-rmse:1.94053\n",
      "[37731]\teval-rmse:3.77267\ttrain-rmse:1.94051\n",
      "[37732]\teval-rmse:3.77249\ttrain-rmse:1.94052\n",
      "[37733]\teval-rmse:3.77222\ttrain-rmse:1.94052\n",
      "[37734]\teval-rmse:3.77341\ttrain-rmse:1.9405\n",
      "[37735]\teval-rmse:3.77382\ttrain-rmse:1.9405\n",
      "[37736]\teval-rmse:3.77354\ttrain-rmse:1.9405\n",
      "[37737]\teval-rmse:3.7732\ttrain-rmse:1.94051\n",
      "[37738]\teval-rmse:3.77309\ttrain-rmse:1.94051\n",
      "[37739]\teval-rmse:3.77212\ttrain-rmse:1.94054\n",
      "[37740]\teval-rmse:3.7723\ttrain-rmse:1.94053\n",
      "[37741]\teval-rmse:3.77162\ttrain-rmse:1.94054\n",
      "[37742]\teval-rmse:3.77221\ttrain-rmse:1.94053\n",
      "[37743]\teval-rmse:3.77171\ttrain-rmse:1.94054\n",
      "[37744]\teval-rmse:3.77049\ttrain-rmse:1.94057\n",
      "[37745]\teval-rmse:3.76866\ttrain-rmse:1.94064\n",
      "[37746]\teval-rmse:3.77025\ttrain-rmse:1.94057\n",
      "[37747]\teval-rmse:3.77009\ttrain-rmse:1.94058\n",
      "[37748]\teval-rmse:3.77059\ttrain-rmse:1.94057\n",
      "[37749]\teval-rmse:3.77114\ttrain-rmse:1.94055\n",
      "[37750]\teval-rmse:3.77069\ttrain-rmse:1.94056\n",
      "[37751]\teval-rmse:3.77211\ttrain-rmse:1.94053\n",
      "[37752]\teval-rmse:3.7704\ttrain-rmse:1.94057\n",
      "[37753]\teval-rmse:3.7692\ttrain-rmse:1.9406\n",
      "[37754]\teval-rmse:3.76822\ttrain-rmse:1.94064\n",
      "[37755]\teval-rmse:3.76706\ttrain-rmse:1.94068\n",
      "[37756]\teval-rmse:3.76574\ttrain-rmse:1.94073\n",
      "[37757]\teval-rmse:3.76614\ttrain-rmse:1.94071\n",
      "[37758]\teval-rmse:3.76482\ttrain-rmse:1.94077\n",
      "[37759]\teval-rmse:3.76505\ttrain-rmse:1.94076\n",
      "[37760]\teval-rmse:3.76609\ttrain-rmse:1.9407\n",
      "[37761]\teval-rmse:3.76499\ttrain-rmse:1.94074\n",
      "[37762]\teval-rmse:3.766\ttrain-rmse:1.9407\n",
      "[37763]\teval-rmse:3.76417\ttrain-rmse:1.94078\n",
      "[37764]\teval-rmse:3.76437\ttrain-rmse:1.94077\n",
      "[37765]\teval-rmse:3.76569\ttrain-rmse:1.94071\n",
      "[37766]\teval-rmse:3.76428\ttrain-rmse:1.94078\n",
      "[37767]\teval-rmse:3.76563\ttrain-rmse:1.94071\n",
      "[37768]\teval-rmse:3.7647\ttrain-rmse:1.94075\n",
      "[37769]\teval-rmse:3.76457\ttrain-rmse:1.94076\n",
      "[37770]\teval-rmse:3.76601\ttrain-rmse:1.9407\n",
      "[37771]\teval-rmse:3.76594\ttrain-rmse:1.94068\n",
      "[37772]\teval-rmse:3.76469\ttrain-rmse:1.94073\n",
      "[37773]\teval-rmse:3.76515\ttrain-rmse:1.94071\n",
      "[37774]\teval-rmse:3.76659\ttrain-rmse:1.94065\n",
      "[37775]\teval-rmse:3.76774\ttrain-rmse:1.9406\n",
      "[37776]\teval-rmse:3.76884\ttrain-rmse:1.94057\n",
      "[37777]\teval-rmse:3.76932\ttrain-rmse:1.94056\n",
      "[37778]\teval-rmse:3.77076\ttrain-rmse:1.94053\n",
      "[37779]\teval-rmse:3.7701\ttrain-rmse:1.94054\n",
      "[37780]\teval-rmse:3.76893\ttrain-rmse:1.94057\n",
      "[37781]\teval-rmse:3.77028\ttrain-rmse:1.94054\n",
      "[37782]\teval-rmse:3.76992\ttrain-rmse:1.94055\n",
      "[37783]\teval-rmse:3.7699\ttrain-rmse:1.94055\n",
      "[37784]\teval-rmse:3.76864\ttrain-rmse:1.9406\n",
      "[37785]\teval-rmse:3.76938\ttrain-rmse:1.94058\n",
      "[37786]\teval-rmse:3.76791\ttrain-rmse:1.94062\n",
      "[37787]\teval-rmse:3.76807\ttrain-rmse:1.94062\n",
      "[37788]\teval-rmse:3.76698\ttrain-rmse:1.94066\n",
      "[37789]\teval-rmse:3.76689\ttrain-rmse:1.94066\n",
      "[37790]\teval-rmse:3.76772\ttrain-rmse:1.94064\n",
      "[37791]\teval-rmse:3.76822\ttrain-rmse:1.94062\n",
      "[37792]\teval-rmse:3.76697\ttrain-rmse:1.94068\n",
      "[37793]\teval-rmse:3.76745\ttrain-rmse:1.94066\n",
      "[37794]\teval-rmse:3.76632\ttrain-rmse:1.94069\n",
      "[37795]\teval-rmse:3.76706\ttrain-rmse:1.94066\n",
      "[37796]\teval-rmse:3.76698\ttrain-rmse:1.94066\n",
      "[37797]\teval-rmse:3.76709\ttrain-rmse:1.94066\n",
      "[37798]\teval-rmse:3.76701\ttrain-rmse:1.94066\n",
      "[37799]\teval-rmse:3.76717\ttrain-rmse:1.94065\n",
      "[37800]\teval-rmse:3.76791\ttrain-rmse:1.94063\n",
      "[37801]\teval-rmse:3.76656\ttrain-rmse:1.94067\n",
      "[37802]\teval-rmse:3.76516\ttrain-rmse:1.94072\n",
      "[37803]\teval-rmse:3.76381\ttrain-rmse:1.94078\n",
      "[37804]\teval-rmse:3.76499\ttrain-rmse:1.94073\n",
      "[37805]\teval-rmse:3.76392\ttrain-rmse:1.94077\n",
      "[37806]\teval-rmse:3.76421\ttrain-rmse:1.94076\n",
      "[37807]\teval-rmse:3.76596\ttrain-rmse:1.94068\n",
      "[37808]\teval-rmse:3.76729\ttrain-rmse:1.94063\n",
      "[37809]\teval-rmse:3.7683\ttrain-rmse:1.94059\n",
      "[37810]\teval-rmse:3.76821\ttrain-rmse:1.94057\n",
      "[37811]\teval-rmse:3.76684\ttrain-rmse:1.94062\n",
      "[37812]\teval-rmse:3.7672\ttrain-rmse:1.94061\n",
      "[37813]\teval-rmse:3.76571\ttrain-rmse:1.94067\n",
      "[37814]\teval-rmse:3.76625\ttrain-rmse:1.94065\n",
      "[37815]\teval-rmse:3.76532\ttrain-rmse:1.94069\n",
      "[37816]\teval-rmse:3.76401\ttrain-rmse:1.94074\n",
      "[37817]\teval-rmse:3.76286\ttrain-rmse:1.9408\n",
      "[37818]\teval-rmse:3.76221\ttrain-rmse:1.94083\n",
      "[37819]\teval-rmse:3.76261\ttrain-rmse:1.94081\n",
      "[37820]\teval-rmse:3.76343\ttrain-rmse:1.94077\n",
      "[37821]\teval-rmse:3.76213\ttrain-rmse:1.94084\n",
      "[37822]\teval-rmse:3.76288\ttrain-rmse:1.94079\n",
      "[37823]\teval-rmse:3.76444\ttrain-rmse:1.94071\n",
      "[37824]\teval-rmse:3.7647\ttrain-rmse:1.9407\n",
      "[37825]\teval-rmse:3.76406\ttrain-rmse:1.94073\n",
      "[37826]\teval-rmse:3.76524\ttrain-rmse:1.94068\n",
      "[37827]\teval-rmse:3.76572\ttrain-rmse:1.94066\n",
      "[37828]\teval-rmse:3.76731\ttrain-rmse:1.9406\n",
      "[37829]\teval-rmse:3.76701\ttrain-rmse:1.9406\n",
      "[37830]\teval-rmse:3.76739\ttrain-rmse:1.94059\n",
      "[37831]\teval-rmse:3.76592\ttrain-rmse:1.94065\n",
      "[37832]\teval-rmse:3.76723\ttrain-rmse:1.9406\n",
      "[37833]\teval-rmse:3.76714\ttrain-rmse:1.9406\n",
      "[37834]\teval-rmse:3.76755\ttrain-rmse:1.94058\n",
      "[37835]\teval-rmse:3.76907\ttrain-rmse:1.94052\n",
      "[37836]\teval-rmse:3.77021\ttrain-rmse:1.94048\n",
      "[37837]\teval-rmse:3.77196\ttrain-rmse:1.94042\n",
      "[37838]\teval-rmse:3.77185\ttrain-rmse:1.94041\n",
      "[37839]\teval-rmse:3.77034\ttrain-rmse:1.94044\n",
      "[37840]\teval-rmse:3.77024\ttrain-rmse:1.94045\n",
      "[37841]\teval-rmse:3.77199\ttrain-rmse:1.94039\n",
      "[37842]\teval-rmse:3.77166\ttrain-rmse:1.9404\n",
      "[37843]\teval-rmse:3.77315\ttrain-rmse:1.94037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37844]\teval-rmse:3.77457\ttrain-rmse:1.94033\n",
      "[37845]\teval-rmse:3.77597\ttrain-rmse:1.94031\n",
      "[37846]\teval-rmse:3.77644\ttrain-rmse:1.94031\n",
      "[37847]\teval-rmse:3.77761\ttrain-rmse:1.9403\n",
      "[37848]\teval-rmse:3.77876\ttrain-rmse:1.94029\n",
      "[37849]\teval-rmse:3.77913\ttrain-rmse:1.94029\n",
      "[37850]\teval-rmse:3.77925\ttrain-rmse:1.9403\n",
      "[37851]\teval-rmse:3.77913\ttrain-rmse:1.94028\n",
      "[37852]\teval-rmse:3.78055\ttrain-rmse:1.94029\n",
      "[37853]\teval-rmse:3.7793\ttrain-rmse:1.94028\n",
      "[37854]\teval-rmse:3.77901\ttrain-rmse:1.94028\n",
      "[37855]\teval-rmse:3.77776\ttrain-rmse:1.94028\n",
      "[37856]\teval-rmse:3.7783\ttrain-rmse:1.94029\n",
      "[37857]\teval-rmse:3.7773\ttrain-rmse:1.9403\n",
      "[37858]\teval-rmse:3.77592\ttrain-rmse:1.9403\n",
      "[37859]\teval-rmse:3.7763\ttrain-rmse:1.9403\n",
      "[37860]\teval-rmse:3.77492\ttrain-rmse:1.94031\n",
      "[37861]\teval-rmse:3.77513\ttrain-rmse:1.94031\n",
      "[37862]\teval-rmse:3.7747\ttrain-rmse:1.94032\n",
      "[37863]\teval-rmse:3.77451\ttrain-rmse:1.94032\n",
      "[37864]\teval-rmse:3.77472\ttrain-rmse:1.94032\n",
      "[37865]\teval-rmse:3.77606\ttrain-rmse:1.94032\n",
      "[37866]\teval-rmse:3.77559\ttrain-rmse:1.94032\n",
      "[37867]\teval-rmse:3.77582\ttrain-rmse:1.94032\n",
      "[37868]\teval-rmse:3.77755\ttrain-rmse:1.94029\n",
      "[37869]\teval-rmse:3.77795\ttrain-rmse:1.94029\n",
      "[37870]\teval-rmse:3.7781\ttrain-rmse:1.94029\n",
      "[37871]\teval-rmse:3.77679\ttrain-rmse:1.94029\n",
      "[37872]\teval-rmse:3.77537\ttrain-rmse:1.9403\n",
      "[37873]\teval-rmse:3.77651\ttrain-rmse:1.94029\n",
      "[37874]\teval-rmse:3.7781\ttrain-rmse:1.94028\n",
      "[37875]\teval-rmse:3.77764\ttrain-rmse:1.94028\n",
      "[37876]\teval-rmse:3.77602\ttrain-rmse:1.94029\n",
      "[37877]\teval-rmse:3.77727\ttrain-rmse:1.94028\n",
      "[37878]\teval-rmse:3.77869\ttrain-rmse:1.94026\n",
      "[37879]\teval-rmse:3.77768\ttrain-rmse:1.94027\n",
      "[37880]\teval-rmse:3.77927\ttrain-rmse:1.94027\n",
      "[37881]\teval-rmse:3.77795\ttrain-rmse:1.94029\n",
      "[37882]\teval-rmse:3.77935\ttrain-rmse:1.94028\n",
      "[37883]\teval-rmse:3.77864\ttrain-rmse:1.94028\n",
      "[37884]\teval-rmse:3.77851\ttrain-rmse:1.94027\n",
      "[37885]\teval-rmse:3.77865\ttrain-rmse:1.94027\n",
      "[37886]\teval-rmse:3.77896\ttrain-rmse:1.94027\n",
      "[37887]\teval-rmse:3.7785\ttrain-rmse:1.94027\n",
      "[37888]\teval-rmse:3.77903\ttrain-rmse:1.94027\n",
      "[37889]\teval-rmse:3.77765\ttrain-rmse:1.94027\n",
      "[37890]\teval-rmse:3.77634\ttrain-rmse:1.94028\n",
      "[37891]\teval-rmse:3.77535\ttrain-rmse:1.9403\n",
      "[37892]\teval-rmse:3.77654\ttrain-rmse:1.9403\n",
      "[37893]\teval-rmse:3.7769\ttrain-rmse:1.94029\n",
      "[37894]\teval-rmse:3.77661\ttrain-rmse:1.9403\n",
      "[37895]\teval-rmse:3.77818\ttrain-rmse:1.94031\n",
      "[37896]\teval-rmse:3.77718\ttrain-rmse:1.94032\n",
      "[37897]\teval-rmse:3.77869\ttrain-rmse:1.94032\n",
      "[37898]\teval-rmse:3.78026\ttrain-rmse:1.94033\n",
      "[37899]\teval-rmse:3.78012\ttrain-rmse:1.94032\n",
      "[37900]\teval-rmse:3.77959\ttrain-rmse:1.94032\n",
      "[37901]\teval-rmse:3.77921\ttrain-rmse:1.94032\n",
      "[37902]\teval-rmse:3.77969\ttrain-rmse:1.94033\n",
      "[37903]\teval-rmse:3.77836\ttrain-rmse:1.94034\n",
      "[37904]\teval-rmse:3.77672\ttrain-rmse:1.94034\n",
      "[37905]\teval-rmse:3.77787\ttrain-rmse:1.94034\n",
      "[37906]\teval-rmse:3.77826\ttrain-rmse:1.94034\n",
      "[37907]\teval-rmse:3.77756\ttrain-rmse:1.94033\n",
      "[37908]\teval-rmse:3.77906\ttrain-rmse:1.94034\n",
      "[37909]\teval-rmse:3.77976\ttrain-rmse:1.94034\n",
      "[37910]\teval-rmse:3.78117\ttrain-rmse:1.94033\n",
      "[37911]\teval-rmse:3.78291\ttrain-rmse:1.94033\n",
      "[37912]\teval-rmse:3.78341\ttrain-rmse:1.94034\n",
      "[37913]\teval-rmse:3.78409\ttrain-rmse:1.94035\n",
      "[37914]\teval-rmse:3.78478\ttrain-rmse:1.94035\n",
      "[37915]\teval-rmse:3.78617\ttrain-rmse:1.94039\n",
      "[37916]\teval-rmse:3.78651\ttrain-rmse:1.9404\n",
      "[37917]\teval-rmse:3.78647\ttrain-rmse:1.9404\n",
      "[37918]\teval-rmse:3.78527\ttrain-rmse:1.94037\n",
      "[37919]\teval-rmse:3.78553\ttrain-rmse:1.94038\n",
      "[37920]\teval-rmse:3.78521\ttrain-rmse:1.94038\n",
      "[37921]\teval-rmse:3.78398\ttrain-rmse:1.94035\n",
      "[37922]\teval-rmse:3.78244\ttrain-rmse:1.94033\n",
      "[37923]\teval-rmse:3.78243\ttrain-rmse:1.94033\n",
      "[37924]\teval-rmse:3.78125\ttrain-rmse:1.94032\n",
      "[37925]\teval-rmse:3.78276\ttrain-rmse:1.94031\n",
      "[37926]\teval-rmse:3.7832\ttrain-rmse:1.94032\n",
      "[37927]\teval-rmse:3.78171\ttrain-rmse:1.94028\n",
      "[37928]\teval-rmse:3.7798\ttrain-rmse:1.94026\n",
      "[37929]\teval-rmse:3.78113\ttrain-rmse:1.94029\n",
      "[37930]\teval-rmse:3.78057\ttrain-rmse:1.94028\n",
      "[37931]\teval-rmse:3.78101\ttrain-rmse:1.94029\n",
      "[37932]\teval-rmse:3.78137\ttrain-rmse:1.94029\n",
      "[37933]\teval-rmse:3.78154\ttrain-rmse:1.94029\n",
      "[37934]\teval-rmse:3.7803\ttrain-rmse:1.9403\n",
      "[37935]\teval-rmse:3.77981\ttrain-rmse:1.9403\n",
      "[37936]\teval-rmse:3.78051\ttrain-rmse:1.94031\n",
      "[37937]\teval-rmse:3.78036\ttrain-rmse:1.94029\n",
      "[37938]\teval-rmse:3.78104\ttrain-rmse:1.9403\n",
      "[37939]\teval-rmse:3.78242\ttrain-rmse:1.94031\n",
      "[37940]\teval-rmse:3.78168\ttrain-rmse:1.94029\n",
      "[37941]\teval-rmse:3.77979\ttrain-rmse:1.94028\n",
      "[37942]\teval-rmse:3.77853\ttrain-rmse:1.94027\n",
      "[37943]\teval-rmse:3.77897\ttrain-rmse:1.94028\n",
      "[37944]\teval-rmse:3.77933\ttrain-rmse:1.94028\n",
      "[37945]\teval-rmse:3.78074\ttrain-rmse:1.94029\n",
      "[37946]\teval-rmse:3.7807\ttrain-rmse:1.94029\n",
      "[37947]\teval-rmse:3.78055\ttrain-rmse:1.94027\n",
      "[37948]\teval-rmse:3.78157\ttrain-rmse:1.94029\n",
      "[37949]\teval-rmse:3.78107\ttrain-rmse:1.94029\n",
      "[37950]\teval-rmse:3.78034\ttrain-rmse:1.94028\n",
      "[37951]\teval-rmse:3.77884\ttrain-rmse:1.94026\n",
      "[37952]\teval-rmse:3.77736\ttrain-rmse:1.94024\n",
      "[37953]\teval-rmse:3.77613\ttrain-rmse:1.94026\n",
      "[37954]\teval-rmse:3.7776\ttrain-rmse:1.94026\n",
      "[37955]\teval-rmse:3.77747\ttrain-rmse:1.94026\n",
      "[37956]\teval-rmse:3.77779\ttrain-rmse:1.94026\n",
      "[37957]\teval-rmse:3.77759\ttrain-rmse:1.94026\n",
      "[37958]\teval-rmse:3.77723\ttrain-rmse:1.94026\n",
      "[37959]\teval-rmse:3.77752\ttrain-rmse:1.94026\n",
      "[37960]\teval-rmse:3.77893\ttrain-rmse:1.94024\n",
      "[37961]\teval-rmse:3.77909\ttrain-rmse:1.94024\n",
      "[37962]\teval-rmse:3.77994\ttrain-rmse:1.94025\n",
      "[37963]\teval-rmse:3.78119\ttrain-rmse:1.94027\n",
      "[37964]\teval-rmse:3.78118\ttrain-rmse:1.94027\n",
      "[37965]\teval-rmse:3.78142\ttrain-rmse:1.94027\n",
      "[37966]\teval-rmse:3.78069\ttrain-rmse:1.94026\n",
      "[37967]\teval-rmse:3.78048\ttrain-rmse:1.94026\n",
      "[37968]\teval-rmse:3.78034\ttrain-rmse:1.94024\n",
      "[37969]\teval-rmse:3.77978\ttrain-rmse:1.94023\n",
      "[37970]\teval-rmse:3.78117\ttrain-rmse:1.94025\n",
      "[37971]\teval-rmse:3.78258\ttrain-rmse:1.94027\n",
      "[37972]\teval-rmse:3.78325\ttrain-rmse:1.94029\n",
      "[37973]\teval-rmse:3.78395\ttrain-rmse:1.9403\n",
      "[37974]\teval-rmse:3.78428\ttrain-rmse:1.94031\n",
      "[37975]\teval-rmse:3.78423\ttrain-rmse:1.94031\n",
      "[37976]\teval-rmse:3.78371\ttrain-rmse:1.9403\n",
      "[37977]\teval-rmse:3.78522\ttrain-rmse:1.94033\n",
      "[37978]\teval-rmse:3.78359\ttrain-rmse:1.94028\n",
      "[37979]\teval-rmse:3.78429\ttrain-rmse:1.94028\n",
      "[37980]\teval-rmse:3.78355\ttrain-rmse:1.94027\n",
      "[37981]\teval-rmse:3.78356\ttrain-rmse:1.94027\n",
      "[37982]\teval-rmse:3.78218\ttrain-rmse:1.94024\n",
      "[37983]\teval-rmse:3.78187\ttrain-rmse:1.94024\n",
      "[37984]\teval-rmse:3.78069\ttrain-rmse:1.94023\n",
      "[37985]\teval-rmse:3.77967\ttrain-rmse:1.94023\n",
      "[37986]\teval-rmse:3.78035\ttrain-rmse:1.94024\n",
      "[37987]\teval-rmse:3.78004\ttrain-rmse:1.94024\n",
      "[37988]\teval-rmse:3.78072\ttrain-rmse:1.94025\n",
      "[37989]\teval-rmse:3.78068\ttrain-rmse:1.94025\n",
      "[37990]\teval-rmse:3.7809\ttrain-rmse:1.94025\n",
      "[37991]\teval-rmse:3.77991\ttrain-rmse:1.94024\n",
      "[37992]\teval-rmse:3.7801\ttrain-rmse:1.94024\n",
      "[37993]\teval-rmse:3.77823\ttrain-rmse:1.94025\n",
      "[37994]\teval-rmse:3.77957\ttrain-rmse:1.94026\n",
      "[37995]\teval-rmse:3.77793\ttrain-rmse:1.94026\n",
      "[37996]\teval-rmse:3.77782\ttrain-rmse:1.94026\n",
      "[37997]\teval-rmse:3.77611\ttrain-rmse:1.94026\n",
      "[37998]\teval-rmse:3.77666\ttrain-rmse:1.94025\n",
      "[37999]\teval-rmse:3.77622\ttrain-rmse:1.94026\n",
      "[38000]\teval-rmse:3.775\ttrain-rmse:1.94028\n",
      "[38001]\teval-rmse:3.77612\ttrain-rmse:1.94027\n",
      "[38002]\teval-rmse:3.77641\ttrain-rmse:1.94027\n",
      "[38003]\teval-rmse:3.77677\ttrain-rmse:1.94027\n",
      "[38004]\teval-rmse:3.77698\ttrain-rmse:1.94027\n",
      "[38005]\teval-rmse:3.7763\ttrain-rmse:1.94027\n",
      "[38006]\teval-rmse:3.77617\ttrain-rmse:1.94027\n",
      "[38007]\teval-rmse:3.77563\ttrain-rmse:1.94027\n",
      "[38008]\teval-rmse:3.77528\ttrain-rmse:1.94028\n",
      "[38009]\teval-rmse:3.7743\ttrain-rmse:1.9403\n",
      "[38010]\teval-rmse:3.77258\ttrain-rmse:1.94031\n",
      "[38011]\teval-rmse:3.77409\ttrain-rmse:1.94027\n",
      "[38012]\teval-rmse:3.77257\ttrain-rmse:1.94029\n",
      "[38013]\teval-rmse:3.77388\ttrain-rmse:1.94028\n",
      "[38014]\teval-rmse:3.77427\ttrain-rmse:1.94028\n",
      "[38015]\teval-rmse:3.77464\ttrain-rmse:1.94027\n",
      "[38016]\teval-rmse:3.7734\ttrain-rmse:1.94029\n",
      "[38017]\teval-rmse:3.77385\ttrain-rmse:1.94028\n",
      "[38018]\teval-rmse:3.77271\ttrain-rmse:1.9403\n",
      "[38019]\teval-rmse:3.77411\ttrain-rmse:1.94028\n",
      "[38020]\teval-rmse:3.77281\ttrain-rmse:1.94029\n",
      "[38021]\teval-rmse:3.77334\ttrain-rmse:1.94029\n",
      "[38022]\teval-rmse:3.77291\ttrain-rmse:1.94029\n",
      "[38023]\teval-rmse:3.7744\ttrain-rmse:1.94027\n",
      "[38024]\teval-rmse:3.77371\ttrain-rmse:1.94028\n",
      "[38025]\teval-rmse:3.77276\ttrain-rmse:1.94029\n",
      "[38026]\teval-rmse:3.77292\ttrain-rmse:1.94029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38027]\teval-rmse:3.77264\ttrain-rmse:1.94029\n",
      "[38028]\teval-rmse:3.77303\ttrain-rmse:1.94029\n",
      "[38029]\teval-rmse:3.77269\ttrain-rmse:1.9403\n",
      "[38030]\teval-rmse:3.77172\ttrain-rmse:1.94032\n",
      "[38031]\teval-rmse:3.77025\ttrain-rmse:1.94035\n",
      "[38032]\teval-rmse:3.77071\ttrain-rmse:1.94034\n",
      "[38033]\teval-rmse:3.77061\ttrain-rmse:1.94034\n",
      "[38034]\teval-rmse:3.77027\ttrain-rmse:1.94035\n",
      "[38035]\teval-rmse:3.76932\ttrain-rmse:1.94038\n",
      "[38036]\teval-rmse:3.7705\ttrain-rmse:1.94035\n",
      "[38037]\teval-rmse:3.77066\ttrain-rmse:1.94035\n",
      "[38038]\teval-rmse:3.77209\ttrain-rmse:1.94031\n",
      "[38039]\teval-rmse:3.77351\ttrain-rmse:1.94027\n",
      "[38040]\teval-rmse:3.7738\ttrain-rmse:1.94027\n",
      "[38041]\teval-rmse:3.77251\ttrain-rmse:1.9403\n",
      "[38042]\teval-rmse:3.77102\ttrain-rmse:1.94032\n",
      "[38043]\teval-rmse:3.76975\ttrain-rmse:1.94036\n",
      "[38044]\teval-rmse:3.76854\ttrain-rmse:1.94039\n",
      "[38045]\teval-rmse:3.7691\ttrain-rmse:1.94038\n",
      "[38046]\teval-rmse:3.76757\ttrain-rmse:1.94042\n",
      "[38047]\teval-rmse:3.769\ttrain-rmse:1.94038\n",
      "[38048]\teval-rmse:3.76852\ttrain-rmse:1.9404\n",
      "[38049]\teval-rmse:3.7697\ttrain-rmse:1.94036\n",
      "[38050]\teval-rmse:3.77021\ttrain-rmse:1.94035\n",
      "[38051]\teval-rmse:3.76902\ttrain-rmse:1.94039\n",
      "[38052]\teval-rmse:3.76949\ttrain-rmse:1.94038\n",
      "[38053]\teval-rmse:3.77092\ttrain-rmse:1.94033\n",
      "[38054]\teval-rmse:3.77081\ttrain-rmse:1.94031\n",
      "[38055]\teval-rmse:3.76961\ttrain-rmse:1.94034\n",
      "[38056]\teval-rmse:3.76843\ttrain-rmse:1.94037\n",
      "[38057]\teval-rmse:3.76777\ttrain-rmse:1.94039\n",
      "[38058]\teval-rmse:3.76594\ttrain-rmse:1.94048\n",
      "[38059]\teval-rmse:3.76444\ttrain-rmse:1.94053\n",
      "[38060]\teval-rmse:3.76288\ttrain-rmse:1.94062\n",
      "[38061]\teval-rmse:3.7629\ttrain-rmse:1.94062\n",
      "[38062]\teval-rmse:3.76338\ttrain-rmse:1.94059\n",
      "[38063]\teval-rmse:3.7639\ttrain-rmse:1.94057\n",
      "[38064]\teval-rmse:3.76461\ttrain-rmse:1.94054\n",
      "[38065]\teval-rmse:3.76447\ttrain-rmse:1.94054\n",
      "[38066]\teval-rmse:3.76567\ttrain-rmse:1.94049\n",
      "[38067]\teval-rmse:3.76441\ttrain-rmse:1.94054\n",
      "[38068]\teval-rmse:3.76515\ttrain-rmse:1.94051\n",
      "[38069]\teval-rmse:3.7657\ttrain-rmse:1.9405\n",
      "[38070]\teval-rmse:3.76625\ttrain-rmse:1.94047\n",
      "[38071]\teval-rmse:3.76532\ttrain-rmse:1.94051\n",
      "[38072]\teval-rmse:3.76665\ttrain-rmse:1.94047\n",
      "[38073]\teval-rmse:3.76656\ttrain-rmse:1.94047\n",
      "[38074]\teval-rmse:3.76783\ttrain-rmse:1.94043\n",
      "[38075]\teval-rmse:3.76821\ttrain-rmse:1.94042\n",
      "[38076]\teval-rmse:3.7694\ttrain-rmse:1.94038\n",
      "[38077]\teval-rmse:3.76968\ttrain-rmse:1.94037\n",
      "[38078]\teval-rmse:3.76818\ttrain-rmse:1.94041\n",
      "[38079]\teval-rmse:3.76843\ttrain-rmse:1.9404\n",
      "[38080]\teval-rmse:3.76827\ttrain-rmse:1.94041\n",
      "[38081]\teval-rmse:3.76877\ttrain-rmse:1.9404\n",
      "[38082]\teval-rmse:3.76851\ttrain-rmse:1.9404\n",
      "[38083]\teval-rmse:3.76787\ttrain-rmse:1.94042\n",
      "[38084]\teval-rmse:3.76771\ttrain-rmse:1.94043\n",
      "[38085]\teval-rmse:3.7673\ttrain-rmse:1.94044\n",
      "[38086]\teval-rmse:3.76778\ttrain-rmse:1.94043\n",
      "[38087]\teval-rmse:3.76816\ttrain-rmse:1.94041\n",
      "[38088]\teval-rmse:3.76841\ttrain-rmse:1.94041\n",
      "[38089]\teval-rmse:3.76891\ttrain-rmse:1.94039\n",
      "[38090]\teval-rmse:3.76858\ttrain-rmse:1.9404\n",
      "[38091]\teval-rmse:3.76764\ttrain-rmse:1.94043\n",
      "[38092]\teval-rmse:3.76701\ttrain-rmse:1.94045\n",
      "[38093]\teval-rmse:3.76566\ttrain-rmse:1.94049\n",
      "[38094]\teval-rmse:3.76559\ttrain-rmse:1.9405\n",
      "[38095]\teval-rmse:3.76417\ttrain-rmse:1.94055\n",
      "[38096]\teval-rmse:3.76417\ttrain-rmse:1.94055\n",
      "[38097]\teval-rmse:3.76309\ttrain-rmse:1.9406\n",
      "[38098]\teval-rmse:3.76175\ttrain-rmse:1.94068\n",
      "[38099]\teval-rmse:3.76247\ttrain-rmse:1.94065\n",
      "[38100]\teval-rmse:3.76117\ttrain-rmse:1.94071\n",
      "[38101]\teval-rmse:3.75987\ttrain-rmse:1.94079\n",
      "[38102]\teval-rmse:3.76139\ttrain-rmse:1.94071\n",
      "[38103]\teval-rmse:3.76102\ttrain-rmse:1.94073\n",
      "[38104]\teval-rmse:3.76229\ttrain-rmse:1.94066\n",
      "[38105]\teval-rmse:3.76216\ttrain-rmse:1.94067\n",
      "[38106]\teval-rmse:3.76235\ttrain-rmse:1.94065\n",
      "[38107]\teval-rmse:3.76309\ttrain-rmse:1.94062\n",
      "[38108]\teval-rmse:3.76364\ttrain-rmse:1.94059\n",
      "[38109]\teval-rmse:3.76404\ttrain-rmse:1.94057\n",
      "[38110]\teval-rmse:3.76578\ttrain-rmse:1.94049\n",
      "[38111]\teval-rmse:3.76466\ttrain-rmse:1.94054\n",
      "[38112]\teval-rmse:3.76329\ttrain-rmse:1.9406\n",
      "[38113]\teval-rmse:3.7619\ttrain-rmse:1.94067\n",
      "[38114]\teval-rmse:3.76168\ttrain-rmse:1.94068\n",
      "[38115]\teval-rmse:3.76077\ttrain-rmse:1.94073\n",
      "[38116]\teval-rmse:3.76134\ttrain-rmse:1.94069\n",
      "[38117]\teval-rmse:3.76283\ttrain-rmse:1.94061\n",
      "[38118]\teval-rmse:3.76307\ttrain-rmse:1.9406\n",
      "[38119]\teval-rmse:3.76284\ttrain-rmse:1.9406\n",
      "[38120]\teval-rmse:3.76408\ttrain-rmse:1.94055\n",
      "[38121]\teval-rmse:3.76443\ttrain-rmse:1.94053\n",
      "[38122]\teval-rmse:3.76394\ttrain-rmse:1.94055\n",
      "[38123]\teval-rmse:3.76371\ttrain-rmse:1.94056\n",
      "[38124]\teval-rmse:3.76488\ttrain-rmse:1.94051\n",
      "[38125]\teval-rmse:3.76395\ttrain-rmse:1.94055\n",
      "[38126]\teval-rmse:3.7657\ttrain-rmse:1.94047\n",
      "[38127]\teval-rmse:3.76504\ttrain-rmse:1.9405\n",
      "[38128]\teval-rmse:3.76341\ttrain-rmse:1.94057\n",
      "[38129]\teval-rmse:3.76465\ttrain-rmse:1.94051\n",
      "[38130]\teval-rmse:3.76423\ttrain-rmse:1.94053\n",
      "[38131]\teval-rmse:3.76452\ttrain-rmse:1.94051\n",
      "[38132]\teval-rmse:3.7636\ttrain-rmse:1.94056\n",
      "[38133]\teval-rmse:3.76368\ttrain-rmse:1.94055\n",
      "[38134]\teval-rmse:3.7648\ttrain-rmse:1.9405\n",
      "[38135]\teval-rmse:3.76581\ttrain-rmse:1.94046\n",
      "[38136]\teval-rmse:3.76599\ttrain-rmse:1.94045\n",
      "[38137]\teval-rmse:3.76669\ttrain-rmse:1.94043\n",
      "[38138]\teval-rmse:3.76544\ttrain-rmse:1.94047\n",
      "[38139]\teval-rmse:3.76452\ttrain-rmse:1.94051\n",
      "[38140]\teval-rmse:3.76444\ttrain-rmse:1.94052\n",
      "[38141]\teval-rmse:3.76306\ttrain-rmse:1.94058\n",
      "[38142]\teval-rmse:3.76273\ttrain-rmse:1.94059\n",
      "[38143]\teval-rmse:3.76303\ttrain-rmse:1.94058\n",
      "[38144]\teval-rmse:3.76343\ttrain-rmse:1.94056\n",
      "[38145]\teval-rmse:3.76163\ttrain-rmse:1.94067\n",
      "[38146]\teval-rmse:3.76151\ttrain-rmse:1.94067\n",
      "[38147]\teval-rmse:3.76189\ttrain-rmse:1.94065\n",
      "[38148]\teval-rmse:3.76324\ttrain-rmse:1.94058\n",
      "[38149]\teval-rmse:3.76343\ttrain-rmse:1.94057\n",
      "[38150]\teval-rmse:3.76304\ttrain-rmse:1.94059\n",
      "[38151]\teval-rmse:3.76189\ttrain-rmse:1.94065\n",
      "[38152]\teval-rmse:3.76215\ttrain-rmse:1.94064\n",
      "[38153]\teval-rmse:3.76073\ttrain-rmse:1.94071\n",
      "[38154]\teval-rmse:3.76036\ttrain-rmse:1.94074\n",
      "[38155]\teval-rmse:3.75914\ttrain-rmse:1.94081\n",
      "[38156]\teval-rmse:3.75908\ttrain-rmse:1.94082\n",
      "[38157]\teval-rmse:3.75941\ttrain-rmse:1.9408\n",
      "[38158]\teval-rmse:3.75989\ttrain-rmse:1.94077\n",
      "[38159]\teval-rmse:3.76148\ttrain-rmse:1.94068\n",
      "[38160]\teval-rmse:3.76118\ttrain-rmse:1.9407\n",
      "[38161]\teval-rmse:3.7616\ttrain-rmse:1.94067\n",
      "[38162]\teval-rmse:3.7629\ttrain-rmse:1.94059\n",
      "[38163]\teval-rmse:3.76111\ttrain-rmse:1.94071\n",
      "[38164]\teval-rmse:3.76082\ttrain-rmse:1.94072\n",
      "[38165]\teval-rmse:3.76157\ttrain-rmse:1.94069\n",
      "[38166]\teval-rmse:3.76176\ttrain-rmse:1.94068\n",
      "[38167]\teval-rmse:3.76197\ttrain-rmse:1.94066\n",
      "[38168]\teval-rmse:3.76349\ttrain-rmse:1.9406\n",
      "[38169]\teval-rmse:3.76403\ttrain-rmse:1.94057\n",
      "[38170]\teval-rmse:3.7624\ttrain-rmse:1.94066\n",
      "[38171]\teval-rmse:3.76138\ttrain-rmse:1.94071\n",
      "[38172]\teval-rmse:3.76163\ttrain-rmse:1.9407\n",
      "[38173]\teval-rmse:3.76042\ttrain-rmse:1.94076\n",
      "[38174]\teval-rmse:3.7616\ttrain-rmse:1.94069\n",
      "[38175]\teval-rmse:3.76159\ttrain-rmse:1.94069\n",
      "[38176]\teval-rmse:3.76283\ttrain-rmse:1.94064\n",
      "[38177]\teval-rmse:3.76305\ttrain-rmse:1.94062\n",
      "[38178]\teval-rmse:3.76448\ttrain-rmse:1.94055\n",
      "[38179]\teval-rmse:3.76302\ttrain-rmse:1.94062\n",
      "[38180]\teval-rmse:3.76435\ttrain-rmse:1.94055\n",
      "[38181]\teval-rmse:3.76326\ttrain-rmse:1.94061\n",
      "[38182]\teval-rmse:3.76353\ttrain-rmse:1.9406\n",
      "[38183]\teval-rmse:3.7623\ttrain-rmse:1.94066\n",
      "[38184]\teval-rmse:3.76389\ttrain-rmse:1.94058\n",
      "[38185]\teval-rmse:3.76463\ttrain-rmse:1.94054\n",
      "[38186]\teval-rmse:3.7643\ttrain-rmse:1.94055\n",
      "[38187]\teval-rmse:3.76563\ttrain-rmse:1.9405\n",
      "[38188]\teval-rmse:3.7661\ttrain-rmse:1.94049\n",
      "[38189]\teval-rmse:3.76579\ttrain-rmse:1.9405\n",
      "[38190]\teval-rmse:3.76455\ttrain-rmse:1.94055\n",
      "[38191]\teval-rmse:3.76484\ttrain-rmse:1.94054\n",
      "[38192]\teval-rmse:3.76337\ttrain-rmse:1.94061\n",
      "[38193]\teval-rmse:3.76477\ttrain-rmse:1.94055\n",
      "[38194]\teval-rmse:3.76652\ttrain-rmse:1.94048\n",
      "[38195]\teval-rmse:3.76636\ttrain-rmse:1.94048\n",
      "[38196]\teval-rmse:3.76785\ttrain-rmse:1.94044\n",
      "[38197]\teval-rmse:3.76937\ttrain-rmse:1.94039\n",
      "[38198]\teval-rmse:3.77112\ttrain-rmse:1.94034\n",
      "[38199]\teval-rmse:3.77249\ttrain-rmse:1.9403\n",
      "[38200]\teval-rmse:3.77199\ttrain-rmse:1.94031\n",
      "[38201]\teval-rmse:3.77088\ttrain-rmse:1.94033\n",
      "[38202]\teval-rmse:3.77137\ttrain-rmse:1.94032\n",
      "[38203]\teval-rmse:3.77175\ttrain-rmse:1.94031\n",
      "[38204]\teval-rmse:3.77045\ttrain-rmse:1.94034\n",
      "[38205]\teval-rmse:3.77068\ttrain-rmse:1.94033\n",
      "[38206]\teval-rmse:3.77058\ttrain-rmse:1.94031\n",
      "[38207]\teval-rmse:3.77096\ttrain-rmse:1.9403\n",
      "[38208]\teval-rmse:3.77086\ttrain-rmse:1.94028\n",
      "[38209]\teval-rmse:3.77054\ttrain-rmse:1.94029\n",
      "[38210]\teval-rmse:3.77193\ttrain-rmse:1.94026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38211]\teval-rmse:3.77234\ttrain-rmse:1.94025\n",
      "[38212]\teval-rmse:3.77407\ttrain-rmse:1.94021\n",
      "[38213]\teval-rmse:3.77252\ttrain-rmse:1.94023\n",
      "[38214]\teval-rmse:3.77139\ttrain-rmse:1.94026\n",
      "[38215]\teval-rmse:3.77028\ttrain-rmse:1.94028\n",
      "[38216]\teval-rmse:3.76886\ttrain-rmse:1.94032\n",
      "[38217]\teval-rmse:3.76924\ttrain-rmse:1.94031\n",
      "[38218]\teval-rmse:3.77099\ttrain-rmse:1.94025\n",
      "[38219]\teval-rmse:3.77273\ttrain-rmse:1.9402\n",
      "[38220]\teval-rmse:3.77177\ttrain-rmse:1.94023\n",
      "[38221]\teval-rmse:3.77328\ttrain-rmse:1.94018\n",
      "[38222]\teval-rmse:3.77317\ttrain-rmse:1.94019\n",
      "[38223]\teval-rmse:3.77367\ttrain-rmse:1.94018\n",
      "[38224]\teval-rmse:3.77384\ttrain-rmse:1.94017\n",
      "[38225]\teval-rmse:3.77236\ttrain-rmse:1.94021\n",
      "[38226]\teval-rmse:3.77274\ttrain-rmse:1.9402\n",
      "[38227]\teval-rmse:3.77416\ttrain-rmse:1.94016\n",
      "[38228]\teval-rmse:3.77351\ttrain-rmse:1.94018\n",
      "[38229]\teval-rmse:3.77493\ttrain-rmse:1.94014\n",
      "[38230]\teval-rmse:3.77625\ttrain-rmse:1.94013\n",
      "[38231]\teval-rmse:3.77582\ttrain-rmse:1.94014\n",
      "[38232]\teval-rmse:3.77547\ttrain-rmse:1.94014\n",
      "[38233]\teval-rmse:3.77512\ttrain-rmse:1.94015\n",
      "[38234]\teval-rmse:3.77681\ttrain-rmse:1.94011\n",
      "[38235]\teval-rmse:3.77822\ttrain-rmse:1.94009\n",
      "[38236]\teval-rmse:3.77699\ttrain-rmse:1.9401\n",
      "[38237]\teval-rmse:3.7774\ttrain-rmse:1.9401\n",
      "[38238]\teval-rmse:3.77881\ttrain-rmse:1.94009\n",
      "[38239]\teval-rmse:3.77843\ttrain-rmse:1.94009\n",
      "[38240]\teval-rmse:3.77944\ttrain-rmse:1.94009\n",
      "[38241]\teval-rmse:3.77873\ttrain-rmse:1.94009\n",
      "[38242]\teval-rmse:3.77719\ttrain-rmse:1.9401\n",
      "[38243]\teval-rmse:3.7762\ttrain-rmse:1.94011\n",
      "[38244]\teval-rmse:3.77657\ttrain-rmse:1.94011\n",
      "[38245]\teval-rmse:3.77687\ttrain-rmse:1.94011\n",
      "[38246]\teval-rmse:3.77803\ttrain-rmse:1.9401\n",
      "[38247]\teval-rmse:3.77767\ttrain-rmse:1.94011\n",
      "[38248]\teval-rmse:3.77614\ttrain-rmse:1.94013\n",
      "[38249]\teval-rmse:3.77492\ttrain-rmse:1.94014\n",
      "[38250]\teval-rmse:3.77538\ttrain-rmse:1.94013\n",
      "[38251]\teval-rmse:3.77562\ttrain-rmse:1.94013\n",
      "[38252]\teval-rmse:3.77553\ttrain-rmse:1.94011\n",
      "[38253]\teval-rmse:3.77381\ttrain-rmse:1.94014\n",
      "[38254]\teval-rmse:3.77516\ttrain-rmse:1.94011\n",
      "[38255]\teval-rmse:3.77463\ttrain-rmse:1.94012\n",
      "[38256]\teval-rmse:3.77366\ttrain-rmse:1.94014\n",
      "[38257]\teval-rmse:3.77216\ttrain-rmse:1.94019\n",
      "[38258]\teval-rmse:3.77089\ttrain-rmse:1.94023\n",
      "[38259]\teval-rmse:3.77073\ttrain-rmse:1.94023\n",
      "[38260]\teval-rmse:3.77114\ttrain-rmse:1.94022\n",
      "[38261]\teval-rmse:3.76987\ttrain-rmse:1.94026\n",
      "[38262]\teval-rmse:3.77028\ttrain-rmse:1.94024\n",
      "[38263]\teval-rmse:3.76892\ttrain-rmse:1.94028\n",
      "[38264]\teval-rmse:3.76911\ttrain-rmse:1.94027\n",
      "[38265]\teval-rmse:3.77037\ttrain-rmse:1.94023\n",
      "[38266]\teval-rmse:3.77071\ttrain-rmse:1.94022\n",
      "[38267]\teval-rmse:3.77214\ttrain-rmse:1.94018\n",
      "[38268]\teval-rmse:3.77337\ttrain-rmse:1.94015\n",
      "[38269]\teval-rmse:3.77319\ttrain-rmse:1.94015\n",
      "[38270]\teval-rmse:3.77182\ttrain-rmse:1.94018\n",
      "[38271]\teval-rmse:3.77356\ttrain-rmse:1.94013\n",
      "[38272]\teval-rmse:3.77345\ttrain-rmse:1.94014\n",
      "[38273]\teval-rmse:3.77337\ttrain-rmse:1.94011\n",
      "[38274]\teval-rmse:3.77284\ttrain-rmse:1.94012\n",
      "[38275]\teval-rmse:3.77458\ttrain-rmse:1.94008\n",
      "[38276]\teval-rmse:3.77393\ttrain-rmse:1.94009\n",
      "[38277]\teval-rmse:3.7734\ttrain-rmse:1.94011\n",
      "[38278]\teval-rmse:3.77457\ttrain-rmse:1.94009\n",
      "[38279]\teval-rmse:3.77608\ttrain-rmse:1.94006\n",
      "[38280]\teval-rmse:3.77655\ttrain-rmse:1.94005\n",
      "[38281]\teval-rmse:3.77726\ttrain-rmse:1.94005\n",
      "[38282]\teval-rmse:3.7769\ttrain-rmse:1.94005\n",
      "[38283]\teval-rmse:3.7755\ttrain-rmse:1.94006\n",
      "[38284]\teval-rmse:3.77508\ttrain-rmse:1.94007\n",
      "[38285]\teval-rmse:3.77681\ttrain-rmse:1.94004\n",
      "[38286]\teval-rmse:3.7758\ttrain-rmse:1.94006\n",
      "[38287]\teval-rmse:3.77561\ttrain-rmse:1.94006\n",
      "[38288]\teval-rmse:3.77422\ttrain-rmse:1.94009\n",
      "[38289]\teval-rmse:3.77394\ttrain-rmse:1.9401\n",
      "[38290]\teval-rmse:3.77326\ttrain-rmse:1.94011\n",
      "[38291]\teval-rmse:3.7723\ttrain-rmse:1.94014\n",
      "[38292]\teval-rmse:3.7725\ttrain-rmse:1.94013\n",
      "[38293]\teval-rmse:3.77367\ttrain-rmse:1.9401\n",
      "[38294]\teval-rmse:3.7734\ttrain-rmse:1.94011\n",
      "[38295]\teval-rmse:3.7744\ttrain-rmse:1.94008\n",
      "[38296]\teval-rmse:3.77295\ttrain-rmse:1.94012\n",
      "[38297]\teval-rmse:3.77284\ttrain-rmse:1.9401\n",
      "[38298]\teval-rmse:3.77321\ttrain-rmse:1.94009\n",
      "[38299]\teval-rmse:3.7731\ttrain-rmse:1.94007\n",
      "[38300]\teval-rmse:3.77382\ttrain-rmse:1.94005\n",
      "[38301]\teval-rmse:3.77442\ttrain-rmse:1.94004\n",
      "[38302]\teval-rmse:3.77583\ttrain-rmse:1.94002\n",
      "[38303]\teval-rmse:3.77725\ttrain-rmse:1.93999\n",
      "[38304]\teval-rmse:3.77851\ttrain-rmse:1.93998\n",
      "[38305]\teval-rmse:3.77663\ttrain-rmse:1.94003\n",
      "[38306]\teval-rmse:3.77765\ttrain-rmse:1.94001\n",
      "[38307]\teval-rmse:3.77865\ttrain-rmse:1.94\n",
      "[38308]\teval-rmse:3.78015\ttrain-rmse:1.93999\n",
      "[38309]\teval-rmse:3.7805\ttrain-rmse:1.93999\n",
      "[38310]\teval-rmse:3.78209\ttrain-rmse:1.93999\n",
      "[38311]\teval-rmse:3.78381\ttrain-rmse:1.93999\n",
      "[38312]\teval-rmse:3.78545\ttrain-rmse:1.94001\n",
      "[38313]\teval-rmse:3.7868\ttrain-rmse:1.94003\n",
      "[38314]\teval-rmse:3.78796\ttrain-rmse:1.94006\n",
      "[38315]\teval-rmse:3.78756\ttrain-rmse:1.94005\n",
      "[38316]\teval-rmse:3.78913\ttrain-rmse:1.9401\n",
      "[38317]\teval-rmse:3.78888\ttrain-rmse:1.94009\n",
      "[38318]\teval-rmse:3.78854\ttrain-rmse:1.94009\n",
      "[38319]\teval-rmse:3.7882\ttrain-rmse:1.94008\n",
      "[38320]\teval-rmse:3.78976\ttrain-rmse:1.94011\n",
      "[38321]\teval-rmse:3.79124\ttrain-rmse:1.94016\n",
      "[38322]\teval-rmse:3.79082\ttrain-rmse:1.94015\n",
      "[38323]\teval-rmse:3.79237\ttrain-rmse:1.94021\n",
      "[38324]\teval-rmse:3.79375\ttrain-rmse:1.94027\n",
      "[38325]\teval-rmse:3.79194\ttrain-rmse:1.94019\n",
      "[38326]\teval-rmse:3.79036\ttrain-rmse:1.94013\n",
      "[38327]\teval-rmse:3.79176\ttrain-rmse:1.94019\n",
      "[38328]\teval-rmse:3.79177\ttrain-rmse:1.94019\n",
      "[38329]\teval-rmse:3.79219\ttrain-rmse:1.9402\n",
      "[38330]\teval-rmse:3.79184\ttrain-rmse:1.94019\n",
      "[38331]\teval-rmse:3.79321\ttrain-rmse:1.94025\n",
      "[38332]\teval-rmse:3.79366\ttrain-rmse:1.94027\n",
      "[38333]\teval-rmse:3.79346\ttrain-rmse:1.94025\n",
      "[38334]\teval-rmse:3.79179\ttrain-rmse:1.94018\n",
      "[38335]\teval-rmse:3.79227\ttrain-rmse:1.9402\n",
      "[38336]\teval-rmse:3.79292\ttrain-rmse:1.94023\n",
      "[38337]\teval-rmse:3.79288\ttrain-rmse:1.94022\n",
      "[38338]\teval-rmse:3.79308\ttrain-rmse:1.94023\n",
      "[38339]\teval-rmse:3.79318\ttrain-rmse:1.94024\n",
      "[38340]\teval-rmse:3.79285\ttrain-rmse:1.94022\n",
      "[38341]\teval-rmse:3.79119\ttrain-rmse:1.94015\n",
      "[38342]\teval-rmse:3.78978\ttrain-rmse:1.94012\n",
      "[38343]\teval-rmse:3.78937\ttrain-rmse:1.94011\n",
      "[38344]\teval-rmse:3.78913\ttrain-rmse:1.9401\n",
      "[38345]\teval-rmse:3.78997\ttrain-rmse:1.94013\n",
      "[38346]\teval-rmse:3.79122\ttrain-rmse:1.94017\n",
      "[38347]\teval-rmse:3.7926\ttrain-rmse:1.94023\n",
      "[38348]\teval-rmse:3.79416\ttrain-rmse:1.94028\n",
      "[38349]\teval-rmse:3.79275\ttrain-rmse:1.94023\n",
      "[38350]\teval-rmse:3.79256\ttrain-rmse:1.94021\n",
      "[38351]\teval-rmse:3.79275\ttrain-rmse:1.94022\n",
      "[38352]\teval-rmse:3.79323\ttrain-rmse:1.94024\n",
      "[38353]\teval-rmse:3.7928\ttrain-rmse:1.94022\n",
      "[38354]\teval-rmse:3.79436\ttrain-rmse:1.94026\n",
      "[38355]\teval-rmse:3.79413\ttrain-rmse:1.94025\n",
      "[38356]\teval-rmse:3.79454\ttrain-rmse:1.94027\n",
      "[38357]\teval-rmse:3.79435\ttrain-rmse:1.94026\n",
      "[38358]\teval-rmse:3.79485\ttrain-rmse:1.94028\n",
      "[38359]\teval-rmse:3.79483\ttrain-rmse:1.94028\n",
      "[38360]\teval-rmse:3.79598\ttrain-rmse:1.94033\n",
      "[38361]\teval-rmse:3.79711\ttrain-rmse:1.9404\n",
      "[38362]\teval-rmse:3.79767\ttrain-rmse:1.94043\n",
      "[38363]\teval-rmse:3.79617\ttrain-rmse:1.94035\n",
      "[38364]\teval-rmse:3.79774\ttrain-rmse:1.94044\n",
      "[38365]\teval-rmse:3.79805\ttrain-rmse:1.94046\n",
      "[38366]\teval-rmse:3.79748\ttrain-rmse:1.94043\n",
      "[38367]\teval-rmse:3.79726\ttrain-rmse:1.94042\n",
      "[38368]\teval-rmse:3.79648\ttrain-rmse:1.94038\n",
      "[38369]\teval-rmse:3.79764\ttrain-rmse:1.94045\n",
      "[38370]\teval-rmse:3.79702\ttrain-rmse:1.94042\n",
      "[38371]\teval-rmse:3.79639\ttrain-rmse:1.94038\n",
      "[38372]\teval-rmse:3.79577\ttrain-rmse:1.94035\n",
      "[38373]\teval-rmse:3.79426\ttrain-rmse:1.94026\n",
      "[38374]\teval-rmse:3.79398\ttrain-rmse:1.94026\n",
      "[38375]\teval-rmse:3.79429\ttrain-rmse:1.94027\n",
      "[38376]\teval-rmse:3.79392\ttrain-rmse:1.94026\n",
      "[38377]\teval-rmse:3.79564\ttrain-rmse:1.94031\n",
      "[38378]\teval-rmse:3.79504\ttrain-rmse:1.94027\n",
      "[38379]\teval-rmse:3.79548\ttrain-rmse:1.9403\n",
      "[38380]\teval-rmse:3.79612\ttrain-rmse:1.94033\n",
      "[38381]\teval-rmse:3.7963\ttrain-rmse:1.94034\n",
      "[38382]\teval-rmse:3.7945\ttrain-rmse:1.94024\n",
      "[38383]\teval-rmse:3.79397\ttrain-rmse:1.94023\n",
      "[38384]\teval-rmse:3.79536\ttrain-rmse:1.9403\n",
      "[38385]\teval-rmse:3.79535\ttrain-rmse:1.9403\n",
      "[38386]\teval-rmse:3.79514\ttrain-rmse:1.94029\n",
      "[38387]\teval-rmse:3.79541\ttrain-rmse:1.9403\n",
      "[38388]\teval-rmse:3.79408\ttrain-rmse:1.94023\n",
      "[38389]\teval-rmse:3.79334\ttrain-rmse:1.9402\n",
      "[38390]\teval-rmse:3.79474\ttrain-rmse:1.94026\n",
      "[38391]\teval-rmse:3.79491\ttrain-rmse:1.94027\n",
      "[38392]\teval-rmse:3.79535\ttrain-rmse:1.94029\n",
      "[38393]\teval-rmse:3.79531\ttrain-rmse:1.94029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38394]\teval-rmse:3.79494\ttrain-rmse:1.94028\n",
      "[38395]\teval-rmse:3.79414\ttrain-rmse:1.94024\n",
      "[38396]\teval-rmse:3.79279\ttrain-rmse:1.94018\n",
      "[38397]\teval-rmse:3.7926\ttrain-rmse:1.94018\n",
      "[38398]\teval-rmse:3.7941\ttrain-rmse:1.94024\n",
      "[38399]\teval-rmse:3.79359\ttrain-rmse:1.94022\n",
      "[38400]\teval-rmse:3.79213\ttrain-rmse:1.94015\n",
      "[38401]\teval-rmse:3.79032\ttrain-rmse:1.94009\n",
      "[38402]\teval-rmse:3.79058\ttrain-rmse:1.94009\n",
      "[38403]\teval-rmse:3.78926\ttrain-rmse:1.94005\n",
      "[38404]\teval-rmse:3.79042\ttrain-rmse:1.94008\n",
      "[38405]\teval-rmse:3.7911\ttrain-rmse:1.94011\n",
      "[38406]\teval-rmse:3.78973\ttrain-rmse:1.94006\n",
      "[38407]\teval-rmse:3.78924\ttrain-rmse:1.94005\n",
      "[38408]\teval-rmse:3.78818\ttrain-rmse:1.94003\n",
      "[38409]\teval-rmse:3.78801\ttrain-rmse:1.94003\n",
      "[38410]\teval-rmse:3.78776\ttrain-rmse:1.94003\n",
      "[38411]\teval-rmse:3.78644\ttrain-rmse:1.94\n",
      "[38412]\teval-rmse:3.78593\ttrain-rmse:1.93999\n",
      "[38413]\teval-rmse:3.78545\ttrain-rmse:1.93999\n",
      "[38414]\teval-rmse:3.78577\ttrain-rmse:1.93999\n",
      "[38415]\teval-rmse:3.78445\ttrain-rmse:1.93997\n",
      "[38416]\teval-rmse:3.78479\ttrain-rmse:1.93998\n",
      "[38417]\teval-rmse:3.78464\ttrain-rmse:1.93996\n",
      "[38418]\teval-rmse:3.78597\ttrain-rmse:1.93998\n",
      "[38419]\teval-rmse:3.78643\ttrain-rmse:1.93999\n",
      "[38420]\teval-rmse:3.78627\ttrain-rmse:1.93999\n",
      "[38421]\teval-rmse:3.78485\ttrain-rmse:1.93996\n",
      "[38422]\teval-rmse:3.78462\ttrain-rmse:1.93996\n",
      "[38423]\teval-rmse:3.7831\ttrain-rmse:1.93996\n",
      "[38424]\teval-rmse:3.78297\ttrain-rmse:1.93994\n",
      "[38425]\teval-rmse:3.7847\ttrain-rmse:1.93994\n",
      "[38426]\teval-rmse:3.78279\ttrain-rmse:1.93993\n",
      "[38427]\teval-rmse:3.78242\ttrain-rmse:1.93993\n",
      "[38428]\teval-rmse:3.78221\ttrain-rmse:1.93993\n",
      "[38429]\teval-rmse:3.78273\ttrain-rmse:1.93994\n",
      "[38430]\teval-rmse:3.78157\ttrain-rmse:1.93993\n",
      "[38431]\teval-rmse:3.78175\ttrain-rmse:1.93993\n",
      "[38432]\teval-rmse:3.78349\ttrain-rmse:1.93993\n",
      "[38433]\teval-rmse:3.78317\ttrain-rmse:1.93993\n",
      "[38434]\teval-rmse:3.78304\ttrain-rmse:1.93993\n",
      "[38435]\teval-rmse:3.78184\ttrain-rmse:1.93991\n",
      "[38436]\teval-rmse:3.78304\ttrain-rmse:1.93992\n",
      "[38437]\teval-rmse:3.78273\ttrain-rmse:1.93992\n",
      "[38438]\teval-rmse:3.7817\ttrain-rmse:1.93992\n",
      "[38439]\teval-rmse:3.78288\ttrain-rmse:1.93993\n",
      "[38440]\teval-rmse:3.78357\ttrain-rmse:1.93994\n",
      "[38441]\teval-rmse:3.78484\ttrain-rmse:1.93995\n",
      "[38442]\teval-rmse:3.78437\ttrain-rmse:1.93994\n",
      "[38443]\teval-rmse:3.78472\ttrain-rmse:1.93994\n",
      "[38444]\teval-rmse:3.78539\ttrain-rmse:1.93995\n",
      "[38445]\teval-rmse:3.78609\ttrain-rmse:1.93996\n",
      "[38446]\teval-rmse:3.78576\ttrain-rmse:1.93996\n",
      "[38447]\teval-rmse:3.78562\ttrain-rmse:1.93996\n",
      "[38448]\teval-rmse:3.78717\ttrain-rmse:1.93999\n",
      "[38449]\teval-rmse:3.78754\ttrain-rmse:1.93999\n",
      "[38450]\teval-rmse:3.78869\ttrain-rmse:1.94002\n",
      "[38451]\teval-rmse:3.78914\ttrain-rmse:1.94003\n",
      "[38452]\teval-rmse:3.78879\ttrain-rmse:1.94003\n",
      "[38453]\teval-rmse:3.78723\ttrain-rmse:1.93998\n",
      "[38454]\teval-rmse:3.78735\ttrain-rmse:1.93998\n",
      "[38455]\teval-rmse:3.78597\ttrain-rmse:1.93997\n",
      "[38456]\teval-rmse:3.78421\ttrain-rmse:1.93994\n",
      "[38457]\teval-rmse:3.78423\ttrain-rmse:1.93994\n",
      "[38458]\teval-rmse:3.78574\ttrain-rmse:1.93997\n",
      "[38459]\teval-rmse:3.78527\ttrain-rmse:1.93996\n",
      "[38460]\teval-rmse:3.78577\ttrain-rmse:1.93997\n",
      "[38461]\teval-rmse:3.78689\ttrain-rmse:1.93999\n",
      "[38462]\teval-rmse:3.78807\ttrain-rmse:1.94002\n",
      "[38463]\teval-rmse:3.78947\ttrain-rmse:1.94004\n",
      "[38464]\teval-rmse:3.78981\ttrain-rmse:1.94006\n",
      "[38465]\teval-rmse:3.78904\ttrain-rmse:1.94003\n",
      "[38466]\teval-rmse:3.78937\ttrain-rmse:1.94004\n",
      "[38467]\teval-rmse:3.78859\ttrain-rmse:1.94002\n",
      "[38468]\teval-rmse:3.78696\ttrain-rmse:1.93998\n",
      "[38469]\teval-rmse:3.78707\ttrain-rmse:1.93998\n",
      "[38470]\teval-rmse:3.78649\ttrain-rmse:1.93997\n",
      "[38471]\teval-rmse:3.78669\ttrain-rmse:1.93998\n",
      "[38472]\teval-rmse:3.78795\ttrain-rmse:1.94001\n",
      "[38473]\teval-rmse:3.78634\ttrain-rmse:1.93997\n",
      "[38474]\teval-rmse:3.78663\ttrain-rmse:1.93997\n",
      "[38475]\teval-rmse:3.78715\ttrain-rmse:1.93999\n",
      "[38476]\teval-rmse:3.78698\ttrain-rmse:1.93997\n",
      "[38477]\teval-rmse:3.78552\ttrain-rmse:1.93993\n",
      "[38478]\teval-rmse:3.78538\ttrain-rmse:1.93991\n",
      "[38479]\teval-rmse:3.78575\ttrain-rmse:1.93992\n",
      "[38480]\teval-rmse:3.7852\ttrain-rmse:1.93991\n",
      "[38481]\teval-rmse:3.78564\ttrain-rmse:1.93992\n",
      "[38482]\teval-rmse:3.78695\ttrain-rmse:1.93995\n",
      "[38483]\teval-rmse:3.78672\ttrain-rmse:1.93994\n",
      "[38484]\teval-rmse:3.78669\ttrain-rmse:1.93994\n",
      "[38485]\teval-rmse:3.78652\ttrain-rmse:1.93992\n",
      "[38486]\teval-rmse:3.78604\ttrain-rmse:1.93991\n",
      "[38487]\teval-rmse:3.78483\ttrain-rmse:1.93988\n",
      "[38488]\teval-rmse:3.78328\ttrain-rmse:1.93985\n",
      "[38489]\teval-rmse:3.78225\ttrain-rmse:1.93986\n",
      "[38490]\teval-rmse:3.78084\ttrain-rmse:1.93984\n",
      "[38491]\teval-rmse:3.78132\ttrain-rmse:1.93985\n",
      "[38492]\teval-rmse:3.78088\ttrain-rmse:1.93985\n",
      "[38493]\teval-rmse:3.7797\ttrain-rmse:1.93985\n",
      "[38494]\teval-rmse:3.77847\ttrain-rmse:1.93985\n",
      "[38495]\teval-rmse:3.77794\ttrain-rmse:1.93986\n",
      "[38496]\teval-rmse:3.77751\ttrain-rmse:1.93986\n",
      "[38497]\teval-rmse:3.77598\ttrain-rmse:1.93988\n",
      "[38498]\teval-rmse:3.77452\ttrain-rmse:1.93992\n",
      "[38499]\teval-rmse:3.77626\ttrain-rmse:1.93988\n",
      "[38500]\teval-rmse:3.77496\ttrain-rmse:1.93989\n",
      "[38501]\teval-rmse:3.77443\ttrain-rmse:1.93991\n",
      "[38502]\teval-rmse:3.77415\ttrain-rmse:1.93991\n",
      "[38503]\teval-rmse:3.77373\ttrain-rmse:1.93993\n",
      "[38504]\teval-rmse:3.7732\ttrain-rmse:1.93993\n",
      "[38505]\teval-rmse:3.77278\ttrain-rmse:1.93995\n",
      "[38506]\teval-rmse:3.77228\ttrain-rmse:1.93996\n",
      "[38507]\teval-rmse:3.77131\ttrain-rmse:1.93998\n",
      "[38508]\teval-rmse:3.77134\ttrain-rmse:1.93998\n",
      "[38509]\teval-rmse:3.77206\ttrain-rmse:1.93996\n",
      "[38510]\teval-rmse:3.77157\ttrain-rmse:1.93998\n",
      "[38511]\teval-rmse:3.77131\ttrain-rmse:1.93998\n",
      "[38512]\teval-rmse:3.77004\ttrain-rmse:1.94001\n",
      "[38513]\teval-rmse:3.76886\ttrain-rmse:1.94004\n",
      "[38514]\teval-rmse:3.76703\ttrain-rmse:1.94014\n",
      "[38515]\teval-rmse:3.76569\ttrain-rmse:1.9402\n",
      "[38516]\teval-rmse:3.76524\ttrain-rmse:1.94022\n",
      "[38517]\teval-rmse:3.76478\ttrain-rmse:1.94024\n",
      "[38518]\teval-rmse:3.76471\ttrain-rmse:1.94024\n",
      "[38519]\teval-rmse:3.76464\ttrain-rmse:1.94025\n",
      "[38520]\teval-rmse:3.76535\ttrain-rmse:1.94021\n",
      "[38521]\teval-rmse:3.76374\ttrain-rmse:1.94032\n",
      "[38522]\teval-rmse:3.76351\ttrain-rmse:1.94033\n",
      "[38523]\teval-rmse:3.76344\ttrain-rmse:1.94033\n",
      "[38524]\teval-rmse:3.76503\ttrain-rmse:1.94025\n",
      "[38525]\teval-rmse:3.76659\ttrain-rmse:1.94019\n",
      "[38526]\teval-rmse:3.76652\ttrain-rmse:1.94019\n",
      "[38527]\teval-rmse:3.76621\ttrain-rmse:1.9402\n",
      "[38528]\teval-rmse:3.76456\ttrain-rmse:1.94031\n",
      "[38529]\teval-rmse:3.76599\ttrain-rmse:1.94024\n",
      "[38530]\teval-rmse:3.76639\ttrain-rmse:1.94022\n",
      "[38531]\teval-rmse:3.76783\ttrain-rmse:1.94016\n",
      "[38532]\teval-rmse:3.76743\ttrain-rmse:1.94017\n",
      "[38533]\teval-rmse:3.76861\ttrain-rmse:1.94013\n",
      "[38534]\teval-rmse:3.76844\ttrain-rmse:1.94014\n",
      "[38535]\teval-rmse:3.76733\ttrain-rmse:1.94018\n",
      "[38536]\teval-rmse:3.76797\ttrain-rmse:1.94015\n",
      "[38537]\teval-rmse:3.76789\ttrain-rmse:1.94015\n",
      "[38538]\teval-rmse:3.76742\ttrain-rmse:1.94017\n",
      "[38539]\teval-rmse:3.76608\ttrain-rmse:1.94026\n",
      "[38540]\teval-rmse:3.76613\ttrain-rmse:1.94025\n",
      "[38541]\teval-rmse:3.76432\ttrain-rmse:1.94037\n",
      "[38542]\teval-rmse:3.76269\ttrain-rmse:1.94049\n",
      "[38543]\teval-rmse:3.76209\ttrain-rmse:1.94054\n",
      "[38544]\teval-rmse:3.76171\ttrain-rmse:1.94056\n",
      "[38545]\teval-rmse:3.76141\ttrain-rmse:1.94058\n",
      "[38546]\teval-rmse:3.76035\ttrain-rmse:1.94068\n",
      "[38547]\teval-rmse:3.75884\ttrain-rmse:1.94082\n",
      "[38548]\teval-rmse:3.7574\ttrain-rmse:1.94091\n",
      "[38549]\teval-rmse:3.75793\ttrain-rmse:1.94086\n",
      "[38550]\teval-rmse:3.75911\ttrain-rmse:1.94074\n",
      "[38551]\teval-rmse:3.75738\ttrain-rmse:1.94092\n",
      "[38552]\teval-rmse:3.75841\ttrain-rmse:1.94082\n",
      "[38553]\teval-rmse:3.75753\ttrain-rmse:1.94087\n",
      "[38554]\teval-rmse:3.75773\ttrain-rmse:1.94085\n",
      "[38555]\teval-rmse:3.75761\ttrain-rmse:1.94085\n",
      "[38556]\teval-rmse:3.75799\ttrain-rmse:1.94081\n",
      "[38557]\teval-rmse:3.75974\ttrain-rmse:1.94071\n",
      "[38558]\teval-rmse:3.76148\ttrain-rmse:1.94062\n",
      "[38559]\teval-rmse:3.76307\ttrain-rmse:1.94052\n",
      "[38560]\teval-rmse:3.76201\ttrain-rmse:1.94058\n",
      "[38561]\teval-rmse:3.76111\ttrain-rmse:1.94063\n",
      "[38562]\teval-rmse:3.7623\ttrain-rmse:1.94052\n",
      "[38563]\teval-rmse:3.76216\ttrain-rmse:1.94053\n",
      "[38564]\teval-rmse:3.76237\ttrain-rmse:1.94051\n",
      "[38565]\teval-rmse:3.76224\ttrain-rmse:1.94051\n",
      "[38566]\teval-rmse:3.76342\ttrain-rmse:1.94042\n",
      "[38567]\teval-rmse:3.76282\ttrain-rmse:1.94047\n",
      "[38568]\teval-rmse:3.76176\ttrain-rmse:1.94052\n",
      "[38569]\teval-rmse:3.76312\ttrain-rmse:1.94041\n",
      "[38570]\teval-rmse:3.7642\ttrain-rmse:1.94034\n",
      "[38571]\teval-rmse:3.76563\ttrain-rmse:1.94025\n",
      "[38572]\teval-rmse:3.76557\ttrain-rmse:1.94023\n",
      "[38573]\teval-rmse:3.7656\ttrain-rmse:1.94022\n",
      "[38574]\teval-rmse:3.76711\ttrain-rmse:1.94016\n",
      "[38575]\teval-rmse:3.76618\ttrain-rmse:1.94019\n",
      "[38576]\teval-rmse:3.76645\ttrain-rmse:1.94018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38577]\teval-rmse:3.76796\ttrain-rmse:1.94012\n",
      "[38578]\teval-rmse:3.76801\ttrain-rmse:1.94012\n",
      "[38579]\teval-rmse:3.7669\ttrain-rmse:1.94018\n",
      "[38580]\teval-rmse:3.76528\ttrain-rmse:1.94028\n",
      "[38581]\teval-rmse:3.76417\ttrain-rmse:1.94033\n",
      "[38582]\teval-rmse:3.76469\ttrain-rmse:1.94031\n",
      "[38583]\teval-rmse:3.76644\ttrain-rmse:1.94023\n",
      "[38584]\teval-rmse:3.76811\ttrain-rmse:1.94012\n",
      "[38585]\teval-rmse:3.76771\ttrain-rmse:1.94015\n",
      "[38586]\teval-rmse:3.76763\ttrain-rmse:1.94015\n",
      "[38587]\teval-rmse:3.76646\ttrain-rmse:1.94019\n",
      "[38588]\teval-rmse:3.76721\ttrain-rmse:1.94016\n",
      "[38589]\teval-rmse:3.76745\ttrain-rmse:1.94015\n",
      "[38590]\teval-rmse:3.76684\ttrain-rmse:1.94019\n",
      "[38591]\teval-rmse:3.76501\ttrain-rmse:1.94032\n",
      "[38592]\teval-rmse:3.76619\ttrain-rmse:1.94026\n",
      "[38593]\teval-rmse:3.76604\ttrain-rmse:1.94026\n",
      "[38594]\teval-rmse:3.76596\ttrain-rmse:1.94027\n",
      "[38595]\teval-rmse:3.76737\ttrain-rmse:1.94021\n",
      "[38596]\teval-rmse:3.76721\ttrain-rmse:1.94021\n",
      "[38597]\teval-rmse:3.76755\ttrain-rmse:1.94019\n",
      "[38598]\teval-rmse:3.76627\ttrain-rmse:1.94023\n",
      "[38599]\teval-rmse:3.76786\ttrain-rmse:1.94017\n",
      "[38600]\teval-rmse:3.76636\ttrain-rmse:1.94022\n",
      "[38601]\teval-rmse:3.7681\ttrain-rmse:1.94015\n",
      "[38602]\teval-rmse:3.76846\ttrain-rmse:1.94013\n",
      "[38603]\teval-rmse:3.76691\ttrain-rmse:1.94024\n",
      "[38604]\teval-rmse:3.76834\ttrain-rmse:1.94018\n",
      "[38605]\teval-rmse:3.76958\ttrain-rmse:1.94014\n",
      "[38606]\teval-rmse:3.76841\ttrain-rmse:1.94018\n",
      "[38607]\teval-rmse:3.76729\ttrain-rmse:1.94021\n",
      "[38608]\teval-rmse:3.7678\ttrain-rmse:1.94019\n",
      "[38609]\teval-rmse:3.76733\ttrain-rmse:1.9402\n",
      "[38610]\teval-rmse:3.76616\ttrain-rmse:1.94028\n",
      "[38611]\teval-rmse:3.76555\ttrain-rmse:1.94032\n",
      "[38612]\teval-rmse:3.76559\ttrain-rmse:1.94032\n",
      "[38613]\teval-rmse:3.76564\ttrain-rmse:1.94032\n",
      "[38614]\teval-rmse:3.76438\ttrain-rmse:1.94038\n",
      "[38615]\teval-rmse:3.76315\ttrain-rmse:1.94044\n",
      "[38616]\teval-rmse:3.76302\ttrain-rmse:1.94044\n",
      "[38617]\teval-rmse:3.76476\ttrain-rmse:1.94036\n",
      "[38618]\teval-rmse:3.76611\ttrain-rmse:1.9403\n",
      "[38619]\teval-rmse:3.76769\ttrain-rmse:1.94024\n",
      "[38620]\teval-rmse:3.76676\ttrain-rmse:1.94027\n",
      "[38621]\teval-rmse:3.76587\ttrain-rmse:1.94032\n",
      "[38622]\teval-rmse:3.76557\ttrain-rmse:1.94033\n",
      "[38623]\teval-rmse:3.76614\ttrain-rmse:1.94031\n",
      "[38624]\teval-rmse:3.76748\ttrain-rmse:1.94025\n",
      "[38625]\teval-rmse:3.76699\ttrain-rmse:1.94027\n",
      "[38626]\teval-rmse:3.76858\ttrain-rmse:1.94021\n",
      "[38627]\teval-rmse:3.76891\ttrain-rmse:1.94019\n",
      "[38628]\teval-rmse:3.76875\ttrain-rmse:1.94019\n",
      "[38629]\teval-rmse:3.76924\ttrain-rmse:1.94017\n",
      "[38630]\teval-rmse:3.76945\ttrain-rmse:1.94016\n",
      "[38631]\teval-rmse:3.77104\ttrain-rmse:1.94012\n",
      "[38632]\teval-rmse:3.77087\ttrain-rmse:1.94012\n",
      "[38633]\teval-rmse:3.76943\ttrain-rmse:1.94016\n",
      "[38634]\teval-rmse:3.77007\ttrain-rmse:1.94012\n",
      "[38635]\teval-rmse:3.76889\ttrain-rmse:1.94015\n",
      "[38636]\teval-rmse:3.76879\ttrain-rmse:1.94013\n",
      "[38637]\teval-rmse:3.76912\ttrain-rmse:1.94012\n",
      "[38638]\teval-rmse:3.76795\ttrain-rmse:1.94016\n",
      "[38639]\teval-rmse:3.76733\ttrain-rmse:1.9402\n",
      "[38640]\teval-rmse:3.76772\ttrain-rmse:1.94018\n",
      "[38641]\teval-rmse:3.76663\ttrain-rmse:1.94023\n",
      "[38642]\teval-rmse:3.76632\ttrain-rmse:1.94025\n",
      "[38643]\teval-rmse:3.76697\ttrain-rmse:1.9402\n",
      "[38644]\teval-rmse:3.76604\ttrain-rmse:1.94024\n",
      "[38645]\teval-rmse:3.76471\ttrain-rmse:1.9403\n",
      "[38646]\teval-rmse:3.76448\ttrain-rmse:1.94031\n",
      "[38647]\teval-rmse:3.76424\ttrain-rmse:1.94032\n",
      "[38648]\teval-rmse:3.76427\ttrain-rmse:1.94031\n",
      "[38649]\teval-rmse:3.76419\ttrain-rmse:1.94029\n",
      "[38650]\teval-rmse:3.76562\ttrain-rmse:1.94022\n",
      "[38651]\teval-rmse:3.7643\ttrain-rmse:1.94028\n",
      "[38652]\teval-rmse:3.76504\ttrain-rmse:1.94024\n",
      "[38653]\teval-rmse:3.76631\ttrain-rmse:1.94016\n",
      "[38654]\teval-rmse:3.76582\ttrain-rmse:1.94017\n",
      "[38655]\teval-rmse:3.76718\ttrain-rmse:1.9401\n",
      "[38656]\teval-rmse:3.76734\ttrain-rmse:1.94009\n",
      "[38657]\teval-rmse:3.7671\ttrain-rmse:1.9401\n",
      "[38658]\teval-rmse:3.76663\ttrain-rmse:1.94012\n",
      "[38659]\teval-rmse:3.76698\ttrain-rmse:1.9401\n",
      "[38660]\teval-rmse:3.76605\ttrain-rmse:1.94013\n",
      "[38661]\teval-rmse:3.76641\ttrain-rmse:1.94011\n",
      "[38662]\teval-rmse:3.76712\ttrain-rmse:1.94009\n",
      "[38663]\teval-rmse:3.76696\ttrain-rmse:1.94009\n",
      "[38664]\teval-rmse:3.7655\ttrain-rmse:1.94017\n",
      "[38665]\teval-rmse:3.7667\ttrain-rmse:1.9401\n",
      "[38666]\teval-rmse:3.76708\ttrain-rmse:1.94008\n",
      "[38667]\teval-rmse:3.76677\ttrain-rmse:1.94009\n",
      "[38668]\teval-rmse:3.76701\ttrain-rmse:1.94008\n",
      "[38669]\teval-rmse:3.76859\ttrain-rmse:1.94\n",
      "[38670]\teval-rmse:3.76734\ttrain-rmse:1.94004\n",
      "[38671]\teval-rmse:3.76709\ttrain-rmse:1.94005\n",
      "[38672]\teval-rmse:3.76766\ttrain-rmse:1.94003\n",
      "[38673]\teval-rmse:3.76782\ttrain-rmse:1.94002\n",
      "[38674]\teval-rmse:3.76781\ttrain-rmse:1.94002\n",
      "[38675]\teval-rmse:3.76688\ttrain-rmse:1.94005\n",
      "[38676]\teval-rmse:3.76845\ttrain-rmse:1.94\n",
      "[38677]\teval-rmse:3.76797\ttrain-rmse:1.94002\n",
      "[38678]\teval-rmse:3.76688\ttrain-rmse:1.94005\n",
      "[38679]\teval-rmse:3.7654\ttrain-rmse:1.94011\n",
      "[38680]\teval-rmse:3.76559\ttrain-rmse:1.94009\n",
      "[38681]\teval-rmse:3.76508\ttrain-rmse:1.94012\n",
      "[38682]\teval-rmse:3.76456\ttrain-rmse:1.94015\n",
      "[38683]\teval-rmse:3.76463\ttrain-rmse:1.94015\n",
      "[38684]\teval-rmse:3.76502\ttrain-rmse:1.94012\n",
      "[38685]\teval-rmse:3.76438\ttrain-rmse:1.94016\n",
      "[38686]\teval-rmse:3.76597\ttrain-rmse:1.94009\n",
      "[38687]\teval-rmse:3.76589\ttrain-rmse:1.94007\n",
      "[38688]\teval-rmse:3.76763\ttrain-rmse:1.94\n",
      "[38689]\teval-rmse:3.76936\ttrain-rmse:1.93994\n",
      "[38690]\teval-rmse:3.76842\ttrain-rmse:1.93997\n",
      "[38691]\teval-rmse:3.77016\ttrain-rmse:1.93992\n",
      "[38692]\teval-rmse:3.77158\ttrain-rmse:1.93988\n",
      "[38693]\teval-rmse:3.773\ttrain-rmse:1.93984\n",
      "[38694]\teval-rmse:3.7729\ttrain-rmse:1.93984\n",
      "[38695]\teval-rmse:3.77238\ttrain-rmse:1.93985\n",
      "[38696]\teval-rmse:3.77344\ttrain-rmse:1.93982\n",
      "[38697]\teval-rmse:3.77333\ttrain-rmse:1.9398\n",
      "[38698]\teval-rmse:3.77236\ttrain-rmse:1.93982\n",
      "[38699]\teval-rmse:3.77267\ttrain-rmse:1.93981\n",
      "[38700]\teval-rmse:3.77124\ttrain-rmse:1.93987\n",
      "[38701]\teval-rmse:3.77113\ttrain-rmse:1.93986\n",
      "[38702]\teval-rmse:3.77246\ttrain-rmse:1.93983\n",
      "[38703]\teval-rmse:3.77386\ttrain-rmse:1.93981\n",
      "[38704]\teval-rmse:3.77374\ttrain-rmse:1.93979\n",
      "[38705]\teval-rmse:3.77401\ttrain-rmse:1.93978\n",
      "[38706]\teval-rmse:3.77233\ttrain-rmse:1.93982\n",
      "[38707]\teval-rmse:3.77214\ttrain-rmse:1.93983\n",
      "[38708]\teval-rmse:3.7708\ttrain-rmse:1.93986\n",
      "[38709]\teval-rmse:3.77183\ttrain-rmse:1.93982\n",
      "[38710]\teval-rmse:3.77149\ttrain-rmse:1.93983\n",
      "[38711]\teval-rmse:3.77131\ttrain-rmse:1.93983\n",
      "[38712]\teval-rmse:3.77264\ttrain-rmse:1.93981\n",
      "[38713]\teval-rmse:3.77311\ttrain-rmse:1.9398\n",
      "[38714]\teval-rmse:3.77348\ttrain-rmse:1.93979\n",
      "[38715]\teval-rmse:3.775\ttrain-rmse:1.93975\n",
      "[38716]\teval-rmse:3.77626\ttrain-rmse:1.93973\n",
      "[38717]\teval-rmse:3.77478\ttrain-rmse:1.93974\n",
      "[38718]\teval-rmse:3.77466\ttrain-rmse:1.93972\n",
      "[38719]\teval-rmse:3.7735\ttrain-rmse:1.93975\n",
      "[38720]\teval-rmse:3.77398\ttrain-rmse:1.93973\n",
      "[38721]\teval-rmse:3.77469\ttrain-rmse:1.93972\n",
      "[38722]\teval-rmse:3.77499\ttrain-rmse:1.93972\n",
      "[38723]\teval-rmse:3.77466\ttrain-rmse:1.93973\n",
      "[38724]\teval-rmse:3.7731\ttrain-rmse:1.93977\n",
      "[38725]\teval-rmse:3.77173\ttrain-rmse:1.93979\n",
      "[38726]\teval-rmse:3.77324\ttrain-rmse:1.93976\n",
      "[38727]\teval-rmse:3.77426\ttrain-rmse:1.93974\n",
      "[38728]\teval-rmse:3.77414\ttrain-rmse:1.93972\n",
      "[38729]\teval-rmse:3.77539\ttrain-rmse:1.93969\n",
      "[38730]\teval-rmse:3.77678\ttrain-rmse:1.93968\n",
      "[38731]\teval-rmse:3.77649\ttrain-rmse:1.93969\n",
      "[38732]\teval-rmse:3.77637\ttrain-rmse:1.93967\n",
      "[38733]\teval-rmse:3.77584\ttrain-rmse:1.93968\n",
      "[38734]\teval-rmse:3.7747\ttrain-rmse:1.93969\n",
      "[38735]\teval-rmse:3.77315\ttrain-rmse:1.9397\n",
      "[38736]\teval-rmse:3.77281\ttrain-rmse:1.93971\n",
      "[38737]\teval-rmse:3.77248\ttrain-rmse:1.93972\n",
      "[38738]\teval-rmse:3.77421\ttrain-rmse:1.93968\n",
      "[38739]\teval-rmse:3.77378\ttrain-rmse:1.93969\n",
      "[38740]\teval-rmse:3.77381\ttrain-rmse:1.93969\n",
      "[38741]\teval-rmse:3.77531\ttrain-rmse:1.93966\n",
      "[38742]\teval-rmse:3.7741\ttrain-rmse:1.93967\n",
      "[38743]\teval-rmse:3.77367\ttrain-rmse:1.93967\n",
      "[38744]\teval-rmse:3.77411\ttrain-rmse:1.93966\n",
      "[38745]\teval-rmse:3.77465\ttrain-rmse:1.93965\n",
      "[38746]\teval-rmse:3.77638\ttrain-rmse:1.93962\n",
      "[38747]\teval-rmse:3.77516\ttrain-rmse:1.93963\n",
      "[38748]\teval-rmse:3.77488\ttrain-rmse:1.93964\n",
      "[38749]\teval-rmse:3.77614\ttrain-rmse:1.93963\n",
      "[38750]\teval-rmse:3.77483\ttrain-rmse:1.93965\n",
      "[38751]\teval-rmse:3.77448\ttrain-rmse:1.93966\n",
      "[38752]\teval-rmse:3.77475\ttrain-rmse:1.93965\n",
      "[38753]\teval-rmse:3.77346\ttrain-rmse:1.93967\n",
      "[38754]\teval-rmse:3.77225\ttrain-rmse:1.9397\n",
      "[38755]\teval-rmse:3.77248\ttrain-rmse:1.93969\n",
      "[38756]\teval-rmse:3.77249\ttrain-rmse:1.93969\n",
      "[38757]\teval-rmse:3.77399\ttrain-rmse:1.93966\n",
      "[38758]\teval-rmse:3.77455\ttrain-rmse:1.93965\n",
      "[38759]\teval-rmse:3.77357\ttrain-rmse:1.93967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38760]\teval-rmse:3.77346\ttrain-rmse:1.93967\n",
      "[38761]\teval-rmse:3.77478\ttrain-rmse:1.93965\n",
      "[38762]\teval-rmse:3.77467\ttrain-rmse:1.93964\n",
      "[38763]\teval-rmse:3.77368\ttrain-rmse:1.93966\n",
      "[38764]\teval-rmse:3.77424\ttrain-rmse:1.93965\n",
      "[38765]\teval-rmse:3.77462\ttrain-rmse:1.93965\n",
      "[38766]\teval-rmse:3.77364\ttrain-rmse:1.93967\n",
      "[38767]\teval-rmse:3.77402\ttrain-rmse:1.93966\n",
      "[38768]\teval-rmse:3.77526\ttrain-rmse:1.93965\n",
      "[38769]\teval-rmse:3.77571\ttrain-rmse:1.93964\n",
      "[38770]\teval-rmse:3.77601\ttrain-rmse:1.93964\n",
      "[38771]\teval-rmse:3.7775\ttrain-rmse:1.93964\n",
      "[38772]\teval-rmse:3.77739\ttrain-rmse:1.93964\n",
      "[38773]\teval-rmse:3.77569\ttrain-rmse:1.93965\n",
      "[38774]\teval-rmse:3.77684\ttrain-rmse:1.93965\n",
      "[38775]\teval-rmse:3.77538\ttrain-rmse:1.93965\n",
      "[38776]\teval-rmse:3.77687\ttrain-rmse:1.93965\n",
      "[38777]\teval-rmse:3.77743\ttrain-rmse:1.93965\n",
      "[38778]\teval-rmse:3.7755\ttrain-rmse:1.93967\n",
      "[38779]\teval-rmse:3.77521\ttrain-rmse:1.93968\n",
      "[38780]\teval-rmse:3.77509\ttrain-rmse:1.93968\n",
      "[38781]\teval-rmse:3.77624\ttrain-rmse:1.93967\n",
      "[38782]\teval-rmse:3.7747\ttrain-rmse:1.93967\n",
      "[38783]\teval-rmse:3.77627\ttrain-rmse:1.93965\n",
      "[38784]\teval-rmse:3.77557\ttrain-rmse:1.93965\n",
      "[38785]\teval-rmse:3.77547\ttrain-rmse:1.93963\n",
      "[38786]\teval-rmse:3.77696\ttrain-rmse:1.93962\n",
      "[38787]\teval-rmse:3.77684\ttrain-rmse:1.9396\n",
      "[38788]\teval-rmse:3.77784\ttrain-rmse:1.9396\n",
      "[38789]\teval-rmse:3.77713\ttrain-rmse:1.9396\n",
      "[38790]\teval-rmse:3.77678\ttrain-rmse:1.9396\n",
      "[38791]\teval-rmse:3.77626\ttrain-rmse:1.93961\n",
      "[38792]\teval-rmse:3.7758\ttrain-rmse:1.93961\n",
      "[38793]\teval-rmse:3.77463\ttrain-rmse:1.93961\n",
      "[38794]\teval-rmse:3.7731\ttrain-rmse:1.93964\n",
      "[38795]\teval-rmse:3.77445\ttrain-rmse:1.93961\n",
      "[38796]\teval-rmse:3.77576\ttrain-rmse:1.9396\n",
      "[38797]\teval-rmse:3.7754\ttrain-rmse:1.9396\n",
      "[38798]\teval-rmse:3.77529\ttrain-rmse:1.93959\n",
      "[38799]\teval-rmse:3.77702\ttrain-rmse:1.93956\n",
      "[38800]\teval-rmse:3.77715\ttrain-rmse:1.93956\n",
      "[38801]\teval-rmse:3.77663\ttrain-rmse:1.93956\n",
      "[38802]\teval-rmse:3.77506\ttrain-rmse:1.93957\n",
      "[38803]\teval-rmse:3.77472\ttrain-rmse:1.93957\n",
      "[38804]\teval-rmse:3.77613\ttrain-rmse:1.93956\n",
      "[38805]\teval-rmse:3.77601\ttrain-rmse:1.93956\n",
      "[38806]\teval-rmse:3.77774\ttrain-rmse:1.93954\n",
      "[38807]\teval-rmse:3.7764\ttrain-rmse:1.93954\n",
      "[38808]\teval-rmse:3.77661\ttrain-rmse:1.93954\n",
      "[38809]\teval-rmse:3.77777\ttrain-rmse:1.93954\n",
      "[38810]\teval-rmse:3.77915\ttrain-rmse:1.93955\n",
      "[38811]\teval-rmse:3.77789\ttrain-rmse:1.93954\n",
      "[38812]\teval-rmse:3.77632\ttrain-rmse:1.93954\n",
      "[38813]\teval-rmse:3.77466\ttrain-rmse:1.93956\n",
      "[38814]\teval-rmse:3.77605\ttrain-rmse:1.93955\n",
      "[38815]\teval-rmse:3.77737\ttrain-rmse:1.93954\n",
      "[38816]\teval-rmse:3.77717\ttrain-rmse:1.93955\n",
      "[38817]\teval-rmse:3.77764\ttrain-rmse:1.93955\n",
      "[38818]\teval-rmse:3.77648\ttrain-rmse:1.93954\n",
      "[38819]\teval-rmse:3.77744\ttrain-rmse:1.93954\n",
      "[38820]\teval-rmse:3.77847\ttrain-rmse:1.93955\n",
      "[38821]\teval-rmse:3.77731\ttrain-rmse:1.93954\n",
      "[38822]\teval-rmse:3.77718\ttrain-rmse:1.93955\n",
      "[38823]\teval-rmse:3.77852\ttrain-rmse:1.93955\n",
      "[38824]\teval-rmse:3.77885\ttrain-rmse:1.93955\n",
      "[38825]\teval-rmse:3.78025\ttrain-rmse:1.93956\n",
      "[38826]\teval-rmse:3.7806\ttrain-rmse:1.93956\n",
      "[38827]\teval-rmse:3.77941\ttrain-rmse:1.93955\n",
      "[38828]\teval-rmse:3.77768\ttrain-rmse:1.93955\n",
      "[38829]\teval-rmse:3.77598\ttrain-rmse:1.93955\n",
      "[38830]\teval-rmse:3.77651\ttrain-rmse:1.93955\n",
      "[38831]\teval-rmse:3.77699\ttrain-rmse:1.93955\n",
      "[38832]\teval-rmse:3.77754\ttrain-rmse:1.93955\n",
      "[38833]\teval-rmse:3.7787\ttrain-rmse:1.93955\n",
      "[38834]\teval-rmse:3.77902\ttrain-rmse:1.93955\n",
      "[38835]\teval-rmse:3.77882\ttrain-rmse:1.93955\n",
      "[38836]\teval-rmse:3.77882\ttrain-rmse:1.93955\n",
      "[38837]\teval-rmse:3.7775\ttrain-rmse:1.93955\n",
      "[38838]\teval-rmse:3.77602\ttrain-rmse:1.93956\n",
      "[38839]\teval-rmse:3.7755\ttrain-rmse:1.93956\n",
      "[38840]\teval-rmse:3.77485\ttrain-rmse:1.93957\n",
      "[38841]\teval-rmse:3.77354\ttrain-rmse:1.9396\n",
      "[38842]\teval-rmse:3.77257\ttrain-rmse:1.93962\n",
      "[38843]\teval-rmse:3.7723\ttrain-rmse:1.93963\n",
      "[38844]\teval-rmse:3.77102\ttrain-rmse:1.93965\n",
      "[38845]\teval-rmse:3.77006\ttrain-rmse:1.93968\n",
      "[38846]\teval-rmse:3.76887\ttrain-rmse:1.93972\n",
      "[38847]\teval-rmse:3.77043\ttrain-rmse:1.93968\n",
      "[38848]\teval-rmse:3.77062\ttrain-rmse:1.93968\n",
      "[38849]\teval-rmse:3.77217\ttrain-rmse:1.93965\n",
      "[38850]\teval-rmse:3.77207\ttrain-rmse:1.93965\n",
      "[38851]\teval-rmse:3.77355\ttrain-rmse:1.93964\n",
      "[38852]\teval-rmse:3.77241\ttrain-rmse:1.93965\n",
      "[38853]\teval-rmse:3.77255\ttrain-rmse:1.93965\n",
      "[38854]\teval-rmse:3.77133\ttrain-rmse:1.93966\n",
      "[38855]\teval-rmse:3.7717\ttrain-rmse:1.93965\n",
      "[38856]\teval-rmse:3.77318\ttrain-rmse:1.93964\n",
      "[38857]\teval-rmse:3.77373\ttrain-rmse:1.93963\n",
      "[38858]\teval-rmse:3.77524\ttrain-rmse:1.93962\n",
      "[38859]\teval-rmse:3.77545\ttrain-rmse:1.93962\n",
      "[38860]\teval-rmse:3.77577\ttrain-rmse:1.93962\n",
      "[38861]\teval-rmse:3.77715\ttrain-rmse:1.93962\n",
      "[38862]\teval-rmse:3.77558\ttrain-rmse:1.93962\n",
      "[38863]\teval-rmse:3.77707\ttrain-rmse:1.9396\n",
      "[38864]\teval-rmse:3.77565\ttrain-rmse:1.9396\n",
      "[38865]\teval-rmse:3.77722\ttrain-rmse:1.9396\n",
      "[38866]\teval-rmse:3.77652\ttrain-rmse:1.9396\n",
      "[38867]\teval-rmse:3.77632\ttrain-rmse:1.9396\n",
      "[38868]\teval-rmse:3.77678\ttrain-rmse:1.9396\n",
      "[38869]\teval-rmse:3.77489\ttrain-rmse:1.93961\n",
      "[38870]\teval-rmse:3.77624\ttrain-rmse:1.93961\n",
      "[38871]\teval-rmse:3.77604\ttrain-rmse:1.93961\n",
      "[38872]\teval-rmse:3.77432\ttrain-rmse:1.93962\n",
      "[38873]\teval-rmse:3.77366\ttrain-rmse:1.93963\n",
      "[38874]\teval-rmse:3.77357\ttrain-rmse:1.93963\n",
      "[38875]\teval-rmse:3.77291\ttrain-rmse:1.93964\n",
      "[38876]\teval-rmse:3.77168\ttrain-rmse:1.93965\n",
      "[38877]\teval-rmse:3.77061\ttrain-rmse:1.93968\n",
      "[38878]\teval-rmse:3.77012\ttrain-rmse:1.93969\n",
      "[38879]\teval-rmse:3.76995\ttrain-rmse:1.93969\n",
      "[38880]\teval-rmse:3.77119\ttrain-rmse:1.93966\n",
      "[38881]\teval-rmse:3.77172\ttrain-rmse:1.93965\n",
      "[38882]\teval-rmse:3.77305\ttrain-rmse:1.93963\n",
      "[38883]\teval-rmse:3.77161\ttrain-rmse:1.93966\n",
      "[38884]\teval-rmse:3.77195\ttrain-rmse:1.93966\n",
      "[38885]\teval-rmse:3.77067\ttrain-rmse:1.93969\n",
      "[38886]\teval-rmse:3.77107\ttrain-rmse:1.93968\n",
      "[38887]\teval-rmse:3.77074\ttrain-rmse:1.93969\n",
      "[38888]\teval-rmse:3.76946\ttrain-rmse:1.93973\n",
      "[38889]\teval-rmse:3.7708\ttrain-rmse:1.9397\n",
      "[38890]\teval-rmse:3.77253\ttrain-rmse:1.93966\n",
      "[38891]\teval-rmse:3.77108\ttrain-rmse:1.93968\n",
      "[38892]\teval-rmse:3.76973\ttrain-rmse:1.93971\n",
      "[38893]\teval-rmse:3.77106\ttrain-rmse:1.93966\n",
      "[38894]\teval-rmse:3.77009\ttrain-rmse:1.93969\n",
      "[38895]\teval-rmse:3.77058\ttrain-rmse:1.93968\n",
      "[38896]\teval-rmse:3.77129\ttrain-rmse:1.93966\n",
      "[38897]\teval-rmse:3.77119\ttrain-rmse:1.93965\n",
      "[38898]\teval-rmse:3.77159\ttrain-rmse:1.93964\n",
      "[38899]\teval-rmse:3.77149\ttrain-rmse:1.93962\n",
      "[38900]\teval-rmse:3.7714\ttrain-rmse:1.93961\n",
      "[38901]\teval-rmse:3.7713\ttrain-rmse:1.93961\n",
      "[38902]\teval-rmse:3.77271\ttrain-rmse:1.93959\n",
      "[38903]\teval-rmse:3.77374\ttrain-rmse:1.93957\n",
      "[38904]\teval-rmse:3.77506\ttrain-rmse:1.93955\n",
      "[38905]\teval-rmse:3.7736\ttrain-rmse:1.93957\n",
      "[38906]\teval-rmse:3.77473\ttrain-rmse:1.93956\n",
      "[38907]\teval-rmse:3.77505\ttrain-rmse:1.93955\n",
      "[38908]\teval-rmse:3.7766\ttrain-rmse:1.93955\n",
      "[38909]\teval-rmse:3.77561\ttrain-rmse:1.93957\n",
      "[38910]\teval-rmse:3.77708\ttrain-rmse:1.93957\n",
      "[38911]\teval-rmse:3.77575\ttrain-rmse:1.93959\n",
      "[38912]\teval-rmse:3.77508\ttrain-rmse:1.93959\n",
      "[38913]\teval-rmse:3.77384\ttrain-rmse:1.93961\n",
      "[38914]\teval-rmse:3.77557\ttrain-rmse:1.93957\n",
      "[38915]\teval-rmse:3.77592\ttrain-rmse:1.93957\n",
      "[38916]\teval-rmse:3.77731\ttrain-rmse:1.93957\n",
      "[38917]\teval-rmse:3.77685\ttrain-rmse:1.93957\n",
      "[38918]\teval-rmse:3.77563\ttrain-rmse:1.93957\n",
      "[38919]\teval-rmse:3.77423\ttrain-rmse:1.93958\n",
      "[38920]\teval-rmse:3.7738\ttrain-rmse:1.93958\n",
      "[38921]\teval-rmse:3.77371\ttrain-rmse:1.93958\n",
      "[38922]\teval-rmse:3.77396\ttrain-rmse:1.93958\n",
      "[38923]\teval-rmse:3.7751\ttrain-rmse:1.93956\n",
      "[38924]\teval-rmse:3.77396\ttrain-rmse:1.93959\n",
      "[38925]\teval-rmse:3.77328\ttrain-rmse:1.93959\n",
      "[38926]\teval-rmse:3.77301\ttrain-rmse:1.9396\n",
      "[38927]\teval-rmse:3.77331\ttrain-rmse:1.93959\n",
      "[38928]\teval-rmse:3.77216\ttrain-rmse:1.93961\n",
      "[38929]\teval-rmse:3.77285\ttrain-rmse:1.9396\n",
      "[38930]\teval-rmse:3.77433\ttrain-rmse:1.93958\n",
      "[38931]\teval-rmse:3.77335\ttrain-rmse:1.9396\n",
      "[38932]\teval-rmse:3.77172\ttrain-rmse:1.93963\n",
      "[38933]\teval-rmse:3.77076\ttrain-rmse:1.93966\n",
      "[38934]\teval-rmse:3.77066\ttrain-rmse:1.93966\n",
      "[38935]\teval-rmse:3.77137\ttrain-rmse:1.93965\n",
      "[38936]\teval-rmse:3.76999\ttrain-rmse:1.93967\n",
      "[38937]\teval-rmse:3.76982\ttrain-rmse:1.93968\n",
      "[38938]\teval-rmse:3.76973\ttrain-rmse:1.93968\n",
      "[38939]\teval-rmse:3.76878\ttrain-rmse:1.93971\n",
      "[38940]\teval-rmse:3.76853\ttrain-rmse:1.93972\n",
      "[38941]\teval-rmse:3.76846\ttrain-rmse:1.9397\n",
      "[38942]\teval-rmse:3.76829\ttrain-rmse:1.93971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38943]\teval-rmse:3.76725\ttrain-rmse:1.93975\n",
      "[38944]\teval-rmse:3.76898\ttrain-rmse:1.93969\n",
      "[38945]\teval-rmse:3.76771\ttrain-rmse:1.93973\n",
      "[38946]\teval-rmse:3.76762\ttrain-rmse:1.93972\n",
      "[38947]\teval-rmse:3.76799\ttrain-rmse:1.9397\n",
      "[38948]\teval-rmse:3.76801\ttrain-rmse:1.9397\n",
      "[38949]\teval-rmse:3.76786\ttrain-rmse:1.93971\n",
      "[38950]\teval-rmse:3.76904\ttrain-rmse:1.93967\n",
      "[38951]\teval-rmse:3.7703\ttrain-rmse:1.93964\n",
      "[38952]\teval-rmse:3.76989\ttrain-rmse:1.93965\n",
      "[38953]\teval-rmse:3.77144\ttrain-rmse:1.93962\n",
      "[38954]\teval-rmse:3.77191\ttrain-rmse:1.93962\n",
      "[38955]\teval-rmse:3.77062\ttrain-rmse:1.93963\n",
      "[38956]\teval-rmse:3.77053\ttrain-rmse:1.93963\n",
      "[38957]\teval-rmse:3.76957\ttrain-rmse:1.93966\n",
      "[38958]\teval-rmse:3.76815\ttrain-rmse:1.9397\n",
      "[38959]\teval-rmse:3.76853\ttrain-rmse:1.93969\n",
      "[38960]\teval-rmse:3.76901\ttrain-rmse:1.93968\n",
      "[38961]\teval-rmse:3.7693\ttrain-rmse:1.93967\n",
      "[38962]\teval-rmse:3.76877\ttrain-rmse:1.93968\n",
      "[38963]\teval-rmse:3.76878\ttrain-rmse:1.93968\n",
      "[38964]\teval-rmse:3.76916\ttrain-rmse:1.93967\n",
      "[38965]\teval-rmse:3.76776\ttrain-rmse:1.93971\n",
      "[38966]\teval-rmse:3.76634\ttrain-rmse:1.93975\n",
      "[38967]\teval-rmse:3.7668\ttrain-rmse:1.93974\n",
      "[38968]\teval-rmse:3.76734\ttrain-rmse:1.93972\n",
      "[38969]\teval-rmse:3.76736\ttrain-rmse:1.93972\n",
      "[38970]\teval-rmse:3.7661\ttrain-rmse:1.93976\n",
      "[38971]\teval-rmse:3.76652\ttrain-rmse:1.93974\n",
      "[38972]\teval-rmse:3.76644\ttrain-rmse:1.93975\n",
      "[38973]\teval-rmse:3.76528\ttrain-rmse:1.93978\n",
      "[38974]\teval-rmse:3.76559\ttrain-rmse:1.93977\n",
      "[38975]\teval-rmse:3.76535\ttrain-rmse:1.93978\n",
      "[38976]\teval-rmse:3.76511\ttrain-rmse:1.93979\n",
      "[38977]\teval-rmse:3.76419\ttrain-rmse:1.93983\n",
      "[38978]\teval-rmse:3.76327\ttrain-rmse:1.93988\n",
      "[38979]\teval-rmse:3.76373\ttrain-rmse:1.93986\n",
      "[38980]\teval-rmse:3.76327\ttrain-rmse:1.93988\n",
      "[38981]\teval-rmse:3.76177\ttrain-rmse:1.93994\n",
      "[38982]\teval-rmse:3.76029\ttrain-rmse:1.94003\n",
      "[38983]\teval-rmse:3.76008\ttrain-rmse:1.94004\n",
      "[38984]\teval-rmse:3.76081\ttrain-rmse:1.94\n",
      "[38985]\teval-rmse:3.76222\ttrain-rmse:1.93994\n",
      "[38986]\teval-rmse:3.76396\ttrain-rmse:1.93986\n",
      "[38987]\teval-rmse:3.7626\ttrain-rmse:1.93992\n",
      "[38988]\teval-rmse:3.76288\ttrain-rmse:1.93991\n",
      "[38989]\teval-rmse:3.76255\ttrain-rmse:1.93992\n",
      "[38990]\teval-rmse:3.76293\ttrain-rmse:1.9399\n",
      "[38991]\teval-rmse:3.76245\ttrain-rmse:1.93992\n",
      "[38992]\teval-rmse:3.76239\ttrain-rmse:1.93992\n",
      "[38993]\teval-rmse:3.76312\ttrain-rmse:1.93989\n",
      "[38994]\teval-rmse:3.7647\ttrain-rmse:1.93982\n",
      "[38995]\teval-rmse:3.7662\ttrain-rmse:1.93975\n",
      "[38996]\teval-rmse:3.76502\ttrain-rmse:1.93979\n",
      "[38997]\teval-rmse:3.76628\ttrain-rmse:1.93975\n",
      "[38998]\teval-rmse:3.76619\ttrain-rmse:1.93975\n",
      "[38999]\teval-rmse:3.7665\ttrain-rmse:1.93974\n",
      "[39000]\teval-rmse:3.76515\ttrain-rmse:1.93978\n",
      "[39001]\teval-rmse:3.76673\ttrain-rmse:1.93971\n",
      "[39002]\teval-rmse:3.76526\ttrain-rmse:1.93978\n",
      "[39003]\teval-rmse:3.7656\ttrain-rmse:1.93976\n",
      "[39004]\teval-rmse:3.76421\ttrain-rmse:1.93983\n",
      "[39005]\teval-rmse:3.76356\ttrain-rmse:1.93986\n",
      "[39006]\teval-rmse:3.76223\ttrain-rmse:1.93992\n",
      "[39007]\teval-rmse:3.76098\ttrain-rmse:1.93998\n",
      "[39008]\teval-rmse:3.76058\ttrain-rmse:1.94\n",
      "[39009]\teval-rmse:3.762\ttrain-rmse:1.93992\n",
      "[39010]\teval-rmse:3.76194\ttrain-rmse:1.93992\n",
      "[39011]\teval-rmse:3.76062\ttrain-rmse:1.93999\n",
      "[39012]\teval-rmse:3.75962\ttrain-rmse:1.94006\n",
      "[39013]\teval-rmse:3.75949\ttrain-rmse:1.94006\n",
      "[39014]\teval-rmse:3.75969\ttrain-rmse:1.94005\n",
      "[39015]\teval-rmse:3.75908\ttrain-rmse:1.94009\n",
      "[39016]\teval-rmse:3.75872\ttrain-rmse:1.94011\n",
      "[39017]\teval-rmse:3.75729\ttrain-rmse:1.9402\n",
      "[39018]\teval-rmse:3.75772\ttrain-rmse:1.94017\n",
      "[39019]\teval-rmse:3.75744\ttrain-rmse:1.94019\n",
      "[39020]\teval-rmse:3.75887\ttrain-rmse:1.9401\n",
      "[39021]\teval-rmse:3.75743\ttrain-rmse:1.9402\n",
      "[39022]\teval-rmse:3.75917\ttrain-rmse:1.9401\n",
      "[39023]\teval-rmse:3.75912\ttrain-rmse:1.9401\n",
      "[39024]\teval-rmse:3.75823\ttrain-rmse:1.94015\n",
      "[39025]\teval-rmse:3.75712\ttrain-rmse:1.94023\n",
      "[39026]\teval-rmse:3.75625\ttrain-rmse:1.94028\n",
      "[39027]\teval-rmse:3.75741\ttrain-rmse:1.94019\n",
      "[39028]\teval-rmse:3.759\ttrain-rmse:1.94007\n",
      "[39029]\teval-rmse:3.75779\ttrain-rmse:1.94015\n",
      "[39030]\teval-rmse:3.75635\ttrain-rmse:1.94024\n",
      "[39031]\teval-rmse:3.75768\ttrain-rmse:1.94016\n",
      "[39032]\teval-rmse:3.75807\ttrain-rmse:1.94013\n",
      "[39033]\teval-rmse:3.7592\ttrain-rmse:1.94006\n",
      "[39034]\teval-rmse:3.75876\ttrain-rmse:1.94009\n",
      "[39035]\teval-rmse:3.75814\ttrain-rmse:1.94013\n",
      "[39036]\teval-rmse:3.7584\ttrain-rmse:1.94011\n",
      "[39037]\teval-rmse:3.7585\ttrain-rmse:1.9401\n",
      "[39038]\teval-rmse:3.76024\ttrain-rmse:1.94\n",
      "[39039]\teval-rmse:3.76073\ttrain-rmse:1.93997\n",
      "[39040]\teval-rmse:3.76113\ttrain-rmse:1.93995\n",
      "[39041]\teval-rmse:3.75991\ttrain-rmse:1.94002\n",
      "[39042]\teval-rmse:3.75853\ttrain-rmse:1.94012\n",
      "[39043]\teval-rmse:3.76001\ttrain-rmse:1.94003\n",
      "[39044]\teval-rmse:3.76159\ttrain-rmse:1.93995\n",
      "[39045]\teval-rmse:3.76275\ttrain-rmse:1.93989\n",
      "[39046]\teval-rmse:3.7611\ttrain-rmse:1.93999\n",
      "[39047]\teval-rmse:3.76212\ttrain-rmse:1.93993\n",
      "[39048]\teval-rmse:3.76243\ttrain-rmse:1.93991\n",
      "[39049]\teval-rmse:3.76375\ttrain-rmse:1.93984\n",
      "[39050]\teval-rmse:3.76501\ttrain-rmse:1.93979\n",
      "[39051]\teval-rmse:3.76556\ttrain-rmse:1.93977\n",
      "[39052]\teval-rmse:3.76514\ttrain-rmse:1.93979\n",
      "[39053]\teval-rmse:3.76422\ttrain-rmse:1.93983\n",
      "[39054]\teval-rmse:3.7628\ttrain-rmse:1.9399\n",
      "[39055]\teval-rmse:3.76422\ttrain-rmse:1.93984\n",
      "[39056]\teval-rmse:3.76375\ttrain-rmse:1.93986\n",
      "[39057]\teval-rmse:3.7626\ttrain-rmse:1.93992\n",
      "[39058]\teval-rmse:3.76333\ttrain-rmse:1.93989\n",
      "[39059]\teval-rmse:3.76285\ttrain-rmse:1.93991\n",
      "[39060]\teval-rmse:3.7642\ttrain-rmse:1.93984\n",
      "[39061]\teval-rmse:3.76381\ttrain-rmse:1.93986\n",
      "[39062]\teval-rmse:3.76482\ttrain-rmse:1.93981\n",
      "[39063]\teval-rmse:3.76357\ttrain-rmse:1.93987\n",
      "[39064]\teval-rmse:3.7641\ttrain-rmse:1.93985\n",
      "[39065]\teval-rmse:3.76443\ttrain-rmse:1.93984\n",
      "[39066]\teval-rmse:3.76585\ttrain-rmse:1.93979\n",
      "[39067]\teval-rmse:3.7657\ttrain-rmse:1.9398\n",
      "[39068]\teval-rmse:3.76546\ttrain-rmse:1.93981\n",
      "[39069]\teval-rmse:3.76499\ttrain-rmse:1.93982\n",
      "[39070]\teval-rmse:3.76383\ttrain-rmse:1.93988\n",
      "[39071]\teval-rmse:3.76291\ttrain-rmse:1.93992\n",
      "[39072]\teval-rmse:3.762\ttrain-rmse:1.93996\n",
      "[39073]\teval-rmse:3.76217\ttrain-rmse:1.93996\n",
      "[39074]\teval-rmse:3.761\ttrain-rmse:1.94\n",
      "[39075]\teval-rmse:3.76055\ttrain-rmse:1.94003\n",
      "[39076]\teval-rmse:3.75893\ttrain-rmse:1.94012\n",
      "[39077]\teval-rmse:3.75765\ttrain-rmse:1.94019\n",
      "[39078]\teval-rmse:3.75745\ttrain-rmse:1.9402\n",
      "[39079]\teval-rmse:3.75598\ttrain-rmse:1.94029\n",
      "[39080]\teval-rmse:3.7546\ttrain-rmse:1.9404\n",
      "[39081]\teval-rmse:3.75327\ttrain-rmse:1.9405\n",
      "[39082]\teval-rmse:3.75327\ttrain-rmse:1.9405\n",
      "[39083]\teval-rmse:3.75309\ttrain-rmse:1.94051\n",
      "[39084]\teval-rmse:3.75467\ttrain-rmse:1.94039\n",
      "[39085]\teval-rmse:3.75509\ttrain-rmse:1.94036\n",
      "[39086]\teval-rmse:3.75648\ttrain-rmse:1.94027\n",
      "[39087]\teval-rmse:3.75603\ttrain-rmse:1.9403\n",
      "[39088]\teval-rmse:3.75726\ttrain-rmse:1.94022\n",
      "[39089]\teval-rmse:3.75737\ttrain-rmse:1.94022\n",
      "[39090]\teval-rmse:3.75649\ttrain-rmse:1.94027\n",
      "[39091]\teval-rmse:3.75538\ttrain-rmse:1.94034\n",
      "[39092]\teval-rmse:3.75549\ttrain-rmse:1.94033\n",
      "[39093]\teval-rmse:3.75662\ttrain-rmse:1.94026\n",
      "[39094]\teval-rmse:3.75534\ttrain-rmse:1.94034\n",
      "[39095]\teval-rmse:3.75707\ttrain-rmse:1.94022\n",
      "[39096]\teval-rmse:3.75749\ttrain-rmse:1.9402\n",
      "[39097]\teval-rmse:3.75821\ttrain-rmse:1.94016\n",
      "[39098]\teval-rmse:3.7596\ttrain-rmse:1.94008\n",
      "[39099]\teval-rmse:3.75987\ttrain-rmse:1.94007\n",
      "[39100]\teval-rmse:3.75825\ttrain-rmse:1.94017\n",
      "[39101]\teval-rmse:3.75851\ttrain-rmse:1.94015\n",
      "[39102]\teval-rmse:3.75967\ttrain-rmse:1.94009\n",
      "[39103]\teval-rmse:3.76006\ttrain-rmse:1.94007\n",
      "[39104]\teval-rmse:3.75993\ttrain-rmse:1.94008\n",
      "[39105]\teval-rmse:3.75888\ttrain-rmse:1.94014\n",
      "[39106]\teval-rmse:3.75768\ttrain-rmse:1.94022\n",
      "[39107]\teval-rmse:3.75807\ttrain-rmse:1.9402\n",
      "[39108]\teval-rmse:3.75965\ttrain-rmse:1.94011\n",
      "[39109]\teval-rmse:3.76039\ttrain-rmse:1.94008\n",
      "[39110]\teval-rmse:3.76093\ttrain-rmse:1.94005\n",
      "[39111]\teval-rmse:3.76216\ttrain-rmse:1.93999\n",
      "[39112]\teval-rmse:3.76163\ttrain-rmse:1.94002\n",
      "[39113]\teval-rmse:3.76164\ttrain-rmse:1.94002\n",
      "[39114]\teval-rmse:3.76306\ttrain-rmse:1.93994\n",
      "[39115]\teval-rmse:3.76267\ttrain-rmse:1.93996\n",
      "[39116]\teval-rmse:3.76144\ttrain-rmse:1.94002\n",
      "[39117]\teval-rmse:3.76199\ttrain-rmse:1.94\n",
      "[39118]\teval-rmse:3.76051\ttrain-rmse:1.94008\n",
      "[39119]\teval-rmse:3.75946\ttrain-rmse:1.94014\n",
      "[39120]\teval-rmse:3.75802\ttrain-rmse:1.94024\n",
      "[39121]\teval-rmse:3.75812\ttrain-rmse:1.94023\n",
      "[39122]\teval-rmse:3.75793\ttrain-rmse:1.94024\n",
      "[39123]\teval-rmse:3.75849\ttrain-rmse:1.94021\n",
      "[39124]\teval-rmse:3.75812\ttrain-rmse:1.94023\n",
      "[39125]\teval-rmse:3.75821\ttrain-rmse:1.94022\n",
      "[39126]\teval-rmse:3.75639\ttrain-rmse:1.94035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39127]\teval-rmse:3.75797\ttrain-rmse:1.94023\n",
      "[39128]\teval-rmse:3.75837\ttrain-rmse:1.94021\n",
      "[39129]\teval-rmse:3.76011\ttrain-rmse:1.94011\n",
      "[39130]\teval-rmse:3.76153\ttrain-rmse:1.94004\n",
      "[39131]\teval-rmse:3.76124\ttrain-rmse:1.94006\n",
      "[39132]\teval-rmse:3.76102\ttrain-rmse:1.94007\n",
      "[39133]\teval-rmse:3.76012\ttrain-rmse:1.94012\n",
      "[39134]\teval-rmse:3.76086\ttrain-rmse:1.94007\n",
      "[39135]\teval-rmse:3.7614\ttrain-rmse:1.94005\n",
      "[39136]\teval-rmse:3.75996\ttrain-rmse:1.94011\n",
      "[39137]\teval-rmse:3.75842\ttrain-rmse:1.94021\n",
      "[39138]\teval-rmse:3.75871\ttrain-rmse:1.94019\n",
      "[39139]\teval-rmse:3.75894\ttrain-rmse:1.94018\n",
      "[39140]\teval-rmse:3.75782\ttrain-rmse:1.94026\n",
      "[39141]\teval-rmse:3.75771\ttrain-rmse:1.94027\n",
      "[39142]\teval-rmse:3.75803\ttrain-rmse:1.94025\n",
      "[39143]\teval-rmse:3.75775\ttrain-rmse:1.94026\n",
      "[39144]\teval-rmse:3.75671\ttrain-rmse:1.94033\n",
      "[39145]\teval-rmse:3.75791\ttrain-rmse:1.94024\n",
      "[39146]\teval-rmse:3.7572\ttrain-rmse:1.9403\n",
      "[39147]\teval-rmse:3.75768\ttrain-rmse:1.94026\n",
      "[39148]\teval-rmse:3.75778\ttrain-rmse:1.94025\n",
      "[39149]\teval-rmse:3.75758\ttrain-rmse:1.94027\n",
      "[39150]\teval-rmse:3.75892\ttrain-rmse:1.94018\n",
      "[39151]\teval-rmse:3.75943\ttrain-rmse:1.94015\n",
      "[39152]\teval-rmse:3.76101\ttrain-rmse:1.94007\n",
      "[39153]\teval-rmse:3.76011\ttrain-rmse:1.94012\n",
      "[39154]\teval-rmse:3.7606\ttrain-rmse:1.94009\n",
      "[39155]\teval-rmse:3.76176\ttrain-rmse:1.94005\n",
      "[39156]\teval-rmse:3.76162\ttrain-rmse:1.94005\n",
      "[39157]\teval-rmse:3.76278\ttrain-rmse:1.94001\n",
      "[39158]\teval-rmse:3.76436\ttrain-rmse:1.93995\n",
      "[39159]\teval-rmse:3.76431\ttrain-rmse:1.93993\n",
      "[39160]\teval-rmse:3.76503\ttrain-rmse:1.93991\n",
      "[39161]\teval-rmse:3.76524\ttrain-rmse:1.9399\n",
      "[39162]\teval-rmse:3.76657\ttrain-rmse:1.93987\n",
      "[39163]\teval-rmse:3.76609\ttrain-rmse:1.93989\n",
      "[39164]\teval-rmse:3.7665\ttrain-rmse:1.93988\n",
      "[39165]\teval-rmse:3.7661\ttrain-rmse:1.93988\n",
      "[39166]\teval-rmse:3.76646\ttrain-rmse:1.93988\n",
      "[39167]\teval-rmse:3.76643\ttrain-rmse:1.93988\n",
      "[39168]\teval-rmse:3.76661\ttrain-rmse:1.93987\n",
      "[39169]\teval-rmse:3.76835\ttrain-rmse:1.93981\n",
      "[39170]\teval-rmse:3.76818\ttrain-rmse:1.93981\n",
      "[39171]\teval-rmse:3.76755\ttrain-rmse:1.93983\n",
      "[39172]\teval-rmse:3.76788\ttrain-rmse:1.93982\n",
      "[39173]\teval-rmse:3.76778\ttrain-rmse:1.93982\n",
      "[39174]\teval-rmse:3.76822\ttrain-rmse:1.93982\n",
      "[39175]\teval-rmse:3.76945\ttrain-rmse:1.93979\n",
      "[39176]\teval-rmse:3.76961\ttrain-rmse:1.93979\n",
      "[39177]\teval-rmse:3.76811\ttrain-rmse:1.93982\n",
      "[39178]\teval-rmse:3.76779\ttrain-rmse:1.93983\n",
      "[39179]\teval-rmse:3.76634\ttrain-rmse:1.93986\n",
      "[39180]\teval-rmse:3.76759\ttrain-rmse:1.93983\n",
      "[39181]\teval-rmse:3.76878\ttrain-rmse:1.9398\n",
      "[39182]\teval-rmse:3.76728\ttrain-rmse:1.93984\n",
      "[39183]\teval-rmse:3.76689\ttrain-rmse:1.93985\n",
      "[39184]\teval-rmse:3.76839\ttrain-rmse:1.93982\n",
      "[39185]\teval-rmse:3.76693\ttrain-rmse:1.93985\n",
      "[39186]\teval-rmse:3.76715\ttrain-rmse:1.93985\n",
      "[39187]\teval-rmse:3.76718\ttrain-rmse:1.93984\n",
      "[39188]\teval-rmse:3.7667\ttrain-rmse:1.93985\n",
      "[39189]\teval-rmse:3.76791\ttrain-rmse:1.93983\n",
      "[39190]\teval-rmse:3.76665\ttrain-rmse:1.93988\n",
      "[39191]\teval-rmse:3.76555\ttrain-rmse:1.9399\n",
      "[39192]\teval-rmse:3.7669\ttrain-rmse:1.93986\n",
      "[39193]\teval-rmse:3.76704\ttrain-rmse:1.93985\n",
      "[39194]\teval-rmse:3.76835\ttrain-rmse:1.93983\n",
      "[39195]\teval-rmse:3.76826\ttrain-rmse:1.93983\n",
      "[39196]\teval-rmse:3.76705\ttrain-rmse:1.93985\n",
      "[39197]\teval-rmse:3.76652\ttrain-rmse:1.93987\n",
      "[39198]\teval-rmse:3.76604\ttrain-rmse:1.93988\n",
      "[39199]\teval-rmse:3.76742\ttrain-rmse:1.93985\n",
      "[39200]\teval-rmse:3.76856\ttrain-rmse:1.93983\n",
      "[39201]\teval-rmse:3.76938\ttrain-rmse:1.93981\n",
      "[39202]\teval-rmse:3.76787\ttrain-rmse:1.93983\n",
      "[39203]\teval-rmse:3.76666\ttrain-rmse:1.93986\n",
      "[39204]\teval-rmse:3.76514\ttrain-rmse:1.93989\n",
      "[39205]\teval-rmse:3.76661\ttrain-rmse:1.93985\n",
      "[39206]\teval-rmse:3.76567\ttrain-rmse:1.93989\n",
      "[39207]\teval-rmse:3.7652\ttrain-rmse:1.9399\n",
      "[39208]\teval-rmse:3.76505\ttrain-rmse:1.9399\n",
      "[39209]\teval-rmse:3.76542\ttrain-rmse:1.93989\n",
      "[39210]\teval-rmse:3.76536\ttrain-rmse:1.93988\n",
      "[39211]\teval-rmse:3.76608\ttrain-rmse:1.93986\n",
      "[39212]\teval-rmse:3.76758\ttrain-rmse:1.93983\n",
      "[39213]\teval-rmse:3.76695\ttrain-rmse:1.93985\n",
      "[39214]\teval-rmse:3.76817\ttrain-rmse:1.93983\n",
      "[39215]\teval-rmse:3.76837\ttrain-rmse:1.93982\n",
      "[39216]\teval-rmse:3.76935\ttrain-rmse:1.93981\n",
      "[39217]\teval-rmse:3.76954\ttrain-rmse:1.93981\n",
      "[39218]\teval-rmse:3.77001\ttrain-rmse:1.9398\n",
      "[39219]\teval-rmse:3.76983\ttrain-rmse:1.93981\n",
      "[39220]\teval-rmse:3.76966\ttrain-rmse:1.93981\n",
      "[39221]\teval-rmse:3.77068\ttrain-rmse:1.9398\n",
      "[39222]\teval-rmse:3.77139\ttrain-rmse:1.9398\n",
      "[39223]\teval-rmse:3.77043\ttrain-rmse:1.93983\n",
      "[39224]\teval-rmse:3.77216\ttrain-rmse:1.93978\n",
      "[39225]\teval-rmse:3.77254\ttrain-rmse:1.93978\n",
      "[39226]\teval-rmse:3.77222\ttrain-rmse:1.93978\n",
      "[39227]\teval-rmse:3.77073\ttrain-rmse:1.93979\n",
      "[39228]\teval-rmse:3.77186\ttrain-rmse:1.93979\n",
      "[39229]\teval-rmse:3.7703\ttrain-rmse:1.9398\n",
      "[39230]\teval-rmse:3.77043\ttrain-rmse:1.9398\n",
      "[39231]\teval-rmse:3.77017\ttrain-rmse:1.9398\n",
      "[39232]\teval-rmse:3.76895\ttrain-rmse:1.93982\n",
      "[39233]\teval-rmse:3.77052\ttrain-rmse:1.93977\n",
      "[39234]\teval-rmse:3.769\ttrain-rmse:1.93978\n",
      "[39235]\teval-rmse:3.76851\ttrain-rmse:1.93979\n",
      "[39236]\teval-rmse:3.76904\ttrain-rmse:1.93978\n",
      "[39237]\teval-rmse:3.76774\ttrain-rmse:1.93981\n",
      "[39238]\teval-rmse:3.76647\ttrain-rmse:1.93984\n",
      "[39239]\teval-rmse:3.76506\ttrain-rmse:1.93989\n",
      "[39240]\teval-rmse:3.76381\ttrain-rmse:1.93993\n",
      "[39241]\teval-rmse:3.76358\ttrain-rmse:1.93994\n",
      "[39242]\teval-rmse:3.76269\ttrain-rmse:1.93998\n",
      "[39243]\teval-rmse:3.76314\ttrain-rmse:1.93996\n",
      "[39244]\teval-rmse:3.76368\ttrain-rmse:1.93994\n",
      "[39245]\teval-rmse:3.76542\ttrain-rmse:1.93986\n",
      "[39246]\teval-rmse:3.76495\ttrain-rmse:1.93988\n",
      "[39247]\teval-rmse:3.76371\ttrain-rmse:1.93993\n",
      "[39248]\teval-rmse:3.76342\ttrain-rmse:1.93995\n",
      "[39249]\teval-rmse:3.76296\ttrain-rmse:1.93996\n",
      "[39250]\teval-rmse:3.76189\ttrain-rmse:1.94001\n",
      "[39251]\teval-rmse:3.7604\ttrain-rmse:1.94008\n",
      "[39252]\teval-rmse:3.76171\ttrain-rmse:1.94002\n",
      "[39253]\teval-rmse:3.76242\ttrain-rmse:1.93999\n",
      "[39254]\teval-rmse:3.76399\ttrain-rmse:1.9399\n",
      "[39255]\teval-rmse:3.76473\ttrain-rmse:1.93988\n",
      "[39256]\teval-rmse:3.76333\ttrain-rmse:1.93994\n",
      "[39257]\teval-rmse:3.76506\ttrain-rmse:1.93986\n",
      "[39258]\teval-rmse:3.76638\ttrain-rmse:1.93982\n",
      "[39259]\teval-rmse:3.76699\ttrain-rmse:1.93979\n",
      "[39260]\teval-rmse:3.76691\ttrain-rmse:1.93978\n",
      "[39261]\teval-rmse:3.76693\ttrain-rmse:1.93978\n",
      "[39262]\teval-rmse:3.76584\ttrain-rmse:1.93981\n",
      "[39263]\teval-rmse:3.76603\ttrain-rmse:1.9398\n",
      "[39264]\teval-rmse:3.76556\ttrain-rmse:1.93982\n",
      "[39265]\teval-rmse:3.76672\ttrain-rmse:1.93979\n",
      "[39266]\teval-rmse:3.76664\ttrain-rmse:1.93977\n",
      "[39267]\teval-rmse:3.76639\ttrain-rmse:1.93978\n",
      "[39268]\teval-rmse:3.7677\ttrain-rmse:1.93975\n",
      "[39269]\teval-rmse:3.76944\ttrain-rmse:1.93969\n",
      "[39270]\teval-rmse:3.76849\ttrain-rmse:1.93972\n",
      "[39271]\teval-rmse:3.76876\ttrain-rmse:1.93971\n",
      "[39272]\teval-rmse:3.76734\ttrain-rmse:1.93976\n",
      "[39273]\teval-rmse:3.76683\ttrain-rmse:1.93978\n",
      "[39274]\teval-rmse:3.76659\ttrain-rmse:1.93979\n",
      "[39275]\teval-rmse:3.76728\ttrain-rmse:1.93977\n",
      "[39276]\teval-rmse:3.76678\ttrain-rmse:1.93978\n",
      "[39277]\teval-rmse:3.767\ttrain-rmse:1.93977\n",
      "[39278]\teval-rmse:3.76748\ttrain-rmse:1.93976\n",
      "[39279]\teval-rmse:3.76717\ttrain-rmse:1.93977\n",
      "[39280]\teval-rmse:3.76843\ttrain-rmse:1.93974\n",
      "[39281]\teval-rmse:3.76827\ttrain-rmse:1.93975\n",
      "[39282]\teval-rmse:3.76872\ttrain-rmse:1.93974\n",
      "[39283]\teval-rmse:3.76909\ttrain-rmse:1.93973\n",
      "[39284]\teval-rmse:3.76935\ttrain-rmse:1.93972\n",
      "[39285]\teval-rmse:3.7679\ttrain-rmse:1.93975\n",
      "[39286]\teval-rmse:3.76758\ttrain-rmse:1.93976\n",
      "[39287]\teval-rmse:3.76779\ttrain-rmse:1.93975\n",
      "[39288]\teval-rmse:3.76894\ttrain-rmse:1.93972\n",
      "[39289]\teval-rmse:3.76767\ttrain-rmse:1.93976\n",
      "[39290]\teval-rmse:3.76765\ttrain-rmse:1.93976\n",
      "[39291]\teval-rmse:3.76897\ttrain-rmse:1.93973\n",
      "[39292]\teval-rmse:3.76932\ttrain-rmse:1.93973\n",
      "[39293]\teval-rmse:3.7709\ttrain-rmse:1.9397\n",
      "[39294]\teval-rmse:3.77082\ttrain-rmse:1.93969\n",
      "[39295]\teval-rmse:3.77052\ttrain-rmse:1.93969\n",
      "[39296]\teval-rmse:3.7701\ttrain-rmse:1.9397\n",
      "[39297]\teval-rmse:3.76961\ttrain-rmse:1.93971\n",
      "[39298]\teval-rmse:3.76929\ttrain-rmse:1.93972\n",
      "[39299]\teval-rmse:3.76802\ttrain-rmse:1.93974\n",
      "[39300]\teval-rmse:3.76875\ttrain-rmse:1.93972\n",
      "[39301]\teval-rmse:3.76923\ttrain-rmse:1.93971\n",
      "[39302]\teval-rmse:3.76959\ttrain-rmse:1.9397\n",
      "[39303]\teval-rmse:3.7683\ttrain-rmse:1.93973\n",
      "[39304]\teval-rmse:3.76827\ttrain-rmse:1.93973\n",
      "[39305]\teval-rmse:3.76884\ttrain-rmse:1.93971\n",
      "[39306]\teval-rmse:3.76719\ttrain-rmse:1.93976\n",
      "Stopping. Best iteration:\n",
      "[38806]\teval-rmse:3.77774\ttrain-rmse:1.93954\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_boost_round = 50000\n",
    "bst = xgb.train(xgb_params,\n",
    "                dtrain,\n",
    "                num_boost_round,\n",
    "                early_stopping_rounds=500,\n",
    "                evals=evallist,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 181.03427124,   20.89995766,   41.17654419], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.predict(pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
